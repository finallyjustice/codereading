[PATCH v5 0/2] Improve virtio performance for 9k mtu

... from Gavin Li <gavinl@nvidia.com> ...

https://lore.kernel.org/all/20220901021038.84751-1-gavinl@nvidia.com/


The main patch is:

[PATCH v5 2/2] virtio-net: use mtu size as buffer length for big packets

Currently, the virtio-net always allocate MAX_SKB_FRAGS size sk_buff for big
packet, even when the GSO is not enabled.

It is sufficient to use mtu size to allocate sk_buff if GSO is not used.

This patch is to NOT use mtu, if guest GSO has been negotiated then it has been
enabled, even if it's actually been disabled at runtime through
VIRTIO_NET_F_CTRL_GUEST_OFFLOADS.

Here is the performance data.

MTU(Bytes)/Bandwidth (Gbit/s)
             Before   After
  1500        22.5     22.4
  9000        12.8     25.9



The 'big_packets_num_skbfrags' is added to "struct virtnet_info".

@@ -225,6 +225,9 @@ struct virtnet_info {
 	/* I like... big packets and I cannot lie! */
 	bool big_packets;
 
+	/* number of sg entries allocated for big packets */
+	unsigned int big_packets_num_skbfrags;
+
 	/* Host will merge rx buffers for big packets (shake it! shake it!) */
 	bool mergeable_rx_bufs;


vi->big_packets_num_skbfrags is set to mtu accordingly.

+static void virtnet_set_big_packets_fields(struct virtnet_info *vi, const int mtu)
+{
+	bool guest_gso = virtnet_check_guest_gso(vi);
+
+	/* If device can receive ANY guest GSO packets, regardless of mtu,
+	 * allocate packets of maximum size, otherwise limit it to only
+	 * mtu size worth only.
+	 */
+	if (mtu > ETH_DATA_LEN || guest_gso) {
+		vi->big_packets = true;
+		vi->big_packets_num_skbfrags = guest_gso ? MAX_SKB_FRAGS : DIV_ROUND_UP(mtu, PAGE_SIZE);
+	}
+}
