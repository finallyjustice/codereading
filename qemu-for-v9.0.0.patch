From c651c4ec1f6f1f69215e20810c16421b420d0012 Mon Sep 17 00:00:00 2001
From: Dongli Zhang <dongli.zhang0129@gmail.com>
Date: Tue, 3 Sep 2024 16:01:27 -0700
Subject: [PATCH 1/1] qemu for v9.0.0

Signed-off-by: Dongli Zhang <dongli.zhang0129@gmail.com>
---
 accel/kvm/kvm-all.c                           |  128 ++
 block.c                                       | 1149 ++++++++++++++++-
 block/aio_task.c                              |    6 +
 block/block-backend.c                         |  346 +++++
 block/dirty-bitmap.c                          |    5 +
 block/file-posix.c                            |  238 ++++
 block/io.c                                    |  269 ++++
 block/mirror.c                                |  577 +++++++++
 block/qcow2-threads.c                         |    5 +
 block/qcow2.c                                 |    6 +
 block/raw-format.c                            |   99 ++
 blockdev.c                                    |  569 ++++++++
 blockjob.c                                    |   65 +
 hw/block/virtio-blk.c                         |  330 +++++
 hw/core/qdev-properties-system.c              |    6 +
 hw/core/vm-change-state-handler.c             |   87 ++
 hw/i386/kvm/apic.c                            |   14 +
 hw/net/virtio-net.c                           |   22 +
 hw/pci/msi.c                                  |   10 +
 hw/pci/msix.c                                 |   60 +
 hw/pci/pci.c                                  |   85 ++
 hw/pci/pcie.c                                 |    4 +
 hw/pci/pcie_port.c                            |   14 +
 hw/scsi/megasas.c                             |    6 +
 hw/scsi/scsi-bus.c                            |    6 +
 hw/scsi/scsi-disk.c                           |   38 +
 hw/scsi/scsi-generic.c                        |    6 +
 hw/scsi/vhost-scsi-common.c                   |   37 +
 hw/scsi/virtio-scsi.c                         |   22 +
 hw/vfio/helpers.c                             |   17 +
 hw/vfio/pci.c                                 |  132 ++
 hw/vfio/pci.h                                 |    9 +
 hw/virtio/vhost-scsi-pci.c                    |   10 +
 hw/virtio/vhost.c                             |   58 +
 hw/virtio/virtio-bus.c                        |   53 +
 hw/virtio/virtio-pci.c                        |   57 +
 hw/virtio/virtio.c                            |  148 +++
 include/block/aio.h                           |    9 +
 include/block/block_int-common.h              |   27 +
 include/hw/block/block.h                      |   30 +
 include/hw/hotplug.h                          |   23 +
 include/hw/i386/apic_internal.h               |   10 +
 include/hw/pci/pci_bus.h                      |    8 +
 include/hw/pci/pci_device.h                   |   51 +
 include/hw/scsi/scsi.h                        |   10 +
 include/hw/virtio/vhost.h                     |   42 +
 include/hw/virtio/virtio-blk.h                |   60 +
 include/hw/virtio/virtio.h                    |  141 ++
 include/qemu/coroutine-tls.h                  |   12 +
 include/qemu/transactions.h                   |   12 +
 .../standard-headers/linux/virtio_config.h    |   36 +
 include/sysemu/kvm_int.h                      |   39 +
 iothread.c                                    |   20 +
 job.c                                         |   37 +
 linux-headers/linux/kvm.h                     |    4 +
 net/tap-linux.c                               |    8 +
 net/tap.c                                     |   43 +
 scsi/utils.c                                  |    6 +
 system/cpus.c                                 |    4 +
 system/memory.c                               |   29 +
 system/qdev-monitor.c                         |    6 +
 system/vl.c                                   |   10 +
 target/arm/kvm.c                              |    5 +
 target/arm/tcg/tlb_helper.c                   |   21 +
 target/i386/cpu.c                             |   34 +
 target/i386/host-cpu.c                        |   10 +
 target/i386/kvm/kvm.c                         |  314 +++++
 util/aio-posix.c                              |   23 +
 util/aio-wait.c                               |    5 +
 util/async.c                                  |   29 +
 util/event_notifier-posix.c                   |   55 +
 util/main-loop.c                              |   46 +
 util/osdep.c                                  |  120 ++
 util/transactions.c                           |   61 +
 74 files changed, 6092 insertions(+), 1 deletion(-)

diff --git a/accel/kvm/kvm-all.c b/accel/kvm/kvm-all.c
index 931f74256..79e9fbf32 100644
--- a/accel/kvm/kvm-all.c
+++ b/accel/kvm/kvm-all.c
@@ -1182,6 +1182,11 @@ static uint32_t adjust_ioeventfd_endianness(uint32_t val, uint32_t size)
     return val;
 }
 
+/*
+ * called by:
+ *   - accel/kvm/kvm-all.c|1655| <<kvm_mem_ioeventfd_add>> r = kvm_set_ioeventfd_mmio(fd, section->offset_within_address_space, data, true, int128_get64(section->size), match_data);
+ *   - accel/kvm/kvm-all.c|1673| <<kvm_mem_ioeventfd_del>> r = kvm_set_ioeventfd_mmio(fd, section->offset_within_address_space, data, false, int128_get64(section->size), match_data);
+ */
 static int kvm_set_ioeventfd_mmio(int fd, hwaddr addr, uint32_t val,
                                   bool assign, uint32_t size, bool datamatch)
 {
@@ -1818,6 +1823,22 @@ void kvm_init_irq_routing(KVMState *s)
     kvm_arch_init_irq_routing(s);
 }
 
+/*
+ * called by:
+ *   - accel/kvm/kvm-all.c|2156| <<kvm_irqchip_add_hv_sint_route>> kvm_irqchip_commit_routes(s);
+ *   - hw/i386/kvm/ioapic.c|46| <<kvm_pc_setup_irq_routing>> kvm_irqchip_commit_routes(s);
+ *   - hw/intc/arm_gic_kvm.c|590| <<kvm_arm_gic_realize>> kvm_irqchip_commit_routes(kvm_state);
+ *   - hw/intc/arm_gicv3_kvm.c|874| <<kvm_arm_gicv3_realize>> kvm_irqchip_commit_routes(kvm_state);
+ *   - hw/intc/ioapic.c|208| <<ioapic_update_kvm_routes>> kvm_irqchip_commit_routes(kvm_state);
+ *   - hw/intc/openpic_kvm.c|254| <<kvm_openpic_realize>> kvm_irqchip_commit_routes(s);
+ *   - hw/intc/s390_flic_kvm.c|345| <<kvm_s390_add_adapter_routes>> kvm_irqchip_commit_routes(kvm_state);
+ *   - hw/misc/ivshmem.c|294| <<ivshmem_vector_unmask>> kvm_irqchip_commit_routes(kvm_state);
+ *   - hw/vfio/pci.c|510| <<vfio_update_kvm_msi_virq>> kvm_irqchip_commit_routes(kvm_state);
+ *   - hw/virtio/virtio-pci.c|1005| <<virtio_pci_one_vector_unmask>> kvm_irqchip_commit_routes(kvm_state);
+ *   - include/sysemu/kvm.h|468| <<kvm_irqchip_commit_route_changes>> kvm_irqchip_commit_routes(c->s);
+ *   - target/i386/kvm/kvm.c|5552| <<kvm_update_msi_routes_all>> kvm_irqchip_commit_routes(kvm_state);
+ *   - target/riscv/kvm/kvm-cpu.c|1660| <<kvm_riscv_aia_create>> kvm_irqchip_commit_routes(kvm_state);
+ */
 void kvm_irqchip_commit_routes(KVMState *s)
 {
     int ret;
@@ -1836,6 +1857,13 @@ void kvm_irqchip_commit_routes(KVMState *s)
     assert(ret == 0);
 }
 
+/*
+ * called by:
+ *   - accel/kvm/kvm-all.c|1919| <<kvm_irqchip_add_irq_route>> kvm_add_routing_entry(s, &e);
+ *   - accel/kvm/kvm-all.c|2060| <<kvm_irqchip_add_msi_route>> kvm_add_routing_entry(s, &kroute);
+ *   - accel/kvm/kvm-all.c|2177| <<kvm_irqchip_add_adapter_route>> kvm_add_routing_entry(s, &kroute);
+ *   - accel/kvm/kvm-all.c|2204| <<kvm_irqchip_add_hv_sint_route>> kvm_add_routing_entry(s, &kroute);
+ */
 static void kvm_add_routing_entry(KVMState *s,
                                   struct kvm_irq_routing_entry *entry)
 {
@@ -1860,6 +1888,10 @@ static void kvm_add_routing_entry(KVMState *s,
     set_gsi(s, entry->gsi);
 }
 
+/*
+ * called by:
+ *   - accel/kvm/kvm-all.c|2100| <<kvm_irqchip_update_msi_route>> return kvm_update_routing_entry(s, &kroute);
+ */
 static int kvm_update_routing_entry(KVMState *s,
                                     struct kvm_irq_routing_entry *new_entry)
 {
@@ -1884,6 +1916,17 @@ static int kvm_update_routing_entry(KVMState *s,
     return -ESRCH;
 }
 
+/*
+ * called by:
+ *   - hw/i386/kvm/ioapic.c|32| <<kvm_pc_setup_irq_routing>> kvm_irqchip_add_irq_route(s, i, KVM_IRQCHIP_PIC_MASTER, i);
+ *   - hw/i386/kvm/ioapic.c|35| <<kvm_pc_setup_irq_routing>> kvm_irqchip_add_irq_route(s, i, KVM_IRQCHIP_PIC_SLAVE, i - 8);
+ *   - hw/i386/kvm/ioapic.c|40| <<kvm_pc_setup_irq_routing>> kvm_irqchip_add_irq_route(s, i, KVM_IRQCHIP_IOAPIC, 2);
+ *   - hw/i386/kvm/ioapic.c|42| <<kvm_pc_setup_irq_routing>> kvm_irqchip_add_irq_route(s, i, KVM_IRQCHIP_IOAPIC, i);
+ *   - hw/intc/arm_gic_kvm.c|585| <<kvm_arm_gic_realize>> kvm_irqchip_add_irq_route(kvm_state, i, 0, i);
+ *   - hw/intc/arm_gicv3_kvm.c|869| <<kvm_arm_gicv3_realize>> kvm_irqchip_add_irq_route(kvm_state, i, 0, i);
+ *   - hw/intc/openpic_kvm.c|248| <<kvm_openpic_realize>> kvm_irqchip_add_irq_route(kvm_state, i, 0, i);
+ *   - target/riscv/kvm/kvm-cpu.c|1657| <<kvm_riscv_aia_create>> kvm_irqchip_add_irq_route(kvm_state, idx, 0, idx);
+ */
 void kvm_irqchip_add_irq_route(KVMState *s, int irq, int irqchip, int pin)
 {
     struct kvm_irq_routing_entry e = {};
@@ -1947,6 +1990,11 @@ static int kvm_irqchip_get_virq(KVMState *s)
     }
 }
 
+/*
+ * called by:
+ *   - hw/i386/kvm/apic.c|193| <<kvm_send_msi>> ret = kvm_irqchip_send_msi(kvm_state, *msg);
+ *   - target/i386/kvm/xen-emu.c|456| <<kvm_xen_inject_vcpu_callback_vector>> kvm_irqchip_send_msi(kvm_state, msg);
+ */
 int kvm_irqchip_send_msi(KVMState *s, MSIMessage msg)
 {
     struct kvm_msi msi;
@@ -1960,6 +2008,13 @@ int kvm_irqchip_send_msi(KVMState *s, MSIMessage msg)
     return kvm_vm_ioctl(s, KVM_SIGNAL_MSI, &msi);
 }
 
+/*
+ * called by:
+ *   - hw/misc/ivshmem.c|434| <<ivshmem_add_kvm_msi_virq>> ret = kvm_irqchip_add_msi_route(&c, vector, pdev);
+ *   - hw/vfio/pci.c|469| <<vfio_add_kvm_msi_virq>> vector->virq = kvm_irqchip_add_msi_route(&vfio_route_change, vector_n, &vdev->pdev);
+ *   - hw/virtio/virtio-pci.c|819| <<kvm_virtio_pci_vq_vector_use>> ret = kvm_irqchip_add_msi_route(&c, vector, &proxy->pci_dev);
+ *   - target/i386/kvm/kvm.c|5400| <<kvm_arch_init_irq_routing>> if (kvm_irqchip_add_msi_route(&c, 0, NULL) < 0) {
+ */
 int kvm_irqchip_add_msi_route(KVMRouteChange *c, int vector, PCIDevice *dev)
 {
     struct kvm_irq_routing_entry kroute = {};
@@ -1984,6 +2039,32 @@ int kvm_irqchip_add_msi_route(KVMRouteChange *c, int vector, PCIDevice *dev)
         return virq;
     }
 
+    /*
+     * 1162 struct kvm_irq_routing_msi {
+     * 1163         __u32 address_lo;
+     * 1164         __u32 address_hi;
+     * 1165         __u32 data;
+     * 1166         union {
+     * 1167                 __u32 pad;
+     * 1168                 __u32 devid;
+     * 1169         };
+     * 1170 };
+     *
+     * 1200 struct kvm_irq_routing_entry {
+     * 1201         __u32 gsi;
+     * 1202         __u32 type;
+     * 1203         __u32 flags;
+     * 1204         __u32 pad;
+     * 1205         union {
+     * 1206                 struct kvm_irq_routing_irqchip irqchip;
+     * 1207                 struct kvm_irq_routing_msi msi;
+     * 1208                 struct kvm_irq_routing_s390_adapter adapter;
+     * 1209                 struct kvm_irq_routing_hv_sint hv_sint;
+     * 1210                 struct kvm_irq_routing_xen_evtchn xen_evtchn;
+     * 1211                 __u32 pad[8];
+     * 1212         } u;
+     * 1213 };
+     */
     kroute.gsi = virq;
     kroute.type = KVM_IRQ_ROUTING_MSI;
     kroute.flags = 0;
@@ -1994,6 +2075,11 @@ int kvm_irqchip_add_msi_route(KVMRouteChange *c, int vector, PCIDevice *dev)
         kroute.flags = KVM_MSI_VALID_DEVID;
         kroute.u.msi.devid = pci_requester_id(dev);
     }
+    /*
+     * called by:
+     *   - accel/kvm/kvm-all.c|2078| <<kvm_irqchip_add_msi_route>> if (kvm_arch_fixup_msi_route(&kroute, msg.address, msg.data, dev)) {
+     *   - accel/kvm/kvm-all.c|2129| <<kvm_irqchip_update_msi_route>> if (kvm_arch_fixup_msi_route(&kroute, msg.address, msg.data, dev)) {
+     */
     if (kvm_arch_fixup_msi_route(&kroute, msg.address, msg.data, dev)) {
         kvm_irqchip_release_virq(s, virq);
         return -EINVAL;
@@ -2014,6 +2100,14 @@ int kvm_irqchip_add_msi_route(KVMRouteChange *c, int vector, PCIDevice *dev)
     return virq;
 }
 
+/*
+ * called by:
+ *   - hw/intc/ioapic.c|205| <<ioapic_update_kvm_routes>> kvm_irqchip_update_msi_route(kvm_state, i, msg, NULL);
+ *   - hw/misc/ivshmem.c|290| <<ivshmem_vector_unmask>> ret = kvm_irqchip_update_msi_route(kvm_state, v->virq, msg, dev);
+ *   - hw/vfio/pci.c|519| <<vfio_update_kvm_msi_virq>> kvm_irqchip_update_msi_route(kvm_state, vector->virq, msg, pdev);
+ *   - hw/virtio/virtio-pci.c|1027| <<virtio_pci_one_vector_unmask>> ret = kvm_irqchip_update_msi_route(kvm_state, irqfd->virq, msg, &proxy->pci_dev);
+ *   - target/i386/kvm/kvm.c|5550| <<kvm_update_msi_routes_all>> kvm_irqchip_update_msi_route(kvm_state, entry->virq, msg, dev);
+ */
 int kvm_irqchip_update_msi_route(KVMState *s, int virq, MSIMessage msg,
                                  PCIDevice *dev)
 {
@@ -2037,15 +2131,28 @@ int kvm_irqchip_update_msi_route(KVMState *s, int virq, MSIMessage msg,
         kroute.flags = KVM_MSI_VALID_DEVID;
         kroute.u.msi.devid = pci_requester_id(dev);
     }
+    /*
+     * called by:
+     *   - accel/kvm/kvm-all.c|2078| <<kvm_irqchip_add_msi_route>> if (kvm_arch_fixup_msi_route(&kroute, msg.address, msg.data, dev)) {
+     *   - accel/kvm/kvm-all.c|2129| <<kvm_irqchip_update_msi_route>> if (kvm_arch_fixup_msi_route(&kroute, msg.address, msg.data, dev)) {
+     */
     if (kvm_arch_fixup_msi_route(&kroute, msg.address, msg.data, dev)) {
         return -EINVAL;
     }
 
     trace_kvm_irqchip_update_msi_route(virq);
 
+    /*
+     * 只在此处调用
+     */
     return kvm_update_routing_entry(s, &kroute);
 }
 
+/*
+ * called by:
+ *   - accel/kvm/kvm-all.c|2202| <<kvm_irqchip_add_irqfd_notifier_gsi>> return kvm_irqchip_assign_irqfd(s, n, rn, virq, true);
+ *   - accel/kvm/kvm-all.c|2208| <<kvm_irqchip_remove_irqfd_notifier_gsi>> return kvm_irqchip_assign_irqfd(s, n, NULL, virq, false);
+ */
 static int kvm_irqchip_assign_irqfd(KVMState *s, EventNotifier *event,
                                     EventNotifier *resample, int virq,
                                     bool assign)
@@ -2092,6 +2199,10 @@ static int kvm_irqchip_assign_irqfd(KVMState *s, EventNotifier *event,
     return kvm_vm_ioctl(s, KVM_IRQFD, &irqfd);
 }
 
+/*
+ * called by:
+ *   - hw/intc/s390_flic_kvm.c|338| <<kvm_s390_add_adapter_routes>> ret = kvm_irqchip_add_adapter_route(kvm_state, &routes->adapter);
+ */
 int kvm_irqchip_add_adapter_route(KVMState *s, AdapterInfo *adapter)
 {
     struct kvm_irq_routing_entry kroute = {};
@@ -2191,6 +2302,19 @@ int kvm_irqchip_update_msi_route(KVMState *s, int virq, MSIMessage msg)
 }
 #endif /* !KVM_CAP_IRQ_ROUTING */
 
+/*
+ * called by:
+ *   - accel/kvm/kvm-all.c|2220| <<kvm_irqchip_add_irqfd_notifier>> return kvm_irqchip_add_irqfd_notifier_gsi(s, n, rn, GPOINTER_TO_INT(gsi));
+ *   - accel/stubs/kvm-stub.c|86| <<kvm_irqchip_add_irqfd_notifier_gsi>> int kvm_irqchip_add_irqfd_notifier_gsi(KVMState *s, EventNotifier *n,
+ *   - hw/hyperv/hyperv.c|438| <<hyperv_sint_route_new>> r = kvm_irqchip_add_irqfd_notifier_gsi(kvm_state, &sint_route->sint_set_notifier, ack_notifier, gsi);
+ *   - hw/misc/ivshmem.c|296| <<ivshmem_vector_unmask>> ret = kvm_irqchip_add_irqfd_notifier_gsi(kvm_state, n, NULL, v->virq);
+ *   - hw/misc/ivshmem.c|467| <<setup_interrupt>> kvm_irqchip_add_irqfd_notifier_gsi(kvm_state, n, NULL, s->msi_vectors[vector].virq);
+ *   - hw/remote/proxy.c|45| <<proxy_intx_update>> kvm_irqchip_add_irqfd_notifier_gsi(kvm_state, &dev->intr, &dev->resample, dev->virq);
+ *   - hw/s390x/virtio-ccw.c|1003| <<virtio_ccw_add_irqfd>> return kvm_irqchip_add_irqfd_notifier_gsi(kvm_state, notifier, NULL, dev->routes.gsi[n]);
+ *   - hw/vfio/pci.c|142| <<vfio_intx_enable_kvm>> if (kvm_irqchip_add_irqfd_notifier_gsi(kvm_state, &vdev->intx.interrupt, &vdev->intx.unmask, vdev->intx.route.irq)) {
+ *   - hw/vfio/pci.c|483| <<vfio_connect_kvm_msi_virq>> if (kvm_irqchip_add_irqfd_notifier_gsi(kvm_state, &vector->kvm_interrupt, NULL, vector->virq) < 0) {
+ *   - hw/virtio/virtio-pci.c|844| <<kvm_virtio_pci_irqfd_use>> return kvm_irqchip_add_irqfd_notifier_gsi(kvm_state, n, NULL, irqfd->virq);
+ */
 int kvm_irqchip_add_irqfd_notifier_gsi(KVMState *s, EventNotifier *n,
                                        EventNotifier *rn, int virq)
 {
@@ -3387,6 +3511,10 @@ int kvm_on_sigbus_vcpu(CPUState *cpu, int code, void *addr)
 #endif
 }
 
+/*
+ * 在以下使用kvm_on_sigbus():
+ *   - system/cpus.c|373| <<sigbus_handler>> if (kvm_on_sigbus(siginfo->si_code, siginfo->si_addr)) {
+ */
 /* Called synchronously (via signalfd) in main thread.  */
 int kvm_on_sigbus(int code, void *addr)
 {
diff --git a/block.c b/block.c
index 468cf5e67..c977fbf12 100644
--- a/block.c
+++ b/block.c
@@ -68,14 +68,49 @@
 
 #define NOT_DONE 0x7fffffff /* used while emulated sync operation in progress */
 
+/*
+ * 这个文档:
+ * A Practical Look at QEMU's Block Layer Primitives
+ * https://kashyapc.fedorapeople.org/virt/LinuxCon-NA-2016/A-Practical-Look-at-QEMU-Block-Layer-Primitives-LC-NA-2016.pdf
+ */
+
+/*
+ * 在以下使用graph_bdrv_states:
+ *   - block.c|72| <<QTAILQ_HEAD>> static QTAILQ_HEAD(, BlockDriverState) graph_bdrv_states =
+ *   - block.c|1636| <<bdrv_assign_node_name>> QTAILQ_INSERT_TAIL(&graph_bdrv_states, bs, node_list);
+ *   - block.c|5682| <<bdrv_delete>> QTAILQ_REMOVE(&graph_bdrv_states, bs, node_list);
+ *   - block.c|6360| <<bdrv_find_node>> QTAILQ_FOREACH(bs, &graph_bdrv_states, node_list) {
+ *   - block.c|6379| <<bdrv_named_nodes_list>> QTAILQ_FOREACH(bs, &graph_bdrv_states, node_list) {
+ *   - block.c|6514| <<bdrv_get_xdbg_block_graph>> QTAILQ_FOREACH(bs, &graph_bdrv_states, node_list) {
+ *   - block.c|6579| <<bdrv_next_node>> return QTAILQ_FIRST(&graph_bdrv_states);
+ */
 /* Protected by BQL */
 static QTAILQ_HEAD(, BlockDriverState) graph_bdrv_states =
     QTAILQ_HEAD_INITIALIZER(graph_bdrv_states);
 
+/*
+ * 在以下使用all_bdrv_states:
+ *   - block.c|92| <<QTAILQ_HEAD>> static QTAILQ_HEAD(, BlockDriverState) all_bdrv_states =
+ *   - block.c|93| <<QTAILQ_HEAD>> QTAILQ_HEAD_INITIALIZER(all_bdrv_states);
+ *   - block.c|511| <<bdrv_new>> QTAILQ_INSERT_TAIL(&all_bdrv_states, bs, bs_list);
+ *   - block.c|5435| <<bdrv_close_all>> assert(QTAILQ_EMPTY(&all_bdrv_states));
+ *   - block.c|5941| <<bdrv_delete>> QTAILQ_REMOVE(&all_bdrv_states, bs, bs_list);
+ *   - block.c|6955| <<bdrv_next_all_states>> return QTAILQ_FIRST(&all_bdrv_states);
+ */
 /* Protected by BQL */
 static QTAILQ_HEAD(, BlockDriverState) all_bdrv_states =
     QTAILQ_HEAD_INITIALIZER(all_bdrv_states);
 
+/*
+ * 在以下使用bdrv_drivers:
+ *   - block.c|6580| <<global>> QLIST_FOREACH(drv, &bdrv_drivers, list) 
+ *   - block.c|97| <<QLIST_HEAD>> QLIST_HEAD_INITIALIZER(bdrv_drivers);
+ *   - block.c|482| <<bdrv_register>> QLIST_INSERT_HEAD(&bdrv_drivers, bdrv, list);
+ *   - block.c|521| <<bdrv_do_find_format>> QLIST_FOREACH(drv1, &bdrv_drivers, list) {
+ *   - block.c|966| <<find_hdev_driver>> QLIST_FOREACH(d, &bdrv_drivers, list) {
+ *   - block.c|984| <<bdrv_do_find_protocol>> QLIST_FOREACH(drv1, &bdrv_drivers, list) 
+ *   - block.c|1075| <<bdrv_probe_all>> QLIST_FOREACH(d, &bdrv_drivers, list) {
+ */
 /* Protected by BQL */
 static QLIST_HEAD(, BlockDriver) bdrv_drivers =
     QLIST_HEAD_INITIALIZER(bdrv_drivers);
@@ -400,13 +435,87 @@ char *bdrv_get_full_backing_filename(BlockDriverState *bs, Error **errp)
     return bdrv_make_absolute_filename(bs, bs->backing_file, errp);
 }
 
+/*
+ * called by:
+ *   - block/blkdebug.c|1104| <<bdrv_blkdebug_init>> bdrv_register(&bdrv_blkdebug);
+ *   - block/blkio.c|1145| <<bdrv_blkio_init>> bdrv_register(&bdrv_io_uring);
+ *   - block/blkio.c|1146| <<bdrv_blkio_init>> bdrv_register(&bdrv_nvme_io_uring);
+ *   - block/blkio.c|1147| <<bdrv_blkio_init>> bdrv_register(&bdrv_virtio_blk_vfio_pci);
+ *   - block/blkio.c|1148| <<bdrv_blkio_init>> bdrv_register(&bdrv_virtio_blk_vhost_user);
+ *   - block/blkio.c|1149| <<bdrv_blkio_init>> bdrv_register(&bdrv_virtio_blk_vhost_vdpa);
+ *   - block/blklogwrites.c|612| <<bdrv_blk_log_writes_init>> bdrv_register(&bdrv_blk_log_writes);
+ *   - block/blkreplay.c|163| <<bdrv_blkreplay_init>> bdrv_register(&bdrv_blkreplay);
+ *   - block/blkverify.c|341| <<bdrv_blkverify_init>> bdrv_register(&bdrv_blkverify);
+ *   - block/bochs.c|316| <<bdrv_bochs_init>> bdrv_register(&bdrv_bochs);
+ *   - block/cloop.c|312| <<bdrv_cloop_init>> bdrv_register(&bdrv_cloop);
+ *   - block/copy-before-write.c|562| <<cbw_init>> bdrv_register(&bdrv_cbw_filter);
+ *   - block/copy-on-read.c|293| <<bdrv_copy_on_read_init>> bdrv_register(&bdrv_copy_on_read);
+ *   - block/crypto.c|1098| <<block_crypto_init>> bdrv_register(&bdrv_crypto_luks);
+ *   - block/curl.c|1109| <<curl_block_init>> bdrv_register(&bdrv_http);
+ *   - block/curl.c|1110| <<curl_block_init>> bdrv_register(&bdrv_https);
+ *   - block/curl.c|1111| <<curl_block_init>> bdrv_register(&bdrv_ftp);
+ *   - block/curl.c|1112| <<curl_block_init>> bdrv_register(&bdrv_ftps);
+ *   - block/dmg.c|798| <<bdrv_dmg_init>> bdrv_register(&bdrv_dmg);
+ *   - block/file-posix.c|4746| <<bdrv_file_init>> bdrv_register(&bdrv_file);
+ *   - block/file-posix.c|4748| <<bdrv_file_init>> bdrv_register(&bdrv_host_device);
+ *   - block/file-posix.c|4750| <<bdrv_file_init>> bdrv_register(&bdrv_host_cdrom);
+ *   - block/file-posix.c|4753| <<bdrv_file_init>> bdrv_register(&bdrv_host_cdrom);
+ *   - block/file-win32.c|940| <<bdrv_file_init>> bdrv_register(&bdrv_file);
+ *   - block/file-win32.c|941| <<bdrv_file_init>> bdrv_register(&bdrv_host_device);
+ *   - block/filter-compress.c|157| <<bdrv_compress_init>> bdrv_register(&bdrv_compress);
+ *   - block/gluster.c|1678| <<bdrv_gluster_init>> bdrv_register(&bdrv_gluster_rdma);
+ *   - block/gluster.c|1679| <<bdrv_gluster_init>> bdrv_register(&bdrv_gluster_unix);
+ *   - block/gluster.c|1680| <<bdrv_gluster_init>> bdrv_register(&bdrv_gluster_tcp);
+ *   - block/gluster.c|1681| <<bdrv_gluster_init>> bdrv_register(&bdrv_gluster);
+ *   - block/iscsi.c|2506| <<iscsi_block_init>> bdrv_register(&bdrv_iscsi);
+ *   - block/iscsi.c|2508| <<iscsi_block_init>> bdrv_register(&bdrv_iser);
+ *   - block/nbd.c|2230| <<bdrv_nbd_init>> bdrv_register(&bdrv_nbd);
+ *   - block/nbd.c|2231| <<bdrv_nbd_init>> bdrv_register(&bdrv_nbd_tcp);
+ *   - block/nbd.c|2232| <<bdrv_nbd_init>> bdrv_register(&bdrv_nbd_unix);
+ *   - block/nfs.c|917| <<nfs_block_init>> bdrv_register(&bdrv_nfs);
+ *   - block/null.c|325| <<bdrv_null_init>> bdrv_register(&bdrv_null_co);
+ *   - block/null.c|326| <<bdrv_null_init>> bdrv_register(&bdrv_null_aio);
+ *   - block/nvme.c|1662| <<bdrv_nvme_init>> bdrv_register(&bdrv_nvme);
+ *   - block/parallels.c|1482| <<bdrv_parallels_init>> bdrv_register(&bdrv_parallels);
+ *   - block/preallocate.c|624| <<bdrv_preallocate_init>> bdrv_register(&bdrv_preallocate_filter);
+ *   - block/qcow.c|1215| <<bdrv_qcow_init>> bdrv_register(&bdrv_qcow);
+ *   - block/qcow2.c|6203| <<bdrv_qcow2_init>> bdrv_register(&bdrv_qcow2);
+ *   - block/qed.c|1678| <<bdrv_qed_init>> bdrv_register(&bdrv_qed);
+ *   - block/quorum.c|1315| <<bdrv_quorum_init>> bdrv_register(&bdrv_quorum);
+ *   - block/raw-format.c|679| <<bdrv_raw_init>> bdrv_register(&bdrv_raw);
+ *   - block/rbd.c|1852| <<bdrv_rbd_init>> bdrv_register(&bdrv_rbd);
+ *   - block/replication.c|748| <<bdrv_replication_init>> bdrv_register(&bdrv_replication);
+ *   - block/snapshot-access.c|132| <<snapshot_access_init>> bdrv_register(&bdrv_snapshot_access_drv);
+ *   - block/ssh.c|1390| <<bdrv_ssh_init>> bdrv_register(&bdrv_ssh);
+ *   - block/throttle.c|276| <<bdrv_throttle_init>> bdrv_register(&bdrv_throttle);
+ *   - block/vdi.c|1063| <<bdrv_vdi_init>> bdrv_register(&bdrv_vdi);
+ *   - block/vhdx.c|2270| <<bdrv_vhdx_init>> bdrv_register(&bdrv_vhdx);
+ *   - block/vmdk.c|3179| <<bdrv_vmdk_init>> bdrv_register(&bdrv_vmdk);
+ *   - block/vpc.c|1254| <<bdrv_vpc_init>> bdrv_register(&bdrv_vpc);
+ *   - block/vvfat.c|3277| <<bdrv_vvfat_init>> bdrv_register(&bdrv_vvfat);
+ */
 void bdrv_register(BlockDriver *bdrv)
 {
     assert(bdrv->format_name);
     GLOBAL_STATE_CODE();
+    /*
+     * 在以下使用bdrv_drivers:
+     *   - block.c|6580| <<global>> QLIST_FOREACH(drv, &bdrv_drivers, list)
+     *   - block.c|97| <<QLIST_HEAD>> QLIST_HEAD_INITIALIZER(bdrv_drivers);
+     *   - block.c|482| <<bdrv_register>> QLIST_INSERT_HEAD(&bdrv_drivers, bdrv, list);
+     *   - block.c|521| <<bdrv_do_find_format>> QLIST_FOREACH(drv1, &bdrv_drivers, list) {
+     *   - block.c|966| <<find_hdev_driver>> QLIST_FOREACH(d, &bdrv_drivers, list) {
+     *   - block.c|984| <<bdrv_do_find_protocol>> QLIST_FOREACH(drv1, &bdrv_drivers, list)
+     *   - block.c|1075| <<bdrv_probe_all>> QLIST_FOREACH(d, &bdrv_drivers, list) {
+     */
     QLIST_INSERT_HEAD(&bdrv_drivers, bdrv, list);
 }
 
+/*
+ * called by:
+ *   - block.c|1895| <<bdrv_new_open_driver_opts>> bs = bdrv_new();
+ *   - block.c|4507| <<bdrv_open_inherit>> bs = bdrv_new();
+ */
 BlockDriverState *bdrv_new(void)
 {
     BlockDriverState *bs;
@@ -1226,11 +1335,24 @@ static int bdrv_child_cb_inactivate(BdrvChild *child)
     return 0;
 }
 
+/*
+ * 看过了
+ */
 static bool bdrv_child_cb_change_aio_ctx(BdrvChild *child, AioContext *ctx,
                                          GHashTable *visited, Transaction *tran,
                                          Error **errp)
 {
     BlockDriverState *bs = child->opaque;
+    /*
+     * called by:
+     *   - block.c|1343| <<bdrv_child_cb_change_aio_ctx>> return bdrv_change_aio_context(bs, ctx, visited, tran, errp);
+     *   - block.c|8493| <<bdrv_child_change_aio_context>> return bdrv_change_aio_context(c->bs, ctx, visited, tran, errp);
+     *   - block.c|8600| <<bdrv_try_change_aio_context>> ret = bdrv_change_aio_context(bs, ctx, visited, tran, errp);
+     *
+     * 返回0 (false是失败)
+     *
+     * 看过了
+     */
     return bdrv_change_aio_context(bs, ctx, visited, tran, errp);
 }
 
@@ -1258,6 +1380,10 @@ static void bdrv_temp_snapshot_options(int *child_flags, QDict *child_options,
     *child_flags &= ~BDRV_O_NATIVE_AIO;
 }
 
+/*
+ * called by:
+ *   - block.c|1582| <<bdrv_child_cb_attach>> bdrv_backing_attach(child);
+ */
 static void GRAPH_WRLOCK bdrv_backing_attach(BdrvChild *c)
 {
     BlockDriverState *parent = c->opaque;
@@ -1298,6 +1424,10 @@ static void GRAPH_WRLOCK bdrv_backing_attach(BdrvChild *c)
                     parent->backing_blocker);
 }
 
+/*
+ * called by:
+ *   - block.c|1590| <<bdrv_child_cb_detach>> bdrv_backing_detach(child);
+ */
 static void bdrv_backing_detach(BdrvChild *c)
 {
     BlockDriverState *parent = c->opaque;
@@ -1436,6 +1566,8 @@ static void bdrv_inherited_options(BdrvChildRole role, bool parent_is_format,
     *child_flags = flags;
 }
 
+/*
+ */
 static void GRAPH_WRLOCK bdrv_child_cb_attach(BdrvChild *child)
 {
     BlockDriverState *bs = child->opaque;
@@ -1478,6 +1610,11 @@ static void GRAPH_WRLOCK bdrv_child_cb_attach(BdrvChild *child)
     }
 }
 
+/*
+ * 1. 从BdrvChild->opaque中取出BlockDriverState(上一级的)
+ * 2. 把这个BdrvChild从上一级的BlockDriverState->children移除
+ * 3. 根据情况修改上一级的BlockDriverState->file或者backing
+ */
 static void GRAPH_WRLOCK bdrv_child_cb_detach(BdrvChild *child)
 {
     BlockDriverState *bs = child->opaque;
@@ -1487,7 +1624,18 @@ static void GRAPH_WRLOCK bdrv_child_cb_detach(BdrvChild *child)
     }
 
     assert_bdrv_graph_writable();
+    /*
+     * BdrvChild *child:
+     * -> QLIST_ENTRY(BdrvChild GRAPH_RDLOCK_PTR) next;
+     * -> QLIST_ENTRY(BdrvChild GRAPH_RDLOCK_PTR) next_parent;
+     */
     QLIST_REMOVE(child, next);
+    /*
+     * BlockDriverState *bs = child->opaque
+     * -> QLIST_HEAD(, BdrvChild GRAPH_RDLOCK_PTR) children;
+     * -> BdrvChild * GRAPH_RDLOCK_PTR backing;
+     * -> BdrvChild * GRAPH_RDLOCK_PTR file;
+     */
     if (child == bs->backing) {
         assert(child != bs->file);
         bs->backing = NULL;
@@ -1532,9 +1680,19 @@ const BdrvChildClass child_of_bds = {
     .get_parent_aio_context = child_of_bds_get_parent_aio_context,
 };
 
+/*
+ * called by:
+ *   - block.c|3446| <<bdrv_attach_child_common_abort>> if (bdrv_child_get_parent_aio_context(s->child) != s->old_parent_ctx) {
+ *   - block.c|3557| <<bdrv_attach_child_common>> parent_ctx = bdrv_child_get_parent_aio_context(new_child);
+ */
 AioContext *bdrv_child_get_parent_aio_context(BdrvChild *c)
 {
     IO_CODE();
+    /*
+     * BdrvChildClass child_of_bds.get_parent_aio_context = child_of_bds_get_parent_aio_context()
+     * BdrvChildClass child_root.get_parent_aio_context = blk_root_get_parent_aio_context()
+     * BdrvChildClass child_job.get_parent_aio_context = child_job_get_parent_aio_context()
+     */
     return c->klass->get_parent_aio_context(c);
 }
 
@@ -1594,6 +1752,10 @@ static void update_options_from_flags(QDict *options, int flags)
     }
 }
 
+/*
+ * called by:
+ *   - block.c|1649| <<bdrv_open_driver>> bdrv_assign_node_name(bs, node_name, &local_err);
+ */
 static void bdrv_assign_node_name(BlockDriverState *bs,
                                   const char *node_name,
                                   Error **errp)
@@ -1633,6 +1795,16 @@ static void bdrv_assign_node_name(BlockDriverState *bs,
 
     /* copy node name into the bs and insert it into the graph list */
     pstrcpy(bs->node_name, sizeof(bs->node_name), node_name);
+    /*
+     * 在以下使用graph_bdrv_states:
+     *   - block.c|72| <<QTAILQ_HEAD>> static QTAILQ_HEAD(, BlockDriverState) graph_bdrv_states =
+     *   - block.c|1636| <<bdrv_assign_node_name>> QTAILQ_INSERT_TAIL(&graph_bdrv_states, bs, node_list);
+     *   - block.c|5682| <<bdrv_delete>> QTAILQ_REMOVE(&graph_bdrv_states, bs, node_list);
+     *   - block.c|6360| <<bdrv_find_node>> QTAILQ_FOREACH(bs, &graph_bdrv_states, node_list) {
+     *   - block.c|6379| <<bdrv_named_nodes_list>> QTAILQ_FOREACH(bs, &graph_bdrv_states, node_list) {
+     *   - block.c|6514| <<bdrv_get_xdbg_block_graph>> QTAILQ_FOREACH(bs, &graph_bdrv_states, node_list) {
+     *   - block.c|6579| <<bdrv_next_node>> return QTAILQ_FIRST(&graph_bdrv_states);
+     */
     QTAILQ_INSERT_TAIL(&graph_bdrv_states, bs, node_list);
 out:
     g_free(gen_node_name);
@@ -1738,6 +1910,11 @@ open_failed:
  * after the call (even on failure), so if the caller intends to reuse the
  * dictionary, it needs to use qobject_ref() before calling bdrv_open.
  */
+/*
+ * called by:
+ *   - block.c|1927| <<bdrv_new_open_driver>> return bdrv_new_open_driver_opts(drv, node_name, NULL, flags, errp);
+ *   - block.c|6341| <<bdrv_insert_node>> new_node_bs = bdrv_new_open_driver_opts(drv, node_name, options, flags, errp);
+ */
 BlockDriverState *bdrv_new_open_driver_opts(BlockDriver *drv,
                                             const char *node_name,
                                             QDict *options, int flags,
@@ -1769,6 +1946,12 @@ BlockDriverState *bdrv_new_open_driver_opts(BlockDriver *drv,
     return bs;
 }
 
+/*
+ * 非unit test的使用:
+ *   - block/commit.c|314| <<commit_start>> commit_top_bs = bdrv_new_open_driver(&bdrv_commit_top, filter_node_name, 0, errp);
+ *   - block/commit.c|505| <<bdrv_commit>> commit_top_bs = bdrv_new_open_driver(&bdrv_commit_top, NULL, BDRV_O_RDWR, &local_err);
+ *   - block/mirror.c|1797| <<mirror_start_job>> mirror_top_bs = bdrv_new_open_driver(&bdrv_mirror_top, filter_node_name, BDRV_O_RDWR, errp);
+ */
 /* Create and open a block node. */
 BlockDriverState *bdrv_new_open_driver(BlockDriver *drv, const char *node_name,
                                        int flags, Error **errp)
@@ -2202,6 +2385,10 @@ static char *bdrv_child_user_desc(BdrvChild *c)
  * Check that @a allows everything that @b needs. @a and @b must reference same
  * child node.
  */
+/*
+ * called by:
+ *   - block.c|2435| <<bdrv_parent_perms_conflict>> if (!bdrv_a_allow_b(a, b, errp)) {
+ */
 static bool bdrv_a_allow_b(BdrvChild *a, BdrvChild *b, Error **errp)
 {
     const char *child_bs_name;
@@ -2379,10 +2566,39 @@ TransactionActionDrv bdrv_drv_set_perm_drv = {
     .commit = bdrv_drv_set_perm_commit,
 };
 
+/*
+ * [0] qemu_lock_fd
+ * [0] raw_handle_perm_lock
+ * [0] raw_check_perm
+ * [0] bdrv_drv_set_perm
+ * [0] bdrv_node_refresh_perm
+ * [0] bdrv_list_refresh_perms
+ * [0] bdrv_replace_node_common
+ * [0] mirror_start_job
+ * [0] commit_active_start
+ * [0] qmp_block_commit
+ * [0] qmp_marshal_block_commit
+ * [0] do_qmp_dispatch_bh
+ * [0] aio_bh_poll
+ * [0] aio_dispatch
+ * [0] aio_ctx_dispatch
+ * [0] g_main_context_dispatch
+ * [0] glib_pollfds_poll
+ * [0] os_host_main_loop_wait
+ * [0] main_loop_wait
+ * [0] qemu_main_loop
+ * [0] qemu_default_main
+ * [0] __libc_start_main
+ * [0] _start
+ */
 /*
  * After calling this function, the transaction @tran may only be completed
  * while holding a reader lock for the graph.
  */
+/*
+ * called by:
+ *   - block.c|2546| <<bdrv_node_refresh_perm>> ret = bdrv_drv_set_perm(bs, cumulative_perms, cumulative_shared_perms, tran, errp);
+ */
 static int GRAPH_RDLOCK
 bdrv_drv_set_perm(BlockDriverState *bs, uint64_t perm, uint64_t shared_perm,
                   Transaction *tran, Error **errp)
@@ -2392,6 +2608,10 @@ bdrv_drv_set_perm(BlockDriverState *bs, uint64_t perm, uint64_t shared_perm,
         return 0;
     }
 
+    /*
+     * block/file-posix.c|3955| <<global>> BlockDriver bdrv_file.bdrv_check_perm = raw_check_perm,
+     * block/file-posix.c|4324| <<global>> BlockDriver bdrv_host_device.bdrv_check_perm = raw_check_perm,
+     */
     if (bs->drv->bdrv_check_perm) {
         int ret = bs->drv->bdrv_check_perm(bs, perm, shared_perm, errp);
         if (ret < 0) {
@@ -2466,6 +2686,24 @@ static TransactionActionDrv bdrv_replace_child_drv = {
  *
  * The function doesn't update permissions, caller is responsible for this.
  */
+/*
+ * 核心思想是让参数的BdrvChild->bs指向参数的BlockDriverState
+ * 1. 如果BdrvChild->bs已经有了, 调用child->klass->detach(child)
+ *    blk_root_detach()
+ *        如果是"root", 没有核心的操作
+ *    bdrv_child_cb_detach()
+ *    把BdrvChild->从old_bs->parents上移除.
+ * 2. 设置ChildBdrv->bs为新的new_bs 
+ * 3. 把child放入BlockDriverState->parent中
+ *    blk_root_attach()
+ *        如果是"root", 没有核心的操作
+ *    bdrv_child_cb_attach()
+ *
+ * called by:
+ *   - block.c|5630| <<bdrv_remove_child>> bdrv_replace_child_tran(child, NULL, tran);
+ *   - block.c|5706| <<bdrv_replace_node_noperm>> bdrv_replace_child_tran(c, to, tran);
+ *   - block.c|6001| <<bdrv_replace_child_bs>> bdrv_replace_child_tran(child, new_bs, tran);
+ */
 static void GRAPH_WRLOCK
 bdrv_replace_child_tran(BdrvChild *child, BlockDriverState *new_bs,
                         Transaction *tran)
@@ -2485,10 +2723,55 @@ bdrv_replace_child_tran(BdrvChild *child, BlockDriverState *new_bs,
         bdrv_ref(new_bs);
     }
 
+    /*
+     *
+     * 核心思想是让参数的BdrvChild->bs指向参数的BlockDriverState
+     * 1. 如果BdrvChild->bs已经有了, 调用child->klass->detach(child)
+     *    blk_root_detach()
+     *        如果是"root", 没有核心的操作
+     *    bdrv_child_cb_detach()
+     *    把BdrvChild->从old_bs->parents上移除.
+     * 2. 设置ChildBdrv->bs为新的new_bs 
+     * 3. 把child放入BlockDriverState->parent中
+     *    blk_root_attach()
+     *        如果是"root", 没有核心的操作
+     *    bdrv_child_cb_attach()
+     * called by:
+     *   - block.c|2602| <<bdrv_replace_child_abort>> bdrv_replace_child_noperm(s->child, s->old_bs);
+     *   - block.c|2645| <<bdrv_replace_child_tran>> bdrv_replace_child_noperm(child, new_bs);
+     *   - block.c|3297| <<bdrv_attach_child_common_abort>> bdrv_replace_child_noperm(s->child, NULL);
+     *   - block.c|3424| <<bdrv_attach_child_common>> bdrv_replace_child_noperm(new_child, child_bs);
+     *   - block.c|3572| <<bdrv_root_unref_child>> bdrv_replace_child_noperm(child, NULL);
+     */
     bdrv_replace_child_noperm(child, new_bs);
     /* old_bs reference is transparently moved from @child to @s */
 }
 
+/*
+ * [0] qemu_lock_fd
+ * [0] raw_handle_perm_lock
+ * [0] raw_check_perm
+ * [0] bdrv_drv_set_perm
+ * [0] bdrv_node_refresh_perm
+ * [0] bdrv_list_refresh_perms
+ * [0] bdrv_replace_node_common
+ * [0] mirror_start_job
+ * [0] commit_active_start
+ * [0] qmp_block_commit
+ * [0] qmp_marshal_block_commit
+ * [0] do_qmp_dispatch_bh
+ * [0] aio_bh_poll
+ * [0] aio_dispatch
+ * [0] aio_ctx_dispatch
+ * [0] g_main_context_dispatch
+ * [0] glib_pollfds_poll
+ * [0] os_host_main_loop_wait
+ * [0] main_loop_wait
+ * [0] qemu_main_loop
+ * [0] qemu_default_main
+ * [0] __libc_start_main
+ * [0] _start
+ */
 /*
  * Refresh permissions in @bs subtree. The function is intended to be called
  * after some graph modification that was done without permission update.
@@ -2496,6 +2779,10 @@ bdrv_replace_child_tran(BdrvChild *child, BlockDriverState *new_bs,
  * After calling this function, the transaction @tran may only be completed
  * while holding a reader lock for the graph.
  */
+/*
+ * called by:
+ *   - block.c|2597| <<bdrv_do_refresh_perms>> ret = bdrv_node_refresh_perm(bs, q, tran, errp);
+ */
 static int GRAPH_RDLOCK
 bdrv_node_refresh_perm(BlockDriverState *bs, BlockReopenQueue *q,
                        Transaction *tran, Error **errp)
@@ -2543,6 +2830,12 @@ bdrv_node_refresh_perm(BlockDriverState *bs, BlockReopenQueue *q,
         return 0;
     }
 
+    /*
+     * called by:
+     *   - block.c|2546| <<bdrv_node_refresh_perm>> ret = bdrv_drv_set_perm(bs, cumulative_perms, cumulative_shared_perms, tran, errp);
+     *
+     * 这里!!!
+     */
     ret = bdrv_drv_set_perm(bs, cumulative_perms, cumulative_shared_perms, tran,
                             errp);
     if (ret < 0) {
@@ -2575,6 +2868,11 @@ bdrv_node_refresh_perm(BlockDriverState *bs, BlockReopenQueue *q,
  * After calling this function, the transaction @tran may only be completed
  * while holding a reader lock for the graph.
  */
+/*
+ * called by:
+ *   - block.c|2710| <<bdrv_list_refresh_perms>> return bdrv_do_refresh_perms(refresh_list, q, tran, errp);
+ *   - block.c|2778| <<bdrv_refresh_perms>> ret = bdrv_do_refresh_perms(list, NULL, tran, errp);
+ */
 static int GRAPH_RDLOCK
 bdrv_do_refresh_perms(GSList *list, BlockReopenQueue *q, Transaction *tran,
                       Error **errp)
@@ -2590,6 +2888,9 @@ bdrv_do_refresh_perms(GSList *list, BlockReopenQueue *q, Transaction *tran,
             return -EINVAL;
         }
 
+        /*
+	 * 只在此处调用
+	 */
         ret = bdrv_node_refresh_perm(bs, q, tran, errp);
         if (ret < 0) {
             return ret;
@@ -2599,6 +2900,31 @@ bdrv_do_refresh_perms(GSList *list, BlockReopenQueue *q, Transaction *tran,
     return 0;
 }
 
+/*
+ * [0] qemu_lock_fd
+ * [0] raw_handle_perm_lock
+ * [0] raw_check_perm
+ * [0] bdrv_drv_set_perm
+ * [0] bdrv_node_refresh_perm
+ * [0] bdrv_list_refresh_perms
+ * [0] bdrv_replace_node_common
+ * [0] mirror_start_job
+ * [0] commit_active_start
+ * [0] qmp_block_commit
+ * [0] qmp_marshal_block_commit
+ * [0] do_qmp_dispatch_bh
+ * [0] aio_bh_poll
+ * [0] aio_dispatch
+ * [0] aio_ctx_dispatch
+ * [0] g_main_context_dispatch
+ * [0] glib_pollfds_poll
+ * [0] os_host_main_loop_wait
+ * [0] main_loop_wait
+ * [0] qemu_main_loop
+ * [0] qemu_default_main
+ * [0] __libc_start_main
+ * [0] _start
+ */
 /*
  * @list is any list of nodes. List is completed by all subtrees and
  * topologically sorted. It's not a problem if some node occurs in the @list
@@ -2607,6 +2933,12 @@ bdrv_do_refresh_perms(GSList *list, BlockReopenQueue *q, Transaction *tran,
  * After calling this function, the transaction @tran may only be completed
  * while holding a reader lock for the graph.
  */
+/*
+ * called by:
+ *   - block.c|4577| <<bdrv_reopen_multiple>> ret = bdrv_list_refresh_perms(refresh_list, bs_queue, tran, errp);
+ *   - block.c|5391| <<bdrv_replace_node_common>> ret = bdrv_list_refresh_perms(refresh_list, NULL, tran, errp);
+ *   - block.c|5506| <<bdrv_replace_child_bs>> ret = bdrv_list_refresh_perms(refresh_list, NULL, tran, errp);
+ */
 static int GRAPH_RDLOCK
 bdrv_list_refresh_perms(GSList *list, BlockReopenQueue *q, Transaction *tran,
                         Error **errp)
@@ -2618,9 +2950,24 @@ bdrv_list_refresh_perms(GSList *list, BlockReopenQueue *q, Transaction *tran,
         refresh_list = bdrv_topological_dfs(refresh_list, found, list->data);
     }
 
+    /*
+     * called by:
+     *   - block.c|2710| <<bdrv_list_refresh_perms>> return bdrv_do_refresh_perms(refresh_list, q, tran, errp);
+     *   - block.c|2778| <<bdrv_refresh_perms>> ret = bdrv_do_refresh_perms(list, NULL, tran, errp);
+     */
     return bdrv_do_refresh_perms(refresh_list, q, tran, errp);
 }
 
+/*
+ * called by:
+ *   - block.c|2391| <<bdrv_drv_set_perm_commit>> bdrv_get_cumulative_perm(bs, &cumulative_perms,
+ *   - block.c|2601| <<bdrv_node_refresh_perm>> bdrv_get_cumulative_perm(bs, &cumulative_perms, &cumulative_shared_perms);
+ *   - block.c|2892| <<bdrv_child_refresh_perms>> bdrv_get_cumulative_perm(bs, &parent_perms, &parent_shared);
+ *   - block.c|3341| <<bdrv_attach_child_noperm>> bdrv_get_cumulative_perm(parent_bs, &perm, &shared_perm);
+ *   - block.c|7333| <<bdrv_inactivate_recurse>> bdrv_get_cumulative_perm(bs, &cumulative_perms,
+ *   - blockdev.c|1504| <<external_snapshot_action>> bdrv_get_cumulative_perm(state->new_bs, &perm, &shared);
+ *   - blockdev.c|2712| <<qmp_block_commit>> bdrv_get_cumulative_perm(top_bs, &top_perm, &top_shared);
+ */
 void bdrv_get_cumulative_perm(BlockDriverState *bs, uint64_t *perm,
                               uint64_t *shared_perm)
 {
@@ -2630,6 +2977,14 @@ void bdrv_get_cumulative_perm(BlockDriverState *bs, uint64_t *perm,
 
     GLOBAL_STATE_CODE();
 
+    /*
+     * BlockDriverState *bs:
+     * -> QLIST_HEAD(, BdrvChild GRAPH_RDLOCK_PTR) parents;
+     *
+     * BdrvChild *c:
+     * -> uint64_t perm;
+     * -> uint64_t shared_perm;
+     */
     QLIST_FOREACH(c, &bs->parents, next_parent) {
         cumulative_perms |= c->perm;
         cumulative_shared_perms &= c->shared_perm;
@@ -2674,6 +3029,17 @@ char *bdrv_perm_names(uint64_t perm)
  * After calling this function, the transaction @tran may only be completed
  * while holding a reader lock for the graph.
  */
+/*
+ * called by:
+ *   - block.c|2928| <<bdrv_child_try_set_perm>> ret = bdrv_refresh_perms(c->bs, tran, &local_err);
+ *   - block.c|3462| <<bdrv_root_attach_child>> ret = bdrv_refresh_perms(child_bs, tran, errp);
+ *   - block.c|3500| <<bdrv_attach_child>> ret = bdrv_refresh_perms(parent_bs, tran, errp);
+ *   - block.c|3528| <<bdrv_root_unref_child>> bdrv_refresh_perms(child_bs, NULL, NULL);
+ *   - block.c|3786| <<bdrv_set_backing_hd_drained>> ret = bdrv_refresh_perms(bs, tran, errp);
+ *   - block.c|5836| <<bdrv_append>> ret = bdrv_refresh_perms(bs_new, tran, errp);
+ *   - block.c|7321| <<bdrv_activate>> ret = bdrv_refresh_perms(bs, NULL, errp);
+ *   - block.c|7466| <<bdrv_inactivate_recurse>> bdrv_refresh_perms(bs, NULL, NULL);
+ */
 static int GRAPH_RDLOCK
 bdrv_refresh_perms(BlockDriverState *bs, Transaction *tran, Error **errp)
 {
@@ -2729,6 +3095,19 @@ int bdrv_child_try_set_perm(BdrvChild *c, uint64_t perm, uint64_t shared,
     return ret;
 }
 
+/*
+ * called by:
+ *   - block/crypto.c|916| <<block_crypto_amend_prepare>> ret = bdrv_child_refresh_perms(bs, bs->file, errp);
+ *   - block/crypto.c|932| <<block_crypto_amend_cleanup>> bdrv_child_refresh_perms(bs, bs->file, &errp);
+ *   - block/mirror.c|721| <<mirror_exit_common>> bdrv_child_refresh_perms(mirror_top_bs, mirror_top_bs->backing,
+ *   - block/mirror.c|2258| <<mirror_start_job>> bdrv_child_refresh_perms(mirror_top_bs, mirror_top_bs->backing,
+ *   - block/preallocate.c|540| <<preallocate_drop_resize>> bdrv_child_refresh_perms(bs, bs->file, NULL);
+ *   - block/qcow2.c|1674| <<qcow2_do_open>> bdrv_child_refresh_perms(bs, bs->file, &error_abort);
+ *   - block/vmdk.c|1381| <<vmdk_open>> bdrv_child_refresh_perms(bs, bs->file, &error_abort);
+ *   - tests/unit/test-bdrv-graph-mod.c|386| <<test_parallel_perm_update>> bdrv_child_refresh_perms(top, top->children.lh_first, &error_abort);
+ *   - tests/unit/test-bdrv-graph-mod.c|393| <<test_parallel_perm_update>> bdrv_child_refresh_perms(top, top->children.lh_first, &error_abort);
+ *   - tests/unit/test-bdrv-graph-mod.c|400| <<test_parallel_perm_update>> bdrv_child_refresh_perms(top, top->children.lh_first, &error_abort);
+ */
 int bdrv_child_refresh_perms(BlockDriverState *bs, BdrvChild *c, Error **errp)
 {
     uint64_t parent_perms, parent_shared;
@@ -2921,6 +3300,26 @@ uint64_t bdrv_qapi_perm_to_blk_perm(BlockPermission qapi_perm)
  * If @new_bs is non-NULL, the parent of @child must already be drained through
  * @child.
  */
+/*
+ * called by:
+ *   - block.c|2602| <<bdrv_replace_child_abort>> bdrv_replace_child_noperm(s->child, s->old_bs);
+ *   - block.c|2645| <<bdrv_replace_child_tran>> bdrv_replace_child_noperm(child, new_bs);
+ *   - block.c|3297| <<bdrv_attach_child_common_abort>> bdrv_replace_child_noperm(s->child, NULL);
+ *   - block.c|3424| <<bdrv_attach_child_common>> bdrv_replace_child_noperm(new_child, child_bs);
+ *   - block.c|3572| <<bdrv_root_unref_child>> bdrv_replace_child_noperm(child, NULL);
+ *
+ * 核心思想是让参数的BdrvChild->bs指向参数的BlockDriverState
+ * 1. 如果BdrvChild->bs已经有了, 调用child->klass->detach(child)
+ *    blk_root_detach()
+ *        如果是"root", 没有核心的操作
+ *    bdrv_child_cb_detach()
+ *    把BdrvChild->从old_bs->parents上移除.
+ * 2. 设置ChildBdrv->bs为新的new_bs
+ * 3. 把child放入BlockDriverState->parent中
+ *    blk_root_attach()
+ *        如果是"root", 没有核心的操作
+ *    bdrv_child_cb_attach()
+ */
 static void GRAPH_WRLOCK
 bdrv_replace_child_noperm(BdrvChild *child, BlockDriverState *new_bs)
 {
@@ -2957,6 +3356,49 @@ bdrv_replace_child_noperm(BdrvChild *child, BlockDriverState *new_bs)
         assert(bdrv_get_aio_context(old_bs) == bdrv_get_aio_context(new_bs));
     }
 
+    /*
+     * 如果上级是BlockBackend.
+     *
+     * 359 static const BdrvChildClass child_root = {
+     * 360     .inherit_options    = blk_root_inherit_options,
+     * 361 
+     * 362     .change_media       = blk_root_change_media,
+     * 363     .resize             = blk_root_resize,
+     * 364     .get_name           = blk_root_get_name,
+     * 365     .get_parent_desc    = blk_root_get_parent_desc,
+     * 366                                   
+     * 367     .drained_begin      = blk_root_drained_begin,
+     * 368     .drained_poll       = blk_root_drained_poll,
+     * 369     .drained_end        = blk_root_drained_end,
+     * 370     
+     * 371     .activate           = blk_root_activate,
+     * 372     .inactivate         = blk_root_inactivate,
+     * 373     
+     * 374     .attach             = blk_root_attach,
+     * 375     .detach             = blk_root_detach,
+     * 376                                    
+     * 377     .change_aio_ctx     = blk_root_change_aio_ctx,
+     * 378     
+     * 379     .get_parent_aio_context = blk_root_get_parent_aio_context,
+     * 380 };
+     *
+     * 如果上级是BlockDriverState
+     *
+     * 1624 const BdrvChildClass child_of_bds = {
+     * 1625     .parent_is_bds   = true,
+     * 1626     .get_parent_desc = bdrv_child_get_parent_desc,
+     * 1627     .inherit_options = bdrv_inherited_options,
+     * 1628     .drained_begin   = bdrv_child_cb_drained_begin,
+     * 1629     .drained_poll    = bdrv_child_cb_drained_poll,
+     * 1630     .drained_end     = bdrv_child_cb_drained_end,
+     * 1631     .attach          = bdrv_child_cb_attach,
+     * 1632     .detach          = bdrv_child_cb_detach,
+     * 1633     .inactivate      = bdrv_child_cb_inactivate,
+     * 1634     .change_aio_ctx  = bdrv_child_cb_change_aio_ctx,
+     * 1635     .update_filename = bdrv_child_cb_update_filename,
+     * 1636     .get_parent_aio_context = child_of_bds_get_parent_aio_context,
+     * 1637 };
+     */
     if (old_bs) {
         if (child->klass->detach) {
             child->klass->detach(child);
@@ -2967,6 +3409,12 @@ bdrv_replace_child_noperm(BdrvChild *child, BlockDriverState *new_bs)
     child->bs = new_bs;
 
     if (new_bs) {
+        /*
+	 * 把child放入bs的parents里!!!
+	 *
+	 * blk_root_attach()
+	 * bdrv_child_cb_attach()
+	 */
         QLIST_INSERT_HEAD(&new_bs->parents, child, next_parent);
         if (child->klass->attach) {
             child->klass->attach(child);
@@ -3062,6 +3510,25 @@ static TransactionActionDrv bdrv_attach_child_common_drv = {
  * Both @parent_bs and @child_bs can move to a different AioContext in this
  * function.
  */
+/*
+ * called by:
+ *   - block.c|3541| <<bdrv_attach_child_noperm>> return bdrv_attach_child_common(child_bs, child_name, child_class, child_role, perm, shared_perm, parent_bs, tran, errp);
+ *   - block.c|3571| <<bdrv_root_attach_child>> child = bdrv_attach_child_common(child_bs, child_name, child_class, child_role, perm, shared_perm, opaque, tran, errp);
+ *
+ * BdrvChild:
+ * -> QLIST_ENTRY(BdrvChild GRAPH_RDLOCK_PTR) next;
+ * -> QLIST_ENTRY(BdrvChild GRAPH_RDLOCK_PTR) next_parent;
+ *
+ * 新分配一个BdrvChild, 等这些做完
+ *
+ * new_bs->children包含了新分配的child(BdrvChild)
+ *
+ * 新分配的child->bs = old_bs
+ * 新分配的child->opaque = new_bs
+ * 新分配的child->name = "backing"
+ *
+ * old_bs->parent有了新分配的child(BdrvChild)
+ */
 static BdrvChild * GRAPH_WRLOCK
 bdrv_attach_child_common(BlockDriverState *child_bs,
                          const char *child_name,
@@ -3073,11 +3540,34 @@ bdrv_attach_child_common(BlockDriverState *child_bs,
 {
     BdrvChild *new_child;
     AioContext *parent_ctx;
+    /*
+     * 返回mainloop或者iothread
+     */
     AioContext *child_ctx = bdrv_get_aio_context(child_bs);
 
     assert(child_class->get_parent_desc);
     GLOBAL_STATE_CODE();
 
+    /*
+     * struct BdrvChild {
+     *     BlockDriverState *bs;
+     *     char *name;
+     *     const BdrvChildClass *klass;
+     *     BdrvChildRole role;
+     *     void *opaque;
+     *
+     *     uint64_t perm;
+     *
+     *     uint64_t shared_perm;
+     *
+     *     bool frozen;
+     *
+     *     bool quiesced_parent;
+     *
+     *     QLIST_ENTRY(BdrvChild GRAPH_RDLOCK_PTR) next; --> 所有把这个BdrvChild当下一级的链接起来的
+     *     QLIST_ENTRY(BdrvChild GRAPH_RDLOCK_PTR) next_parent; --> 所有把这个BdrvChild当上一级的链接起来的
+     * };
+     */
     new_child = g_new(BdrvChild, 1);
     *new_child = (BdrvChild) {
         .bs             = NULL,
@@ -3094,6 +3584,9 @@ bdrv_attach_child_common(BlockDriverState *child_bs,
      * child_bs into the AioContext of the new parent. If this doesn't work,
      * try moving the parent into the AioContext of child_bs instead.
      */
+    /*
+     * 返回的是上一级BlockBackend或者BS的ctx (mainloop或者iothread)
+     */
     parent_ctx = bdrv_child_get_parent_aio_context(new_child);
     if (child_ctx != parent_ctx) {
         Error *local_err = NULL;
@@ -3143,6 +3636,28 @@ bdrv_attach_child_common(BlockDriverState *child_bs,
      * is fully quiesced, so it will not be negatively affected either.
      */
     bdrv_parent_drained_begin_single(new_child);
+    /*
+     * called by:
+     *   - block.c|2602| <<bdrv_replace_child_abort>> bdrv_replace_child_noperm(s->child, s->old_bs);
+     *   - block.c|2645| <<bdrv_replace_child_tran>> bdrv_replace_child_noperm(child, new_bs);
+     *   - block.c|3297| <<bdrv_attach_child_common_abort>> bdrv_replace_child_noperm(s->child, NULL);
+     *   - block.c|3424| <<bdrv_attach_child_common>> bdrv_replace_child_noperm(new_child, child_bs);
+     *   - block.c|3572| <<bdrv_root_unref_child>> bdrv_replace_child_noperm(child, NULL);
+     *
+     * BdrvChild:
+     * -> QLIST_ENTRY(BdrvChild GRAPH_RDLOCK_PTR) next;
+     * -> QLIST_ENTRY(BdrvChild GRAPH_RDLOCK_PTR) next_parent;
+     *
+     * 等这些做完
+     *
+     * new_bs->children包含了新分配的child(BdrvChild)
+     *
+     * 新分配的child->bs = old_bs
+     * 新分配的child->opaque = new_bs
+     * 新分配的child->name = "backing"
+     *
+     * old_bs->parent有了新分配的child(BdrvChild)
+     */
     bdrv_replace_child_noperm(new_child, child_bs);
 
     BdrvAttachChildCommonState *s = g_new(BdrvAttachChildCommonState, 1);
@@ -3151,7 +3666,13 @@ bdrv_attach_child_common(BlockDriverState *child_bs,
         .old_parent_ctx = parent_ctx,
         .old_child_ctx = child_ctx,
     };
-    tran_add(tran, &bdrv_attach_child_common_drv, s);
+    /*
+     * 3478 static TransactionActionDrv bdrv_attach_child_common_drv = {
+     * 3479     .abort = bdrv_attach_child_common_abort,
+     * 3480     .clean = g_free,
+     * 3481 };
+     */
+    tran_add(tran, &drv_attach_child_common_drv, s);
 
     return new_child;
 }
@@ -3165,6 +3686,17 @@ bdrv_attach_child_common(BlockDriverState *child_bs,
  * After calling this function, the transaction @tran may only be completed
  * while holding a writer lock for the graph.
  */
+/*
+ * called by:
+ *   - block.c|3493| <<bdrv_attach_child>> child = bdrv_attach_child_noperm(parent_bs, child_bs, child_name, child_class, child_role, tran, errp);
+ *   - block.c|3738| <<bdrv_set_file_or_backing_noperm>> child = bdrv_attach_child_noperm(parent_bs, child_bs, is_backing ? "backing" : "file",
+ *                             &child_of_bds, role, tran, errp);
+ *   - block.c|5823| <<bdrv_append>> child = bdrv_attach_child_noperm(bs_new, bs_top, "backing", &child_of_bds, bdrv_backing_role(bs_new), tran, errp);
+ *
+ * 比如:
+ * parent_bs是bs_new (新的)
+ * child_bs是bs_top
+ */
 static BdrvChild * GRAPH_WRLOCK
 bdrv_attach_child_noperm(BlockDriverState *parent_bs,
                          BlockDriverState *child_bs,
@@ -3189,6 +3721,26 @@ bdrv_attach_child_noperm(BlockDriverState *parent_bs,
     bdrv_child_perm(parent_bs, child_bs, NULL, child_role, NULL,
                     perm, shared_perm, &perm, &shared_perm);
 
+    /*
+     * BdrvChild:
+     * -> QLIST_ENTRY(BdrvChild GRAPH_RDLOCK_PTR) next;
+     * -> QLIST_ENTRY(BdrvChild GRAPH_RDLOCK_PTR) next_parent;
+     *
+     * 新分配一个BdrvChild, 等这些做完
+     *
+     * new_bs->children包含了新分配的child(BdrvChild)
+     *
+     * 新分配的child->bs = old_bs
+     * 新分配的child->opaque = new_bs
+     * 新分配的child->name = "backing"
+     *
+     * old_bs->parent有了新分配的child(BdrvChild)
+     *
+     *
+     * 比如:
+     * parent_bs是bs_new (新的)
+     * child_bs是bs_top
+     */
     return bdrv_attach_child_common(child_bs, child_name, child_class,
                                     child_role, perm, shared_perm, parent_bs,
                                     tran, errp);
@@ -3201,6 +3753,35 @@ bdrv_attach_child_noperm(BlockDriverState *parent_bs,
  * On failure NULL is returned, errp is set and the reference to
  * child_bs is also dropped.
  */
+/*
+ * 359 static const BdrvChildClass child_root = {
+ * 360     .inherit_options    = blk_root_inherit_options,
+ * 361 
+ * 362     .change_media       = blk_root_change_media,
+ * 363     .resize             = blk_root_resize,
+ * 364     .get_name           = blk_root_get_name,
+ * 365     .get_parent_desc    = blk_root_get_parent_desc,
+ * 366                                   
+ * 367     .drained_begin      = blk_root_drained_begin,
+ * 368     .drained_poll       = blk_root_drained_poll,
+ * 369     .drained_end        = blk_root_drained_end,
+ * 370     
+ * 371     .activate           = blk_root_activate,
+ * 372     .inactivate         = blk_root_inactivate,
+ * 373     
+ * 374     .attach             = blk_root_attach,
+ * 375     .detach             = blk_root_detach,
+ * 376                                    
+ * 377     .change_aio_ctx     = blk_root_change_aio_ctx,
+ * 378     
+ * 379     .get_parent_aio_context = blk_root_get_parent_aio_context,
+ * 380 };
+ *
+ * called by:
+ *   - block/block-backend.c|1037| <<blk_insert_bs>> blk->root = bdrv_root_attach_child(bs, "root", &child_root,
+ *             BDRV_CHILD_FILTERED | BDRV_CHILD_PRIMARY, blk->perm, blk->shared_perm, blk, errp);
+ *   - blockjob.c|252| <<block_job_add_bdrv>> c = bdrv_root_attach_child(bs, name, &child_job, 0, perm, shared_perm, job, errp);
+ */
 BdrvChild *bdrv_root_attach_child(BlockDriverState *child_bs,
                                   const char *child_name,
                                   const BdrvChildClass *child_class,
@@ -3212,8 +3793,42 @@ BdrvChild *bdrv_root_attach_child(BlockDriverState *child_bs,
     BdrvChild *child;
     Transaction *tran = tran_new();
 
+    /*
+     * 注释:
+     *
+     * qemu_in_main_thread: return whether it's possible to safely access
+     * the global state of the block layer.
+     *
+     * Global state of the block layer is not accessible from I/O threads
+     * or worker threads; only from threads that "own" the default
+     * AioContext that qemu_get_aio_context() returns.  For tests, block
+     * layer tools and qemu-storage-daemon there is a designated thread that
+     * runs the event loop for qemu_get_aio_context(), and that is the
+     * main thread.
+     *
+     * For emulators, however, any thread that holds the BQL can act
+     * as the block layer main thread; this will be any of the actual
+     * main thread, the vCPU threads or the RCU thread.
+     *
+     * For clarity, do not use this function outside the block layer.
+     */
     GLOBAL_STATE_CODE();
 
+    /*
+     * BdrvChild:
+     * -> QLIST_ENTRY(BdrvChild GRAPH_RDLOCK_PTR) next;
+     * -> QLIST_ENTRY(BdrvChild GRAPH_RDLOCK_PTR) next_parent;
+     *
+     * 新分配一个BdrvChild, 等这些做完
+     *
+     * new_bs->children包含了新分配的child(BdrvChild)
+     *
+     * 新分配的child->bs = old_bs
+     * 新分配的child->opaque = new_bs
+     * 新分配的child->name = "backing"
+     *
+     * old_bs->parent有了新分配的child(BdrvChild)
+     */
     child = bdrv_attach_child_common(child_bs, child_name, child_class,
                                    child_role, perm, shared_perm, opaque,
                                    tran, errp);
@@ -3222,6 +3837,20 @@ BdrvChild *bdrv_root_attach_child(BlockDriverState *child_bs,
         goto out;
     }
 
+    /*
+     * called by:
+     *   - block.c|2928| <<bdrv_child_try_set_perm>> ret = bdrv_refresh_perms(c->bs, tran, &local_err);
+     *   - block.c|3462| <<bdrv_root_attach_child>> ret = bdrv_refresh_perms(child_bs, tran, errp);
+     *   - block.c|3500| <<bdrv_attach_child>> ret = bdrv_refresh_perms(parent_bs, tran, errp);
+     *   - block.c|3528| <<bdrv_root_unref_child>> bdrv_refresh_perms(child_bs, NULL, NULL);
+     *   - block.c|3786| <<bdrv_set_backing_hd_drained>> ret = bdrv_refresh_perms(bs, tran, errp);
+     *   - block.c|5836| <<bdrv_append>> ret = bdrv_refresh_perms(bs_new, tran, errp);
+     *   - block.c|7321| <<bdrv_activate>> ret = bdrv_refresh_perms(bs, NULL, errp);
+     *   - block.c|7466| <<bdrv_inactivate_recurse>> bdrv_refresh_perms(bs, NULL, NULL);
+     *
+     * bdrv_refresh_perms()
+     * -> bdrv_do_refresh_perms()
+     */
     ret = bdrv_refresh_perms(child_bs, tran, errp);
 
 out:
@@ -5174,6 +5803,10 @@ void bdrv_close_all(void)
     assert(QTAILQ_EMPTY(&all_bdrv_states));
 }
 
+/*
+ * called by:
+ *   - block.c|5782| <<bdrv_replace_node_noperm>> if (!should_update_child(c, to)) {
+ */
 static bool GRAPH_RDLOCK should_update_child(BdrvChild *c, BlockDriverState *to)
 {
     GQueue *queue;
@@ -5285,6 +5918,31 @@ static void GRAPH_WRLOCK bdrv_remove_child(BdrvChild *child, Transaction *tran)
     tran_add(tran, &bdrv_remove_child_drv, child);
 }
 
+/*
+ * [0] qemu_lock_fd
+ * [0] raw_handle_perm_lock
+ * [0] raw_check_perm
+ * [0] bdrv_drv_set_perm
+ * [0] bdrv_node_refresh_perm
+ * [0] bdrv_list_refresh_perms
+ * [0] bdrv_replace_node_common
+ * [0] mirror_start_job
+ * [0] commit_active_start
+ * [0] qmp_block_commit
+ * [0] qmp_marshal_block_commit
+ * [0] do_qmp_dispatch_bh
+ * [0] aio_bh_poll
+ * [0] aio_dispatch
+ * [0] aio_ctx_dispatch
+ * [0] g_main_context_dispatch
+ * [0] glib_pollfds_poll
+ * [0] os_host_main_loop_wait
+ * [0] main_loop_wait
+ * [0] qemu_main_loop
+ * [0] qemu_default_main
+ * [0] __libc_start_main
+ * [0] _start
+ */
 /*
  * Both @from and @to (if non-NULL) must be drained. @to must be kept drained
  * until the transaction is completed.
@@ -5292,6 +5950,25 @@ static void GRAPH_WRLOCK bdrv_remove_child(BdrvChild *child, Transaction *tran)
  * After calling this function, the transaction @tran may only be completed
  * while holding a writer lock for the graph.
  */
+/*
+ * BdrvChild:
+ * -> QLIST_ENTRY(BdrvChild GRAPH_RDLOCK_PTR) next;
+ * -> QLIST_ENTRY(BdrvChild GRAPH_RDLOCK_PTR) next_parent;
+ *
+ * 新分配一个BdrvChild, 等这些做完
+ *
+ * new_bs->children包含了新分配的child(BdrvChild)
+ *
+ * 新分配的child->bs = old_bs
+ * 新分配的child->opaque = new_bs
+ * 新分配的child->name = "backing"
+ *
+ * old_bs->parent有了新分配的child(BdrvChild)
+ *
+ * called by:
+ *   - block.c|5574| <<bdrv_replace_node_common>> ret = bdrv_replace_node_noperm(from, to, auto_skip, tran, errp);
+ *   - block.c|5712| <<bdrv_append>> ret = bdrv_replace_node_noperm(bs_top, bs_new, true, tran, errp);
+ */
 static int GRAPH_WRLOCK
 bdrv_replace_node_noperm(BlockDriverState *from,
                          BlockDriverState *to,
@@ -5305,6 +5982,23 @@ bdrv_replace_node_noperm(BlockDriverState *from,
     assert(from->quiesce_counter);
     assert(to->quiesce_counter);
 
+    /*
+     * BdrvChild:
+     * -> QLIST_ENTRY(BdrvChild GRAPH_RDLOCK_PTR) next;
+     * -> QLIST_ENTRY(BdrvChild GRAPH_RDLOCK_PTR) next_parent;
+     *
+     * 新分配一个BdrvChild, 等这些做完
+     *
+     * new_bs->children包含了新分配的child(BdrvChild)
+     *
+     * 新分配的child->bs = old_bs
+     * 新分配的child->opaque = new_bs
+     * 新分配的child->name = "backing"
+     *
+     * old_bs->parent有了新分配的child(BdrvChild) ---> 还有旧的呢!!!!
+     *
+     * 旧的BdrvChild应该是"root"
+     */
     QLIST_FOREACH_SAFE(c, &from->parents, next_parent, next) {
         assert(c->bs == from);
         if (!should_update_child(c, to)) {
@@ -5320,12 +6014,49 @@ bdrv_replace_node_noperm(BlockDriverState *from,
                        c->name, from->node_name);
             return -EPERM;
         }
+        /*
+	 * called by:
+	 *   - block.c|5630| <<bdrv_remove_child>> bdrv_replace_child_tran(child, NULL, tran);
+	 *   - block.c|5706| <<bdrv_replace_node_noperm>> bdrv_replace_child_tran(c, to, tran);
+	 *   - block.c|6001| <<bdrv_replace_child_bs>> bdrv_replace_child_tran(child, new_bs, tran);
+	 *
+	 * BdrvChild *c
+	 *
+	 * 把所有from的BlockDriverState->parent的bs都换成to
+	 *
+	 * 比如, 这样"root"的BdrvChild->bs就是new_bs了!!!
+	 */
         bdrv_replace_child_tran(c, to, tran);
     }
 
     return 0;
 }
 
+/*
+ * [0] qemu_lock_fd
+ * [0] raw_handle_perm_lock
+ * [0] raw_check_perm
+ * [0] bdrv_drv_set_perm
+ * [0] bdrv_node_refresh_perm
+ * [0] bdrv_list_refresh_perms
+ * [0] bdrv_replace_node_common
+ * [0] mirror_start_job
+ * [0] commit_active_start
+ * [0] qmp_block_commit
+ * [0] qmp_marshal_block_commit
+ * [0] do_qmp_dispatch_bh
+ * [0] aio_bh_poll
+ * [0] aio_dispatch
+ * [0] aio_ctx_dispatch
+ * [0] g_main_context_dispatch
+ * [0] glib_pollfds_poll
+ * [0] os_host_main_loop_wait
+ * [0] main_loop_wait
+ * [0] qemu_main_loop
+ * [0] qemu_default_main
+ * [0] __libc_start_main
+ * [0] _start
+ */
 /*
  * Switch all parents of @from to point to @to instead. @from and @to must be in
  * the same AioContext and both must be drained.
@@ -5339,10 +6070,27 @@ bdrv_replace_node_noperm(BlockDriverState *from,
  * With @detach_subchain=true @to must be in a backing chain of @from. In this
  * case backing link of the cow-parent of @to is removed.
  */
+/*
+ * called by:
+ *   - block.c|5406| <<bdrv_replace_node>> return bdrv_replace_node_common(from, to, true, false, errp);
+ *   - block.c|5422| <<bdrv_drop_filter>> ret = bdrv_replace_node_common(bs, child_bs, true, true, errp);
+ *   - block.c|5889| <<bdrv_drop_intermediate>> bdrv_replace_node_common(top, base, false, false, &local_err);
+ */
 static int GRAPH_WRLOCK
 bdrv_replace_node_common(BlockDriverState *from, BlockDriverState *to,
                          bool auto_skip, bool detach_subchain, Error **errp)
 {
+    /*
+     * 28 typedef struct TransactionAction {
+     * 29     TransactionActionDrv *drv;
+     * 30     void *opaque;
+     * 31     QSLIST_ENTRY(TransactionAction) entry;
+     * 32 } TransactionAction;
+     * 33
+     * 34 struct Transaction {
+     * 35     QSLIST_HEAD(, TransactionAction) actions;
+     * 36 };
+     */
     Transaction *tran = tran_new();
     g_autoptr(GSList) refresh_list = NULL;
     BlockDriverState *to_cow_parent = NULL;
@@ -5354,6 +6102,9 @@ bdrv_replace_node_common(BlockDriverState *from, BlockDriverState *to,
     assert(to->quiesce_counter);
     assert(bdrv_get_aio_context(from) == bdrv_get_aio_context(to));
 
+    /*
+     * 比如是false
+     */
     if (detach_subchain) {
         assert(bdrv_chain_contains(from, to));
         assert(from != to);
@@ -5371,6 +6122,11 @@ bdrv_replace_node_common(BlockDriverState *from, BlockDriverState *to,
      * permissions based on new graph. If we fail, we'll roll-back the
      * replacement.
      */
+    /*
+     * called by:
+     *   - block.c|5574| <<bdrv_replace_node_common>> ret = bdrv_replace_node_noperm(from, to, auto_skip, tran, errp);
+     *   - block.c|5712| <<bdrv_append>> ret = bdrv_replace_node_noperm(bs_top, bs_new, true, tran, errp);
+     */
     ret = bdrv_replace_node_noperm(from, to, auto_skip, tran, errp);
     if (ret < 0) {
         goto out;
@@ -5381,9 +6137,33 @@ bdrv_replace_node_common(BlockDriverState *from, BlockDriverState *to,
         bdrv_remove_child(bdrv_filter_or_cow_child(to_cow_parent), tran);
     }
 
+    /*
+     * 注释:
+     * Adds a new element on to the start of the list.
+     * The return value is the new start of the list, which may have changed,
+     * so make sure you store the new value.
+     */
     refresh_list = g_slist_prepend(refresh_list, to);
     refresh_list = g_slist_prepend(refresh_list, from);
 
+    /*
+     * 28 typedef struct TransactionAction {
+     * 29     TransactionActionDrv *drv;
+     * 30     void *opaque;
+     * 31     QSLIST_ENTRY(TransactionAction) entry;
+     * 32 } TransactionAction;
+     * 33
+     * 34 struct Transaction {
+     * 35     QSLIST_HEAD(, TransactionAction) actions;
+     * 36 };
+     *
+     * called by:
+     *   - block.c|4577| <<bdrv_reopen_multiple>> ret = bdrv_list_refresh_perms(refresh_list, bs_queue, tran, errp);
+     *   - block.c|5391| <<bdrv_replace_node_common>> ret = bdrv_list_refresh_perms(refresh_list, NULL, tran, errp);
+     *   - block.c|5506| <<bdrv_replace_child_bs>> ret = bdrv_list_refresh_perms(refresh_list, NULL, tran, errp);
+     *
+     * 这里!!!
+     */
     ret = bdrv_list_refresh_perms(refresh_list, NULL, tran, errp);
     if (ret < 0) {
         goto out;
@@ -5396,9 +6176,25 @@ out:
     return ret;
 }
 
+/*
+ * called by:
+ *   - block.c|5709| <<bdrv_insert_node>> ret = bdrv_replace_node(bs, new_node_bs, errp);
+ *   - block/commit.c|106| <<commit_abort>> bdrv_replace_node(s->commit_top_bs, commit_top_backing_bs, &error_abort);
+ *   - block/commit.c|442| <<commit_start>> bdrv_replace_node(commit_top_bs, top, &error_abort);
+ *   - block/mirror.c|766| <<mirror_exit_common>> bdrv_replace_node(to_replace, target_bs, &local_err);
+ *   - block/mirror.c|794| <<mirror_exit_common>> bdrv_replace_node(mirror_top_bs, mirror_top_bs->backing->bs, &error_abort);
+ *   - block/mirror.c|2029| <<mirror_start_job>> bdrv_replace_node(mirror_top_bs, bs, &error_abort);
+ *   - blockdev.c|1546| <<external_snapshot_abort>> bdrv_replace_node(state->new_bs, state->old_bs, &error_abort);
+ */
 int bdrv_replace_node(BlockDriverState *from, BlockDriverState *to,
                       Error **errp)
 {
+    /*
+     * called by:
+     *   - block.c|5406| <<bdrv_replace_node>> return bdrv_replace_node_common(from, to, true, false, errp);
+     *   - block.c|5422| <<bdrv_drop_filter>> ret = bdrv_replace_node_common(bs, child_bs, true, true, errp);
+     *   - block.c|5889| <<bdrv_drop_intermediate>> bdrv_replace_node_common(top, base, false, false, &local_err);
+     */
     return bdrv_replace_node_common(from, to, true, false, errp);
 }
 
@@ -5434,6 +6230,27 @@ int bdrv_drop_filter(BlockDriverState *bs, Error **errp)
  *
  * This function does not create any image files.
  */
+/*
+ * called by:
+ *   - block.c|4036| <<bdrv_append_temp_snapshot>> ret = bdrv_append(bs_snapshot, bs, errp);
+ *   - block/commit.c|328| <<commit_start>> ret = bdrv_append(commit_top_bs, top, errp);
+ *   - block/mirror.c|1819| <<mirror_start_job>> ret = bdrv_append(mirror_top_bs, bs, errp);
+ *   - blockdev.c|1517| <<external_snapshot_action>> ret = bdrv_append(state->new_bs, state->old_bs, errp);
+ *   - tests/unit/test-bdrv-drain.c|1364| <<test_append_to_drained>> bdrv_append(overlay, base, &error_abort);
+ *   - tests/unit/test-bdrv-graph-mod.c|145| <<test_update_perm_tree>> ret = bdrv_append(filter, bs, NULL);
+ *   - tests/unit/test-bdrv-graph-mod.c|212| <<test_should_update_child>> bdrv_append(filter, bs, &error_abort);
+ *   - tests/unit/test-bdrv-graph-mod.c|439| <<test_append_greedy_filter>> bdrv_append(fl, base, &error_abort);
+ *
+ * 如果是external_snapshot_action过来的
+ * bs_new应该就是一个独立的BS
+ *
+ * bs_top指向的是:
+ *
+ * Backend-->Child("root")-->BS
+ *                           ^
+ *                           |
+ *                          这个!
+ */
 int bdrv_append(BlockDriverState *bs_new, BlockDriverState *bs_top,
                 Error **errp)
 {
@@ -5452,6 +6269,40 @@ int bdrv_append(BlockDriverState *bs_new, BlockDriverState *bs_top,
 
     bdrv_graph_wrlock();
 
+    /*
+     * called by:
+     *   - block.c|3493| <<bdrv_attach_child>> child = bdrv_attach_child_noperm(parent_bs, child_bs, child_name, child_class, child_role, tran, errp);
+     *   - block.c|3738| <<bdrv_set_file_or_backing_noperm>> child = bdrv_attach_child_noperm(parent_bs, child_bs, is_backing ? "backing" : "file",
+     *                             &child_of_bds, role, tran, errp);
+     *   - block.c|5823| <<bdrv_append>> child = bdrv_attach_child_noperm(bs_new, bs_top, "backing", &child_of_bds, bdrv_backing_role(bs_new), tran, errp);
+     *
+     * 如果是external_snapshot_action过来的
+     * bs_new应该就是一个独立的BS
+     *
+     * bs_top指向的是:
+     *
+     * Backend-->Child("root")-->BS
+     *                           ^
+     *                           |
+     *                          这个!
+     *
+     * 似乎是创建一个BdrvChild("backing"), 把其bs设置成bs_top.
+     *
+     *
+     * BdrvChild:
+     * -> QLIST_ENTRY(BdrvChild GRAPH_RDLOCK_PTR) next;
+     * -> QLIST_ENTRY(BdrvChild GRAPH_RDLOCK_PTR) next_parent;
+     *
+     * 新分配一个BdrvChild, 等这些做完
+     *
+     * new_bs->children包含了新分配的child(BdrvChild)
+     *
+     * 新分配的child->bs = old_bs
+     * 新分配的child->opaque = new_bs
+     * 新分配的child->name = "backing"
+     *
+     * old_bs->parent有了新分配的child(BdrvChild)
+     */
     child = bdrv_attach_child_noperm(bs_new, bs_top, "backing",
                                      &child_of_bds, bdrv_backing_role(bs_new),
                                      tran, errp);
@@ -5460,11 +6311,27 @@ int bdrv_append(BlockDriverState *bs_new, BlockDriverState *bs_top,
         goto out;
     }
 
+    /*
+     * called by:
+     *   - block.c|5574| <<bdrv_replace_node_common>> ret = bdrv_replace_node_noperm(from, to, auto_skip, tran, errp);
+     *   - block.c|5712| <<bdrv_append>> ret = bdrv_replace_node_noperm(bs_top, bs_new, true, tran, errp);
+     */
     ret = bdrv_replace_node_noperm(bs_top, bs_new, true, tran, errp);
     if (ret < 0) {
         goto out;
     }
 
+    /*
+     * called by:
+     *   - block.c|2928| <<bdrv_child_try_set_perm>> ret = bdrv_refresh_perms(c->bs, tran, &local_err);
+     *   - block.c|3462| <<bdrv_root_attach_child>> ret = bdrv_refresh_perms(child_bs, tran, errp);
+     *   - block.c|3500| <<bdrv_attach_child>> ret = bdrv_refresh_perms(parent_bs, tran, errp);
+     *   - block.c|3528| <<bdrv_root_unref_child>> bdrv_refresh_perms(child_bs, NULL, NULL);
+     *   - block.c|3786| <<bdrv_set_backing_hd_drained>> ret = bdrv_refresh_perms(bs, tran, errp);
+     *   - block.c|5836| <<bdrv_append>> ret = bdrv_refresh_perms(bs_new, tran, errp);
+     *   - block.c|7321| <<bdrv_activate>> ret = bdrv_refresh_perms(bs, NULL, errp);
+     *   - block.c|7466| <<bdrv_inactivate_recurse>> bdrv_refresh_perms(bs, NULL, NULL);
+     */
     ret = bdrv_refresh_perms(bs_new, tran, errp);
 out:
     tran_finalize(tran, ret);
@@ -5542,6 +6409,11 @@ static void bdrv_delete(BlockDriverState *bs)
  * The caller must make sure that @bs stays in the same AioContext, i.e.
  * @options must not refer to nodes in a different AioContext.
  */
+/*
+ * called by:
+ *   - block/copy-before-write.c|542| <<bdrv_cbw_append>> top = bdrv_insert_node(source, opts, BDRV_O_RDWR, errp);
+ *   - block/stream.c|343| <<stream_start>> cor_filter_bs = bdrv_insert_node(bs, opts, BDRV_O_RDWR, errp);
+ */
 BlockDriverState *bdrv_insert_node(BlockDriverState *bs, QDict *options,
                                    int flags, Error **errp)
 {
@@ -5683,6 +6555,15 @@ bdrv_co_change_backing_file(BlockDriverState *bs, const char *backing_file,
  *
  * Returns the bottommost base image if bs == NULL.
  */
+/*
+ * called by:
+ *   - block.c|5900| <<bdrv_find_base>> return bdrv_find_overlay(bs, NULL);
+ *   - block/commit.c|346| <<commit_start>> s->base_overlay = bdrv_find_overlay(top, base);
+ *   - block/mirror.c|1917| <<mirror_start_job>> s->base_overlay = bdrv_find_overlay(bs, base);
+ *   - block/mirror.c|1962| <<mirror_start_job>> filtered_target = bdrv_cow_bs(bdrv_find_overlay(bs, target));
+ *   - block/stream.c|292| <<stream_start>> base_overlay = bdrv_find_overlay(bs, base);
+ *   - blockdev.c|2718| <<qmp_block_commit>> BlockDriverState *overlay_bs = bdrv_find_overlay(bs, top_bs);
+ */
 BlockDriverState *bdrv_find_overlay(BlockDriverState *active,
                                     BlockDriverState *bs)
 {
@@ -5703,11 +6584,25 @@ BlockDriverState *bdrv_find_overlay(BlockDriverState *active,
     return NULL;
 }
 
+/*
+ * called by:
+ *   - blockdev.c|2622| <<qmp_block_commit>> base_bs = bdrv_find_base(top_bs);
+ *   - blockdev.c|3380| <<qmp_change_backing_file>> if (bdrv_find_base(image_bs) == image_bs) {
+ */
 /* Given a BDS, searches for the base layer. */
 BlockDriverState *bdrv_find_base(BlockDriverState *bs)
 {
     GLOBAL_STATE_CODE();
 
+    /*
+     * called by:
+     *   - block.c|5900| <<bdrv_find_base>> return bdrv_find_overlay(bs, NULL);
+     *   - block/commit.c|346| <<commit_start>> s->base_overlay = bdrv_find_overlay(top, base);
+     *   - block/mirror.c|1917| <<mirror_start_job>> s->base_overlay = bdrv_find_overlay(bs, base);
+     *   - block/mirror.c|1962| <<mirror_start_job>> filtered_target = bdrv_cow_bs(bdrv_find_overlay(bs, target));
+     *   - block/stream.c|292| <<stream_start>> base_overlay = bdrv_find_overlay(bs, base);
+     *   - blockdev.c|2718| <<qmp_block_commit>> BlockDriverState *overlay_bs = bdrv_find_overlay(bs, top_bs);
+     */
     return bdrv_find_overlay(bs, NULL);
 }
 
@@ -6189,6 +7084,24 @@ void bdrv_iterate_format(void (*it)(void *opaque, const char *name),
     g_free(formats);
 }
 
+/*
+ * called by:
+ *   - block.c|1623| <<bdrv_assign_node_name>> if (bdrv_find_node(node_name)) {
+ *   - block.c|6548| <<bdrv_lookup_bs>> bs = bdrv_find_node(node_name);
+ *   - block.c|7935| <<check_to_replace_node>> BlockDriverState *to_replace_bs = bdrv_find_node(node_name);
+ *   - block/block-backend.c|733| <<monitor_add_blk>> if (bdrv_find_node(name)) {
+ *   - block/copy-on-read.c|66| <<cor_open>> bottom_bs = bdrv_find_node(bottom_node);
+ *   - block/mirror.c|1184| <<mirror_complete>> s->to_replace = bdrv_find_node(s->replaces);
+ *   - block/monitor/block-hmp-cmds.c|149| <<hmp_drive_del>> bs = bdrv_find_node(id);
+ *   - block/qapi-sysemu.c|287| <<blockdev_insert_medium>> bs = bdrv_find_node(node_name);
+ *   - block/snapshot.c|495| <<bdrv_all_get_snapshot_devices>> BlockDriverState *bs = bdrv_find_node(devices->value);
+ *   - block/write-threshold.c|37| <<qmp_block_set_write_threshold>> bs = bdrv_find_node(node_name);
+ *   - blockdev.c|3476| <<qmp_blockdev_reopen>> bs = bdrv_find_node(options->node_name);
+ *   - blockdev.c|3511| <<qmp_blockdev_del>> bs = bdrv_find_node(node_name);
+ *   - blockdev.c|3588| <<qmp_x_blockdev_change>> new_bs = bdrv_find_node(node);
+ *   - blockdev.c|3633| <<qmp_x_blockdev_set_iothread>> bs = bdrv_find_node(node_name);
+ *   - tests/unit/test-block-iothread.c|766| <<test_propagate_mirror>> filter = bdrv_find_node("filter_node");
+ */
 /* This function is to find a node in the bs graph */
 BlockDriverState *bdrv_find_node(const char *node_name)
 {
@@ -6197,6 +7110,16 @@ BlockDriverState *bdrv_find_node(const char *node_name)
     assert(node_name);
     GLOBAL_STATE_CODE();
 
+    /*
+     * 在以下使用graph_bdrv_states:
+     *   - block.c|72| <<QTAILQ_HEAD>> static QTAILQ_HEAD(, BlockDriverState) graph_bdrv_states =
+     *   - block.c|1636| <<bdrv_assign_node_name>> QTAILQ_INSERT_TAIL(&graph_bdrv_states, bs, node_list);
+     *   - block.c|5682| <<bdrv_delete>> QTAILQ_REMOVE(&graph_bdrv_states, bs, node_list);
+     *   - block.c|6360| <<bdrv_find_node>> QTAILQ_FOREACH(bs, &graph_bdrv_states, node_list) {
+     *   - block.c|6379| <<bdrv_named_nodes_list>> QTAILQ_FOREACH(bs, &graph_bdrv_states, node_list) {
+     *   - block.c|6514| <<bdrv_get_xdbg_block_graph>> QTAILQ_FOREACH(bs, &graph_bdrv_states, node_list) {
+     *   - block.c|6579| <<bdrv_next_node>> return QTAILQ_FIRST(&graph_bdrv_states);
+     */
     QTAILQ_FOREACH(bs, &graph_bdrv_states, node_list) {
         if (!strcmp(node_name, bs->node_name)) {
             return bs;
@@ -6362,6 +7285,39 @@ XDbgBlockGraph *bdrv_get_xdbg_block_graph(Error **errp)
     return xdbg_graph_finalize(gr);
 }
 
+/*
+ * called by:
+ *   - block.c|4097| <<bdrv_open_inherit>> bs = bdrv_lookup_bs(reference, reference, errp);
+ *   - block.c|4833| <<bdrv_reopen_parse_file_or_backing>> new_child_bs = bdrv_lookup_bs(NULL, str, errp);
+ *   - block/amend.c|102| <<qmp_x_blockdev_amend>> bs = bdrv_lookup_bs(NULL, node_name, errp);
+ *   - block/export/export.c|103| <<blk_exp_add>> bs = bdrv_lookup_bs(NULL, export->node_name, errp);
+ *   - block/monitor/bitmap-qmp-cmds.c|71| <<block_dirty_bitmap_lookup>> bs = bdrv_lookup_bs(node, node, NULL);
+ *   - block/monitor/bitmap-qmp-cmds.c|104| <<qmp_block_dirty_bitmap_add>> bs = bdrv_lookup_bs(node, node, errp);
+ *   - block/monitor/block-hmp-cmds.c|564| <<hmp_qemu_io>> bs = bdrv_lookup_bs(NULL, device, &err);
+ *   - block/replication.c|408| <<backup_job_cleanup>> top_bs = bdrv_lookup_bs(s->top_id, s->top_id, NULL);
+ *   - block/replication.c|570| <<replication_start>> top_bs = bdrv_lookup_bs(s->top_id, s->top_id, NULL);
+ *   - blockdev-nbd.c|194| <<qmp_nbd_server_add>> bs = bdrv_lookup_bs(arg->device, arg->device, errp);
+ *   - blockdev.c|1064| <<qmp_get_root_bs>> bs = bdrv_lookup_bs(name, name, errp);
+ *   - blockdev.c|1408| <<external_snapshot_action>> state->old_bs = bdrv_lookup_bs(device, node_name, errp);
+ *   - blockdev.c|1446| <<external_snapshot_action>> bdrv_lookup_bs(snapshot_node_name, snapshot_node_name, NULL)) {
+ *   - blockdev.c|1631| <<drive_backup_action>> bs = bdrv_lookup_bs(backup->device, backup->device, errp);
+ *   - blockdev.c|1802| <<blockdev_backup_action>> bs = bdrv_lookup_bs(backup->device, backup->device, errp);
+ *   - blockdev.c|1807| <<blockdev_backup_action>> target_bs = bdrv_lookup_bs(backup->target, backup->target, errp);
+ *   - blockdev.c|2263| <<qmp_block_resize>> bs = bdrv_lookup_bs(device, node_name, &local_err);
+ *   - blockdev.c|2345| <<qmp_block_stream>> bs = bdrv_lookup_bs(device, device, errp);
+ *   - blockdev.c|2363| <<qmp_block_stream>> base_bs = bdrv_lookup_bs(NULL, base_node, errp);
+ *   - blockdev.c|2378| <<qmp_block_stream>> bottom_bs = bdrv_lookup_bs(NULL, bottom, errp);
+ *   - blockdev.c|2552| <<qmp_block_commit>> bs = bdrv_lookup_bs(device, device, NULL);
+ *   - blockdev.c|2576| <<qmp_block_commit>> top_bs = bdrv_lookup_bs(NULL, top_node, errp);
+ *   - blockdev.c|2606| <<qmp_block_commit>> base_bs = bdrv_lookup_bs(NULL, base_node, errp);
+ *   - blockdev.c|3169| <<qmp_blockdev_mirror>> target_bs = bdrv_lookup_bs(target, target, errp);
+ *   - blockdev.c|3369| <<qmp_change_backing_file>> image_bs = bdrv_lookup_bs(NULL, image_node_name, &local_err);
+ *   - blockdev.c|3563| <<qmp_x_blockdev_change>> parent_bs = bdrv_lookup_bs(parent, parent, errp);
+ *   - hw/core/qdev-properties-system.c|114| <<set_drive_helper>> bs = bdrv_lookup_bs(NULL, str, errp);
+ *   - hw/core/qdev-properties-system.c|136| <<set_drive_helper>> bs = bdrv_lookup_bs(NULL, str, NULL);
+ *   - migration/block-dirty-bitmap.c|1075| <<dirty_bitmap_load_header>> s->bs = bdrv_lookup_bs(NULL, amin->string, &local_err);
+ *   - migration/block-dirty-bitmap.c|1078| <<dirty_bitmap_load_header>> s->bs = bdrv_lookup_bs(s->node_alias, s->node_alias,
+ */
 BlockDriverState *bdrv_lookup_bs(const char *device,
                                  const char *node_name,
                                  Error **errp)
@@ -6385,6 +7341,18 @@ BlockDriverState *bdrv_lookup_bs(const char *device,
     }
 
     if (node_name) {
+        /*
+	 * 在以下使用graph_bdrv_states:
+	 *   - block.c|72| <<QTAILQ_HEAD>> static QTAILQ_HEAD(, BlockDriverState) graph_bdrv_states =
+	 *   - block.c|1636| <<bdrv_assign_node_name>> QTAILQ_INSERT_TAIL(&graph_bdrv_states, bs, node_list);
+	 *   - block.c|5682| <<bdrv_delete>> QTAILQ_REMOVE(&graph_bdrv_states, bs, node_list);
+	 *   - block.c|6360| <<bdrv_find_node>> QTAILQ_FOREACH(bs, &graph_bdrv_states, node_list) {
+	 *   - block.c|6379| <<bdrv_named_nodes_list>> QTAILQ_FOREACH(bs, &graph_bdrv_states, node_list) {
+	 *   - block.c|6514| <<bdrv_get_xdbg_block_graph>> QTAILQ_FOREACH(bs, &graph_bdrv_states, node_list) {
+	 *   - block.c|6579| <<bdrv_next_node>> return QTAILQ_FIRST(&graph_bdrv_states);
+         *
+	 * 从graph_bdrv_states寻找!
+	 */
         bs = bdrv_find_node(node_name);
 
         if (bs) {
@@ -6398,6 +7366,20 @@ BlockDriverState *bdrv_lookup_bs(const char *device,
     return NULL;
 }
 
+/*
+ * called by:
+ *   - block.c|5520| <<bdrv_replace_node_common>> assert(bdrv_chain_contains(from, to));
+ *   - block.c|6060| <<bdrv_drop_intermediate>> if (!bdrv_chain_contains(top, base)) {
+ *   - block/block-copy.c|403| <<block_copy_state_new>> is_fleecing = bdrv_chain_contains(target->bs, source->bs);
+ *   - block/mirror.c|690| <<mirror_exit_common>> if (bdrv_chain_contains(src, target_bs)) {
+ *   - block/mirror.c|1791| <<mirror_start_job>> target_is_backing = bdrv_chain_contains(bs, target);
+ *   - block/mirror.c|1877| <<mirror_start_job>> if (bdrv_chain_contains(bs, bdrv_skip_filters(target))) {
+ *   - blockdev.c|2367| <<qmp_block_stream>> if (bs == base_bs || !bdrv_chain_contains(bs, base_bs)) {
+ *   - blockdev.c|2391| <<qmp_block_stream>> if (!bdrv_chain_contains(bs, bottom_bs)) {
+ *   - blockdev.c|2599| <<qmp_block_commit>> if (!bdrv_chain_contains(bs, top_bs)) {
+ *   - blockdev.c|2632| <<qmp_block_commit>> if (!bdrv_chain_contains(top_bs, base_bs)) {
+ *   - blockdev.c|3433| <<qmp_change_backing_file>> if (!bdrv_chain_contains(bs, image_bs)) {
+ */
 /* If 'base' is in the same chain as 'top', return true. Otherwise,
  * return false.  If either argument is NULL, return false. */
 bool bdrv_chain_contains(BlockDriverState *top, BlockDriverState *base)
@@ -7205,6 +8187,19 @@ bool bdrv_op_blocker_is_empty(BlockDriverState *bs)
  * Must not be called while holding the lock of an AioContext other than the
  * current one.
  */
+/*
+ * called by:
+ *   - blockdev.c|1602| <<external_snapshot_action>> bdrv_img_create(new_image_file, format, state->old_bs->filename, state->old_bs->drv->format_name, NULL, size, flags, false, &local_err);
+ *   - blockdev.c|1865| <<drive_backup_action>> bdrv_img_create(backup->target, format, explicit_backing->filename, explicit_backing->drv->format_name, NULL, size, flags, false, &local_err);
+ *   - blockdev.c|1870| <<drive_backup_action>> bdrv_img_create(backup->target, format, NULL, NULL, NULL, size, flags, false, &local_err);
+ *   - blockdev.c|3343| <<qmp_drive_mirror>> bdrv_img_create(arg->target, format, NULL, NULL, NULL, size, flags, false, &local_err);
+ *   - blockdev.c|3361| <<qmp_drive_mirror>> bdrv_img_create(arg->target, format, explicit_backing->filename, explicit_backing->drv->format_name, NULL, size, flags, false, &local_err);
+ *   - qemu-img.c|597| <<img_create>> bdrv_img_create(filename, fmt, base_filename, base_fmt, options, img_size, flags, quiet, &local_err);
+ *   - tests/unit/test-replication.c|148| <<prepare_imgs>> bdrv_img_create(p_local_disk, "qcow2", NULL, NULL, NULL, IMG_SIZE, BDRV_O_RDWR, true, &error_abort);
+ *   - tests/unit/test-replication.c|152| <<prepare_imgs>> bdrv_img_create(s_local_disk, "qcow2", NULL, NULL, NULL, IMG_SIZE, BDRV_O_RDWR, true, &error_abort);
+ *   - tests/unit/test-replication.c|154| <<prepare_imgs>> bdrv_img_create(s_active_disk, "qcow2", NULL, NULL, NULL, IMG_SIZE, BDRV_O_RDWR, true, &error_abort);
+ *   - tests/unit/test-replication.c|156| <<prepare_imgs>> bdrv_img_create(s_hidden_disk, "qcow2", NULL, NULL, NULL, IMG_SIZE, BDRV_O_RDWR, true, &error_abort);
+ */
 void bdrv_img_create(const char *filename, const char *fmt,
                      const char *base_filename, const char *base_fmt,
                      char *options, uint64_t img_size, int flags, bool quiet,
@@ -7401,6 +8396,10 @@ out:
 AioContext *bdrv_get_aio_context(BlockDriverState *bs)
 {
     IO_CODE();
+    /*
+     * BlckDriverState *bs:
+     * -> AioContext *aio_context;
+     */
     return bs ? bs->aio_context : qemu_get_aio_context();
 }
 
@@ -7436,6 +8435,10 @@ static void bdrv_do_remove_aio_context_notifier(BdrvAioNotifier *ban)
     g_free(ban);
 }
 
+/*
+ * called by:
+ *   - block.c|8534| <<bdrv_set_aio_context_commit>> bdrv_detach_aio_context(bs);
+ */
 static void bdrv_detach_aio_context(BlockDriverState *bs)
 {
     BdrvAioNotifier *baf, *baf_tmp;
@@ -7462,6 +8465,10 @@ static void bdrv_detach_aio_context(BlockDriverState *bs)
     bs->aio_context = NULL;
 }
 
+/*
+ * called by:
+ *   - block.c|8535| <<bdrv_set_aio_context_commit>> bdrv_attach_aio_context(bs, new_context);
+ */
 static void bdrv_attach_aio_context(BlockDriverState *bs,
                                     AioContext *new_context)
 {
@@ -7491,6 +8498,10 @@ typedef struct BdrvStateSetAioContext {
     BlockDriverState *bs;
 } BdrvStateSetAioContext;
 
+/*
+ * called by:
+ *   - block.c|8546| <<bdrv_change_aio_context>> if (!bdrv_parent_change_aio_context(c, ctx, visited, tran, errp)) {
+ */
 static bool bdrv_parent_change_aio_context(BdrvChild *c, AioContext *ctx,
                                            GHashTable *visited,
                                            Transaction *tran,
@@ -7512,6 +8523,18 @@ static bool bdrv_parent_change_aio_context(BdrvChild *c, AioContext *ctx,
         g_free(user);
         return false;
     }
+    /*
+     * BdrvChild *c:
+     * - const BdrvChildClass *klass;
+     *   -> change_aio_ctx
+     *
+     * block.c <<change_aio_ctx>>
+     *   BdrvChildClass child_of_bds.change_aio_ctx = bdrv_child_cb_change_aio_ctx,
+     * block/block-backend.c <<change_aio_ctx>>
+     *   BdrvChildClass child_root.change_aio_ctx = blk_root_change_aio_ctx,
+     * blockjob.c <<change_aio_ctx>>
+     *   BdrvChildClass child_job.change_aio_ctx = child_job_change_aio_ctx,
+     */
     if (!c->klass->change_aio_ctx(c, ctx, visited, tran, errp)) {
         assert(!errp || *errp);
         return false;
@@ -7519,6 +8542,13 @@ static bool bdrv_parent_change_aio_context(BdrvChild *c, AioContext *ctx,
     return true;
 }
 
+/*
+ * called by:
+ *   - block.c|8553| <<bdrv_change_aio_context>> if (!bdrv_child_change_aio_context(c, ctx, visited, tran, errp)) {
+ *   - blockjob.c|157| <<child_job_change_aio_ctx>> if (!bdrv_child_change_aio_context(sibling, ctx, visited, tran, errp)) {
+ *
+ * 看过了
+ */
 bool bdrv_child_change_aio_context(BdrvChild *c, AioContext *ctx,
                                    GHashTable *visited, Transaction *tran,
                                    Error **errp)
@@ -7528,9 +8558,22 @@ bool bdrv_child_change_aio_context(BdrvChild *c, AioContext *ctx,
         return true;
     }
     g_hash_table_add(visited, c);
+    /*
+     * called by:
+     *   - block.c|1343| <<bdrv_child_cb_change_aio_ctx>> return bdrv_change_aio_context(bs, ctx, visited, tran, errp);
+     *   - block.c|8493| <<bdrv_child_change_aio_context>> return bdrv_change_aio_context(c->bs, ctx, visited, tran, errp);
+     *   - block.c|8600| <<bdrv_try_change_aio_context>> ret = bdrv_change_aio_context(bs, ctx, visited, tran, errp);
+     *
+     * 返回0 (false是失败)
+     *
+     * 看过了
+     */
     return bdrv_change_aio_context(c->bs, ctx, visited, tran, errp);
 }
 
+/*
+ * TransactionActionDrv set_aio_context.clean = bdrv_set_aio_context_clean()
+ */
 static void bdrv_set_aio_context_clean(void *opaque)
 {
     BdrvStateSetAioContext *state = (BdrvStateSetAioContext *) opaque;
@@ -7542,16 +8585,32 @@ static void bdrv_set_aio_context_clean(void *opaque)
     g_free(state);
 }
 
+/*
+ * TransactionActionDrv set_aio_context.commit = bdrv_set_aio_context_commit()
+ */
 static void bdrv_set_aio_context_commit(void *opaque)
 {
+    /*
+     * 8457 typedef struct BdrvStateSetAioContext {
+     * 8458     AioContext *new_ctx;
+     * 8459     BlockDriverState *bs;
+     * 8460 } BdrvStateSetAioContext;
+     */
     BdrvStateSetAioContext *state = (BdrvStateSetAioContext *) opaque;
     BlockDriverState *bs = (BlockDriverState *) state->bs;
     AioContext *new_context = state->new_ctx;
 
+    /*
+     * 下面两个函数都是只在此处调用	
+     */
     bdrv_detach_aio_context(bs);
     bdrv_attach_aio_context(bs, new_context);
 }
 
+/*
+ * 在以下使用set_aio_context:
+ *   - block.c|8590| <<bdrv_change_aio_context>> tran_add(tran, &set_aio_context, state);
+ */
 static TransactionActionDrv set_aio_context = {
     .commit = bdrv_set_aio_context_commit,
     .clean = bdrv_set_aio_context_clean,
@@ -7566,6 +8625,16 @@ static TransactionActionDrv set_aio_context = {
  * @visited will accumulate all visited BdrvChild objects. The caller is
  * responsible for freeing the list afterwards.
  */
+/*
+ * called by:
+ *   - block.c|1343| <<bdrv_child_cb_change_aio_ctx>> return bdrv_change_aio_context(bs, ctx, visited, tran, errp);
+ *   - block.c|8493| <<bdrv_child_change_aio_context>> return bdrv_change_aio_context(c->bs, ctx, visited, tran, errp);
+ *   - block.c|8600| <<bdrv_try_change_aio_context>> ret = bdrv_change_aio_context(bs, ctx, visited, tran, errp);
+ *
+ * 返回0 (false是失败)
+ *
+ * 看过了
+ */
 static bool bdrv_change_aio_context(BlockDriverState *bs, AioContext *ctx,
                                     GHashTable *visited, Transaction *tran,
                                     Error **errp)
@@ -7616,6 +8685,28 @@ static bool bdrv_change_aio_context(BlockDriverState *bs, AioContext *ctx,
  * If ignore_child is not NULL, that child (and its subgraph) will not
  * be touched.
  */
+/*
+ * called by:
+ *   - block.c|3453| <<bdrv_attach_child_common_abort>> bdrv_try_change_aio_context(bs, s->old_child_ctx, NULL, &error_abort);
+ *   - block.c|3576| <<bdrv_attach_child_common>> int ret = bdrv_try_change_aio_context(child_bs, parent_ctx, NULL, &local_err);
+ *   - block.c|3889| <<bdrv_root_unref_child>> bdrv_try_change_aio_context(child_bs, qemu_get_aio_context(), NULL, NULL);
+ *   - block/block-backend.c|2781| <<blk_set_aio_context>> ret = bdrv_try_change_aio_context(bs, new_context, NULL, errp);
+ *   - block/export/export.c|133| <<blk_exp_add>> ret = bdrv_try_change_aio_context(bs, new_ctx, NULL, set_context_errp);
+ *   - blockdev.c|1853| <<external_snapshot_abort>> ret = bdrv_try_change_aio_context(state->old_bs, aio_context, NULL, NULL);
+ *   - blockdev.c|2027| <<drive_backup_action>> ret = bdrv_try_change_aio_context(target_bs, aio_context, NULL, errp);
+ *   - blockdev.c|2114| <<blockdev_backup_action>> ret = bdrv_try_change_aio_context(target_bs, aio_context, NULL, errp);
+ *   - blockdev.c|3543| <<qmp_drive_mirror>> ret = bdrv_try_change_aio_context(target_bs, aio_context, NULL, errp);
+ *   - blockdev.c|3604| <<qmp_blockdev_mirror>> ret = bdrv_try_change_aio_context(target_bs, aio_context, NULL, errp);
+ *   - blockdev.c|4118| <<qmp_x_blockdev_set_iothread>> bdrv_try_change_aio_context(bs, new_context, NULL, errp);
+ *   - tests/unit/test-bdrv-drain.c|1398| <<test_set_aio_context>> bdrv_try_change_aio_context(bs, ctx_a, NULL, &error_abort);
+ *   - tests/unit/test-bdrv-drain.c|1402| <<test_set_aio_context>> bdrv_try_change_aio_context(bs, ctx_b, NULL, &error_abort);
+ *   - tests/unit/test-bdrv-drain.c|1403| <<test_set_aio_context>> bdrv_try_change_aio_context(bs, qemu_get_aio_context(), NULL, &error_abort);
+ *   - tests/unit/test-block-iothread.c|769| <<test_propagate_mirror>> bdrv_try_change_aio_context(src, ctx, NULL, &error_abort);
+ *   - tests/unit/test-block-iothread.c|776| <<test_propagate_mirror>> bdrv_try_change_aio_context(target, main_ctx, NULL, &error_abort);
+ *   - tests/unit/test-block-iothread.c|785| <<test_propagate_mirror>> bdrv_try_change_aio_context(target, ctx, NULL, &local_err);
+ *   - tests/unit/test-block-iothread.c|795| <<test_propagate_mirror>> bdrv_try_change_aio_context(target, ctx, NULL, &error_abort);
+ *   - tests/unit/test-block-iothread.c|805| <<test_propagate_mirror>> bdrv_try_change_aio_context(target, main_ctx, NULL, &error_abort);
+ */
 int bdrv_try_change_aio_context(BlockDriverState *bs, AioContext *ctx,
                                 BdrvChild *ignore_child, Error **errp)
 {
@@ -7635,6 +8726,9 @@ int bdrv_try_change_aio_context(BlockDriverState *bs, AioContext *ctx,
     if (ignore_child) {
         g_hash_table_add(visited, ignore_child);
     }
+    /*
+     * 重点是这里, 只有这里失败
+     */
     ret = bdrv_change_aio_context(bs, ctx, visited, tran, errp);
     g_hash_table_destroy(visited);
 
@@ -7655,6 +8749,11 @@ int bdrv_try_change_aio_context(BlockDriverState *bs, AioContext *ctx,
     return 0;
 }
 
+/*
+ * called by:
+ *   - block/block-backend.c|312| <<blk_root_attach>> bdrv_add_aio_context_notifier(child->bs, notifier->attached_aio_context, notifier->detach_aio_context, notifier->opaque);
+ *   - block/block-backend.c|2753| <<blk_root_attach>> bdrv_add_aio_context_notifier(bs, attached_aio_context, detach_aio_context, opaque);
+ */
 void bdrv_add_aio_context_notifier(BlockDriverState *bs,
         void (*attached_aio_context)(AioContext *new_context, void *opaque),
         void (*detach_aio_context)(void *opaque), void *opaque)
@@ -8178,6 +9277,18 @@ int bdrv_make_empty(BdrvChild *c, Error **errp)
  * Return the child that @bs acts as an overlay for, and from which data may be
  * copied in COW or COR operations.  Usually this is the backing file.
  */
+/*
+ * called by:
+ *   - block.c|7054| <<bdrv_has_zero_init>> if (bdrv_cow_child(bs)) {
+ *   - block.c|7268| <<bdrv_find_backing_image>> bdrv_cow_child(curr_bs) != NULL;
+ *   - block.c|8799| <<bdrv_filter_or_cow_child>> BdrvChild *cow_child = bdrv_cow_child(bs);
+ *   - block/block-backend.c|3044| <<blk_commit_all>> if (blk_is_inserted(blk) && bdrv_cow_child(unfiltered_bs)) {
+ *   - block/io.c|3852| <<bdrv_co_truncate>> backing = bdrv_cow_child(bs);
+ *   - blockdev.c|1644| <<external_snapshot_action>> if (bdrv_cow_child(state->new_bs)) {
+ *   - include/block/block_int-io.h|144| <<bdrv_cow_bs>> return child_bs(bdrv_cow_child(bs));
+ *
+ * 核心是返回BlockDriverState->backing
+ */
 BdrvChild *bdrv_cow_child(BlockDriverState *bs)
 {
     IO_CODE();
@@ -8270,6 +9381,11 @@ BdrvChild *bdrv_primary_child(BlockDriverState *bs)
     return found;
 }
 
+/*
+ * called by:
+ *   - block.c|8527| <<bdrv_skip_implicit_filters>> return bdrv_do_skip_filters(bs, true);
+ *   - block.c|8537| <<bdrv_skip_filters>> return bdrv_do_skip_filters(bs, false);
+ */
 static BlockDriverState * GRAPH_RDLOCK
 bdrv_do_skip_filters(BlockDriverState *bs, bool stop_on_explicit_filter)
 {
@@ -8315,6 +9431,32 @@ BlockDriverState *bdrv_skip_implicit_filters(BlockDriverState *bs)
     return bdrv_do_skip_filters(bs, true);
 }
 
+/*
+ * called by:
+ *   - block.c|5876| <<bdrv_find_overlay>> bs = bdrv_skip_filters(bs);
+ *   - block.c|5877| <<bdrv_find_overlay>> active = bdrv_skip_filters(active);
+ *   - block.c|6973| <<bdrv_find_backing_image>> for (curr_bs = bdrv_skip_filters(bs);
+ *   - block.c|8602| <<bdrv_backing_chain_next>> return bdrv_skip_filters(bdrv_cow_bs(bdrv_skip_filters(bs)));
+ *   - block/block-backend.c|2840| <<blk_commit_all>> BlockDriverState *unfiltered_bs = bdrv_skip_filters(blk_bs(blk));
+ *   - block/commit.c|274| <<commit_start>> if (bdrv_skip_filters(top) == bdrv_skip_filters(base)) {
+ *   - block/commit.c|354| <<commit_start>> assert(bdrv_skip_filters(filtered_base) == bdrv_skip_filters(base));
+ *   - block/mirror.c|726| <<mirror_exit_common>> BlockDriverState *unfiltered_target = bdrv_skip_filters(target_bs);
+ *   - block/mirror.c|738| <<mirror_exit_common>> ret = bdrv_open_backing_file(bdrv_skip_filters(target_bs), NULL,
+ *   - block/mirror.c|1785| <<mirror_start_job>> if (bdrv_skip_filters(bs) == bdrv_skip_filters(target)) {
+ *   - block/mirror.c|1877| <<mirror_start_job>> if (bdrv_chain_contains(bs, bdrv_skip_filters(target))) {
+ *   - block/mirror.c|1964| <<mirror_start_job>> assert(bdrv_skip_filters(filtered_target) ==
+ *   - block/mirror.c|1965| <<mirror_start_job>> bdrv_skip_filters(target));
+ *   - block/stream.c|67| <<stream_prepare>> unfiltered_bs = bdrv_skip_filters(s->target_bs);
+ *   - block/stream.c|91| <<stream_prepare>> unfiltered_base = bdrv_skip_filters(base);
+ *   - block/stream.c|165| <<stream_run>> unfiltered_bs = bdrv_skip_filters(s->target_bs);
+ *   - blockdev.c|1672| <<drive_backup_action>> source = bdrv_cow_bs(bdrv_skip_filters(bs));
+ *   - blockdev.c|2685| <<qmp_block_commit>> bdrv_skip_filters(top_bs) == bdrv_skip_filters(bs))
+ *   - blockdev.c|2688| <<qmp_block_commit>> if (bdrv_skip_filters(top_bs) == bdrv_skip_filters(bs)) {
+ *   - blockdev.c|3054| <<qmp_drive_mirror>> target_backing_bs = bdrv_cow_bs(bdrv_skip_filters(bs));
+ *   - qemu-img.c|1746| <<convert_iteration_sectors>> base = bdrv_cow_bs(bdrv_skip_filters(src_bs));
+ *   - qemu-img.c|3163| <<get_block_status>> bs = bdrv_skip_filters(bs);
+ *   - qemu-img.c|3673| <<img_rebase>> unfiltered_bs = bdrv_skip_filters(bs);
+ */
 /*
  * Return the first BDS that does not have a filtered child down the
  * chain starting from @bs (including @bs itself).
@@ -8322,6 +9464,11 @@ BlockDriverState *bdrv_skip_implicit_filters(BlockDriverState *bs)
 BlockDriverState *bdrv_skip_filters(BlockDriverState *bs)
 {
     IO_CODE();
+    /*
+     * called by:
+     *   - block.c|8527| <<bdrv_skip_implicit_filters>> return bdrv_do_skip_filters(bs, true);
+     *   - block.c|8537| <<bdrv_skip_filters>> return bdrv_do_skip_filters(bs, false);
+     */
     return bdrv_do_skip_filters(bs, false);
 }
 
diff --git a/block/aio_task.c b/block/aio_task.c
index 9bd17ea2c..8abec7c1b 100644
--- a/block/aio_task.c
+++ b/block/aio_task.c
@@ -27,6 +27,12 @@
 #include "block/aio_task.h"
 
 struct AioTaskPool {
+    /*
+     * 在以下使用AioTaskPool->main_co:
+     *   - block/aio_task.c|57| <<aio_task_co>> aio_co_wake(pool->main_co);
+     *   - block/aio_task.c|64| <<aio_task_pool_wait_one>> assert(qemu_coroutine_self() == pool->main_co);
+     *   - block/aio_task.c|103| <<aio_task_pool_new>> pool->main_co = qemu_coroutine_self();
+     */
     Coroutine *main_co;
     int status;
     int max_busy_tasks;
diff --git a/block/block-backend.c b/block/block-backend.c
index db6f9b92a..0249b29e0 100644
--- a/block/block-backend.c
+++ b/block/block-backend.c
@@ -28,6 +28,12 @@
 #include "trace.h"
 #include "migration/misc.h"
 
+/*
+ * 这个文档:
+ * A Practical Look at QEMU's Block Layer Primitives
+ * https://kashyapc.fedorapeople.org/virt/LinuxCon-NA-2016/A-Practical-Look-at-QEMU-Block-Layer-Primitives-LC-NA-2016.pdf
+ */
+
 /* Number of coroutines to reserve per attached device model */
 #define COROUTINE_POOL_RESERVATION 64
 
@@ -47,6 +53,12 @@ struct BlockBackend {
     AioContext *ctx; /* access with atomic operations only */
     DriveInfo *legacy_dinfo;    /* null unless created by drive_new() */
     QTAILQ_ENTRY(BlockBackend) link;         /* for block_backends */
+    /*
+     * 在以下使用BlockBackend->monitor_link:
+     *   - block/block-backend.c|623| <<blk_next>> return blk ? QTAILQ_NEXT(blk, monitor_link)
+     *   - block/block-backend.c|756| <<monitor_add_blk>> QTAILQ_INSERT_TAIL(&monitor_block_backends, blk, monitor_link);
+     *   - block/block-backend.c|779| <<monitor_remove_blk>> QTAILQ_REMOVE(&monitor_block_backends, blk, monitor_link);
+     */
     QTAILQ_ENTRY(BlockBackend) monitor_link; /* for monitor_block_backends */
     BlockBackendPublic public;
 
@@ -71,9 +83,24 @@ struct BlockBackend {
     uint64_t shared_perm;
     bool disable_perm;
 
+    /*
+     * 在以下使用BlockBackend->allow_aio_context_change:
+     *   - block/block-backend.c|1507| <<blk_set_allow_aio_context_change>> blk->allow_aio_context_change = allow;
+     *   - block/block-backend.c|2778| <<blk_set_aio_context>> old_allow_change = blk->allow_aio_context_change;
+     *   - block/block-backend.c|2779| <<blk_set_aio_context>> blk->allow_aio_context_change = true;
+     *   - block/block-backend.c|2783| <<blk_set_aio_context>> blk->allow_aio_context_change = old_allow_change;
+     *   - block/block-backend.c|2820| <<blk_root_change_aio_ctx>> if (!blk->allow_aio_context_change) {
+     */
     bool allow_aio_context_change;
     bool allow_write_beyond_eof;
 
+    /*
+     * 在以下使用BlockBackend->insert_bs_notifiers:
+     *   - block/block-backend.c|463| <<blk_new>> notifier_list_init(&blk->insert_bs_notifiers);
+     *   - block/block-backend.c|602| <<blk_delete>> assert(QLIST_EMPTY(&blk->insert_bs_notifiers.notifiers));
+     *   - block/block-backend.c|1173| <<blk_insert_bs>> notifier_list_notify(&blk->insert_bs_notifiers, blk);
+     *   - block/block-backend.c|2901| <<blk_add_insert_bs_notifier>> notifier_list_add(&blk->insert_bs_notifiers, notify);
+     */
     /* Protected by BQL */
     NotifierList remove_bs_notifiers, insert_bs_notifiers;
     QLIST_HEAD(, BlockBackendAioNotifier) aio_notifiers;
@@ -108,6 +135,14 @@ static void drive_info_del(DriveInfo *dinfo);
 static BlockBackend *bdrv_first_blk(BlockDriverState *bs);
 
 /* All BlockBackends. Protected by BQL. */
+/*
+ * 在以下使用block_backends:
+ *   - block/block-backend.c|111| <<QTAILQ_HEAD>> static QTAILQ_HEAD(, BlockBackend) block_backends =
+ *   - block/block-backend.c|112| <<QTAILQ_HEAD>> QTAILQ_HEAD_INITIALIZER(block_backends);
+ *   - block/block-backend.c|394| <<blk_new>> QTAILQ_INSERT_TAIL(&block_backends, blk, link);
+ *   - block/block-backend.c|513| <<blk_delete>> QTAILQ_REMOVE(&block_backends, blk, link);
+ *   - block/block-backend.c|575| <<blk_all_next>> : QTAILQ_FIRST(&block_backends);
+ */
 static QTAILQ_HEAD(, BlockBackend) block_backends =
     QTAILQ_HEAD_INITIALIZER(block_backends);
 
@@ -115,6 +150,13 @@ static QTAILQ_HEAD(, BlockBackend) block_backends =
  * All BlockBackends referenced by the monitor and which are iterated through by
  * blk_next(). Protected by BQL.
  */
+/*
+ * 在以下使用monitor_block_backends:
+ *   - block/block-backend.c|118| <<QTAILQ_HEAD>> static QTAILQ_HEAD(, BlockBackend) monitor_block_backends =
+ *   - block/block-backend.c|590| <<blk_next>> : QTAILQ_FIRST(&monitor_block_backends);
+ *   - block/block-backend.c|707| <<monitor_add_blk>> QTAILQ_INSERT_TAIL(&monitor_block_backends, blk, monitor_link);
+ *   - block/block-backend.c|723| <<monitor_remove_blk>> QTAILQ_REMOVE(&monitor_block_backends, blk, monitor_link);
+ */
 static QTAILQ_HEAD(, BlockBackend) monitor_block_backends =
     QTAILQ_HEAD_INITIALIZER(monitor_block_backends);
 
@@ -280,6 +322,9 @@ static int GRAPH_RDLOCK blk_root_inactivate(BdrvChild *child)
     return 0;
 }
 
+/*
+ * BdrvChildClass child_root.attach = blk_root_attach()
+ */
 static void blk_root_attach(BdrvChild *child)
 {
     BlockBackend *blk = child->opaque;
@@ -318,6 +363,14 @@ static AioContext *blk_root_get_parent_aio_context(BdrvChild *c)
     return blk_get_aio_context(blk);
 }
 
+/*
+ * 在以下使用child_root:
+ *   - block/block-backend.c|328| <<global>> static const BdrvChildClass child_root = {
+ *   - block/block-backend.c|821| <<bdrv_first_blk>> if (child->klass == &child_root) {
+ *   - block/block-backend.c|849| <<bdrv_is_root_node>> if (c->klass != &child_root) {
+ *   - block/block-backend.c|964| <<blk_insert_bs>> blk->root = bdrv_root_attach_child(bs, "root", &child_root, BDRV_CHILD_FILTERED | BDRV_CHILD_PRIMARY,
+ *                                                  blk->perm, blk->shared_perm, blk, errp);
+ */
 static const BdrvChildClass child_root = {
     .inherit_options    = blk_root_inherit_options,
 
@@ -341,6 +394,55 @@ static const BdrvChildClass child_root = {
     .get_parent_aio_context = blk_root_get_parent_aio_context,
 };
 
+/*
+ * called by:
+ *   - block.c|4322| <<bdrv_open_inherit>> file = blk_new(ctx, 0, BLK_PERM_ALL);
+ *   - block/block-backend.c|433| <<blk_new_with_bs>> BlockBackend *blk = blk_new(bdrv_get_aio_context(bs), perm, shared_perm);
+ *   - block/block-backend.c|513| <<blk_new_open>> blk = blk_new(bdrv_get_aio_context(bs), perm, shared);
+ *   - block/commit.c|394| <<commit_start>> s->base = blk_new(s->common.job.aio_context,
+ *   - block/commit.c|406| <<commit_start>> s->top = blk_new(s->common.job.aio_context, 0, BLK_PERM_ALL);
+ *   - block/commit.c|494| <<bdrv_commit>> src = blk_new(ctx, BLK_PERM_CONSISTENT_READ | BLK_PERM_WRITE_UNCHANGED,
+ *   - block/commit.c|496| <<bdrv_commit>> backing = blk_new(ctx, BLK_PERM_WRITE | BLK_PERM_RESIZE, BLK_PERM_ALL);
+ *   - block/export/export.c|156| <<blk_exp_add>> blk = blk_new(ctx, perm, BLK_PERM_ALL);
+ *   - block/mirror.c|2067| <<mirror_start_job>> s->target = blk_new(s->common.job.aio_context,
+ *   - block/monitor/block-hmp-cmds.c|572| <<hmp_qemu_io>> blk = local_blk = blk_new(bdrv_get_aio_context(bs), 0, BLK_PERM_ALL);
+ *   - blockdev.c|591| <<blockdev_init>> blk = blk_new(qemu_get_aio_context(), 0, BLK_PERM_ALL);
+ *   - hw/block/fdc.c|68| <<blk_create_empty_drive>> return blk_new(qemu_get_aio_context(), 0, BLK_PERM_ALL);
+ *   - hw/block/swim.c|205| <<swim_drive_realize>> dev->conf.blk = blk_new(qemu_get_aio_context(), 0, BLK_PERM_ALL);
+ *   - hw/block/xen-block.c|760| <<xen_cdrom_realize>> conf->blk = blk_new(qemu_get_aio_context(), 0, BLK_PERM_ALL);
+ *   - hw/core/qdev-properties-system.c|146| <<set_drive_helper>> blk = blk_new(iothread ? ctx : qemu_get_aio_context(),
+ *   - hw/ide/ide-dev.c|88| <<ide_dev_initfn>> dev->conf.blk = blk_new(qemu_get_aio_context(), 0, BLK_PERM_ALL);
+ *   - hw/scsi/scsi-disk.c|2569| <<scsi_cd_realize>> dev->conf.blk = blk_new(qemu_get_aio_context(), 0, BLK_PERM_ALL);
+ *   - migration/block.c|415| <<init_blk_migration>> bmds->blk = blk_new(qemu_get_aio_context(),
+ *   - qemu-img.c|3717| <<img_rebase>> blk_old_backing = blk_new(qemu_get_aio_context(),
+ *   - qemu-img.c|3770| <<img_rebase>> blk_new_backing = blk_new(qemu_get_aio_context(),
+ *   - tests/unit/test-bdrv-drain.c|190| <<test_setup>> blk = blk_new(qemu_get_aio_context(), BLK_PERM_ALL, BLK_PERM_ALL);
+ *   - tests/unit/test-bdrv-drain.c|381| <<test_nested>> blk = blk_new(qemu_get_aio_context(), BLK_PERM_ALL, BLK_PERM_ALL);
+ *   - tests/unit/test-bdrv-drain.c|431| <<test_graph_change_drain_all>> blk_a = blk_new(qemu_get_aio_context(), BLK_PERM_ALL, BLK_PERM_ALL);
+ *   - tests/unit/test-bdrv-drain.c|447| <<test_graph_change_drain_all>> blk_b = blk_new(qemu_get_aio_context(), BLK_PERM_ALL, BLK_PERM_ALL);
+ *   - tests/unit/test-bdrv-drain.c|546| <<test_iothread_common>> blk = blk_new(qemu_get_aio_context(), BLK_PERM_ALL, BLK_PERM_ALL);
+ *   - tests/unit/test-bdrv-drain.c|739| <<test_blockjob_common_drain_node>> blk_src = blk_new(qemu_get_aio_context(), BLK_PERM_ALL, BLK_PERM_ALL);
+ *   - tests/unit/test-bdrv-drain.c|763| <<test_blockjob_common_drain_node>> blk_target = blk_new(qemu_get_aio_context(), BLK_PERM_ALL, BLK_PERM_ALL);
+ *   - tests/unit/test-bdrv-drain.c|1075| <<do_test_delete_by_drain>> blk = blk_new(qemu_get_aio_context(), BLK_PERM_ALL, BLK_PERM_ALL);
+ *   - tests/unit/test-bdrv-drain.c|1247| <<test_detach_indirect>> blk = blk_new(qemu_get_aio_context(), BLK_PERM_ALL, BLK_PERM_ALL);
+ *   - tests/unit/test-bdrv-drain.c|1350| <<test_append_to_drained>> blk = blk_new(qemu_get_aio_context(), BLK_PERM_ALL, BLK_PERM_ALL);
+ *   - tests/unit/test-bdrv-drain.c|1922| <<do_test_replace_child_mid_drain>> parent_blk = blk_new(qemu_get_aio_context(),
+ *   - tests/unit/test-bdrv-graph-mod.c|132| <<test_update_perm_tree>> BlockBackend *root = blk_new(qemu_get_aio_context(),
+ *   - tests/unit/test-bdrv-graph-mod.c|198| <<test_should_update_child>> BlockBackend *root = blk_new(qemu_get_aio_context(), 0, BLK_PERM_ALL);
+ *   - tests/unit/test-block-backend.c|41| <<test_drain_aio_error>> BlockBackend *blk = blk_new(qemu_get_aio_context(),
+ *   - tests/unit/test-block-backend.c|58| <<test_drain_all_aio_error>> BlockBackend *blk = blk_new(qemu_get_aio_context(),
+ *   - tests/unit/test-block-iothread.c|476| <<test_sync_op>> blk = blk_new(qemu_get_aio_context(), BLK_PERM_ALL, BLK_PERM_ALL);
+ *   - tests/unit/test-block-iothread.c|557| <<test_attach_blockjob>> blk = blk_new(qemu_get_aio_context(), BLK_PERM_ALL, BLK_PERM_ALL);
+ *   - tests/unit/test-block-iothread.c|626| <<test_propagate_basic>> blk = blk_new(qemu_get_aio_context(), BLK_PERM_ALL & ~BLK_PERM_RESIZE,
+ *   - tests/unit/test-block-iothread.c|713| <<test_propagate_diamond>> blk = blk_new(qemu_get_aio_context(), BLK_PERM_ALL & ~BLK_PERM_RESIZE,
+ *   - tests/unit/test-block-iothread.c|782| <<test_propagate_mirror>> blk = blk_new(qemu_get_aio_context(), 0, BLK_PERM_ALL);
+ *   - tests/unit/test-block-iothread.c|821| <<test_attach_second_node>> blk = blk_new(ctx, BLK_PERM_ALL, BLK_PERM_ALL);
+ *   - tests/unit/test-block-iothread.c|852| <<test_attach_preserve_blk_ctx>> blk = blk_new(ctx, BLK_PERM_ALL, BLK_PERM_ALL);
+ *   - tests/unit/test-blockjob.c|71| <<create_blk>> BlockBackend *blk = blk_new(qemu_get_aio_context(), 0, BLK_PERM_ALL);
+ *   - tests/unit/test-throttle.c|745| <<test_groups>> blk1 = blk_new(qemu_get_aio_context(), 0, BLK_PERM_ALL);
+ *   - tests/unit/test-throttle.c|746| <<test_groups>> blk2 = blk_new(qemu_get_aio_context(), 0, BLK_PERM_ALL);
+ *   - tests/unit/test-throttle.c|747| <<test_groups>> blk3 = blk_new(qemu_get_aio_context(), 0, BLK_PERM_ALL);
+ */
 /*
  * Create a new BlockBackend with a reference count of one.
  *
@@ -391,6 +493,13 @@ BlockBackend *blk_new(AioContext *ctx, uint64_t perm, uint64_t shared_perm)
  *
  * Return the new BlockBackend on success, null on failure.
  */
+/*
+ * called by:
+ *   - block/qcow2-snapshot.c|790| <<qcow2_snapshot_goto>> BlockBackend *blk = blk_new_with_bs(bs, BLK_PERM_RESIZE, BLK_PERM_ALL,
+  4 block/qcow2.c|5898| <<qcow2_amend_options>> BlockBackend *blk = blk_new_with_bs(bs, BLK_PERM_RESIZE, BLK_PERM_ALL,
+  5 block/stream.c|359| <<stream_start>> s->blk = blk_new_with_bs(cor_filter_bs, BLK_PERM_CONSISTENT_READ,
+  6 qemu-img.c|1105| <<img_commit>> old_backing_blk = blk_new_with_bs(bs, BLK_PERM_WRITE, BLK_PERM_ALL,
+ */
 BlockBackend *blk_new_with_bs(BlockDriverState *bs, uint64_t perm,
                               uint64_t shared_perm, Error **errp)
 {
@@ -420,6 +529,20 @@ BlockBackend *blk_new_with_bs(BlockDriverState *bs, uint64_t perm,
  * though, so callers of this function have to be able to specify @filename and
  * @flags.
  */
+/*
+ * called by:
+ *   - blockdev.c|616| <<blockdev_init>> blk = blk_new_open(file, NULL, bs_opts, bdrv_flags, errp);
+ *   - qemu-img.c|376| <<img_open_opts>> blk = blk_new_open(NULL, NULL, options, flags, &local_err);
+ *   - qemu-img.c|405| <<img_open_file>> blk = blk_new_open(filename, NULL, options, flags, &local_err);
+ *   - qemu-img.c|3782| <<img_rebase>> blk_new_backing = blk_new_open(out_real_path, NULL,
+ *   - qemu-io.c|108| <<openfile>> qemuio_blk = blk_new_open(name, NULL, opts, flags, &local_err);
+ *   - qemu-nbd.c|1105| <<main>> blk = blk_new_open(NULL, NULL, options, flags, &local_err);
+ *   - qemu-nbd.c|1111| <<main>> blk = blk_new_open(opts.srcpath, NULL, options, flags, &local_err);
+ *   - tests/unit/test-image-locking.c|43| <<open_image>> blk = blk_new_open(path, NULL, options, BDRV_O_RDWR, &local_err);
+ *   - tests/unit/test-replication.c|189| <<start_primary>> blk = blk_new_open(NULL, NULL, qdict, BDRV_O_RDWR, &error_abort);
+ *   - tests/unit/test-replication.c|305| <<start_secondary>> blk = blk_new_open(NULL, NULL, qdict, BDRV_O_RDWR, &error_abort);
+ *   - tests/unit/test-replication.c|331| <<start_secondary>> blk = blk_new_open(NULL, NULL, qdict, BDRV_O_RDWR, &error_abort);
+ */
 BlockBackend *blk_new_open(const char *filename, const char *reference,
                            QDict *options, int flags, Error **errp)
 {
@@ -553,6 +676,21 @@ void blk_unref(BlockBackend *blk)
  * Behaves similarly to blk_next() but iterates over all BlockBackends, even the
  * ones which are hidden (i.e. are not referenced by the monitor).
  */
+/*
+ * called by:
+ *   - block.c|6742| <<bdrv_get_xdbg_block_graph>> for (blk = blk_all_next(NULL); blk; blk = blk_all_next(blk)) {
+ *   - block/block-backend.c|584| <<blk_remove_all_bs>> while ((blk = blk_all_next(blk)) != NULL) {
+ *   - block/block-backend.c|645| <<bdrv_next>> it->blk = blk_all_next(it->blk);
+ *   - block/block-backend.c|1181| <<blk_by_dev>> while ((blk = blk_all_next(blk)) != NULL) {
+ *   - block/block-backend.c|2254| <<blk_drain_all>> while ((blk = blk_all_next(blk)) != NULL) {
+ *   - block/block-backend.c|2880| <<blk_commit_all>> while ((blk = blk_all_next(blk)) != NULL) {
+ *   - block/qapi.c|671| <<qmp_query_block>> for (blk = blk_all_next(NULL); blk; blk = blk_all_next(blk)) {
+ *   - block/qapi.c|710| <<qmp_query_blockstats>> for (blk = blk_all_next(NULL); blk; blk = blk_all_next(blk)) {
+ *   - tests/unit/test-bdrv-drain.c|280| <<test_drv_cb_co_drain_all_entry>> BlockBackend *blk = blk_all_next(NULL);
+ *   - tests/unit/test-bdrv-drain.c|293| <<test_drv_cb_co_drain_entry>> BlockBackend *blk = blk_all_next(NULL);
+ *   - tests/unit/test-bdrv-drain.c|350| <<test_quiesce_co_drain_all_entry>> BlockBackend *blk = blk_all_next(NULL);
+ *   - tests/unit/test-bdrv-drain.c|363| <<test_quiesce_co_drain_entry>> BlockBackend *blk = blk_all_next(NULL);
+ */
 BlockBackend *blk_all_next(BlockBackend *blk)
 {
     GLOBAL_STATE_CODE();
@@ -583,13 +721,44 @@ void blk_remove_all_bs(void)
  *     ...
  * }
  */
+/*
+ * called by:
+ *   - block/block-backend.c|748| <<blk_by_name>> while ((blk = blk_next(blk)) != NULL) {
+ *   - block/block-backend.c|839| <<blk_by_legacy_dinfo>> while ((blk = blk_next(blk)) != NULL) {
+ *   - blockdev.c|123| <<override_max_devs>> for (blk = blk_next(NULL); blk; blk = blk_next(blk)) {
+ *   - blockdev.c|228| <<drive_get>> for (blk = blk_next(NULL); blk; blk = blk_next(blk)) {
+ *   - blockdev.c|252| <<drive_check_orphaned>> for (blk = blk_next(NULL); blk; blk = blk_next(blk)) {
+ *   - blockdev.c|300| <<drive_get_max_bus>> for (blk = blk_next(NULL); blk; blk = blk_next(blk)) {
+ *   - migration/block-dirty-bitmap.c|629| <<init_dirty_bitmap_migration>> for (blk = blk_next(NULL); blk; blk = blk_next(blk)) {
+ *   - monitor/hmp.c|1335| <<monitor_find_completion_by_table>> while ((blk = blk_next(blk)) != NULL) {
+ *   - monitor/qmp-cmds.c|89| <<qmp_cont>> for (blk = blk_next(NULL); blk; blk = blk_next(blk)) {
+ */
 BlockBackend *blk_next(BlockBackend *blk)
 {
     GLOBAL_STATE_CODE();
+    /*
+     * 在以下使用monitor_block_backends:
+     *   - block/block-backend.c|118| <<QTAILQ_HEAD>> static QTAILQ_HEAD(, BlockBackend) monitor_block_backends =
+     *   - block/block-backend.c|590| <<blk_next>> : QTAILQ_FIRST(&monitor_block_backends);
+     *   - block/block-backend.c|707| <<monitor_add_blk>> QTAILQ_INSERT_TAIL(&monitor_block_backends, blk, monitor_link);
+     *   - block/block-backend.c|723| <<monitor_remove_blk>> QTAILQ_REMOVE(&monitor_block_backends, blk, monitor_link);
+     */
     return blk ? QTAILQ_NEXT(blk, monitor_link)
                : QTAILQ_FIRST(&monitor_block_backends);
 }
 
+/*
+ * called by:
+ *   - block.c|7383| <<bdrv_activate_all>> for (bs = bdrv_first(&it); bs; bs = bdrv_next(&it)) {
+ *   - block.c|7485| <<bdrv_inactivate_all>> for (bs = bdrv_first(&it); bs; bs = bdrv_next(&it)) {
+ *   - block/block-backend.c|690| <<bdrv_first>> return bdrv_next(it);
+ *   - block/io.c|2397| <<bdrv_flush_all>> for (bs = bdrv_first(&it); bs; bs = bdrv_next(&it)) {
+ *   - block/monitor/block-hmp-cmds.c|897| <<hmp_info_snapshots>> for (bs1 = bdrv_first(&it1); bs1; bs1 = bdrv_next(&it1)) {
+ *   - block/snapshot.c|506| <<bdrv_all_get_snapshot_devices>> for (bs = bdrv_first(&it); bs; bs = bdrv_next(&it)) {
+ *   - migration/block.c|394| <<init_blk_migration>> for (bs = bdrv_first(&it); bs; bs = bdrv_next(&it)) {
+ *   - migration/block.c|399| <<init_blk_migration>> for (i = 0, bs = bdrv_first(&it); bs; bs = bdrv_next(&it), i++) {
+ *   - migration/migration-hmp-cmds.c|862| <<vm_completion>> for (bs = bdrv_first(&it); bs; bs = bdrv_next(&it)) {
+ */
 /* Iterates over all top-level BlockDriverStates, i.e. BDSs that are owned by
  * the monitor or attached to a BlockBackend */
 BlockDriverState *bdrv_next(BdrvNextIterator *it)
@@ -682,6 +851,14 @@ void bdrv_next_cleanup(BdrvNextIterator *it)
  * Returns true on success and false on failure. In the latter case, an Error
  * object is returned through @errp.
  */
+/*
+ * called by:
+ *   - blockdev.c|641| <<blockdev_init>> if (!monitor_add_blk(blk, id, errp)) {
+ *   - tests/unit/test-blockjob.c|84| <<create_blk>> monitor_add_blk(blk, name, &err);
+ *   - tests/unit/test-replication.c|192| <<start_primary>> monitor_add_blk(blk, P_ID, &error_abort);
+ *   - tests/unit/test-replication.c|307| <<start_secondary>> monitor_add_blk(blk, S_LOCAL_DISK_ID, &error_abort);
+ *   - tests/unit/test-replication.c|333| <<start_secondary>> monitor_add_blk(blk, S_ID, &error_abort)
+ */
 bool monitor_add_blk(BlockBackend *blk, const char *name, Error **errp)
 {
     assert(!blk->name);
@@ -704,6 +881,13 @@ bool monitor_add_blk(BlockBackend *blk, const char *name, Error **errp)
     }
 
     blk->name = g_strdup(name);
+    /*
+     * 在以下使用monitor_block_backends:
+     *   - block/block-backend.c|118| <<QTAILQ_HEAD>> static QTAILQ_HEAD(, BlockBackend) monitor_block_backends =
+     *   - block/block-backend.c|590| <<blk_next>> : QTAILQ_FIRST(&monitor_block_backends);
+     *   - block/block-backend.c|707| <<monitor_add_blk>> QTAILQ_INSERT_TAIL(&monitor_block_backends, blk, monitor_link);
+     *   - block/block-backend.c|723| <<monitor_remove_blk>> QTAILQ_REMOVE(&monitor_block_backends, blk, monitor_link);
+     */
     QTAILQ_INSERT_TAIL(&monitor_block_backends, blk, monitor_link);
     return true;
 }
@@ -720,6 +904,13 @@ void monitor_remove_blk(BlockBackend *blk)
         return;
     }
 
+    /*
+     * 在以下使用monitor_block_backends:
+     *   - block/block-backend.c|118| <<QTAILQ_HEAD>> static QTAILQ_HEAD(, BlockBackend) monitor_block_backends =
+     *   - block/block-backend.c|590| <<blk_next>> : QTAILQ_FIRST(&monitor_block_backends);
+     *   - block/block-backend.c|707| <<monitor_add_blk>> QTAILQ_INSERT_TAIL(&monitor_block_backends, blk, monitor_link);
+     *   - block/block-backend.c|723| <<monitor_remove_blk>> QTAILQ_REMOVE(&monitor_block_backends, blk, monitor_link);
+     */
     QTAILQ_REMOVE(&monitor_block_backends, blk, monitor_link);
     g_free(blk->name);
     blk->name = NULL;
@@ -770,6 +961,14 @@ static BlockBackend * GRAPH_RDLOCK bdrv_first_blk(BlockDriverState *bs)
     assert_bdrv_graph_readable();
 
     QLIST_FOREACH(child, &bs->parents, next_parent) {
+        /*
+	 * 在以下使用child_root:
+	 *   - block/block-backend.c|328| <<global>> static const BdrvChildClass child_root = {
+	 *   - block/block-backend.c|821| <<bdrv_first_blk>> if (child->klass == &child_root) {
+	 *   - block/block-backend.c|849| <<bdrv_is_root_node>> if (c->klass != &child_root) {
+	 *   - block/block-backend.c|964| <<blk_insert_bs>> blk->root = bdrv_root_attach_child(bs, "root", &child_root, BDRV_CHILD_FILTERED | BDRV_CHILD_PRIMARY,
+	 *                                                  blk->perm, blk->shared_perm, blk, errp);
+	 */
         if (child->klass == &child_root) {
             return child->opaque;
         }
@@ -798,6 +997,14 @@ bool bdrv_is_root_node(BlockDriverState *bs)
     assert_bdrv_graph_readable();
 
     QLIST_FOREACH(c, &bs->parents, next_parent) {
+        /*
+	 * 在以下使用child_root:
+	 *   - block/block-backend.c|328| <<global>> static const BdrvChildClass child_root = {
+	 *   - block/block-backend.c|821| <<bdrv_first_blk>> if (child->klass == &child_root) {
+	 *   - block/block-backend.c|849| <<bdrv_is_root_node>> if (c->klass != &child_root) {
+	 *   - block/block-backend.c|964| <<blk_insert_bs>> blk->root = bdrv_root_attach_child(bs, "root", &child_root, BDRV_CHILD_FILTERED | BDRV_CHILD_PRIMARY,
+	 *                                                  blk->perm, blk->shared_perm, blk, errp);
+	 */
         if (c->klass != &child_root) {
             return false;
         }
@@ -903,6 +1110,47 @@ void blk_remove_bs(BlockBackend *blk)
     bdrv_graph_wrunlock();
 }
 
+/*
+ * called by:
+ *   - block.c|4226| <<bdrv_open_inherit>> blk_insert_bs(file, file_bs, &local_err);
+ *   - block/block-backend.c|416| <<blk_new_with_bs>> if (blk_insert_bs(blk, bs, errp) < 0) {
+ *   - block/block-backend.c|482| <<blk_new_open>> blk_insert_bs(blk, bs, errp);
+ *   - block/commit.c|398| <<commit_start>> ret = blk_insert_bs(s->base, base, errp);
+ *   - block/commit.c|407| <<commit_start>> ret = blk_insert_bs(s->top, top, errp);
+ *   - block/commit.c|498| <<bdrv_commit>> ret = blk_insert_bs(src, bs, &local_err);
+ *   - block/commit.c|515| <<bdrv_commit>> ret = blk_insert_bs(backing, backing_file_bs, &local_err);
+ *   - block/export/export.c|162| <<blk_exp_add>> ret = blk_insert_bs(blk, bs, errp);
+ *   - block/mirror.c|1970| <<mirror_start_job>> ret = blk_insert_bs(s->target, target, errp);
+ *   - block/monitor/block-hmp-cmds.c|573| <<hmp_qemu_io>> ret = blk_insert_bs(blk, bs, &err);
+ *   - block/qapi-sysemu.c|254| <<qmp_blockdev_insert_anon_medium>> ret = blk_insert_bs(blk, bs, errp);
+ *   - hw/core/qdev-properties-system.c|150| <<set_drive_helper>> ret = blk_insert_bs(blk, bs, errp);
+ *   - migration/block.c|445| <<init_blk_migration>> ret = blk_insert_bs(bmds->blk, bs, &local_err);
+ *   - qemu-img.c|3720| <<img_rebase>> ret = blk_insert_bs(blk_old_backing, base_bs,
+ *   - qemu-img.c|3773| <<img_rebase>> ret = blk_insert_bs(blk_new_backing, prefix_chain_bs,
+ *   - qemu-nbd.c|1130| <<main>> blk_insert_bs(blk, bs, &error_fatal);
+ *   - tests/unit/test-bdrv-drain.c|193| <<test_setup>> blk_insert_bs(blk, bs, &error_abort);
+ *   - tests/unit/test-bdrv-drain.c|385| <<test_nested>> blk_insert_bs(blk, bs, &error_abort);
+ *   - tests/unit/test-bdrv-drain.c|435| <<test_graph_change_drain_all>> blk_insert_bs(blk_a, bs_a, &error_abort);
+ *   - tests/unit/test-bdrv-drain.c|451| <<test_graph_change_drain_all>> blk_insert_bs(blk_b, bs_b, &error_abort);
+ *   - tests/unit/test-bdrv-drain.c|550| <<test_iothread_common>> blk_insert_bs(blk, bs, &error_abort);
+ *   - tests/unit/test-bdrv-drain.c|740| <<test_blockjob_common_drain_node>> blk_insert_bs(blk_src, src_overlay, &error_abort);
+ *   - tests/unit/test-bdrv-drain.c|764| <<test_blockjob_common_drain_node>> blk_insert_bs(blk_target, target, &error_abort);
+ *   - tests/unit/test-bdrv-drain.c|1076| <<do_test_delete_by_drain>> blk_insert_bs(blk, bs, &error_abort);
+ *   - tests/unit/test-bdrv-drain.c|1248| <<test_detach_indirect>> blk_insert_bs(blk, parent_a, &error_abort);
+ *   - tests/unit/test-bdrv-drain.c|1353| <<test_append_to_drained>> blk_insert_bs(blk, base, &error_abort);
+ *   - tests/unit/test-bdrv-drain.c|1924| <<do_test_replace_child_mid_drain>> blk_insert_bs(parent_blk, parent_bs, &error_abort);
+ *   - tests/unit/test-bdrv-graph-mod.c|138| <<test_update_perm_tree>> blk_insert_bs(root, bs, &error_abort);
+ *   - tests/unit/test-bdrv-graph-mod.c|203| <<test_should_update_child>> blk_insert_bs(root, bs, &error_abort);
+ *   - tests/unit/test-block-iothread.c|479| <<test_sync_op>> blk_insert_bs(blk, bs, &error_abort);
+ *   - tests/unit/test-block-iothread.c|559| <<test_attach_blockjob>> blk_insert_bs(blk, bs, &error_abort);
+ *   - tests/unit/test-block-iothread.c|629| <<test_propagate_basic>> blk_insert_bs(blk, bs_a, &error_abort);
+ *   - tests/unit/test-block-iothread.c|715| <<test_propagate_diamond>> blk_insert_bs(blk, bs_verify, &error_abort);
+ *   - tests/unit/test-block-iothread.c|783| <<test_propagate_mirror>> blk_insert_bs(blk, src, &error_abort);
+ *   - tests/unit/test-block-iothread.c|823| <<test_attach_second_node>> blk_insert_bs(blk, bs, &error_abort);
+ *   - tests/unit/test-block-iothread.c|857| <<test_attach_preserve_blk_ctx>> blk_insert_bs(blk, bs, &error_abort);
+ *   - tests/unit/test-block-iothread.c|867| <<test_attach_preserve_blk_ctx>> blk_insert_bs(blk, bs, &error_abort);
+ *   - tests/unit/test-blockjob.c|79| <<create_blk>> blk_insert_bs(blk, bs, &error_abort);
+ */
 /*
  * Associates a new BlockDriverState with @blk.
  */
@@ -913,6 +1161,21 @@ int blk_insert_bs(BlockBackend *blk, BlockDriverState *bs, Error **errp)
     GLOBAL_STATE_CODE();
     bdrv_ref(bs);
     bdrv_graph_wrlock();
+    /*
+     * 在以下使用child_root:
+     *   - block/block-backend.c|328| <<global>> static const BdrvChildClass child_root = {
+     *   - block/block-backend.c|821| <<bdrv_first_blk>> if (child->klass == &child_root) {
+     *   - block/block-backend.c|849| <<bdrv_is_root_node>> if (c->klass != &child_root) {
+     *   - block/block-backend.c|964| <<blk_insert_bs>> blk->root = bdrv_root_attach_child(bs, "root", &child_root, BDRV_CHILD_FILTERED | BDRV_CHILD_PRIMARY,
+     *                                                  blk->perm, blk->shared_perm, blk, errp);
+     *
+     * BlockBackend *blk:
+     * -> BdrvChild *root;
+     *
+     * bs怎么来的??
+     *
+     * BDRV_CHILD_FILTERED | BDRV_CHILD_PRIMARY是BdrvChildRoleBits
+     */
     blk->root = bdrv_root_attach_child(bs, "root", &child_root,
                                        BDRV_CHILD_FILTERED | BDRV_CHILD_PRIMARY,
                                        blk->perm, blk->shared_perm,
@@ -983,6 +1246,15 @@ void blk_get_perm(BlockBackend *blk, uint64_t *perm, uint64_t *shared_perm)
  * Attach device model @dev to @blk.
  * Return 0 on success, -EBUSY when a device model is attached already.
  */
+/*
+ * called by:
+ *   - hw/block/fdc.c|497| <<floppy_drive_realize>> ret = blk_attach_dev(dev->conf.blk, qdev);
+ *   - hw/block/swim.c|206| <<swim_drive_realize>> ret = blk_attach_dev(dev->conf.blk, qdev);
+ *   - hw/block/xen-block.c|762| <<xen_cdrom_realize>> rc = blk_attach_dev(conf->blk, DEVICE(blockdev));
+ *   - hw/core/qdev-properties-system.c|161| <<set_drive_helper>> if (blk_attach_dev(blk, dev) < 0) {
+ *   - hw/ide/ide-dev.c|89| <<ide_dev_initfn>> ret = blk_attach_dev(dev->conf.blk, &dev->qdev);
+ *   - hw/scsi/scsi-disk.c|2570| <<scsi_cd_realize>> ret = blk_attach_dev(dev->conf.blk, &dev->qdev);
+ */
 int blk_attach_dev(BlockBackend *blk, DeviceState *dev)
 {
     GLOBAL_STATE_CODE();
@@ -1565,6 +1837,10 @@ static void blk_aio_complete_bh(void *opaque)
     blk_aio_complete(acb);
 }
 
+/*
+ * 比如cb是virtio_blk_rw_complete()
+ *     co_entry是blk_aio_write_entry()
+ */
 static BlockAIOCB *blk_aio_prwv(BlockBackend *blk, int64_t offset,
                                 int64_t bytes,
                                 void *iobuf, CoroutineEntry co_entry,
@@ -1610,6 +1886,11 @@ static void coroutine_fn blk_aio_read_entry(void *opaque)
     blk_aio_complete(acb);
 }
 
+/*
+ * 在以下使用blk_aio_write_entry():
+ *   - block/block-backend.c|1630| <<blk_aio_pwrite_zeroes>> return blk_aio_prwv(blk, offset, bytes, NULL, blk_aio_write_entry, flags | BDRV_REQ_ZERO_WRITE, cb, opaque);
+ *   - block/block-backend.c|1712| <<blk_aio_pwritev>> return blk_aio_prwv(blk, offset, qiov->size, qiov, blk_aio_write_entry, flags, cb, opaque);
+ */
 static void coroutine_fn blk_aio_write_entry(void *opaque)
 {
     BlkAioEmAIOCB *acb = opaque;
@@ -1622,6 +1903,19 @@ static void coroutine_fn blk_aio_write_entry(void *opaque)
     blk_aio_complete(acb);
 }
 
+/*
+ * 在以下使用blk_aio_pwrite_zeroes():
+ *   - hw/block/virtio-blk.c|568| <<virtio_blk_handle_discard_write_zeroes>> blk_aio_pwrite_zeroes(s->blk, sector << BDRV_SECTOR_BITS, bytes, blk_aio_flags, virtio_blk_discard_write_zeroes_complete, req);
+ *   - hw/nvme/ctrl.c|2192| <<nvme_rw_cb>> req->aiocb = blk_aio_pwrite_zeroes(blk, offset, mlen, BDRV_REQ_MAY_UNMAP, nvme_rw_complete_cb, req);
+ *   - hw/nvme/ctrl.c|2539| <<nvme_dsm_md_cb>> iocb->aiocb = blk_aio_pwrite_zeroes(ns->blkconf.blk, nvme_moff(ns, slba), nvme_m2b(ns, nlb), BDRV_REQ_MAY_UNMAP, nvme_dsm_cb, iocb);
+ *   - hw/nvme/ctrl.c|3637| <<nvme_do_write>> req->aiocb = blk_aio_pwrite_zeroes(blk, data_offset, data_size, BDRV_REQ_MAY_UNMAP, nvme_rw_cb, req);
+ *   - hw/nvme/ctrl.c|3911| <<nvme_zone_reset_epilogue_cb>> iocb->aiocb = blk_aio_pwrite_zeroes(ns->blkconf.blk, moff, count, BDRV_REQ_MAY_UNMAP, nvme_zone_reset_cb, iocb);
+ *   - hw/nvme/ctrl.c|3965| <<nvme_zone_reset_cb>> iocb->aiocb = blk_aio_pwrite_zeroes(ns->blkconf.blk, nvme_l2b(ns, zone->d.zslba), nvme_l2b(ns, ns->zone_size), BDRV_REQ_MAY_UNMAP, nvme_zone_reset_epilogue_cb, iocb);
+ *   - hw/nvme/ctrl.c|6523| <<nvme_format_ns_cb>> iocb->aiocb = blk_aio_pwrite_zeroes(ns->blkconf.blk, iocb->offset, bytes, BDRV_REQ_MAY_UNMAP, nvme_format_ns_cb, iocb);
+ *   - hw/nvme/dif.c|632| <<nvme_dif_rw>> req->aiocb = blk_aio_pwrite_zeroes(blk, offset, len, flags, nvme_dif_rw_mdata_out_cb, ctx);
+ *   - hw/scsi/scsi-disk.c|1889| <<scsi_disk_emulate_write_same>> r->req.aiocb = blk_aio_pwrite_zeroes(s->qdev.conf.blk, r->req.cmd.lba * s->qdev.blocksize, nb_sectors * s->qdev.blocksize, flags, scsi_aio_complete, r);
+ *   - qemu-io-cmds.c|1683| <<aio_write_f>> blk_aio_pwrite_zeroes(blk, ctx->offset, count, ctx->flags, aio_write_done, ctx);
+ */
 BlockAIOCB *blk_aio_pwrite_zeroes(BlockBackend *blk, int64_t offset,
                                   int64_t bytes, BdrvRequestFlags flags,
                                   BlockCompletionFunc *cb, void *opaque)
@@ -1692,6 +1986,33 @@ void coroutine_mixed_fn blk_get_geometry(BlockBackend *blk,
     *nb_sectors_ptr = ret < 0 ? 0 : ret;
 }
 
+/*
+ * called by:
+ *   - hw/block/dataplane/xen-block.c|378| <<xen_block_do_aio>> blk_aio_preadv(dataplane->blk, request->start, &request->v, 0,
+ *   - hw/block/virtio-blk.c|463| <<submit_requests>> blk_aio_preadv(blk, sector_num << BDRV_SECTOR_BITS, qiov,
+ *   - hw/ide/core.c|715| <<ide_buffered_readv>> aioreq = blk_aio_preadv(s->blk, sector_num << BDRV_SECTOR_BITS,
+ *   - hw/nvme/ctrl.c|1452| <<nvme_blk_read>> req->aiocb = blk_aio_preadv(blk, offset, &req->sg.iov, 0, cb, req);
+ *   - hw/nvme/ctrl.c|2298| <<nvme_verify_mdata_in_cb>> req->aiocb = blk_aio_preadv(blk, offset, &ctx->mdata.iov, 0,
+ *   - hw/nvme/ctrl.c|2454| <<nvme_compare_data_cb>> req->aiocb = blk_aio_preadv(blk, offset, &ctx->mdata.iov, 0,
+ *   - hw/nvme/ctrl.c|2690| <<nvme_verify>> req->aiocb = blk_aio_preadv(ns->blkconf.blk, offset, &ctx->data.iov, 0,
+ *   - hw/nvme/ctrl.c|3042| <<nvme_copy_in_cb>> iocb->aiocb = blk_aio_preadv(ns->blkconf.blk, nvme_moff(ns, slba),
+ *   - hw/nvme/ctrl.c|3101| <<nvme_do_copy>> iocb->aiocb = blk_aio_preadv(ns->blkconf.blk, nvme_l2b(ns, slba),
+ *   - hw/nvme/ctrl.c|3268| <<nvme_compare>> req->aiocb = blk_aio_preadv(blk, offset, &ctx->data.iov, 0,
+ *   - hw/nvme/dif.c|506| <<nvme_dif_rw_mdata_in_cb>> req->aiocb = blk_aio_preadv(blk, offset, &ctx->mdata.iov, 0,
+ *   - hw/nvme/dif.c|655| <<nvme_dif_rw>> req->aiocb = blk_aio_preadv(ns->blkconf.blk, offset, &ctx->data.iov, 0,
+ *   - hw/scsi/scsi-disk.c|3079| <<scsi_dma_readv>> return blk_aio_preadv(s->qdev.conf.blk, offset, iov, 0, cb, cb_opaque);
+ *   - migration/block.c|322| <<mig_save_device_bulk>> blk->aiocb = blk_aio_preadv(bb, cur_sector * BDRV_SECTOR_SIZE, &blk->qiov,
+ *   - migration/block.c|553| <<mig_save_device_dirty>> blk->aiocb = blk_aio_preadv(bmds->blk,
+ *   - qemu-img.c|4495| <<bench_cb>> acb = blk_aio_preadv(b->blk, offset, b->qiov, 0, bench_cb, b);
+ *   - qemu-io-cmds.c|649| <<do_aio_readv>> blk_aio_preadv(blk, offset, qiov, flags, aio_rw_done, &async_ret);
+ *   - qemu-io-cmds.c|1543| <<aio_read_f>> blk_aio_preadv(blk, ctx->offset, &ctx->qiov, ctx->flags, aio_read_done,
+ *   - system/dma-helpers.c|247| <<dma_blk_read_io_func>> return blk_aio_preadv(blk, offset, iov, 0, cb, cb_opaque);
+ *   - tests/unit/test-bdrv-drain.c|245| <<test_drv_cb_common>> acb = blk_aio_preadv(blk, 0, &qiov, 0, aio_ret_cb, &aio_ret);
+ *   - tests/unit/test-bdrv-drain.c|561| <<test_iothread_common>> acb = blk_aio_preadv(blk, 0, &qiov, 0, test_iothread_aio_cb, &aio_ret);
+ *   - tests/unit/test-bdrv-drain.c|563| <<test_iothread_common>> acb = blk_aio_preadv(blk, 0, &qiov, 0, aio_ret_cb, &aio_ret);
+ *   - tests/unit/test-bdrv-drain.c|1291| <<test_detach_indirect>> acb = blk_aio_preadv(blk, 0, &qiov, 0, detach_by_parent_aio_cb, NULL);
+ *   - tests/unit/test-replication.c|76| <<test_blk_read>> blk_aio_preadv(blk, offset, &qiov, 0, blk_rw_done, &async_ret);
+ */
 BlockAIOCB *blk_aio_preadv(BlockBackend *blk, int64_t offset,
                            QEMUIOVector *qiov, BdrvRequestFlags flags,
                            BlockCompletionFunc *cb, void *opaque)
@@ -1702,6 +2023,27 @@ BlockAIOCB *blk_aio_preadv(BlockBackend *blk, int64_t offset,
                         blk_aio_read_entry, flags, cb, opaque);
 }
 
+/*
+ * called by:
+ *   - hw/block/dataplane/xen-block.c|393| <<xen_block_do_aio>> blk_aio_pwritev(dataplane->blk, request->start, &request->v, 0, xen_block_complete_aio, request);
+ *   - hw/block/m25p80.c|564| <<flash_sync_page>> blk_aio_pwritev(s->blk, page * s->pi->page_size, iov, 0, blk_sync_complete, iov);
+ *   - hw/block/m25p80.c|580| <<flash_sync_area>> blk_aio_pwritev(s->blk, off, iov, 0, blk_sync_complete, iov);
+ *   - hw/block/virtio-blk.c|399| <<submit_requests>> blk_aio_pwritev(blk, sector_num << BDRV_SECTOR_BITS, qiov, flags, virtio_blk_rw_complete, mrb->reqs[start]);
+ *   - hw/ide/core.c|1101| <<ide_sector_write>> s->pio_aiocb = blk_aio_pwritev(s->blk, sector_num << BDRV_SECTOR_BITS, &s->qiov, 0, ide_sector_write_cb, s);
+ *   - hw/nvme/ctrl.c|1465| <<nvme_blk_write>> req->aiocb = blk_aio_pwritev(blk, offset, &req->sg.iov, 0, cb, req);
+ *   - hw/nvme/ctrl.c|2917| <<nvme_copy_out_cb>> iocb->aiocb = blk_aio_pwritev(ns->blkconf.blk, nvme_moff(ns, iocb->slba), &iocb->iov, 0, nvme_copy_out_completed_cb, iocb);
+ *   - hw/nvme/ctrl.c|3011| <<nvme_copy_in_completed_cb>> iocb->aiocb = blk_aio_pwritev(ns->blkconf.blk, nvme_l2b(ns, iocb->slba), &iocb->iov, 0, nvme_copy_out_cb, iocb);
+ *   - hw/nvme/dif.c|530| <<nvme_dif_rw_mdata_out_cb>> req->aiocb = blk_aio_pwritev(blk, offset, &ctx->mdata.iov, 0, nvme_dif_rw_cb, ctx);
+ *   - hw/nvme/dif.c|701| <<nvme_dif_rw>> req->aiocb = blk_aio_pwritev(ns->blkconf.blk, offset, &ctx->data.iov, 0, nvme_dif_rw_mdata_out_cb, ctx);
+ *   - hw/scsi/scsi-disk.c|1842| <<scsi_write_same_complete>> r->req.aiocb = blk_aio_pwritev(s->qdev.conf.blk, data->sector << BDRV_SECTOR_BITS, &data->qiov, 0, scsi_write_same_complete, data);
+ *   - hw/scsi/scsi-disk.c|1914| <<scsi_disk_emulate_write_same>> r->req.aiocb = blk_aio_pwritev(s->qdev.conf.blk, data->sector << BDRV_SECTOR_BITS, &data->qiov, 0, scsi_write_same_complete, data);
+ *   - hw/scsi/scsi-disk.c|3089| <<scsi_dma_writev>> return blk_aio_pwritev(s->qdev.conf.blk, offset, iov, 0, cb, cb_opaque);
+ *   - qemu-img.c|4493| <<bench_cb>> acb = blk_aio_pwritev(b->blk, offset, b->qiov, 0, bench_cb, b);
+ *   - qemu-io-cmds.c|663| <<do_aio_writev>> blk_aio_pwritev(blk, offset, qiov, flags, aio_rw_done, &async_ret);
+ *   - qemu-io-cmds.c|1699| <<aio_write_f>> blk_aio_pwritev(blk, ctx->offset, &ctx->qiov, ctx->flags, aio_write_done, ctx);
+ *   - system/dma-helpers.c|265| <<dma_blk_write_io_func>> return blk_aio_pwritev(blk, offset, iov, 0, cb, cb_opaque);
+ *   - tests/unit/test-replication.c|113| <<test_blk_write>> blk_aio_pwritev(blk, offset, &qiov, 0, blk_rw_done, &async_ret);
+ */
 BlockAIOCB *blk_aio_pwritev(BlockBackend *blk, int64_t offset,
                             QEMUIOVector *qiov, BdrvRequestFlags flags,
                             BlockCompletionFunc *cb, void *opaque)
@@ -2425,6 +2767,10 @@ AioContext *blk_get_aio_context(BlockBackend *blk)
         return qemu_get_aio_context();
     }
 
+    /*
+     * BlockBackend *blk:
+     * -> AioContext *ctx;
+     */
     return qatomic_read(&blk->ctx);
 }
 
diff --git a/block/dirty-bitmap.c b/block/dirty-bitmap.c
index 13a197975..67de24b55 100644
--- a/block/dirty-bitmap.c
+++ b/block/dirty-bitmap.c
@@ -495,6 +495,11 @@ bool bdrv_dirty_bitmap_get(BdrvDirtyBitmap *bitmap, int64_t offset)
  * but clamped between [4K, 64K]. Defaults to 64K in the case that there
  * is no cluster size information available.
  */
+/*
+ * called by:
+ *   - block/mirror.c|1849| <<mirror_start_job>> granularity = bdrv_get_default_bitmap_granularity(target);
+ *   - block/monitor/bitmap-qmp-cmds.c|117| <<qmp_block_dirty_bitmap_add>> granularity = bdrv_get_default_bitmap_granularity(bs);
+ */
 uint32_t bdrv_get_default_bitmap_granularity(BlockDriverState *bs)
 {
     BlockDriverInfo bdi;
diff --git a/block/file-posix.c b/block/file-posix.c
index 35684f7e2..68ef7dc3c 100644
--- a/block/file-posix.c
+++ b/block/file-posix.c
@@ -131,7 +131,25 @@
 
 /* Posix file locking bytes. Libvirt takes byte 0, we start from higher bytes,
  * leaving a few more bytes for its future use. */
+/*
+ * 在以下使用RAW_LOCK_PERM_BASE:
+ *   - block/file-posix.c|139| <<global>> #define RAW_LOCK_PERM_BASE 100
+ *   - block/file-posix.c|878| <<raw_apply_lock_bytes>> int off = RAW_LOCK_PERM_BASE + i;
+ *   - block/file-posix.c|949| <<raw_check_lock_bytes>> int off = RAW_LOCK_PERM_BASE + i;
+ *
+ * Posix file locking bytes. Libvirt takes byte 0, we start from higher bytes,
+ * leaving a few more bytes for its future use.
+ */
 #define RAW_LOCK_PERM_BASE             100
+/*
+ * 在以下使用RAW_LOCK_SHARED_BASE:
+ *   - block/file-posix.c|135| <<global>> #define RAW_LOCK_SHARED_BASE 200
+ *   - block/file-posix.c|900| <<raw_apply_lock_bytes>> int off = RAW_LOCK_SHARED_BASE + i;
+ *   - block/file-posix.c|933| <<raw_check_lock_bytes>> int off = RAW_LOCK_SHARED_BASE + i;
+ *
+ * Posix file locking bytes. Libvirt takes byte 0, we start from higher bytes,
+ * leaving a few more bytes for its future use.
+ */
 #define RAW_LOCK_SHARED_BASE           200
 
 typedef struct BDRVRawState {
@@ -826,6 +844,20 @@ static int raw_open(BlockDriverState *bs, QDict *options, int flags,
     return raw_open_common(bs, options, flags, 0, false, errp);
 }
 
+/*
+ * 在以下使用RAW_PL_PREPARE:
+ *   - block/file-posix.c|1048| <<raw_handle_perm_lock>> case RAW_PL_PREPARE:
+ *   - block/file-posix.c|3931| <<raw_check_perm>> ret = raw_handle_perm_lock(bs, RAW_PL_PREPARE, perm, shared, errp);
+ *
+ * 在以下使用RAW_PL_ABORT:
+ *   - block/file-posix.c|1074| <<raw_handle_perm_lock>> case RAW_PL_ABORT:
+ *   - block/file-posix.c|3941| <<raw_check_perm>> raw_handle_perm_lock(bs, RAW_PL_ABORT, 0, 0, NULL);
+ *   - block/file-posix.c|3984| <<raw_abort_perm_update>> raw_handle_perm_lock(bs, RAW_PL_ABORT, 0, 0, NULL);
+ *
+ * 在以下使用RAW_PL_COMMIT:
+ *   - block/file-posix.c|1084| <<raw_handle_perm_lock>> case RAW_PL_COMMIT:
+ *   - block/file-posix.c|3968| <<raw_set_perm>> raw_handle_perm_lock(bs, RAW_PL_COMMIT, perm, shared, NULL);
+ */
 typedef enum {
     RAW_PL_PREPARE,
     RAW_PL_COMMIT,
@@ -839,6 +871,16 @@ typedef enum {
  * file; if @unlock == true, also unlock the unneeded bytes.
  * @shared_perm_lock_bits is the mask of all permissions that are NOT shared.
  */
+/*
+ * called by:
+ *   - block/file-posix.c|1020| <<raw_handle_perm_lock(RAW_PL_PREPARE)>> ret = raw_apply_lock_bytes(s, s->fd, s->perm | new_perm,
+ *                                                       ~s->shared_perm | ~new_shared, false, errp);
+ *   - block/file-posix.c|1034| <<raw_handle_perm_lock(RAW_PL_ABORT)>> raw_apply_lock_bytes(s, s->fd, s->perm, ~s->shared_perm, true, &local_err);
+ *   - block/file-posix.c|1044| <<raw_handle_perm_lock(RAW_PL_COMMIT)>> raw_apply_lock_bytes(s, s->fd, new_perm, ~new_shared, true, &local_err);
+ *   - block/file-posix.c|2963| <<raw_co_create>> result = raw_apply_lock_bytes(NULL, fd, perm, ~shared, false, errp);
+ *   - block/file-posix.c|3028| <<raw_co_create>> raw_apply_lock_bytes(NULL, fd, 0, 0, true, &local_err);
+ *   - block/file-posix.c|3886| <<raw_check_perm>> ret = raw_apply_lock_bytes(NULL, s->perm_change_fd, perm, ~shared, false, errp);
+ */
 static int raw_apply_lock_bytes(BDRVRawState *s, int fd,
                                 uint64_t perm_lock_bits,
                                 uint64_t shared_perm_lock_bits,
@@ -865,9 +907,42 @@ static int raw_apply_lock_bytes(BDRVRawState *s, int fd,
         }
     }
 
+    /*
+     * BLK_PERM_CONSISTENT_READ    = 0x01,
+     * BLK_PERM_WRITE              = 0x02,
+     * BLK_PERM_WRITE_UNCHANGED    = 0x04,
+     * BLK_PERM_RESIZE             = 0x08,
+     * BLK_PERM_ALL                = 0x0f,
+     * #define PERM_FOREACH(i) \
+     *     for ((i) = 0; (1ULL << (i)) <= BLK_PERM_ALL; i++)
+     */
     PERM_FOREACH(i) {
+        /*
+	 * 在以下使用RAW_LOCK_PERM_BASE:
+	 *   - block/file-posix.c|139| <<global>> #define RAW_LOCK_PERM_BASE 100
+	 *   - block/file-posix.c|878| <<raw_apply_lock_bytes>> int off = RAW_LOCK_PERM_BASE + i;
+	 *   - block/file-posix.c|949| <<raw_check_lock_bytes>> int off = RAW_LOCK_PERM_BASE + i;
+	 *
+	 * Posix file locking bytes. Libvirt takes byte 0, we start from higher bytes,
+	 * leaving a few more bytes for its future use.
+	 */
         int off = RAW_LOCK_PERM_BASE + i;
         uint64_t bit = (1ULL << i);
+        /*
+	 * BLK_PERM_CONSISTENT_READ    = 0x01,
+	 * BLK_PERM_WRITE              = 0x02,
+	 * BLK_PERM_WRITE_UNCHANGED    = 0x04,
+	 * BLK_PERM_RESIZE             = 0x08,
+	 * BLK_PERM_ALL                = 0x0f,
+	 * #define PERM_FOREACH(i) \
+	 *     for ((i) = 0; (1ULL << (i)) <= BLK_PERM_ALL; i++)
+	 *
+	 * 一个例子:
+	 * perm_lock_bits来自参数
+	 * locked_perm来自BDRVRawState->locked_perm
+	 *
+	 * 参数里有, 但是existing的没有...
+	 */
         if ((perm_lock_bits & bit) && !(locked_perm & bit)) {
             ret = qemu_lock_fd(fd, off, 1, false);
             if (ret) {
@@ -955,6 +1030,37 @@ static int raw_check_lock_bytes(int fd, uint64_t perm, uint64_t shared_perm,
     return 0;
 }
 
+/*
+ * [0] qemu_lock_fd
+ * [0] raw_handle_perm_lock
+ * [0] raw_check_perm
+ * [0] bdrv_drv_set_perm
+ * [0] bdrv_node_refresh_perm
+ * [0] bdrv_list_refresh_perms
+ * [0] bdrv_replace_node_common
+ * [0] mirror_start_job
+ * [0] commit_active_start
+ * [0] qmp_block_commit
+ * [0] qmp_marshal_block_commit
+ * [0] do_qmp_dispatch_bh
+ * [0] aio_bh_poll
+ * [0] aio_dispatch
+ * [0] aio_ctx_dispatch
+ * [0] g_main_context_dispatch
+ * [0] glib_pollfds_poll
+ * [0] os_host_main_loop_wait
+ * [0] main_loop_wait
+ * [0] qemu_main_loop
+ * [0] qemu_default_main
+ * [0] __libc_start_main
+ * [0] _start
+ *
+ * called by:
+ *   - block/file-posix.c|3820| <<raw_check_perm>> ret = raw_handle_perm_lock(bs, RAW_PL_PREPARE, perm, shared, errp);
+ *   - block/file-posix.c|3830| <<raw_check_perm>> raw_handle_perm_lock(bs, RAW_PL_ABORT, 0, 0, NULL);
+ *   - block/file-posix.c|3857| <<raw_set_perm>> raw_handle_perm_lock(bs, RAW_PL_COMMIT, perm, shared, NULL);
+ *   - block/file-posix.c|3873| <<raw_abort_perm_update>> raw_handle_perm_lock(bs, RAW_PL_ABORT, 0, 0, NULL);
+ */
 static int raw_handle_perm_lock(BlockDriverState *bs,
                                 RawPermLockOp op,
                                 uint64_t new_perm, uint64_t new_shared,
@@ -1038,6 +1144,10 @@ static int fcntl_setfl(int fd, int flag)
     return 0;
 }
 
+/*
+ * called by:
+ *   - block/file-posix.c|3897| <<raw_check_perm>> ret = raw_reconfigure_getfd(bs, input_flags, &open_flags, perm, false, errp);
+ */
 static int raw_reconfigure_getfd(BlockDriverState *bs, int flags,
                                  int *open_flags, uint64_t perm, bool force_dup,
                                  Error **errp)
@@ -2404,6 +2514,18 @@ out:
     return result;
 }
 
+/*
+ * called by:
+ *   - block/file-posix.c|2533| <<raw_co_prw>> ret = raw_thread_pool_submit(handle_aiocb_rw, &acb);
+ *   - block/file-posix.c|2603| <<raw_co_flush_to_disk>> return raw_thread_pool_submit(handle_aiocb_flush, &acb);
+ *   - block/file-posix.c|2642| <<raw_regular_truncate>> return raw_thread_pool_submit(handle_aiocb_truncate, &acb);
+ *   - block/file-posix.c|3400| <<raw_co_zone_report>> return raw_thread_pool_submit(handle_aiocb_zone_report, &acb);
+ *   - block/file-posix.c|3477| <<raw_co_zone_mgmt>> ret = raw_thread_pool_submit(handle_aiocb_zone_mgmt, &acb);
+ *   - block/file-posix.c|3559| <<raw_do_pdiscard>> ret = raw_thread_pool_submit(handle_aiocb_discard, &acb);
+ *   - block/file-posix.c|3665| <<raw_do_pwrite_zeroes>> return raw_thread_pool_submit(handler, &acb);
+ *   - block/file-posix.c|3906| <<raw_co_copy_range_to>> return raw_thread_pool_submit(handle_aiocb_copy_range, &acb);
+ *   - block/file-posix.c|4249| <<hdev_co_ioctl>> return raw_thread_pool_submit(handle_aiocb_ioctl, &acb);
+ */
 static int coroutine_fn raw_thread_pool_submit(ThreadPoolFunc func, void *arg)
 {
     return thread_pool_submit_co(func, arg);
@@ -2473,6 +2595,12 @@ static inline bool raw_check_linux_aio(BDRVRawState *s)
 }
 #endif
 
+/*
+ * called by:
+ *   - block/file-posix.c|2693| <<raw_co_preadv>> return raw_co_prw(bs, &offset, bytes, qiov, QEMU_AIO_READ);
+ *   - block/file-posix.c|2700| <<raw_co_pwritev>> return raw_co_prw(bs, &offset, bytes, qiov, QEMU_AIO_WRITE);
+ *   - block/file-posix.c|3657| <<raw_co_zone_append>> return raw_co_prw(bs, offset, len, qiov, QEMU_AIO_ZONE_APPEND);
+ */
 static int coroutine_fn raw_co_prw(BlockDriverState *bs, int64_t *offset_ptr,
                                    uint64_t bytes, QEMUIOVector *qiov, int type)
 {
@@ -2530,6 +2658,18 @@ static int coroutine_fn raw_co_prw(BlockDriverState *bs, int64_t *offset_ptr,
     };
 
     assert(qiov->size == bytes);
+    /*
+     * called by:
+     *   - block/file-posix.c|2533| <<raw_co_prw>> ret = raw_thread_pool_submit(handle_aiocb_rw, &acb);
+     *   - block/file-posix.c|2603| <<raw_co_flush_to_disk>> return raw_thread_pool_submit(handle_aiocb_flush, &acb);
+     *   - block/file-posix.c|2642| <<raw_regular_truncate>> return raw_thread_pool_submit(handle_aiocb_truncate, &acb);
+     *   - block/file-posix.c|3400| <<raw_co_zone_report>> return raw_thread_pool_submit(handle_aiocb_zone_report, &acb);
+     *   - block/file-posix.c|3477| <<raw_co_zone_mgmt>> ret = raw_thread_pool_submit(handle_aiocb_zone_mgmt, &acb);
+     *   - block/file-posix.c|3559| <<raw_do_pdiscard>> ret = raw_thread_pool_submit(handle_aiocb_discard, &acb);
+     *   - block/file-posix.c|3665| <<raw_do_pwrite_zeroes>> return raw_thread_pool_submit(handler, &acb);
+     *   - block/file-posix.c|3906| <<raw_co_copy_range_to>> return raw_thread_pool_submit(handle_aiocb_copy_range, &acb);
+     *   - block/file-posix.c|4249| <<hdev_co_ioctl>> return raw_thread_pool_submit(handle_aiocb_ioctl, &acb);
+     */
     ret = raw_thread_pool_submit(handle_aiocb_rw, &acb);
     goto out; /* Avoid the compiler err of unused label */
 
@@ -2564,6 +2704,26 @@ out:
     return ret;
 }
 
+/*
+ * #0来自file-posix.c
+ * #5来自raw-format.c
+ * (gdb) bt
+ * #0  raw_co_preadv (bs=0x555557401530, offset=0, bytes=512, qiov=0x7fffe00032b8, flags=BDRV_REQ_REGISTERED_BUF) at ../block/file-posix.c:2571
+ * #1  0x0000555555f35a50 in bdrv_driver_preadv (bs=0x555557401530, offset=0, bytes=512, qiov=0x7fffe00032b8, qiov_offset=0, flags=8) at ../block/io.c:1002
+ * #2  0x0000555555f36d3e in bdrv_aligned_preadv (child=0x55555740e110, req=0x7ffda6e6ea50, offset=0, bytes=512, align=512, qiov=0x7fffe00032b8, qiov_offset=0, flags=8) at ../block/io.c:1395
+ * #3  0x0000555555f37cf5 in bdrv_co_preadv_part (child=0x55555740e110, offset=0, bytes=512, qiov=0x7fffe00032b8, qiov_offset=0, flags=BDRV_REQ_REGISTERED_BUF) at ../block/io.c:1819
+ * #4  0x0000555555f37a85 in bdrv_co_preadv (child=0x55555740e110, offset=0, bytes=512, qiov=0x7fffe00032b8, flags=BDRV_REQ_REGISTERED_BUF) at ../block/io.c:1768
+ * #5  0x0000555555f7f3ac in raw_co_preadv (bs=0x555557407880, offset=0, bytes=512, qiov=0x7fffe00032b8, flags=BDRV_REQ_REGISTERED_BUF) at ../block/raw-format.c:221
+ * #6  0x0000555555f35a50 in bdrv_driver_preadv (bs=0x555557407880, offset=0, bytes=512, qiov=0x7fffe00032b8, qiov_offset=0, flags=8) at ../block/io.c:1002
+ * #7  0x0000555555f36d3e in bdrv_aligned_preadv (child=0x555558069da0, req=0x7ffda6e6eda0, offset=0, bytes=512, align=1, qiov=0x7fffe00032b8, qiov_offset=0, flags=8) at ../block/io.c:1395
+ * #8  0x0000555555f37cf5 in bdrv_co_preadv_part (child=0x555558069da0, offset=0, bytes=512, qiov=0x7fffe00032b8, qiov_offset=0, flags=BDRV_REQ_REGISTERED_BUF) at ../block/io.c:1819
+ * #9  0x0000555555f217fc in blk_co_do_preadv_part (blk=0x5555580ed980, offset=0, bytes=512, qiov=0x7fffe00032b8, qiov_offset=0, flags=BDRV_REQ_REGISTERED_BUF) at ../block/block-backend.c:1347
+ * #10 0x0000555555f22223 in blk_aio_read_entry (opaque=0x7fffe0003360) at ../block/block-backend.c:1608
+ * #11 0x00005555560d8120 in coroutine_trampoline (i0=-536857664, i1=32767) at ../util/coroutine-ucontext.c:175
+ * #12 0x00007ffff4ee1150 in __start_context () at /lib/../lib64/libc.so.6
+ * #13 0x00007fffef4539e0 in  ()
+ * #14 0x0000000000000000 in  ()
+ */
 static int coroutine_fn raw_co_preadv(BlockDriverState *bs, int64_t offset,
                                       int64_t bytes, QEMUIOVector *qiov,
                                       BdrvRequestFlags flags)
@@ -3567,6 +3727,37 @@ raw_co_pdiscard(BlockDriverState *bs, int64_t offset, int64_t bytes)
     return raw_do_pdiscard(bs, offset, bytes, false);
 }
 
+/*
+ * (gdb) bt
+ * #0  bdrv_co_get_self_request (bs=0x629000005200) at ../block/io.c:720
+ * #1  0x00005555570f6929 in raw_do_pwrite_zeroes (bs=0x629000005200, offset=458752, bytes=65536, flags=BDRV_REQ_NO_FALLBACK, blkdev=false) at ../block/file-posix.c:3598
+ * #2  0x00005555570f6f1d in raw_co_pwrite_zeroes (bs=0x629000005200, offset=458752, bytes=65536, flags=BDRV_REQ_NO_FALLBACK) at ../block/file-posix.c:3641
+ * #3  0x0000555556fb193d in bdrv_co_do_pwrite_zeroes (bs=0x629000005200, offset=458752, bytes=65536, flags=258) at ../block/io.c:1901
+ * #4  0x0000555556fb2b50 in bdrv_aligned_pwritev (child=0x608000002920, req=0x7ffd14df80d0, offset=458752, bytes=65536, align=512, qiov=0x0, qiov_offset=0, flags=258) at ../block/io.c:2100
+ * #5  0x0000555556fb33a7 in bdrv_co_do_zero_pwritev (child=0x608000002920, offset=458752, bytes=65536, flags=258, req=0x7ffd14df80d0) at ../block/io.c:2183
+ * #6  0x0000555556fb3c43 in bdrv_co_pwritev_part (child=0x608000002920, offset=458752, bytes=65536, qiov=0x0, qiov_offset=0, flags=258) at ../block/io.c:2283
+ * #7  0x0000555556fb362c in bdrv_co_pwritev (child=0x608000002920, offset=458752, bytes=65536, qiov=0x0, flags=258) at ../block/io.c:2216
+ * #8  0x0000555556fb3f19 in bdrv_co_pwrite_zeroes (child=0x608000002920, offset=458752, bytes=65536, flags=BDRV_REQ_NO_FALLBACK) at ../block/io.c:2322
+ * #9  0x0000555556ffae77 in handle_alloc_space (bs=0x62900000a200, l2meta=0x60b0011bb730) at ../block/qcow2.c:2557
+ * #10 0x0000555556ffb3de in qcow2_co_pwritev_task (bs=0x62900000a200, host_offset=458752, offset=131072, bytes=8192, qiov=0x61200532c758, qiov_offset=0, l2meta=0x60b0011bb730) at ../block/qcow2.c:2609
+ * #11 0x0000555556ffb828 in qcow2_co_pwritev_task_entry (task=0x7ffd14c07320) at ../block/qcow2.c:2657
+ * #12 0x0000555556ff97cd in qcow2_add_task
+ *     (bs=0x62900000a200, pool=0x0, func=0x555556ffb653 <qcow2_co_pwritev_task_entry>, subcluster_type=QCOW2_SUBCLUSTER_UNALLOCATED_PLAIN, host_offset=458752, offset=131072, bytes=8192, qiov=0x61200532c758, qiov_offset=0, l2meta=0x60b0011bb730) at ../block/qcow2.c:2307
+ * #13 0x0000555556ffbd90 in qcow2_co_pwritev_part (bs=0x62900000a200, offset=131072, bytes=8192, qiov=0x61200532c758, qiov_offset=0, flags=BDRV_REQ_REGISTERED_BUF) at ../block/qcow2.c:2709
+ * #14 0x0000555556face86 in bdrv_driver_pwritev (bs=0x62900000a200, offset=131072, bytes=8192, qiov=0x61200532c758, qiov_offset=0, flags=BDRV_REQ_REGISTERED_BUF) at ../block/io.c:1070
+ * #15 0x0000555556fb2bcb in bdrv_aligned_pwritev (child=0x608000002e20, req=0x7ffd14df7cd0, offset=131072, bytes=8192, align=1, qiov=0x61200532c758, qiov_offset=0, flags=BDRV_REQ_REGISTERED_BUF) at ../block/io.c:2106
+ * #16 0x0000555556fb3d48 in bdrv_co_pwritev_part (child=0x608000002e20, offset=131072, bytes=8192, qiov=0x61200532c758, qiov_offset=0, flags=BDRV_REQ_REGISTERED_BUF) at ../block/io.c:2299
+ * #17 0x0000555556f7f9bd in blk_co_do_pwritev_part (blk=0x6190000d8e80, offset=131072, bytes=8192, qiov=0x61200532c758, qiov_offset=0, flags=BDRV_REQ_REGISTERED_BUF) at ../block/block-backend.c:1425
+ * #18 0x0000555556f80d1d in blk_aio_write_entry (opaque=0x6080016c0920) at ../block/block-backend.c:1620
+ * #19 0x000055555734236e in coroutine_trampoline (i0=87277888, i1=24864) at ../util/coroutine-ucontext.c:175
+ * #20 0x00007ffff70b4830 in __start_context () at /lib64/libc.so.6
+ * #21 0x00007fffef7e01c0 in  ()
+ * #22 0x0000000000000000 in  ()
+ *
+ * called by:
+ *   - block/file-posix.c|3641| <<raw_co_pwrite_zeroes>> return raw_do_pwrite_zeroes(bs, offset, bytes, flags, false);
+ *   - block/file-posix.c|4243| <<hdev_co_pwrite_zeroes>> return raw_do_pwrite_zeroes(bs, offset, bytes, flags, true);
+ */
 static int coroutine_fn
 raw_do_pwrite_zeroes(BlockDriverState *bs, int64_t offset, int64_t bytes,
                      BdrvRequestFlags flags, bool blkdev)
@@ -3634,6 +3825,9 @@ raw_do_pwrite_zeroes(BlockDriverState *bs, int64_t offset, int64_t bytes,
     return raw_thread_pool_submit(handler, &acb);
 }
 
+/*
+ * BlockDriver bdrv_file.block/file-posix.c|3923| <<global>> .bdrv_co_pwrite_zeroes = raw_co_pwrite_zeroes,
+ */
 static int coroutine_fn raw_co_pwrite_zeroes(
     BlockDriverState *bs, int64_t offset,
     int64_t bytes, BdrvRequestFlags flags)
@@ -3739,6 +3933,34 @@ static QemuOptsList raw_create_opts = {
     }
 };
 
+/*
+ * [0] qemu_lock_fd
+ * [0] raw_handle_perm_lock
+ * [0] raw_check_perm
+ * [0] bdrv_drv_set_perm
+ * [0] bdrv_node_refresh_perm
+ * [0] bdrv_list_refresh_perms
+ * [0] bdrv_replace_node_common
+ * [0] mirror_start_job
+ * [0] commit_active_start
+ * [0] qmp_block_commit
+ * [0] qmp_marshal_block_commit
+ * [0] do_qmp_dispatch_bh
+ * [0] aio_bh_poll
+ * [0] aio_dispatch
+ * [0] aio_ctx_dispatch
+ * [0] g_main_context_dispatch
+ * [0] glib_pollfds_poll
+ * [0] os_host_main_loop_wait
+ * [0] main_loop_wait
+ * [0] qemu_main_loop
+ * [0] qemu_default_main
+ * [0] __libc_start_main
+ * [0] _start
+ *
+ * block/file-posix.c|3955| <<global>> BlockDriver bdrv_file.bdrv_check_perm = raw_check_perm,
+ * block/file-posix.c|4324| <<global>> BlockDriver bdrv_host_device.bdrv_check_perm = raw_check_perm,
+ */
 static int raw_check_perm(BlockDriverState *bs, uint64_t perm, uint64_t shared,
                           Error **errp)
 {
@@ -3771,6 +3993,17 @@ static int raw_check_perm(BlockDriverState *bs, uint64_t perm, uint64_t shared,
 
     /* Prepare permissions on old fd to avoid conflicts between old and new,
      * but keep everything locked that new will need. */
+    /*
+     * called by:
+     *   - block/file-posix.c|3820| <<raw_check_perm>> ret = raw_handle_perm_lock(bs, RAW_PL_PREPARE, perm, shared, errp);
+     *   - block/file-posix.c|3830| <<raw_check_perm>> raw_handle_perm_lock(bs, RAW_PL_ABORT, 0, 0, NULL);
+     *   - block/file-posix.c|3857| <<raw_set_perm>> raw_handle_perm_lock(bs, RAW_PL_COMMIT, perm, shared, NULL);
+     *   - block/file-posix.c|3873| <<raw_abort_perm_update>> raw_handle_perm_lock(bs, RAW_PL_ABORT, 0, 0, NULL);
+     *
+     * BDRVRawState *s:
+     * -> int fd;
+     * -> int perm_change_fd;
+     */
     ret = raw_handle_perm_lock(bs, RAW_PL_PREPARE, perm, shared, errp);
     if (ret < 0) {
         goto fail;
@@ -3797,6 +4030,11 @@ fail:
 
 static void raw_set_perm(BlockDriverState *bs, uint64_t perm, uint64_t shared)
 {
+    /*
+     * BDRVRawState *s:
+     * -> uint64_t perm;
+     * -> uint64_t shared_perm;
+     */
     BDRVRawState *s = bs->opaque;
 
     /* For reopen, we have already switched to the new fd (.bdrv_set_perm is
diff --git a/block/io.c b/block/io.c
index 7217cf811..f8911283d 100644
--- a/block/io.c
+++ b/block/io.c
@@ -119,6 +119,12 @@ bdrv_parent_drained_poll(BlockDriverState *bs, BdrvChild *ignore,
     return busy;
 }
 
+/*
+ * called by:
+ *   - block.c|2644| <<bdrv_replace_child_abort>> bdrv_parent_drained_begin_single(s->child);
+ *   - block.c|3621| <<bdrv_attach_child_common>> bdrv_parent_drained_begin_single(new_child);
+ *   - block/io.c|62| <<bdrv_parent_drained_begin>> bdrv_parent_drained_begin_single(c);
+ */
 void bdrv_parent_drained_begin_single(BdrvChild *c)
 {
     GLOBAL_STATE_CODE();
@@ -126,6 +132,10 @@ void bdrv_parent_drained_begin_single(BdrvChild *c)
     assert(!c->quiesced_parent);
     c->quiesced_parent = true;
 
+    /*
+     * BdrvChild *c:
+     * -> const BdrvChildClass *klass;
+     */
     if (c->klass->drained_begin) {
         /* called with rdlock taken, but it doesn't really need it. */
         c->klass->drained_begin(c);
@@ -384,6 +394,59 @@ void bdrv_do_drained_begin_quiesce(BlockDriverState *bs, BdrvChild *parent)
     bdrv_do_drained_begin(bs, parent, false);
 }
 
+/*
+ * called by:
+ *   - block.c|502| <<bdrv_new>> bdrv_drained_begin(bs);
+ *   - block.c|3801| <<bdrv_set_backing_hd>> bdrv_drained_begin(drain_bs);
+ *   - block.c|4579| <<bdrv_reopen_queue_child>> bdrv_drained_begin(bs);
+ *   - block.c|4997| <<bdrv_reopen_parse_file_or_backing>> bdrv_drained_begin(old_child_bs);
+ *   - block.c|5339| <<bdrv_close>> bdrv_drained_begin(bs);
+ *   - block.c|5770| <<bdrv_drop_filter>> bdrv_drained_begin(child_bs);
+ *   - block.c|5815| <<bdrv_append>> bdrv_drained_begin(bs_top);
+ *   - block.c|5816| <<bdrv_append>> bdrv_drained_begin(bs_new);
+ *   - block.c|5858| <<bdrv_replace_child_bs>> bdrv_drained_begin(old_bs);
+ *   - block.c|5859| <<bdrv_replace_child_bs>> bdrv_drained_begin(new_bs);
+ *   - block.c|5951| <<bdrv_insert_node>> bdrv_drained_begin(bs);
+ *   - block.c|5952| <<bdrv_insert_node>> bdrv_drained_begin(new_node_bs);
+ *   - block.c|6233| <<bdrv_drop_intermediate>> bdrv_drained_begin(base);
+ *   - block.c|8080| <<bdrv_change_aio_context>> bdrv_drained_begin(bs);
+ *   - block/block-backend.c|1070| <<blk_remove_bs>> bdrv_drained_begin(bs);
+ *   - block/block-backend.c|2388| <<blk_drain>> bdrv_drained_begin(bs);
+ *   - block/block-backend.c|3066| <<blk_io_limits_disable>> bdrv_drained_begin(bs);
+ *   - block/commit.c|104| <<commit_abort>> bdrv_drained_begin(commit_top_backing_bs);
+ *   - block/commit.c|440| <<commit_start>> bdrv_drained_begin(top);
+ *   - block/io.c|434| <<bdrv_drain>> bdrv_drained_begin(bs);
+ *   - block/mirror.c|716| <<mirror_exit_common>> bdrv_drained_begin(mirror_top_bs);
+ *   - block/mirror.c|717| <<mirror_exit_common>> bdrv_drained_begin(target_bs);
+ *   - block/mirror.c|758| <<mirror_exit_common>> bdrv_drained_begin(to_replace);
+ *   - block/mirror.c|1115| <<mirror_run>> bdrv_drained_begin(bs);
+ *   - block/mirror.c|1166| <<mirror_run>> bdrv_drained_begin(bs);
+ *   - block/mirror.c|1935| <<mirror_start_job>> bdrv_drained_begin(bs);
+ *   - block/mirror.c|2303| <<mirror_start_job>> bdrv_drained_begin(bs);
+ *   - block/snapshot.c|371| <<bdrv_snapshot_delete>> bdrv_drained_begin(bs);
+ *   - block/stream.c|83| <<stream_prepare>> bdrv_drained_begin(unfiltered_bs);
+ *   - block/stream.c|86| <<stream_prepare>> bdrv_drained_begin(unfiltered_bs_cow);
+ *   - blockdev.c|1261| <<internal_snapshot_action>> bdrv_drained_begin(bs);
+ *   - blockdev.c|1427| <<external_snapshot_action>> bdrv_drained_begin(state->old_bs);
+ *   - blockdev.c|1576| <<external_snapshot_abort>> bdrv_drained_begin(state->new_bs);
+ *   - blockdev.c|1658| <<drive_backup_action>> bdrv_drained_begin(bs);
+ *   - blockdev.c|1836| <<blockdev_backup_action>> bdrv_drained_begin(state->bs);
+ *   - blockdev.c|2307| <<qmp_block_resize>> bdrv_drained_begin(bs);
+ *   - tests/unit/test-bdrv-drain.c|166| <<do_drain_begin>> case BDRV_DRAIN: bdrv_drained_begin(bs); break;
+ *   - tests/unit/test-bdrv-drain.c|1295| <<test_detach_indirect>> bdrv_drained_begin(parent_b);
+ *   - tests/unit/test-bdrv-drain.c|1296| <<test_detach_indirect>> bdrv_drained_begin(a);
+ *   - tests/unit/test-bdrv-drain.c|1297| <<test_detach_indirect>> bdrv_drained_begin(b);
+ *   - tests/unit/test-bdrv-drain.c|1298| <<test_detach_indirect>> bdrv_drained_begin(c);
+ *   - tests/unit/test-bdrv-drain.c|1397| <<test_set_aio_context>> bdrv_drained_begin(bs);
+ *   - tests/unit/test-bdrv-drain.c|1401| <<test_set_aio_context>> bdrv_drained_begin(bs);
+ *   - tests/unit/test-bdrv-drain.c|1545| <<test_blockjob_commit_by_drained_end>> bdrv_drained_begin(bs_child);
+ *   - tests/unit/test-bdrv-drain.c|1946| <<do_test_replace_child_mid_drain>> bdrv_drained_begin(old_child_bs);
+ *   - tests/unit/test-bdrv-drain.c|1949| <<do_test_replace_child_mid_drain>> bdrv_drained_begin(new_child_bs);
+ *   - tests/unit/test-bdrv-drain.c|1971| <<do_test_replace_child_mid_drain>> bdrv_drained_begin(old_child_bs);
+ *   - tests/unit/test-bdrv-drain.c|1972| <<do_test_replace_child_mid_drain>> bdrv_drained_begin(new_child_bs);
+ *   - tests/unit/test-bdrv-graph-mod.c|236| <<test_parallel_exclusive_write>> bdrv_drained_begin(fl1);
+ *   - tests/unit/test-bdrv-graph-mod.c|237| <<test_parallel_exclusive_write>> bdrv_drained_begin(fl2);
+ */
 void coroutine_mixed_fn
 bdrv_drained_begin(BlockDriverState *bs)
 {
@@ -422,12 +485,71 @@ static void bdrv_do_drained_end(BlockDriverState *bs, BdrvChild *parent)
     }
 }
 
+/*
+ * called by:
+ *   - block.c|1287| <<bdrv_child_cb_drained_end>> bdrv_drained_end(bs);
+ *   - block.c|3808| <<bdrv_set_backing_hd>> bdrv_drained_end(drain_bs);
+ *   - block.c|4735| <<bdrv_reopen_queue_free>> bdrv_drained_end(bs_entry->state.bs);
+ *   - block.c|5012| <<bdrv_reopen_parse_file_or_backing>> bdrv_drained_end(old_child_bs);
+ *   - block.c|5387| <<bdrv_close>> bdrv_drained_end(bs);
+ *   - block.c|5777| <<bdrv_drop_filter>> bdrv_drained_end(child_bs);
+ *   - block.c|5843| <<bdrv_append>> bdrv_drained_end(bs_top);
+ *   - block.c|5844| <<bdrv_append>> bdrv_drained_end(bs_new);
+ *   - block.c|5875| <<bdrv_replace_child_bs>> bdrv_drained_end(old_bs);
+ *   - block.c|5876| <<bdrv_replace_child_bs>> bdrv_drained_end(new_bs);
+ *   - block.c|5959| <<bdrv_insert_node>> bdrv_drained_end(new_node_bs);
+ *   - block.c|5960| <<bdrv_insert_node>> bdrv_drained_end(bs);
+ *   - block.c|6317| <<bdrv_drop_intermediate>> bdrv_drained_end(base);
+ *   - block.c|8018| <<bdrv_set_aio_context_clean>> bdrv_drained_end(bs);
+ *   - block/block-backend.c|1073| <<blk_remove_bs>> bdrv_drained_end(bs);
+ *   - block/block-backend.c|2396| <<blk_drain>> bdrv_drained_end(bs);
+ *   - block/block-backend.c|3070| <<blk_io_limits_disable>> bdrv_drained_end(bs);
+ *   - block/commit.c|108| <<commit_abort>> bdrv_drained_end(commit_top_backing_bs);
+ *   - block/commit.c|444| <<commit_start>> bdrv_drained_end(top);
+ *   - block/io.c|488| <<bdrv_drain>> bdrv_drained_end(bs);
+ *   - block/mirror.c|774| <<mirror_exit_common>> bdrv_drained_end(to_replace);
+ *   - block/mirror.c|797| <<mirror_exit_common>> bdrv_drained_end(target_bs);
+ *   - block/mirror.c|802| <<mirror_exit_common>> bdrv_drained_end(src);
+ *   - block/mirror.c|803| <<mirror_exit_common>> bdrv_drained_end(mirror_top_bs);
+ *   - block/mirror.c|1122| <<mirror_run>> bdrv_drained_end(bs);
+ *   - block/mirror.c|1995| <<mirror_start_job>> bdrv_drained_end(bs);
+ *   - block/mirror.c|2352| <<mirror_start_job>> bdrv_drained_end(bs);
+ *   - block/snapshot.c|384| <<bdrv_snapshot_delete>> bdrv_drained_end(bs);
+ *   - block/stream.c|127| <<stream_prepare>> bdrv_drained_end(unfiltered_bs_cow);
+ *   - block/stream.c|130| <<stream_prepare>> bdrv_drained_end(unfiltered_bs);
+ *   - blockdev.c|1353| <<internal_snapshot_clean>> bdrv_drained_end(state->bs);
+ *   - blockdev.c|1580| <<external_snapshot_abort>> bdrv_drained_end(state->new_bs);
+ *   - blockdev.c|1595| <<external_snapshot_clean>> bdrv_drained_end(state->old_bs);
+ *   - blockdev.c|1786| <<drive_backup_clean>> bdrv_drained_end(state->bs);
+ *   - blockdev.c|1868| <<blockdev_backup_clean>> bdrv_drained_end(state->bs);
+ *   - blockdev.c|2313| <<qmp_block_resize>> bdrv_drained_end(bs);
+ *   - tests/unit/test-bdrv-drain.c|175| <<do_drain_end>> case BDRV_DRAIN: bdrv_drained_end(bs); break;
+ *   - tests/unit/test-bdrv-drain.c|1318| <<test_detach_indirect>> bdrv_drained_end(parent_b);
+ *   - tests/unit/test-bdrv-drain.c|1319| <<test_detach_indirect>> bdrv_drained_end(a);
+ *   - tests/unit/test-bdrv-drain.c|1320| <<test_detach_indirect>> bdrv_drained_end(b);
+ *   - tests/unit/test-bdrv-drain.c|1321| <<test_detach_indirect>> bdrv_drained_end(c);
+ *   - tests/unit/test-bdrv-drain.c|1399| <<test_set_aio_context>> bdrv_drained_end(bs);
+ *   - tests/unit/test-bdrv-drain.c|1404| <<test_set_aio_context>> bdrv_drained_end(bs);
+ *   - tests/unit/test-bdrv-drain.c|1547| <<test_blockjob_commit_by_drained_end>> bdrv_drained_end(bs_child);
+ *   - tests/unit/test-bdrv-drain.c|1976| <<do_test_replace_child_mid_drain>> bdrv_drained_end(new_child_bs);
+ *   - tests/unit/test-bdrv-drain.c|1977| <<do_test_replace_child_mid_drain>> bdrv_drained_end(old_child_bs);
+ *   - tests/unit/test-bdrv-drain.c|2029| <<do_test_replace_child_mid_drain>> bdrv_drained_end(new_child_bs);
+ *   - tests/unit/test-bdrv-drain.c|2032| <<do_test_replace_child_mid_drain>> bdrv_drained_end(old_child_bs);
+ *   - tests/unit/test-bdrv-graph-mod.c|261| <<test_parallel_exclusive_write>> bdrv_drained_end(fl2);
+ *   - tests/unit/test-bdrv-graph-mod.c|262| <<test_parallel_exclusive_write>> bdrv_drained_end(fl1);
+ */
 void bdrv_drained_end(BlockDriverState *bs)
 {
     IO_OR_GS_CODE();
     bdrv_do_drained_end(bs, NULL);
 }
 
+/*
+ * called by:
+ *   - block.c|5344| <<bdrv_close>> bdrv_drain(bs);
+ *   - qemu-io-cmds.c|2417| <<reopen_f>> bdrv_drain(bs);
+ *   - tests/unit/test-bdrv-drain.c|1102| <<do_test_delete_by_drain>> bdrv_drain(child_bs);
+ */
 void bdrv_drain(BlockDriverState *bs)
 {
     IO_OR_GS_CODE();
@@ -582,6 +704,15 @@ void bdrv_drain_all(void)
  *
  * This function should be called when a tracked request is completing.
  */
+/*
+ * called by:
+ *   - block/io.c|1822| <<bdrv_co_preadv_part>> tracked_request_end(&req);
+ *   - block/io.c|2305| <<bdrv_co_pwritev_part>> tracked_request_end(&req);
+ *   - block/io.c|3187| <<bdrv_co_pdiscard>> tracked_request_end(&req);
+ *   - block/io.c|3445| <<bdrv_co_copy_range_internal>> tracked_request_end(&req);
+ *   - block/io.c|3461| <<bdrv_co_copy_range_internal>> tracked_request_end(&req);
+ *   - block/io.c|3661| <<bdrv_co_truncate>> tracked_request_end(&req);
+ */
 static void coroutine_fn tracked_request_end(BdrvTrackedRequest *req)
 {
     if (req->serialising) {
@@ -603,6 +734,15 @@ static void coroutine_fn tracked_request_end(BdrvTrackedRequest *req)
 /**
  * Add an active request to the tracked requests list
  */
+/*
+ * called by:
+ *   - block/io.c|1818| <<bdrv_co_preadv_part>> tracked_request_begin(&req, bs, offset, bytes, BDRV_TRACKED_READ);
+ *   - block/io.c|2279| <<bdrv_co_pwritev_part>> tracked_request_begin(&req, bs, offset, bytes, BDRV_TRACKED_WRITE);
+ *   - block/io.c|3118| <<bdrv_co_pdiscard>> tracked_request_begin(&req, bs, offset, bytes, BDRV_TRACKED_DISCARD);
+ *   - block/io.c|3432| <<bdrv_co_copy_range_internal>> tracked_request_begin(&req, src->bs, src_offset, bytes, BDRV_TRACKED_READ);
+ *   - block/io.c|3449| <<bdrv_co_copy_range_internal>> tracked_request_begin(&req, dst->bs, dst_offset, bytes, BDRV_TRACKED_WRITE);
+ *   - block/io.c|3584| <<bdrv_co_truncate>> tracked_request_begin(&req, bs, offset - new_bytes, new_bytes, BDRV_TRACKED_TRUNCATE);
+ */
 static void coroutine_fn tracked_request_begin(BdrvTrackedRequest *req,
                                                BlockDriverState *bs,
                                                int64_t offset,
@@ -625,6 +765,13 @@ static void coroutine_fn tracked_request_begin(BdrvTrackedRequest *req,
     qemu_co_queue_init(&req->wait_queue);
 
     qemu_mutex_lock(&bs->reqs_lock);
+    /*
+     * 在以下使用BlockDriverState->tracked_requests:
+     *   - block/io.c|628| <<tracked_request_begin>> QLIST_INSERT_HEAD(&bs->tracked_requests, req, list);
+     *   - block/io.c|654| <<bdrv_find_conflicting_request>> QLIST_FOREACH(req, &self->bs->tracked_requests, list) {
+     *   - block/io.c|724| <<bdrv_co_get_self_request>> QLIST_FOREACH(req, &bs->tracked_requests, list) {
+     *   - block/mirror.c|1130| <<mirror_run>> assert(QLIST_EMPTY(&bs->tracked_requests));
+     */
     QLIST_INSERT_HEAD(&bs->tracked_requests, req, list);
     qemu_mutex_unlock(&bs->reqs_lock);
 }
@@ -715,6 +862,10 @@ static void tracked_request_set_serialising(BdrvTrackedRequest *req,
  * Return the tracked request on @bs for the current coroutine, or
  * NULL if there is none.
  */
+/*
+ * called by:
+ *   - block/file-posix.c|3598| <<raw_do_pwrite_zeroes>> req = bdrv_co_get_self_request(bs);
+ */
 BdrvTrackedRequest *coroutine_fn bdrv_co_get_self_request(BlockDriverState *bs)
 {
     BdrvTrackedRequest *req;
@@ -722,6 +873,13 @@ BdrvTrackedRequest *coroutine_fn bdrv_co_get_self_request(BlockDriverState *bs)
     IO_CODE();
 
     QLIST_FOREACH(req, &bs->tracked_requests, list) {
+        /*
+	 * 在以下使用BlockDriverState->tracked_requests:
+	 *   - block/io.c|628| <<tracked_request_begin>> QLIST_INSERT_HEAD(&bs->tracked_requests, req, list);
+	 *   - block/io.c|654| <<bdrv_find_conflicting_request>> QLIST_FOREACH(req, &self->bs->tracked_requests, list) {
+	 *   - block/io.c|724| <<bdrv_co_get_self_request>> QLIST_FOREACH(req, &bs->tracked_requests, list) {
+	 *   - block/mirror.c|1130| <<mirror_run>> assert(QLIST_EMPTY(&bs->tracked_requests));
+	 */
         if (req->co == self) {
             return req;
         }
@@ -970,10 +1128,21 @@ static void bdrv_co_io_em_complete(void *opaque, int ret)
     aio_co_wake(co->coroutine);
 }
 
+/*
+ * called by:
+ *   - block/io.c|1296| <<bdrv_co_do_copy_on_readv>> ret = bdrv_driver_preadv(bs, align_offset, pnum,
+ *   - block/io.c|1335| <<bdrv_co_do_copy_on_readv>> ret = bdrv_driver_preadv(bs, offset + progress,
+ *   - block/io.c|1431| <<bdrv_aligned_preadv>> ret = bdrv_driver_preadv(bs, offset, bytes, qiov, qiov_offset, flags);
+ *   - block/io.c|1442| <<bdrv_aligned_preadv>> ret = bdrv_driver_preadv(bs, offset + bytes - bytes_remaining,
+ */
 static int coroutine_fn GRAPH_RDLOCK
 bdrv_driver_preadv(BlockDriverState *bs, int64_t offset, int64_t bytes,
                    QEMUIOVector *qiov, size_t qiov_offset, int flags)
 {
+    /*
+     * BlockDriverState *bs:
+     * -> BlockDriver *drv;
+     */
     BlockDriver *drv = bs->drv;
     int64_t sector_num;
     unsigned int nb_sectors;
@@ -988,6 +1157,9 @@ bdrv_driver_preadv(BlockDriverState *bs, int64_t offset, int64_t bytes,
         return -ENOMEDIUM;
     }
 
+    /*
+     * qcow2_co_preadv_part()
+     */
     if (drv->bdrv_co_preadv_part) {
         return drv->bdrv_co_preadv_part(bs, offset, bytes, qiov, qiov_offset,
                                         flags);
@@ -998,6 +1170,10 @@ bdrv_driver_preadv(BlockDriverState *bs, int64_t offset, int64_t bytes,
         qiov = &local_qiov;
     }
 
+    /*
+     * raw_co_preadv()
+     * bdrv_mirror_top_preadv()
+     */
     if (drv->bdrv_co_preadv) {
         ret = drv->bdrv_co_preadv(bs, offset, bytes, qiov, flags);
         goto out;
@@ -1760,6 +1936,37 @@ static int bdrv_pad_request(BlockDriverState *bs,
     return 0;
 }
 
+/*
+ * called by:
+ *   - block/blkdebug.c|651| <<blkdebug_co_preadv>> return bdrv_co_preadv(bs->file, offset, bytes, qiov, flags);
+ *   - block/blklogwrites.c|338| <<blk_log_writes_co_preadv>> return bdrv_co_preadv(bs->file, offset, bytes, qiov, flags);
+ *   - block/blkreplay.c|78| <<blkreplay_co_preadv>> int ret = bdrv_co_preadv(bs->file, offset, bytes, qiov, flags);
+ *   - block/bochs.c|275| <<bochs_co_preadv>> ret = bdrv_co_preadv(bs->file, block_offset, 512,
+ *   - block/commit.c|224| <<bdrv_commit_top_preadv>> return bdrv_co_preadv(bs->backing, offset, bytes, qiov, flags);
+ *   - block/copy-before-write.c|85| <<cbw_co_preadv>> return bdrv_co_preadv(bs->file, offset, bytes, qiov, flags);
+ *   - block/crypto.c|506| <<block_crypto_co_preadv>> ret = bdrv_co_preadv(bs->file, payload_offset + offset + bytes_done,
+ *   - block/mirror.c|401| <<mirror_co_read>> ret = bdrv_co_preadv(s->mirror_top_bs->backing, op->offset, op->bytes,
+ *   - block/mirror.c|1520| <<bdrv_mirror_top_preadv>> return bdrv_co_preadv(bs->backing, offset, bytes, qiov, flags);
+ *   - block/parallels.c|511| <<parallels_co_readv>> ret = bdrv_co_preadv(bs->backing, sector_num * BDRV_SECTOR_SIZE,
+ *   - block/parallels.c|520| <<parallels_co_readv>> ret = bdrv_co_preadv(bs->file, position * BDRV_SECTOR_SIZE, nbytes,
+ *   - block/qed.c|895| <<qed_read_backing_file>> return bdrv_co_preadv(s->bs->backing, pos, qiov->size, qiov, 0);
+ *   - block/qed.c|1336| <<qed_aio_read_data>> r = bdrv_co_preadv(bs->file, offset, acb->cur_qiov.size,
+ *   - block/quorum.c|591| <<read_quorum_children_entry>> sacb->ret = bdrv_co_preadv(s->children[i], acb->offset, acb->bytes,
+ *   - block/quorum.c|660| <<read_fifo_child>> ret = bdrv_co_preadv(s->children[n], acb->offset, acb->bytes,
+ *   - block/raw-format.c|240| <<raw_co_preadv>> return bdrv_co_preadv(bs->file, offset, bytes, qiov, flags);
+ *   - block/replication.c|241| <<replication_co_readv>> ret = bdrv_co_preadv(bs->file, sector_num * BDRV_SECTOR_SIZE,
+ *   - block/throttle.c|126| <<throttle_co_preadv>> return bdrv_co_preadv(bs->file, offset, bytes, qiov, flags);
+ *   - block/vdi.c|589| <<vdi_co_preadv>> ret = bdrv_co_preadv(bs->file, data_offset, n_bytes,
+ *   - block/vhdx.c|1220| <<vhdx_co_readv>> ret = bdrv_co_preadv(bs->file, sinfo.file_offset,
+ *   - block/vmdk.c|1927| <<vmdk_read_extent>> ret = bdrv_co_preadv(extent->file,
+ *   - block/vmdk.c|2019| <<vmdk_co_preadv>> ret = bdrv_co_preadv(bs->backing, offset, n_bytes,
+ *   - block/vpc.c|627| <<vpc_co_preadv>> return bdrv_co_preadv(bs->file, offset, bytes, qiov, 0);
+ *   - block/vpc.c|644| <<vpc_co_preadv>> ret = bdrv_co_preadv(bs->file, image_offset, n_bytes
+ *   - include/block/block_int-io.h|67| <<bdrv_co_pread>> return bdrv_co_preadv(child, offset, bytes, &qiov, flags);
+ *   - tests/unit/test-bdrv-drain.c|966| <<bdrv_test_top_co_preadv>> return bdrv_co_preadv(tts->wait_child, offset, bytes, qiov, flags);
+ *   - tests/unit/test-bdrv-drain.c|1003| <<test_co_delete_by_drain>> bdrv_co_preadv(tts->wait_child, 0, 65536, &qiov, 0);
+ *   - tests/unit/test-bdrv-drain.c|1760| <<bdrv_replace_test_co_preadv>> ret = bdrv_co_preadv(bs->backing, offset, bytes, qiov, 0);
+ */
 int coroutine_fn bdrv_co_preadv(BdrvChild *child,
     int64_t offset, int64_t bytes, QEMUIOVector *qiov,
     BdrvRequestFlags flags)
@@ -1768,6 +1975,18 @@ int coroutine_fn bdrv_co_preadv(BdrvChild *child,
     return bdrv_co_preadv_part(child, offset, bytes, qiov, 0, flags);
 }
 
+/*
+ * called by:
+ *   - block/block-backend.c|1582| <<blk_co_do_preadv_part>> ret = bdrv_co_preadv_part(blk->root, offset, bytes, qiov, qiov_offset,
+ *   - block/copy-before-write.c|276| <<cbw_co_preadv_snapshot>> ret = bdrv_co_preadv_part(file, offset, cur_bytes,
+ *   - block/copy-on-read.c|145| <<cor_co_preadv_part>> return bdrv_co_preadv_part(bs->file, offset, bytes, qiov, qiov_offset,
+ *   - block/copy-on-read.c|170| <<cor_co_preadv_part>> ret = bdrv_co_preadv_part(bs->file, offset, n, qiov, qiov_offset,
+ *   - block/filter-compress.c|72| <<compress_co_preadv_part>> return bdrv_co_preadv_part(bs->file, offset, bytes, qiov, qiov_offset,
+ *   - block/io.c|1804| <<bdrv_co_preadv>> return bdrv_co_preadv_part(child, offset, bytes, qiov, 0, flags);
+ *   - block/preallocate.c|282| <<preallocate_co_preadv_part>> return bdrv_co_preadv_part(bs->file, offset, bytes, qiov, qiov_offset,
+ *   - block/qcow2.c|2339| <<qcow2_co_preadv_task>> return bdrv_co_preadv_part(bs->backing, offset, bytes,
+ *   - block/qcow2.c|2353| <<qcow2_co_preadv_task>> return bdrv_co_preadv_part(s->data_file, host_offset,
+ */
 int coroutine_fn bdrv_co_preadv_part(BdrvChild *child,
     int64_t offset, int64_t bytes,
     QEMUIOVector *qiov, size_t qiov_offset,
@@ -1828,6 +2047,11 @@ fail:
     return ret;
 }
 
+/*
+ * called by:
+ *   - block/io.c|1301| <<bdrv_co_do_copy_on_readv>> ret = bdrv_co_do_pwrite_zeroes(bs, align_offset, pnum, BDRV_REQ_WRITE_UNCHANGED);
+ *   - block/io.c|2129| <<bdrv_aligned_pwritev>> ret = bdrv_co_do_pwrite_zeroes(bs, offset, bytes, flags);
+ */
 static int coroutine_fn GRAPH_RDLOCK
 bdrv_co_do_pwrite_zeroes(BlockDriverState *bs, int64_t offset, int64_t bytes,
                          BdrvRequestFlags flags)
@@ -2276,6 +2500,15 @@ int coroutine_fn bdrv_co_pwritev_part(BdrvChild *child,
     }
 
     bdrv_inc_in_flight(bs);
+    /*
+     * called by:
+     *   - block/io.c|1818| <<bdrv_co_preadv_part>> tracked_request_begin(&req, bs, offset, bytes, BDRV_TRACKED_READ);
+     *   - block/io.c|2279| <<bdrv_co_pwritev_part>> tracked_request_begin(&req, bs, offset, bytes, BDRV_TRACKED_WRITE);
+     *   - block/io.c|3118| <<bdrv_co_pdiscard>> tracked_request_begin(&req, bs, offset, bytes, BDRV_TRACKED_DISCARD);
+     *   - block/io.c|3432| <<bdrv_co_copy_range_internal>> tracked_request_begin(&req, src->bs, src_offset, bytes, BDRV_TRACKED_READ);
+     *   - block/io.c|3449| <<bdrv_co_copy_range_internal>> tracked_request_begin(&req, dst->bs, dst_offset, bytes, BDRV_TRACKED_WRITE);
+     *   - block/io.c|3584| <<bdrv_co_truncate>> tracked_request_begin(&req, bs, offset - new_bytes, new_bytes, BDRV_TRACKED_TRUNCATE);
+     */
     tracked_request_begin(&req, bs, offset, bytes, BDRV_TRACKED_WRITE);
 
     if (flags & BDRV_REQ_ZERO_WRITE) {
@@ -3442,6 +3675,15 @@ static int coroutine_fn GRAPH_RDLOCK bdrv_co_copy_range_internal(
                                                     bytes,
                                                     read_flags, write_flags);
 
+        /*
+	 * called by:
+	 *   - block/io.c|1822| <<bdrv_co_preadv_part>> tracked_request_end(&req);
+	 *   - block/io.c|2305| <<bdrv_co_pwritev_part>> tracked_request_end(&req);
+	 *   - block/io.c|3187| <<bdrv_co_pdiscard>> tracked_request_end(&req);
+	 *   - block/io.c|3445| <<bdrv_co_copy_range_internal>> tracked_request_end(&req);
+	 *   - block/io.c|3461| <<bdrv_co_copy_range_internal>> tracked_request_end(&req);
+	 *   - block/io.c|3661| <<bdrv_co_truncate>> tracked_request_end(&req);
+	 */
         tracked_request_end(&req);
         bdrv_dec_in_flight(src->bs);
     } else {
@@ -3458,6 +3700,15 @@ static int coroutine_fn GRAPH_RDLOCK bdrv_co_copy_range_internal(
                                                       read_flags, write_flags);
         }
         bdrv_co_write_req_finish(dst, dst_offset, bytes, &req, ret);
+        /*
+	 * called by:
+	 *   - block/io.c|1822| <<bdrv_co_preadv_part>> tracked_request_end(&req);
+	 *   - block/io.c|2305| <<bdrv_co_pwritev_part>> tracked_request_end(&req);
+	 *   - block/io.c|3187| <<bdrv_co_pdiscard>> tracked_request_end(&req);
+	 *   - block/io.c|3445| <<bdrv_co_copy_range_internal>> tracked_request_end(&req);
+	 *   - block/io.c|3461| <<bdrv_co_copy_range_internal>> tracked_request_end(&req);
+	 *   - block/io.c|3661| <<bdrv_co_truncate>> tracked_request_end(&req);
+	 */
         tracked_request_end(&req);
         bdrv_dec_in_flight(dst->bs);
     }
@@ -3581,6 +3832,15 @@ int coroutine_fn bdrv_co_truncate(BdrvChild *child, int64_t offset, bool exact,
     }
 
     bdrv_inc_in_flight(bs);
+    /*
+     * called by:
+     *   - block/io.c|1818| <<bdrv_co_preadv_part>> tracked_request_begin(&req, bs, offset, bytes, BDRV_TRACKED_READ);
+     *   - block/io.c|2279| <<bdrv_co_pwritev_part>> tracked_request_begin(&req, bs, offset, bytes, BDRV_TRACKED_WRITE);
+     *   - block/io.c|3118| <<bdrv_co_pdiscard>> tracked_request_begin(&req, bs, offset, bytes, BDRV_TRACKED_DISCARD);
+     *   - block/io.c|3432| <<bdrv_co_copy_range_internal>> tracked_request_begin(&req, src->bs, src_offset, bytes, BDRV_TRACKED_READ);
+     *   - block/io.c|3449| <<bdrv_co_copy_range_internal>> tracked_request_begin(&req, dst->bs, dst_offset, bytes, BDRV_TRACKED_WRITE);
+     *   - block/io.c|3584| <<bdrv_co_truncate>> tracked_request_begin(&req, bs, offset - new_bytes, new_bytes, BDRV_TRACKED_TRUNCATE);
+     */
     tracked_request_begin(&req, bs, offset - new_bytes, new_bytes,
                           BDRV_TRACKED_TRUNCATE);
 
@@ -3658,6 +3918,15 @@ int coroutine_fn bdrv_co_truncate(BdrvChild *child, int64_t offset, bool exact,
     bdrv_co_write_req_finish(child, offset - new_bytes, new_bytes, &req, 0);
 
 out:
+    /*
+     * called by:
+     *   - block/io.c|1822| <<bdrv_co_preadv_part>> tracked_request_end(&req);
+     *   - block/io.c|2305| <<bdrv_co_pwritev_part>> tracked_request_end(&req);
+     *   - block/io.c|3187| <<bdrv_co_pdiscard>> tracked_request_end(&req);
+     *   - block/io.c|3445| <<bdrv_co_copy_range_internal>> tracked_request_end(&req);
+     *   - block/io.c|3461| <<bdrv_co_copy_range_internal>> tracked_request_end(&req);
+     *   - block/io.c|3661| <<bdrv_co_truncate>> tracked_request_end(&req);
+     */
     tracked_request_end(&req);
     bdrv_dec_in_flight(bs);
 
diff --git a/block/mirror.c b/block/mirror.c
index 1bdce3b65..85b2c0938 100644
--- a/block/mirror.c
+++ b/block/mirror.c
@@ -25,6 +25,12 @@
 #include "qemu/bitmap.h"
 #include "qemu/memalign.h"
 
+/*
+ * 这个文档:
+ * A Practical Look at QEMU's Block Layer Primitives
+ * https://kashyapc.fedorapeople.org/virt/LinuxCon-NA-2016/A-Practical-Look-at-QEMU-Block-Layer-Primitives-LC-NA-2016.pdf
+ */
+
 #define MAX_IN_FLIGHT 16
 #define MAX_IO_BYTES (1 << 20) /* 1 Mb */
 #define DEFAULT_MIRROR_BUF_SIZE (MAX_IN_FLIGHT * MAX_IO_BYTES)
@@ -1030,6 +1036,9 @@ static int coroutine_fn mirror_run(Job *job, Error **errp)
 
     assert(!s->dbi);
     s->dbi = bdrv_dirty_iter_new(s->dirty_bitmap);
+    /*
+     * 重要的主循环!!!!!
+     */
     for (;;) {
         int64_t cnt, delta;
         bool should_complete;
@@ -1313,6 +1322,18 @@ static const BlockJobDriver mirror_job_driver = {
     .query                  = mirror_query,
 };
 
+/*
+ * 在以下使用commit_active_job_driver:
+ *   - block/mirror.c|2557| <<commit_active_start>> &commit_active_job_driver, false, base, auto_complete,
+ *
+ * 2557     job = mirror_start_job( 
+ * 2558                      job_id, bs, creation_flags, base, NULL, speed, 0, 0,
+ * 2559                      MIRROR_LEAVE_BACKING_CHAIN, false,
+ * 2560                      on_error, on_error, true, cb, opaque,
+ * 2561                      &commit_active_job_driver, false, base, auto_complete,
+ * 2562                      filter_node_name, false, MIRROR_COPY_MODE_BACKGROUND,
+ * 2563                      errp);
+ */
 static const BlockJobDriver commit_active_job_driver = {
     .job_driver = {
         .instance_size          = sizeof(MirrorBlockJob),
@@ -1512,6 +1533,11 @@ static int coroutine_fn GRAPH_RDLOCK
 bdrv_mirror_top_preadv(BlockDriverState *bs, int64_t offset, int64_t bytes,
                        QEMUIOVector *qiov, BdrvRequestFlags flags)
 {
+    /*
+     * BlockDriverState *bs:
+     * -> BlockDriver *drv;
+     * -> BdrvChild * GRAPH_RDLOCK_PTR backing;
+     */
     return bdrv_co_preadv(bs->backing, offset, bytes, qiov, flags);
 }
 
@@ -1522,6 +1548,12 @@ static bool should_copy_to_target(MirrorBDSOpaque *s)
         qatomic_read(&s->job->copy_mode) == MIRROR_COPY_MODE_WRITE_BLOCKING;
 }
 
+/*
+ * called by:
+ *   - block/mirror.c|1599| <<bdrv_mirror_top_pwritev>> ret = bdrv_mirror_top_do_write(bs, MIRROR_METHOD_COPY, copy_to_target,
+ *   - block/mirror.c|1624| <<bdrv_mirror_top_pwrite_zeroes>> return bdrv_mirror_top_do_write(bs, MIRROR_METHOD_ZERO, copy_to_target,
+ *   - block/mirror.c|1632| <<bdrv_mirror_top_pdiscard>> return bdrv_mirror_top_do_write(bs, MIRROR_METHOD_DISCARD, copy_to_target,
+ */
 static int coroutine_fn GRAPH_RDLOCK
 bdrv_mirror_top_do_write(BlockDriverState *bs, MirrorMethod method,
                          bool copy_to_target, uint64_t offset, uint64_t bytes,
@@ -1685,6 +1717,10 @@ static void bdrv_mirror_top_child_perm(BlockDriverState *bs, BdrvChild *c,
     }
 }
 
+/*
+ * 在以下使用bdrv_mirror_top:
+ *   - block/mirror.c|1797| <<mirror_start_job>> mirror_top_bs = bdrv_new_open_driver(&bdrv_mirror_top, filter_node_name,
+ */
 /* Dummy node that provides consistent read to its users without requiring it
  * from its backing file and that allows writes on the backing file chain. */
 static BlockDriver bdrv_mirror_top = {
@@ -1701,6 +1737,84 @@ static BlockDriver bdrv_mirror_top = {
     .filtered_child_is_backing  = true,
 };
 
+/*
+ * [0] qemu_lock_fd
+ * [0] raw_handle_perm_lock
+ * [0] raw_check_perm
+ * [0] bdrv_drv_set_perm
+ * [0] bdrv_node_refresh_perm
+ * [0] bdrv_list_refresh_perms
+ * [0] bdrv_replace_node_common
+ * [0] mirror_start_job
+ * [0] commit_active_start
+ * [0] qmp_block_commit
+ * [0] qmp_marshal_block_commit
+ * [0] do_qmp_dispatch_bh
+ * [0] aio_bh_poll
+ * [0] aio_dispatch
+ * [0] aio_ctx_dispatch
+ * [0] g_main_context_dispatch
+ * [0] glib_pollfds_poll
+ * [0] os_host_main_loop_wait
+ * [0] main_loop_wait
+ * [0] qemu_main_loop
+ * [0] qemu_default_main
+ * [0] __libc_start_main
+ * [0] _start
+ *
+ * #0  mirror_start_job (job_id=0x7ffdd0007e50 "jobA", bs=0x555557eb20d0, creation_flags=0, target=0x555557407880,
+ *              replaces=0x0, speed=0, granularity=0, buf_size=0, backing_mode=MIRROR_LEAVE_BACKING_CHAIN,
+ *              zero_target=false, on_source_error=BLOCKDEV_ON_ERROR_REPORT, on_target_error=BLOCKDEV_ON_ERROR_REPORT,
+ *              unmap=true, cb=0x0, opaque=0x0, driver=0x555556f73c00 <commit_active_job_driver>, is_none_mode=false,
+ *              base=0x555557407880, auto_complete=false, filter_node_name=0x0, is_mirror=false,
+ *              copy_mode=MIRROR_COPY_MODE_BACKGROUND, errp=0x7fffffffd558) at ../block/mirror.c:1722
+ * #1  0x0000555555f43713 in commit_active_start (job_id=0x7ffdd0007e50 "jobA", bs=0x555557eb20d0, base=0x555557407880,
+ *             creation_flags=0, speed=0, on_error=BLOCKDEV_ON_ERROR_REPORT, filter_node_name=0x0, cb=0x0, opaque=0x0,
+ *             auto_complete=false, errp=0x7fffffffd558) at ../block/mirror.c:2055
+ * #2  0x0000555555edf260 in qmp_block_commit (job_id=0x7ffdd0007e50 "jobA", device=0x555557400d70 "over01",
+ *             base_node=0x0, base=0x0, top_node=0x0, top=0x0, backing_file=0x0, has_backing_mask_protocol=false,
+ *             backing_mask_protocol=false, has_speed=false, speed=0, has_on_error=false,
+ *             on_error=BLOCKDEV_ON_ERROR_REPORT, filter_node_name=0x0, has_auto_finalize=false, auto_finalize=false,
+ *             has_auto_dismiss=false, auto_dismiss=false, errp=0x7fffffffd688) at ../blockdev.c:2597
+ * #3  0x0000555556010f4a in qmp_marshal_block_commit (args=0x7fffd8005c90, ret=0x7ffff7f9eda8, errp=0x7ffff7f9eda0)
+ *             at qapi/qapi-commands-block-core.c:408
+ * #4  0x00005555560a4413 in do_qmp_dispatch_bh (opaque=0x7ffff7f9ee40) at ../qapi/qmp-dispatch.c:128
+ * #5  0x00005555560d3305 in aio_bh_call (bh=0x55555807f070) at ../util/async.c:171
+ * #6  0x00005555560d3453 in aio_bh_poll (ctx=0x555557169480) at ../util/async.c:218
+ * #7  0x00005555560b2a26 in aio_dispatch (ctx=0x555557169480) at ../util/aio-posix.c:423
+ * #8  0x00005555560d3922 in aio_ctx_dispatch (source=0x555557169480, callback=0x0, user_data=0x0) at ../util/async.c:360
+ * #9  0x00007ffff6c53aed in g_main_context_dispatch () at /lib/../lib64/libglib-2.0.so.0
+ * #10 0x00005555560d4ff3 in glib_pollfds_poll () at ../util/main-loop.c:287
+ * #11 0x00005555560d5081 in os_host_main_loop_wait (timeout=0) at ../util/main-loop.c:310
+ * #12 0x00005555560d51b0 in main_loop_wait (nonblocking=0) at ../util/main-loop.c:589
+ * #13 0x0000555555bc3abf in qemu_main_loop () at ../system/runstate.c:783
+ * #14 0x0000555555e8a1bb in qemu_default_main () at ../system/main.c:37
+ * #15 0x0000555555e8a1f8 in main (argc=32, argv=0x7fffffffdaf8) at ../system/main.c:48
+ *
+ * called by:
+ *   - block/mirror.c|2028| <<mirror_start>> mirror_start_job(job_id, bs, creation_flags, target, replaces,
+ *                                                       speed, granularity, buf_size, backing_mode, zero_target,
+ *                                                       on_source_error, on_target_error, unmap, NULL, NULL,
+ *                                                       &mirror_job_driver, is_none_mode, base, false,
+ *                                                       filter_node_name, true, copy_mode, errp);
+ *   - block/mirror.c|2055| <<commit_active_start>> job = mirror_start_job(job_id, bs, creation_flags, base, NULL, speed, 0, 0,
+ *                                                       MIRROR_LEAVE_BACKING_CHAIN, false,
+ *                                                       on_error, on_error, true, cb, opaque,
+ *                                                       &commit_active_job_driver, false, base, auto_complete,
+ *                                                       filter_node_name, false, MIRROR_COPY_MODE_BACKGROUND,
+ *                                                       errp);
+ *
+ * bs     :
+ *   - filename = "/tmp/overlay01.qcow2"i,
+ *   - exact_filename = "/tmp/overlay01.qcow2"
+ *   - backing_file = "test01.qcow2"
+ *   - auto_backing_file = "test01.qcow2"
+ * target :
+ *   - filename = "test01.qcow2"
+ *   - exact_filename = "test01.qcow2"
+ *   - backing_file = 0
+ *   - auto_backing_file = 0
+ */
 static BlockJob *mirror_start_job(
                              const char *job_id, BlockDriverState *bs,
                              int creation_flags, BlockDriverState *target,
@@ -1719,7 +1833,31 @@ static BlockJob *mirror_start_job(
                              bool is_mirror, MirrorCopyMode copy_mode,
                              Error **errp)
 {
+    /*
+     * 执行的时候coroutine随时进来.
+     * (gdb) n
+     * 0x00005555560d862f in qemu_coroutine_switch (from_=0x7ffdd0014160, to_=0x7ffff7fa0270, action=COROUTINE_TERMINATE)
+     *     at ../util/coroutine-ucontext.c:321
+     * 321	    ret = sigsetjmp(from->env, 0);
+     */
+    /*
+     * typedef struct MirrorBlockJob {
+     *     BlockJob common;
+     *     BlockBackend *target;
+     *     BlockDriverState *mirror_top_bs;
+     *     BlockDriverState *base;
+     *     BlockDriverState *base_overlay;
+     *
+     *     char *replaces;
+     */
     MirrorBlockJob *s;
+    /*
+     * typedef struct MirrorBDSOpaque {
+     *     MirrorBlockJob *job;
+     *     bool stop;
+     *     bool is_commit;
+     * } MirrorBDSOpaque;
+     */
     MirrorBDSOpaque *bs_opaque;
     BlockDriverState *mirror_top_bs;
     bool target_is_backing;
@@ -1750,12 +1888,56 @@ static BlockJob *mirror_start_job(
         return NULL;
     }
 
+    /*
+     * called by:
+     *   - block.c|5520| <<bdrv_replace_node_common>> assert(bdrv_chain_contains(from, to));
+     *   - block.c|6060| <<bdrv_drop_intermediate>> if (!bdrv_chain_contains(top, base)) {
+     *   - block/block-copy.c|403| <<block_copy_state_new>> is_fleecing = bdrv_chain_contains(target->bs, source->bs);
+     *   - block/mirror.c|690| <<mirror_exit_common>> if (bdrv_chain_contains(src, target_bs)) {
+     *   - block/mirror.c|1791| <<mirror_start_job>> target_is_backing = bdrv_chain_contains(bs, target);
+     *   - block/mirror.c|1877| <<mirror_start_job>> if (bdrv_chain_contains(bs, bdrv_skip_filters(target))) {
+     *   - blockdev.c|2367| <<qmp_block_stream>> if (bs == base_bs || !bdrv_chain_contains(bs, base_bs)) {
+     *   - blockdev.c|2391| <<qmp_block_stream>> if (!bdrv_chain_contains(bs, bottom_bs)) {
+     *   - blockdev.c|2599| <<qmp_block_commit>> if (!bdrv_chain_contains(bs, top_bs)) {
+     *   - blockdev.c|2632| <<qmp_block_commit>> if (!bdrv_chain_contains(top_bs, base_bs)) {
+     *   - blockdev.c|3433| <<qmp_change_backing_file>> if (!bdrv_chain_contains(bs, image_bs)) {
+     *
+     * 一般返回true
+     *
+     * bs是top
+     * target是base
+     */
     target_is_backing = bdrv_chain_contains(bs, target);
     bdrv_graph_rdunlock_main_loop();
 
     /* In the case of active commit, add dummy driver to provide consistent
      * reads on the top, while disabling it in the intermediate nodes, and make
      * the backing chain writable. */
+    /*
+     * 没有open method???!
+     * 1694 static BlockDriver bdrv_mirror_top = {
+     * 1695     .format_name                = "mirror_top",
+     * 1696     .bdrv_co_preadv             = bdrv_mirror_top_preadv,
+     * 1697     .bdrv_co_pwritev            = bdrv_mirror_top_pwritev,
+     * 1698     .bdrv_co_pwrite_zeroes      = bdrv_mirror_top_pwrite_zeroes,
+     * 1699     .bdrv_co_pdiscard           = bdrv_mirror_top_pdiscard,
+     * 1700     .bdrv_co_flush              = bdrv_mirror_top_flush,
+     * 1701     .bdrv_refresh_filename      = bdrv_mirror_top_refresh_filename,
+     * 1702     .bdrv_child_perm            = bdrv_mirror_top_child_perm,
+     * 1703 
+     * 1704     .is_filter                  = true,
+     * 1705     .filtered_child_is_backing  = true,
+     * 1706 };
+     *
+     * 非unit test的使用:
+     *   - block/commit.c|314| <<commit_start>> commit_top_bs = bdrv_new_open_driver(&bdrv_commit_top, filter_node_name, 0, errp);
+     *   - block/commit.c|505| <<bdrv_commit>> commit_top_bs = bdrv_new_open_driver(&bdrv_commit_top, NULL, BDRV_O_RDWR, &local_err);
+     *   - block/mirror.c|1797| <<mirror_start_job>> mirror_top_bs = bdrv_new_open_driver(&bdrv_mirror_top, filter_node_name, BDRV_O_RDWR, errp);
+     *
+     * BlockDriverState *mirror_top_bs;
+     *
+     * 注释: Create and open a block node
+     */
     mirror_top_bs = bdrv_new_open_driver(&bdrv_mirror_top, filter_node_name,
                                          BDRV_O_RDWR, errp);
     if (mirror_top_bs == NULL) {
@@ -1773,11 +1955,74 @@ static BlockJob *mirror_start_job(
     mirror_top_bs->supported_zero_flags = BDRV_REQ_WRITE_UNCHANGED |
                                           BDRV_REQ_NO_FALLBACK;
     bs_opaque = g_new0(MirrorBDSOpaque, 1);
+    /*
+     * MirrorBDSOpaque *bs_opaque;
+     */
     mirror_top_bs->opaque = bs_opaque;
 
     bs_opaque->is_commit = target_is_backing;
 
     bdrv_drained_begin(bs);
+    /*
+     * (gdb) p *mirror_top_bs 
+     * $5 = {open_flags = 2, encrypted = false, sg = false, probed = false, force_share = false, implicit = true, 
+     *   drv = 0x5555570589c0 <bdrv_mirror_top>, opaque = 0x555557f40540, aio_context = 0x5555573fd610, aio_notifiers = {lh_first = 0x0}, 
+     *   walking_aio_notifiers = false, filename = '\000' <repeats 4095 times>, backing_file = '\000' <repeats 4095 times>, 
+     *   auto_backing_file = '\000' <repeats 4095 times>, backing_format = '\000' <repeats 15 times>, full_open_options = 0x0, 
+     *   exact_filename = '\000' <repeats 4095 times>, bl = {request_alignment = 1, max_pdiscard = 0, pdiscard_alignment = 0, max_pwrite_zeroes = 0, 
+     *     pwrite_zeroes_alignment = 0, opt_transfer = 0, max_transfer = 0, max_hw_transfer = 0, max_hw_iov = 0, min_mem_alignment = 512, 
+     *     opt_mem_alignment = 4096, max_iov = 1024, has_variable_length = false, zoned = BLK_Z_NONE, zone_size = 0, nr_zones = 0, 
+     *     max_append_sectors = 0, max_open_zones = 0, max_active_zones = 0, write_granularity = 0}, supported_read_flags = BDRV_REQ_REGISTERED_BUF, 
+     *   supported_write_flags = BDRV_REQ_WRITE_UNCHANGED, supported_zero_flags = 320, supported_truncate_flags = 0, 
+     *   node_name = "#block629", '\000' <repeats 22 times>, node_list = {tqe_next = 0x0, tqe_circ = {tql_next = 0x0, tql_prev = 0x555557eb61c8}}, 
+     *   bs_list = {tqe_next = 0x0, tqe_circ = {tql_next = 0x0, tql_prev = 0x5555574aedb8}}, monitor_list = {tqe_next = 0x0, tqe_circ = {
+     *       tql_next = 0x0, tql_prev = 0x0}}, refcnt = 2, op_blockers = {{lh_first = 0x0} <repeats 16 times>}, inherits_from = 0x0, children = {
+     *     lh_first = 0x7ffdc8005e80}, backing = 0x7ffdc8005e80, file = 0x0, parents = {lh_first = 0x55555807cab0}, options = 0x55555740e230, 
+     *   explicit_options = 0x555557a68880, detect_zeroes = BLOCKDEV_DETECT_ZEROES_OPTIONS_OFF, backing_blocker = 0x0, total_sectors = 20971520, 
+     *   write_threshold_offset = 0, dirty_bitmap_mutex = {lock = {__data = {__lock = 0, __count = 0, __owner = 0, __nusers = 0, __kind = 0, 
+     *         __spins = 0, __elision = 0, __list = {__prev = 0x0, __next = 0x0}}, __size = '\000' <repeats 39 times>, __align = 0}, file = 0x0, 
+     *     line = 0, initialized = true}, dirty_bitmaps = {lh_first = 0x0}, wr_highest_offset = {value = 0}, copy_on_read = 0, in_flight = 0, 
+     *   serialising_in_flight = 0, enable_write_cache = 0, quiesce_counter = 1, write_gen = 0, reqs_lock = {lock = {__data = {__lock = 0, 
+     *         __count = 0, __owner = 0, __nusers = 0, __kind = 0, __spins = 0, __elision = 0, __list = {__prev = 0x0, __next = 0x0}}, 
+     *       __size = '\000' <repeats 39 times>, __align = 0}, file = 0x0, line = 0, initialized = true}, tracked_requests = {lh_first = 0x0}, 
+     *   flush_queue = {entries = {sqh_first = 0x0, sqh_last = 0x5555580884b8}}, active_flush_req = false, flushed_gen = 0, never_freeze = true, 
+     *   bsc_modify_lock = {locked = 0, ctx = 0x0, from_push = {slh_first = 0x0}, to_pop = {slh_first = 0x0}, handoff = 0, sequence = 0, 
+     *     holder = 0x0}, block_status_cache = 0x555557dcf990, wps = 0x0}
+     *
+     *
+     * bs     :
+     *   - filename = "/tmp/overlay01.qcow2",
+     *   - exact_filename = "/tmp/overlay01.qcow2"
+     *   - backing_file = "test01.qcow2"
+     *   - auto_backing_file = "test01.qcow2"
+     * target :
+     *   - filename = "test01.qcow2"
+     *   - exact_filename = "test01.qcow2"
+     *   - backing_file = 0
+     *   - auto_backing_file = 0
+     *
+     * 注释:
+     * Add new bs contents at the top of an image chain while the chain is
+     * live, while keeping required fields on the top layer.
+     *
+     * This will modify the BlockDriverState fields, and swap contents
+     * between bs_new and bs_top. Both bs_new and bs_top are modified.
+     *
+     * bs_new must not be attached to a BlockBackend and must not have backing
+     * child.
+     *
+     * This function does not create any image files.
+     *
+     * called by:
+     *   - block.c|4036| <<bdrv_append_temp_snapshot>> ret = bdrv_append(bs_snapshot, bs, errp);
+     *   - block/commit.c|328| <<commit_start>> ret = bdrv_append(commit_top_bs, top, errp);
+     *   - block/mirror.c|1819| <<mirror_start_job>> ret = bdrv_append(mirror_top_bs, bs, errp);
+     *   - blockdev.c|1517| <<external_snapshot_action>> ret = bdrv_append(state->new_bs, state->old_bs, errp);
+     *   - tests/unit/test-bdrv-drain.c|1364| <<test_append_to_drained>> bdrv_append(overlay, base, &error_abort);
+     *   - tests/unit/test-bdrv-graph-mod.c|145| <<test_update_perm_tree>> ret = bdrv_append(filter, bs, NULL);
+     *   - tests/unit/test-bdrv-graph-mod.c|212| <<test_should_update_child>> bdrv_append(filter, bs, &error_abort);
+     *   - tests/unit/test-bdrv-graph-mod.c|439| <<test_append_greedy_filter>> bdrv_append(fl, base, &error_abort);
+     */
     ret = bdrv_append(mirror_top_bs, bs, errp);
     bdrv_drained_end(bs);
 
@@ -1786,6 +2031,23 @@ static BlockJob *mirror_start_job(
         return NULL;
     }
 
+    /*
+     * called by:
+     *   - block/backup.c|474| <<backup_job_create>> job = block_job_create(job_id, &backup_job_driver, txn, cbw,
+     *   - block/commit.c|298| <<commit_start>> s = block_job_create(job_id, &commit_job_driver, NULL, bs, 0, BLK_PERM_ALL,
+     *   - block/mirror.c|1993| <<mirror_start_job>> s = block_job_create(job_id, driver, NULL, mirror_top_bs,
+     *   - block/stream.c|352| <<stream_start>> s = block_job_create(job_id, &stream_job_driver, NULL, cor_filter_bs,
+     *   - tests/unit/test-bdrv-drain.c|767| <<test_blockjob_common_drain_node>> tjob = block_job_create("job0", &test_job_driver, NULL, src,
+     *   - tests/unit/test-bdrv-drain.c|1534| <<test_blockjob_commit_by_drained_end>> job = block_job_create("job", &test_drop_backing_job_driver, NULL,
+     *   - tests/unit/test-bdrv-drain.c|1694| <<test_drop_intermediate_poll>> job = block_job_create("job", &test_simple_job_driver, NULL, job_node,
+     *   - tests/unit/test-block-iothread.c|561| <<test_attach_blockjob>> tjob = block_job_create("job0", &test_job_driver, NULL, bs,
+     *   - tests/unit/test-blockjob-txn.c|96| <<test_block_job_start>> s = block_job_create(job_id, &test_block_job_driver, txn, bs,
+     *   - tests/unit/test-blockjob.c|40| <<mk_job>> job = block_job_create(id, drv, NULL, blk_bs(blk),
+     *
+     * MirrorBlockJob *s;
+     *
+     * driver的例子: commit_active_job_driver
+     */
     /* Make sure that the source is not resized while the job is running */
     s = block_job_create(job_id, driver, NULL, mirror_top_bs,
                          BLK_PERM_CONSISTENT_READ,
@@ -1799,6 +2061,11 @@ static BlockJob *mirror_start_job(
     /* The block job now has a reference to this node */
     bdrv_unref(mirror_top_bs);
 
+    /*
+     * 有s->mirror_top_bs就没问题
+     *
+     * MirrorBlockJob *s;
+     */
     s->mirror_top_bs = mirror_top_bs;
 
     /* No resize for the target either; while the mirror is still running, a
@@ -1849,9 +2116,88 @@ static BlockJob *mirror_start_job(
         bdrv_graph_rdunlock_main_loop();
     }
 
+    /*
+     * 可以看下s->target(BlockBackend)是不是在block_backends链表
+     *
+     * MirrorBlockJob *s;
+     * -> BlockBackend *target;
+     */
     s->target = blk_new(s->common.job.aio_context,
                         target_perms, target_shared_perms);
+    /*
+     * bs     :
+     *   - filename = "/tmp/overlay01.qcow2"i,
+     *   - exact_filename = "/tmp/overlay01.qcow2"
+     *   - backing_file = "test01.qcow2"
+     *   - auto_backing_file = "test01.qcow2"
+     * target :
+     *   - filename = "test01.qcow2"
+     *   - exact_filename = "test01.qcow2"
+     *   - backing_file = 0
+     *   - auto_backing_file = 0
+     *
+     * 查看下root是不是NULL????
+     */
     ret = blk_insert_bs(s->target, target, errp);
+    /*
+     * (gdb) p *target
+     * $7 = {open_flags = 8226, encrypted = false, sg = false, probed = false, force_share = false, implicit = false,
+     *   drv = 0x55555705acc0 <bdrv_qcow2>, opaque = 0x55555740f250, aio_context = 0x5555573fd610, aio_notifiers = {lh_first = 0x0},
+     *   walking_aio_notifiers = false, filename = "test01.qcow2", '\000' <repeats 4083 times>, backing_file = '\000' <repeats 4095 times>,
+     *   auto_backing_file = '\000' <repeats 4095 times>, backing_format = '\000' <repeats 15 times>, full_open_options = 0x555557503200,
+     *   exact_filename = "test01.qcow2", '\000' <repeats 4083 times>, bl = {request_alignment = 1, max_pdiscard = 0, pdiscard_alignment = 65536,
+     *     max_pwrite_zeroes = 0, pwrite_zeroes_alignment = 65536, opt_transfer = 0, max_transfer = 0, max_hw_transfer = 0, max_hw_iov = 0,
+     *     min_mem_alignment = 512, opt_mem_alignment = 4096, max_iov = 1024, has_variable_length = false, zoned = BLK_Z_NONE, zone_size = 0,
+     *     nr_zones = 0, max_append_sectors = 0, max_open_zones = 0, max_active_zones = 0, write_granularity = 0},
+     *   supported_read_flags = BDRV_REQ_REGISTERED_BUF, supported_write_flags = BDRV_REQ_REGISTERED_BUF, supported_zero_flags = 260,
+     *   supported_truncate_flags = BDRV_REQ_ZERO_WRITE, node_name = "drive01", '\000' <repeats 24 times>, node_list = {tqe_next = 0x555557428450,
+     *     tqe_circ = {tql_next = 0x555557428450, tql_prev = 0x555557405628}}, bs_list = {tqe_next = 0x5555574210e0, tqe_circ = {
+     *       tql_next = 0x5555574210e0, tql_prev = 0x555557405638}}, monitor_list = {tqe_next = 0x0, tqe_circ = {tql_next = 0x0,
+     *       tql_prev = 0x555557405648}}, refcnt = 3, op_blockers = {{lh_first = 0x0}, {lh_first = 0x0}, {lh_first = 0x555557506bb0}, {
+     *       lh_first = 0x5555575cab60}, {lh_first = 0x0}, {lh_first = 0x5555581e4dc0}, {lh_first = 0x555557e74660}, {lh_first = 0x555557e74680}, {
+     *       lh_first = 0x55555750b0e0}, {lh_first = 0x55555750b100}, {lh_first = 0x5555574aac10}, {lh_first = 0x5555574aac30}, {
+     *       lh_first = 0x5555574b0bc0}, {lh_first = 0x5555574b0be0}, {lh_first = 0x0}, {lh_first = 0x55555779d4f0}}, inherits_from = 0x0, children = {
+     *     lh_first = 0x555557400fe0}, backing = 0x0, file = 0x555557400fe0, parents = {lh_first = 0x555557eafb90}, options = 0x555557406860,
+     *   explicit_options = 0x55555740bb90, detect_zeroes = BLOCKDEV_DETECT_ZEROES_OPTIONS_OFF, backing_blocker = 0x0, total_sectors = 20971520,
+     *   write_threshold_offset = 0, dirty_bitmap_mutex = {lock = {__data = {__lock = 0, __count = 0, __owner = 0, __nusers = 0, __kind = 0,
+     *         __spins = 0, __elision = 0, __list = {__prev = 0x0, __next = 0x0}}, __size = '\000' <repeats 39 times>, __align = 0}, file = 0x0,
+     *     line = 0, initialized = true}, dirty_bitmaps = {lh_first = 0x0}, wr_highest_offset = {value = 0}, copy_on_read = 0, in_flight = 0,
+     *   serialising_in_flight = 0, enable_write_cache = 0, quiesce_counter = 0, write_gen = 0, reqs_lock = {lock = {__data = {__lock = 0,
+     *         __count = 0, __owner = 0, __nusers = 0, __kind = 0, __spins = 0, __elision = 0, __list = {__prev = 0x0, __next = 0x0}},
+     *       __size = '\000' <repeats 39 times>, __align = 0}, file = 0x0, line = 0, initialized = true}, tracked_requests = {lh_first = 0x0},
+     *   flush_queue = {entries = {sqh_first = 0x0, sqh_last = 0x55555740bb28}}, active_flush_req = false, flushed_gen = 0, never_freeze = false,
+     *   bsc_modify_lock = {locked = 0, ctx = 0x0, from_push = {slh_first = 0x0}, to_pop = {slh_first = 0x0}, handoff = 0, sequence = 0,
+     *     holder = 0x0}, block_status_cache = 0x5555574005d0, wps = 0x0}
+     *
+     * (gdb) p *s
+     * $8 = {common = {job = {id = 0x555557d672c0 "jobA", driver = 0x555556f73c00 <commit_active_job_driver>, co = 0x0, auto_finalize = true,
+     *       auto_dismiss = true, cb = 0x0, opaque = 0x0, progress = {current = 0, total = 0, lock = {lock = {__data = {__lock = 0, __count = 0,
+     *               __owner = 0, __nusers = 0, __kind = 0, __spins = 0, __elision = 0, __list = {__prev = 0x0, __next = 0x0}},
+     *             __size = '\000' <repeats 39 times>, __align = 0}, file = 0x0, line = 0, initialized = true}}, aio_context = 0x5555573fd610,
+     *       refcnt = 1, status = JOB_STATUS_CREATED, sleep_timer = {expire_time = -1, timer_list = 0x55555716e450,
+     *         cb = 0x555555f01fd7 <job_sleep_timer_cb>, opaque = 0x5555581d1000, next = 0x0, attributes = 0, scale = 1}, pause_count = 1,
+     *       busy = false, paused = true, user_paused = false, cancelled = false, force_cancel = false, deferred_to_main_loop = false, ret = 0,
+     *       err = 0x0, on_finalize_cancelled = {notifiers = {lh_first = 0x5555581d1198}}, on_finalize_completed = {notifiers = {lh_first =
+     *     0x5555581d11b0}}, on_pending = {notifiers = {lh_first = 0x5555581d11c8}}, on_ready = {notifiers = {lh_first = 0x5555581d11e0}}, on_idle = {
+     *         notifiers = {lh_first = 0x5555581d11f8}}, job_list = {le_next = 0x0, le_prev = 0x5555570ace58 <jobs>}, txn = 0x555557eb1f40,
+     *       txn_list = {le_next = 0x0, le_prev = 0x555557eb1f48}}, iostatus = BLOCK_DEVICE_IO_STATUS_OK, speed = 0, limit = {lock = {lock = {
+     *           __data = {__lock = 0, __count = 0, __owner = 0, __nusers = 0, __kind = 0, __spins = 0, __elision = 0, __list = {__prev = 0x0,
+     *               __next = 0x0}}, __size = '\000' <repeats 39 times>, __align = 0}, file = 0x0, line = 0, initialized = true},
+     *       slice_start_time = 0, slice_end_time = 0, slice_quota = 0, slice_ns = 100000000, dispatched = 0}, blocker = 0x555557c23740,
+     *     finalize_cancelled_notifier = {notify = 0x555555f00104 <block_job_event_cancelled_locked>, node = {le_next = 0x0,
+     *         le_prev = 0x5555581d10d0}}, finalize_completed_notifier = {notify = 0x555555f001df <block_job_event_completed_locked>, node = {
+     *         le_next = 0x0, le_prev = 0x5555581d10d8}}, pending_notifier = {notify = 0x555555f002f5 <block_job_event_pending_locked>, node = {
+     *         le_next = 0x0, le_prev = 0x5555581d10e0}}, ready_notifier = {notify = 0x555555f0034a <block_job_event_ready_locked>, node = {le_next =
+     *     0x0, le_prev = 0x5555581d10e8}}, idle_notifier = {notify = 0x555555effa09 <block_job_on_idle_locked>, node = {le_next = 0x0,
+     *         le_prev = 0x5555581d10f0}}, nodes = 0x555558056ba0 = {0x55555740f920}}, target = 0x555557dccfd0, mirror_top_bs = 0x555558084210,
+     *   base = 0x0, base_overlay = 0x0, replaces = 0x0, to_replace = 0x0, replace_blocker = 0x0, is_none_mode = false,
+     *   backing_mode = MIRROR_SOURCE_BACKING_CHAIN, zero_target = false, copy_mode = MIRROR_COPY_MODE_BACKGROUND,
+     *   on_source_error = BLOCKDEV_ON_ERROR_REPORT, on_target_error = BLOCKDEV_ON_ERROR_REPORT, actively_synced = false, should_complete = false,
+     *   granularity = 0, buf_size = 0, bdev_length = 0, cow_bitmap = 0x0, dirty_bitmap = 0x0, dbi = 0x0, buf = 0x0, buf_free = {sqh_first = 0x0,
+     *     sqh_last = 0x0}, buf_free_count = 0, last_pause_ns = 0, in_flight_bitmap = 0x0, in_flight = 0, bytes_in_flight = 0, ops_in_flight = {
+     *     tqh_first = 0x0, tqh_circ = {tql_next = 0x0, tql_prev = 0x0}}, ret = 0, unmap = false, target_cluster_size = 0, max_iov = 0,
+     *   initial_zeroing_ongoing = false, in_active_write_counter = 0, active_write_bytes_in_flight = 0, prepared = false, in_drain = false}
+     */
     if (ret < 0) {
         goto fail;
     }
@@ -1864,6 +2210,11 @@ static BlockJob *mirror_start_job(
          * ensure that. */
         blk_set_force_allow_inactivate(s->target);
     }
+    /*
+     * 如果这样怎么办???
+     * (gdb) p s.target->allow_aio_context_change
+     * $19 = false
+     */
     blk_set_allow_aio_context_change(s->target, true);
     blk_set_disable_request_queuing(s->target, true);
 
@@ -1885,6 +2236,16 @@ static BlockJob *mirror_start_job(
     }
     bdrv_graph_rdunlock_main_loop();
 
+    /*
+     * typedef struct MirrorBlockJob {
+     *     BlockJob common;
+     *     BlockBackend *target;
+     *     BlockDriverState *mirror_top_bs;
+     *     BlockDriverState *base;
+     *     BlockDriverState *base_overlay;
+     *
+     * char *replaces;
+     */
     s->dirty_bitmap = bdrv_create_dirty_bitmap(s->mirror_top_bs, granularity,
                                                NULL, errp);
     if (!s->dirty_bitmap) {
@@ -1898,6 +2259,18 @@ static BlockJob *mirror_start_job(
     bdrv_disable_dirty_bitmap(s->dirty_bitmap);
 
     bdrv_graph_wrlock();
+    /*
+     * bs     :
+     *   - filename = "/tmp/overlay01.qcow2"i,
+     *   - exact_filename = "/tmp/overlay01.qcow2"
+     *   - backing_file = "test01.qcow2"
+     *   - auto_backing_file = "test01.qcow2"
+     * target :
+     *   - filename = "test01.qcow2"
+     *   - exact_filename = "test01.qcow2"
+     *   - backing_file = 0
+     *   - auto_backing_file = 0
+     */
     ret = block_job_add_bdrv(&s->common, "source", bs, 0,
                              BLK_PERM_WRITE_UNCHANGED | BLK_PERM_WRITE |
                              BLK_PERM_CONSISTENT_READ,
@@ -1907,6 +2280,19 @@ static BlockJob *mirror_start_job(
         goto fail;
     }
 
+    /*
+     * called by:
+     *   - block/backup.c|500| <<backup_job_create>> block_job_add_bdrv(&job->common, "target", target, 0, BLK_PERM_ALL,
+     *   - block/commit.c|373| <<commit_start>> ret = block_job_add_bdrv(&s->common, "intermediate node", iter, 0,
+     *   - block/commit.c|387| <<commit_start>> ret = block_job_add_bdrv(&s->common, "base", base, 0, BLK_PERM_ALL, errp);
+     *   - block/mirror.c|2017| <<mirror_start_job>> ret = block_job_add_bdrv(&s->common, "source", bs, 0,
+     *   - block/mirror.c|2027| <<mirror_start_job>> block_job_add_bdrv(&s->common, "target", target, 0, BLK_PERM_ALL,
+     *   - block/mirror.c|2064| <<mirror_start_job>> ret = block_job_add_bdrv(&s->common, "intermediate node", iter, 0,
+     *   - block/stream.c|377| <<stream_start>> if (block_job_add_bdrv(&s->common, "active node", bs, 0,
+     *   - block/stream.c|396| <<stream_start>> ret = block_job_add_bdrv(&s->common, "intermediate node", iter, 0,
+     *   - blockjob.c|537| <<block_job_create>> ret = block_job_add_bdrv(job, "main node", bs, perm, shared_perm, errp);
+     *   - tests/unit/test-bdrv-drain.c|774| <<test_blockjob_common_drain_node>> block_job_add_bdrv(job, "target", target, 0, BLK_PERM_ALL, &error_abort);
+     */
     /* Required permissions are already taken with blk_new() */
     block_job_add_bdrv(&s->common, "target", target, 0, BLK_PERM_ALL,
                        &error_abort);
@@ -1963,11 +2349,29 @@ static BlockJob *mirror_start_job(
     QTAILQ_INIT(&s->ops_in_flight);
 
     trace_mirror_start(bs, s, opaque);
+    /*
+     * (gdb) p s->common.job
+     * $9 = {id = 0x555557d672c0 "jobA", driver = 0x555556f73c00 <commit_active_job_driver>, co = 0x7ffdd0014160, auto_finalize = true,
+     *   auto_dismiss = true, cb = 0x0, opaque = 0x0, progress = {current = 0, total = 0, lock = {lock = {__data = {__lock = 0, __count = 0,
+     *           __owner = 0, __nusers = 0, __kind = 0, __spins = 0, __elision = 0, __list = {__prev = 0x0, __next = 0x0}},
+     *         __size = '\000' <repeats 39 times>, __align = 0}, file = 0x0, line = 0, initialized = true}}, aio_context = 0x5555573fd610, refcnt = 1,
+     *   status = JOB_STATUS_RUNNING, sleep_timer = {expire_time = -1, timer_list = 0x55555716e450, cb = 0x555555f01fd7 <job_sleep_timer_cb>,
+     *     opaque = 0x5555581d1000, next = 0x0, attributes = 0, scale = 1}, pause_count = 0, busy = true, paused = false, user_paused = false,
+     *   cancelled = false, force_cancel = false, deferred_to_main_loop = false, ret = 0, err = 0x0, on_finalize_cancelled = {notifiers = {lh_first =
+     *     0x5555581d1198}}, on_finalize_completed = {notifiers = {lh_first = 0x5555581d11b0}}, on_pending = {notifiers = {lh_first =
+     *     0x5555581d11c8}}, on_ready = {notifiers = {lh_first = 0x5555581d11e0}}, on_idle = {notifiers = {lh_first = 0x5555581d11f8}}, job_list = {
+     *     le_next = 0x0, le_prev = 0x5555570ace58 <jobs>}, txn = 0x555557eb1f40, txn_list = {le_next = 0x0, le_prev = 0x555557eb1f48}}
+     *
+     * 只要是job->driver->run(job, &job->err)???? --> mirror_run()
+     */
     job_start(&s->common.job);
 
     return &s->common;
 
 fail:
+    /*
+     * MirrorBlockJob *s;
+     */
     if (s) {
         /* Make sure this BDS does not go away until we have completed the graph
          * changes below */
@@ -1986,8 +2390,42 @@ fail:
     bdrv_drained_begin(bs);
     bdrv_graph_wrlock();
     assert(mirror_top_bs->backing->bs == bs);
+    /*
+     * called by:
+     *   - block/crypto.c|916| <<block_crypto_amend_prepare>> ret = bdrv_child_refresh_perms(bs, bs->file, errp);
+     *   - block/crypto.c|932| <<block_crypto_amend_cleanup>> bdrv_child_refresh_perms(bs, bs->file, &errp);
+     *   - block/mirror.c|721| <<mirror_exit_common>> bdrv_child_refresh_perms(mirror_top_bs, mirror_top_bs->backing,
+     *   - block/mirror.c|2258| <<mirror_start_job>> bdrv_child_refresh_perms(mirror_top_bs, mirror_top_bs->backing,
+     *   - block/preallocate.c|540| <<preallocate_drop_resize>> bdrv_child_refresh_perms(bs, bs->file, NULL);
+     *   - block/qcow2.c|1674| <<qcow2_do_open>> bdrv_child_refresh_perms(bs, bs->file, &error_abort);
+     *   - block/vmdk.c|1381| <<vmdk_open>> bdrv_child_refresh_perms(bs, bs->file, &error_abort);
+     *   - tests/unit/test-bdrv-graph-mod.c|386| <<test_parallel_perm_update>> bdrv_child_refresh_perms(top, top->children.lh_first, &error_abort);
+     *   - tests/unit/test-bdrv-graph-mod.c|393| <<test_parallel_perm_update>> bdrv_child_refresh_perms(top, top->children.lh_first, &error_abort);
+     *   - tests/unit/test-bdrv-graph-mod.c|400| <<test_parallel_perm_update>> bdrv_child_refresh_perms(top, top->children.lh_first, &error_abort);
+     */
     bdrv_child_refresh_perms(mirror_top_bs, mirror_top_bs->backing,
                              &error_abort);
+    /*
+     * bs     :
+     *   - filename = "/tmp/overlay01.qcow2"i,
+     *   - exact_filename = "/tmp/overlay01.qcow2"
+     *   - backing_file = "test01.qcow2"
+     *   - auto_backing_file = "test01.qcow2"
+     * target :
+     *   - filename = "test01.qcow2"
+     *   - exact_filename = "test01.qcow2"
+     *   - backing_file = 0
+     *   - auto_backing_file = 0
+     *
+     * called by:
+     *   - block.c|5709| <<bdrv_insert_node>> ret = bdrv_replace_node(bs, new_node_bs, errp);
+     *   - block/commit.c|106| <<commit_abort>> bdrv_replace_node(s->commit_top_bs, commit_top_backing_bs, &error_abort);
+     *   - block/commit.c|442| <<commit_start>> bdrv_replace_node(commit_top_bs, top, &error_abort);
+     *   - block/mirror.c|766| <<mirror_exit_common>> bdrv_replace_node(to_replace, target_bs, &local_err);
+     *   - block/mirror.c|794| <<mirror_exit_common>> bdrv_replace_node(mirror_top_bs, mirror_top_bs->backing->bs, &error_abort);
+     *   - block/mirror.c|2029| <<mirror_start_job>> bdrv_replace_node(mirror_top_bs, bs, &error_abort);
+     *   - blockdev.c|1546| <<external_snapshot_abort>> bdrv_replace_node(state->new_bs, state->old_bs, &error_abort);
+     */
     bdrv_replace_node(mirror_top_bs, bs, &error_abort);
     bdrv_graph_wrunlock();
     bdrv_drained_end(bs);
@@ -2032,6 +2470,131 @@ void mirror_start(const char *job_id, BlockDriverState *bs,
                      filter_node_name, true, copy_mode, errp);
 }
 
+/*
+ * [0] qemu_lock_fd  
+ * [0] raw_handle_perm_lock
+ * [0] raw_check_perm
+ * [0] bdrv_drv_set_perm
+ * [0] bdrv_node_refresh_perm
+ * [0] bdrv_list_refresh_perms
+ * [0] bdrv_replace_node_common
+ * [0] mirror_start_job
+ * [0] commit_active_start
+ * [0] qmp_block_commit
+ * [0] qmp_marshal_block_commit
+ * [0] do_qmp_dispatch_bh     
+ * [0] aio_bh_poll
+ * [0] aio_dispatch           
+ * [0] aio_ctx_dispatch       
+ * [0] g_main_context_dispatch
+ * [0] glib_pollfds_poll      
+ * [0] os_host_main_loop_wait 
+ * [0] main_loop_wait
+ * [0] qemu_main_loop
+ * [0] qemu_default_main
+ * [0] __libc_start_main
+ * [0] _start
+ *
+ * (gdb) bt
+ * #0  commit_active_start (job_id=0x555557400e10 "jobA", bs=0x555557eb20d0, base=0x555557407880, creation_flags=0, speed=0,
+ *     on_error=BLOCKDEV_ON_ERROR_REPORT, filter_node_name=0x0, cb=0x0, opaque=0x0, auto_complete=false, errp=0x7fffffffd558)
+ *     at ../block/mirror.c:2042
+ * #1  0x0000555555edf260 in qmp_block_commit (job_id=0x555557400e10 "jobA", device=0x555557400d70 "over01",
+ *     base_node=0x0, base=0x0, top_node=0x0, top=0x0, backing_file=0x0, has_backing_mask_protocol=false,
+ *     backing_mask_protocol=false, has_speed=false, speed=0, has_on_error=false, on_error=BLOCKDEV_ON_ERROR_REPORT,
+ *     filter_node_name=0x0, has_auto_finalize=false, auto_finalize=false, has_auto_dismiss=false, auto_dismiss=false,
+ *     errp=0x7fffffffd688) at ../blockdev.c:2597
+ * #2  0x0000555556010f4a in qmp_marshal_block_commit (args=0x7fffd8005c90, ret=0x7ffff7f9eda8, errp=0x7ffff7f9eda0)
+ *     at qapi/qapi-commands-block-core.c:408
+ * #3  0x00005555560a4413 in do_qmp_dispatch_bh (opaque=0x7ffff7f9ee40) at ../qapi/qmp-dispatch.c:128
+ * #4  0x00005555560d3305 in aio_bh_call (bh=0x555557e6cfc0) at ../util/async.c:171
+ * #5  0x00005555560d3453 in aio_bh_poll (ctx=0x555557169480) at ../util/async.c:218
+ * #6  0x00005555560b2a26 in aio_dispatch (ctx=0x555557169480) at ../util/aio-posix.c:423
+ * #7  0x00005555560d3922 in aio_ctx_dispatch (source=0x555557169480, callback=0x0, user_data=0x0) at ../util/async.c:360
+ * #8  0x00007ffff6c53aed in g_main_context_dispatch () at /lib/../lib64/libglib-2.0.so.0
+ * #9  0x00005555560d4ff3 in glib_pollfds_poll () at ../util/main-loop.c:287
+ * #10 0x00005555560d5081 in os_host_main_loop_wait (timeout=0) at ../util/main-loop.c:310
+ * #11 0x00005555560d51b0 in main_loop_wait (nonblocking=0) at ../util/main-loop.c:589
+ * #12 0x0000555555bc3abf in qemu_main_loop () at ../system/runstate.c:783
+ * #13 0x0000555555e8a1bb in qemu_default_main () at ../system/main.c:37
+ * #14 0x0000555555e8a1f8 in main (argc=32, argv=0x7fffffffdaf8) at ../system/main.c:48
+ *
+ * (gdb) p *bs
+ * $3 = {open_flags = 8226, encrypted = false, sg = false, probed = false, force_share = false, implicit = false,
+ *   drv = 0x55555705acc0 <bdrv_qcow2>, opaque = 0x5555580f2200, aio_context = 0x5555573fd610, aio_notifiers = {lh_first = 0x0},
+ *   walking_aio_notifiers = false, filename = "/tmp/overlay01.qcow2", '\000' <repeats 4075 times>,
+ *   backing_file = "test01.qcow2", '\000' <repeats 4083 times>, auto_backing_file = "test01.qcow2", '\000' <repeats 4083 times>,
+ *   backing_format = "qcow2\000\000\000\000\000\000\000\000\000\000", full_open_options = 0x0,
+ *   exact_filename = "/tmp/overlay01.qcow2", '\000' <repeats 4075 times>, bl = {request_alignment = 1, max_pdiscard = 0,
+ *     pdiscard_alignment = 65536, max_pwrite_zeroes = 0, pwrite_zeroes_alignment = 65536, opt_transfer = 0, max_transfer = 0,
+ *     max_hw_transfer = 0, max_hw_iov = 0, min_mem_alignment = 512, opt_mem_alignment = 4096, max_iov = 1024, has_variable_length = false,
+ *     zoned = BLK_Z_NONE, zone_size = 0, nr_zones = 0, max_append_sectors = 0, max_open_zones = 0, max_active_zones = 0, write_granularity = 0},
+ *   supported_read_flags = BDRV_REQ_REGISTERED_BUF, supported_write_flags = BDRV_REQ_REGISTERED_BUF, supported_zero_flags = 260,
+ *   supported_truncate_flags = BDRV_REQ_ZERO_WRITE, node_name = "over01", '\000' <repeats 25 times>, node_list = {tqe_next = 0x0, tqe_circ = {
+ *       tql_next = 0x0, tql_prev = 0x5555574aeda8}}, bs_list = {tqe_next = 0x5555574aacb0, tqe_circ = {tql_next = 0x5555574aacb0,
+ *       tql_prev = 0x55555742c558}}, monitor_list = {tqe_next = 0x0, tqe_circ = {tql_next = 0x0, tql_prev = 0x0}}, refcnt = 1, op_blockers = {{
+ *       lh_first = 0x0} <repeats 16 times>}, inherits_from = 0x0, children = {lh_first = 0x555557fe1110}, backing = 0x555557fe1110,
+ *   file = 0x7fffdc1b67a0, parents = {lh_first = 0x55555807cab0}, options = 0x555557491e00, explicit_options = 0x555557dcbfb0,
+ *   detect_zeroes = BLOCKDEV_DETECT_ZEROES_OPTIONS_OFF, backing_blocker = 0x555557726bf0, total_sectors = 20971520, write_threshold_offset = 0,
+ *   dirty_bitmap_mutex = {lock = {__data = {__lock = 0, __count = 0, __owner = 0, __nusers = 0, __kind = 0, __spins = 0, __elision = 0, __list = {
+ *           __prev = 0x0, __next = 0x0}}, __size = '\000' <repeats 39 times>, __align = 0}, file = 0x0, line = 0, initialized = true},
+ *   dirty_bitmaps = {lh_first = 0x0}, wr_highest_offset = {value = 0}, copy_on_read = 0, in_flight = 0, serialising_in_flight = 0,
+ *   enable_write_cache = 0, quiesce_counter = 0, write_gen = 0, reqs_lock = {lock = {__data = {__lock = 0, __count = 0, __owner = 0,
+ *         __nusers = 0, __kind = 0, __spins = 0, __elision = 0, __list = {__prev = 0x0, __next = 0x0}}, __size = '\000' <repeats 39 times>,
+ *       __align = 0}, file = 0x0, line = 0, initialized = true}, tracked_requests = {lh_first = 0x0}, flush_queue = {entries = {sqh_first = 0x0,
+ *       sqh_last = 0x555557eb6378}}, active_flush_req = false, flushed_gen = 0, never_freeze = false, bsc_modify_lock = {locked = 0, ctx = 0x0,
+ *     from_push = {slh_first = 0x0}, to_pop = {slh_first = 0x0}, handoff = 0, sequence = 0, holder = 0x0}, block_status_cache = 0x5555574010d0,
+ *   wps = 0x0}
+ *
+ * (gdb) p *base
+ * $4 = {open_flags = 8224, encrypted = false, sg = false, probed = false, force_share = false, implicit = false,
+ *   drv = 0x55555705acc0 <bdrv_qcow2>, opaque = 0x55555740f250, aio_context = 0x5555573fd610, aio_notifiers = {lh_first = 0x0},
+ *   walking_aio_notifiers = false, filename = "test01.qcow2", '\000' <repeats 4083 times>, backing_file = '\000' <repeats 4095 times>,
+ *   auto_backing_file = '\000' <repeats 4095 times>, backing_format = '\000' <repeats 15 times>, full_open_options = 0x555557503200,
+ *   exact_filename = "test01.qcow2", '\000' <repeats 4083 times>, bl = {request_alignment = 1, max_pdiscard = 0, pdiscard_alignment = 65536,
+ *     max_pwrite_zeroes = 0, pwrite_zeroes_alignment = 65536, opt_transfer = 0, max_transfer = 0, max_hw_transfer = 0, max_hw_iov = 0,
+ *     min_mem_alignment = 512, opt_mem_alignment = 4096, max_iov = 1024, has_variable_length = false, zoned = BLK_Z_NONE, zone_size = 0,
+ *     nr_zones = 0, max_append_sectors = 0, max_open_zones = 0, max_active_zones = 0, write_granularity = 0},
+ *   supported_read_flags = BDRV_REQ_REGISTERED_BUF, supported_write_flags = BDRV_REQ_REGISTERED_BUF, supported_zero_flags = 260,
+ *   supported_truncate_flags = BDRV_REQ_ZERO_WRITE, node_name = "drive01", '\000' <repeats 24 times>, node_list = {tqe_next = 0x555557428450,
+ *     tqe_circ = {tql_next = 0x555557428450, tql_prev = 0x555557405628}}, bs_list = {tqe_next = 0x5555574210e0, tqe_circ = {
+ *       tql_next = 0x5555574210e0, tql_prev = 0x555557405638}}, monitor_list = {tqe_next = 0x0, tqe_circ = {tql_next = 0x0,
+ *       tql_prev = 0x555557405648}}, refcnt = 2, op_blockers = {{lh_first = 0x0}, {lh_first = 0x0}, {lh_first = 0x555557400580}, {
+ *       lh_first = 0x555557f18ee0}, {lh_first = 0x0}, {lh_first = 0x555557f6c020}, {lh_first = 0x555557e6c7a0}, {lh_first = 0x555557c03f90}, {
+ *       lh_first = 0x555557c03fb0}, {lh_first = 0x555557e6dfc0}, {lh_first = 0x555557e6dfe0}, {lh_first = 0x5555575da640}, {
+ *       lh_first = 0x5555575da660}, {lh_first = 0x5555577442b0}, {lh_first = 0x0}, {lh_first = 0x555557761e90}}, inherits_from = 0x0, children = {
+ *     lh_first = 0x555557400fe0}, backing = 0x0, file = 0x555557400fe0, parents = {lh_first = 0x555557fe1110}, options = 0x555557504220,
+ *   explicit_options = 0x555557a68880, detect_zeroes = BLOCKDEV_DETECT_ZEROES_OPTIONS_OFF, backing_blocker = 0x0, total_sectors = 20971520,
+ *   write_threshold_offset = 0, dirty_bitmap_mutex = {lock = {__data = {__lock = 0, __count = 0, __owner = 0, __nusers = 0, __kind = 0,
+ *         __spins = 0, __elision = 0, __list = {__prev = 0x0, __next = 0x0}}, __size = '\000' <repeats 39 times>, __align = 0}, file = 0x0,
+ *     line = 0, initialized = true}, dirty_bitmaps = {lh_first = 0x0}, wr_highest_offset = {value = 0}, copy_on_read = 0, in_flight = 0,
+ *   serialising_in_flight = 0, enable_write_cache = 0, quiesce_counter = 0, write_gen = 0, reqs_lock = {lock = {__data = {__lock = 0,
+ *         __count = 0, __owner = 0, __nusers = 0, __kind = 0, __spins = 0, __elision = 0, __list = {__prev = 0x0, __next = 0x0}},
+ *       __size = '\000' <repeats 39 times>, __align = 0}, file = 0x0, line = 0, initialized = true}, tracked_requests = {lh_first = 0x0},
+ *   flush_queue = {entries = {sqh_first = 0x0, sqh_last = 0x55555740bb28}}, active_flush_req = false, flushed_gen = 0, never_freeze = false,
+ *   bsc_modify_lock = {locked = 0, ctx = 0x0, from_push = {slh_first = 0x0}, to_pop = {slh_first = 0x0}, handoff = 0, sequence = 0,
+ *     holder = 0x0}, block_status_cache = 0x5555574005d0, wps = 0x0}
+ *
+ * called by:
+ *   - block/replication.c|711| <<replication_stop>> s->commit_job = commit_active_start(NULL, bs->file->bs, s->secondary_disk->bs,
+ *                                    JOB_INTERNAL, 0, BLOCKDEV_ON_ERROR_REPORT, NULL, replication_done, bs, true, errp);
+ *   - blockdev.c|2622| <<qmp_block_commit>> commit_active_start(job_id, top_bs, base_bs, job_flags, speed, on_error,
+ *                                    filter_node_name, NULL, NULL, false, &local_err);
+ *   - qemu-img.c|1080| <<img_commit>> commit_active_start("commit", bs, base_bs, JOB_DEFAULT, rate_limit,
+ *                                    BLOCKDEV_ON_ERROR_REPORT, NULL, common_block_job_cb, &cbi, false, &local_err);
+ *
+ * 两个重要的参数:
+ * bs   :
+ *   - filename = "/tmp/overlay01.qcow2"i,
+ *   - exact_filename = "/tmp/overlay01.qcow2"
+ *   - backing_file = "test01.qcow2"
+ *   - auto_backing_file = "test01.qcow2"
+ * base :
+ *   - filename = "test01.qcow2"
+ *   - exact_filename = "test01.qcow2"
+ *   - backing_file = 0
+ *   - auto_backing_file = 0
+ */
 BlockJob *commit_active_start(const char *job_id, BlockDriverState *bs,
                               BlockDriverState *base, int creation_flags,
                               int64_t speed, BlockdevOnError on_error,
@@ -2052,6 +2615,20 @@ BlockJob *commit_active_start(const char *job_id, BlockDriverState *bs,
         }
     }
 
+    /*
+     * called by:
+     *   - block/mirror.c|2028| <<mirror_start>> mirror_start_job(job_id, bs, creation_flags, target, replaces,
+     *                                                       speed, granularity, buf_size, backing_mode, zero_target,
+     *                                                       on_source_error, on_target_error, unmap, NULL, NULL,
+     *                                                       &mirror_job_driver, is_none_mode, base, false,
+     *                                                       filter_node_name, true, copy_mode, errp);
+     *   - block/mirror.c|2055| <<commit_active_start>> job = mirror_start_job(job_id, bs, creation_flags, base, NULL, speed, 0, 0,
+     *                                                       MIRROR_LEAVE_BACKING_CHAIN, false,
+     *                                                       on_error, on_error, true, cb, opaque,
+     *                                                       &commit_active_job_driver, false, base, auto_complete,
+     *                                                       filter_node_name, false, MIRROR_COPY_MODE_BACKGROUND,
+     *                                                       errp);
+     */
     job = mirror_start_job(
                      job_id, bs, creation_flags, base, NULL, speed, 0, 0,
                      MIRROR_LEAVE_BACKING_CHAIN, false,
diff --git a/block/qcow2-threads.c b/block/qcow2-threads.c
index d6071a1ea..03c3e07a5 100644
--- a/block/qcow2-threads.c
+++ b/block/qcow2-threads.c
@@ -38,6 +38,11 @@
 #include "block/thread-pool.h"
 #include "crypto.h"
 
+/*
+ * called by:
+ *   - block/qcow2-threads.c|350| <<qcow2_co_do_compress>> qcow2_co_process(bs, qcow2_compress_pool_func, &arg);
+ *   - block/qcow2-threads.c|478| <<qcow2_co_encdec>> return len == 0 ? 0 : qcow2_co_process(bs, qcow2_encdec_pool_func, &arg);
+ */
 static int coroutine_fn
 qcow2_co_process(BlockDriverState *bs, ThreadPoolFunc *func, void *arg)
 {
diff --git a/block/qcow2.c b/block/qcow2.c
index 956128b40..73b00efb4 100644
--- a/block/qcow2.c
+++ b/block/qcow2.c
@@ -2272,6 +2272,12 @@ typedef struct Qcow2AioTask {
 } Qcow2AioTask;
 
 static coroutine_fn int qcow2_co_preadv_task_entry(AioTask *task);
+/*
+ * called by:
+ *   - block/qcow2.c|2410| <<qcow2_co_preadv_part>> ret = qcow2_add_task(bs, aio, qcow2_co_preadv_task_entry, type, host_offset, offset, cur_bytes, qiov, qiov_offset, NULL);
+ *   - block/qcow2.c|2709| <<qcow2_co_pwritev_part>> ret = qcow2_add_task(bs, aio, qcow2_co_pwritev_task_entry, 0, host_offset, offset, cur_bytes, qiov, qiov_offset, l2meta);
+ *   - block/qcow2.c|4786| <<qcow2_co_pwritev_compressed_part>> ret = qcow2_add_task(bs, aio, qcow2_co_pwritev_compressed_task_entry, 0, 0, offset, chunk_size, qiov, qiov_offset, NULL);
+ */
 static coroutine_fn int qcow2_add_task(BlockDriverState *bs,
                                        AioTaskPool *pool,
                                        AioTaskFunc func,
diff --git a/block/raw-format.c b/block/raw-format.c
index ac7e8495f..294819fd1 100644
--- a/block/raw-format.c
+++ b/block/raw-format.c
@@ -42,6 +42,11 @@ typedef struct BDRVRawState {
 
 static const char *const mutable_opts[] = { "offset", "size", NULL };
 
+/*
+ * 在以下使用raw_runtime_opts:
+ *   - block/raw-format.c|47| <<global>> .head = QTAILQ_HEAD_INITIALIZER(raw_runtime_opts.head),
+ *   - block/raw-format.c|82| <<raw_read_options>> opts = qemu_opts_create(&raw_runtime_opts, NULL, 0, &error_abort);
+ */
 static QemuOptsList raw_runtime_opts = {
     .name = "raw",
     .head = QTAILQ_HEAD_INITIALIZER(raw_runtime_opts.head),
@@ -185,6 +190,15 @@ static void raw_reopen_abort(BDRVReopenState *state)
     state->opaque = NULL;
 }
 
+/*
+ * called by:
+ *   - block/raw-format.c|220| <<raw_co_preadv>> ret = raw_adjust_offset(bs, &offset, bytes, false);
+ *   - block/raw-format.c|274| <<raw_co_pwritev>> ret = raw_adjust_offset(bs, &offset, bytes, true);
+ *   - block/raw-format.c|308| <<raw_co_pwrite_zeroes>> ret = raw_adjust_offset(bs, &offset, bytes, true);
+ *   - block/raw-format.c|320| <<raw_co_pdiscard>> ret = raw_adjust_offset(bs, &offset, bytes, true);
+ *   - block/raw-format.c|587| <<raw_co_copy_range_from>> ret = raw_adjust_offset(bs, &src_offset, bytes, false);
+ *   - block/raw-format.c|604| <<raw_co_copy_range_to>> ret = raw_adjust_offset(bs, &dst_offset, bytes, true);
+ */
 /* Check and adjust the offset, against 'offset' and 'size' options. */
 static inline int raw_adjust_offset(BlockDriverState *bs, int64_t *offset,
                                     int64_t bytes, bool is_write)
@@ -206,6 +220,26 @@ static inline int raw_adjust_offset(BlockDriverState *bs, int64_t *offset,
     return 0;
 }
 
+/*
+ * #0来自file-posix.c
+ * #5来自raw-format.c
+ * (gdb) bt
+ * #0  raw_co_preadv (bs=0x555557401530, offset=0, bytes=512, qiov=0x7fffe00032b8, flags=BDRV_REQ_REGISTERED_BUF) at ../block/file-posix.c:2571
+ * #1  0x0000555555f35a50 in bdrv_driver_preadv (bs=0x555557401530, offset=0, bytes=512, qiov=0x7fffe00032b8, qiov_offset=0, flags=8) at ../block/io.c:1002
+ * #2  0x0000555555f36d3e in bdrv_aligned_preadv (child=0x55555740e110, req=0x7ffda6e6ea50, offset=0, bytes=512, align=512, qiov=0x7fffe00032b8, qiov_offset=0, flags=8) at ../block/io.c:1395
+ * #3  0x0000555555f37cf5 in bdrv_co_preadv_part (child=0x55555740e110, offset=0, bytes=512, qiov=0x7fffe00032b8, qiov_offset=0, flags=BDRV_REQ_REGISTERED_BUF) at ../block/io.c:1819
+ * #4  0x0000555555f37a85 in bdrv_co_preadv (child=0x55555740e110, offset=0, bytes=512, qiov=0x7fffe00032b8, flags=BDRV_REQ_REGISTERED_BUF) at ../block/io.c:1768
+ * #5  0x0000555555f7f3ac in raw_co_preadv (bs=0x555557407880, offset=0, bytes=512, qiov=0x7fffe00032b8, flags=BDRV_REQ_REGISTERED_BUF) at ../block/raw-format.c:221
+ * #6  0x0000555555f35a50 in bdrv_driver_preadv (bs=0x555557407880, offset=0, bytes=512, qiov=0x7fffe00032b8, qiov_offset=0, flags=8) at ../block/io.c:1002
+ * #7  0x0000555555f36d3e in bdrv_aligned_preadv (child=0x555558069da0, req=0x7ffda6e6eda0, offset=0, bytes=512, align=1, qiov=0x7fffe00032b8, qiov_offset=0, flags=8) at ../block/io.c:1395
+ * #8  0x0000555555f37cf5 in bdrv_co_preadv_part (child=0x555558069da0, offset=0, bytes=512, qiov=0x7fffe00032b8, qiov_offset=0, flags=BDRV_REQ_REGISTERED_BUF) at ../block/io.c:1819
+ * #9  0x0000555555f217fc in blk_co_do_preadv_part (blk=0x5555580ed980, offset=0, bytes=512, qiov=0x7fffe00032b8, qiov_offset=0, flags=BDRV_REQ_REGISTERED_BUF) at ../block/block-backend.c:1347
+ * #10 0x0000555555f22223 in blk_aio_read_entry (opaque=0x7fffe0003360) at ../block/block-backend.c:1608
+ * #11 0x00005555560d8120 in coroutine_trampoline (i0=-536857664, i1=32767) at ../util/coroutine-ucontext.c:175
+ * #12 0x00007ffff4ee1150 in __start_context () at /lib/../lib64/libc.so.6
+ * #13 0x00007fffef4539e0 in  ()
+ * #14 0x0000000000000000 in  ()
+ */
 static int coroutine_fn GRAPH_RDLOCK
 raw_co_preadv(BlockDriverState *bs, int64_t offset, int64_t bytes,
               QEMUIOVector *qiov, BdrvRequestFlags flags)
@@ -218,6 +252,11 @@ raw_co_preadv(BlockDriverState *bs, int64_t offset, int64_t bytes,
     }
 
     BLKDBG_CO_EVENT(bs->file, BLKDBG_READ_AIO);
+    /*
+     * BlockDriverState *bs:
+     * -> BdrvChild * GRAPH_RDLOCK_PTR backing;
+     * -> BdrvChild * GRAPH_RDLOCK_PTR file;
+     */
     return bdrv_co_preadv(bs->file, offset, bytes, qiov, flags);
 }
 
@@ -680,3 +719,63 @@ static void bdrv_raw_init(void)
 }
 
 block_init(bdrv_raw_init);
+
+/*
+ * 在以下使用bdrv_register(参数是BlockDriver)
+ *   - block/blkdebug.c|1104| <<bdrv_blkdebug_init>> bdrv_register(&bdrv_blkdebug);
+ *   - block/blkio.c|1145| <<bdrv_blkio_init>> bdrv_register(&bdrv_io_uring);
+ *   - block/blkio.c|1146| <<bdrv_blkio_init>> bdrv_register(&bdrv_nvme_io_uring);
+ *   - block/blkio.c|1147| <<bdrv_blkio_init>> bdrv_register(&bdrv_virtio_blk_vfio_pci);
+ *   - block/blkio.c|1148| <<bdrv_blkio_init>> bdrv_register(&bdrv_virtio_blk_vhost_user);
+ *   - block/blkio.c|1149| <<bdrv_blkio_init>> bdrv_register(&bdrv_virtio_blk_vhost_vdpa);
+ *   - block/blklogwrites.c|612| <<bdrv_blk_log_writes_init>> bdrv_register(&bdrv_blk_log_writes);
+ *   - block/blkreplay.c|163| <<bdrv_blkreplay_init>> bdrv_register(&bdrv_blkreplay);
+ *   - block/blkverify.c|341| <<bdrv_blkverify_init>> bdrv_register(&bdrv_blkverify);
+ *   - block/bochs.c|316| <<bdrv_bochs_init>> bdrv_register(&bdrv_bochs);
+ *   - block/cloop.c|312| <<bdrv_cloop_init>> bdrv_register(&bdrv_cloop);
+ *   - block/copy-before-write.c|562| <<cbw_init>> bdrv_register(&bdrv_cbw_filter);
+ *   - block/copy-on-read.c|293| <<bdrv_copy_on_read_init>> bdrv_register(&bdrv_copy_on_read);
+ *   - block/crypto.c|1098| <<block_crypto_init>> bdrv_register(&bdrv_crypto_luks);
+ *   - block/curl.c|1109| <<curl_block_init>> bdrv_register(&bdrv_http);
+ *   - block/curl.c|1110| <<curl_block_init>> bdrv_register(&bdrv_https);
+ *   - block/curl.c|1111| <<curl_block_init>> bdrv_register(&bdrv_ftp);
+ *   - block/curl.c|1112| <<curl_block_init>> bdrv_register(&bdrv_ftps);
+ *   - block/dmg.c|798| <<bdrv_dmg_init>> bdrv_register(&bdrv_dmg);
+ *   - block/file-posix.c|4746| <<bdrv_file_init>> bdrv_register(&bdrv_file);
+ *   - block/file-posix.c|4748| <<bdrv_file_init>> bdrv_register(&bdrv_host_device);
+ *   - block/file-posix.c|4750| <<bdrv_file_init>> bdrv_register(&bdrv_host_cdrom);
+ *   - block/file-posix.c|4753| <<bdrv_file_init>> bdrv_register(&bdrv_host_cdrom);
+ *   - block/file-win32.c|940| <<bdrv_file_init>> bdrv_register(&bdrv_file);
+ *   - block/file-win32.c|941| <<bdrv_file_init>> bdrv_register(&bdrv_host_device);
+ *   - block/filter-compress.c|157| <<bdrv_compress_init>> bdrv_register(&bdrv_compress);
+ *   - block/gluster.c|1678| <<bdrv_gluster_init>> bdrv_register(&bdrv_gluster_rdma);
+ *   - block/gluster.c|1679| <<bdrv_gluster_init>> bdrv_register(&bdrv_gluster_unix);
+ *   - block/gluster.c|1680| <<bdrv_gluster_init>> bdrv_register(&bdrv_gluster_tcp);
+ *   - block/gluster.c|1681| <<bdrv_gluster_init>> bdrv_register(&bdrv_gluster);
+ *   - block/iscsi.c|2506| <<iscsi_block_init>> bdrv_register(&bdrv_iscsi);
+ *   - block/iscsi.c|2508| <<iscsi_block_init>> bdrv_register(&bdrv_iser);
+ *   - block/nbd.c|2230| <<bdrv_nbd_init>> bdrv_register(&bdrv_nbd);
+ *   - block/nbd.c|2231| <<bdrv_nbd_init>> bdrv_register(&bdrv_nbd_tcp);
+ *   - block/nbd.c|2232| <<bdrv_nbd_init>> bdrv_register(&bdrv_nbd_unix);
+ *   - block/nfs.c|917| <<nfs_block_init>> bdrv_register(&bdrv_nfs);
+ *   - block/null.c|325| <<bdrv_null_init>> bdrv_register(&bdrv_null_co);
+ *   - block/null.c|326| <<bdrv_null_init>> bdrv_register(&bdrv_null_aio);
+ *   - block/nvme.c|1662| <<bdrv_nvme_init>> bdrv_register(&bdrv_nvme);
+ *   - block/parallels.c|1482| <<bdrv_parallels_init>> bdrv_register(&bdrv_parallels);
+ *   - block/preallocate.c|624| <<bdrv_preallocate_init>> bdrv_register(&bdrv_preallocate_filter);
+ *   - block/qcow.c|1215| <<bdrv_qcow_init>> bdrv_register(&bdrv_qcow);
+ *   - block/qcow2.c|6203| <<bdrv_qcow2_init>> bdrv_register(&bdrv_qcow2);
+ *   - block/qed.c|1678| <<bdrv_qed_init>> bdrv_register(&bdrv_qed);
+ *   - block/quorum.c|1315| <<bdrv_quorum_init>> bdrv_register(&bdrv_quorum);
+ *   - block/raw-format.c|679| <<bdrv_raw_init>> bdrv_register(&bdrv_raw);
+ *   - block/rbd.c|1852| <<bdrv_rbd_init>> bdrv_register(&bdrv_rbd);
+ *   - block/replication.c|748| <<bdrv_replication_init>> bdrv_register(&bdrv_replication);
+ *   - block/snapshot-access.c|132| <<snapshot_access_init>> bdrv_register(&bdrv_snapshot_access_drv);
+ *   - block/ssh.c|1390| <<bdrv_ssh_init>> bdrv_register(&bdrv_ssh);
+ *   - block/throttle.c|276| <<bdrv_throttle_init>> bdrv_register(&bdrv_throttle);
+ *   - block/vdi.c|1063| <<bdrv_vdi_init>> bdrv_register(&bdrv_vdi);
+ *   - block/vhdx.c|2270| <<bdrv_vhdx_init>> bdrv_register(&bdrv_vhdx);
+ *   - block/vmdk.c|3179| <<bdrv_vmdk_init>> bdrv_register(&bdrv_vmdk);
+ *   - block/vpc.c|1254| <<bdrv_vpc_init>> bdrv_register(&bdrv_vpc);
+ *   - block/vvfat.c|3277| <<bdrv_vvfat_init>> bdrv_register(&bdrv_vvfat);
+ */
diff --git a/blockdev.c b/blockdev.c
index 057601dcf..63414ef3a 100644
--- a/blockdev.c
+++ b/blockdev.c
@@ -64,6 +64,12 @@
 #include "qemu/main-loop.h"
 #include "qemu/throttle-options.h"
 
+/*
+ * 这个文档:
+ * A Practical Look at QEMU's Block Layer Primitives
+ * https://kashyapc.fedorapeople.org/virt/LinuxCon-NA-2016/A-Practical-Look-at-QEMU-Block-Layer-Primitives-LC-NA-2016.pdf
+ */
+
 /* Protected by BQL */
 QTAILQ_HEAD(, BlockDriverState) monitor_bdrv_states =
     QTAILQ_HEAD_INITIALIZER(monitor_bdrv_states);
@@ -475,6 +481,10 @@ static OnOffAuto account_get_opt(QemuOpts *opts, const char *name)
     return ON_OFF_AUTO_OFF;
 }
 
+/*
+ * called by:
+ *   - blockdev.c|1006| <<drive_new>> blk = blockdev_init(filename, bs_opts, errp);
+ */
 /* Takes the ownership of bs_opts */
 static BlockBackend *blockdev_init(const char *file, QDict *bs_opts,
                                    Error **errp)
@@ -659,6 +669,11 @@ err_no_opts:
     return NULL;
 }
 
+/*
+ * called by:
+ *   - block/monitor/block-hmp-cmds.c|80| <<hmp_drive_add_node>> BlockDriverState *bs = bds_tree_init(qdict, &local_err);
+ *   - blockdev.c|3537| <<qmp_blockdev_add>> bs = bds_tree_init(qdict, errp);
+ */
 /* Takes the ownership of bs_opts */
 BlockDriverState *bds_tree_init(QDict *bs_opts, Error **errp)
 {
@@ -772,6 +787,12 @@ QemuOptsList qemu_legacy_drive_opts = {
     },
 };
 
+/*
+ * called by:
+ *   - block/monitor/block-hmp-cmds.c|110| <<hmp_drive_add>> dinfo = drive_new(opts, mc->block_default_type, &err);
+ *   - system/vl.c|648| <<drive_init_func>> return drive_new(opts, *block_default_type, errp) == NULL;
+ *   - system/vl.c|674| <<default_drive>> dinfo = drive_new(opts, type, &error_abort);
+ */
 DriveInfo *drive_new(QemuOpts *all_opts, BlockInterfaceType block_default_type,
                      Error **errp)
 {
@@ -1036,6 +1057,15 @@ fail:
     return dinfo;
 }
 
+/*
+ * called by:
+ *   - blockdev.c|1137| <<qmp_blockdev_snapshot_delete_internal_sync>> bs = qmp_get_root_bs(device, errp);
+ *   - blockdev.c|1221| <<internal_snapshot_action>> bs = qmp_get_root_bs(device, errp);
+ *   - blockdev.c|2521| <<qmp_block_commit>> bs = qmp_get_root_bs(device, &local_err);
+ *   - blockdev.c|2971| <<qmp_drive_mirror>> bs = qmp_get_root_bs(arg->device, errp);
+ *   - blockdev.c|3135| <<qmp_blockdev_mirror>> bs = qmp_get_root_bs(device, errp);
+ *   - blockdev.c|3333| <<qmp_change_backing_file>> bs = qmp_get_root_bs(device, errp);
+ */
 static BlockDriverState *qmp_get_root_bs(const char *name, Error **errp)
 {
     BlockDriverState *bs;
@@ -1060,15 +1090,39 @@ static BlockDriverState *qmp_get_root_bs(const char *name, Error **errp)
     return bs;
 }
 
+/*
+ * called by:
+ *   - blockdev.c|1110| <<qmp_blockdev_snapshot_sync>> blockdev_do_action(&action, errp);
+ *   - blockdev.c|1124| <<qmp_blockdev_snapshot>> blockdev_do_action(&action, errp);
+ *   - blockdev.c|1139| <<qmp_blockdev_snapshot_internal_sync>> blockdev_do_action(&action, errp);
+ *   - blockdev.c|2887| <<qmp_drive_backup>> blockdev_do_action(&action, errp);
+ *   - blockdev.c|2912| <<qmp_blockdev_backup>> blockdev_do_action(&action, errp);
+ */
 static void blockdev_do_action(TransactionAction *action, Error **errp)
 {
     TransactionActionList list;
 
     list.value = action;
     list.next = NULL;
+    /*
+     * 只在此处调用
+     */
     qmp_transaction(&list, NULL, errp);
 }
 
+/*
+ * -object iothread,id=iothread01 \
+ * -device virtio-blk-pci,id=vblk01,num-queues=8,drive=drive01,iothread=iothread01 \
+ * -blockdev node-name=file01,driver=file,aio=threads,filename=test01.qcow2,cache.direct=on,cache.no-flush=off \
+ * -blockdev node-name=drive01,driver=qcow2,cache.direct=on,cache.no-flush=off,file=file01 \
+ *
+ * # blockdev-snapshot-sync node-name=drive01 snapshot-file=/tmp/overlay01.qcow2 snapshot-node-name=over01
+ * # block-commit device=over01 job-id=jobA
+ * # block-job-complete device=jobA
+ *
+ * called by:
+ *   - block/monitor/block-hmp-cmds.c|357| <<hmp_snapshot_blkdev>> qmp_blockdev_snapshot_sync(device, NULL, filename, NULL, format,
+ */
 void qmp_blockdev_snapshot_sync(const char *device, const char *node_name,
                                 const char *snapshot_file,
                                 const char *snapshot_node_name,
@@ -1084,10 +1138,32 @@ void qmp_blockdev_snapshot_sync(const char *device, const char *node_name,
         .has_mode = has_mode,
         .mode = mode,
     };
+    /*
+     * 在以下使用TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT_SYNC:
+     *   - blockdev.c|1141| <<qmp_blockdev_snapshot_sync>> .type = TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT_SYNC,
+     *   - blockdev.c|1469| <<external_snapshot_action>> case TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT_SYNC:
+     *   - blockdev.c|1510| <<external_snapshot_action>> if (action->type == TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT_SYNC) {
+     *   - blockdev.c|2213| <<transaction_action>> case TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT_SYNC:
+     *
+     *
+     * 28 typedef struct TransactionAction {
+     * 29     TransactionActionDrv *drv;
+     * 30     void *opaque;
+     * 31     QSLIST_ENTRY(TransactionAction) entry;
+     * 32 } TransactionAction;
+     */
     TransactionAction action = {
         .type = TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT_SYNC,
         .u.blockdev_snapshot_sync.data = &snapshot,
     };
+    /*
+     * called by:
+     *   - blockdev.c|1110| <<qmp_blockdev_snapshot_sync>> blockdev_do_action(&action, errp);
+     *   - blockdev.c|1124| <<qmp_blockdev_snapshot>> blockdev_do_action(&action, errp);
+     *   - blockdev.c|1139| <<qmp_blockdev_snapshot_internal_sync>> blockdev_do_action(&action, errp);
+     *   - blockdev.c|2887| <<qmp_drive_backup>> blockdev_do_action(&action, errp);
+     *   - blockdev.c|2912| <<qmp_blockdev_backup>> blockdev_do_action(&action, errp);
+     */
     blockdev_do_action(&action, errp);
 }
 
@@ -1321,6 +1397,17 @@ static void internal_snapshot_clean(void *opaque)
     bdrv_drained_end(state->bs);
 }
 
+/*
+ * 在以下使用ExternalSnapshotState->overlay_appended:
+ *   - blockdev.c|1681| <<external_snapshot_action>> state->overlay_appended = true;
+ *   - blockdev.c|1700| <<external_snapshot_abort>> if (state->overlay_appended) {
+ *
+ * typedef struct ExternalSnapshotState {
+ *     BlockDriverState *old_bs;
+ *     BlockDriverState *new_bs;
+ *     bool overlay_appended;
+ * } ExternalSnapshotState;
+ */
 /* external snapshot private data */
 typedef struct ExternalSnapshotState {
     BlockDriverState *old_bs;
@@ -1331,12 +1418,61 @@ typedef struct ExternalSnapshotState {
 static void external_snapshot_commit(void *opaque);
 static void external_snapshot_abort(void *opaque);
 static void external_snapshot_clean(void *opaque);
+/*
+ * 在以下使用external_snapshot_drv:
+ *   - blockdev.c|1408| <<external_snapshot_action>> tran_add(tran, &external_snapshot_drv, state);
+ */
 TransactionActionDrv external_snapshot_drv = {
     .commit = external_snapshot_commit,
     .abort = external_snapshot_abort,
     .clean = external_snapshot_clean,
 };
 
+/*
+ * BlockdevSnapshotSync snapshot = {
+ *     .device = (char *) device,
+ *     .node_name = (char *) node_name,
+ *     .snapshot_file = (char *) snapshot_file,
+ *     .snapshot_node_name = (char *) snapshot_node_name,
+ *     .format = (char *) format,
+ *     .has_mode = has_mode,
+ *     .mode = mode,
+ * };
+ *
+ * 在以下使用TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT_SYNC:
+ *   - blockdev.c|1141| <<qmp_blockdev_snapshot_sync>> .type = TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT_SYNC,
+ *   - blockdev.c|1469| <<external_snapshot_action>> case TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT_SYNC:
+ *   - blockdev.c|1510| <<external_snapshot_action>> if (action->type == TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT_SYNC) {
+ *   - blockdev.c|2213| <<transaction_action>> case TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT_SYNC:
+ *
+ *
+ * 28 typedef struct TransactionAction {
+ * 29     TransactionActionDrv *drv;
+ * 30     void *opaque;
+ * 31     QSLIST_ENTRY(TransactionAction) entry;
+ * 32 } TransactionAction;
+ *
+ * TransactionAction action = {
+ *     .type = TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT_SYNC,
+ *     .u.blockdev_snapshot_sync.data = &snapshot,
+ * };
+ *
+ * -object iothread,id=iothread01 \
+ * -device virtio-blk-pci,id=vblk01,num-queues=8,drive=drive01,iothread=iothread01 \
+ * -blockdev node-name=file01,driver=file,aio=threads,filename=test01.qcow2,cache.direct=on,cache.no-flush=off \
+ * -blockdev node-name=drive01,driver=qcow2,cache.direct=on,cache.no-flush=off,file=file01 \
+ *
+ * # blockdev-snapshot-sync node-name=drive01 snapshot-file=/tmp/overlay01.qcow2 snapshot-node-name=over01
+ * # block-commit device=over01 job-id=jobA
+ * # block-job-complete device=jobA
+ *
+ * called by:
+ *   - blockdev.c|2124| <<transaction_action>> external_snapshot_action(act, tran, errp);
+ *
+ * 处理:
+ * TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT:
+ * TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT_SYNC:
+ */
 static void external_snapshot_action(TransactionAction *action,
                                      Transaction *tran, Error **errp)
 {
@@ -1357,6 +1493,36 @@ static void external_snapshot_action(TransactionAction *action,
     /* TODO We'll eventually have to take a writer lock in this function */
     GRAPH_RDLOCK_GUARD_MAINLOOP();
 
+    /*
+     * called by:
+     *   - block.c|2440| <<bdrv_child_set_perm>> tran_add(tran, &bdrv_child_set_pem_drv, s);
+     *   - block.c|2525| <<bdrv_drv_set_perm>> tran_add(tran, &bdrv_drv_set_perm_drv, bs);
+     *   - block.c|2604| <<bdrv_replace_child_tran>> tran_add(tran, &bdrv_replace_child_drv, s);
+     *   - block.c|3397| <<bdrv_attach_child_common>> tran_add(tran, &bdrv_attach_child_common_drv, s);
+     *   - block.c|3589| <<bdrv_set_inherits_from>> tran_add(tran, &bdrv_set_inherits_from_drv, s);
+     *   - block.c|5540| <<bdrv_remove_child>> tran_add(tran, &bdrv_remove_child_drv, child);
+     *   - block.c|8128| <<bdrv_change_aio_context>> tran_add(tran, &set_aio_context, state);
+     *   - block/block-backend.c|2827| <<blk_root_change_aio_ctx>> tran_add(tran, &set_blk_root_context, s);
+     *   - block/io.c|184| <<bdrv_refresh_limits>> tran_add(tran, &bdrv_refresh_limits_drv, s);
+     *   - blockdev.c|1248| <<internal_snapshot_action>> tran_add(tran, &internal_snapshot_drv, state);
+     *   - blockdev.c|1392| <<external_snapshot_action>> tran_add(tran, &external_snapshot_drv, state);
+     *   - blockdev.c|1638| <<drive_backup_action>> tran_add(tran, &drive_backup_drv, state);
+     *   - blockdev.c|1813| <<blockdev_backup_action>> tran_add(tran, &blockdev_backup_drv, state);
+     *   - blockdev.c|1890| <<block_dirty_bitmap_add_action>> tran_add(tran, &block_dirty_bitmap_add_drv, state);
+     *   - blockdev.c|1929| <<block_dirty_bitmap_clear_action>> tran_add(tran, &block_dirty_bitmap_clear_drv, state);
+     *   - blockdev.c|1973| <<block_dirty_bitmap_enable_action>> tran_add(tran, &block_dirty_bitmap_enable_drv, state);
+     *   - blockdev.c|2011| <<block_dirty_bitmap_disable_action>> tran_add(tran, &block_dirty_bitmap_disable_drv, state);
+     *   - blockdev.c|2049| <<block_dirty_bitmap_merge_action>> tran_add(tran, &block_dirty_bitmap_merge_drv, state);
+     *   - blockdev.c|2069| <<block_dirty_bitmap_remove_action>> tran_add(tran, &block_dirty_bitmap_remove_drv, state);
+     *   - blockdev.c|2105| <<abort_action>> tran_add(tran, &abort_drv, NULL);
+     *   - blockjob.c|169| <<child_job_change_aio_ctx>> tran_add(tran, &change_child_job_context, s);
+     *
+     * 1378 TransactionActionDrv external_snapshot_drv = {
+     * 1379     .commit = external_snapshot_commit,
+     * 1380     .abort = external_snapshot_abort,
+     * 1381     .clean = external_snapshot_clean,
+     * 1382 };
+     */
     tran_add(tran, &external_snapshot_drv, state);
 
     /* 'blockdev-snapshot' and 'blockdev-snapshot-sync' have similar
@@ -1373,6 +1539,16 @@ static void external_snapshot_action(TransactionAction *action,
         break;
     case TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT_SYNC:
         {
+            /*
+	     * -object iothread,id=iothread01 \
+	     * -device virtio-blk-pci,id=vblk01,num-queues=8,drive=drive01,iothread=iothread01 \
+	     * -blockdev node-name=file01,driver=file,aio=threads,filename=test01.qcow2,cache.direct=on,cache.no-flush=off \
+	     * -blockdev node-name=drive01,driver=qcow2,cache.direct=on,cache.no-flush=off,file=file01 \
+	     *
+	     * # blockdev-snapshot-sync node-name=drive01 snapshot-file=/tmp/overlay01.qcow2 snapshot-node-name=over01
+	     * # block-commit device=over01 job-id=jobA
+	     * # block-job-complete device=jobA
+	     */
             BlockdevSnapshotSync *s = action->u.blockdev_snapshot_sync.data;
             device = s->device;
             node_name = s->node_name;
@@ -1386,6 +1562,29 @@ static void external_snapshot_action(TransactionAction *action,
 
     /* start processing */
 
+    /*
+     * 1396 typedef struct ExternalSnapshotState {
+     * 1397     BlockDriverState *old_bs;
+     * 1398     BlockDriverState *new_bs;
+     * 1399     bool overlay_appended;
+     * 1400 } ExternalSnapshotState;
+     *
+     * ExternalSnapshotState *state = g_new0(ExternalSnapshotState, 1);
+     *
+     * 根据 ...
+     * -object iothread,id=iothread01 \
+     * -device virtio-blk-pci,id=vblk01,num-queues=8,drive=drive01,iothread=iothread01 \
+     * -blockdev node-name=file01,driver=file,aio=threads,filename=test01.qcow2,cache.direct=on,cache.no-flush=off \
+     * -blockdev node-name=drive01,driver=qcow2,cache.direct=on,cache.no-flush=off,file=file01 \
+     *
+     * # blockdev-snapshot-sync node-name=drive01 snapshot-file=/tmp/overlay01.qcow2 snapshot-node-name=over01
+     * # block-commit device=over01 job-id=jobA
+     * # block-job-complete device=jobA
+     * ... 猜测:
+     * Backend-->Child-->BS (找到的这个!)
+     *
+     * 根据device或者node_name寻找BlockDriverState
+     */
     state->old_bs = bdrv_lookup_bs(device, node_name, errp);
     if (!state->old_bs) {
         return;
@@ -1423,6 +1622,16 @@ static void external_snapshot_action(TransactionAction *action,
             return;
         }
 
+        /*
+	 * -object iothread,id=iothread01 \
+	 * -device virtio-blk-pci,id=vblk01,num-queues=8,drive=drive01,iothread=iothread01 \
+	 * -blockdev node-name=file01,driver=file,aio=threads,filename=test01.qcow2,cache.direct=on,cache.no-flush=off \
+	 * -blockdev node-name=drive01,driver=qcow2,cache.direct=on,cache.no-flush=off,file=file01 \
+	 *
+	 * # blockdev-snapshot-sync node-name=drive01 snapshot-file=/tmp/overlay01.qcow2 snapshot-node-name=over01
+	 * # block-commit device=over01 job-id=jobA
+	 * # block-job-complete device=jobA
+	 */
         if (snapshot_node_name &&
             bdrv_lookup_bs(snapshot_node_name, snapshot_node_name, NULL)) {
             error_setg(errp, "New overlay node-name already in use");
@@ -1430,6 +1639,9 @@ static void external_snapshot_action(TransactionAction *action,
         }
 
         flags = state->old_bs->open_flags;
+        /*
+	 * 需要修改flags
+	 */
         flags &= ~(BDRV_O_SNAPSHOT | BDRV_O_COPY_ON_READ);
         flags |= BDRV_O_NO_BACKING;
 
@@ -1443,6 +1655,24 @@ static void external_snapshot_action(TransactionAction *action,
             }
             bdrv_refresh_filename(state->old_bs);
 
+            /*
+	     * called by:
+	     *   - blockdev.c|1602| <<external_snapshot_action>> bdrv_img_create(new_image_file, format, state->old_bs->filename,
+	     *                             state->old_bs->drv->format_name, NULL, size, flags, false, &local_err);
+	     *   - blockdev.c|1865| <<drive_backup_action>> bdrv_img_create(backup->target, format, explicit_backing->filename,
+	     *                             explicit_backing->drv->format_name, NULL, size, flags, false, &local_err);
+	     *   - blockdev.c|1870| <<drive_backup_action>> bdrv_img_create(backup->target, format, NULL, NULL, NULL, size, flags, false, &local_err);
+	     *   - blockdev.c|3343| <<qmp_drive_mirror>> bdrv_img_create(arg->target, format, NULL, NULL, NULL, size, flags, false, &local_err);
+	     *   - blockdev.c|3361| <<qmp_drive_mirror>> bdrv_img_create(arg->target, format, explicit_backing->filename,
+	     *                             explicit_backing->drv->format_name, NULL, size, flags, false, &local_err);
+	     *   - qemu-img.c|597| <<img_create>> bdrv_img_create(filename, fmt, base_filename, base_fmt, options, img_size, flags, quiet, &local_err);
+	     *   - tests/unit/test-replication.c|148| <<prepare_imgs>> bdrv_img_create(p_local_disk, "qcow2", NULL, NULL, NULL, IMG_SIZE, BDRV_O_RDWR, true, &error_abort);
+	     *   - tests/unit/test-replication.c|152| <<prepare_imgs>> bdrv_img_create(s_local_disk, "qcow2", NULL, NULL, NULL, IMG_SIZE, BDRV_O_RDWR, true, &error_abort);
+	     *   - tests/unit/test-replication.c|154| <<prepare_imgs>> bdrv_img_create(s_active_disk, "qcow2", NULL, NULL, NULL, IMG_SIZE, BDRV_O_RDWR, true, &error_abort);
+	     *   - tests/unit/test-replication.c|156| <<prepare_imgs>> bdrv_img_create(s_hidden_disk, "qcow2", NULL, NULL, NULL, IMG_SIZE, BDRV_O_RDWR, true, &error_abort);
+	     *
+	     * 这里应该是创建实体的文件
+	     */
             bdrv_img_create(new_image_file, format,
                             state->old_bs->filename,
                             state->old_bs->drv->format_name,
@@ -1461,6 +1691,15 @@ static void external_snapshot_action(TransactionAction *action,
         qdict_put_str(options, "driver", format);
     }
 
+    /*
+     * 1396 typedef struct ExternalSnapshotState {
+     * 1397     BlockDriverState *old_bs;
+     * 1398     BlockDriverState *new_bs;
+     * 1399     bool overlay_appended;
+     * 1400 } ExternalSnapshotState;
+     *
+     * ExternalSnapshotState *state = g_new0(ExternalSnapshotState, 1);
+     */
     state->new_bs = bdrv_open(new_image_file, snapshot_ref, options, flags,
                               errp);
 
@@ -1474,17 +1713,38 @@ static void external_snapshot_action(TransactionAction *action,
      * if the parents don't assume that they are already seeing a valid image.
      * (Specifically, allow it as a mirror target, which is write-only access.)
      */
+    /*
+     * called by:
+     *   - block.c|2391| <<bdrv_drv_set_perm_commit>> bdrv_get_cumulative_perm(bs, &cumulative_perms,
+     *   - block.c|2601| <<bdrv_node_refresh_perm>> bdrv_get_cumulative_perm(bs, &cumulative_perms, &cumulative_shared_perms);
+     *   - block.c|2892| <<bdrv_child_refresh_perms>> bdrv_get_cumulative_perm(bs, &parent_perms, &parent_shared);
+     *   - block.c|3341| <<bdrv_attach_child_noperm>> bdrv_get_cumulative_perm(parent_bs, &perm, &shared_perm);
+     *   - block.c|7333| <<bdrv_inactivate_recurse>> bdrv_get_cumulative_perm(bs, &cumulative_perms,
+     *   - blockdev.c|1504| <<external_snapshot_action>> bdrv_get_cumulative_perm(state->new_bs, &perm, &shared);
+     *   - blockdev.c|2712| <<qmp_block_commit>> bdrv_get_cumulative_perm(top_bs, &top_perm, &top_shared);
+     */
     bdrv_get_cumulative_perm(state->new_bs, &perm, &shared);
     if (perm & BLK_PERM_CONSISTENT_READ) {
         error_setg(errp, "The overlay is already in use");
         return;
     }
 
+    /*
+     * struct ExternalSnapshotState:
+     * -> BlockDriverState *new_bs;
+     *    -> BlockDriver *drv;
+     *       -> bool is_filter;
+     */
     if (state->new_bs->drv->is_filter) {
         error_setg(errp, "Filters cannot be used as overlays");
         return;
     }
 
+    /*
+     * 核心是返回BlockDriverState->backing
+     *
+     * 不能有backing
+     */
     if (bdrv_cow_child(state->new_bs)) {
         error_setg(errp, "The overlay already has a backing image");
         return;
@@ -1495,10 +1755,53 @@ static void external_snapshot_action(TransactionAction *action,
         return;
     }
 
+    /*
+     * called by:
+     *   - block.c|4036| <<bdrv_append_temp_snapshot>> ret = bdrv_append(bs_snapshot, bs, errp);
+     *   - block/commit.c|328| <<commit_start>> ret = bdrv_append(commit_top_bs, top, errp);
+     *   - block/mirror.c|1819| <<mirror_start_job>> ret = bdrv_append(mirror_top_bs, bs, errp);
+     *   - blockdev.c|1517| <<external_snapshot_action>> ret = bdrv_append(state->new_bs, state->old_bs, errp);
+     *   - tests/unit/test-bdrv-drain.c|1364| <<test_append_to_drained>> bdrv_append(overlay, base, &error_abort);
+     *   - tests/unit/test-bdrv-graph-mod.c|145| <<test_update_perm_tree>> ret = bdrv_append(filter, bs, NULL);
+     *   - tests/unit/test-bdrv-graph-mod.c|212| <<test_should_update_child>> bdrv_append(filter, bs, &error_abort);
+     *   - tests/unit/test-bdrv-graph-mod.c|439| <<test_append_greedy_filter>> bdrv_append(fl, base, &error_abort);
+     *
+     * 注释:
+     * Add new bs contents at the top of an image chain while the chain is
+     * live, while keeping required fields on the top layer.
+     *
+     * This will modify the BlockDriverState fields, and swap contents
+     * between bs_new and bs_top. Both bs_new and bs_top are modified.
+     *
+     * bs_new must not be attached to a BlockBackend and must not have backing
+     * child.
+     *
+     * This function does not create any image files.
+     *
+     * new_bs应该就是一个独立的BS
+     *
+     * old_bs指向的是:
+     *
+     * Backend-->Child("root")-->BS
+     *                           ^
+     *                           |
+     *                          这个!
+     */
     ret = bdrv_append(state->new_bs, state->old_bs, errp);
     if (ret < 0) {
         return;
     }
+    /*
+     * 在以下使用ExternalSnapshotState->overlay_appended:
+     *   - blockdev.c|1681| <<external_snapshot_action>> state->overlay_appended = true;
+     *   - blockdev.c|1700| <<external_snapshot_abort>> if (state->overlay_appended) {
+     *
+     * typedef struct ExternalSnapshotState {
+     *     BlockDriverState *old_bs;
+     *     BlockDriverState *new_bs;
+     *     bool overlay_appended;
+     * } ExternalSnapshotState;
+     */
     state->overlay_appended = true;
 }
 
@@ -1518,6 +1821,17 @@ static void external_snapshot_abort(void *opaque)
 {
     ExternalSnapshotState *state = opaque;
     if (state->new_bs) {
+        /*
+	 * 在以下使用ExternalSnapshotState->overlay_appended:
+	 *   - blockdev.c|1681| <<external_snapshot_action>> state->overlay_appended = true;
+	 *   - blockdev.c|1700| <<external_snapshot_abort>> if (state->overlay_appended) {
+	 *
+	 * typedef struct ExternalSnapshotState {
+	 *     BlockDriverState *old_bs;
+	 *     BlockDriverState *new_bs;
+	 *     bool overlay_appended;
+	 * } ExternalSnapshotState;
+	 */
         if (state->overlay_appended) {
             AioContext *aio_context;
             AioContext *tmp_context;
@@ -1578,6 +1892,10 @@ static BlockJob *do_backup_common(BackupCommon *backup,
 static void drive_backup_commit(void *opaque);
 static void drive_backup_abort(void *opaque);
 static void drive_backup_clean(void *opaque);
+/*
+ * 在以下使用drive_backup_drv:
+ *   - blockdev.c|1654| <<drive_backup_action>> tran_add(tran, &drive_backup_drv, state);
+ */
 TransactionActionDrv drive_backup_drv = {
     .commit = drive_backup_commit,
     .abort = drive_backup_abort,
@@ -2079,12 +2397,54 @@ static void abort_commit(void *opaque)
     g_assert_not_reached(); /* this action never succeeds */
 }
 
+/*
+ * called by:
+ *   - blockdev.c|2211| <<qmp_transaction>> transaction_action(act->value, block_job_txn, tran, &local_err);
+ */
 static void transaction_action(TransactionAction *act, JobTxn *block_job_txn,
                                Transaction *tran, Error **errp)
 {
     switch (act->type) {
     case TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT:
     case TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT_SYNC:
+        /*
+	 * -object iothread,id=iothread01 \
+	 * -device virtio-blk-pci,id=vblk01,num-queues=8,drive=drive01,iothread=iothread01 \
+	 * -blockdev node-name=file01,driver=file,aio=threads,filename=test01.qcow2,cache.direct=on,cache.no-flush=off \
+	 * -blockdev node-name=drive01,driver=qcow2,cache.direct=on,cache.no-flush=off,file=file01 \
+	 *
+	 * # blockdev-snapshot-sync node-name=drive01 snapshot-file=/tmp/overlay01.qcow2 snapshot-node-name=over01
+	 * # block-commit device=over01 job-id=jobA
+	 * # block-job-complete device=jobA
+	 *
+	 * BlockdevSnapshotSync snapshot = {
+	 *     .device = (char *) device,
+	 *     .node_name = (char *) node_name,
+	 *     .snapshot_file = (char *) snapshot_file,
+	 *     .snapshot_node_name = (char *) snapshot_node_name,
+	 *     .format = (char *) format,
+	 *     .has_mode = has_mode,
+	 *     .mode = mode,
+	 * };
+	 *
+	 * 在以下使用TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT_SYNC:
+	 *   - blockdev.c|1141| <<qmp_blockdev_snapshot_sync>> .type = TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT_SYNC,
+	 *   - blockdev.c|1469| <<external_snapshot_action>> case TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT_SYNC:
+	 *   - blockdev.c|1510| <<external_snapshot_action>> if (action->type == TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT_SYNC) {
+	 *   - blockdev.c|2213| <<transaction_action>> case TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT_SYNC:
+	 *
+	 *
+	 * 28 typedef struct TransactionAction {
+	 * 29     TransactionActionDrv *drv;
+	 * 30     void *opaque;
+	 * 31     QSLIST_ENTRY(TransactionAction) entry;
+	 * 32 } TransactionAction;
+	 *
+	 * TransactionAction action = {
+	 *     .type = TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT_SYNC,
+	 *     .u.blockdev_snapshot_sync.data = &snapshot,
+	 * };
+	 */
         external_snapshot_action(act, tran, errp);
         return;
     case TRANSACTION_ACTION_KIND_DRIVE_BACKUP:
@@ -2146,6 +2506,10 @@ static void transaction_action(TransactionAction *act, JobTxn *block_job_txn,
  *
  * Always run under BQL.
  */
+/*
+ * called by:
+ *   - blockdev.c|1088| <<blockdev_do_action>> qmp_transaction(&list, NULL, errp);
+ */
 void qmp_transaction(TransactionActionList *actions,
                      struct TransactionProperties *properties,
                      Error **errp)
@@ -2189,6 +2553,9 @@ void qmp_transaction(TransactionActionList *actions,
 
     /* We don't do anything in this loop that commits us to the operations */
     for (act = actions; act; act = act->next) {
+        /*
+	 * 只在此处调用
+	 */
         transaction_action(act->value, block_job_txn, tran, &local_err);
         if (local_err) {
             error_propagate(errp, local_err);
@@ -2421,6 +2788,56 @@ out_rdlock:
     bdrv_graph_rdunlock_main_loop();
 }
 
+/*
+ * [0] qemu_lock_fd
+ * [0] raw_handle_perm_lock
+ * [0] raw_check_perm
+ * [0] bdrv_drv_set_perm
+ * [0] bdrv_node_refresh_perm
+ * [0] bdrv_list_refresh_perms
+ * [0] bdrv_replace_node_common
+ * [0] mirror_start_job
+ * [0] commit_active_start
+ * [0] qmp_block_commit
+ * [0] qmp_marshal_block_commit
+ * [0] do_qmp_dispatch_bh
+ * [0] aio_bh_poll
+ * [0] aio_dispatch
+ * [0] aio_ctx_dispatch
+ * [0] g_main_context_dispatch
+ * [0] glib_pollfds_poll
+ * [0] os_host_main_loop_wait
+ * [0] main_loop_wait
+ * [0] qemu_main_loop
+ * [0] qemu_default_main
+ * [0] __libc_start_main
+ * [0] _start
+ *
+ * (QEMU) blockdev-snapshot-sync node-name=drive01 snapshot-file=/tmp/overlay01.qcow2 snapshot-node-name=over01
+ * (QEMU) block-commit device=over01 job-id=jobA
+ * (QEMU) block-job-complete device=jobA
+ *
+ * (gdb) bt
+ * #0  qmp_block_commit (job_id=0x555557400e10 "jobA", device=0x555557400d70 "over01",
+ *                base_node=0x0, base=0x0, top_node=0x0, top=0x0, backing_file=0x0,
+ *                has_backing_mask_protocol=false, backing_mask_protocol=false,
+ *                has_speed=false, speed=0, has_on_error=false, on_error=BLOCKDEV_ON_ERROR_REPORT,
+ *                filter_node_name=0x0, has_auto_finalize=false, auto_finalize=false,
+ *                has_auto_dismiss=false, auto_dismiss=false, errp=0x7fffffffd688) at ../blockdev.c:2438
+ * #1  0x0000555556010f4a in qmp_marshal_block_commit (args=0x7fffd8005c90, ret=0x7ffff7f9eda8, errp=0x7ffff7f9eda0) at qapi/qapi-commands-block-core.c:408
+ * #2  0x00005555560a4413 in do_qmp_dispatch_bh (opaque=0x7ffff7f9ee40) at ../qapi/qmp-dispatch.c:128
+ * #3  0x00005555560d3305 in aio_bh_call (bh=0x555557c93d70) at ../util/async.c:171
+ * #4  0x00005555560d3453 in aio_bh_poll (ctx=0x555557169480) at ../util/async.c:218
+ * #5  0x00005555560b2a26 in aio_dispatch (ctx=0x555557169480) at ../util/aio-posix.c:423
+ * #6  0x00005555560d3922 in aio_ctx_dispatch (source=0x555557169480, callback=0x0, user_data=0x0) at ../util/async.c:360
+ * #7  0x00007ffff6c53aed in g_main_context_dispatch () at /lib/../lib64/libglib-2.0.so.0
+ * #8  0x00005555560d4ff3 in glib_pollfds_poll () at ../util/main-loop.c:287
+ * #9  0x00005555560d5081 in os_host_main_loop_wait (timeout=0) at ../util/main-loop.c:310
+ * #10 0x00005555560d51b0 in main_loop_wait (nonblocking=0) at ../util/main-loop.c:589
+ * #11 0x0000555555bc3abf in qemu_main_loop () at ../system/runstate.c:783
+ * #12 0x0000555555e8a1bb in qemu_default_main () at ../system/main.c:37
+ * #13 0x0000555555e8a1f8 in main (argc=32, argv=0x7fffffffdaf8) at ../system/main.c:48
+ */
 void qmp_block_commit(const char *job_id, const char *device,
                       const char *base_node,
                       const char *base,
@@ -2436,6 +2853,13 @@ void qmp_block_commit(const char *job_id, const char *device,
                       bool has_auto_dismiss, bool auto_dismiss,
                       Error **errp)
 {
+    /* #0  qmp_block_commit (job_id=0x555557400e10 "jobA", device=0x555557400d70 "over01",
+     *                base_node=0x0, base=0x0, top_node=0x0, top=0x0, backing_file=0x0,
+     *                has_backing_mask_protocol=false, backing_mask_protocol=false,
+     *                has_speed=false, speed=0, has_on_error=false, on_error=BLOCKDEV_ON_ERROR_REPORT,
+     *                filter_node_name=0x0, has_auto_finalize=false, auto_finalize=false,
+     *                has_auto_dismiss=false, auto_dismiss=false, errp=0x7fffffffd688) at ../blockdev.c:2438
+     */
     BlockDriverState *bs;
     BlockDriverState *iter;
     BlockDriverState *base_bs, *top_bs;
@@ -2447,6 +2871,9 @@ void qmp_block_commit(const char *job_id, const char *device,
     /* TODO We'll eventually have to take a writer lock in this function */
     GRAPH_RDLOCK_GUARD_MAINLOOP();
 
+    /*
+     * 默认false
+     */
     if (!has_speed) {
         speed = 0;
     }
@@ -2468,6 +2895,18 @@ void qmp_block_commit(const char *job_id, const char *device,
      *  live commit feature versions; for this to work, we must make sure to
      *  perform the device lookup before any generic errors that may occur in a
      *  scenario in which all optional arguments are omitted. */
+    /*
+     * called by:
+     *   - blockdev.c|1137| <<qmp_blockdev_snapshot_delete_internal_sync>> bs = qmp_get_root_bs(device, errp);
+     *   - blockdev.c|1221| <<internal_snapshot_action>> bs = qmp_get_root_bs(device, errp);
+     *   - blockdev.c|2521| <<qmp_block_commit>> bs = qmp_get_root_bs(device, &local_err);
+     *   - blockdev.c|2971| <<qmp_drive_mirror>> bs = qmp_get_root_bs(arg->device, errp);
+     *   - blockdev.c|3135| <<qmp_blockdev_mirror>> bs = qmp_get_root_bs(device, errp);
+     *   - blockdev.c|3333| <<qmp_change_backing_file>> bs = qmp_get_root_bs(device, errp);
+     *
+     * qmp_get_root_bs()
+     * -> bdrv_lookup_bs()
+     */
     bs = qmp_get_root_bs(device, &local_err);
     if (!bs) {
         bs = bdrv_lookup_bs(device, device, NULL);
@@ -2481,6 +2920,13 @@ void qmp_block_commit(const char *job_id, const char *device,
         return;
     }
 
+    /*
+     * 7658 AioContext *bdrv_get_aio_context(BlockDriverState *bs)
+     * 7659 {
+     * 7660     IO_CODE();
+     * 7661     return bs ? bs->aio_context : qemu_get_aio_context();
+     * 7662 }
+     */
     aio_context = bdrv_get_aio_context(bs);
 
     if (bdrv_op_is_blocked(bs, BLOCK_OP_TYPE_COMMIT_SOURCE, errp)) {
@@ -2490,6 +2936,9 @@ void qmp_block_commit(const char *job_id, const char *device,
     /* default top_bs is the active layer */
     top_bs = bs;
 
+    /*
+     * 猜测一般top_node和top都是0
+     */
     if (top_node && top) {
         error_setg(errp, "'top-node' and 'top' are mutually exclusive");
         return;
@@ -2520,6 +2969,9 @@ void qmp_block_commit(const char *job_id, const char *device,
 
     assert(bdrv_get_aio_context(top_bs) == aio_context);
 
+    /*
+     * base_node和base一般也都是0
+     */
     if (base_node && base) {
         error_setg(errp, "'base-node' and 'base' are mutually exclusive");
         return;
@@ -2540,6 +2992,14 @@ void qmp_block_commit(const char *job_id, const char *device,
             return;
         }
     } else {
+        /*
+	 * 因为base_node和base一般也都是0
+	 * 所以这个else很重要
+	 *
+	 * called by:
+	 *   - blockdev.c|2622| <<qmp_block_commit>> base_bs = bdrv_find_base(top_bs);
+	 *   - blockdev.c|3380| <<qmp_change_backing_file>> if (bdrv_find_base(image_bs) == image_bs) {
+	 */
         base_bs = bdrv_find_base(top_bs);
         if (base_bs == NULL) {
             error_setg(errp, "There is no backimg image");
@@ -2557,6 +3017,19 @@ void qmp_block_commit(const char *job_id, const char *device,
         }
     }
 
+    /*
+     * 这里有两个很重要的:
+     * top_bs  :
+     *   - filename = "/tmp/overlay01.qcow2"i,
+     *   - exact_filename = "/tmp/overlay01.qcow2"
+     *   - backing_file = "test01.qcow2"
+     *   - auto_backing_file = "test01.qcow2"
+     * base_bs :
+     *   - filename = "test01.qcow2"
+     *   - exact_filename = "test01.qcow2"
+     *   - backing_file = 0
+     *   - auto_backing_file = 0
+     */
     /* Do not allow attempts to commit an image into itself */
     if (top_bs == base_bs) {
         error_setg(errp, "cannot commit an image into itself");
@@ -2571,6 +3044,16 @@ void qmp_block_commit(const char *job_id, const char *device,
      * to later attach this node to a writing parent.
      * (Active commit is never really wrong.)
      */
+    /*
+     * called by:
+     *   - block.c|2391| <<bdrv_drv_set_perm_commit>> bdrv_get_cumulative_perm(bs, &cumulative_perms,
+     *   - block.c|2601| <<bdrv_node_refresh_perm>> bdrv_get_cumulative_perm(bs, &cumulative_perms, &cumulative_shared_perms);
+     *   - block.c|2892| <<bdrv_child_refresh_perms>> bdrv_get_cumulative_perm(bs, &parent_perms, &parent_shared);
+     *   - block.c|3341| <<bdrv_attach_child_noperm>> bdrv_get_cumulative_perm(parent_bs, &perm, &shared_perm);
+     *   - block.c|7333| <<bdrv_inactivate_recurse>> bdrv_get_cumulative_perm(bs, &cumulative_perms,
+     *   - blockdev.c|1504| <<external_snapshot_action>> bdrv_get_cumulative_perm(state->new_bs, &perm, &shared);
+     *   - blockdev.c|2712| <<qmp_block_commit>> bdrv_get_cumulative_perm(top_bs, &top_perm, &top_shared);
+     */
     bdrv_get_cumulative_perm(top_bs, &top_perm, &top_shared);
     if (top_perm & BLK_PERM_WRITE ||
         bdrv_skip_filters(top_bs) == bdrv_skip_filters(bs))
@@ -2594,6 +3077,27 @@ void qmp_block_commit(const char *job_id, const char *device,
              */
             job_id = bdrv_get_device_name(bs);
         }
+        /*
+	 * called by:
+	 *   - block/replication.c|711| <<replication_stop>> s->commit_job = commit_active_start(NULL, bs->file->bs, s->secondary_disk->bs,
+	 *                                    JOB_INTERNAL, 0, BLOCKDEV_ON_ERROR_REPORT, NULL, replication_done, bs, true, errp);
+	 *   - blockdev.c|2622| <<qmp_block_commit>> commit_active_start(job_id, top_bs, base_bs, job_flags, speed, on_error,
+	 *                                    filter_node_name, NULL, NULL, false, &local_err);
+	 *   - qemu-img.c|1080| <<img_commit>> commit_active_start("commit", bs, base_bs, JOB_DEFAULT, rate_limit,
+	 *                                    BLOCKDEV_ON_ERROR_REPORT, NULL, common_block_job_cb, &cbi, false, &local_err);
+	 *
+	 * 两个重要的参数:
+	 * top_bs  :
+	 *   - filename = "/tmp/overlay01.qcow2"i,
+	 *   - exact_filename = "/tmp/overlay01.qcow2"
+	 *   - backing_file = "test01.qcow2"
+	 *   - auto_backing_file = "test01.qcow2"
+	 * base_bs :
+	 *   - filename = "test01.qcow2"
+	 *   - exact_filename = "test01.qcow2"
+	 *   - backing_file = 0
+	 *   - auto_backing_file = 0
+	 */
         commit_active_start(job_id, top_bs, base_bs, job_flags, speed, on_error,
                             filter_node_name, NULL, NULL, false, &local_err);
     } else {
@@ -2612,6 +3116,11 @@ void qmp_block_commit(const char *job_id, const char *device,
     }
 }
 
+/*
+ * called by:
+ *   - blockdev.c|1769| <<drive_backup_action>> state->job = do_backup_common(qapi_DriveBackup_base(backup),
+ *   - blockdev.c|1854| <<blockdev_backup_action>> state->job = do_backup_common(qapi_BlockdevBackup_base(backup),
+ */
 /* Common QMP interface for drive-backup and blockdev-backup */
 static BlockJob *do_backup_common(BackupCommon *backup,
                                   BlockDriverState *bs,
@@ -2772,6 +3281,11 @@ void qmp_blockdev_backup(BlockdevBackup *backup, Error **errp)
 /* Parameter check and block job starting for drive mirroring.
  * Caller should hold @device and @target's aio context (must be the same).
  **/
+/*
+ * called by:
+ *   - blockdev.c|3307| <<qmp_drive_mirror>> blockdev_mirror_common(arg->job_id, bs, target_bs,
+ *   - blockdev.c|3367| <<qmp_blockdev_mirror>> blockdev_mirror_common(job_id, bs, target_bs,
+ */
 static void blockdev_mirror_common(const char *job_id, BlockDriverState *bs,
                                    BlockDriverState *target,
                                    const char *replaces,
@@ -3109,6 +3623,17 @@ void qmp_blockdev_mirror(const char *job_id,
 /*
  * Get a block job using its ID. Called with job_mutex held.
  */
+/*
+ * called by:
+ *   - blockdev.c|3277| <<qmp_block_job_set_speed>> job = find_block_job_locked(device, errp);
+ *   - blockdev.c|3292| <<qmp_block_job_cancel>> job = find_block_job_locked(device, errp);
+ *   - blockdev.c|3317| <<qmp_block_job_pause>> job = find_block_job_locked(device, errp);
+ *   - blockdev.c|3332| <<qmp_block_job_resume>> job = find_block_job_locked(device, errp);
+ *   - blockdev.c|3347| <<qmp_block_job_complete>> job = find_block_job_locked(device, errp);
+ *   - blockdev.c|3362| <<qmp_block_job_finalize>> job = find_block_job_locked(id, errp);
+ *   - blockdev.c|3381| <<qmp_block_job_dismiss>> bjob = find_block_job_locked(id, errp);
+ *   - blockdev.c|3397| <<qmp_block_job_change>> job = find_block_job_locked(opts->id, errp);
+ */
 static BlockJob *find_block_job_locked(const char *id, Error **errp)
 {
     BlockJob *job;
@@ -3289,6 +3814,11 @@ void qmp_change_backing_file(const char *device,
         goto out_rdlock;
     }
 
+    /*
+     * called by:
+     *   - blockdev.c|2622| <<qmp_block_commit>> base_bs = bdrv_find_base(top_bs);
+     *   - blockdev.c|3380| <<qmp_change_backing_file>> if (bdrv_find_base(image_bs) == image_bs) {
+     */
     if (bdrv_find_base(image_bs) == image_bs) {
         error_setg(errp, "not allowing backing file change on an image "
                          "without a backing file");
@@ -3338,6 +3868,12 @@ out_rdlock:
     bdrv_graph_rdunlock_main_loop();
 }
 
+/*
+ * called by:
+ *   - hw/block/xen-block.c|832| <<xen_block_blockdev_add>> qmp_blockdev_add(options, errp);
+ *   - storage-daemon/qemu-storage-daemon.c|279| <<process_options>> qmp_blockdev_add(options, &error_fatal);
+ *   - system/vl.c|698| <<configure_blockdev>> qmp_blockdev_add(bdo->bdo, &error_fatal);
+ */
 void qmp_blockdev_add(BlockdevOptions *options, Error **errp)
 {
     BlockDriverState *bs;
@@ -3450,6 +3986,10 @@ void qmp_blockdev_del(const char *node_name, Error **errp)
     bdrv_unref(bs);
 }
 
+/*
+ * called by:
+ *   - blockdev.c|3638| <<qmp_x_blockdev_change>> p_child = bdrv_find_child(parent_bs, child);
+ */
 static BdrvChild * GRAPH_RDLOCK
 bdrv_find_child(BlockDriverState *parent_bs, const char *child_name)
 {
@@ -3509,6 +4049,10 @@ out:
     bdrv_graph_wrunlock();
 }
 
+/*
+ * called by:
+ *   - block/monitor/block-hmp-cmds.c|822| <<hmp_info_block_jobs>> list = qmp_query_block_jobs(&error_abort);
+ */
 BlockJobInfoList *qmp_query_block_jobs(Error **errp)
 {
     BlockJobInfoList *head = NULL, **tail = &head;
@@ -3534,6 +4078,9 @@ BlockJobInfoList *qmp_query_block_jobs(Error **errp)
     return head;
 }
 
+/*
+ * 只被qmp调用
+ */
 void qmp_x_blockdev_set_iothread(const char *node_name, StrOrNull *iothread,
                                  bool has_force, bool force, Error **errp)
 {
@@ -3571,6 +4118,14 @@ void qmp_x_blockdev_set_iothread(const char *node_name, StrOrNull *iothread,
     bdrv_try_change_aio_context(bs, new_context, NULL, errp);
 }
 
+/*
+ * 在以下使用qemu_common_drive_opts:
+ *   - blockdev.c|3722| <<global>> QemuOptsList qemu_common_drive_opts = {
+ *   - blockdev.c|3724| <<global>> .head = QTAILQ_HEAD_INITIALIZER(qemu_common_drive_opts.head),
+ *   - include/sysemu/sysemu.h|106| <<global>> extern QemuOptsList qemu_common_drive_opts;
+ *   - blockdev.c|507| <<blockdev_init>> opts = qemu_opts_create(&qemu_common_drive_opts, id, 1, errp);
+ *   - system/vl.c|2747| <<qemu_init>> qemu_add_drive_opts(&qemu_common_drive_opts);
+ */
 QemuOptsList qemu_common_drive_opts = {
     .name = "drive",
     .head = QTAILQ_HEAD_INITIALIZER(qemu_common_drive_opts.head),
@@ -3634,6 +4189,20 @@ QemuOptsList qemu_common_drive_opts = {
     },
 };
 
+/*
+ * 在以下使用qemu_drive_opts:
+ *   - blockdev.c|3785| <<global>> QemuOptsList qemu_drive_opts = {
+ *   - blockdev.c|3787| <<global>> .head = QTAILQ_HEAD_INITIALIZER(qemu_drive_opts.head),
+ *   - include/sysemu/sysemu.h|107| <<global>> extern QemuOptsList qemu_drive_opts;
+ *   - tests/unit/test-replication.c|36| <<global>> QemuOptsList qemu_drive_opts = {
+ *   - tests/unit/test-replication.c|38| <<global>> .head = QTAILQ_HEAD_INITIALIZER(qemu_drive_opts.head),
+ *   - block/monitor/block-hmp-cmds.c|67| <<hmp_drive_add_node>> opts = qemu_opts_parse_noisily(&qemu_drive_opts, optstr, false);
+ *   - system/vl.c|2745| <<qemu_init>> qemu_add_opts(&qemu_drive_opts);
+ *   - system/vl.c|2748| <<qemu_init>> qemu_add_drive_opts(&qemu_drive_opts);
+ *   - tests/unit/test-replication.c|182| <<start_primary>> opts = qemu_opts_parse_noisily(&qemu_drive_opts, cmdline, false);
+ *   - tests/unit/test-replication.c|298| <<start_secondary>> opts = qemu_opts_parse_noisily(&qemu_drive_opts, cmdline, false);
+ *   - tests/unit/test-replication.c|324| <<start_secondary>> opts = qemu_opts_parse_noisily(&qemu_drive_opts, cmdline, false);
+ */
 QemuOptsList qemu_drive_opts = {
     .name = "drive",
     .head = QTAILQ_HEAD_INITIALIZER(qemu_drive_opts.head),
diff --git a/blockjob.c b/blockjob.c
index d5f29e14a..bc6ec2875 100644
--- a/blockjob.c
+++ b/blockjob.c
@@ -154,6 +154,9 @@ static bool child_job_change_aio_ctx(BdrvChild *c, AioContext *ctx,
 
     for (l = job->nodes; l; l = l->next) {
         BdrvChild *sibling = l->data;
+        /*
+	 * 看过了
+	 */
         if (!bdrv_child_change_aio_context(sibling, ctx, visited,
                                            tran, errp)) {
             return false;
@@ -179,6 +182,10 @@ static AioContext *child_job_get_parent_aio_context(BdrvChild *c)
     return job->job.aio_context;
 }
 
+/*
+ * 在以下使用child_job:
+ *   - blockjob.c|256| <<block_job_add_bdrv>> c = bdrv_root_attach_child(bs, name, &child_job, 0, perm, shared_perm, job, errp);
+ */
 static const BdrvChildClass child_job = {
     .get_parent_desc    = child_job_get_parent_desc,
     .drained_begin      = child_job_drained_begin,
@@ -213,6 +220,10 @@ void block_job_remove_all_bdrv(BlockJob *job)
     bdrv_graph_wrunlock();
 }
 
+/*
+ * called by:
+ *   - blockdev.c|160| <<blockdev_mark_auto_del>> !block_job_has_bdrv(job, blk_bs(blk))))
+ */
 bool block_job_has_bdrv(BlockJob *job, BlockDriverState *bs)
 {
     GSList *el;
@@ -228,6 +239,19 @@ bool block_job_has_bdrv(BlockJob *job, BlockDriverState *bs)
     return false;
 }
 
+/*
+ * called by:
+ *   - block/backup.c|500| <<backup_job_create>> block_job_add_bdrv(&job->common, "target", target, 0, BLK_PERM_ALL,
+ *   - block/commit.c|373| <<commit_start>> ret = block_job_add_bdrv(&s->common, "intermediate node", iter, 0,
+ *   - block/commit.c|387| <<commit_start>> ret = block_job_add_bdrv(&s->common, "base", base, 0, BLK_PERM_ALL, errp);
+ *   - block/mirror.c|2017| <<mirror_start_job>> ret = block_job_add_bdrv(&s->common, "source", bs, 0,
+ *   - block/mirror.c|2027| <<mirror_start_job>> block_job_add_bdrv(&s->common, "target", target, 0, BLK_PERM_ALL,
+ *   - block/mirror.c|2064| <<mirror_start_job>> ret = block_job_add_bdrv(&s->common, "intermediate node", iter, 0,
+ *   - block/stream.c|377| <<stream_start>> if (block_job_add_bdrv(&s->common, "active node", bs, 0,
+ *   - block/stream.c|396| <<stream_start>> ret = block_job_add_bdrv(&s->common, "intermediate node", iter, 0,
+ *   - blockjob.c|537| <<block_job_create>> ret = block_job_add_bdrv(job, "main node", bs, perm, shared_perm, errp);
+ *   - tests/unit/test-bdrv-drain.c|774| <<test_blockjob_common_drain_node>> block_job_add_bdrv(job, "target", target, 0, BLK_PERM_ALL, &error_abort);
+ */
 int block_job_add_bdrv(BlockJob *job, const char *name, BlockDriverState *bs,
                        uint64_t perm, uint64_t shared_perm, Error **errp)
 {
@@ -236,6 +260,22 @@ int block_job_add_bdrv(BlockJob *job, const char *name, BlockDriverState *bs,
 
     bdrv_ref(bs);
 
+    /*
+     * 186 static const BdrvChildClass child_job = {
+     * 187     .get_parent_desc    = child_job_get_parent_desc,
+     * 188     .drained_begin      = child_job_drained_begin,
+     * 189     .drained_poll       = child_job_drained_poll,
+     * 190     .drained_end        = child_job_drained_end,
+     * 191     .change_aio_ctx     = child_job_change_aio_ctx,
+     * 192     .stay_at_node       = true,
+     * 193     .get_parent_aio_context = child_job_get_parent_aio_context,
+     * 194 };
+     *
+     * called by:
+     *   - block/block-backend.c|1037| <<blk_insert_bs>> blk->root = bdrv_root_attach_child(bs, "root", &child_root,
+     *             BDRV_CHILD_FILTERED | BDRV_CHILD_PRIMARY, blk->perm, blk->shared_perm, blk, errp);
+     *   - blockjob.c|252| <<block_job_add_bdrv>> c = bdrv_root_attach_child(bs, name, &child_job, 0, perm, shared_perm, job, errp);
+     */
     c = bdrv_root_attach_child(bs, name, &child_job, 0, perm, shared_perm, job,
                                errp);
     if (c == NULL) {
@@ -487,6 +527,19 @@ static void block_job_event_ready_locked(Notifier *n, void *opaque)
 }
 
 
+/*
+ * called by:
+ *   - block/backup.c|474| <<backup_job_create>> job = block_job_create(job_id, &backup_job_driver, txn, cbw,
+ *   - block/commit.c|298| <<commit_start>> s = block_job_create(job_id, &commit_job_driver, NULL, bs, 0, BLK_PERM_ALL,
+ *   - block/mirror.c|1993| <<mirror_start_job>> s = block_job_create(job_id, driver, NULL, mirror_top_bs,
+ *   - block/stream.c|352| <<stream_start>> s = block_job_create(job_id, &stream_job_driver, NULL, cor_filter_bs,
+ *   - tests/unit/test-bdrv-drain.c|767| <<test_blockjob_common_drain_node>> tjob = block_job_create("job0", &test_job_driver, NULL, src,
+ *   - tests/unit/test-bdrv-drain.c|1534| <<test_blockjob_commit_by_drained_end>> job = block_job_create("job", &test_drop_backing_job_driver, NULL,
+ *   - tests/unit/test-bdrv-drain.c|1694| <<test_drop_intermediate_poll>> job = block_job_create("job", &test_simple_job_driver, NULL, job_node,
+ *   - tests/unit/test-block-iothread.c|561| <<test_attach_blockjob>> tjob = block_job_create("job0", &test_job_driver, NULL, bs,
+ *   - tests/unit/test-blockjob-txn.c|96| <<test_block_job_start>> s = block_job_create(job_id, &test_block_job_driver, txn, bs,
+ *   - tests/unit/test-blockjob.c|40| <<mk_job>> job = block_job_create(id, drv, NULL, blk_bs(blk),
+ */
 void *block_job_create(const char *job_id, const BlockJobDriver *driver,
                        JobTxn *txn, BlockDriverState *bs, uint64_t perm,
                        uint64_t shared_perm, int64_t speed, int flags,
@@ -534,6 +587,9 @@ void *block_job_create(const char *job_id, const BlockJobDriver *driver,
     error_setg(&job->blocker, "block device is in use by block job: %s",
                job_type_str(&job->job));
 
+    /*
+     * 似乎创建了新的"main node"的child, 指向了这个bs
+     */
     ret = block_job_add_bdrv(job, "main node", bs, perm, shared_perm, errp);
     if (ret < 0) {
         goto fail;
@@ -577,6 +633,15 @@ void block_job_user_resume(Job *job)
     block_job_iostatus_reset(bjob);
 }
 
+/*
+ * called by:
+ *   - block/backup.c|128| <<backup_error_action>> return block_job_error_action(&job->common, job->on_source_error,
+ *   - block/backup.c|131| <<backup_error_action>> return block_job_error_action(&job->common, job->on_target_error,
+ *   - block/commit.c|187| <<commit_run>> block_job_error_action(&s->common, s->on_error,
+ *   - block/mirror.c|141| <<mirror_error_action>> return block_job_error_action(&s->common, s->on_source_error,
+ *   - block/mirror.c|144| <<mirror_error_action>> return block_job_error_action(&s->common, s->on_target_error,
+ *   - block/stream.c|218| <<stream_run>> block_job_error_action(&s->common, s->on_error, true, -ret);
+ */
 BlockErrorAction block_job_error_action(BlockJob *job, BlockdevOnError on_err,
                                         int is_read, int error)
 {
diff --git a/hw/block/virtio-blk.c b/hw/block/virtio-blk.c
index bb86e65f6..7cb6dd38f 100644
--- a/hw/block/virtio-blk.c
+++ b/hw/block/virtio-blk.c
@@ -37,6 +37,12 @@
 #include "hw/virtio/virtio-blk-common.h"
 #include "qemu/coroutine.h"
 
+/*
+ * 这个文档:
+ * A Practical Look at QEMU's Block Layer Primitives
+ * https://kashyapc.fedorapeople.org/virt/LinuxCon-NA-2016/A-Practical-Look-at-QEMU-Block-Layer-Primitives-LC-NA-2016.pdf
+ */
+
 static void virtio_blk_ioeventfd_attach(VirtIOBlock *s);
 
 static void virtio_blk_init_request(VirtIOBlock *s, VirtQueue *vq,
@@ -100,6 +106,20 @@ static int virtio_blk_handle_rw_error(VirtIOBlockReq *req, int error,
     return action != BLOCK_ERROR_ACTION_IGNORE;
 }
 
+/*
+ * (gdb) bt
+ * #0  virtio_blk_rw_complete (opaque=0x6120019435c0, ret=0) at ../hw/block/virtio-blk.c:105
+ * #1  0x0000555556f805a4 in blk_aio_complete (acb=0x608000f026a0) at ../block/block-backend.c:1555
+ * #2  0x0000555556f80d66 in blk_aio_write_entry (opaque=0x608000f026a0) at ../block/block-backend.c:1622
+ * #3  0x000055555734236e in coroutine_trampoline (i0=106945984, i1=24864) at ../util/coroutine-ucontext.c:175
+ * #4  0x00007ffff70b4830 in __start_context () at /lib64/libc.so.6
+ * #5  0x00007ffde38341c0 in  ()
+ * #6  0x0000000000000000 in  ()
+ *
+ * 在以下使用virtio_blk_rw_complete():
+ *   - hw/block/virtio-blk.c|434| <<submit_requests>> blk_aio_pwritev(blk, sector_num << BDRV_SECTOR_BITS, qiov, flags, virtio_blk_rw_complete, mrb->reqs[start]);
+ *   - hw/block/virtio-blk.c|438| <<submit_requests>> blk_aio_preadv(blk, sector_num << BDRV_SECTOR_BITS, qiov, flags, virtio_blk_rw_complete, mrb->reqs[start]);
+ */
 static void virtio_blk_rw_complete(void *opaque, int ret)
 {
     VirtIOBlockReq *next = opaque;
@@ -353,6 +373,52 @@ static void virtio_blk_handle_scsi(VirtIOBlockReq *req)
     }
 }
 
+/*
+ * (qemu) qemu-system-x86_64: ../block/file-posix.c:3599: raw_do_pwrite_zeroes: Assertion `req' failed.
+ * run.sh: line 11: 74885 Aborted                 (core dumped) /home/opc/qemu/build/qemu-system-x86_64 -hda ol89.qcow2 -m 8G -smp 4 -vnc :4 -enable-kvm -cpu host -net nic -net user,hostfwd=tcp::5028-:22 -monitor stdio -name debug-threads=on -object iothread,id=t0 -object iothread,id=t1 -object iothread,id=t2 -object iothread,id=t3 -blockdev node-name=file01,driver=file,filename=test.qcow2,cache.direct=on,cache.no-flush=off -blockdev node-name=drive01,driver=qcow2,cache.direct=on,cache.no-flush=off,file=file01 -device '{"driver": "virtio-blk-pci", "drive": "drive01", "iothread-vq-mapping": [{"iothread": "t0", "vqs": [0]}, {"iothread": "t1", "vqs": [1]}, {"iothread": "t2", "vqs": [2]}, {"iothread": "t3", "vqs": [3]}]}'
+ *
+ * 在以下调用tracked_request_end():
+ *   - block/io.c|1822| <<bdrv_co_preadv_part>> tracked_request_end(&req);
+ *   - block/io.c|2305| <<bdrv_co_pwritev_part>> tracked_request_end(&req);
+ *   - block/io.c|3187| <<bdrv_co_pdiscard>> tracked_request_end(&req);
+ *   - block/io.c|3445| <<bdrv_co_copy_range_internal>> tracked_request_end(&req);
+ *   - block/io.c|3461| <<bdrv_co_copy_range_internal>> tracked_request_end(&req);
+ *   - block/io.c|3661| <<bdrv_co_truncate>> tracked_request_end(&req);
+ *
+ * (gdb) bt
+ * #0  bdrv_co_get_self_request (bs=0x629000005200) at ../block/io.c:720
+ * #1  0x00005555570f6929 in raw_do_pwrite_zeroes (bs=0x629000005200, offset=458752, bytes=65536, flags=BDRV_REQ_NO_FALLBACK, blkdev=false) at ../block/file-posix.c:3598
+ * #2  0x00005555570f6f1d in raw_co_pwrite_zeroes (bs=0x629000005200, offset=458752, bytes=65536, flags=BDRV_REQ_NO_FALLBACK) at ../block/file-posix.c:3641
+ * #3  0x0000555556fb193d in bdrv_co_do_pwrite_zeroes (bs=0x629000005200, offset=458752, bytes=65536, flags=258) at ../block/io.c:1901
+ * #4  0x0000555556fb2b50 in bdrv_aligned_pwritev (child=0x608000002920, req=0x7ffd14df80d0, offset=458752, bytes=65536, align=512, qiov=0x0, qiov_offset=0, flags=258) at ../block/io.c:2100
+ * #5  0x0000555556fb33a7 in bdrv_co_do_zero_pwritev (child=0x608000002920, offset=458752, bytes=65536, flags=258, req=0x7ffd14df80d0) at ../block/io.c:2183
+ * #6  0x0000555556fb3c43 in bdrv_co_pwritev_part (child=0x608000002920, offset=458752, bytes=65536, qiov=0x0, qiov_offset=0, flags=258) at ../block/io.c:2283
+ * #7  0x0000555556fb362c in bdrv_co_pwritev (child=0x608000002920, offset=458752, bytes=65536, qiov=0x0, flags=258) at ../block/io.c:2216
+ * #8  0x0000555556fb3f19 in bdrv_co_pwrite_zeroes (child=0x608000002920, offset=458752, bytes=65536, flags=BDRV_REQ_NO_FALLBACK) at ../block/io.c:2322
+ * #9  0x0000555556ffae77 in handle_alloc_space (bs=0x62900000a200, l2meta=0x60b0011bb730) at ../block/qcow2.c:2557
+ * #10 0x0000555556ffb3de in qcow2_co_pwritev_task (bs=0x62900000a200, host_offset=458752, offset=131072, bytes=8192, qiov=0x61200532c758, qiov_offset=0, l2meta=0x60b0011bb730) at ../block/qcow2.c:2609
+ * #11 0x0000555556ffb828 in qcow2_co_pwritev_task_entry (task=0x7ffd14c07320) at ../block/qcow2.c:2657
+ * #12 0x0000555556ff97cd in qcow2_add_task (bs=0x62900000a200, pool=0x0, func=0x555556ffb653 <qcow2_co_pwritev_task_entry>, subcluster_type=QCOW2_SUBCLUSTER_UNALLOCATED_PLAIN,
+ *                           host_offset=458752, offset=131072, bytes=8192, qiov=0x61200532c758, qiov_offset=0, l2meta=0x60b0011bb730) at ../block/qcow2.c:2307
+ * #13 0x0000555556ffbd90 in qcow2_co_pwritev_part (bs=0x62900000a200, offset=131072, bytes=8192, qiov=0x61200532c758, qiov_offset=0, flags=BDRV_REQ_REGISTERED_BUF) at ../block/qcow2.c:2709
+ * #14 0x0000555556face86 in bdrv_driver_pwritev (bs=0x62900000a200, offset=131072, bytes=8192, qiov=0x61200532c758, qiov_offset=0, flags=BDRV_REQ_REGISTERED_BUF) at ../block/io.c:1070
+ * #15 0x0000555556fb2bcb in bdrv_aligned_pwritev (child=0x608000002e20, req=0x7ffd14df7cd0, offset=131072, bytes=8192, align=1, qiov=0x61200532c758, qiov_offset=0, flags=BDRV_REQ_REGISTERED_BUF)
+ *                           at ../block/io.c:2106
+ * #16 0x0000555556fb3d48 in bdrv_co_pwritev_part (child=0x608000002e20, offset=131072, bytes=8192, qiov=0x61200532c758, qiov_offset=0, flags=BDRV_REQ_REGISTERED_BUF) at ../block/io.c:2299
+ * #17 0x0000555556f7f9bd in blk_co_do_pwritev_part (blk=0x6190000d8e80, offset=131072, bytes=8192, qiov=0x61200532c758, qiov_offset=0, flags=BDRV_REQ_REGISTERED_BUF) at ../block/block-backend.c:1425
+ * #18 0x0000555556f80d1d in blk_aio_write_entry (opaque=0x6080016c0920) at ../block/block-backend.c:1620
+ * #19 0x000055555734236e in coroutine_trampoline (i0=87277888, i1=24864) at ../util/coroutine-ucontext.c:175
+ * #20 0x00007ffff70b4830 in __start_context () at /lib64/libc.so.6
+ * #21 0x00007fffef7e01c0 in  ()
+ * #22 0x0000000000000000 in  ()
+ */
+
+/*
+ * called by:
+ *   - hw/block/virtio-blk.c|462| <<virtio_blk_submit_multireq>> submit_requests(s, mrb, 0, 1, -1);
+ *   - hw/block/virtio-blk.c|486| <<virtio_blk_submit_multireq>> submit_requests(s, mrb, start, num_reqs, niov);
+ *   - hw/block/virtio-blk.c|502| <<virtio_blk_submit_multireq>> submit_requests(s, mrb, start, num_reqs, niov);
+ */
 static inline void submit_requests(VirtIOBlock *s, MultiReqBuffer *mrb,
                                    int start, int num_reqs, int niov)
 {
@@ -424,6 +490,19 @@ static int multireq_compare(const void *a, const void *b)
     }
 }
 
+/*
+ * called by:
+ *   - hw/block/virtio-blk.c|517| <<virtio_blk_handle_flush>> virtio_blk_submit_multireq(s, mrb);
+ *   - hw/block/virtio-blk.c|1034| <<virtio_blk_handle_request>> virtio_blk_submit_multireq(s, mrb);
+ *   - hw/block/virtio-blk.c|1166| <<virtio_blk_handle_vq>> virtio_blk_submit_multireq(s, &mrb);
+ *   - hw/block/virtio-blk.c|1214| <<virtio_blk_dma_restart_bh>> virtio_blk_submit_multireq(s, &mrb);
+ *
+ * typedef struct MultiReqBuffer {
+ *     VirtIOBlockReq *reqs[VIRTIO_BLK_MAX_MERGE_REQS];
+ *     unsigned int num_reqs;
+ *     bool is_write;
+ * } MultiReqBuffer;
+ */
 static void virtio_blk_submit_multireq(VirtIOBlock *s, MultiReqBuffer *mrb)
 {
     int i = 0, start = 0, num_reqs = 0, niov = 0, nb_sectors = 0;
@@ -928,6 +1007,11 @@ out:
     return err_status;
 }
 
+/*
+ * called by:
+ *   - hw/block/virtio-blk.c|1153| <<virtio_blk_handle_vq>> if (virtio_blk_handle_request(req, &mrb)) {
+ *   - hw/block/virtio-blk.c|1198| <<virtio_blk_dma_restart_bh>> if (virtio_blk_handle_request(req, &mrb)) {
+ */
 static int virtio_blk_handle_request(VirtIOBlockReq *req, MultiReqBuffer *mrb)
 {
     uint32_t type;
@@ -1108,6 +1192,10 @@ static int virtio_blk_handle_request(VirtIOBlockReq *req, MultiReqBuffer *mrb)
     return 0;
 }
 
+/*
+ * 在以下使用virtio_blk_handle_vq():
+ *   - hw/block/virtio-blk.c|1186| <<virtio_blk_handle_output>> virtio_blk_handle_vq(s, vq);
+ */
 void virtio_blk_handle_vq(VirtIOBlock *s, VirtQueue *vq)
 {
     VirtIOBlockReq *req;
@@ -1134,17 +1222,56 @@ void virtio_blk_handle_vq(VirtIOBlock *s, VirtQueue *vq)
         }
     } while (!virtio_queue_empty(vq));
 
+    /*
+     * typedef struct MultiReqBuffer {
+     *     VirtIOBlockReq *reqs[VIRTIO_BLK_MAX_MERGE_REQS];
+     *     unsigned int num_reqs;
+     *     bool is_write;
+     * } MultiReqBuffer;
+     */
     if (mrb.num_reqs) {
+        /*
+	 * called by:
+	 *   - hw/block/virtio-blk.c|517| <<virtio_blk_handle_flush>> virtio_blk_submit_multireq(s, mrb);
+	 *   - hw/block/virtio-blk.c|1034| <<virtio_blk_handle_request>> virtio_blk_submit_multireq(s, mrb);
+	 *   - hw/block/virtio-blk.c|1166| <<virtio_blk_handle_vq>> virtio_blk_submit_multireq(s, &mrb);
+	 *   - hw/block/virtio-blk.c|1214| <<virtio_blk_dma_restart_bh>> virtio_blk_submit_multireq(s, &mrb);
+	 */
         virtio_blk_submit_multireq(s, &mrb);
     }
 
     defer_call_end();
 }
 
+/*
+ * (gdb) bt
+ * #0  virtio_blk_handle_output (vdev=0x62d00001c830, vq=0x7ffddbda4800) at ../hw/block/virtio-blk.c:1010
+ * #1  0x0000555556ca8da7 in virtio_queue_notify_vq (vq=0x7ffddbda4800) at ../hw/virtio/virtio.c:2277
+ * #2  0x0000555556cb03f4 in virtio_queue_host_notifier_read (n=0x7ffddbda4874) at ../hw/virtio/virtio.c:3641
+ * #3  0x00005555572f3b2f in aio_dispatch_handler (ctx=0x613000121880, node=0x60d000036c20) at ../util/aio-posix.c:372
+ * #4  0x00005555572f3d80 in aio_dispatch_ready_handlers (ctx=0x613000121880, ready_list=0x7ffff1947aa0) at ../util/aio-posix.c:401
+ * #5  0x00005555572f5845 in aio_poll (ctx=0x613000121880, blocking=true) at ../util/aio-posix.c:723
+ * #6  0x0000555556ef1830 in iothread_run (opaque=0x611000024440) at ../iothread.c:63
+ * #7  0x00005555573005c6 in qemu_thread_start (args=0x603000090d30) at ../util/qemu-thread-posix.c:541
+ * #8  0x00007ffff70eac12 in start_thread () at /lib64/libc.so.6
+ * #9  0x00007ffff716fcc0 in clone3 () at /lib64/libc.so.6
+ *
+ * 在以下使用virtio_blk_handle_output():
+ *   - hw/block/virtio-blk.c|2079| <<virtio_blk_device_realize>> virtio_add_queue(vdev, conf->queue_size, virtio_blk_handle_output);
+ */
 static void virtio_blk_handle_output(VirtIODevice *vdev, VirtQueue *vq)
 {
     VirtIOBlock *s = (VirtIOBlock *)vdev;
 
+    /*
+     * 在以下使用VirtIOBlock->ioeventfd_disabled:
+     *   - hw/block/virtio-blk.c|1202| <<virtio_blk_handle_output>> if (!s->ioeventfd_disabled && !s->ioeventfd_started) {
+     *   - hw/block/virtio-blk.c|1207| <<virtio_blk_handle_output>> if (!s->ioeventfd_disabled) {
+     *   - hw/block/virtio-blk.c|2057| <<virtio_blk_start_ioeventfd>> s->ioeventfd_disabled = true;
+     *   - hw/block/virtio-blk.c|2094| <<virtio_blk_stop_ioeventfd>> if (s->ioeventfd_disabled) {
+     *   - hw/block/virtio-blk.c|2095| <<virtio_blk_stop_ioeventfd>> s->ioeventfd_disabled = false;
+     *   - hw/block/virtio-blk.c|2246| <<virtio_blk_device_realize>> s->ioeventfd_disabled = true;
+     */
     if (!s->ioeventfd_disabled && !s->ioeventfd_started) {
         /* Some guests kick before setting VIRTIO_CONFIG_S_DRIVER_OK so start
          * ioeventfd here instead of waiting for .set_status().
@@ -1155,6 +1282,9 @@ static void virtio_blk_handle_output(VirtIODevice *vdev, VirtQueue *vq)
         }
     }
 
+    /*
+     * 只在此处调用
+     */
     virtio_blk_handle_vq(s, vq);
 }
 
@@ -1190,6 +1320,31 @@ static void virtio_blk_dma_restart_bh(void *opaque)
     blk_dec_in_flight(s->conf.conf.blk);
 }
 
+/*
+ * (gdb) bt
+ * #0  virtio_blk_dma_restart_cb (opaque=0x62d00001c830, running=false, state=RUN_STATE_PAUSED) at ../hw/block/virtio-blk.c:1059
+ * #1  0x000055555677f0e8 in vm_state_notify (running=false, state=RUN_STATE_PAUSED) at ../system/runstate.c:380
+ * #2  0x000055555675eefe in do_vm_stop (state=RUN_STATE_PAUSED, send_stop=true) at ../system/cpus.c:290
+ * #3  0x00005555567612ab in vm_stop (state=RUN_STATE_PAUSED) at ../system/cpus.c:697
+ * #4  0x0000555556856668 in qmp_stop (errp=0x0) at ../monitor/qmp-cmds.c:61
+ * #5  0x00005555568490c0 in hmp_stop (mon=0x610000003540, qdict=0x621000231500) at ../monitor/hmp-cmds.c:119
+ * #6  0x0000555556852256 in handle_hmp_command_exec (mon=0x610000003540, cmd=0x555558959120 <hmp_cmds+7680>, qdict=0x621000231500) at ../monitor/hmp.c:1106
+ * #7  0x00005555568526f2 in handle_hmp_command (mon=0x610000003540, cmdline=0x0) at ../monitor/hmp.c:1158
+ * #8  0x000055555684b248 in monitor_command_cb (opaque=0x610000003540, cmdline=0x626000000100 "stop", readline_opaque=0x0) at ../monitor/hmp.c:47
+ * #9  0x0000555557369303 in readline_handle_byte (rs=0x626000000100, ch=13) at ../util/readline.c:419
+ * #10 0x00005555568542ab in monitor_read (opaque=0x610000003540, buf=0x7ffff537e020 "\r", size=1) at ../monitor/hmp.c:1390
+ * #11 0x00005555571298fd in qemu_chr_be_write_impl (s=0x610000003440, buf=0x7ffff537e020 "\r", len=1) at ../chardev/char.c:214
+ * #12 0x00005555571299a8 in qemu_chr_be_write (s=0x610000003440, buf=0x7ffff537e020 "\r", len=1) at ../chardev/char.c:226
+ * #13 0x000055555712e942 in fd_chr_read (chan=0x60b000068160, cond=G_IO_IN, opaque=0x610000003440) at ../chardev/char-fd.c:72
+ * #14 0x0000555556e85ff5 in qio_channel_fd_source_dispatch (source=0x60c000054dc0, callback=0x55555712e6b1 <fd_chr_read>, user_data=0x610000003440) at ../io/channel-watch.c:84
+ * #15 0x00007ffff7533f4f in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #16 0x000055555733abaa in glib_pollfds_poll () at ../util/main-loop.c:287
+ * #17 0x000055555733ad23 in os_host_main_loop_wait (timeout=499000000) at ../util/main-loop.c:310
+ * #18 0x000055555733b03c in main_loop_wait (nonblocking=0) at ../util/main-loop.c:589
+ * #19 0x0000555556780465 in qemu_main_loop () at ../system/runstate.c:795
+ * #20 0x0000555556e39fe2 in qemu_default_main () at ../system/main.c:37
+ * #21 0x0000555556e3a01f in main (argc=42, argv=0x7fffffffda58) at ../system/main.c:48
+ */
 static void virtio_blk_dma_restart_cb(void *opaque, bool running,
                                       RunState state)
 {
@@ -1512,6 +1667,10 @@ static void virtio_blk_resize(void *opaque)
     aio_bh_schedule_oneshot(qemu_get_aio_context(), virtio_resize_cb, vdev);
 }
 
+/*
+ * called by:
+ *   - hw/block/virtio-blk.c|1707| <<virtio_blk_drained_begin>> virtio_blk_ioeventfd_detach(s);
+ */
 static void virtio_blk_ioeventfd_detach(VirtIOBlock *s)
 {
     VirtIODevice *vdev = VIRTIO_DEVICE(s);
@@ -1522,12 +1681,115 @@ static void virtio_blk_ioeventfd_detach(VirtIOBlock *s)
     }
 }
 
+/*
+ * (gdb) bt
+ * #0  virtio_blk_dma_restart_cb (opaque=0x62d00001c830, running=false, state=RUN_STATE_PAUSED) at ../hw/block/virtio-blk.c:1059
+ * #1  0x000055555677f0e8 in vm_state_notify (running=false, state=RUN_STATE_PAUSED) at ../system/runstate.c:380
+ * #2  0x000055555675eefe in do_vm_stop (state=RUN_STATE_PAUSED, send_stop=true) at ../system/cpus.c:290
+ * #3  0x00005555567612ab in vm_stop (state=RUN_STATE_PAUSED) at ../system/cpus.c:697
+ * #4  0x0000555556856668 in qmp_stop (errp=0x0) at ../monitor/qmp-cmds.c:61
+ * #5  0x00005555568490c0 in hmp_stop (mon=0x610000003540, qdict=0x621000231500) at ../monitor/hmp-cmds.c:119
+ * #6  0x0000555556852256 in handle_hmp_command_exec (mon=0x610000003540, cmd=0x555558959120 <hmp_cmds+7680>, qdict=0x621000231500) at ../monitor/hmp.c:1106
+ * #7  0x00005555568526f2 in handle_hmp_command (mon=0x610000003540, cmdline=0x0) at ../monitor/hmp.c:1158
+ * #8  0x000055555684b248 in monitor_command_cb (opaque=0x610000003540, cmdline=0x626000000100 "stop", readline_opaque=0x0) at ../monitor/hmp.c:47
+ * #9  0x0000555557369303 in readline_handle_byte (rs=0x626000000100, ch=13) at ../util/readline.c:419
+ * #10 0x00005555568542ab in monitor_read (opaque=0x610000003540, buf=0x7ffff537e020 "\r", size=1) at ../monitor/hmp.c:1390
+ * #11 0x00005555571298fd in qemu_chr_be_write_impl (s=0x610000003440, buf=0x7ffff537e020 "\r", len=1) at ../chardev/char.c:214
+ * #12 0x00005555571299a8 in qemu_chr_be_write (s=0x610000003440, buf=0x7ffff537e020 "\r", len=1) at ../chardev/char.c:226
+ * #13 0x000055555712e942 in fd_chr_read (chan=0x60b000068160, cond=G_IO_IN, opaque=0x610000003440) at ../chardev/char-fd.c:72
+ * #14 0x0000555556e85ff5 in qio_channel_fd_source_dispatch (source=0x60c000054dc0, callback=0x55555712e6b1 <fd_chr_read>, user_data=0x610000003440) at ../io/channel-watch.c:84
+ * #15 0x00007ffff7533f4f in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #16 0x000055555733abaa in glib_pollfds_poll () at ../util/main-loop.c:287
+ * #17 0x000055555733ad23 in os_host_main_loop_wait (timeout=499000000) at ../util/main-loop.c:310
+ * #18 0x000055555733b03c in main_loop_wait (nonblocking=0) at ../util/main-loop.c:589
+ * #19 0x0000555556780465 in qemu_main_loop () at ../system/runstate.c:795
+ * #20 0x0000555556e39fe2 in qemu_default_main () at ../system/main.c:37
+ * #21 0x0000555556e3a01f in main (argc=42, argv=0x7fffffffda58) at ../system/main.c:48
+ *
+ *
+ * 初始化(BIOS/Kernel)会调用
+ * system_powerdown会调用
+ *
+ * (gdb) bt
+ * #0  virtio_queue_aio_attach_host_notifier (vq=0x7ffddbda4800, ctx=0x613000121880) at ../hw/virtio/virtio.c:3575
+ * #1  0x0000555556ba8095 in virtio_blk_ioeventfd_attach (s=0x62d00001c830) at ../hw/block/virtio-blk.c:1391
+ * #2  0x0000555556ba9e98 in virtio_blk_start_ioeventfd (vdev=0x62d00001c830) at ../hw/block/virtio-blk.c:1721
+ * #3  0x00005555566934ae in virtio_bus_start_ioeventfd (bus=0x62d00001c7b0) at ../hw/virtio/virtio-bus.c:236
+ * #4  0x000055555669686b in virtio_pci_start_ioeventfd (proxy=0x62d000014400) at ../hw/virtio/virtio-pci.c:375
+ * #5  0x000055555669cafe in virtio_pci_common_write (opaque=0x62d000014400, addr=20, val=15, size=1) at ../hw/virtio/virtio-pci.c:1616
+ * #6  0x0000555556d1538b in memory_region_write_accessor (mr=0x62d000014fa0, addr=20, value=0x7ffde5865020, size=1, shift=0, mask=255, attrs=...) at ../system/memory.c:497
+ * #7  0x0000555556d159cf in access_with_adjusted_size (addr=20, value=0x7ffde5865020, size=1, access_size_min=1, access_size_max=4, access_fn=0x555556d15177 <memory_region_write_accessor>, mr=0x62d000014fa0, attrs=...)
+ *     at ../system/memory.c:573
+ * #8  0x0000555556d1dcf0 in memory_region_dispatch_write (mr=0x62d000014fa0, addr=20, data=15, op=MO_8, attrs=...) at ../system/memory.c:1521
+ * #9  0x0000555556d41d5c in flatview_write_continue_step (attrs=..., buf=0x7ffff6205028 "\017", len=1, mr_addr=20, l=0x7ffde5960540, mr=0x62d000014fa0) at ../system/physmem.c:2756
+ * #10 0x0000555556d41f50 in flatview_write_continue (fv=0x606000085e20, addr=4261412884, attrs=..., ptr=0x7ffff6205028, len=1, mr_addr=20, l=1, mr=0x62d000014fa0) at ../system/physmem.c:2786
+ * #11 0x0000555556d42254 in flatview_write (fv=0x606000085e20, addr=4261412884, attrs=..., buf=0x7ffff6205028, len=1) at ../system/physmem.c:2817
+ * #12 0x0000555556d42e3d in address_space_write (as=0x555558d5fda0 <address_space_memory>, addr=4261412884, attrs=..., buf=0x7ffff6205028, len=1) at ../system/physmem.c:2937
+ * #13 0x0000555556d42f00 in address_space_rw (as=0x555558d5fda0 <address_space_memory>, addr=4261412884, attrs=..., buf=0x7ffff6205028, len=1, is_write=true) at ../system/physmem.c:2947
+ * #14 0x0000555556e104c0 in kvm_cpu_exec (cpu=0x62b000000200) at ../accel/kvm/kvm-all.c:3031
+ * #15 0x0000555556e1981b in kvm_vcpu_thread_fn (arg=0x62b000000200) at ../accel/kvm/kvm-accel-ops.c:50
+ * #16 0x00005555573005c6 in qemu_thread_start (args=0x6030000a4b60) at ../util/qemu-thread-posix.c:541
+ * #17 0x00007ffff70eac12 in start_thread () at /lib64/libc.so.6
+ * #18 0x00007ffff716fcc0 in clone3 () at /lib64/libc.so.6
+ *
+ * stop/cont会调用
+ *
+ * (gdb) bt
+ * #0  virtio_queue_aio_attach_host_notifier (vq=0x7ffddbda4c28, ctx=0x613000123100) at ../hw/virtio/virtio.c:3575
+ * #1  0x0000555556ba8095 in virtio_blk_ioeventfd_attach (s=0x62d00001c830) at ../hw/block/virtio-blk.c:1391
+ * #2  0x0000555556ba9e98 in virtio_blk_start_ioeventfd (vdev=0x62d00001c830) at ../hw/block/virtio-blk.c:1721
+ * #3  0x00005555566934ae in virtio_bus_start_ioeventfd (bus=0x62d00001c7b0) at ../hw/virtio/virtio-bus.c:236
+ * #4  0x000055555669686b in virtio_pci_start_ioeventfd (proxy=0x62d000014400) at ../hw/virtio/virtio-pci.c:375
+ * #5  0x000055555669b223 in virtio_pci_vmstate_change (d=0x62d000014400, running=true) at ../hw/virtio/virtio-pci.c:1361
+ * #6  0x0000555556cae295 in virtio_vmstate_change (opaque=0x62d00001c830, running=true, state=RUN_STATE_RUNNING) at ../hw/virtio/virtio.c:3207
+ * #7  0x000055555677ee82 in vm_state_notify (running=true, state=RUN_STATE_RUNNING) at ../system/runstate.c:370
+ * #8  0x00005555567614b9 in vm_prepare_start (step_pending=false) at ../system/cpus.c:740
+ * #9  0x0000555556761535 in vm_start () at ../system/cpus.c:747
+ * #10 0x0000555556856af7 in qmp_cont (errp=0x7ffff4c74e60) at ../monitor/qmp-cmds.c:114
+ * #11 0x00005555568495d0 in hmp_cont (mon=0x610000003540, qdict=0x621000138900) at ../monitor/hmp-cmds.c:171
+ * #12 0x0000555556852256 in handle_hmp_command_exec (mon=0x610000003540, cmd=0x5555589579b0 <hmp_cmds+1680>, qdict=0x621000138900) at ../monitor/hmp.c:1106
+ * #13 0x00005555568526f2 in handle_hmp_command (mon=0x610000003540, cmdline=0x0) at ../monitor/hmp.c:1158
+ * #14 0x000055555684b248 in monitor_command_cb (opaque=0x610000003540, cmdline=0x626000000100 "cont", readline_opaque=0x0) at ../monitor/hmp.c:47
+ * #15 0x0000555557369303 in readline_handle_byte (rs=0x626000000100, ch=13) at ../util/readline.c:419
+ * #16 0x00005555568542ab in monitor_read (opaque=0x610000003540, buf=0x7ffff535a020 "\r", size=1) at ../monitor/hmp.c:1390
+ * #17 0x00005555571298fd in qemu_chr_be_write_impl (s=0x610000003440, buf=0x7ffff535a020 "\r", len=1) at ../chardev/char.c:214
+ * #18 0x00005555571299a8 in qemu_chr_be_write (s=0x610000003440, buf=0x7ffff535a020 "\r", len=1) at ../chardev/char.c:226
+ * #19 0x000055555712e942 in fd_chr_read (chan=0x60b000068160, cond=G_IO_IN, opaque=0x610000003440) at ../chardev/char-fd.c:72
+ * #20 0x0000555556e85ff5 in qio_channel_fd_source_dispatch (source=0x60c000054dc0, callback=0x55555712e6b1 <fd_chr_read>, user_data=0x610000003440) at ../io/channel-watch.c:84
+ * #21 0x00007ffff7533f4f in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #22 0x000055555733abaa in glib_pollfds_poll () at ../util/main-loop.c:287
+ * #23 0x000055555733ad23 in os_host_main_loop_wait (timeout=499000000) at ../util/main-loop.c:310
+ * #24 0x000055555733b03c in main_loop_wait (nonblocking=0) at ../util/main-loop.c:589
+ * #25 0x0000555556780465 in qemu_main_loop () at ../system/runstate.c:795
+ * #26 0x0000555556e39fe2 in qemu_default_main () at ../system/main.c:37
+ * #27 0x0000555556e3a01f in main (argc=42, argv=0x7fffffffda58) at ../system/main.c:48
+ *
+ * called by:
+ *   - hw/block/virtio-blk.c|1605| <<virtio_blk_drained_end>> virtio_blk_ioeventfd_attach(s);
+ *   - hw/block/virtio-blk.c|1934| <<virtio_blk_start_ioeventfd>> virtio_blk_ioeventfd_attach(s);
+ */
 static void virtio_blk_ioeventfd_attach(VirtIOBlock *s)
 {
     VirtIODevice *vdev = VIRTIO_DEVICE(s);
 
     for (uint16_t i = 0; i < s->conf.num_queues; i++) {
         VirtQueue *vq = virtio_get_queue(vdev, i);
+        /*
+	 * 在以下使用vq_aio_context[][]:
+	 *   - hw/block/virtio-blk.c|1261| <<virtio_blk_dma_restart_cb>> aio_bh_schedule_oneshot(s->vq_aio_context[i], virtio_blk_dma_restart_bh, vq_rq[i]);
+	 *   - hw/block/virtio-blk.c|1549| <<virtio_blk_ioeventfd_detach>> virtio_queue_aio_detach_host_notifier(vq, s->vq_aio_context[i]);
+	 *   - hw/block/virtio-blk.c|1559| <<virtio_blk_ioeventfd_attach>> virtio_queue_aio_attach_host_notifier(vq, s->vq_aio_context[i]);
+	 *   - hw/block/virtio-blk.c|1749| <<virtio_blk_vq_aio_context_init>> s->vq_aio_context = g_new(AioContext *, conf->num_queues);
+	 *   - hw/block/virtio-blk.c|1753| <<virtio_blk_vq_aio_context_init>> if (!apply_iothread_vq_mapping(conf->iothread_vq_mapping_list, s->vq_aio_context, conf->num_queues, errp)) {
+	 *   - hw/block/virtio-blk.c|1756| <<virtio_blk_vq_aio_context_init>> g_free(s->vq_aio_context);
+	 *   - hw/block/virtio-blk.c|1757| <<virtio_blk_vq_aio_context_init>> s->vq_aio_context = NULL;
+	 *   - hw/block/virtio-blk.c|1763| <<virtio_blk_vq_aio_context_init>> s->vq_aio_context[i] = ctx;
+	 *   - hw/block/virtio-blk.c|1771| <<virtio_blk_vq_aio_context_init>> s->vq_aio_context[i] = ctx;
+	 *   - hw/block/virtio-blk.c|1798| <<virtio_blk_vq_aio_context_cleanup>> g_free(s->vq_aio_context);
+	 *   - hw/block/virtio-blk.c|1799| <<virtio_blk_vq_aio_context_cleanup>> s->vq_aio_context = NULL;
+	 *   - hw/block/virtio-blk.c|1864| <<virtio_blk_start_ioeventfd>> r = blk_set_aio_context(s->conf.conf.blk, s->vq_aio_context[0], &local_err);
+	 *   - hw/block/virtio-blk.c|1943| <<virtio_blk_stop_ioeventfd>> AioContext *ctx = s->vq_aio_context[i];
+	 */
         virtio_queue_aio_attach_host_notifier(vq, s->vq_aio_context[i]);
     }
 }
@@ -1632,6 +1894,10 @@ validate_iothread_vq_mapping_list(IOThreadVirtQueueMappingList *list,
  *
  * Returns: %true on success, %false on failure.
  **/
+/*
+ * called by:
+ *   - hw/block/virtio-blk.c|1752| <<virtio_blk_vq_aio_context_init>> if (!apply_iothread_vq_mapping(conf->iothread_vq_mapping_list, s->vq_aio_context, conf->num_queues, errp)) {
+ */
 static bool apply_iothread_vq_mapping(
         IOThreadVirtQueueMappingList *iothread_vq_mapping_list,
         AioContext **vq_aio_context,
@@ -1652,6 +1918,14 @@ static bool apply_iothread_vq_mapping(
     }
 
     for (node = iothread_vq_mapping_list; node; node = node->next) {
+        /*
+	 * called by:
+	 *   - block/export/export.c|123| <<blk_exp_add>> iothread = iothread_by_id(export->iothread);
+	 *   - blockdev.c|3560| <<qmp_x_blockdev_set_iothread>> IOThread *obj = iothread_by_id(iothread->u.s);
+	 *   - hw/block/virtio-blk.c|1601| <<validate_iothread_vq_mapping_list>> if (!iothread_by_id(name)) {
+	 *   - hw/block/virtio-blk.c|1683| <<apply_iothread_vq_mapping>> IOThread *iothread = iothread_by_id(node->value->iothread);
+	 *   - hw/block/virtio-blk.c|1789| <<virtio_blk_vq_aio_context_cleanup>> IOThread *iothread = iothread_by_id(node->value->iothread);
+	 */
         IOThread *iothread = iothread_by_id(node->value->iothread);
         AioContext *ctx = iothread_get_aio_context(iothread);
 
@@ -1680,6 +1954,13 @@ static bool apply_iothread_vq_mapping(
     return true;
 }
 
+/*
+ * called by:
+ *   - hw/block/virtio-blk.c|2088| <<virtio_blk_device_realize>> virtio_blk_vq_aio_context_init(s, &err);
+ *
+ * VirtIOBlock *s:
+ * -> AioContext **vq_aio_context;
+ */
 /* Context: BQL held */
 static bool virtio_blk_vq_aio_context_init(VirtIOBlock *s, Error **errp)
 {
@@ -1771,6 +2052,10 @@ static void virtio_blk_vq_aio_context_cleanup(VirtIOBlock *s)
     s->vq_aio_context = NULL;
 }
 
+/*
+ * 在以下使用virtio_blk_start_ioeventfd():
+ *   - hw/block/virtio-blk.c|2254| <<virtio_blk_class_init>> vdc->start_ioeventfd = virtio_blk_start_ioeventfd;
+ */
 /* Context: BQL held */
 static int virtio_blk_start_ioeventfd(VirtIODevice *vdev)
 {
@@ -1959,9 +2244,48 @@ static void virtio_blk_stop_ioeventfd(VirtIODevice *vdev)
     s->ioeventfd_stopping = false;
 }
 
+/*
+ * (gdb) bt
+ * #0  virtio_blk_device_realize (dev=0x5555580dc630, errp=0x7fffffffd0c0) at ../hw/block/virtio-blk.c:1963
+ * #1  0x0000555555ddca97 in virtio_device_realize (dev=0x5555580dc630, errp=0x7fffffffd120) at ../hw/virtio/virtio.c:3717
+ * #2  0x0000555555e8f7e6 in device_set_realized (obj=0x5555580dc630, value=true, errp=0x7fffffffd3e0) at ../hw/core/qdev.c:510
+ * #3  0x0000555555e9b328 in property_set_bool (obj=0x5555580dc630, v=0x5555580e7b40, name=0x555556331b21 "realized", opaque=0x555557178e90, errp=0x7fffffffd3e0)
+ *     at ../qom/object.c:2358
+ * #4  0x0000555555e98e36 in object_property_set (obj=0x5555580dc630, name=0x555556331b21 "realized", v=0x5555580e7b40, errp=0x7fffffffd3e0) at ../qom/object.c:1472
+ * #5  0x0000555555e9dba3 in object_property_set_qobject (obj=0x5555580dc630, name=0x555556331b21 "realized", value=0x5555580e7a80, errp=0x7fffffffd3e0) at ../qom/qom-qobject.c:28
+ * #6  0x0000555555e991eb in object_property_set_bool (obj=0x5555580dc630, name=0x555556331b21 "realized", value=true, errp=0x7fffffffd3e0) at ../qom/object.c:1541
+ * #7  0x0000555555e8eed3 in qdev_realize (dev=0x5555580dc630, bus=0x5555580dc5b0, errp=0x7fffffffd3e0) at ../hw/core/qdev.c:292
+ * #8  0x0000555555dfd710 in virtio_blk_pci_realize (vpci_dev=0x5555580d4260, errp=0x7fffffffd3e0) at ../hw/virtio/virtio-blk-pci.c:64
+ * #9  0x0000555555b60e6d in virtio_pci_realize (pci_dev=0x5555580d4260, errp=0x7fffffffd3e0) at ../hw/virtio/virtio-pci.c:2259
+ * #10 0x0000555555a812cf in pci_qdev_realize (qdev=0x5555580d4260, errp=0x7fffffffd4a0) at ../hw/pci/pci.c:2093
+ * #11 0x0000555555b6127f in virtio_pci_dc_realize (qdev=0x5555580d4260, errp=0x7fffffffd4a0) at ../hw/virtio/virtio-pci.c:2351
+ * #12 0x0000555555e8f7e6 in device_set_realized (obj=0x5555580d4260, value=true, errp=0x7fffffffd710) at ../hw/core/qdev.c:510
+ * #13 0x0000555555e9b328 in property_set_bool (obj=0x5555580d4260, v=0x5555580e0e00, name=0x555556331b21 "realized", opaque=0x555557178e90, errp=0x7fffffffd710)
+ *     at ../qom/object.c:2358
+ * #14 0x0000555555e98e36 in object_property_set (obj=0x5555580d4260, name=0x555556331b21 "realized", v=0x5555580e0e00, errp=0x7fffffffd710) at ../qom/object.c:1472
+ * #15 0x0000555555e9dba3 in object_property_set_qobject (obj=0x5555580d4260, name=0x555556331b21 "realized", value=0x555557401a80, errp=0x7fffffffd710) at ../qom/qom-qobject.c:28
+ * #16 0x0000555555e991eb in object_property_set_bool (obj=0x5555580d4260, name=0x555556331b21 "realized", value=true, errp=0x7fffffffd710) at ../qom/object.c:1541
+ * #17 0x0000555555e8eed3 in qdev_realize (dev=0x5555580d4260, bus=0x55555761c5a0, errp=0x7fffffffd710) at ../hw/core/qdev.c:292
+ * #18 0x0000555555bbc55d in qdev_device_add_from_qdict (opts=0x5555580d3220, from_json=false, errp=0x7fffffffd710) at ../system/qdev-monitor.c:718
+ * #19 0x0000555555bbc611 in qdev_device_add (opts=0x55555716d840, errp=0x5555570af7c0 <error_fatal>) at ../system/qdev-monitor.c:737
+ * #20 0x0000555555bc6d64 in device_init_func (opaque=0x0, opts=0x55555716d840, errp=0x5555570af7c0 <error_fatal>) at ../system/vl.c:1200
+ * #21 0x00005555560c439e in qemu_opts_foreach (list=0x555556f98e80 <qemu_device_opts>, func=0x555555bc6d35 <device_init_func>, opaque=0x0, errp=0x5555570af7c0 <error_fatal>)
+ *     at ../util/qemu-option.c:1135
+ * #22 0x0000555555bcac00 in qemu_create_cli_devices () at ../system/vl.c:2637
+ * #23 0x0000555555bcae46 in qmp_x_exit_preconfig (errp=0x5555570af7c0 <error_fatal>) at ../system/vl.c:2706
+ * #24 0x0000555555bcd92e in qemu_init (argc=30, argv=0x7fffffffdb18) at ../system/vl.c:3739
+ * #25 0x0000555555e8a1ef in main (argc=30, argv=0x7fffffffdb18) at ../system/main.c:47
+ */
 static void virtio_blk_device_realize(DeviceState *dev, Error **errp)
 {
     VirtIODevice *vdev = VIRTIO_DEVICE(dev);
+    /*
+     * struct VirtIOBlock {
+     * -> BlockBackend *blk;
+     * -> VirtIOBlkConf conf;
+     *    -> BlockConf conf;
+     *       -> BlockBackend *blk;
+     */
     VirtIOBlock *s = VIRTIO_BLK(dev);
     VirtIOBlkConf *conf = &s->conf;
     BlockDriverState *bs;
@@ -2071,6 +2395,12 @@ static void virtio_blk_device_realize(DeviceState *dev, Error **errp)
      * This must be after virtio_init() so virtio_blk_dma_restart_cb() gets
      * called after ->start_ioeventfd() has already set blk's AioContext.
      */
+    /*
+     * called by:
+     *   - hw/block/virtio-blk.c|2157| <<virtio_blk_device_realize>> qdev_add_vm_change_state_handler(dev, virtio_blk_dma_restart_cb, s);
+     *   - hw/scsi/scsi-bus.c|358| <<scsi_qdev_realize>> dev->vmsentry = qdev_add_vm_change_state_handler(DEVICE(dev), scsi_dma_restart_cb, dev);
+     *   - hw/virtio/virtio.c|3285| <<virtio_init>> vdev->vmstate = qdev_add_vm_change_state_handler(DEVICE(vdev), virtio_vmstate_change, vdev);
+     */
     s->change =
         qdev_add_vm_change_state_handler(dev, virtio_blk_dma_restart_cb, s);
 
diff --git a/hw/core/qdev-properties-system.c b/hw/core/qdev-properties-system.c
index d79d6f4b5..cbfea4de7 100644
--- a/hw/core/qdev-properties-system.c
+++ b/hw/core/qdev-properties-system.c
@@ -133,6 +133,9 @@ static void set_drive_helper(Object *obj, Visitor *v, const char *name,
 
     blk = blk_by_name(str);
     if (!blk) {
+        /*
+	 * bs是已经有的
+	 */
         bs = bdrv_lookup_bs(NULL, str, NULL);
         if (bs) {
             /*
@@ -173,6 +176,9 @@ static void set_drive_helper(Object *obj, Visitor *v, const char *name,
         goto fail;
     }
 
+    /*
+     * 这里设置的!
+     */
     *ptr = blk;
 
 fail:
diff --git a/hw/core/vm-change-state-handler.c b/hw/core/vm-change-state-handler.c
index 8e2639224..5f1c759b4 100644
--- a/hw/core/vm-change-state-handler.c
+++ b/hw/core/vm-change-state-handler.c
@@ -52,6 +52,88 @@ static int qdev_get_dev_tree_depth(DeviceState *dev)
  *
  * Returns: an entry to be freed with qemu_del_vm_change_state_handler()
  */
+/*
+ * 先
+ * (gdb) bt
+ * #0  qdev_add_vm_change_state_handler (dev=0x62d00001c830, cb=0x555556cae0c9 <virtio_vmstate_change>, opaque=0x62d00001c830) at ../hw/core/vm-change-state-handler.c:59
+ * #1  0x0000555556caea60 in virtio_init (vdev=0x62d00001c830, device_id=2, config_size=57) at ../hw/virtio/virtio.c:3263
+ * #2  0x0000555556baaf85 in virtio_blk_device_realize (dev=0x62d00001c830, errp=0x7ffff4cdeda0) at ../hw/block/virtio-blk.c:1902
+ * #3  0x0000555556cb0bab in virtio_device_realize (dev=0x62d00001c830, errp=0x7ffff4cdec20) at ../hw/virtio/virtio.c:3718
+ * #4  0x0000555556e45110 in device_set_realized (obj=0x62d00001c830, value=true, errp=0x7ffff4cde0a0) at ../hw/core/qdev.c:510
+ * #5  0x0000555556e5c5b5 in property_set_bool (obj=0x62d00001c830, v=0x61100009bcc0, name=0x555557875960 "realized", opaque=0x60200000c5f0, errp=0x7ffff4cde0a0) at ../qom/object.c:2354
+ * #6  0x0000555556e57a50 in object_property_set (obj=0x62d00001c830, name=0x555557875960 "realized", v=0x61100009bcc0, errp=0x7ffff4cde0a0) at ../qom/object.c:1463
+ * #7  0x0000555556e6148d in object_property_set_qobject (obj=0x62d00001c830, name=0x555557875960 "realized", value=0x6030000d1560, errp=0x7ffff4cde0a0) at ../qom/qom-qobject.c:28
+ * #8  0x0000555556e57fca in object_property_set_bool (obj=0x62d00001c830, name=0x555557875960 "realized", value=true, errp=0x7ffff4cde0a0) at ../qom/object.c:1533
+ * #9  0x0000555556e43fba in qdev_realize (dev=0x62d00001c830, bus=0x62d00001c7b0, errp=0x7ffff4cde0a0) at ../hw/core/qdev.c:291
+ * #10 0x0000555556cfb5c4 in virtio_blk_pci_realize (vpci_dev=0x62d000014400, errp=0x7ffff4cde0a0) at ../hw/virtio/virtio-blk-pci.c:64
+ * #11 0x00005555566a0878 in virtio_pci_realize (pci_dev=0x62d000014400, errp=0x7ffff4cde0a0) at ../hw/virtio/virtio-pci.c:2259
+ * #12 0x0000555556475b08 in pci_qdev_realize (qdev=0x62d000014400, errp=0x7ffff4cddde0) at ../hw/pci/pci.c:2093
+ * #13 0x00005555566a10f7 in virtio_pci_dc_realize (qdev=0x62d000014400, errp=0x7ffff4cddde0) at ../hw/virtio/virtio-pci.c:2351
+ * #14 0x0000555556e45110 in device_set_realized (obj=0x62d000014400, value=true, errp=0x7ffff4de17c0) at ../hw/core/qdev.c:510
+ * #15 0x0000555556e5c5b5 in property_set_bool (obj=0x62d000014400, v=0x61100009bb80, name=0x555557875960 "realized", opaque=0x60200000c5f0, errp=0x7ffff4de17c0) at ../qom/object.c:2354
+ * #16 0x0000555556e57a50 in object_property_set (obj=0x62d000014400, name=0x555557875960 "realized", v=0x61100009bb80, errp=0x7ffff4de17c0) at ../qom/object.c:1463
+ * #17 0x0000555556e6148d in object_property_set_qobject (obj=0x62d000014400, name=0x555557875960 "realized", value=0x6030000d0fc0, errp=0x7ffff4de17c0) at ../qom/qom-qobject.c:28
+ * #18 0x0000555556e57fca in object_property_set_bool (obj=0x62d000014400, name=0x555557875960 "realized", value=true, errp=0x7ffff4de17c0) at ../qom/object.c:1533
+ * #19 0x0000555556e43fba in qdev_realize (dev=0x62d000014400, bus=0x61d000102c80, errp=0x7ffff4de17c0) at ../hw/core/qdev.c:291
+ * #20 0x0000555556771f7e in qdev_device_add_from_qdict (opts=0x62100000dd00, from_json=true, errp=0x7ffff4de17c0) at ../system/qdev-monitor.c:719
+ * #21 0x000055555678ec8b in qemu_create_cli_devices () at ../system/vl.c:2656
+ * #22 0x000055555678f001 in qmp_x_exit_preconfig (errp=0x555558dc1a00 <error_fatal>) at ../system/vl.c:2713
+ * #23 0x0000555556793f88 in qemu_init (argc=34, argv=0x7fffffffdb78) at ../system/vl.c:3758
+ * #24 0x0000555556e3a016 in main (argc=34, argv=0x7fffffffdb78) at ../system/main.c:47
+ *
+ * 再
+ * (gdb) bt
+ * #0  qdev_add_vm_change_state_handler (dev=0x62d00001c830, cb=0x555556ba5184 <virtio_blk_dma_restart_cb>, opaque=0x62d00001c830) at ../hw/core/vm-change-state-handler.c:59
+ * #1  0x0000555556bab377 in virtio_blk_device_realize (dev=0x62d00001c830, errp=0x7ffff4cdeda0) at ../hw/block/virtio-blk.c:1935
+ * #2  0x0000555556cb0bab in virtio_device_realize (dev=0x62d00001c830, errp=0x7ffff4cdec20) at ../hw/virtio/virtio.c:3718
+ * #3  0x0000555556e45110 in device_set_realized (obj=0x62d00001c830, value=true, errp=0x7ffff4cde0a0) at ../hw/core/qdev.c:510
+ * #4  0x0000555556e5c5b5 in property_set_bool (obj=0x62d00001c830, v=0x61100009bcc0, name=0x555557875960 "realized", opaque=0x60200000c5f0, errp=0x7ffff4cde0a0) at ../qom/object.c:2354
+ * #5  0x0000555556e57a50 in object_property_set (obj=0x62d00001c830, name=0x555557875960 "realized", v=0x61100009bcc0, errp=0x7ffff4cde0a0) at ../qom/object.c:1463
+ * #6  0x0000555556e6148d in object_property_set_qobject (obj=0x62d00001c830, name=0x555557875960 "realized", value=0x6030000d1560, errp=0x7ffff4cde0a0) at ../qom/qom-qobject.c:28
+ * #7  0x0000555556e57fca in object_property_set_bool (obj=0x62d00001c830, name=0x555557875960 "realized", value=true, errp=0x7ffff4cde0a0) at ../qom/object.c:1533
+ * #8  0x0000555556e43fba in qdev_realize (dev=0x62d00001c830, bus=0x62d00001c7b0, errp=0x7ffff4cde0a0) at ../hw/core/qdev.c:291
+ * #9  0x0000555556cfb5c4 in virtio_blk_pci_realize (vpci_dev=0x62d000014400, errp=0x7ffff4cde0a0) at ../hw/virtio/virtio-blk-pci.c:64
+ * #10 0x00005555566a0878 in virtio_pci_realize (pci_dev=0x62d000014400, errp=0x7ffff4cde0a0) at ../hw/virtio/virtio-pci.c:2259
+ * #11 0x0000555556475b08 in pci_qdev_realize (qdev=0x62d000014400, errp=0x7ffff4cddde0) at ../hw/pci/pci.c:2093
+ * #12 0x00005555566a10f7 in virtio_pci_dc_realize (qdev=0x62d000014400, errp=0x7ffff4cddde0) at ../hw/virtio/virtio-pci.c:2351
+ * #13 0x0000555556e45110 in device_set_realized (obj=0x62d000014400, value=true, errp=0x7ffff4de17c0) at ../hw/core/qdev.c:510
+ * #14 0x0000555556e5c5b5 in property_set_bool (obj=0x62d000014400, v=0x61100009bb80, name=0x555557875960 "realized", opaque=0x60200000c5f0, errp=0x7ffff4de17c0) at ../qom/object.c:2354
+ * #15 0x0000555556e57a50 in object_property_set (obj=0x62d000014400, name=0x555557875960 "realized", v=0x61100009bb80, errp=0x7ffff4de17c0) at ../qom/object.c:1463
+ * #16 0x0000555556e6148d in object_property_set_qobject (obj=0x62d000014400, name=0x555557875960 "realized", value=0x6030000d0fc0, errp=0x7ffff4de17c0) at ../qom/qom-qobject.c:28
+ * #17 0x0000555556e57fca in object_property_set_bool (obj=0x62d000014400, name=0x555557875960 "realized", value=true, errp=0x7ffff4de17c0) at ../qom/object.c:1533
+ * #18 0x0000555556e43fba in qdev_realize (dev=0x62d000014400, bus=0x61d000102c80, errp=0x7ffff4de17c0) at ../hw/core/qdev.c:291
+ * #19 0x0000555556771f7e in qdev_device_add_from_qdict (opts=0x62100000dd00, from_json=true, errp=0x7ffff4de17c0) at ../system/qdev-monitor.c:719
+ * #20 0x000055555678ec8b in qemu_create_cli_devices () at ../system/vl.c:2656
+ * #21 0x000055555678f001 in qmp_x_exit_preconfig (errp=0x555558dc1a00 <error_fatal>) at ../system/vl.c:2713
+ * #22 0x0000555556793f88 in qemu_init (argc=34, argv=0x7fffffffdb78) at ../system/vl.c:3758
+ * #23 0x0000555556e3a016 in main (argc=34, argv=0x7fffffffdb78) at ../system/main.c:47
+ *
+ * 先
+ * (gdb) bt
+ * #0  virtio_vmstate_change (opaque=0x62d00001c830, running=true, state=RUN_STATE_RUNNING) at ../hw/virtio/virtio.c:3196
+ * #1  0x000055555677ee82 in vm_state_notify (running=true, state=RUN_STATE_RUNNING) at ../system/runstate.c:370
+ * #2  0x00005555567614b9 in vm_prepare_start (step_pending=false) at ../system/cpus.c:740
+ * #3  0x0000555556761535 in vm_start () at ../system/cpus.c:747
+ * #4  0x0000555556856af7 in qmp_cont (errp=0x0) at ../monitor/qmp-cmds.c:114
+ * #5  0x000055555678f234 in qmp_x_exit_preconfig (errp=0x555558dc1a00 <error_fatal>) at ../system/vl.c:2738
+ * #6  0x0000555556793f88 in qemu_init (argc=34, argv=0x7fffffffdb78) at ../system/vl.c:3758
+ * #7  0x0000555556e3a016 in main (argc=34, argv=0x7fffffffdb78) at ../system/main.c:47
+ *
+ * 再
+ * #0  virtio_blk_dma_restart_cb (opaque=0x62d00001c830, running=true, state=RUN_STATE_RUNNING) at ../hw/block/virtio-blk.c:1059
+ * #1  0x000055555677ee82 in vm_state_notify (running=true, state=RUN_STATE_RUNNING) at ../system/runstate.c:370
+ * #2  0x00005555567614b9 in vm_prepare_start (step_pending=false) at ../system/cpus.c:740
+ * #3  0x0000555556761535 in vm_start () at ../system/cpus.c:747
+ * #4  0x0000555556856af7 in qmp_cont (errp=0x0) at ../monitor/qmp-cmds.c:114
+ * #5  0x000055555678f234 in qmp_x_exit_preconfig (errp=0x555558dc1a00 <error_fatal>) at ../system/vl.c:2738
+ * #6  0x0000555556793f88 in qemu_init (argc=34, argv=0x7fffffffdb78) at ../system/vl.c:3758
+ * #7  0x0000555556e3a016 in main (argc=34, argv=0x7fffffffdb78) at ../system/main.c:47
+ *
+ * called by:
+ *   - hw/block/virtio-blk.c|2157| <<virtio_blk_device_realize>> qdev_add_vm_change_state_handler(dev, virtio_blk_dma_restart_cb, s);
+ *   - hw/scsi/scsi-bus.c|358| <<scsi_qdev_realize>> dev->vmsentry = qdev_add_vm_change_state_handler(DEVICE(dev), scsi_dma_restart_cb, dev);
+ *   - hw/virtio/virtio.c|3285| <<virtio_init>> vdev->vmstate = qdev_add_vm_change_state_handler(DEVICE(vdev), virtio_vmstate_change, vdev);
+ */
 VMChangeStateEntry *qdev_add_vm_change_state_handler(DeviceState *dev,
                                                      VMChangeStateHandler *cb,
                                                      void *opaque)
@@ -63,6 +145,11 @@ VMChangeStateEntry *qdev_add_vm_change_state_handler(DeviceState *dev,
  * Exactly like qdev_add_vm_change_state_handler() but passes a prepare_cb
  * argument too.
  */
+/*
+ * 在以下使用qdev_add_vm_change_state_handler_full():
+ *   - hw/core/vm-change-state-handler.c|59| <<qdev_add_vm_change_state_handler>> return qdev_add_vm_change_state_handler_full(dev, cb, NULL, opaque);
+ *   - hw/vfio/migration.c|859| <<vfio_migration_init>> migration->vm_state = qdev_add_vm_change_state_handler_full(vbasedev->dev, vfio_vmstate_change, prepare_cb, vbasedev);
+ */
 VMChangeStateEntry *qdev_add_vm_change_state_handler_full(
     DeviceState *dev, VMChangeStateHandler *cb,
     VMChangeStateHandler *prepare_cb, void *opaque)
diff --git a/hw/i386/kvm/apic.c b/hw/i386/kvm/apic.c
index a72c28e8a..69ffa20bd 100644
--- a/hw/i386/kvm/apic.c
+++ b/hw/i386/kvm/apic.c
@@ -179,6 +179,20 @@ static void kvm_apic_external_nmi(APICCommonState *s)
     run_on_cpu(CPU(s->cpu), do_inject_external_nmi, RUN_ON_CPU_HOST_PTR(s));
 }
 
+/*
+ * 在以下使用APICommonClass->send_msi:
+ *   - hw/i386/amd_iommu.c|1382| <<amdvi_mem_ir_write>> apic_get_class(NULL)->send_msi(&to);
+ *   - hw/i386/intel_iommu.c|400| <<vtd_generate_interrupt>> apic_get_class(NULL)->send_msi(&msi);
+ *   - hw/i386/intel_iommu.c|3628| <<vtd_mem_ir_write>> apic_get_class(NULL)->send_msi(&to);
+ *   - hw/i386/kvm/apic.c|257| <<kvm_apic_class_init>> k->send_msi = kvm_send_msi;
+ *   - hw/i386/xen/xen_apic.c|89| <<xen_apic_class_init>> k->send_msi = xen_send_msi;
+ *   - hw/intc/apic.c|1193| <<apic_class_init>> k->send_msi = apic_send_msi;
+ *   - target/i386/whpx/whpx-apic.c|267| <<whpx_apic_class_init>> k->send_msi = whpx_send_msi;
+ *
+ * 在以下使用kvm_send_msi():
+ *   - hw/i386/kvm/apic.c|211| <<kvm_apic_mem_write>> kvm_send_msi(&msg);
+ *   - hw/i386/kvm/apic.c|257| <<kvm_apic_class_init>> k->send_msi = kvm_send_msi;
+ */
 static void kvm_send_msi(MSIMessage *msg)
 {
     int ret;
diff --git a/hw/net/virtio-net.c b/hw/net/virtio-net.c
index 24e5e7d34..e76eeb42c 100644
--- a/hw/net/virtio-net.c
+++ b/hw/net/virtio-net.c
@@ -2717,6 +2717,14 @@ static void virtio_net_tx_complete(NetClientState *nc, ssize_t len)
     }
 }
 
+/*
+ * called by:
+ *   - hw/net/virtio-net.c|2702| <<virtio_net_tx_complete>> ret = virtio_net_flush_tx(q);
+ *   - hw/net/virtio-net.c|2894| <<virtio_net_tx_timer>> ret = virtio_net_flush_tx(q);
+ *   - hw/net/virtio-net.c|2914| <<virtio_net_tx_timer>> ret = virtio_net_flush_tx(q);
+ *   - hw/net/virtio-net.c|2944| <<virtio_net_tx_bh>> ret = virtio_net_flush_tx(q);
+ *   - hw/net/virtio-net.c|2962| <<virtio_net_tx_bh>> ret = virtio_net_flush_tx(q);
+ */
 /* TX */
 static int32_t virtio_net_flush_tx(VirtIONetQueue *q)
 {
@@ -2740,6 +2748,20 @@ static int32_t virtio_net_flush_tx(VirtIONetQueue *q)
         struct iovec sg[VIRTQUEUE_MAX_SIZE], sg2[VIRTQUEUE_MAX_SIZE + 1], *out_sg;
         struct virtio_net_hdr_v1_hash vhdr;
 
+        /*
+	 * typedef struct VirtQueueElement
+	 * {
+	 *     unsigned int index;
+	 *     unsigned int len;
+	 *     unsigned int ndescs;
+	 *     unsigned int out_num;
+	 *     unsigned int in_num;
+	 *     hwaddr *in_addr;
+	 *     hwaddr *out_addr;
+	 *     struct iovec *in_sg;
+	 *     struct iovec *out_sg;
+	 * } VirtQueueElement;
+	 */
         elem = virtqueue_pop(q->tx_vq, sizeof(VirtQueueElement));
         if (!elem) {
             break;
diff --git a/hw/pci/msi.c b/hw/pci/msi.c
index 8104ac1d9..618d2091e 100644
--- a/hw/pci/msi.c
+++ b/hw/pci/msi.c
@@ -375,6 +375,16 @@ void msi_notify(PCIDevice *dev, unsigned int vector)
     msi_send_message(dev, msg);
 }
 
+/*
+ * 在以下使用APICommonClass->send_msi:
+ *   - hw/i386/amd_iommu.c|1382| <<amdvi_mem_ir_write>> apic_get_class(NULL)->send_msi(&to);
+ *   - hw/i386/intel_iommu.c|400| <<vtd_generate_interrupt>> apic_get_class(NULL)->send_msi(&msi);
+ *   - hw/i386/intel_iommu.c|3628| <<vtd_mem_ir_write>> apic_get_class(NULL)->send_msi(&to);
+ *   - hw/i386/kvm/apic.c|257| <<kvm_apic_class_init>> k->send_msi = kvm_send_msi;
+ *   - hw/i386/xen/xen_apic.c|89| <<xen_apic_class_init>> k->send_msi = xen_send_msi;
+ *   - hw/intc/apic.c|1193| <<apic_class_init>> k->send_msi = apic_send_msi;
+ *   - target/i386/whpx/whpx-apic.c|267| <<whpx_apic_class_init>> k->send_msi = whpx_send_msi;
+ */
 void msi_send_message(PCIDevice *dev, MSIMessage msg)
 {
     dev->msi_trigger(dev, msg);
diff --git a/hw/pci/msix.c b/hw/pci/msix.c
index 487e49834..a4b563fda 100644
--- a/hw/pci/msix.c
+++ b/hw/pci/msix.c
@@ -71,11 +71,24 @@ static uint8_t *msix_pending_byte(PCIDevice *dev, int vector)
     return dev->msix_pba + vector / 8;
 }
 
+/*
+ * called by:
+ *   - hw/pci/msix.c|142| <<msix_handle_mask_update>> if (!is_masked && msix_is_pending(dev, vector)) {
+ */
 static int msix_is_pending(PCIDevice *dev, int vector)
 {
     return *msix_pending_byte(dev, vector) & msix_pending_mask(vector);
 }
 
+/*
+ * called by:
+ *   - hw/misc/ivshmem.c|346| <<ivshmem_vector_poll>> msix_set_pending(dev, vector);
+ *   - hw/pci/msix.c|536| <<msix_notify>> msix_set_pending(dev, vector);
+ *   - hw/virtio/virtio-pci.c|1143| <<virtio_pci_vector_poll>> msix_set_pending(dev, vector);
+ *   - hw/virtio/virtio-pci.c|1146| <<virtio_pci_vector_poll>> msix_set_pending(dev, vector);
+ *   - hw/virtio/virtio-pci.c|1161| <<virtio_pci_vector_poll>> msix_set_pending(dev, vector);
+ *   - hw/virtio/virtio-pci.c|1164| <<virtio_pci_vector_poll>> msix_set_pending(dev, vector);
+ */
 void msix_set_pending(PCIDevice *dev, unsigned int vector)
 {
     *msix_pending_byte(dev, vector) |= msix_pending_mask(vector);
@@ -104,12 +117,22 @@ bool msix_is_masked(PCIDevice *dev, unsigned int vector)
     return msix_vector_masked(dev, vector, dev->msix_function_masked);
 }
 
+/*
+ * 在以下使用msix_fire_vector_notifier():
+ *   - hw/pci/msix.c|140| <<msix_handle_mask_update>> msix_fire_vector_notifier(dev, vector, is_masked);
+ */
 static void msix_fire_vector_notifier(PCIDevice *dev,
                                       unsigned int vector, bool is_masked)
 {
     MSIMessage msg;
     int ret;
 
+    /*
+     * 在以下调用msix_set_vector_notifiers():
+     *   - hw/misc/ivshmem.c|775| <<ivshmem_enable_irqfd>> if (msix_set_vector_notifiers(pdev, ivshmem_vector_unmask, ivshmem_vector_mask, ivshmem_vector_poll)) {
+     *   - hw/vfio/pci.c|683| <<vfio_msix_enable>> if (msix_set_vector_notifiers(&vdev->pdev, vfio_msix_vector_use, vfio_msix_vector_release, NULL)) {
+     *   - hw/virtio/virtio-pci.c|1291| <<virtio_pci_set_guest_notifiers>> r = msix_set_vector_notifiers(&proxy->pci_dev, virtio_pci_vector_unmask, virtio_pci_vector_mask, virtio_pci_vector_poll);
+     */
     if (!dev->msix_vector_use_notifier) {
         return;
     }
@@ -117,11 +140,27 @@ static void msix_fire_vector_notifier(PCIDevice *dev,
         dev->msix_vector_release_notifier(dev, vector);
     } else {
         msg = msix_get_message(dev, vector);
+	/*
+	 * 在以下调用msix_set_vector_notifiers():
+	 *   - hw/misc/ivshmem.c|775| <<ivshmem_enable_irqfd>> if (msix_set_vector_notifiers(pdev, ivshmem_vector_unmask, ivshmem_vector_mask, ivshmem_vector_poll)) {
+	 *   - hw/vfio/pci.c|683| <<vfio_msix_enable>> if (msix_set_vector_notifiers(&vdev->pdev, vfio_msix_vector_use, vfio_msix_vector_release, NULL)) {
+	 *   - hw/virtio/virtio-pci.c|1291| <<virtio_pci_set_guest_notifiers>> r = msix_set_vector_notifiers(&proxy->pci_dev, virtio_pci_vector_unmask, virtio_pci_vector_mask, virtio_pci_vector_poll);
+	 */
         ret = dev->msix_vector_use_notifier(dev, vector, msg);
         assert(ret >= 0);
     }
 }
 
+/*
+ * called by:
+ *   - hw/pci/msix.c|165| <<msix_set_mask>> msix_handle_mask_update(dev, vector, was_masked);
+ *   - hw/pci/msix.c|206| <<msix_write_config>> msix_handle_mask_update(dev, vector,
+ *   - hw/pci/msix.c|231| <<msix_table_mmio_write>> msix_handle_mask_update(dev, vector, was_masked);
+ *   - hw/pci/msix.c|288| <<msix_mask_all>> msix_handle_mask_update(dev, vector, was_masked);
+ *   - hw/pci/msix.c|506| <<msix_load>> msix_handle_mask_update(dev, vector, true);
+ *
+ * 这里的vector是设备的第几个line
+ */
 static void msix_handle_mask_update(PCIDevice *dev, int vector, bool was_masked)
 {
     bool is_masked = msix_is_masked(dev, vector);
@@ -248,6 +287,21 @@ static uint64_t msix_pba_mmio_read(void *opaque, hwaddr addr,
                                    unsigned size)
 {
     PCIDevice *dev = opaque;
+    /*
+     * 在以下调用msix_set_vector_notifiers():
+     *   - hw/misc/ivshmem.c|775| <<ivshmem_enable_irqfd>> if (msix_set_vector_notifiers(pdev, ivshmem_vector_unmask, ivshmem_vector_mask, ivshmem_vector_poll)) {
+     *   - hw/vfio/pci.c|683| <<vfio_msix_enable>> if (msix_set_vector_notifiers(&vdev->pdev, vfio_msix_vector_use, vfio_msix_vector_release, NULL)) {
+     *   - hw/virtio/virtio-pci.c|1291| <<virtio_pci_set_guest_notifiers>> r = msix_set_vector_notifiers(&proxy->pci_dev, virtio_pci_vector_unmask, virtio_pci_vector_mask, virtio_pci_vector_poll);
+     *
+     * 在以下使用PCIDevice->msix_vector_poll_notifier:
+     *   - hw/pci/msix.c|251| <<msix_pba_mmio_read>> if (dev->msix_vector_poll_notifier) {
+     *   - hw/pci/msix.c|254| <<msix_pba_mmio_read>> dev->msix_vector_poll_notifier(dev, vector_start, vector_end);
+     *   - hw/pci/msix.c|629| <<msix_set_vector_notifiers>> dev->msix_vector_poll_notifier = poll_notifier;
+     *   - hw/pci/msix.c|640| <<msix_set_vector_notifiers>> if (dev->msix_vector_poll_notifier) {
+     *   - hw/pci/msix.c|641| <<msix_set_vector_notifiers>> dev->msix_vector_poll_notifier(dev, 0, dev->msix_entries_nr);
+     *   - hw/pci/msix.c|651| <<msix_set_vector_notifiers>> dev->msix_vector_poll_notifier = NULL;
+     *   - hw/pci/msix.c|670| <<msix_unset_vector_notifiers>> dev->msix_vector_poll_notifier = NULL;
+     */
     if (dev->msix_vector_poll_notifier) {
         unsigned vector_start = addr * 8;
         unsigned vector_end = MIN(addr + size * 8, dev->msix_entries_nr);
@@ -615,6 +669,12 @@ static void msix_unset_notifier_for_vector(PCIDevice *dev, unsigned int vector)
     dev->msix_vector_release_notifier(dev, vector);
 }
 
+/*
+ * 在以下调用msix_set_vector_notifiers():
+ *   - hw/misc/ivshmem.c|775| <<ivshmem_enable_irqfd>> if (msix_set_vector_notifiers(pdev, ivshmem_vector_unmask, ivshmem_vector_mask, ivshmem_vector_poll)) {
+ *   - hw/vfio/pci.c|683| <<vfio_msix_enable>> if (msix_set_vector_notifiers(&vdev->pdev, vfio_msix_vector_use, vfio_msix_vector_release, NULL)) {
+ *   - hw/virtio/virtio-pci.c|1291| <<virtio_pci_set_guest_notifiers>> r = msix_set_vector_notifiers(&proxy->pci_dev, virtio_pci_vector_unmask, virtio_pci_vector_mask, virtio_pci_vector_poll);
+ */
 int msix_set_vector_notifiers(PCIDevice *dev,
                               MSIVectorUseNotifier use_notifier,
                               MSIVectorReleaseNotifier release_notifier,
diff --git a/hw/pci/pci.c b/hw/pci/pci.c
index e7a39cb20..36b203b8b 100644
--- a/hw/pci/pci.c
+++ b/hw/pci/pci.c
@@ -1110,31 +1110,92 @@ uint16_t pci_requester_id(PCIDevice *dev)
     return pci_req_id_cache_extract(&dev->requester_id_cache);
 }
 
+/*
+ * called by:
+ *   - hw/pci/pci.c|1166| <<do_pci_register_device>> if (pci_bus_devfn_available(bus, devfn) && !pci_bus_devfn_reserved(bus, devfn)) {
+ *   - hw/pci/pci.c|1180| <<do_pci_register_device>> } else if (!pci_bus_devfn_available(bus, devfn)) {
+ */
 static bool pci_bus_devfn_available(PCIBus *bus, int devfn)
 {
     return !(bus->devices[devfn]);
 }
 
+/*
+ * called by:
+ *   - hw/pci/pci.c|1167| <<do_pci_register_device>> if (pci_bus_devfn_available(bus, devfn) && !pci_bus_devfn_reserved(bus, devfn)) {
+ *   - hw/pci/pci.c|1175| <<do_pci_register_device>> } else if (pci_bus_devfn_reserved(bus, devfn)) {
+ */
 static bool pci_bus_devfn_reserved(PCIBus *bus, int devfn)
 {
+    /*
+     * 在以下使用PCIBus->slot_reserved_mask:
+     *   - hw/pci/pci.c|511| <<pci_root_bus_internal_init>> bus->slot_reserved_mask = 0x0;
+     *   - hw/pci/pci.c|1130| <<pci_bus_devfn_reserved>> return bus->slot_reserved_mask & (1UL << PCI_SLOT(devfn));
+     *   - hw/pci/pci.c|1135| <<pci_bus_get_slot_reserved_mask>> return bus->slot_reserved_mask;
+     *   - hw/pci/pci.c|1140| <<pci_bus_set_slot_reserved_mask>> bus->slot_reserved_mask |= mask;
+     *   - hw/pci/pci.c|1149| <<pci_bus_clear_slot_reserved_mask>> bus->slot_reserved_mask &= ~mask;
+     */
     return bus->slot_reserved_mask & (1UL << PCI_SLOT(devfn));
 }
 
+/*
+ * called by:
+ *   - hw/xen/xen_pt.c|974| <<xen_igd_clear_slot>> if (!(pci_bus_get_slot_reserved_mask(pci_bus) & XEN_PCI_IGD_SLOT_MASK)) {
+ */
 uint32_t pci_bus_get_slot_reserved_mask(PCIBus *bus)
 {
+    /*
+     * 在以下使用PCIBus->slot_reserved_mask:
+     *   - hw/pci/pci.c|511| <<pci_root_bus_internal_init>> bus->slot_reserved_mask = 0x0;
+     *   - hw/pci/pci.c|1130| <<pci_bus_devfn_reserved>> return bus->slot_reserved_mask & (1UL << PCI_SLOT(devfn));
+     *   - hw/pci/pci.c|1135| <<pci_bus_get_slot_reserved_mask>> return bus->slot_reserved_mask;
+     *   - hw/pci/pci.c|1140| <<pci_bus_set_slot_reserved_mask>> bus->slot_reserved_mask |= mask;
+     *   - hw/pci/pci.c|1149| <<pci_bus_clear_slot_reserved_mask>> bus->slot_reserved_mask &= ~mask;
+     */
     return bus->slot_reserved_mask;
 }
 
+/*
+ * called by:
+ *   - hw/sparc64/sun4u.c|613| <<sun4uv_init>> pci_bus_set_slot_reserved_mask(pci_bus, 0xfffffffc);
+ *   - hw/sparc64/sun4u.c|614| <<sun4uv_init>> pci_bus_set_slot_reserved_mask(pci_busA, 0xfffffff1);
+ *   - hw/sparc64/sun4u.c|615| <<sun4uv_init>> pci_bus_set_slot_reserved_mask(pci_busB, 0xfffffff0);
+ *   - hw/xen/xen_pt.c|954| <<xen_igd_reserve_slot>> pci_bus_set_slot_reserved_mask(pci_bus, XEN_PCI_IGD_SLOT_MASK);
+ */
 void pci_bus_set_slot_reserved_mask(PCIBus *bus, uint32_t mask)
 {
+    /*
+     * 在以下使用PCIBus->slot_reserved_mask:
+     *   - hw/pci/pci.c|511| <<pci_root_bus_internal_init>> bus->slot_reserved_mask = 0x0;
+     *   - hw/pci/pci.c|1130| <<pci_bus_devfn_reserved>> return bus->slot_reserved_mask & (1UL << PCI_SLOT(devfn));
+     *   - hw/pci/pci.c|1135| <<pci_bus_get_slot_reserved_mask>> return bus->slot_reserved_mask;
+     *   - hw/pci/pci.c|1140| <<pci_bus_set_slot_reserved_mask>> bus->slot_reserved_mask |= mask;
+     *   - hw/pci/pci.c|1149| <<pci_bus_clear_slot_reserved_mask>> bus->slot_reserved_mask &= ~mask;
+     */
     bus->slot_reserved_mask |= mask;
 }
 
+/*
+ * called by:
+ *   - hw/xen/xen_pt.c|985| <<xen_igd_clear_slot>> pci_bus_clear_slot_reserved_mask(pci_bus, XEN_PCI_IGD_SLOT_MASK);
+ */
 void pci_bus_clear_slot_reserved_mask(PCIBus *bus, uint32_t mask)
 {
+    /*
+     * 在以下使用PCIBus->slot_reserved_mask:
+     *   - hw/pci/pci.c|511| <<pci_root_bus_internal_init>> bus->slot_reserved_mask = 0x0;
+     *   - hw/pci/pci.c|1130| <<pci_bus_devfn_reserved>> return bus->slot_reserved_mask & (1UL << PCI_SLOT(devfn));
+     *   - hw/pci/pci.c|1135| <<pci_bus_get_slot_reserved_mask>> return bus->slot_reserved_mask;
+     *   - hw/pci/pci.c|1140| <<pci_bus_set_slot_reserved_mask>> bus->slot_reserved_mask |= mask;
+     *   - hw/pci/pci.c|1149| <<pci_bus_clear_slot_reserved_mask>> bus->slot_reserved_mask &= ~mask;
+     */
     bus->slot_reserved_mask &= ~mask;
 }
 
+/*
+ * called by:
+ *   - hw/pci/pci.c|2086| <<pci_qdev_realize>> pci_dev = do_pci_register_device(pci_dev, object_get_typename(OBJECT(qdev)), pci_dev->devfn, errp);
+ */
 /* -1 for devfn means auto assign */
 static PCIDevice *do_pci_register_device(PCIDevice *pci_dev,
                                          const char *name, int devfn,
@@ -2028,6 +2089,10 @@ PCIDevice *pci_find_device(PCIBus *bus, int bus_num, uint8_t devfn)
 
 #define ONBOARD_INDEX_MAX (16 * 1024 - 1)
 
+/*
+ * 在以下使用pci_qdev_realize():
+ *   - hw/pci/pci.c|2632| <<pci_device_class_init>> k->realize = pci_qdev_realize;
+ */
 static void pci_qdev_realize(DeviceState *qdev, Error **errp)
 {
     PCIDevice *pci_dev = (PCIDevice *)qdev;
@@ -2767,6 +2832,12 @@ void pci_bus_get_w64_range(PCIBus *bus, Range *range)
     pci_for_each_device_under_bus(bus, pci_dev_get_w64, range);
 }
 
+/*
+ * called by:
+ *   - hw/pci/pci.c|2178| <<pci_qdev_realize>> if (pci_is_express(pci_dev) &&
+ *                     !pcie_find_capability(pci_dev, PCI_EXT_CAP_ID_ARI) && pcie_has_upstream_port(pci_dev) && PCI_SLOT(pci_dev->devfn)) {
+ *   - hw/pci/pci.c|2867| <<pci_get_function_0>> if(pcie_has_upstream_port(pci_dev)) {
+ */
 static bool pcie_has_upstream_port(PCIDevice *dev)
 {
     PCIDevice *parent_dev = pci_bridge_get_device(pci_get_bus(dev));
@@ -2783,6 +2854,20 @@ static bool pcie_has_upstream_port(PCIDevice *dev)
          pcie_cap_get_type(parent_dev) == PCI_EXP_TYPE_DOWNSTREAM);
 }
 
+/*
+ * called by:
+ *   - hw/isa/vt82c686.c|658| <<via_isa_set_irq>> ViaISAState *s = VIA_ISA(pci_get_function_0(d));
+ *   - hw/pci/pci.c|1207| <<do_pci_register_device>> else if (dev->hotplugged && !pci_is_vf(pci_dev) && pci_get_function_0(pci_dev)) {
+ *   - hw/pci/pci.c|1210| <<do_pci_register_device>> error_setg(errp, "PCI: slot %d function 0 already occupied by %s,"
+ *                              " new func %s cannot be exposed to guest.", PCI_SLOT(pci_get_function_0(pci_dev)->devfn), pci_get_function_0(pci_dev)->name, name);
+ *   - hw/pci/pci.c|1211| <<do_pci_register_device>> error_setg(errp, "PCI: slot %d function 0 already occupied by %s,"
+ *                              " new func %s cannot be exposed to guest.", PCI_SLOT(pci_get_function_0(pci_dev)->devfn), pci_get_function_0(pci_dev)->name, name);
+ *   - hw/pci/pci_host.c|88| <<pci_host_config_write_common>> if ((pci_dev->qdev.hotplugged && !pci_get_function_0(pci_dev)) || !pci_dev->has_power || is_pci_dev_ejected(pci_dev)) {
+ *   - hw/pci/pci_host.c|113| <<pci_host_config_read_common>> if ((pci_dev->qdev.hotplugged && !pci_get_function_0(pci_dev)) || !pci_dev->has_power || is_pci_dev_ejected(pci_dev)) {
+ *   - hw/pci/pcie.c|524| <<pcie_cap_slot_plug_cb>> if (pci_get_function_0(pci_dev)) {
+ *   - hw/ppc/spapr_pci.c|1582| <<spapr_pci_pre_plug>> pci_get_function_0(PCI_DEVICE(drc->dev))->name);
+ *   - hw/rdma/vmw/pvrdma_main.c|628| <<pvrdma_realize>> func0 = pci_get_function_0(pdev);
+ */
 PCIDevice *pci_get_function_0(PCIDevice *pci_dev)
 {
     PCIBus *bus = pci_get_bus(pci_dev);
diff --git a/hw/pci/pcie.c b/hw/pci/pcie.c
index 4b2f0805c..cfdf84d70 100644
--- a/hw/pci/pcie.c
+++ b/hw/pci/pcie.c
@@ -572,6 +572,10 @@ static void pcie_cap_slot_do_unplug(PCIDevice *dev)
                                PCI_EXP_SLTSTA_PDC);
 }
 
+/*
+ * 在以下使用pcie_cap_slot_unplug_request_cb():
+ *   - hw/pci/pcie_port.c|235| <<pcie_slot_class_init>> hc->unplug_request = pcie_cap_slot_unplug_request_cb;
+ */
 void pcie_cap_slot_unplug_request_cb(HotplugHandler *hotplug_dev,
                                      DeviceState *dev, Error **errp)
 {
diff --git a/hw/pci/pcie_port.c b/hw/pci/pcie_port.c
index 20ff2b39e..a6f17ae07 100644
--- a/hw/pci/pcie_port.c
+++ b/hw/pci/pcie_port.c
@@ -102,8 +102,22 @@ PCIESlot *pcie_chassis_find_slot(uint8_t chassis_number, uint16_t slot)
     return pcie_chassis_find_slot_with_chassis(c, slot);
 }
 
+/*
+ * called by:
+ *   - hw/pci-bridge/cxl_downstream.c|169| <<cxl_dsp_realize>> rc = pcie_chassis_add_slot(s);
+ *   - hw/pci-bridge/pcie_root_port.c|106| <<rp_realize>> rc = pcie_chassis_add_slot(s);
+ *   - hw/pci-bridge/xio3130_downstream.c|102| <<xio3130_downstream_realize>> rc = pcie_chassis_add_slot(s);
+ */
 int pcie_chassis_add_slot(struct PCIESlot *slot)
 {
+    /*
+     * struct PCIEChassis {
+     *     uint8_t     number;
+     *
+     *     QLIST_HEAD(, PCIESlot) slots;
+     *     QLIST_ENTRY(PCIEChassis) next;
+     * };
+     */
     struct PCIEChassis *c;
     c = pcie_chassis_find(slot->chassis);
     if (!c) {
diff --git a/hw/scsi/megasas.c b/hw/scsi/megasas.c
index 2d0c60717..ac2869125 100644
--- a/hw/scsi/megasas.c
+++ b/hw/scsi/megasas.c
@@ -37,6 +37,12 @@
 #include "migration/vmstate.h"
 #include "qom/object.h"
 
+/*
+ * 这个文档:
+ * A Practical Look at QEMU's Block Layer Primitives
+ * https://kashyapc.fedorapeople.org/virt/LinuxCon-NA-2016/A-Practical-Look-at-QEMU-Block-Layer-Primitives-LC-NA-2016.pdf
+ */
+
 #define MEGASAS_VERSION_GEN1 "1.70"
 #define MEGASAS_VERSION_GEN2 "1.80"
 #define MEGASAS_MAX_FRAMES 2048         /* Firmware limit at 65535 */
diff --git a/hw/scsi/scsi-bus.c b/hw/scsi/scsi-bus.c
index 9e40b0c92..ad0226a3e 100644
--- a/hw/scsi/scsi-bus.c
+++ b/hw/scsi/scsi-bus.c
@@ -17,6 +17,12 @@
 #include "sysemu/dma.h"
 #include "qemu/cutils.h"
 
+/*
+ * 这个文档:
+ * A Practical Look at QEMU's Block Layer Primitives
+ * https://kashyapc.fedorapeople.org/virt/LinuxCon-NA-2016/A-Practical-Look-at-QEMU-Block-Layer-Primitives-LC-NA-2016.pdf
+ */
+
 static char *scsibus_get_dev_path(DeviceState *dev);
 static char *scsibus_get_fw_dev_path(DeviceState *dev);
 static void scsi_req_dequeue(SCSIRequest *req);
diff --git a/hw/scsi/scsi-disk.c b/hw/scsi/scsi-disk.c
index 4bd7af9d0..f92eda451 100644
--- a/hw/scsi/scsi-disk.c
+++ b/hw/scsi/scsi-disk.c
@@ -47,6 +47,12 @@
 #include <scsi/sg.h>
 #endif
 
+/*
+ * 这个文档:
+ * A Practical Look at QEMU's Block Layer Primitives
+ * https://kashyapc.fedorapeople.org/virt/LinuxCon-NA-2016/A-Practical-Look-at-QEMU-Block-Layer-Primitives-LC-NA-2016.pdf
+ */
+
 #define SCSI_WRITE_SAME_MAX         (512 * KiB)
 #define SCSI_DMA_BUF_SIZE           (128 * KiB)
 #define SCSI_MAX_INQUIRY_LEN        256
@@ -86,6 +92,16 @@ typedef struct SCSIDiskReq {
 #define SCSI_DISK_F_NO_REMOVABLE_DEVOPS   2
 
 struct SCSIDiskState {
+    /*
+     * 3228 static Property scsi_block_properties[] = {
+     * 3229     DEFINE_BLOCK_ERROR_PROPERTIES(SCSIDiskState, qdev.conf),
+     * 3230     DEFINE_PROP_DRIVE("drive", SCSIDiskState, qdev.conf.blk),
+     *
+     * struct SCSIDiskState:
+     * -> SCSIDevice qdev;
+     *    -> BlockConf conf;
+     *       -> BlockBackend *blk;
+     */
     SCSIDevice qdev;
     uint32_t features;
     bool media_changed;
@@ -2887,6 +2903,17 @@ static BlockAIOCB *scsi_block_do_sgio(SCSIBlockReq *req,
     /* The rest is as in scsi-generic.c.  */
     io_header->mx_sb_len = sizeof(r->req.sense);
     io_header->sbp = r->req.sense;
+    /*
+     * sg_io_hd_t *io_header:
+     * -> unsigned int timeout;
+     *
+     * SCSIDiskState *s:
+     * -> SCSIDevice qdev;
+     *    -> QTAILQ_HEAD(, SCSIRequest) requests;
+     *    -> uint32_t channel;
+     *    -> uint32_t lun;
+     *    -> uint32_t io_timeout;
+     */
     io_header->timeout = s->qdev.io_timeout * 1000;
     io_header->usr_ptr = r;
     io_header->flags |= SG_FLAG_DIRECT_IO;
@@ -3208,6 +3235,17 @@ static const TypeInfo scsi_cd_info = {
     .class_init    = scsi_cd_class_initfn,
 };
 
+/*
+ * 3228 static Property scsi_block_properties[] = {
+ * 3229     DEFINE_BLOCK_ERROR_PROPERTIES(SCSIDiskState, qdev.conf),
+ * 3230     DEFINE_PROP_DRIVE("drive", SCSIDiskState, qdev.conf.blk),
+ *
+ * struct SCSIDiskState:
+ * -> SCSIDevice qdev;
+ *    -> BlockConf conf;
+ *       -> BlockBackend *blk;
+ */
+
 #ifdef __linux__
 static Property scsi_block_properties[] = {
     DEFINE_BLOCK_ERROR_PROPERTIES(SCSIDiskState, qdev.conf),
diff --git a/hw/scsi/scsi-generic.c b/hw/scsi/scsi-generic.c
index ee945f87e..4fd08858a 100644
--- a/hw/scsi/scsi-generic.c
+++ b/hw/scsi/scsi-generic.c
@@ -33,6 +33,12 @@
 #define MAX_UINT ((unsigned int)-1)
 #endif
 
+/*
+ * 这个文档:
+ * A Practical Look at QEMU's Block Layer Primitives
+ * https://kashyapc.fedorapeople.org/virt/LinuxCon-NA-2016/A-Practical-Look-at-QEMU-Block-Layer-Primitives-LC-NA-2016.pdf
+ */
+
 typedef struct SCSIGenericReq {
     SCSIRequest req;
     uint8_t *buf;
diff --git a/hw/scsi/vhost-scsi-common.c b/hw/scsi/vhost-scsi-common.c
index 4c8637045..52c156fb7 100644
--- a/hw/scsi/vhost-scsi-common.c
+++ b/hw/scsi/vhost-scsi-common.c
@@ -121,6 +121,33 @@ void vhost_scsi_common_stop(VHostSCSICommon *vsc)
     vhost_dev_disable_notifiers(&vsc->dev, vdev);
 }
 
+/*
+ * LINUX: vhost_scsi_ioctl()
+ *
+ * 2076         case VHOST_GET_FEATURES:
+ * 2077                 features = VHOST_SCSI_FEATURES;
+ * 2078                 if (copy_to_user(featurep, &features, sizeof features))
+ * 2079                         return -EFAULT;
+ * 2080                 return 0;
+ *
+ * 160 enum {
+ * 161         VHOST_SCSI_FEATURES = VHOST_FEATURES | (1ULL << VIRTIO_SCSI_F_HOTPLUG) |
+ * 162                                                (1ULL << VIRTIO_SCSI_F_T10_PI)
+ * 163 };
+ *
+ * 256 enum {
+ * 257         VHOST_FEATURES = (1ULL << VIRTIO_F_NOTIFY_ON_EMPTY) |
+ * 258                          (1ULL << VIRTIO_RING_F_INDIRECT_DESC) |
+ * 259                          (1ULL << VIRTIO_RING_F_EVENT_IDX) |
+ * 260                          (1ULL << VHOST_F_LOG_ALL) |
+ * 261                          (1ULL << VIRTIO_F_ANY_LAYOUT) |
+ * 262                          (1ULL << VIRTIO_F_VERSION_1)
+ * 263 };
+ *
+ * vhost_kernel_get_features()
+ *
+ * vhost_dev_init -->  hdev->vhost_ops->vhost_get_features
+ */
 uint64_t vhost_scsi_common_get_features(VirtIODevice *vdev, uint64_t features,
                                         Error **errp)
 {
@@ -129,6 +156,16 @@ uint64_t vhost_scsi_common_get_features(VirtIODevice *vdev, uint64_t features,
     /* Turn on predefined features supported by this device */
     features |= vsc->host_features;
 
+    /*
+     * called by:
+     *   - hw/block/vhost-user-blk.c|266| <<vhost_user_blk_get_features>> return vhost_get_features(&s->dev, user_feature_bits, features);
+     *   - hw/net/vhost_net.c|120| <<vhost_net_get_features>> return vhost_get_features(&net->dev, vhost_net_get_feature_bits(net),
+     *   - hw/scsi/vhost-scsi-common.c|132| <<vhost_scsi_common_get_features>> return vhost_get_features(&vsc->dev, vsc->feature_bits, features);
+     *   - hw/virtio/vhost-user-fs.c|146| <<vuf_get_features>> return vhost_get_features(&fs->vhost_dev, user_feature_bits, features);
+     *   - hw/virtio/vhost-user-scmi.c|138| <<vu_scmi_get_features>> return vhost_get_features(&scmi->vhost_dev, feature_bits, features);
+     *   - hw/virtio/vhost-user-vsock.c|80| <<vuv_get_features>> features = vhost_get_features(&vvc->vhost_dev, user_feature_bits, features);
+     *   - hw/virtio/vhost-vsock-common.c|37| <<vhost_vsock_common_get_features>> features = vhost_get_features(&vvc->vhost_dev, feature_bits, features);
+     */
     return vhost_get_features(&vsc->dev, vsc->feature_bits, features);
 }
 
diff --git a/hw/scsi/virtio-scsi.c b/hw/scsi/virtio-scsi.c
index 9f02ceea0..93b69fe3f 100644
--- a/hw/scsi/virtio-scsi.c
+++ b/hw/scsi/virtio-scsi.c
@@ -31,6 +31,12 @@
 #include "hw/virtio/virtio-access.h"
 #include "trace.h"
 
+/*
+ * 这个文档:
+ * A Practical Look at QEMU's Block Layer Primitives
+ * https://kashyapc.fedorapeople.org/virt/LinuxCon-NA-2016/A-Practical-Look-at-QEMU-Block-Layer-Primitives-LC-NA-2016.pdf
+ */
+
 typedef struct VirtIOSCSIReq {
     /*
      * Note:
@@ -1193,6 +1199,12 @@ static struct SCSIBusInfo virtio_scsi_scsi_info = {
     .drained_end = virtio_scsi_drained_end,
 };
 
+/*
+ * called by:
+ *   - hw/scsi/vhost-scsi.c|251| <<vhost_scsi_realize>> virtio_scsi_common_realize(dev, vhost_dummy_handle_output, vhost_dummy_handle_output, vhost_dummy_handle_output, &err);
+ *   - hw/scsi/vhost-user-scsi.c|266| <<vhost_user_scsi_realize>> virtio_scsi_common_realize(dev, vhost_user_scsi_handle_output, vhost_user_scsi_handle_output, vhost_user_scsi_handle_output, &err);
+ *   - hw/scsi/virtio-scsi.c|1245| <<virtio_scsi_device_realize>> virtio_scsi_common_realize(dev, virtio_scsi_handle_ctrl, virtio_scsi_handle_event, virtio_scsi_handle_cmd, &err);
+ */
 void virtio_scsi_common_realize(DeviceState *dev,
                                 VirtIOHandleOutput ctrl,
                                 VirtIOHandleOutput evt,
@@ -1233,6 +1245,16 @@ void virtio_scsi_common_realize(DeviceState *dev,
     }
 }
 
+/*
+ * 3228 static Property scsi_block_properties[] = {
+ * 3229     DEFINE_BLOCK_ERROR_PROPERTIES(SCSIDiskState, qdev.conf),
+ * 3230     DEFINE_PROP_DRIVE("drive", SCSIDiskState, qdev.conf.blk),
+ *
+ * struct SCSIDiskState:
+ * -> SCSIDevice qdev;
+ *    -> BlockConf conf;
+ *       -> BlockBackend *blk;
+ */
 static void virtio_scsi_device_realize(DeviceState *dev, Error **errp)
 {
     VirtIODevice *vdev = VIRTIO_DEVICE(dev);
diff --git a/hw/vfio/helpers.c b/hw/vfio/helpers.c
index 47b4096c0..f3b43ed52 100644
--- a/hw/vfio/helpers.c
+++ b/hw/vfio/helpers.c
@@ -107,6 +107,23 @@ static const char *index_to_str(VFIODevice *vbasedev, int index)
     }
 }
 
+/*
+ * called by:
+ *   - hw/vfio/ap.c|120| <<vfio_ap_register_irq_notifier>> if (vfio_set_irq_signaling(vdev, irq, 0, VFIO_IRQ_SET_ACTION_TRIGGER, fd, errp)) {
+ *   - hw/vfio/ap.c|146| <<vfio_ap_unregister_irq_notifier>> if (vfio_set_irq_signaling(&vapdev->vdev, irq, 0, VFIO_IRQ_SET_ACTION_TRIGGER, -1, &err)) {
+ *   - hw/vfio/ccw.c|437| <<vfio_ccw_register_irq_notifier>> if (vfio_set_irq_signaling(vdev, irq, 0, VFIO_IRQ_SET_ACTION_TRIGGER, fd, errp)) {
+ *   - hw/vfio/ccw.c|468| <<vfio_ccw_unregister_irq_notifier>> if (vfio_set_irq_signaling(&vcdev->vdev, irq, 0, VFIO_IRQ_SET_ACTION_TRIGGER, -1, &err)) {
+ *   - hw/vfio/pci.c|150| <<vfio_intx_enable_kvm>> if (vfio_set_irq_signaling(&vdev->vbasedev, VFIO_PCI_INTX_IRQ_INDEX, 0, VFIO_IRQ_SET_ACTION_UNMASK, event_notifier_get_fd(&vdev->intx.unmask), errp)) {
+ *   - hw/vfio/pci.c|298| <<vfio_intx_enable>> if (vfio_set_irq_signaling(&vdev->vbasedev, VFIO_PCI_INTX_IRQ_INDEX, 0, VFIO_IRQ_SET_ACTION_TRIGGER, fd, errp)) {
+ *   - hw/vfio/pci.c|593| <<vfio_msix_vector_do_use>> if (vfio_set_irq_signaling(&vdev->vbasedev, VFIO_PCI_MSIX_IRQ_INDEX, nr, VFIO_IRQ_SET_ACTION_TRIGGER, fd, &err)) {
+ *   - hw/vfio/pci.c|647| <<vfio_msix_vector_release>> if (vfio_set_irq_signaling(&vdev->vbasedev, VFIO_PCI_MSIX_IRQ_INDEX, nr, VFIO_IRQ_SET_ACTION_TRIGGER, fd, &err)) {
+ *   - hw/vfio/pci.c|2860| <<vfio_register_err_notifier>> if (vfio_set_irq_signaling(&vdev->vbasedev, VFIO_PCI_ERR_IRQ_INDEX, 0, VFIO_IRQ_SET_ACTION_TRIGGER, fd, &err)) {
+ *   - hw/vfio/pci.c|2877| <<vfio_unregister_err_notifier>> if (vfio_set_irq_signaling(&vdev->vbasedev, VFIO_PCI_ERR_IRQ_INDEX, 0, VFIO_IRQ_SET_ACTION_TRIGGER, -1, &err)) {
+ *   - hw/vfio/pci.c|2925| <<vfio_register_req_notifier>> if (vfio_set_irq_signaling(&vdev->vbasedev, VFIO_PCI_REQ_IRQ_INDEX, 0, VFIO_IRQ_SET_ACTION_TRIGGER, fd, &err)) {
+ *   - hw/vfio/pci.c|2943| <<vfio_unregister_req_notifier>> if (vfio_set_irq_signaling(&vdev->vbasedev, VFIO_PCI_REQ_IRQ_INDEX, 0, VFIO_IRQ_SET_ACTION_TRIGGER, -1, &err)) {
+ *   - hw/vfio/platform.c|122| <<vfio_set_trigger_eventfd>> ret = vfio_set_irq_signaling(vbasedev, intp->pin, 0, VFIO_IRQ_SET_ACTION_TRIGGER, fd, &err);
+ *   - hw/vfio/platform.c|361| <<vfio_set_resample_eventfd>> ret = vfio_set_irq_signaling(vbasedev, intp->pin, 0, VFIO_IRQ_SET_ACTION_UNMASK, fd, &err);
+ */
 int vfio_set_irq_signaling(VFIODevice *vbasedev, int index, int subindex,
                            int action, int fd, Error **errp)
 {
diff --git a/hw/vfio/pci.c b/hw/vfio/pci.c
index 64780d1b7..aab0eb393 100644
--- a/hw/vfio/pci.c
+++ b/hw/vfio/pci.c
@@ -356,7 +356,19 @@ static void vfio_msi_interrupt(void *opaque)
         /* A masked vector firing needs to use the PBA, enable it */
         if (msix_is_masked(&vdev->pdev, nr)) {
             set_bit(nr, vdev->msix->pending);
+            /*
+	     * 在以下使用PCIDevice->msix_pba_mmio:
+	     *   - hw/pci/msix.c|416| <<msix_init>> memory_region_init_io(&dev->msix_pba_mmio, OBJECT(dev), &msix_pba_mmio_ops, dev, "msix-pba", pba_size);
+	     *   - hw/pci/msix.c|418| <<msix_init>> memory_region_add_subregion(pba_bar, pba_offset, &dev->msix_pba_mmio);
+	     *   - hw/pci/msix.c|498| <<msix_uninit>> memory_region_del_subregion(pba_bar, &dev->msix_pba_mmio);
+	     *   - hw/vfio/pci.c|359| <<vfio_msi_interrupt>> memory_region_set_enabled(&vdev->pdev.msix_pba_mmio, true);
+	     *   - hw/vfio/pci.c|632| <<vfio_msix_vector_do_use>> memory_region_set_enabled(&vdev->pdev.msix_pba_mmio, false);
+	     *   - hw/vfio/pci.c|1737| <<vfio_msix_setup>> memory_region_set_enabled(&vdev->pdev.msix_pba_mmio, false);
+	     */
             memory_region_set_enabled(&vdev->pdev.msix_pba_mmio, true);
+            /*
+	     * 只在这里trace!
+	     */
             trace_vfio_msix_pba_enable(vdev->vbasedev.name);
         }
     } else if (vdev->interrupt == VFIO_INT_MSI) {
@@ -470,6 +482,11 @@ static void vfio_add_kvm_msi_virq(VFIOPCIDevice *vdev, VFIOMSIVector *vector,
                                              vector_n, &vdev->pdev);
 }
 
+/*
+ * called by:
+ *   - hw/vfio/pci.c|565| <<vfio_msix_vector_do_use>> vfio_connect_kvm_msi_virq(vector);
+ *   - hw/vfio/pci.c|692| <<vfio_commit_kvm_msi_virq_batch>> vfio_connect_kvm_msi_virq(&vdev->msi_vectors[i]);
+ */
 static void vfio_connect_kvm_msi_virq(VFIOMSIVector *vector)
 {
     if (vector->virq < 0) {
@@ -503,6 +520,11 @@ static void vfio_remove_kvm_msi_virq(VFIOMSIVector *vector)
     event_notifier_cleanup(&vector->kvm_interrupt);
 }
 
+/*
+ * called by:
+ *   - hw/vfio/pci.c|550| <<vfio_msix_vector_do_use>> vfio_update_kvm_msi_virq(vector, *msg, pdev);
+ *   - hw/vfio/pci.c|897| <<vfio_update_msi>> vfio_update_kvm_msi_virq(vector, msg, &vdev->pdev);
+ */
 static void vfio_update_kvm_msi_virq(VFIOMSIVector *vector, MSIMessage msg,
                                      PCIDevice *pdev)
 {
@@ -510,6 +532,10 @@ static void vfio_update_kvm_msi_virq(VFIOMSIVector *vector, MSIMessage msg,
     kvm_irqchip_commit_routes(kvm_state);
 }
 
+/*
+ * called by:
+ *   - hw/vfio/pci.c|615| <<vfio_msix_vector_use>> return vfio_msix_vector_do_use(pdev, nr, &msg, vfio_msi_interrupt);
+ */
 static int vfio_msix_vector_do_use(PCIDevice *pdev, unsigned int nr,
                                    MSIMessage *msg, IOHandler *handler)
 {
@@ -547,6 +573,15 @@ static int vfio_msix_vector_do_use(PCIDevice *pdev, unsigned int nr,
         }
     } else {
         if (msg) {
+            /*
+	     * 在以下使用VFIOPCIDevice->defer_kvm_irq_routing:
+	     *   - hw/vfio/pci.c|576| <<vfio_msix_vector_do_use>> if (vdev->defer_kvm_irq_routing) {
+	     *   - hw/vfio/pci.c|602| <<vfio_msix_vector_do_use>> if (!vdev->defer_kvm_irq_routing) {
+	     *   - hw/vfio/pci.c|711| <<vfio_prepare_kvm_msi_virq_batch>> assert(!vdev->defer_kvm_irq_routing);
+	     *   - hw/vfio/pci.c|712| <<vfio_prepare_kvm_msi_virq_batch>> vdev->defer_kvm_irq_routing = true;
+	     *   - hw/vfio/pci.c|720| <<vfio_commit_kvm_msi_virq_batch>> assert(vdev->defer_kvm_irq_routing);
+	     *   - hw/vfio/pci.c|721| <<vfio_commit_kvm_msi_virq_batch>> vdev->defer_kvm_irq_routing = false;
+	     */
             if (vdev->defer_kvm_irq_routing) {
                 vfio_add_kvm_msi_virq(vdev, vector, nr, true);
             } else {
@@ -573,6 +608,15 @@ static int vfio_msix_vector_do_use(PCIDevice *pdev, unsigned int nr,
         vdev->nr_vectors = nr + 1;
     }
 
+    /*
+     * 在以下使用VFIOPCIDevice->defer_kvm_irq_routing:
+     *   - hw/vfio/pci.c|576| <<vfio_msix_vector_do_use>> if (vdev->defer_kvm_irq_routing) {
+     *   - hw/vfio/pci.c|602| <<vfio_msix_vector_do_use>> if (!vdev->defer_kvm_irq_routing) {
+     *   - hw/vfio/pci.c|711| <<vfio_prepare_kvm_msi_virq_batch>> assert(!vdev->defer_kvm_irq_routing);
+     *   - hw/vfio/pci.c|712| <<vfio_prepare_kvm_msi_virq_batch>> vdev->defer_kvm_irq_routing = true;
+     *   - hw/vfio/pci.c|720| <<vfio_commit_kvm_msi_virq_batch>> assert(vdev->defer_kvm_irq_routing);
+     *   - hw/vfio/pci.c|721| <<vfio_commit_kvm_msi_virq_batch>> vdev->defer_kvm_irq_routing = false;
+     */
     if (!vdev->defer_kvm_irq_routing) {
         if (vdev->msix->noresize && resizing) {
             vfio_disable_irqindex(&vdev->vbasedev, VFIO_PCI_MSIX_IRQ_INDEX);
@@ -584,6 +628,16 @@ static int vfio_msix_vector_do_use(PCIDevice *pdev, unsigned int nr,
             Error *err = NULL;
             int32_t fd;
 
+	    /*
+	     * 注释
+	     *  Two interrupt paths are configured per vector.  The first, is only used
+	     * for interrupts injected via QEMU.  This is typically the non-accel path,
+	     * but may also be used when we want QEMU to handle masking and pending
+	     * bits.  The KVM path bypasses QEMU and is therefore higher performance,
+	     * but requires masking at the device.  virq is used to track the MSI route
+	     * through KVM, thus kvm_interrupt is only available when virq is set to a
+	     * valid (>= 0) value.
+	     */
             if (vector->virq >= 0) {
                 fd = event_notifier_get_fd(&vector->kvm_interrupt);
             } else {
@@ -598,6 +652,13 @@ static int vfio_msix_vector_do_use(PCIDevice *pdev, unsigned int nr,
         }
     }
 
+    /*
+     * 这里会改变memslots!!!
+     *
+     * VFIOPCIDevice:
+     * -> VFIOMSIXInfo *msix;
+     *    -> unsigned long *pending;
+     */
     /* Disable PBA emulation when nothing more is pending. */
     clear_bit(nr, vdev->msix->pending);
     if (find_first_bit(vdev->msix->pending,
@@ -609,12 +670,34 @@ static int vfio_msix_vector_do_use(PCIDevice *pdev, unsigned int nr,
     return 0;
 }
 
+/*
+ * 在以下调用msix_set_vector_notifiers():
+ *   - hw/misc/ivshmem.c|775| <<ivshmem_enable_irqfd>> if (msix_set_vector_notifiers(pdev, ivshmem_vector_unmask, ivshmem_vector_mask, ivshmem_vector_poll)) {
+ *   - hw/vfio/pci.c|683| <<vfio_msix_enable>> if (msix_set_vector_notifiers(&vdev->pdev, vfio_msix_vector_use, vfio_msix_vector_release, NULL)) {
+ *   - hw/virtio/virtio-pci.c|1291| <<virtio_pci_set_guest_notifiers>> r = msix_set_vector_notifiers(&proxy->pci_dev, virtio_pci_vector_unmask, virtio_pci_vector_mask, virtio_pci_vector_poll);
+ *
+ * 在以下使用vfio_msix_vector_use():
+ *   - hw/vfio/pci.c|693| <<vfio_msix_enable>> if (msix_set_vector_notifiers(&vdev->pdev, vfio_msix_vector_use, vfio_msix_vector_release, NULL)) {
+ */
 static int vfio_msix_vector_use(PCIDevice *pdev,
                                 unsigned int nr, MSIMessage msg)
 {
+    /*
+     * 只在此处调用
+     */
     return vfio_msix_vector_do_use(pdev, nr, &msg, vfio_msi_interrupt);
 }
 
+/*
+ * 在以下调用msix_set_vector_notifiers():
+ *   - hw/misc/ivshmem.c|775| <<ivshmem_enable_irqfd>> if (msix_set_vector_notifiers(pdev, ivshmem_vector_unmask, ivshmem_vector_mask, ivshmem_vector_poll)) {
+ *   - hw/vfio/pci.c|683| <<vfio_msix_enable>> if (msix_set_vector_notifiers(&vdev->pdev, vfio_msix_vector_use, vfio_msix_vector_release, NULL)) {
+ *   - hw/virtio/virtio-pci.c|1291| <<virtio_pci_set_guest_notifiers>> r = msix_set_vector_notifiers(&proxy->pci_dev, virtio_pci_vector_unmask, virtio_pci_vector_mask, virtio_pci_vector_poll);
+ *
+ * 在以下使用vfio_msix_vector_release():
+ *   - hw/vfio/pci.c|684| <<vfio_msix_enable>> if (msix_set_vector_notifiers(&vdev->pdev, vfio_msix_vector_use, vfio_msix_vector_release, NULL)) {
+ *   - hw/vfio/pci.c|824| <<vfio_msix_disable>> vfio_msix_vector_release(&vdev->pdev, i);
+ */
 static void vfio_msix_vector_release(PCIDevice *pdev, unsigned int nr)
 {
     VFIOPCIDevice *vdev = VFIO_PCI(pdev);
@@ -634,6 +717,10 @@ static void vfio_msix_vector_release(PCIDevice *pdev, unsigned int nr)
         int32_t fd = event_notifier_get_fd(&vector->interrupt);
         Error *err = NULL;
 
+        /*
+	 * 这是use的情况.
+	 * vfio_set_irq_signaling(&vdev->vbasedev, VFIO_PCI_MSIX_IRQ_INDEX, nr, VFIO_IRQ_SET_ACTION_TRIGGER, fd, &err)
+	 */
         if (vfio_set_irq_signaling(&vdev->vbasedev, VFIO_PCI_MSIX_IRQ_INDEX, nr,
                                    VFIO_IRQ_SET_ACTION_TRIGGER, fd, &err)) {
             error_reportf_err(err, VFIO_MSG_PREFIX, vdev->vbasedev.name);
@@ -641,8 +728,22 @@ static void vfio_msix_vector_release(PCIDevice *pdev, unsigned int nr)
     }
 }
 
+/*
+ * called by:
+ *   - hw/vfio/pci.c|759| <<vfio_msix_enable>> vfio_prepare_kvm_msi_virq_batch(vdev);
+ *   - hw/vfio/pci.c|808| <<vfio_msi_enable>> vfio_prepare_kvm_msi_virq_batch(vdev);
+ */
 static void vfio_prepare_kvm_msi_virq_batch(VFIOPCIDevice *vdev)
 {
+    /*
+     * 在以下使用VFIOPCIDevice->defer_kvm_irq_routing:
+     *   - hw/vfio/pci.c|576| <<vfio_msix_vector_do_use>> if (vdev->defer_kvm_irq_routing) {
+     *   - hw/vfio/pci.c|602| <<vfio_msix_vector_do_use>> if (!vdev->defer_kvm_irq_routing) {
+     *   - hw/vfio/pci.c|711| <<vfio_prepare_kvm_msi_virq_batch>> assert(!vdev->defer_kvm_irq_routing);
+     *   - hw/vfio/pci.c|712| <<vfio_prepare_kvm_msi_virq_batch>> vdev->defer_kvm_irq_routing = true;
+     *   - hw/vfio/pci.c|720| <<vfio_commit_kvm_msi_virq_batch>> assert(vdev->defer_kvm_irq_routing);
+     *   - hw/vfio/pci.c|721| <<vfio_commit_kvm_msi_virq_batch>> vdev->defer_kvm_irq_routing = false;
+     */
     assert(!vdev->defer_kvm_irq_routing);
     vdev->defer_kvm_irq_routing = true;
     vfio_route_change = kvm_irqchip_begin_route_changes(kvm_state);
@@ -652,6 +753,15 @@ static void vfio_commit_kvm_msi_virq_batch(VFIOPCIDevice *vdev)
 {
     int i;
 
+    /*
+     * 在以下使用VFIOPCIDevice->defer_kvm_irq_routing:
+     *   - hw/vfio/pci.c|576| <<vfio_msix_vector_do_use>> if (vdev->defer_kvm_irq_routing) {
+     *   - hw/vfio/pci.c|602| <<vfio_msix_vector_do_use>> if (!vdev->defer_kvm_irq_routing) {
+     *   - hw/vfio/pci.c|711| <<vfio_prepare_kvm_msi_virq_batch>> assert(!vdev->defer_kvm_irq_routing);
+     *   - hw/vfio/pci.c|712| <<vfio_prepare_kvm_msi_virq_batch>> vdev->defer_kvm_irq_routing = true;
+     *   - hw/vfio/pci.c|720| <<vfio_commit_kvm_msi_virq_batch>> assert(vdev->defer_kvm_irq_routing);
+     *   - hw/vfio/pci.c|721| <<vfio_commit_kvm_msi_virq_batch>> vdev->defer_kvm_irq_routing = false;
+     */
     assert(vdev->defer_kvm_irq_routing);
     vdev->defer_kvm_irq_routing = false;
 
@@ -662,6 +772,11 @@ static void vfio_commit_kvm_msi_virq_batch(VFIOPCIDevice *vdev)
     }
 }
 
+/*
+ * called by:
+ *   - hw/vfio/pci.c|1373| <<vfio_pci_write_config>> vfio_msix_enable(vdev);
+ *   - hw/vfio/pci.c|2712| <<vfio_pci_load_config>> vfio_msix_enable(vdev);
+ */
 static void vfio_msix_enable(VFIOPCIDevice *vdev)
 {
     int ret;
@@ -858,6 +973,10 @@ static void vfio_msi_disable(VFIOPCIDevice *vdev)
     trace_vfio_msi_disable(vdev->vbasedev.name);
 }
 
+/*
+ * called by:
+ *   - hw/vfio/pci.c|1302| <<vfio_pci_write_config>> vfio_update_msi(vdev);
+ */
 static void vfio_update_msi(VFIOPCIDevice *vdev)
 {
     int i;
@@ -1244,6 +1363,19 @@ uint32_t vfio_pci_read_config(PCIDevice *pdev, uint32_t addr, int len)
     return val;
 }
 
+/*
+ * called by:
+ *   - hw/vfio/pci-quirks.c|171| <<vfio_generic_window_quirk_data_write>> vfio_pci_write_config(&vdev->pdev, window->address_val, data, size);
+ *   - hw/vfio/pci-quirks.c|225| <<vfio_generic_quirk_mirror_write>> vfio_pci_write_config(&vdev->pdev, addr, data, size);
+ *   - hw/vfio/pci-quirks.c|647| <<vfio_nvidia_3d0_quirk_write>> vfio_pci_write_config(&vdev->pdev, offset, data, size);
+ *   - hw/vfio/pci-quirks.c|1396| <<vfio_radeon_reset>> vfio_pci_write_config(pdev, PCI_COMMAND, PCI_COMMAND_MEMORY, 2);
+ *   - hw/vfio/pci-quirks.c|1409| <<vfio_radeon_reset>> vfio_pci_write_config(pdev, 0x7c, 0x39d5e86b, 4);
+ *   - hw/vfio/pci-quirks.c|1439| <<vfio_radeon_reset>> vfio_pci_write_config(pdev, PCI_COMMAND, 0, 2);
+ *   - hw/vfio/pci.c|2480| <<vfio_pci_pre_reset>> vfio_pci_write_config(pdev, vdev->pm_cap + PCI_PM_CTRL, pmcsr, 2);
+ *   - hw/vfio/pci.c|2498| <<vfio_pci_pre_reset>> vfio_pci_write_config(pdev, PCI_COMMAND, cmd, 2);
+ *   - hw/vfio/pci.c|2694| <<vfio_pci_load_config>> vfio_pci_write_config(pdev, PCI_COMMAND,
+ *   - hw/vfio/pci.c|3500| <<vfio_pci_dev_class_init>> pdc->config_write = vfio_pci_write_config;
+ */
 void vfio_pci_write_config(PCIDevice *pdev,
                            uint32_t addr, uint32_t val, int len)
 {
diff --git a/hw/vfio/pci.h b/hw/vfio/pci.h
index 6e64a2654..d1793ae10 100644
--- a/hw/vfio/pci.h
+++ b/hw/vfio/pci.h
@@ -175,6 +175,15 @@ struct VFIOPCIDevice {
     bool no_vfio_ioeventfd;
     bool enable_ramfb;
     OnOffAuto ramfb_migrate;
+    /*
+     * 在以下使用VFIOPCIDevice->defer_kvm_irq_routing:
+     *   - hw/vfio/pci.c|576| <<vfio_msix_vector_do_use>> if (vdev->defer_kvm_irq_routing) {
+     *   - hw/vfio/pci.c|602| <<vfio_msix_vector_do_use>> if (!vdev->defer_kvm_irq_routing) {
+     *   - hw/vfio/pci.c|711| <<vfio_prepare_kvm_msi_virq_batch>> assert(!vdev->defer_kvm_irq_routing);
+     *   - hw/vfio/pci.c|712| <<vfio_prepare_kvm_msi_virq_batch>> vdev->defer_kvm_irq_routing = true;
+     *   - hw/vfio/pci.c|720| <<vfio_commit_kvm_msi_virq_batch>> assert(vdev->defer_kvm_irq_routing);
+     *   - hw/vfio/pci.c|721| <<vfio_commit_kvm_msi_virq_batch>> vdev->defer_kvm_irq_routing = false;
+     */
     bool defer_kvm_irq_routing;
     bool clear_parent_atomics_on_exit;
     VFIODisplay *dpy;
diff --git a/hw/virtio/vhost-scsi-pci.c b/hw/virtio/vhost-scsi-pci.c
index 08980bc23..6a5e997de 100644
--- a/hw/virtio/vhost-scsi-pci.c
+++ b/hw/virtio/vhost-scsi-pci.c
@@ -24,6 +24,16 @@
 #include "hw/virtio/virtio-pci.h"
 #include "qom/object.h"
 
+/*
+ * struct VHostSCSIPCI:
+ * -> VirtIOPCIProxy parent_obj;
+ *    -> PCIDevice pci_dev;
+ * -> VHostSCSI vdev;
+ *    -> VHostSCSICommon parent_obj;
+ *       -> VirtIOSCSICommon parent_obj;
+ *          -> VirtIODevice parent_obj;
+ */
+
 typedef struct VHostSCSIPCI VHostSCSIPCI;
 
 /*
diff --git a/hw/virtio/vhost.c b/hw/virtio/vhost.c
index f50180e60..3dce85e10 100644
--- a/hw/virtio/vhost.c
+++ b/hw/virtio/vhost.c
@@ -52,6 +52,14 @@ static unsigned int used_memslots;
 /* Memslots used by backends that only support shared memslots (with an fd). */
 static unsigned int used_shared_memslots;
 
+/*
+ * 在以下使用vhost_devices:
+ *   - hw/virtio/vhost.c|55| <<QLIST_HEAD>> static QLIST_HEAD(, vhost_dev) vhost_devices =
+ *   - hw/virtio/vhost.c|56| <<QLIST_HEAD>> QLIST_HEAD_INITIALIZER(vhost_devices);
+ *   - hw/virtio/vhost.c|63| <<vhost_get_max_memslots>> QLIST_FOREACH(hdev, &vhost_devices, entry) {
+ *   - hw/virtio/vhost.c|74| <<vhost_get_free_memslots>> QLIST_FOREACH(hdev, &vhost_devices, entry) {
+ *   - hw/virtio/vhost.c|1584| <<vhost_dev_init>> QLIST_INSERT_HEAD(&vhost_devices, hdev, entry);
+ */
 static QLIST_HEAD(, vhost_dev) vhost_devices =
     QLIST_HEAD_INITIALIZER(vhost_devices);
 
@@ -1431,6 +1439,21 @@ static void vhost_virtqueue_cleanup(struct vhost_virtqueue *vq)
     }
 }
 
+/*
+ * called by:
+ *   - backends/cryptodev-vhost.c|69| <<cryptodev_vhost_init>> r = vhost_dev_init(&crypto->dev, options->opaque, options->backend_type, 0,
+ *   - backends/vhost-user.c|39| <<vhost_user_backend_dev_init>> ret = vhost_dev_init(&b->dev, &b->vhost_user, VHOST_BACKEND_TYPE_USER, 0,
+ *   - hw/block/vhost-user-blk.c|334| <<vhost_user_blk_connect>> ret = vhost_dev_init(&s->dev, &s->vhost_user, VHOST_BACKEND_TYPE_USER, 0,
+ *   - hw/net/vhost_net.c|206| <<vhost_net_init>> r = vhost_dev_init(&net->dev, options->opaque,
+ *   - hw/scsi/vhost-scsi.c|278| <<vhost_scsi_realize>> ret = vhost_dev_init(&vsc->dev, (void *)(uintptr_t)vhostfd,
+ *   - hw/scsi/vhost-user-scsi.c|158| <<vhost_user_scsi_connect>> ret = vhost_dev_init(&vsc->dev, &s->vhost_user, VHOST_BACKEND_TYPE_USER, 0,
+ *   - hw/virtio/vdpa-dev.c|120| <<vhost_vdpa_device_realize>> ret = vhost_dev_init(&v->dev, &v->vdpa, VHOST_BACKEND_TYPE_VDPA, 0, NULL);
+ *   - hw/virtio/vhost-user-base.c|324| <<vub_device_realize>> ret = vhost_dev_init(&vub->vhost_dev, &vub->vhost_user,
+ *   - hw/virtio/vhost-user-fs.c|252| <<vuf_device_realize>> ret = vhost_dev_init(&fs->vhost_dev, &fs->vhost_user,
+ *   - hw/virtio/vhost-user-scmi.c|250| <<vu_scmi_device_realize>> ret = vhost_dev_init(&scmi->vhost_dev, &scmi->vhost_user,
+ *   - hw/virtio/vhost-user-vsock.c|110| <<vuv_device_realize>> ret = vhost_dev_init(&vvc->vhost_dev, &vsock->vhost_user,
+ *   - hw/virtio/vhost-vsock.c|171| <<vhost_vsock_device_realize>> ret = vhost_dev_init(&vvc->vhost_dev, (void *)(uintptr_t)vhostfd,
+ */
 int vhost_dev_init(struct vhost_dev *hdev, void *opaque,
                    VhostBackendType backend_type, uint32_t busyloop_timeout,
                    Error **errp)
@@ -1456,6 +1479,31 @@ int vhost_dev_init(struct vhost_dev *hdev, void *opaque,
         goto fail;
     }
 
+    /*
+     * LINUX: vhost_scsi_ioctl()
+     *
+     * 2076         case VHOST_GET_FEATURES:
+     * 2077                 features = VHOST_SCSI_FEATURES;
+     * 2078                 if (copy_to_user(featurep, &features, sizeof features))
+     * 2079                         return -EFAULT;
+     * 2080                 return 0;
+     *
+     * 160 enum {
+     * 161         VHOST_SCSI_FEATURES = VHOST_FEATURES | (1ULL << VIRTIO_SCSI_F_HOTPLUG) |
+     * 162                                                (1ULL << VIRTIO_SCSI_F_T10_PI)
+     * 163 };
+     *
+     * 256 enum {
+     * 257         VHOST_FEATURES = (1ULL << VIRTIO_F_NOTIFY_ON_EMPTY) |
+     * 258                          (1ULL << VIRTIO_RING_F_INDIRECT_DESC) |
+     * 259                          (1ULL << VIRTIO_RING_F_EVENT_IDX) |
+     * 260                          (1ULL << VHOST_F_LOG_ALL) |
+     * 261                          (1ULL << VIRTIO_F_ANY_LAYOUT) |
+     * 262                          (1ULL << VIRTIO_F_VERSION_1)
+     * 263 };
+     *
+     * vhost_kernel_get_features()
+     */
     r = hdev->vhost_ops->vhost_get_features(hdev, &features);
     if (r < 0) {
         error_setg_errno(errp, -r, "vhost_get_features failed");
@@ -1786,6 +1834,16 @@ static void vhost_start_config_intr(struct vhost_dev *dev)
     }
 }
 
+/*
+ * called by:
+ *   - hw/block/vhost-user-blk.c|266| <<vhost_user_blk_get_features>> return vhost_get_features(&s->dev, user_feature_bits, features);
+ *   - hw/net/vhost_net.c|120| <<vhost_net_get_features>> return vhost_get_features(&net->dev, vhost_net_get_feature_bits(net),
+ *   - hw/scsi/vhost-scsi-common.c|132| <<vhost_scsi_common_get_features>> return vhost_get_features(&vsc->dev, vsc->feature_bits, features);
+ *   - hw/virtio/vhost-user-fs.c|146| <<vuf_get_features>> return vhost_get_features(&fs->vhost_dev, user_feature_bits, features);
+ *   - hw/virtio/vhost-user-scmi.c|138| <<vu_scmi_get_features>> return vhost_get_features(&scmi->vhost_dev, feature_bits, features);
+ *   - hw/virtio/vhost-user-vsock.c|80| <<vuv_get_features>> features = vhost_get_features(&vvc->vhost_dev, user_feature_bits, features);
+ *   - hw/virtio/vhost-vsock-common.c|37| <<vhost_vsock_common_get_features>> features = vhost_get_features(&vvc->vhost_dev, feature_bits, features);
+ */
 uint64_t vhost_get_features(struct vhost_dev *hdev, const int *feature_bits,
                             uint64_t features)
 {
diff --git a/hw/virtio/virtio-bus.c b/hw/virtio/virtio-bus.c
index 896feb37a..d7461671e 100644
--- a/hw/virtio/virtio-bus.c
+++ b/hw/virtio/virtio-bus.c
@@ -39,6 +39,10 @@ do { printf("virtio_bus: " fmt , ## __VA_ARGS__); } while (0)
 #define DPRINTF(fmt, ...) do { } while (0)
 #endif
 
+/*
+ * called by:
+ *   - hw/virtio/virtio.c|3862| <<virtio_device_realize>> virtio_bus_device_plugged(vdev, &err);
+ */
 /* A VirtIODevice is being plugged */
 void virtio_bus_device_plugged(VirtIODevice *vdev, Error **errp)
 {
@@ -63,6 +67,33 @@ void virtio_bus_device_plugged(VirtIODevice *vdev, Error **errp)
 
     /* Get the features of the plugged device. */
     assert(vdc->get_features != NULL);
+    /*
+     * LINUX: vhost_scsi_ioctl()
+     *
+     * 2076         case VHOST_GET_FEATURES:
+     * 2077                 features = VHOST_SCSI_FEATURES;
+     * 2078                 if (copy_to_user(featurep, &features, sizeof features))
+     * 2079                         return -EFAULT;
+     * 2080                 return 0;
+     *
+     * 160 enum {
+     * 161         VHOST_SCSI_FEATURES = VHOST_FEATURES | (1ULL << VIRTIO_SCSI_F_HOTPLUG) |
+     * 162                                                (1ULL << VIRTIO_SCSI_F_T10_PI)
+     * 163 };
+     *
+     * 256 enum {
+     * 257         VHOST_FEATURES = (1ULL << VIRTIO_F_NOTIFY_ON_EMPTY) |
+     * 258                          (1ULL << VIRTIO_RING_F_INDIRECT_DESC) |
+     * 259                          (1ULL << VIRTIO_RING_F_EVENT_IDX) |
+     * 260                          (1ULL << VHOST_F_LOG_ALL) |
+     * 261                          (1ULL << VIRTIO_F_ANY_LAYOUT) |
+     * 262                          (1ULL << VIRTIO_F_VERSION_1)
+     * 263 };
+     *
+     * vhost_kernel_get_features()
+     *
+     * vhost_scsi是vhost_scsi_common_get_features()
+     */
     vdev->host_features = vdc->get_features(vdev, vdev->host_features,
                                             &local_err);
     if (local_err) {
@@ -216,6 +247,14 @@ void virtio_bus_release_ioeventfd(VirtioBusState *bus)
     }
 }
 
+/*
+ * 在以下使用virtio_bus_start_ioeventfd():
+ *   - hw/s390x/virtio-ccw.c|136| <<virtio_ccw_start_ioeventfd>> virtio_bus_start_ioeventfd(&dev->bus);
+ *   - hw/virtio/virtio-bus.c|215| <<virtio_bus_release_ioeventfd>> virtio_bus_start_ioeventfd(bus);
+ *   - hw/virtio/virtio-mmio.c|63| <<virtio_mmio_start_ioeventfd>> virtio_bus_start_ioeventfd(&proxy->bus);
+ *   - hw/virtio/virtio-pci.c|375| <<virtio_pci_start_ioeventfd>> virtio_bus_start_ioeventfd(&proxy->bus);
+ *   - hw/virtio/virtio.c|3902| <<virtio_device_start_ioeventfd>> return virtio_bus_start_ioeventfd(vbus);
+ */
 int virtio_bus_start_ioeventfd(VirtioBusState *bus)
 {
     VirtioBusClass *k = VIRTIO_BUS_GET_CLASS(bus);
@@ -269,6 +308,20 @@ bool virtio_bus_ioeventfd_enabled(VirtioBusState *bus)
     return k->ioeventfd_assign && k->ioeventfd_enabled(proxy);
 }
 
+/*
+ * called by:
+ *   - hw/block/virtio-blk.c|1807| <<virtio_blk_start_ioeventfd>> r = virtio_bus_set_host_notifier(VIRTIO_BUS(qbus), i, true);
+ *   - hw/block/virtio-blk.c|1813| <<virtio_blk_start_ioeventfd>> virtio_bus_set_host_notifier(VIRTIO_BUS(qbus), i, false);
+ *   - hw/block/virtio-blk.c|1928| <<virtio_blk_stop_ioeventfd>> virtio_bus_set_host_notifier(VIRTIO_BUS(qbus), i, false);
+ *   - hw/scsi/virtio-scsi-dataplane.c|57| <<virtio_scsi_set_host_notifier>> rc = virtio_bus_set_host_notifier(VIRTIO_BUS(qbus), n, true);
+ *   - hw/scsi/virtio-scsi-dataplane.c|168| <<virtio_scsi_dataplane_start>> virtio_bus_set_host_notifier(VIRTIO_BUS(qbus), i, false);
+ *   - hw/scsi/virtio-scsi-dataplane.c|222| <<virtio_scsi_dataplane_stop>> virtio_bus_set_host_notifier(VIRTIO_BUS(qbus), i, false);
+ *   - hw/virtio/vhost.c|1624| <<vhost_dev_disable_notifiers_nvqs>> r = virtio_bus_set_host_notifier(VIRTIO_BUS(qbus), hdev->vq_index + i, false);
+ *   - hw/virtio/vhost.c|1668| <<vhost_dev_enable_notifiers>> r = virtio_bus_set_host_notifier(VIRTIO_BUS(qbus), hdev->vq_index + i, true);
+ *   - hw/virtio/virtio.c|3850| <<virtio_device_start_ioeventfd_impl>> r = virtio_bus_set_host_notifier(qbus, n, true);
+ *   - hw/virtio/virtio.c|3879| <<virtio_device_start_ioeventfd_impl>> r = virtio_bus_set_host_notifier(qbus, n, false);
+ *   - hw/virtio/virtio.c|3922| <<virtio_device_stop_ioeventfd_impl>> r = virtio_bus_set_host_notifier(qbus, n, false);
+ */
 /*
  * This function switches ioeventfd on/off in the device.
  * The caller must set or clear the handlers for the EventNotifier.
diff --git a/hw/virtio/virtio-pci.c b/hw/virtio/virtio-pci.c
index cb159fd07..2351a1d8e 100644
--- a/hw/virtio/virtio-pci.c
+++ b/hw/virtio/virtio-pci.c
@@ -333,6 +333,12 @@ static int virtio_pci_ioeventfd_assign(DeviceState *d, EventNotifier *notifier,
     bool legacy = virtio_pci_legacy(proxy);
     bool modern = virtio_pci_modern(proxy);
     bool modern_pio = proxy->flags & VIRTIO_PCI_FLAG_MODERN_PIO_NOTIFY;
+    /*
+     * VirtIOPCIProxy *proxy:
+     * -> MemoryRegion bar;
+     * -> VirtIOPCIRegion notify;
+     * -> VirtIOPCIRegion notify_pio;
+     */
     MemoryRegion *modern_mr = &proxy->notify.mr;
     MemoryRegion *modern_notify_mr = &proxy->notify_pio.mr;
     MemoryRegion *legacy_mr = &proxy->bar;
@@ -370,6 +376,12 @@ static int virtio_pci_ioeventfd_assign(DeviceState *d, EventNotifier *notifier,
     return 0;
 }
 
+/*
+ * called by:
+ *   - hw/virtio/virtio-pci.c|423| <<virtio_ioport_write(VIRTIO_PCI_STATUS/VIRTIO_CONFIG_S_DRIVER_OK)>> virtio_pci_start_ioeventfd(proxy);
+ *   - hw/virtio/virtio-pci.c|1368| <<virtio_pci_vmstate_change>> virtio_pci_start_ioeventfd(proxy);
+ *   - hw/virtio/virtio-pci.c|1623| <<virtio_pci_common_write(VIRTIO_PCI_COMMON_STATUS/VIRTIO_CONFIG_S_DRIVER_OK)>> virtio_pci_start_ioeventfd(proxy);
+ */
 static void virtio_pci_start_ioeventfd(VirtIOPCIProxy *proxy)
 {
     virtio_bus_start_ioeventfd(&proxy->bus);
@@ -836,6 +848,11 @@ static void kvm_virtio_pci_vq_vector_release(VirtIOPCIProxy *proxy,
     }
 }
 
+/*
+ * 在以下使用kvm_virtio_pci_irqfd_use():
+ *   - hw/virtio/virtio-pci.c|902| <<kvm_virtio_pci_vector_use_one>> ret = kvm_virtio_pci_irqfd_use(proxy, n, vector);
+ *   - hw/virtio/virtio-pci.c|1020| <<virtio_pci_one_vector_unmask>> ret = kvm_virtio_pci_irqfd_use(proxy, n, vector);
+ */
 static int kvm_virtio_pci_irqfd_use(VirtIOPCIProxy *proxy,
                                  EventNotifier *n,
                                  unsigned int vector)
@@ -874,6 +891,12 @@ static int virtio_pci_get_notifier(VirtIOPCIProxy *proxy, int queue_no,
     return 0;
 }
 
+/*
+ * called by:
+ *   - hw/virtio/virtio-pci.c|935| <<kvm_virtio_pci_vector_vq_use>> ret = kvm_virtio_pci_vector_use_one(proxy, queue_no);
+ *   - hw/virtio/virtio-pci.c|942| <<kvm_virtio_pci_vector_config_use>> return kvm_virtio_pci_vector_use_one(proxy, VIRTIO_CONFIG_IRQ_IDX);
+ *   - hw/virtio/virtio-pci.c|1462| <<virtio_pci_set_vector>> kvm_virtio_pci_vector_use_one(proxy, queue_no);
+ */
 static int kvm_virtio_pci_vector_use_one(VirtIOPCIProxy *proxy, int queue_no)
 {
     unsigned int vector;
@@ -922,6 +945,10 @@ undo:
     }
     return ret;
 }
+/*
+ * called by:
+ *   - hw/virtio/virtio-pci.c|1288| <<virtio_pci_set_guest_notifiers>> r = kvm_virtio_pci_vector_vq_use(proxy, nvqs);
+ */
 static int kvm_virtio_pci_vector_vq_use(VirtIOPCIProxy *proxy, int nvqs)
 {
     int queue_no;
@@ -1176,6 +1203,13 @@ void virtio_pci_set_guest_notifier_fd_handler(VirtIODevice *vdev, VirtQueue *vq,
     }
 }
 
+/*
+ * called by:
+ *   - hw/virtio/virtio-pci.c|1263| <<virtio_pci_set_guest_notifiers>> r = virtio_pci_set_guest_notifier(d, n, assign, with_irqfd);
+ *   - hw/virtio/virtio-pci.c|1268| <<virtio_pci_set_guest_notifiers>> r = virtio_pci_set_guest_notifier(d, VIRTIO_CONFIG_IRQ_IDX, assign, with_irqfd);
+ *   - hw/virtio/virtio-pci.c|1311| <<virtio_pci_set_guest_notifiers>> virtio_pci_set_guest_notifier(d, VIRTIO_CONFIG_IRQ_IDX, !assign, with_irqfd);
+ *   - hw/virtio/virtio-pci.c|1317| <<virtio_pci_set_guest_notifiers>> virtio_pci_set_guest_notifier(d, n, !assign, with_irqfd);
+ */
 static int virtio_pci_set_guest_notifier(DeviceState *d, int n, bool assign,
                                          bool with_irqfd)
 {
@@ -1491,9 +1525,28 @@ static uint64_t virtio_pci_common_read(void *opaque, hwaddr addr,
         val = proxy->dfselect;
         break;
     case VIRTIO_PCI_COMMON_DF:
+	/*
+	 * VirtIOPCIProxy *proxy:
+	 * -> uint32_t dfselect;
+	 */
         if (proxy->dfselect <= 1) {
             VirtioDeviceClass *vdc = VIRTIO_DEVICE_GET_CLASS(vdev);
 
+            /*
+	     * 35 #define VIRTIO_LEGACY_FEATURES ((0x1ULL << VIRTIO_F_BAD_FEATURE) | \
+	     * 36                                 (0x1ULL << VIRTIO_F_NOTIFY_ON_EMPTY) | \
+	     * 37                                 (0x1ULL << VIRTIO_F_ANY_LAYOUT))
+	     *
+	     * 在以下使用VirtioDeviceClass->legacy_features:
+	     *   - hw/audio/virtio-snd.c|1399| <<virtio_snd_class_init>> vdc->legacy_features = 0;
+	     *   - hw/net/virtio-net.c|4050| <<virtio_net_class_init>> vdc->legacy_features |= (0x1 << VIRTIO_NET_F_GSO);
+	     *   - hw/s390x/virtio-ccw.c|389| <<virtio_ccw_cb>> (vdev->host_features & ~vdc->legacy_features);
+	     *   - hw/virtio/virtio-mmio.c|170| <<virtio_mmio_read>> return (vdev->host_features & ~vdc->legacy_features)
+	     *   - hw/virtio/virtio-pci.c|1538| <<virtio_pci_common_read>> val = (vdev->host_features & ~vdc->legacy_features) >> (32 * proxy->dfselect);
+	     *   - hw/virtio/virtio.c|4068| <<virtio_device_class_init>> vdc->legacy_features |= VIRTIO_LEGACY_FEATURES;
+	     *
+	     * 这里val是unint32_t
+	     */
             val = (vdev->host_features & ~vdc->legacy_features) >>
                 (32 * proxy->dfselect);
         }
@@ -1940,6 +1993,10 @@ static void virtio_pci_modern_io_region_unmap(VirtIOPCIProxy *proxy,
                                 &region->mr);
 }
 
+/*
+ * 在以下使用virtio_pci_pre_plugged():
+ *   - hw/virtio/virtio-pci.c|2611| <<virtio_pci_bus_class_init>> k->pre_plugged = virtio_pci_pre_plugged;
+ */
 static void virtio_pci_pre_plugged(DeviceState *d, Error **errp)
 {
     VirtIOPCIProxy *proxy = VIRTIO_PCI(d);
diff --git a/hw/virtio/virtio.c b/hw/virtio/virtio.c
index 871674f9b..080f8b81f 100644
--- a/hw/virtio/virtio.c
+++ b/hw/virtio/virtio.c
@@ -148,7 +148,30 @@ struct VirtQueue
     uint16_t vector;
     VirtIOHandleOutput handle_output;
     VirtIODevice *vdev;
+    /*
+     * 在以下使用VirtQueue->guest_notifier:
+     *   - hw/virtio/virtio.c|2493| <<virtio_notify_irqfd>> defer_call(virtio_notify_irqfd_deferred_fn, &vq->guest_notifier);
+     *   - hw/virtio/virtio.c|3501| <<virtio_queue_set_guest_notifier_fd_handler>> event_notifier_set_handler(&vq->guest_notifier, virtio_queue_guest_notifier_read);
+     *   - hw/virtio/virtio.c|3504| <<virtio_queue_set_guest_notifier_fd_handler>> event_notifier_set_handler(&vq->guest_notifier, NULL);
+     *   - hw/virtio/virtio.c|3509| <<virtio_queue_set_guest_notifier_fd_handler>> virtio_queue_guest_notifier_read(&vq->guest_notifier);
+     *   - hw/virtio/virtio.c|3532| <<virtio_queue_get_guest_notifier>> return &vq->guest_notifier;
+     */
     EventNotifier guest_notifier;
+    /*
+     * 在以下使用VirtQueue->host_notifier:
+     *   - hw/virtio/virtio.c|2294| <<virtio_queue_notify>> event_notifier_set(&vq->host_notifier);
+     *   - hw/virtio/virtio.c|3578| <<virtio_queue_aio_attach_host_notifier>> aio_set_event_notifier(ctx, &vq->host_notifier,
+     *   - hw/virtio/virtio.c|3582| <<virtio_queue_aio_attach_host_notifier>> aio_set_event_notifier_poll(ctx, &vq->host_notifier,
+     *   - hw/virtio/virtio.c|3591| <<virtio_queue_aio_attach_host_notifier>> event_notifier_set(&vq->host_notifier);
+     *   - hw/virtio/virtio.c|3627| <<virtio_queue_aio_attach_host_notifier_no_poll>> aio_set_event_notifier(ctx, &vq->host_notifier,
+     *   - hw/virtio/virtio.c|3637| <<virtio_queue_aio_attach_host_notifier_no_poll>> event_notifier_set(&vq->host_notifier);
+     *   - hw/virtio/virtio.c|3642| <<virtio_queue_aio_detach_host_notifier>> aio_set_event_notifier(ctx, &vq->host_notifier, NULL, NULL, NULL);
+     *   - hw/virtio/virtio.c|3666| <<virtio_queue_get_host_notifier>> return &vq->host_notifier;
+     *   - hw/virtio/virtio.c|3827| <<virtio_device_start_ioeventfd_impl>> event_notifier_set_handler(&vq->host_notifier,
+     *   - hw/virtio/virtio.c|3837| <<virtio_device_start_ioeventfd_impl>> event_notifier_set(&vq->host_notifier);
+     *   - hw/virtio/virtio.c|3850| <<virtio_device_start_ioeventfd_impl>> event_notifier_set_handler(&vq->host_notifier, NULL);
+     *   - hw/virtio/virtio.c|3893| <<virtio_device_stop_ioeventfd_impl>> event_notifier_set_handler(&vq->host_notifier, NULL);
+     */
     EventNotifier host_notifier;
     bool host_notifier_enabled;
     QLIST_ENTRY(VirtQueue) node;
@@ -995,6 +1018,46 @@ void virtqueue_flush(VirtQueue *vq, unsigned int count)
     }
 }
 
+/*
+ * called by:
+ *   - hw/9pfs/virtio-9p-device.c|38| <<virtio_9p_push_and_notify>> virtqueue_push(v->vq, elem, pdu->size);
+ *   - hw/audio/virtio-snd.c|749| <<process_cmd>> virtqueue_push(cmd->vq, cmd->elem, sizeof(virtio_snd_hdr) + cmd->payload_size);
+ *   - hw/audio/virtio-snd.c|852| <<empty_invalid_queue>> virtqueue_push(vq, buffer->elem, sizeof(virtio_snd_pcm_status));
+ *   - hw/audio/virtio-snd.c|1149| <<return_tx_buffer>> virtqueue_push(buffer->vq, buffer->elem, sizeof(virtio_snd_pcm_status));
+ *   - hw/audio/virtio-snd.c|1242| <<return_rx_buffer>> virtqueue_push(buffer->vq, buffer->elem, sizeof(virtio_snd_pcm_status) + buffer->size);
+ *   - hw/block/virtio-blk.c|68| <<virtio_blk_req_complete>> virtqueue_push(req->vq, &req->elem, req->in_len);
+ *   - hw/char/virtio-serial-bus.c|125| <<write_to_port>> virtqueue_push(vq, elem, len);
+ *   - hw/char/virtio-serial-bus.c|145| <<discard_vq_data>> virtqueue_push(vq, elem, 0);
+ *   - hw/char/virtio-serial-bus.c|207| <<do_flush_queued_data>> virtqueue_push(vq, port->elem, 0);
+ *   - hw/char/virtio-serial-bus.c|242| <<send_control_msg>> virtqueue_push(vq, elem, len);
+ *   - hw/char/virtio-serial-bus.c|491| <<control_out>> virtqueue_push(vq, elem, 0);
+ *   - hw/display/virtio-gpu.c|179| <<virtio_gpu_ctrl_response>> virtqueue_push(cmd->vq, &cmd->elem, s);
+ *   - hw/display/virtio-gpu.c|1157| <<virtio_gpu_handle_cursor>> virtqueue_push(vq, elem, 0);
+ *   - hw/input/virtio-input.c|65| <<virtio_input_send>> virtqueue_push(vinput->evt, elem, len);
+ *   - hw/input/virtio-input.c|97| <<virtio_input_handle_sts>> virtqueue_push(vinput->sts, elem, len);
+ *   - hw/net/virtio-net.c|1638| <<virtio_net_handle_ctrl>> virtqueue_push(vq, elem, written);
+ *   - hw/net/virtio-net.c|2695| <<virtio_net_tx_complete>> virtqueue_push(q->tx_vq, q->async_tx.elem, 0);
+ *   - hw/net/virtio-net.c|2813| <<virtio_net_flush_tx>> virtqueue_push(q->tx_vq, elem, 0);
+ *   - hw/scsi/virtio-scsi.c|112| <<virtio_scsi_complete_req>> virtqueue_push(vq, &req->elem, req->qsgl.size + req->resp_iov.size);
+ *   - hw/virtio/vhost-shadow-virtqueue.c|465| <<vhost_svq_push_elem>> virtqueue_push(svq->vq, elem, len);
+ *   - hw/virtio/vhost-vsock-common.c|185| <<vhost_vsock_common_send_transport_reset>> virtqueue_push(vq, elem, sizeof(event));
+ *   - hw/virtio/virtio-balloon.c|234| <<balloon_stats_poll_cb>> virtqueue_push(s->svq, s->stats_vq_elem, 0);
+ *   - hw/virtio/virtio-balloon.c|381| <<virtio_balloon_handle_report>> virtqueue_push(vq, elem, 0);
+ *   - hw/virtio/virtio-balloon.c|439| <<virtio_balloon_handle_output>> virtqueue_push(vq, elem, 0);
+ *   - hw/virtio/virtio-balloon.c|460| <<virtio_balloon_receive_stats>> virtqueue_push(vq, s->stats_vq_elem, 0);
+ *   - hw/virtio/virtio-balloon.c|546| <<get_free_page_hints>> virtqueue_push(vq, elem, 0);
+ *   - hw/virtio/virtio-crypto.c|300| <<virtio_crypto_create_session_completion>> virtqueue_push(vq, elem, sizeof(input));
+ *   - hw/virtio/virtio-crypto.c|330| <<virtio_crypto_destroy_session_completion>> virtqueue_push(vq, elem, sizeof(status));
+ *   - hw/virtio/virtio-crypto.c|443| <<virtio_crypto_handle_ctrl>> virtqueue_push(vq, elem, sizeof(input));
+ *   - hw/virtio/virtio-crypto.c|582| <<virtio_crypto_req_complete>> virtqueue_push(req->vq, &req->elem, req->in_len);
+ *   - hw/virtio/virtio-iommu.c|823| <<virtio_iommu_handle_command>> virtqueue_push(vq, elem, sz);
+ *   - hw/virtio/virtio-iommu.c|867| <<virtio_iommu_report_fault>> virtqueue_push(vq, elem, sz);
+ *   - hw/virtio/virtio-mem.c|460| <<virtio_mem_send_response>> virtqueue_push(vq, elem, sizeof(*resp));
+ *   - hw/virtio/virtio-pmem.c|62| <<done_cb>> virtqueue_push(req_data->pmem->rq_vq, &req_data->elem, len);
+ *   - hw/virtio/virtio-rng.c|81| <<chr_read>> virtqueue_push(vrng->vq, elem, len);
+ *   - hw/virtio/virtio.c|1859| <<virtqueue_packed_drop_all>> virtqueue_push(vq, &elem, 0);
+ *   - hw/virtio/virtio.c|1892| <<virtqueue_split_drop_all>> virtqueue_push(vq, &elem, 0);
+ */
 void virtqueue_push(VirtQueue *vq, const VirtQueueElement *elem,
                     unsigned int len)
 {
@@ -2464,6 +2527,11 @@ static void virtio_notify_irqfd_deferred_fn(void *opaque)
     event_notifier_set(notifier);
 }
 
+/*
+ * 在以下调用virtio_notify_irqfd():
+ *   - hw/block/virtio-blk.c|70| <<virtio_blk_req_complete>> virtio_notify_irqfd(vdev, req->vq);
+ *   - hw/scsi/virtio-scsi.c|114| <<virtio_scsi_complete_req>> virtio_notify_irqfd(vdev, vq);
+ */
 void virtio_notify_irqfd(VirtIODevice *vdev, VirtQueue *vq)
 {
     WITH_RCU_READ_LOCK_GUARD() {
@@ -2879,6 +2947,12 @@ const VMStateInfo  virtio_vmstate_info = {
     .put = virtio_device_put,
 };
 
+/*
+ * called by:
+ *   - hw/virtio/virtio.c|2974| <<virtio_set_features_nocheck_bh>> data->ret = virtio_set_features_nocheck(data->vdev, data->val);
+ *   - hw/virtio/virtio.c|2992| <<virtio_set_features_nocheck_maybe_co>> return virtio_set_features_nocheck(vdev, val);
+ *   - hw/virtio/virtio.c|3013| <<virtio_set_features>> ret = virtio_set_features_nocheck(vdev, val);
+ */
 static int virtio_set_features_nocheck(VirtIODevice *vdev, uint64_t val)
 {
     VirtioDeviceClass *k = VIRTIO_DEVICE_GET_CLASS(vdev);
@@ -2925,6 +2999,15 @@ virtio_set_features_nocheck_maybe_co(VirtIODevice *vdev, uint64_t val)
     }
 }
 
+/*
+ * called by:
+ *   - hw/s390x/virtio-ccw.c|431| <<virtio_ccw_cb>> virtio_set_features(vdev, (vdev->guest_features & 0xffffffff00000000ULL) | features.features);
+ *   - hw/s390x/virtio-ccw.c|440| <<virtio_ccw_cb>> virtio_set_features(vdev, (vdev->guest_features & 0x00000000ffffffffULL) | ((uint64_t)features.features << 32));
+ *   - hw/virtio/virtio-mmio.c|318| <<virtio_mmio_write>> virtio_set_features(vdev, value);
+ *   - hw/virtio/virtio-mmio.c|424| <<virtio_mmio_write>> virtio_set_features(vdev, ((uint64_t)proxy->guest_features[1]) << 32 | proxy->guest_features[0]);
+ *   - hw/virtio/virtio-pci.c|408| <<virtio_ioport_write>> virtio_set_features(vdev, val);
+ *   - hw/virtio/virtio-pci.c|1624| <<virtio_pci_common_write>> virtio_set_features(vdev, (((uint64_t)proxy->guest_features[1]) << 32) | proxy->guest_features[0]);
+ */
 int virtio_set_features(VirtIODevice *vdev, uint64_t val)
 {
     int ret;
@@ -3222,6 +3305,29 @@ void virtio_instance_init_common(Object *proxy_obj, void *data,
     qdev_alias_all_properties(vdev, proxy_obj);
 }
 
+/*
+ * called by:
+ *   - hw/9pfs/virtio-9p-device.c|219| <<virtio_9p_device_realize>> virtio_init(vdev, VIRTIO_ID_9P, v->config_size);
+ *   - hw/audio/virtio-snd.c|1093| <<virtio_snd_realize>> virtio_init(vdev, VIRTIO_ID_SOUND, sizeof(virtio_snd_config));
+ *   - hw/block/vhost-user-blk.c|465| <<vhost_user_blk_device_realize>> virtio_init(vdev, VIRTIO_ID_BLOCK, config_size);
+ *   - hw/block/virtio-blk.c|2321| <<virtio_blk_device_realize>> virtio_init(vdev, VIRTIO_ID_BLOCK, s->config_size);
+ *   - hw/char/virtio-serial-bus.c|1047| <<virtio_serial_device_realize>> virtio_init(vdev, VIRTIO_ID_CONSOLE, config_size);
+ *   - hw/display/virtio-gpu-base.c|193| <<virtio_gpu_base_device_realize>> virtio_init(VIRTIO_DEVICE(g), VIRTIO_ID_GPU,
+ *   - hw/input/virtio-input.c|260| <<virtio_input_device_realize>> virtio_init(vdev, VIRTIO_ID_INPUT, vinput->cfg_size);
+ *   - hw/net/virtio-net.c|3705| <<virtio_net_device_realize>> virtio_init(vdev, VIRTIO_ID_NET, n->config_size);
+ *   - hw/scsi/virtio-scsi.c|1206| <<virtio_scsi_common_realize>> virtio_init(vdev, VIRTIO_ID_SCSI, sizeof(VirtIOSCSIConfig));
+ *   - hw/virtio/vdpa-dev.c|150| <<vhost_vdpa_device_realize>> virtio_init(vdev, v->vdev_id, v->config_size);
+ *   - hw/virtio/vhost-user-base.c|304| <<vub_device_realize>> virtio_init(vdev, vub->virtio_id, vub->config_size);
+ *   - hw/virtio/vhost-user-fs.c|238| <<vuf_device_realize>> virtio_init(vdev, VIRTIO_ID_FS, sizeof(struct virtio_fs_config));
+ *   - hw/virtio/vhost-user-scmi.c|243| <<vu_scmi_device_realize>> virtio_init(vdev, VIRTIO_ID_SCMI, 0);
+ *   - hw/virtio/vhost-vsock-common.c|251| <<vhost_vsock_common_realize>> virtio_init(vdev, VIRTIO_ID_VSOCK, sizeof(struct virtio_vsock_config));
+ *   - hw/virtio/virtio-balloon.c|860| <<virtio_balloon_device_realize>> virtio_init(vdev, VIRTIO_ID_BALLOON, virtio_balloon_config_size(s));
+ *   - hw/virtio/virtio-crypto.c|1076| <<virtio_crypto_device_realize>> virtio_init(vdev, VIRTIO_ID_CRYPTO, vcrypto->config_size);
+ *   - hw/virtio/virtio-iommu.c|1306| <<virtio_iommu_device_realize>> virtio_init(vdev, VIRTIO_ID_IOMMU, sizeof(struct virtio_iommu_config));
+ *   - hw/virtio/virtio-mem.c|1098| <<virtio_mem_device_realize>> virtio_init(vdev, VIRTIO_ID_MEM, sizeof(struct virtio_mem_config));
+ *   - hw/virtio/virtio-pmem.c|125| <<virtio_pmem_realize>> virtio_init(vdev, VIRTIO_ID_PMEM, sizeof(struct virtio_pmem_config));
+ *   - hw/virtio/virtio-rng.c|218| <<virtio_rng_device_realize>> virtio_init(vdev, VIRTIO_ID_RNG, 0);
+ */
 void virtio_init(VirtIODevice *vdev, uint16_t device_id, size_t config_size)
 {
     BusState *qbus = qdev_get_parent_bus(DEVICE(vdev));
@@ -3527,6 +3633,19 @@ void virtio_config_set_guest_notifier_fd_handler(VirtIODevice *vdev,
     }
 }
 
+/*
+ * called by:
+ *   - hw/s390x/virtio-ccw.c|1001| <<virtio_ccw_add_irqfd>> EventNotifier *notifier = virtio_queue_get_guest_notifier(vq);
+ *   - hw/s390x/virtio-ccw.c|1011| <<virtio_ccw_remove_irqfd>> EventNotifier *notifier = virtio_queue_get_guest_notifier(vq);
+ *   - hw/s390x/virtio-ccw.c|1024| <<virtio_ccw_set_guest_notifier>> EventNotifier *notifier = virtio_queue_get_guest_notifier(vq);
+ *   - hw/virtio/vhost.c|1718| <<vhost_virtqueue_mask>> file.fd = event_notifier_get_wfd(virtio_queue_get_guest_notifier(vvq));
+ *   - hw/virtio/virtio-mmio.c|655| <<virtio_mmio_set_guest_notifier>> EventNotifier *notifier = virtio_queue_get_guest_notifier(vq);
+ *   - hw/virtio/virtio-pci.c|872| <<virtio_pci_get_notifier>> *n = virtio_queue_get_guest_notifier(vq);
+ *   - hw/virtio/virtio-pci.c|1058| <<virtio_pci_vector_unmask>> n = virtio_queue_get_guest_notifier(vq);
+ *   - hw/virtio/virtio-pci.c|1085| <<virtio_pci_vector_unmask>> n = virtio_queue_get_guest_notifier(vq);
+ *   - hw/virtio/virtio-pci.c|1104| <<virtio_pci_vector_mask>> n = virtio_queue_get_guest_notifier(vq);
+ *   - hw/virtio/virtio-pci.c|1192| <<virtio_pci_set_guest_notifier>> notifier = virtio_queue_get_guest_notifier(vq);
+ */
 EventNotifier *virtio_queue_get_guest_notifier(VirtQueue *vq)
 {
     return &vq->guest_notifier;
@@ -3562,6 +3681,13 @@ static void virtio_queue_host_notifier_aio_poll_end(EventNotifier *n)
     virtio_queue_set_notification(vq, 1);
 }
 
+/*
+ * called by:
+ *   - hw/block/virtio-blk.c|1590| <<virtio_blk_ioeventfd_attach>> virtio_queue_aio_attach_host_notifier(vq, s->vq_aio_context[i]);
+ *   - hw/scsi/virtio-scsi-dataplane.c|157| <<virtio_scsi_dataplane_start>> virtio_queue_aio_attach_host_notifier(vs->ctrl_vq, s->ctx);
+ *   - hw/scsi/virtio-scsi-dataplane.c|161| <<virtio_scsi_dataplane_start>> virtio_queue_aio_attach_host_notifier(vs->cmd_vqs[i], s->ctx);
+ *   - hw/scsi/virtio-scsi.c|1173| <<virtio_scsi_drained_end>> virtio_queue_aio_attach_host_notifier(vq, s->ctx);
+ */
 void virtio_queue_aio_attach_host_notifier(VirtQueue *vq, AioContext *ctx)
 {
     /*
@@ -3641,6 +3767,18 @@ void virtio_queue_host_notifier_read(EventNotifier *n)
     }
 }
 
+/*
+ * called by:
+ *   - hw/block/vhost-user-blk.c|304| <<vhost_user_blk_handle_output>> event_notifier_set(virtio_queue_get_host_notifier(kick_vq));
+  3 hw/block/virtio-blk.c|1880| <<virtio_blk_ioeventfd_stop_vq_bh>> EventNotifier *host_notifier = virtio_queue_get_host_notifier(vq);
+  4 hw/scsi/vhost-user-scsi.c|136| <<vhost_user_scsi_handle_output>> event_notifier_set(virtio_queue_get_host_notifier(kick_vq));
+  5 hw/scsi/virtio-scsi-dataplane.c|77| <<virtio_scsi_dataplane_stop_bh>> host_notifier = virtio_queue_get_host_notifier(vs->ctrl_vq);
+  6 hw/scsi/virtio-scsi-dataplane.c|86| <<virtio_scsi_dataplane_stop_bh>> host_notifier = virtio_queue_get_host_notifier(vs->event_vq);
+  7 hw/scsi/virtio-scsi-dataplane.c|91| <<virtio_scsi_dataplane_stop_bh>> host_notifier = virtio_queue_get_host_notifier(vs->cmd_vqs[i]);
+  8 hw/virtio/vhost.c|1251| <<vhost_virtqueue_start>> file.fd = event_notifier_get_fd(virtio_queue_get_host_notifier(vvq));
+  9 hw/virtio/virtio-bus.c|282| <<virtio_bus_set_host_notifier>> EventNotifier *notifier = virtio_queue_get_host_notifier(vq);
+ 10 hw/virtio/virtio-bus.c|316| <<virtio_bus_cleanup_host_notifier>> EventNotifier *notifier = virtio_queue_get_host_notifier(vq);
+ */
 EventNotifier *virtio_queue_get_host_notifier(VirtQueue *vq)
 {
     return &vq->host_notifier;
@@ -3784,6 +3922,16 @@ static Property virtio_properties[] = {
     DEFINE_PROP_END_OF_LIST(),
 };
 
+/*
+ * 在以下使用VirtioDeviceClass->start_ioeventfd:
+ *   - hw/block/virtio-blk.c|2181| <<virtio_blk_class_init>> vdc->start_ioeventfd = virtio_blk_start_ioeventfd;
+ *   - hw/scsi/virtio-scsi.c|1342| <<virtio_scsi_class_init>> vdc->start_ioeventfd = virtio_scsi_dataplane_start;
+ *   - hw/virtio/virtio-bus.c|236| <<virtio_bus_start_ioeventfd>> r = vdc->start_ioeventfd(vdev);
+ *   - hw/virtio/virtio.c|3965| <<virtio_device_class_init>> vdc->start_ioeventfd = virtio_device_start_ioeventfd_impl;
+ *
+ * 在以下使用virtio_device_start_ioeventfd_impl():
+ *   - hw/virtio/virtio.c|3965| <<virtio_device_class_init>> vdc->start_ioeventfd = virtio_device_start_ioeventfd_impl;
+ */
 static int virtio_device_start_ioeventfd_impl(VirtIODevice *vdev)
 {
     VirtioBusState *qbus = VIRTIO_BUS(qdev_get_parent_bus(DEVICE(vdev)));
diff --git a/include/block/aio.h b/include/block/aio.h
index 8378553eb..b78e118ae 100644
--- a/include/block/aio.h
+++ b/include/block/aio.h
@@ -177,6 +177,15 @@ struct AioContext {
      */
     QemuLockCnt list_lock;
 
+    /*
+     * 在以下使用AioContext->bh_list:
+     *   - util/async.c|93| <<aio_bh_enqueue>> QSLIST_INSERT_HEAD_ATOMIC(&ctx->bh_list, bh, next);
+     *   - util/async.c|186| <<aio_bh_poll>> QSLIST_MOVE_ATOMIC(&slice.bh_list, &ctx->bh_list);
+     *   - util/async.c|281| <<aio_compute_timeout>> timeout = aio_compute_bh_timeout(&ctx->bh_list, timeout);
+     *   - util/async.c|336| <<aio_ctx_check>> QSLIST_FOREACH_RCU(bh, &ctx->bh_list, next) {
+     *   - util/async.c|395| <<aio_ctx_finalize>> while ((bh = aio_bh_dequeue(&ctx->bh_list, &flags))) {
+     *   - util/async.c|580| <<aio_context_new>> QSLIST_INIT(&ctx->bh_list);
+     */
     /* Bottom Halves pending aio_bh_poll() processing */
     BHList bh_list;
 
diff --git a/include/block/block_int-common.h b/include/block/block_int-common.h
index 761276127..3a48f9eef 100644
--- a/include/block/block_int-common.h
+++ b/include/block/block_int-common.h
@@ -1238,8 +1238,35 @@ struct BlockDriverState {
 
     unsigned int write_gen;               /* Current data generation */
 
+    /*
+     * 在以下使用BlockDriverState->reqs_lock:
+     *   - block.c|422| <<bdrv_new>> qemu_mutex_init(&bs->reqs_lock);
+     *   - block.c|5528| <<bdrv_delete>> qemu_mutex_destroy(&bs->reqs_lock);
+     *   - block/io.c|591| <<tracked_request_end>> qemu_mutex_lock(&req->bs->reqs_lock);
+     *   - block/io.c|593| <<tracked_request_end>> qemu_mutex_unlock(&req->bs->reqs_lock);
+     *   - block/io.c|627| <<tracked_request_begin>> qemu_mutex_lock(&bs->reqs_lock);
+     *   - block/io.c|629| <<tracked_request_begin>> qemu_mutex_unlock(&bs->reqs_lock);
+     *   - block/io.c|690| <<bdrv_wait_serialising_requests_locked>> qemu_co_queue_wait(&req->wait_queue, &self->bs->reqs_lock);
+     *   - block/io.c|793| <<bdrv_wait_serialising_requests>> qemu_mutex_lock(&bs->reqs_lock);
+     *   - block/io.c|795| <<bdrv_wait_serialising_requests>> qemu_mutex_unlock(&bs->reqs_lock);
+     *   - block/io.c|803| <<bdrv_make_request_serialising>> qemu_mutex_lock(&req->bs->reqs_lock);
+     *   - block/io.c|808| <<bdrv_make_request_serialising>> qemu_mutex_unlock(&req->bs->reqs_lock);
+     *   - block/io.c|1973| <<bdrv_co_write_req_prepare>> QEMU_LOCK_GUARD(&bs->reqs_lock);
+     *   - block/io.c|2962| <<bdrv_co_flush>> qemu_mutex_lock(&bs->reqs_lock);
+     *   - block/io.c|2967| <<bdrv_co_flush>> qemu_co_queue_wait(&bs->flush_queue, &bs->reqs_lock);
+     *   - block/io.c|2972| <<bdrv_co_flush>> qemu_mutex_unlock(&bs->reqs_lock);
+     *   - block/io.c|3060| <<bdrv_co_flush>> qemu_mutex_lock(&bs->reqs_lock);
+     *   - block/io.c|3064| <<bdrv_co_flush>> qemu_mutex_unlock(&bs->reqs_lock);
+     */
     /* Protected by reqs_lock.  */
     QemuMutex reqs_lock;
+    /*
+     * 在以下使用BlockDriverState->tracked_requests:
+     *   - block/io.c|628| <<tracked_request_begin>> QLIST_INSERT_HEAD(&bs->tracked_requests, req, list);
+     *   - block/io.c|654| <<bdrv_find_conflicting_request>> QLIST_FOREACH(req, &self->bs->tracked_requests, list) {
+     *   - block/io.c|724| <<bdrv_co_get_self_request>> QLIST_FOREACH(req, &bs->tracked_requests, list) {
+     *   - block/mirror.c|1130| <<mirror_run>> assert(QLIST_EMPTY(&bs->tracked_requests));
+     */
     QLIST_HEAD(, BdrvTrackedRequest) tracked_requests;
     CoQueue flush_queue;                  /* Serializing flush queue */
     bool active_flush_req;                /* Flush request in flight? */
diff --git a/include/hw/block/block.h b/include/hw/block/block.h
index de3946a5f..07c297d28 100644
--- a/include/hw/block/block.h
+++ b/include/hw/block/block.h
@@ -68,6 +68,36 @@ static inline unsigned int get_physical_block_exp(BlockConf *conf)
     DEFINE_PROP_ON_OFF_AUTO("account-failed", _state,                   \
                             _conf.account_failed, ON_OFF_AUTO_AUTO)
 
+/*
+ * (gdb) bt
+ * #0  blk_new (ctx=0x55555716e240, perm=0, shared_perm=15) at ../block/block-backend.c:357
+ * #1  0x000055555593f279 in set_drive_helper (obj=0x5555580dc630, v=
+ *     0x5555580e0fc0, name=0x5555580de030 "drive", opaque=0x555556fbbf80 <virtio_blk_properties>, iothread=false, errp=0x7fffffffd710) at ../hw/core/qdev-properties-system.c:146
+ * #2  0x000055555593f453 in set_drive (obj=0x5555580dc630, v=0x5555580e0fc0, name=0x5555580de030 "drive", opaque=0x555556fbbf80 <virtio_blk_properties>, errp=0x7fffffffd710)
+ *     at ../hw/core/qdev-properties-system.c:190
+ * #3  0x0000555555e8b43c in field_prop_set (obj=0x5555580dc630, v=0x5555580e0fc0, name=0x5555580de030 "drive", opaque=0x555556fbbf80 <virtio_blk_properties>, errp=0x7fffffffd710)
+ *     at ../hw/core/qdev-properties.c:88
+ * #4  0x0000555555e98e36 in object_property_set (obj=0x5555580dc630, name=0x5555580de030 "drive", v=0x5555580e0fc0, errp=0x7fffffffd710) at ../qom/object.c:1472
+ * #5  0x0000555555e9c464 in property_set_alias (obj=0x5555580d4260, v=0x5555580e0e00, name=0x5555580e0d90 "drive", opaque=0x5555580de010, errp=0x7fffffffd710) at ../qom/object.c:2799
+ * #6  0x0000555555e98e36 in object_property_set (obj=0x5555580d4260, name=0x5555580e0d90 "drive", v=0x5555580e0e00, errp=0x7fffffffd710) at ../qom/object.c:1472
+ * #7  0x0000555555e9cbc1 in object_set_properties_from_qdict (obj=0x5555580d4260, qdict=0x5555580dfc70, v=0x5555580e0e00, errp=0x7fffffffd710) at ../qom/object_interfaces.c:55
+ * #8  0x0000555555e9ccbc in object_set_properties_from_keyval (obj=0x5555580d4260, qdict=0x5555580dfc70, from_json=false, errp=0x7fffffffd710) at ../qom/object_interfaces.c:73
+ * #9  0x0000555555bbc53a in qdev_device_add_from_qdict (opts=0x5555580d3220, from_json=false, errp=0x7fffffffd710) at ../system/qdev-monitor.c:712
+ * #10 0x0000555555bbc611 in qdev_device_add (opts=0x55555716d840, errp=0x5555570af7c0 <error_fatal>) at ../system/qdev-monitor.c:737
+ * #11 0x0000555555bc6d64 in device_init_func (opaque=0x0, opts=0x55555716d840, errp=0x5555570af7c0 <error_fatal>) at ../system/vl.c:1200
+ * #12 0x00005555560c439e in qemu_opts_foreach (list=0x555556f98e80 <qemu_device_opts>, func=0x555555bc6d35 <device_init_func>, opaque=0x0, errp=0x5555570af7c0 <error_fatal>)
+ *     at ../util/qemu-option.c:1135
+ * #13 0x0000555555bcac00 in qemu_create_cli_devices () at ../system/vl.c:2637
+ * #14 0x0000555555bcae46 in qmp_x_exit_preconfig (errp=0x5555570af7c0 <error_fatal>) at ../system/vl.c:2706
+ * #15 0x0000555555bcd92e in qemu_init (argc=30, argv=0x7fffffffdb18) at ../system/vl.c:3739
+ * #16 0x0000555555e8a1ef in main (argc=30, argv=0x7fffffffdb18) at ../system/main.c:47
+ *
+ * VirtIOBlock:
+ * -> BlockBackend *blk;
+ * -> VirtIOBlkConf conf;
+ *    -> BlockConf conf;
+ *       -> BlockBackend *blk;
+ */
 #define DEFINE_BLOCK_PROPERTIES(_state, _conf)                          \
     DEFINE_PROP_DRIVE("drive", _state, _conf.blk),                      \
     DEFINE_BLOCK_PROPERTIES_BASE(_state, _conf)
diff --git a/include/hw/hotplug.h b/include/hw/hotplug.h
index a9840ed48..5bf50cd32 100644
--- a/include/hw/hotplug.h
+++ b/include/hw/hotplug.h
@@ -57,6 +57,29 @@ struct HotplugHandlerClass {
     /* <public> */
     hotplug_fn pre_plug;
     hotplug_fn plug;
+    /*
+     * 在以下设置HotplugHandlerClass->unplug_request:
+     *   - hw/acpi/generic_event_device.c|416| <<acpi_ged_class_init>> hc->unplug_request = acpi_ged_unplug_request_cb;
+     *   - hw/acpi/piix4.c|648| <<piix4_pm_class_init>> hc->unplug_request = piix4_device_unplug_request_cb;
+     *   - hw/arm/virt.c|3015| <<virt_machine_class_init>> hc->unplug_request = virt_machine_device_unplug_request_cb;
+     *   - hw/i386/microvm.c|667| <<microvm_class_init>> hc->unplug_request = microvm_device_unplug_request_cb;
+     *   - hw/i386/pc.c|1831| <<pc_machine_class_init>> hc->unplug_request = pc_machine_device_unplug_request_cb;
+     *   - hw/isa/lpc_ich9.c|891| <<ich9_lpc_class_init>> hc->unplug_request = ich9_pm_device_unplug_request_cb;
+     *   - hw/loongarch/virt.c|1191| <<loongarch_class_init>> hc->unplug_request = virt_machine_device_unplug_request;
+     *   - hw/pci-bridge/pci_bridge_dev.c|263| <<pci_bridge_dev_class_init>> hc->unplug_request = pci_bridge_dev_unplug_request_cb;
+     *   - hw/pci-bridge/pcie_pci_bridge.c|159| <<pcie_pci_bridge_class_init>> hc->unplug_request = pci_bridge_dev_unplug_request_cb;
+     *   - hw/pci/pcie_port.c|235| <<pcie_slot_class_init>> hc->unplug_request = pcie_cap_slot_unplug_request_cb;
+     *   - hw/ppc/spapr.c|4692| <<spapr_machine_class_init>> hc->unplug_request = spapr_machine_device_unplug_request;
+     *   - hw/ppc/spapr_pci.c|2261| <<spapr_phb_class_init>> hp->unplug_request = spapr_pci_unplug_request;
+     *   - hw/s390x/s390-pci-bus.c|1331| <<s390_pcihost_class_init>> hc->unplug_request = s390_pcihost_unplug_request;
+     *   - hw/s390x/s390-virtio-ccw.c|778| <<ccw_machine_class_init>> hc->unplug_request = s390_machine_device_unplug_request;
+     *   - hw/xen/xen-bus.c|389| <<xen_bus_class_init>> hotplug_class->unplug_request = xen_bus_unplug_request;
+     * 在以下使用HotplugHandlerClass->unplug_request:
+     *   - hw/core/hotplug.c|44| <<hotplug_handler_unplug_request>> if (hdc->unplug_request) {
+     *   - hw/core/hotplug.c|45| <<hotplug_handler_unplug_request>> hdc->unplug_request(plug_handler, plugged_dev, errp);
+     *   - hw/virtio/virtio-md-pci.c|100| <<virtio_md_pci_unplug_request>> if (hdc->unplug_request) {
+     *   - system/qdev-monitor.c|938| <<qdev_unplug>> if (hdc->unplug_request) {
+     */
     hotplug_fn unplug_request;
     hotplug_fn unplug;
     bool (*is_hotpluggable_bus)(HotplugHandler *plug_handler, BusState *bus);
diff --git a/include/hw/i386/apic_internal.h b/include/hw/i386/apic_internal.h
index d6e85833d..b762e01bf 100644
--- a/include/hw/i386/apic_internal.h
+++ b/include/hw/i386/apic_internal.h
@@ -149,6 +149,16 @@ struct APICCommonClass {
     /* send_msi emulates an APIC bus and its proper place would be in a new
      * device, but it's convenient to have it here for now.
      */
+    /*
+     * 在以下使用APICommonClass->send_msi:
+     *   - hw/i386/amd_iommu.c|1382| <<amdvi_mem_ir_write>> apic_get_class(NULL)->send_msi(&to);
+     *   - hw/i386/intel_iommu.c|400| <<vtd_generate_interrupt>> apic_get_class(NULL)->send_msi(&msi);
+     *   - hw/i386/intel_iommu.c|3628| <<vtd_mem_ir_write>> apic_get_class(NULL)->send_msi(&to);
+     *   - hw/i386/kvm/apic.c|257| <<kvm_apic_class_init>> k->send_msi = kvm_send_msi;
+     *   - hw/i386/xen/xen_apic.c|89| <<xen_apic_class_init>> k->send_msi = xen_send_msi;
+     *   - hw/intc/apic.c|1193| <<apic_class_init>> k->send_msi = apic_send_msi;
+     *   - target/i386/whpx/whpx-apic.c|267| <<whpx_apic_class_init>> k->send_msi = whpx_send_msi;
+     */
     void (*send_msi)(MSIMessage *msi);
 };
 
diff --git a/include/hw/pci/pci_bus.h b/include/hw/pci/pci_bus.h
index 226131254..dd6817a18 100644
--- a/include/hw/pci/pci_bus.h
+++ b/include/hw/pci/pci_bus.h
@@ -36,6 +36,14 @@ struct PCIBus {
     const PCIIOMMUOps *iommu_ops;
     void *iommu_opaque;
     uint8_t devfn_min;
+    /*
+     * 在以下使用PCIBus->slot_reserved_mask:
+     *   - hw/pci/pci.c|511| <<pci_root_bus_internal_init>> bus->slot_reserved_mask = 0x0;
+     *   - hw/pci/pci.c|1130| <<pci_bus_devfn_reserved>> return bus->slot_reserved_mask & (1UL << PCI_SLOT(devfn));
+     *   - hw/pci/pci.c|1135| <<pci_bus_get_slot_reserved_mask>> return bus->slot_reserved_mask;
+     *   - hw/pci/pci.c|1140| <<pci_bus_set_slot_reserved_mask>> bus->slot_reserved_mask |= mask;
+     *   - hw/pci/pci.c|1149| <<pci_bus_clear_slot_reserved_mask>> bus->slot_reserved_mask &= ~mask;
+     */
     uint32_t slot_reserved_mask;
     pci_set_irq_fn set_irq;
     pci_map_irq_fn map_irq;
diff --git a/include/hw/pci/pci_device.h b/include/hw/pci/pci_device.h
index d3dd0f64b..bb61a3f96 100644
--- a/include/hw/pci/pci_device.h
+++ b/include/hw/pci/pci_device.h
@@ -112,6 +112,18 @@ struct PCIDevice {
 
     /* Space to store MSIX table & pending bit array */
     uint8_t *msix_table;
+    /*
+     * 在以下使用PCIDevice->msix_pba:
+     *   - hw/pci/msix.c|71| <<msix_pending_byte>> return dev->msix_pba + vector / 8;
+     *   - hw/pci/msix.c|311| <<msix_pba_mmio_read>> return pci_get_long(dev->msix_pba + addr);
+     *   - hw/pci/msix.c|423| <<msix_init>> dev->msix_pba = g_malloc0(pba_size);
+     *   - hw/pci/msix.c|514| <<msix_uninit>> g_free(dev->msix_pba);
+     *   - hw/pci/msix.c|515| <<msix_uninit>> dev->msix_pba = NULL;
+     *   - hw/pci/msix.c|541| <<msix_save>> qemu_put_buffer(f, dev->msix_pba, DIV_ROUND_UP(n, 8));
+     *   - hw/pci/msix.c|556| <<msix_load>> qemu_get_buffer(f, dev->msix_pba, DIV_ROUND_UP(n, 8));
+     *   - hw/pci/msix.c|608| <<msix_reset>> memset(dev->msix_pba, 0, QEMU_ALIGN_UP(dev->msix_entries_nr, 64) / 8);
+     *   - hw/usb/hcd-xhci-pci.c|171| <<usb_xhci_pci_exit>> if (dev->msix_table && dev->msix_pba && dev->msix_entry_used) {
+     */
     uint8_t *msix_pba;
 
     /* May be used by INTx or MSI during interrupt notification */
@@ -125,6 +137,15 @@ struct PCIDevice {
     MemoryRegion msix_exclusive_bar;
     /* Memory Regions for MSIX table and pending bit entries. */
     MemoryRegion msix_table_mmio;
+    /*
+     * 在以下使用PCIDevice->msix_pba_mmio:
+     *   - hw/pci/msix.c|416| <<msix_init>> memory_region_init_io(&dev->msix_pba_mmio, OBJECT(dev), &msix_pba_mmio_ops, dev, "msix-pba", pba_size);
+     *   - hw/pci/msix.c|418| <<msix_init>> memory_region_add_subregion(pba_bar, pba_offset, &dev->msix_pba_mmio);
+     *   - hw/pci/msix.c|498| <<msix_uninit>> memory_region_del_subregion(pba_bar, &dev->msix_pba_mmio);
+     *   - hw/vfio/pci.c|359| <<vfio_msi_interrupt>> memory_region_set_enabled(&vdev->pdev.msix_pba_mmio, true);
+     *   - hw/vfio/pci.c|632| <<vfio_msix_vector_do_use>> memory_region_set_enabled(&vdev->pdev.msix_pba_mmio, false);
+     *   - hw/vfio/pci.c|1737| <<vfio_msix_setup>> memory_region_set_enabled(&vdev->pdev.msix_pba_mmio, false);
+     */
     MemoryRegion msix_pba_mmio;
     /* Reference-count for entries actually in use by driver. */
     unsigned *msix_entry_used;
@@ -153,8 +174,38 @@ struct PCIDevice {
     PCIINTxRoutingNotifier intx_routing_notifier;
 
     /* MSI-X notifiers */
+    /*
+     * 在以下使用PCIDevice->msix_vector_use_notifier:
+     *   - hw/misc/ivshmem.c|795| <<ivshmem_disable_irqfd>> if (!pdev->msix_vector_use_notifier) {
+     *   - hw/pci/msix.c|113| <<msix_fire_vector_notifier>> if (!dev->msix_vector_use_notifier) {
+     *   - hw/pci/msix.c|120| <<msix_fire_vector_notifier>> ret = dev->msix_vector_use_notifier(dev, vector, msg);
+     *   - hw/pci/msix.c|607| <<msix_set_notifier_for_vector>> return dev->msix_vector_use_notifier(dev, vector, msg);
+     *   - hw/pci/msix.c|627| <<msix_set_vector_notifiers>> dev->msix_vector_use_notifier = use_notifier;
+     *   - hw/pci/msix.c|649| <<msix_set_vector_notifiers>> dev->msix_vector_use_notifier = NULL;
+     *   - hw/pci/msix.c|659| <<msix_unset_vector_notifiers>> assert(dev->msix_vector_use_notifier &&
+     *   - hw/pci/msix.c|668| <<msix_unset_vector_notifiers>> dev->msix_vector_use_notifier = NULL;
+     */
     MSIVectorUseNotifier msix_vector_use_notifier;
+    /*
+     * 在以下使用PCIDevice->msix_vector_release_notifier:
+     *   - hw/pci/msix.c|117| <<msix_fire_vector_notifier>> dev->msix_vector_release_notifier(dev, vector);
+     *   - hw/pci/msix.c|615| <<msix_unset_notifier_for_vector>> dev->msix_vector_release_notifier(dev, vector);
+     *   - hw/pci/msix.c|628| <<msix_set_vector_notifiers>> dev->msix_vector_release_notifier = release_notifier;
+     *   - hw/pci/msix.c|650| <<msix_set_vector_notifiers>> dev->msix_vector_release_notifier = NULL;
+     *   - hw/pci/msix.c|660| <<msix_unset_vector_notifiers>> dev->msix_vector_release_notifier);
+     *   - hw/pci/msix.c|669| <<msix_unset_vector_notifiers>> dev->msix_vector_release_notifier = NULL;
+     */
     MSIVectorReleaseNotifier msix_vector_release_notifier;
+    /*
+     * 在以下使用PCIDevice->msix_vector_poll_notifier:
+     *   - hw/pci/msix.c|251| <<msix_pba_mmio_read>> if (dev->msix_vector_poll_notifier) {
+     *   - hw/pci/msix.c|254| <<msix_pba_mmio_read>> dev->msix_vector_poll_notifier(dev, vector_start, vector_end);
+     *   - hw/pci/msix.c|629| <<msix_set_vector_notifiers>> dev->msix_vector_poll_notifier = poll_notifier;
+     *   - hw/pci/msix.c|640| <<msix_set_vector_notifiers>> if (dev->msix_vector_poll_notifier) {
+     *   - hw/pci/msix.c|641| <<msix_set_vector_notifiers>> dev->msix_vector_poll_notifier(dev, 0, dev->msix_entries_nr);
+     *   - hw/pci/msix.c|651| <<msix_set_vector_notifiers>> dev->msix_vector_poll_notifier = NULL;
+     *   - hw/pci/msix.c|670| <<msix_unset_vector_notifiers>> dev->msix_vector_poll_notifier = NULL;
+     */
     MSIVectorPollNotifier msix_vector_poll_notifier;
 
     /* ID of standby device in net_failover pair */
diff --git a/include/hw/scsi/scsi.h b/include/hw/scsi/scsi.h
index c3d5e17e3..20e18bfd4 100644
--- a/include/hw/scsi/scsi.h
+++ b/include/hw/scsi/scsi.h
@@ -91,6 +91,16 @@ struct SCSIDevice
     uint64_t port_wwn;
     int scsi_version;
     int default_scsi_version;
+    /*
+     * 在以下使用SCSIDevice->io_timeout:
+     *   - hw/scsi/scsi-disk.c|3234| <<global>> DEFINE_PROP_UINT32("io_timeout", SCSIDiskState, qdev.io_timeout, DEFAULT_IO_TIMEOUT),
+     *   - hw/scsi/scsi-generic.c|778| <<global>> DEFINE_PROP_UINT32("io_timeout", SCSIDevice, io_timeout, DEFAULT_IO_TIMEOUT),
+     *   - hw/scsi/scsi-disk.c|2701| <<get_device_type>> ret = scsi_SG_IO_FROM_DEV(s->qdev.conf.blk, cmd, sizeof(cmd), buf, sizeof(buf), s->qdev.io_timeout);
+     *   - hw/scsi/scsi-disk.c|2901| <<scsi_block_do_sgio>> io_header->timeout = s->qdev.io_timeout * 1000;
+     *   - hw/scsi/scsi-generic.c|133| <<execute_command>> r->io_header.timeout = s->io_timeout * 1000;
+     *   - hw/scsi/scsi-generic.c|577| <<scsi_generic_set_vpd_bl_emulation>> ret = scsi_SG_IO_FROM_DEV(s->conf.blk, cmd, sizeof(cmd), buf, sizeof(buf), s->io_timeout);
+     *   - hw/scsi/scsi-generic.c|613| <<scsi_generic_read_device_identification>> ret = scsi_SG_IO_FROM_DEV(s->conf.blk, cmd, sizeof(cmd), buf, sizeof(buf), s->io_timeout);
+     */
     uint32_t io_timeout;
     bool needs_vpd_bl_emulation;
     bool hba_supports_iothread;
diff --git a/include/hw/virtio/vhost.h b/include/hw/virtio/vhost.h
index 02477788d..f5b61bb10 100644
--- a/include/hw/virtio/vhost.h
+++ b/include/hw/virtio/vhost.h
@@ -107,7 +107,49 @@ struct vhost_dev {
      * its easy to confuse with the VirtIO backend_features.
      */
     uint64_t features;
+    /*
+     * 在以下使用vhost_dev->acked_features:
+     *   - backends/vhost-user.c|75| <<vhost_user_backend_start>> b->dev.acked_features = b->vdev->guest_features;
+     *   - hw/block/vhost-user-blk.c|143| <<vhost_user_blk_start>> s->dev.acked_features = vdev->guest_features;
+     *   - hw/net/vhost_net.c|136| <<vhost_net_ack_features>> net->dev.acked_features = net->dev.backend_features;
+     *   - hw/net/vhost_net.c|147| <<vhost_net_get_acked_features>> return net->dev.acked_features;
+     *   - hw/scsi/vhost-scsi-common.c|55| <<vhost_scsi_common_start>> vsc->dev.acked_features = vdev->guest_features;
+     *   - hw/virtio/vdpa-dev.c|261| <<vhost_vdpa_device_start>> s->dev.acked_features = vdev->guest_features;
+     *   - hw/virtio/vhost-user-base.c|44| <<vub_start>> vub->vhost_dev.acked_features = vdev->guest_features;
+     *   - hw/virtio/vhost-user-fs.c|78| <<vuf_start>> fs->vhost_dev.acked_features = vdev->guest_features;
+     *   - hw/virtio/vhost-user.c|2338| <<vhost_user_migration_done>> if (virtio_has_feature(dev->acked_features, VIRTIO_NET_F_GUEST_ANNOUNCE)) {
+     *   - hw/virtio/vhost-vsock-common.c|72| <<vhost_vsock_common_start>> vvc->vhost_dev.acked_features = vdev->guest_features;
+     *   - hw/virtio/vhost.c|924| <<vhost_dev_set_features>> uint64_t features = dev->acked_features;
+     *   - hw/virtio/vhost.c|1810| <<vhost_ack_features>> hdev->acked_features |= bit_mask;
+     *   - hw/virtio/virtio-hmp-cmds.c|177| <<hmp_virtio_status>> hmp_virtio_dump_features(mon, s->vhost_dev->acked_features);
+     *   - hw/virtio/virtio-qmp.c|780| <<qmp_x_query_virtio_status>> status->vhost_dev->acked_features = qmp_decode_features(vdev->device_id, hdev->acked_features);
+     */
     uint64_t acked_features;
+    /*
+     * 在以下使用vhost_dev->backend_features:
+     *   - hw/block/vhost-user-blk.c|329| <<vhost_user_blk_connect>> s->dev.backend_features = 0;
+     *   - hw/net/vhost_net.c|136| <<vhost_net_ack_features>> net->dev.acked_features = net->dev.backend_features;
+     *   - hw/net/vhost_net.c|193| <<vhost_net_init>> net->dev.backend_features = qemu_has_vnet_hdr(options->net_backend)
+     *   - hw/net/vhost_net.c|198| <<vhost_net_init>> net->dev.backend_features = 0;
+     *   - hw/net/vhost_net.c|218| <<vhost_net_init>> if (~net->dev.features & net->dev.backend_features) {
+     *   - hw/net/vhost_net.c|221| <<vhost_net_init>> (uint64_t)(~net->dev.features & net->dev.backend_features));
+     *   - hw/scsi/vhost-scsi.c|276| <<vhost_scsi_realize>> vsc->dev.backend_features = 0;
+     *   - hw/scsi/vhost-user-scsi.c|156| <<vhost_user_scsi_connect>> vsc->dev.backend_features = 0;
+     *   - hw/virtio/vdpa-dev.c|107| <<vhost_vdpa_device_realize>> v->dev.backend_features = 0;
+     *   - hw/virtio/vhost-user.c|1437| <<vhost_user_set_features>> ret = vhost_user_set_u64(dev, VHOST_USER_SET_FEATURES,
+     *                     features | dev->backend_features, log_enabled);
+     *   - hw/virtio/vhost-user.c|2164| <<vhost_user_backend_init>> dev->backend_features |= 1ULL << VHOST_USER_F_PROTOCOL_FEATURES;
+     *   - hw/virtio/vhost.c|1979| <<vhost_dev_set_vring_enable>> !virtio_has_feature(hdev->backend_features, VHOST_USER_F_PROTOCOL_FEATURES)) {
+     *   - hw/virtio/virtio-hmp-cmds.c|179| <<hmp_virtio_status>> hmp_virtio_dump_features(mon, s->vhost_dev->backend_features);
+     *   - hw/virtio/virtio-qmp.c|782| <<qmp_x_query_virtio_status>> status->vhost_dev->backend_features = qmp_decode_features(vdev->device_id, hdev->backend_features);
+     *
+     * 在以下使用VirtIODevice->backend_features:
+     *   - hw/net/virtio-net.c|838| <<virtio_net_get_features>> vdev->backend_features = features;
+     *   - hw/net/virtio-net.c|856| <<virtio_net_get_features>> if (!virtio_has_feature(vdev->backend_features, VIRTIO_NET_F_CTRL_VQ)) {
+     *   - hw/net/virtio-net.c|993| <<virtio_net_set_features>> !virtio_has_feature(vdev->backend_features, VIRTIO_NET_F_MTU)) {
+     *   - hw/virtio/virtio-qmp.c|740| <<qmp_x_query_virtio_status>> status->backend_features = qmp_decode_features(vdev->device_id, vdev->backend_features);
+     *   - hw/virtio/virtio-qmp.c|782| <<qmp_x_query_virtio_status>> status->vhost_dev->backend_features = qmp_decode_features(vdev->device_id, hdev->backend_features);
+     */
     uint64_t backend_features;
 
     /**
diff --git a/include/hw/virtio/virtio-blk.h b/include/hw/virtio/virtio-blk.h
index 5c14110c4..ec15eec96 100644
--- a/include/hw/virtio/virtio-blk.h
+++ b/include/hw/virtio/virtio-blk.h
@@ -34,10 +34,41 @@ struct virtio_blk_inhdr
 
 #define VIRTIO_BLK_AUTO_NUM_QUEUES UINT16_MAX
 
+/*
+ * 20 typedef struct BlockConf {
+ * 21     BlockBackend *blk;
+ * 22     OnOffAuto backend_defaults;
+ * 23     uint32_t physical_block_size;
+ * 24     uint32_t logical_block_size;
+ * 25     uint32_t min_io_size;
+ * 26     uint32_t opt_io_size;
+ * 27     int32_t bootindex;
+ * 28     uint32_t discard_granularity;
+ * 29     // geometry, not all devices use this
+ * 30     uint32_t cyls, heads, secs;
+ * 31     uint32_t lcyls, lheads, lsecs;
+ * 32     OnOffAuto wce;
+ * 33     bool share_rw;
+ * 34     OnOffAuto account_invalid, account_failed;
+ * 35     BlockdevOnError rerror;
+ * 36     BlockdevOnError werror;
+ * 37 } BlockConf;
+ */
+
 struct VirtIOBlkConf
 {
     BlockConf conf;
     IOThread *iothread;
+    /*
+     * 在以下使用apply_iothread_vq_mapping->iothread_vq_mapping_list:
+     *   - hw/block/virtio-blk.c|2176| <<global>> DEFINE_PROP_IOTHREAD_VQ_MAPPING_LIST("iothread-vq-mapping", VirtIOBlock, conf.iothread_vq_mapping_list),
+     *   - hw/block/virtio-blk.c|1720| <<virtio_blk_vq_aio_context_init>> if (conf->iothread && conf->iothread_vq_mapping_list) {
+     *   - hw/block/virtio-blk.c|1727| <<virtio_blk_vq_aio_context_init>> if (conf->iothread || conf->iothread_vq_mapping_list) {
+     *   - hw/block/virtio-blk.c|1751| <<virtio_blk_vq_aio_context_init>> if (conf->iothread_vq_mapping_list) {
+     *   - hw/block/virtio-blk.c|1752| <<virtio_blk_vq_aio_context_init>> if (!apply_iothread_vq_mapping(conf->iothread_vq_mapping_list,
+     *   - hw/block/virtio-blk.c|1785| <<virtio_blk_vq_aio_context_cleanup>> if (conf->iothread_vq_mapping_list) {
+     *   - hw/block/virtio-blk.c|1788| <<virtio_blk_vq_aio_context_cleanup>> for (node = conf->iothread_vq_mapping_list; node; node = node->next) {
+     */
     IOThreadVirtQueueMappingList *iothread_vq_mapping_list;
     char *serial;
     uint32_t request_merging;
@@ -60,6 +91,15 @@ struct VirtIOBlock {
     unsigned short sector_mask;
     bool original_wce;
     VMChangeStateEntry *change;
+    /*
+     * 在以下使用VirtIOBlock->ioeventfd_disabled:
+     *   - hw/block/virtio-blk.c|1202| <<virtio_blk_handle_output>> if (!s->ioeventfd_disabled && !s->ioeventfd_started) {
+     *   - hw/block/virtio-blk.c|1207| <<virtio_blk_handle_output>> if (!s->ioeventfd_disabled) {
+     *   - hw/block/virtio-blk.c|2057| <<virtio_blk_start_ioeventfd>> s->ioeventfd_disabled = true;
+     *   - hw/block/virtio-blk.c|2094| <<virtio_blk_stop_ioeventfd>> if (s->ioeventfd_disabled) {
+     *   - hw/block/virtio-blk.c|2095| <<virtio_blk_stop_ioeventfd>> s->ioeventfd_disabled = false;
+     *   - hw/block/virtio-blk.c|2246| <<virtio_blk_device_realize>> s->ioeventfd_disabled = true;
+     */
     bool ioeventfd_disabled;
     bool ioeventfd_started;
     bool ioeventfd_starting;
@@ -69,6 +109,26 @@ struct VirtIOBlock {
      * The AioContext for each virtqueue. The BlockDriverState will use the
      * first element as its AioContext.
      */
+    /*
+     * 在以下使用VirtIOBlock->vq_aio_context[][]:
+     *   - hw/block/virtio-blk.c|1261| <<virtio_blk_dma_restart_cb>> aio_bh_schedule_oneshot(s->vq_aio_context[i], virtio_blk_dma_restart_bh, vq_rq[i]);
+     *   - hw/block/virtio-blk.c|1549| <<virtio_blk_ioeventfd_detach>> virtio_queue_aio_detach_host_notifier(vq, s->vq_aio_context[i]);
+     *   - hw/block/virtio-blk.c|1559| <<virtio_blk_ioeventfd_attach>> virtio_queue_aio_attach_host_notifier(vq, s->vq_aio_context[i]);
+     *   - hw/block/virtio-blk.c|1749| <<virtio_blk_vq_aio_context_init>> s->vq_aio_context = g_new(AioContext *, conf->num_queues);
+     *   - hw/block/virtio-blk.c|1753| <<virtio_blk_vq_aio_context_init>> if (!apply_iothread_vq_mapping(conf->iothread_vq_mapping_list, s->vq_aio_context, conf->num_queues, errp)) {
+     *   - hw/block/virtio-blk.c|1756| <<virtio_blk_vq_aio_context_init>> g_free(s->vq_aio_context);
+     *   - hw/block/virtio-blk.c|1757| <<virtio_blk_vq_aio_context_init>> s->vq_aio_context = NULL;
+     *   - hw/block/virtio-blk.c|1763| <<virtio_blk_vq_aio_context_init>> s->vq_aio_context[i] = ctx;
+     *   - hw/block/virtio-blk.c|1771| <<virtio_blk_vq_aio_context_init>> s->vq_aio_context[i] = ctx;
+     *   - hw/block/virtio-blk.c|1798| <<virtio_blk_vq_aio_context_cleanup>> g_free(s->vq_aio_context);
+     *   - hw/block/virtio-blk.c|1799| <<virtio_blk_vq_aio_context_cleanup>> s->vq_aio_context = NULL;
+     *   - hw/block/virtio-blk.c|1864| <<virtio_blk_start_ioeventfd>> r = blk_set_aio_context(s->conf.conf.blk, s->vq_aio_context[0], &local_err);
+     *   - hw/block/virtio-blk.c|1943| <<virtio_blk_stop_ioeventfd>> AioContext *ctx = s->vq_aio_context[i];
+     *
+     * 注释:
+     * The AioContext for each virtqueue. The BlockDriverState will use the
+     * first element as its AioContext.
+     */
     AioContext **vq_aio_context;
 
     uint64_t host_features;
diff --git a/include/hw/virtio/virtio.h b/include/hw/virtio/virtio.h
index 7d5ffdc14..a9eee398b 100644
--- a/include/hw/virtio/virtio.h
+++ b/include/hw/virtio/virtio.h
@@ -119,8 +119,129 @@ struct VirtIODevice
      * backend (e.g. vhost) and could potentially be a subset of the
      * total feature set offered by QEMU.
      */
+    /*
+     * 下面是VirtIODevice->host_feature在virtio核心使用的地方:
+     *   - hw/virtio/virtio.c|3917| <<global>> DEFINE_VIRTIO_COMMON_FEATURES(VirtIODevice, host_features),
+     *   - hw/virtio/virtio-bus.c|66| <<virtio_bus_device_plugged>> vdev->host_features = vdc->get_features(vdev, vdev->host_features, &local_err);
+     *   - hw/virtio/virtio-bus.c|89| <<virtio_bus_device_plugged>> virtio_add_feature(&vdev->host_features, VIRTIO_F_IOMMU_PLATFORM);
+     *   - hw/virtio/virtio-mmio.c|166| <<virtio_mmio_read>> return vdev->host_features;
+     *   - hw/virtio/virtio-mmio.c|170| <<virtio_mmio_read>> return (vdev->host_features & ~vdc->legacy_features)
+     *   - hw/virtio/virtio-mmio.c|741| <<virtio_mmio_pre_plugged>> virtio_add_feature(&vdev->host_features, VIRTIO_F_VERSION_1);
+     *   - hw/virtio/virtio-pci.c|492| <<virtio_ioport_read>> ret = vdev->host_features;
+     *   - hw/virtio/virtio-pci.c|1531| <<virtio_pci_common_read>> val = (vdev->host_features & ~vdc->legacy_features) >>
+     *   - hw/virtio/virtio-pci.c|1983| <<virtio_pci_pre_plugged>> virtio_add_feature(&vdev->host_features, VIRTIO_F_VERSION_1);
+     *   - hw/virtio/virtio-pci.c|1986| <<virtio_pci_pre_plugged>> virtio_add_feature(&vdev->host_features, VIRTIO_F_BAD_FEATURE);
+     *   - hw/virtio/virtio-pci.c|2006| <<virtio_pci_device_plugged>> !virtio_has_feature(vdev->host_features, VIRTIO_F_VERSION_1)) {
+     *   - hw/virtio/virtio-qmp.c|738| <<qmp_x_query_virtio_status>> status->host_features = qmp_decode_features(vdev->device_id, vdev->host_features);
+     *   - hw/virtio/virtio.c|2608| <<virtio_64bit_features_needed>> return (vdev->host_features >> 32) != 0;
+     *   - hw/virtio/virtio.c|2959| <<virtio_set_features_nocheck>> bool bad = (val & ~(vdev->host_features)) != 0;
+     *   - hw/virtio/virtio.c|2961| <<virtio_set_features_nocheck>> val &= vdev->host_features;
+     *   - hw/virtio/virtio.c|3185| <<virtio_load>> error_report("Features 0x%" PRIx64 " unsupported. "
+     *                                              "Allowed features: 0x%" PRIx64, features64, vdev->host_features);
+     *   - hw/virtio/virtio.c|3192| <<virtio_load>>  error_report("Features 0x%x unsupported. "
+     *                                              "Allowed features: 0x%" PRIx64, features, vdev->host_features);
+     *   - include/hw/virtio/virtio.h|474| <<virtio_host_has_feature>> return virtio_has_feature(vdev->host_features, fbit);
+     *
+     * 下面是VirtIODevice->host_features在具体driver的使用:
+     *   - hw/block/vhost-user-blk.c|563| <<global>> DEFINE_PROP_BIT64("config-wce", VHostUserBlk, parent_obj.host_features,
+     *   - hw/block/vhost-user-blk.c|565| <<global>> DEFINE_PROP_BIT64("discard", VHostUserBlk, parent_obj.host_features,
+     *   - hw/block/vhost-user-blk.c|567| <<global>> DEFINE_PROP_BIT64("write-zeroes", VHostUserBlk, parent_obj.host_features
+     *   - hw/block/vhost-user-blk.c|464| <<vhost_user_blk_device_realize>> config_size = virtio_get_config_size(&virtio_blk_cfg_size_params, vdev->host_features);
+     *   - hw/s390x/virtio-ccw.c|389| <<virtio_ccw_cb>> (vdev->host_features & ~vdc->legacy_features);
+     *   - hw/s390x/virtio-ccw.c|391| <<virtio_ccw_cb>> features.features = (uint32_t)vdev->host_features;
+     *   - hw/s390x/virtio-ccw.c|398| <<virtio_ccw_cb>> features.features = (uint32_t)(vdev->host_features >> 32);
+     *   - hw/s390x/virtio-ccw.c|1147| <<virtio_ccw_pre_plugged>> virtio_add_feature(&vdev->host_features, VIRTIO_F_VERSION_1);
+     *   - hw/s390x/virtio-ccw.c|1161| <<virtio_ccw_device_plugged>> if (!virtio_has_feature(vdev->host_features, VIRTIO_F_VERSION_1))
+     *   - hw/virtio/vhost-user-scmi.c|237| <<vu_scmi_device_realize>> vdev->host_features |= (1ULL << VIRTIO_SCMI_F_P2A_CHANNELS);
+     *
+     * 注释:
+     * These fields represent a set of VirtIO features at various
+     * levels of the stack. @host_features indicates the complete
+     * feature set the VirtIO device can offer to the driver.
+     * @guest_features indicates which features the VirtIO driver has
+     * selected by writing to the feature register. Finally
+     * @backend_features represents everything supported by the
+     * backend (e.g. vhost) and could potentially be a subset of the
+     * total feature set offered by QEMU.
+     */
     uint64_t host_features;
+    /*
+     * 在以下使用VirtIODevice->guest_features:
+     *   - backends/vhost-user.c|75| <<vhost_user_backend_start>> b->dev.acked_features = b->vdev->guest_features;
+     *   - hw/block/vhost-user-blk.c|143| <<vhost_user_blk_start>> s->dev.acked_features = vdev->guest_features;
+     *   - hw/net/virtio-net.c|299| <<virtio_net_vhost_status>> if (virtio_has_feature(vdev->guest_features, VIRTIO_NET_F_MTU)) {
+     *   - hw/net/virtio-net.c|907| <<virtio_net_supported_guest_offloads>> return virtio_net_guest_offloads_by_features(vdev->guest_features);
+     *   - hw/net/virtio-net.c|1989| <<virtio_net_receive_rcu>> virtio_error(vdev, "virtio-net unexpected empty queue: "
+     *                                     "i %zd mergeable %d offset %zd, size %zd, "
+     *                                     "guest hdr len %zd, host hdr len %zd "
+     *                                     "guest features 0x%" PRIx64,
+     *                                     i, n->mergeable_rx_bufs, offset, size,
+     *                                     n->guest_hdr_len, n->host_hdr_len, vdev->guest_features);
+     *   - hw/s390x/virtio-ccw.c|432| <<virtio_ccw_cb>> (vdev->guest_features & 0xffffffff00000000ULL) |
+     *   - hw/s390x/virtio-ccw.c|441| <<virtio_ccw_cb>> (vdev->guest_features & 0x00000000ffffffffULL) |
+     *   - hw/scsi/vhost-scsi-common.c|55| <<vhost_scsi_common_start>> vsc->dev.acked_features = vdev->guest_features;
+     *   - hw/virtio/vdpa-dev.c|261| <<vhost_vdpa_device_start>> s->dev.acked_features = vdev->guest_features;
+     *   - hw/virtio/vhost-user-base.c|44| <<vub_start>> vub->vhost_dev.acked_features = vdev->guest_features;
+     *   - hw/virtio/vhost-user-fs.c|78| <<vuf_start>> fs->vhost_dev.acked_features = vdev->guest_features;
+     *   - hw/virtio/vhost-user-scmi.c|59| <<vu_scmi_start>> vhost_ack_features(vhost_dev, feature_bits, vdev->guest_features);
+     *   - hw/virtio/vhost-vsock-common.c|72| <<vhost_vsock_common_start>> vvc->vhost_dev.acked_features = vdev->guest_features;
+     *   - hw/virtio/virtio-hmp-cmds.c|150| <<hmp_virtio_status>> hmp_virtio_dump_features(mon, s->guest_features);
+     *   - hw/virtio/virtio-mmio.c|321| <<virtio_mmio_write>> proxy->guest_features[proxy->guest_features_sel] = value;
+     *   - hw/virtio/virtio-pci.c|495| <<virtio_ioport_read>> ret = vdev->guest_features;
+     *   - hw/virtio/virtio-qmp.c|736| <<qmp_x_query_virtio_status>> status->guest_features = qmp_decode_features(vdev->device_id, vdev->guest_features);
+     *   - hw/virtio/virtio.c|2222| <<virtio_reset>> vdev->guest_features = 0;
+     *   - hw/virtio/virtio.c|2871| <<virtio_save>> uint32_t guest_features_lo = (vdev->guest_features & 0xffffffff);
+     *   - hw/virtio/virtio.c|2959| <<virtio_set_features_nocheck>> vdev->guest_features = val;
+     *   - hw/virtio/virtio.c|3088| <<virtio_load>> vdev->guest_features = features;
+     *   - hw/virtio/virtio.c|3166| <<virtio_load>> uint64_t features64 = vdev->guest_features;
+     *   - include/hw/virtio/virtio.h|437| <<virtio_vdev_has_feature>> return virtio_has_feature(vdev->guest_features, fbit);
+     *
+     * 注释:
+     * These fields represent a set of VirtIO features at various
+     * levels of the stack. @host_features indicates the complete
+     * feature set the VirtIO device can offer to the driver.
+     * @guest_features indicates which features the VirtIO driver has
+     * selected by writing to the feature register. Finally
+     * @backend_features represents everything supported by the
+     * backend (e.g. vhost) and could potentially be a subset of the
+     * total feature set offered by QEMU.
+     */
     uint64_t guest_features;
+    /*
+     * 在以下使用vhost_dev->backend_features:
+     *   - hw/block/vhost-user-blk.c|329| <<vhost_user_blk_connect>> s->dev.backend_features = 0;
+     *   - hw/net/vhost_net.c|136| <<vhost_net_ack_features>> net->dev.acked_features = net->dev.backend_features;
+     *   - hw/net/vhost_net.c|193| <<vhost_net_init>> net->dev.backend_features = qemu_has_vnet_hdr(options->net_backend)
+     *   - hw/net/vhost_net.c|198| <<vhost_net_init>> net->dev.backend_features = 0;
+     *   - hw/net/vhost_net.c|218| <<vhost_net_init>> if (~net->dev.features & net->dev.backend_features) {
+     *   - hw/net/vhost_net.c|221| <<vhost_net_init>> (uint64_t)(~net->dev.features & net->dev.backend_features));
+     *   - hw/scsi/vhost-scsi.c|276| <<vhost_scsi_realize>> vsc->dev.backend_features = 0;
+     *   - hw/scsi/vhost-user-scsi.c|156| <<vhost_user_scsi_connect>> vsc->dev.backend_features = 0;
+     *   - hw/virtio/vdpa-dev.c|107| <<vhost_vdpa_device_realize>> v->dev.backend_features = 0;
+     *   - hw/virtio/vhost-user.c|1437| <<vhost_user_set_features>> ret = vhost_user_set_u64(dev, VHOST_USER_SET_FEATURES,
+     *                     features | dev->backend_features, log_enabled);
+     *   - hw/virtio/vhost-user.c|2164| <<vhost_user_backend_init>> dev->backend_features |= 1ULL << VHOST_USER_F_PROTOCOL_FEATURES;
+     *   - hw/virtio/vhost.c|1979| <<vhost_dev_set_vring_enable>> !virtio_has_feature(hdev->backend_features, VHOST_USER_F_PROTOCOL_FEATURES)) {
+     *   - hw/virtio/virtio-hmp-cmds.c|179| <<hmp_virtio_status>> hmp_virtio_dump_features(mon, s->vhost_dev->backend_features);
+     *   - hw/virtio/virtio-qmp.c|782| <<qmp_x_query_virtio_status>> status->vhost_dev->backend_features = qmp_decode_features(vdev->device_id, hdev->backend_features);
+     *
+     * 在以下使用VirtIODevice->backend_features:
+     *   - hw/net/virtio-net.c|838| <<virtio_net_get_features>> vdev->backend_features = features;
+     *   - hw/net/virtio-net.c|856| <<virtio_net_get_features>> if (!virtio_has_feature(vdev->backend_features, VIRTIO_NET_F_CTRL_VQ)) {
+     *   - hw/net/virtio-net.c|993| <<virtio_net_set_features>> !virtio_has_feature(vdev->backend_features, VIRTIO_NET_F_MTU)) {
+     *   - hw/virtio/virtio-qmp.c|740| <<qmp_x_query_virtio_status>> status->backend_features = qmp_decode_features(vdev->device_id, vdev->backend_features);
+     *   - hw/virtio/virtio-qmp.c|782| <<qmp_x_query_virtio_status>> status->vhost_dev->backend_features = qmp_decode_features(vdev->device_id, hdev->backend_features);
+     *
+     * 注释:
+     * These fields represent a set of VirtIO features at various
+     * levels of the stack. @host_features indicates the complete
+     * feature set the VirtIO device can offer to the driver.
+     * @guest_features indicates which features the VirtIO driver has
+     * selected by writing to the feature register. Finally
+     * @backend_features represents everything supported by the
+     * backend (e.g. vhost) and could potentially be a subset of the
+     * total feature set offered by QEMU.
+     */
     uint64_t backend_features;
 
     size_t config_len;
@@ -193,6 +314,19 @@ struct VirtioDeviceClass {
      * that are only exposed on the legacy interface but not
      * the modern one.
      */
+    /*
+     * 35 #define VIRTIO_LEGACY_FEATURES ((0x1ULL << VIRTIO_F_BAD_FEATURE) | \
+     * 36                                 (0x1ULL << VIRTIO_F_NOTIFY_ON_EMPTY) | \
+     * 37                                 (0x1ULL << VIRTIO_F_ANY_LAYOUT))
+     *
+     * 在以下使用VirtioDeviceClass->legacy_features:
+     *   - hw/audio/virtio-snd.c|1399| <<virtio_snd_class_init>> vdc->legacy_features = 0;
+     *   - hw/net/virtio-net.c|4050| <<virtio_net_class_init>> vdc->legacy_features |= (0x1 << VIRTIO_NET_F_GSO);
+     *   - hw/s390x/virtio-ccw.c|389| <<virtio_ccw_cb>> (vdev->host_features & ~vdc->legacy_features);
+     *   - hw/virtio/virtio-mmio.c|170| <<virtio_mmio_read>> return (vdev->host_features & ~vdc->legacy_features)
+     *   - hw/virtio/virtio-pci.c|1538| <<virtio_pci_common_read>> val = (vdev->host_features & ~vdc->legacy_features) >> (32 * proxy->dfselect);
+     *   - hw/virtio/virtio.c|4068| <<virtio_device_class_init>> vdc->legacy_features |= VIRTIO_LEGACY_FEATURES;
+     */
     uint64_t legacy_features;
     /* Test and clear event pending status.
      * Should be called after unmask to avoid losing events.
@@ -206,6 +340,13 @@ struct VirtioDeviceClass {
      * must mask in frontend instead.
      */
     void (*guest_notifier_mask)(VirtIODevice *vdev, int n, bool mask);
+    /*
+     * 在以下使用VirtioDeviceClass->start_ioeventfd:
+     *   - hw/block/virtio-blk.c|2181| <<virtio_blk_class_init>> vdc->start_ioeventfd = virtio_blk_start_ioeventfd;
+     *   - hw/scsi/virtio-scsi.c|1342| <<virtio_scsi_class_init>> vdc->start_ioeventfd = virtio_scsi_dataplane_start;
+     *   - hw/virtio/virtio-bus.c|236| <<virtio_bus_start_ioeventfd>> r = vdc->start_ioeventfd(vdev);
+     *   - hw/virtio/virtio.c|3965| <<virtio_device_class_init>> vdc->start_ioeventfd = virtio_device_start_ioeventfd_impl;
+     */
     int (*start_ioeventfd)(VirtIODevice *vdev);
     void (*stop_ioeventfd)(VirtIODevice *vdev);
     /* Saving and loading of a device; trying to deprecate save/load
diff --git a/include/qemu/coroutine-tls.h b/include/qemu/coroutine-tls.h
index 1558a826a..53969f07a 100644
--- a/include/qemu/coroutine-tls.h
+++ b/include/qemu/coroutine-tls.h
@@ -150,6 +150,18 @@
  *   my_count = c + 1;
  *   *(&my_count) = 0;
  */
+/*
+ * called by:
+ *   - util/coroutine-ucontext.c|70| <<global>> QEMU_DEFINE_STATIC_CO_TLS(Coroutine *, current);
+ *   - util/coroutine-ucontext.c|71| <<global>> QEMU_DEFINE_STATIC_CO_TLS(CoroutineUContext, leader);
+ *   - util/coroutine-windows.c|37| <<global>> QEMU_DEFINE_STATIC_CO_TLS(CoroutineWin32, leader);
+ *   - util/coroutine-windows.c|38| <<global>> QEMU_DEFINE_STATIC_CO_TLS(Coroutine *, current);
+ *   - util/defer-call.c|40| <<global>> QEMU_DEFINE_STATIC_CO_TLS(DeferCallThreadState, defer_call_thread_state);
+ *   - system/cpus.c|508| <<QEMU_DEFINE_STATIC_CO_TLS>> QEMU_DEFINE_STATIC_CO_TLS(bool, bql_locked)
+ *   - util/async.c|741| <<QEMU_DEFINE_STATIC_CO_TLS>> QEMU_DEFINE_STATIC_CO_TLS(AioContext *, my_aiocontext)
+ *   - util/qemu-coroutine.c|67| <<QSLIST_HEAD>> QEMU_DEFINE_STATIC_CO_TLS(CoroutinePool, local_pool);
+ *   - util/qemu-coroutine.c|68| <<QSLIST_HEAD>> QEMU_DEFINE_STATIC_CO_TLS(Notifier, local_pool_cleanup_notifier);
+ */
 #define QEMU_DEFINE_STATIC_CO_TLS(type, var)                                 \
     static __thread type co_tls_##var;                                       \
     static __attribute__((noinline, unused))                                 \
diff --git a/include/qemu/transactions.h b/include/qemu/transactions.h
index 2f2060acd..f62b6eb62 100644
--- a/include/qemu/transactions.h
+++ b/include/qemu/transactions.h
@@ -54,6 +54,18 @@ void tran_add(Transaction *tran, TransactionActionDrv *drv, void *opaque);
 void tran_abort(Transaction *tran);
 void tran_commit(Transaction *tran);
 
+/*
+ * called by:
+ *   - block.c|2922| <<bdrv_refresh_perms>> tran_finalize(local_tran, ret);
+ *   - block.c|2941| <<bdrv_child_try_set_perm>> tran_finalize(tran, ret);
+ *   - block.c|3359| <<bdrv_attach_child_common>> tran_finalize(aio_ctx_tran, ret_child == true ? 0 : -1);
+ *   - block.c|3483| <<bdrv_root_attach_child>> tran_finalize(tran, ret);
+ *   - block.c|3524| <<bdrv_attach_child>> tran_finalize(tran, ret);
+ *   - block.c|3806| <<bdrv_set_backing_hd_drained>> tran_finalize(tran, ret);
+ *   - block.c|5759| <<bdrv_replace_node_common>> tran_finalize(tran, ret);
+ *   - block.c|5881| <<bdrv_append>> tran_finalize(tran, ret);
+ *   - block.c|5915| <<bdrv_replace_child_bs>> tran_finalize(tran, ret);
+ */
 static inline void tran_finalize(Transaction *tran, int ret)
 {
     if (ret < 0) {
diff --git a/include/standard-headers/linux/virtio_config.h b/include/standard-headers/linux/virtio_config.h
index 45be0fa1b..d752af80f 100644
--- a/include/standard-headers/linux/virtio_config.h
+++ b/include/standard-headers/linux/virtio_config.h
@@ -63,6 +63,42 @@
 #define VIRTIO_F_ANY_LAYOUT		27
 #endif /* VIRTIO_CONFIG_NO_LEGACY */
 
+/*
+ * 在以下使用VIRTIO_F_VERSION_1:
+ *   - hw/block/vhost-user-blk.c|47| <<global>> VIRTIO_F_VERSION_1,
+ *   - hw/net/vhost_net.c|46| <<global>> VIRTIO_F_VERSION_1,
+ *   - hw/net/vhost_net.c|62| <<global>> VIRTIO_F_VERSION_1,
+ *   - hw/virtio/vhost-user-fs.c|29| <<global>> VIRTIO_F_VERSION_1,
+ *   - hw/virtio/vhost-user-scmi.c|25| <<global>> VIRTIO_F_VERSION_1,
+ *   - hw/virtio/vhost-user-vsock.c|20| <<global>> VIRTIO_F_VERSION_1,
+ *   - hw/virtio/virtio-qmp.c|51| <<global>> FEATURE_ENTRY(VIRTIO_F_VERSION_1, \
+ *   - net/vhost-vdpa.c|64| <<global>> VIRTIO_F_VERSION_1,
+ *   - block/export/vhost-user-blk-server.c|130| <<vu_blk_get_features>> 1ull << VIRTIO_F_VERSION_1 |
+ *   - hw/audio/virtio-snd.c|1094| <<virtio_snd_realize>> virtio_add_feature(&vsnd->features, VIRTIO_F_VERSION_1);
+ *   - hw/block/virtio-blk.c|1531| <<virtio_blk_get_features>> if (virtio_has_feature(features, VIRTIO_F_VERSION_1)) {
+ *   - hw/net/virtio-net.c|200| <<virtio_net_set_config>> !virtio_vdev_has_feature(vdev, VIRTIO_F_VERSION_1) &&
+ *   - hw/net/virtio-net.c|1005| <<virtio_net_set_features>> VIRTIO_F_VERSION_1),
+ *   - hw/net/virtio-net.c|3094| <<virtio_net_post_load_device>> VIRTIO_F_VERSION_1),
+ *   - hw/s390x/virtio-ccw.c|1147| <<virtio_ccw_pre_plugged>> virtio_add_feature(&vdev->host_features, VIRTIO_F_VERSION_1);
+ *   - hw/s390x/virtio-ccw.c|1161| <<virtio_ccw_device_plugged>> if (!virtio_has_feature(vdev->host_features, VIRTIO_F_VERSION_1)) {
+ *   - hw/virtio/vhost-shadow-virtqueue.c|41| <<vhost_svq_valid_features>> case VIRTIO_F_VERSION_1:
+ *   - hw/virtio/vhost.c|1088| <<vhost_needs_vring_endian>> if (virtio_vdev_has_feature(vdev, VIRTIO_F_VERSION_1)) {
+ *   - hw/virtio/virtio-iommu.c|1348| <<virtio_iommu_device_realize>> virtio_add_feature(&s->features, VIRTIO_F_VERSION_1);
+ *   - hw/virtio/virtio-mmio.c|741| <<virtio_mmio_pre_plugged>> virtio_add_feature(&vdev->host_features, VIRTIO_F_VERSION_1);
+ *   - hw/virtio/virtio-pci.c|1438| <<virtio_pci_queue_enabled>> if (virtio_vdev_has_feature(vdev, VIRTIO_F_VERSION_1)) {
+ *   - hw/virtio/virtio-pci.c|1983| <<virtio_pci_pre_plugged>> virtio_add_feature(&vdev->host_features, VIRTIO_F_VERSION_1);
+ *   - hw/virtio/virtio-pci.c|2006| <<virtio_pci_device_plugged>> !virtio_has_feature(vdev->host_features, VIRTIO_F_VERSION_1)) {
+ *   - hw/virtio/virtio.c|2102| <<virtio_set_status>> if (virtio_vdev_has_feature(vdev, VIRTIO_F_VERSION_1)) {
+ *   - hw/virtio/virtio.c|2313| <<virtio_queue_set_align>> if (virtio_vdev_has_feature(vdev, VIRTIO_F_VERSION_1)) {
+ *   - hw/virtio/virtio.c|2597| <<virtio_device_endian_needed>> if (!virtio_vdev_has_feature(vdev, VIRTIO_F_VERSION_1)) {
+ *   - hw/virtio/virtio.c|2615| <<virtio_virtqueue_needed>> return virtio_host_has_feature(vdev, VIRTIO_F_VERSION_1);
+ *   - hw/virtio/virtio.c|3025| <<virtio_set_features>> !virtio_vdev_has_feature(vdev, VIRTIO_F_VERSION_1)) {
+ *   - hw/virtio/virtio.c|3183| <<virtio_load>> !virtio_vdev_has_feature(vdev, VIRTIO_F_VERSION_1)) {
+ *   - hw/virtio/virtio.c|3198| <<virtio_load>> if (virtio_vdev_has_feature(vdev, VIRTIO_F_VERSION_1)) {
+ *   - hw/virtio/virtio.c|3786| <<virtio_error>> if (virtio_vdev_has_feature(vdev, VIRTIO_F_VERSION_1)) {
+ *   - include/hw/virtio/virtio-access.h|32| <<virtio_access_is_big_endian>> if (virtio_vdev_has_feature(vdev, VIRTIO_F_VERSION_1)) {
+ *   - include/hw/virtio/virtio.h|448| <<virtio_is_big_endian>> if (!virtio_vdev_has_feature(vdev, VIRTIO_F_VERSION_1)) {
+ */
 /* v1.0 compliant. */
 #define VIRTIO_F_VERSION_1		32
 
diff --git a/include/sysemu/kvm_int.h b/include/sysemu/kvm_int.h
index 882e37e12..495f09599 100644
--- a/include/sysemu/kvm_int.h
+++ b/include/sysemu/kvm_int.h
@@ -95,9 +95,48 @@ struct KVMState
     unsigned int sigmask_len;
     GHashTable *gsimap;
 #ifdef KVM_CAP_IRQ_ROUTING
+    /*
+     * 在以下使用KVMState->irq_routes:
+     *   - accel/kvm/kvm-all.c|1820| <<kvm_init_irq_routing>> s->irq_routes = g_malloc0(sizeof(*s->irq_routes));
+     *   - accel/kvm/kvm-all.c|1854| <<kvm_irqchip_commit_routes>> s->irq_routes->flags = 0;
+     *   - accel/kvm/kvm-all.c|1856| <<kvm_irqchip_commit_routes>> ret = kvm_vm_ioctl(s, KVM_SET_GSI_ROUTING, s->irq_routes);
+     *   - accel/kvm/kvm-all.c|1866| <<kvm_add_routing_entry>> if (s->irq_routes->nr == s->nr_allocated_irq_routes) {
+     *   - accel/kvm/kvm-all.c|1873| <<kvm_add_routing_entry>> s->irq_routes = g_realloc(s->irq_routes, size);
+     *   - accel/kvm/kvm-all.c|1876| <<kvm_add_routing_entry>> n = s->irq_routes->nr++;
+     *   - accel/kvm/kvm-all.c|1877| <<kvm_add_routing_entry>> new = &s->irq_routes->entries[n];
+     *   - accel/kvm/kvm-all.c|1890| <<kvm_update_routing_entry>> for (n = 0; n < s->irq_routes->nr; n++) {
+     *   - accel/kvm/kvm-all.c|1891| <<kvm_update_routing_entry>> entry = &s->irq_routes->entries[n];
+     *   - accel/kvm/kvm-all.c|1931| <<kvm_irqchip_release_virq>> for (i = 0; i < s->irq_routes->nr; i++) {
+     *   - accel/kvm/kvm-all.c|1932| <<kvm_irqchip_release_virq>> e = &s->irq_routes->entries[i];
+     *   - accel/kvm/kvm-all.c|1934| <<kvm_irqchip_release_virq>> s->irq_routes->nr--;
+     *   - accel/kvm/kvm-all.c|1935| <<kvm_irqchip_release_virq>> *e = s->irq_routes->entries[s->irq_routes->nr];
+     *   - accel/kvm/kvm-all.c|2056| <<kvm_irqchip_add_msi_route>> if (s->irq_routes->nr < s->gsi_count) {
+     */
     struct kvm_irq_routing *irq_routes;
+    /*
+     * 在以下使用KVMState->nr_allocated_irq_routes:
+     *   - accel/kvm/kvm-all.c|1821| <<kvm_init_irq_routing>> s->nr_allocated_irq_routes = 0;
+     *   - accel/kvm/kvm-all.c|1866| <<kvm_add_routing_entry>> if (s->irq_routes->nr == s->nr_allocated_irq_routes) {
+     *   - accel/kvm/kvm-all.c|1867| <<kvm_add_routing_entry>> n = s->nr_allocated_irq_routes * 2;
+     *   - accel/kvm/kvm-all.c|1874| <<kvm_add_routing_entry>> s->nr_allocated_irq_routes = n;
+     */
     int nr_allocated_irq_routes;
+    /*
+     * 在以下使用KVMState->used_gsi_bitmap:
+     *   - accel/kvm/kvm-all.c|1801| <<set_gsi>> set_bit(gsi, s->used_gsi_bitmap);
+     *   - accel/kvm/kvm-all.c|1806| <<clear_gsi>> clear_bit(gsi, s->used_gsi_bitmap);
+     *   - accel/kvm/kvm-all.c|1816| <<kvm_init_irq_routing>> s->used_gsi_bitmap = bitmap_new(gsi_count);
+     *   - accel/kvm/kvm-all.c|1963| <<kvm_irqchip_get_virq>> next_virq = find_first_zero_bit(s->used_gsi_bitmap, s->gsi_count);
+     */
     unsigned long *used_gsi_bitmap;
+    /*
+     * 在以下使用KVMState->gsi_count:
+     *   - accel/kvm/kvm-all.c|1817| <<kvm_init_irq_routing>> s->gsi_count = gsi_count;
+     *   - accel/kvm/kvm-all.c|1912| <<kvm_irqchip_add_irq_route>> assert(pin < s->gsi_count);
+     *   - accel/kvm/kvm-all.c|1963| <<kvm_irqchip_get_virq>> next_virq = find_first_zero_bit(s->used_gsi_bitmap, s->gsi_count);
+     *   - accel/kvm/kvm-all.c|1964| <<kvm_irqchip_get_virq>> if (next_virq >= s->gsi_count) {
+     *   - accel/kvm/kvm-all.c|2056| <<kvm_irqchip_add_msi_route>> if (s->irq_routes->nr < s->gsi_count) {
+     */
     unsigned int gsi_count;
 #endif
     KVMMemoryListener memory_listener;
diff --git a/iothread.c b/iothread.c
index e1e9e0473..a2680aaac 100644
--- a/iothread.c
+++ b/iothread.c
@@ -185,6 +185,14 @@ static void iothread_init(EventLoopBase *base, Error **errp)
 
     iothread->stopping = false;
     iothread->running = true;
+    /*
+     * called by:
+     *   - iothread.c|188| <<iothread_init>> iothread->ctx = aio_context_new(errp);
+     *   - tests/unit/iothread.c|51| <<iothread_run>> iothread->ctx = aio_context_new(&error_abort);
+     *   - tests/unit/test-nested-aio-poll.c|78| <<test>> .ctx = aio_context_new(&error_abort),
+     *   - util/main-loop.c|168| <<qemu_init_main_loop>> qemu_aio_context = aio_context_new(errp);
+     *   - util/main-loop.c|622| <<iohandler_init>> iohandler_ctx = aio_context_new(&error_abort);
+     */
     iothread->ctx = aio_context_new(errp);
     if (!iothread->ctx) {
         return;
@@ -336,6 +344,10 @@ char *iothread_get_id(IOThread *iothread)
 
 AioContext *iothread_get_aio_context(IOThread *iothread)
 {
+    /*
+     * IOThread *iothread:
+     * -> AioContext *ctx;
+     */
     return iothread->ctx;
 }
 
@@ -395,6 +407,14 @@ void iothread_destroy(IOThread *iothread)
     object_unparent(OBJECT(iothread));
 }
 
+/*
+ * called by:
+ *   - block/export/export.c|123| <<blk_exp_add>> iothread = iothread_by_id(export->iothread);
+ *   - blockdev.c|3560| <<qmp_x_blockdev_set_iothread>> IOThread *obj = iothread_by_id(iothread->u.s);
+ *   - hw/block/virtio-blk.c|1601| <<validate_iothread_vq_mapping_list>> if (!iothread_by_id(name)) {
+ *   - hw/block/virtio-blk.c|1683| <<apply_iothread_vq_mapping>> IOThread *iothread = iothread_by_id(node->value->iothread);
+ *   - hw/block/virtio-blk.c|1789| <<virtio_blk_vq_aio_context_cleanup>> IOThread *iothread = iothread_by_id(node->value->iothread);
+ */
 /* Lookup IOThread by its id.  Only finds user-created objects, not internal
  * iothread_create() objects. */
 IOThread *iothread_by_id(const char *id)
diff --git a/job.c b/job.c
index 660ce22c5..b34a31b5c 100644
--- a/job.c
+++ b/job.c
@@ -111,6 +111,14 @@ static void __attribute__((__constructor__)) job_init(void)
     qemu_mutex_init(&job_mutex);
 }
 
+/*
+ * called by:
+ *   - blockdev.c|2312| <<qmp_transaction>> block_job_txn = job_txn_new();
+ *   - job.c|442| <<job_create>> txn = job_txn_new();
+ *   - tests/unit/test-blockjob-txn.c|115| <<test_single_job>> txn = job_txn_new();
+ *   - tests/unit/test-blockjob-txn.c|156| <<test_pair_jobs>> txn = job_txn_new();
+ *   - tests/unit/test-blockjob-txn.c|220| <<test_pair_jobs_fail_cancel_race>> txn = job_txn_new();
+ */
 JobTxn *job_txn_new(void)
 {
     JobTxn *txn = g_new0(JobTxn, 1);
@@ -1112,6 +1120,35 @@ static void coroutine_fn job_co_entry(void *opaque)
     aio_bh_schedule_oneshot(qemu_get_aio_context(), job_exit, job);
 }
 
+/*
+ * called by:
+ *   - block/amend.c|151| <<qmp_x_blockdev_amend>> job_start(&s->common);
+ *   - block/commit.c|418| <<commit_start>> job_start(&s->common.job);
+ *   - block/create.c|106| <<qmp_blockdev_create>> job_start(&s->common);
+ *   - block/mirror.c|2082| <<mirror_start_job>> job_start(&s->common.job);
+ *   - block/replication.c|595| <<replication_start>> job_start(&s->backup_job->job);
+ *   - block/stream.c|415| <<stream_start>> job_start(&s->common.job);
+ *   - blockdev.c|1753| <<drive_backup_commit>> job_start(&state->job->job);
+ *   - blockdev.c|1835| <<blockdev_backup_commit>> job_start(&state->job->job);
+ *   - migration/savevm.c|3524| <<qmp_snapshot_save>> job_start(&s->common);
+ *   - migration/savevm.c|3546| <<qmp_snapshot_load>> job_start(&s->common);
+ *   - migration/savevm.c|3566| <<qmp_snapshot_delete>> job_start(&s->common);
+ *   - tests/unit/test-bdrv-drain.c|788| <<test_blockjob_common_drain_node>> job_start(&job->job);
+ *   - tests/unit/test-bdrv-drain.c|1542| <<test_blockjob_commit_by_drained_end>> job_start(&job->common.job);
+ *   - tests/unit/test-bdrv-drain.c|1702| <<test_drop_intermediate_poll>> job_start(&job->common.job);
+ *   - tests/unit/test-block-iothread.c|564| <<test_attach_blockjob>> job_start(&tjob->common.job);
+ *   - tests/unit/test-blockjob-txn.c|117| <<test_single_job>> job_start(&job->job);
+ *   - tests/unit/test-blockjob-txn.c|159| <<test_pair_jobs>> job_start(&job1->job);
+ *   - tests/unit/test-blockjob-txn.c|160| <<test_pair_jobs>> job_start(&job2->job);
+ *   - tests/unit/test-blockjob-txn.c|223| <<test_pair_jobs_fail_cancel_race>> job_start(&job1->job);
+ *   - tests/unit/test-blockjob-txn.c|224| <<test_pair_jobs_fail_cancel_race>> job_start(&job2->job);
+ *   - tests/unit/test-blockjob.c|269| <<test_cancel_running>> job_start(job);
+ *   - tests/unit/test-blockjob.c|282| <<test_cancel_paused>> job_start(job);
+ *   - tests/unit/test-blockjob.c|300| <<test_cancel_ready>> job_start(job);
+ *   - tests/unit/test-blockjob.c|317| <<test_cancel_standby>> job_start(job);
+ *   - tests/unit/test-blockjob.c|339| <<test_cancel_pending>> job_start(job);
+ *   - tests/unit/test-blockjob.c|366| <<test_cancel_concluded>> job_start(job);
+ */
 void job_start(Job *job)
 {
     assert(qemu_in_main_thread());
diff --git a/linux-headers/linux/kvm.h b/linux-headers/linux/kvm.h
index 17839229b..0957effe8 100644
--- a/linux-headers/linux/kvm.h
+++ b/linux-headers/linux/kvm.h
@@ -2011,6 +2011,10 @@ struct kvm_assigned_msix_entry {
 	__u16 padding[3];
 };
 
+/*
+ * 在以下使用KVM_X2APIC_API_USE_32BIT_IDS:
+ *   - target/i386/kvm/kvm.c|209| <<kvm_enable_x2apic>> kvm_x2apic_api_set_flags(KVM_X2APIC_API_USE_32BIT_IDS | KVM_X2APIC_API_DISABLE_BROADCAST_QUIRK),
+ */
 #define KVM_X2APIC_API_USE_32BIT_IDS            (1ULL << 0)
 #define KVM_X2APIC_API_DISABLE_BROADCAST_QUIRK  (1ULL << 1)
 
diff --git a/net/tap-linux.c b/net/tap-linux.c
index c7e514ecb..87d345033 100644
--- a/net/tap-linux.c
+++ b/net/tap-linux.c
@@ -146,6 +146,14 @@ void tap_set_sndbuf(int fd, const NetdevTapOptions *tap, Error **errp)
     }
 }
 
+/*
+ * called by:
+ *   - net/tap.c|675| <<net_init_bridge>> vnet_hdr = tap_probe_vnet_hdr(fd, errp);
+ *   - net/tap.c|892| <<net_init_tap>> vnet_hdr = tap_probe_vnet_hdr(fd, errp);
+ *   - net/tap.c|949| <<net_init_tap>> vnet_hdr = tap_probe_vnet_hdr(fd, errp);
+ *   - net/tap.c|954| <<net_init_tap>> } else if (vnet_hdr != tap_probe_vnet_hdr(fd, NULL)) {
+ *   - net/tap.c|1001| <<net_init_tap>> vnet_hdr = tap_probe_vnet_hdr(fd, errp);
+ */
 int tap_probe_vnet_hdr(int fd, Error **errp)
 {
     struct ifreq ifr;
diff --git a/net/tap.c b/net/tap.c
index baaa2f7a9..d16574445 100644
--- a/net/tap.c
+++ b/net/tap.c
@@ -60,6 +60,25 @@ typedef struct TAPState {
     bool has_uso;
     bool enabled;
     VHostNetState *vhost_net;
+    /*
+     * 在以下设置TAPState->host_vnet_hdr_len:
+     *   - net/tap.c|286| <<tap_set_vnet_hdr_len>> s->host_vnet_hdr_len = len;
+     *   - net/tap.c|425| <<net_tap_fd_init>> s->host_vnet_hdr_len = vnet_hdr ? sizeof(struct virtio_net_hdr) : 0;
+     * 在以下使用TAPState->host_vnet_hdr_len:
+     *   - net/tap.c|124| <<tap_receive_iov>> if (s->host_vnet_hdr_len && !s->using_vnet_hdr) {
+     *   - net/tap.c|127| <<tap_receive_iov>> iov_copy[0].iov_len = s->host_vnet_hdr_len;
+     *   - net/tap.c|143| <<tap_receive_raw>> if (s->host_vnet_hdr_len) {
+     *   - net/tap.c|145| <<tap_receive_raw>> iov[iovcnt].iov_len = s->host_vnet_hdr_len;
+     *   - net/tap.c|161| <<tap_receive>> if (s->host_vnet_hdr_len && !s->using_vnet_hdr) {
+     *   - net/tap.c|200| <<tap_send>> if (s->host_vnet_hdr_len && !s->using_vnet_hdr) {
+     *   - net/tap.c|201| <<tap_send>> buf += s->host_vnet_hdr_len;
+     *   - net/tap.c|202| <<tap_send>> size -= s->host_vnet_hdr_len;
+     *   - net/tap.c|257| <<tap_has_vnet_hdr>> return !!s->host_vnet_hdr_len;
+     *   - net/tap.c|273| <<tap_get_vnet_hdr_len>> return s->host_vnet_hdr_len;
+     *   - net/tap.c|301| <<tap_using_vnet_hdr>> assert(!!s->host_vnet_hdr_len == using_vnet_hdr);
+     *   - net/tap.c|435| <<net_tap_fd_init>> if (tap_probe_vnet_hdr_len(s->fd, s->host_vnet_hdr_len)) {
+     *   - net/tap.c|436| <<net_tap_fd_init>> tap_fd_set_vnet_hdr_len(s->fd, s->host_vnet_hdr_len);
+     */
     unsigned host_vnet_hdr_len;
     Notifier exit;
 } TAPState;
@@ -181,6 +200,18 @@ static void tap_send_completed(NetClientState *nc, ssize_t len)
     tap_read_poll(s, true);
 }
 
+/*
+ * 在以下使用tap_send():
+ *   - net/tap.c|95| <<tap_update_fd_handler>> s->read_poll && s->enabled ? tap_send : NULL,
+ *
+ * 92 static void tap_update_fd_handler(TAPState *s)
+ * 93 {                         
+ * 94     qemu_set_fd_handler(s->fd,
+ * 95                         s->read_poll && s->enabled ? tap_send : NULL,
+ * 96                         s->write_poll && s->enabled ? tap_writable : NULL,
+ * 97                         s);
+ * 98 }
+ */
 static void tap_send(void *opaque)
 {
     TAPState *s = opaque;
@@ -408,6 +439,11 @@ static NetClientInfo net_tap_info = {
     .set_steering_ebpf = tap_set_steering_ebpf,
 };
 
+/*
+ * called by;
+ *   - net/tap.c|675| <<net_init_bridge>> s = net_tap_fd_init(peer, "bridge", name, fd, vnet_hdr);
+ *   - net/tap.c|726| <<net_init_tap_one>> TAPState *s = net_tap_fd_init(peer, model, name, fd, vnet_hdr);
+ */
 static TAPState *net_tap_fd_init(NetClientState *peer,
                                  const char *model,
                                  const char *name,
@@ -697,6 +733,13 @@ static int net_tap_init(const NetdevTapOptions *tap, int *vnet_hdr,
 
 #define MAX_TAP_QUEUES 1024
 
+/*
+ * called by:
+ *   - net/tap.c|886| <<net_init_tap>> net_init_tap_one(tap, peer, "tap", name, NULL, script, downscript, vhostfdname, vnet_hdr, fd, &err);
+ *   - net/tap.c|949| <<net_init_tap>> net_init_tap_one(tap, peer, "tap", name, ifname, script, downscript, tap->vhostfds ? vhost_fds[i] : NULL, vnet_hdr, fd, &err);
+ *   - net/tap.c|995| <<net_init_tap>> net_init_tap_one(tap, peer, "bridge", name, ifname, script, downscript, vhostfdname, vnet_hdr, fd, &err);
+ *   - net/tap.c|1040| <<net_init_tap>> net_init_tap_one(tap, peer, "tap", name, ifname, i >= 1 ? "no" : script, i >= 1 ? "no" : downscript, vhostfdname, vnet_hdr, fd, &err);
+ */
 static void net_init_tap_one(const NetdevTapOptions *tap, NetClientState *peer,
                              const char *model, const char *name,
                              const char *ifname, const char *script,
diff --git a/scsi/utils.c b/scsi/utils.c
index 357b03667..6e80459fe 100644
--- a/scsi/utils.c
+++ b/scsi/utils.c
@@ -454,6 +454,12 @@ bool scsi_sense_buf_is_guest_recoverable(const uint8_t *in_buf, size_t in_len)
     return scsi_sense_is_guest_recoverable(sense.key, sense.asc, sense.ascq);
 }
 
+/*
+ * called by:
+ *   - hw/scsi/scsi-bus.c|1527| <<scsi_req_print>> scsi_command_name(req->cmd.buf[0]));
+ *   - hw/scsi/scsi-disk.c|2234| <<scsi_disk_emulate_command>> scsi_command_name(buf[0]));
+ *   - hw/scsi/spapr_vscsi.c|809| <<vscsi_queue_cmd>> scsi_command_name(srp->cmd.cdb[0]), lun, n);
+ */
 const char *scsi_command_name(uint8_t cmd)
 {
     static const char *names[] = {
diff --git a/system/cpus.c b/system/cpus.c
index 68d161d96..c3ed8ede1 100644
--- a/system/cpus.c
+++ b/system/cpus.c
@@ -357,6 +357,10 @@ static void sigbus_reraise(void)
     abort();
 }
 
+/*
+ * 在以下使用sigbug_handler():
+ *   - system/cpus.c|389| <<qemu_init_sigbus>> action.sa_sigaction = sigbus_handler;
+ */
 static void sigbus_handler(int n, siginfo_t *siginfo, void *ctx)
 {
     if (siginfo->si_code != BUS_MCEERR_AO && siginfo->si_code != BUS_MCEERR_AR) {
diff --git a/system/memory.c b/system/memory.c
index a229a7998..3f4965fd6 100644
--- a/system/memory.c
+++ b/system/memory.c
@@ -39,6 +39,14 @@
 
 static unsigned memory_region_transaction_depth;
 static bool memory_region_update_pending;
+/*
+ * 在以下使用ioeventfd_update_pending():
+ *   - system/memory.c|1140| <<memory_region_transaction_commit>> ioeventfd_update_pending = false;
+ *   - system/memory.c|1142| <<memory_region_transaction_commit>> } else if (ioeventfd_update_pending) {
+ *   - system/memory.c|1146| <<memory_region_transaction_commit>> ioeventfd_update_pending = false;
+ *   - system/memory.c|2606| <<memory_region_add_eventfd>> ioeventfd_update_pending |= mr->enabled;
+ *   - system/memory.c|2641| <<memory_region_del_eventfd>> ioeventfd_update_pending |= mr->enabled;
+ */
 static bool ioeventfd_update_pending;
 unsigned int global_dirty_tracking;
 
@@ -776,6 +784,10 @@ static FlatView *generate_memory_topology(MemoryRegion *mr)
     return view;
 }
 
+/*
+ * called by:
+ *   - system/memory.c|883| <<address_space_update_ioeventfds>> address_space_add_del_ioeventfds(as, ioeventfds, ioeventfd_nb, as->ioeventfds, as->ioeventfd_nb);
+ */
 static void address_space_add_del_ioeventfds(AddressSpace *as,
                                              MemoryRegionIoeventfd *fds_new,
                                              unsigned fds_new_nb,
@@ -2556,6 +2568,18 @@ void memory_region_clear_flush_coalesced(MemoryRegion *mr)
     }
 }
 
+/*
+ * called by:
+ *   - hw/misc/ivshmem.c|365| <<ivshmem_add_eventfd>> memory_region_add_eventfd(&s->ivshmem_mmio, DOORBELL, 4, true, (posn << 16) | i, &s->peers[posn].eventfds[i]);
+ *   - hw/misc/pci-testdev.c|113| <<pci_testdev_start>> memory_region_add_eventfd(test->mr, le32_to_cpu(test->hdr->offset), test->size, test->match_data, test->hdr->data, &test->notifier);
+ *   - hw/nvme/ctrl.c|4523| <<nvme_init_cq_ioeventfd>> memory_region_add_eventfd(&n->iomem, 0x1000 + offset, 4, false, 0, &cq->notifier);
+ *   - hw/nvme/ctrl.c|4552| <<nvme_init_sq_ioeventfd>> memory_region_add_eventfd(&n->iomem, 0x1000 + offset, 4, false, 0, &sq->notifier);
+ *   - hw/vfio/pci-quirks.c|401| <<vfio_ioeventfd_init>> memory_region_add_eventfd(ioeventfd->mr, ioeventfd->addr, ioeventfd->size, true, ioeventfd->data, &ioeventfd->e);
+ *   - hw/virtio/virtio-mmio.c|52| <<virtio_mmio_ioeventfd_assign>> memory_region_add_eventfd(&proxy->iomem, VIRTIO_MMIO_QUEUE_NOTIFY, 4, true, n, notifier);
+ *   - hw/virtio/virtio-pci.c|345| <<virtio_pci_ioeventfd_assign>> memory_region_add_eventfd(modern_mr, modern_addr, 0, false, n, notifier);
+ *   - hw/virtio/virtio-pci.c|348| <<virtio_pci_ioeventfd_assign>> memory_region_add_eventfd(modern_notify_mr, 0, 2, true, n, notifier);
+ *   - hw/virtio/virtio-pci.c|353| <<virtio_pci_ioeventfd_assign>> memory_region_add_eventfd(legacy_mr, legacy_addr, 2, true, n, notifier);
+ */
 void memory_region_add_eventfd(MemoryRegion *mr,
                                hwaddr addr,
                                unsigned size,
@@ -2581,6 +2605,11 @@ void memory_region_add_eventfd(MemoryRegion *mr,
             break;
         }
     }
+    /*
+     * MemoryRegion *mr:
+     * -> unsigned ioeventfd_nb;
+     * -> MemoryRegionIoeventfd *ioeventfds;
+     */
     ++mr->ioeventfd_nb;
     mr->ioeventfds = g_realloc(mr->ioeventfds,
                                   sizeof(*mr->ioeventfds) * mr->ioeventfd_nb);
diff --git a/system/qdev-monitor.c b/system/qdev-monitor.c
index 840177d19..cd2de2274 100644
--- a/system/qdev-monitor.c
+++ b/system/qdev-monitor.c
@@ -728,6 +728,12 @@ err_del_dev:
     return NULL;
 }
 
+/*
+ * called by:
+ *   - hw/usb/xen-usb.c|769| <<usbback_portid_add>> usbif->ports[port - 1].dev = USB_DEVICE(qdev_device_add(opts, &local_err));
+ *   - system/qdev-monitor.c|862| <<qmp_device_add>> dev = qdev_device_add(opts, errp);
+ *   - system/vl.c|1200| <<device_init_func>> dev = qdev_device_add(opts, errp);
+ */
 /* Takes ownership of @opts on success */
 DeviceState *qdev_device_add(QemuOpts *opts, Error **errp)
 {
diff --git a/system/vl.c b/system/vl.c
index c64422298..398e3f2fc 100644
--- a/system/vl.c
+++ b/system/vl.c
@@ -656,6 +656,12 @@ static int drive_enable_snapshot(void *opaque, QemuOpts *opts, Error **errp)
     return 0;
 }
 
+/*
+ * called by:
+ *   - system/vl.c|713| <<configure_blockdev>> default_drive(default_cdrom, snapshot, machine_class->block_default_type, 2, CDROM_OPTS);
+ *   - system/vl.c|715| <<configure_blockdev>> default_drive(default_floppy, snapshot, IF_FLOPPY, 0, FD_OPTS);
+ *   - system/vl.c|716| <<configure_blockdev>> default_drive(default_sdcard, snapshot, IF_SD, 0, SD_OPTS);
+ */
 static void default_drive(int enable, int snapshot, BlockInterfaceType type,
                           int index, const char *optstr)
 {
@@ -1193,6 +1199,10 @@ static int device_help_func(void *opaque, QemuOpts *opts, Error **errp)
     return qdev_device_help(opts);
 }
 
+/*
+ * called by:
+ *   - system/vl.c|2638| <<qemu_create_cli_devices>> device_init_func, NULL, &error_fatal);
+ */
 static int device_init_func(void *opaque, QemuOpts *opts, Error **errp)
 {
     DeviceState *dev;
diff --git a/target/arm/kvm.c b/target/arm/kvm.c
index ab85d628a..0db43fe9d 100644
--- a/target/arm/kvm.c
+++ b/target/arm/kvm.c
@@ -2356,6 +2356,11 @@ int kvm_arch_get_registers(CPUState *cs)
     return ret;
 }
 
+/*
+ * called by:
+ *   - accel/kvm/kvm-all.c|2876| <<kvm_cpu_exec>> kvm_arch_on_sigbus_vcpu(cpu, pending_sigbus_code, pending_sigbus_addr);
+ *   - accel/kvm/kvm-all.c|3399| <<kvm_on_sigbus>> kvm_arch_on_sigbus_vcpu(first_cpu, code, addr);
+ */
 void kvm_arch_on_sigbus_vcpu(CPUState *c, int code, void *addr)
 {
     ram_addr_t ram_addr;
diff --git a/target/arm/tcg/tlb_helper.c b/target/arm/tcg/tlb_helper.c
index 885bf4ec1..075c58a35 100644
--- a/target/arm/tcg/tlb_helper.c
+++ b/target/arm/tcg/tlb_helper.c
@@ -116,6 +116,10 @@ static uint32_t compute_fsr_fsc(CPUARMState *env, ARMMMUFaultInfo *fi,
     return fsr;
 }
 
+/*
+ * called by:
+ *   - target/arm/tcg/tlb_helper.c|195| <<arm_deliver_fault>> if (report_as_gpc_exception(cpu, current_el, fi)) {
+ */
 static bool report_as_gpc_exception(ARMCPU *cpu, int current_el,
                                     ARMMMUFaultInfo *fi)
 {
@@ -167,6 +171,13 @@ static unsigned encode_gpcsc(ARMMMUFaultInfo *fi)
     return gpcsc[fi->gpcf] | fi->level;
 }
 
+/*
+ * called by:
+ *   - target/arm/tcg/tlb_helper.c|277| <<arm_cpu_do_unaligned_access>> arm_deliver_fault(cpu, vaddr, access_type, mmu_idx, &fi);
+ *   - target/arm/tcg/tlb_helper.c|318| <<arm_cpu_do_transaction_failed>> arm_deliver_fault(cpu, addr, access_type, mmu_idx, &fi);
+ *   - target/arm/tcg/tlb_helper.c|371| <<arm_cpu_tlb_fill>> arm_deliver_fault(cpu, address, access_type, mmu_idx, fi);
+ *   - target/arm/tcg/tlb_helper.c|390| <<arm_cpu_record_sigsegv>> arm_deliver_fault(cpu, addr, access_type, MMU_USER_IDX, &fi);
+ */
 static G_NORETURN
 void arm_deliver_fault(ARMCPU *cpu, vaddr addr,
                        MMUAccessType access_type,
@@ -262,6 +273,16 @@ void arm_deliver_fault(ARMCPU *cpu, vaddr addr,
     raise_exception(env, exc, syn, target_el);
 }
 
+/*
+ * 在以下使用arm_cpu_do_unaligned_access():
+ *   - target/arm/cpu.c|2491| <<global>> TCGCPUOps arm_tcg_ops.do_unaligned_access = arm_cpu_do_unaligned_access,
+ *   - target/arm/tcg/cpu-v7m.c|249| <<global>> TCGCPUOps arm_v7m_tcg_ops.do_unaligned_access = arm_cpu_do_unaligned_access,
+ *   - target/arm/tcg/helper-a64.c|968| <<HELPER(unaligned_access)>> arm_cpu_do_unaligned_access(env_cpu(env), addr, access_type,
+ *   - target/arm/tcg/helper-a64.c|1203| <<check_setg_alignment>> arm_cpu_do_unaligned_access(env_cpu(env), ptr, MMU_DATA_STORE,
+ *   - target/arm/tcg/mte_helper.c|313| <<check_tag_aligned>> arm_cpu_do_unaligned_access(env_cpu(env), ptr, MMU_DATA_STORE,
+ *   - target/arm/tcg/mte_helper.c|917| <<HELPER(mte_check)>> arm_cpu_do_unaligned_access(env_cpu(env), ptr, type, idx, GETPC());
+ *   - target/arm/tcg/tlb_helper.c|396| <<arm_cpu_record_sigbus>> arm_cpu_do_unaligned_access(cs, addr, access_type, MMU_USER_IDX, ra);
+ */
 /* Raise a data fault alignment exception for the specified virtual address */
 void arm_cpu_do_unaligned_access(CPUState *cs, vaddr vaddr,
                                  MMUAccessType access_type,
diff --git a/target/i386/cpu.c b/target/i386/cpu.c
index 33760a2ee..4c8aba95f 100644
--- a/target/i386/cpu.c
+++ b/target/i386/cpu.c
@@ -1691,6 +1691,32 @@ static uint64_t x86_cpu_get_migratable_flags(FeatureWord w)
     return r;
 }
 
+/*
+ * called by:
+ *   - hw/i386/sgx.c|96| <<sgx_calc_host_epc_sections>> host_cpuid(0x12, i + 2, &eax, &ebx, &ecx, &edx);
+ *   - hw/i386/sgx.c|168| <<qmp_query_sgx_capabilities>> host_cpuid(0x7, 0, &eax, &ebx, &ecx, &edx);
+ *   - hw/i386/sgx.c|173| <<qmp_query_sgx_capabilities>> host_cpuid(0x12, 0, &eax, &ebx, &ecx, &edx);
+ *   - target/i386/cpu.c|5767| <<x86_cpu_get_cache_cpuid>> host_cpuid(0, 0, &level, &unused, &unused, &unused);
+ *   - target/i386/cpu.c|5772| <<x86_cpu_get_cache_cpuid>> host_cpuid(0x80000000, 0, &level, &unused, &unused, &unused);
+ *   - target/i386/cpu.c|5784| <<x86_cpu_get_cache_cpuid>> host_cpuid(func, index, eax, ebx, ecx, edx);
+ *   - target/i386/cpu.c|6368| <<cpu_x86_cpuid>> host_cpuid(index, 2, eax, ebx, ecx, edx);
+ *   - target/i386/host-cpu.c|23| <<host_cpu_phys_bits>> host_cpuid(0x80000000, 0, &eax, NULL, NULL, NULL);
+ *   - target/i386/host-cpu.c|25| <<host_cpu_phys_bits>> host_cpuid(0x80000008, 0, &eax, NULL, NULL, NULL);
+ *   - target/i386/host-cpu.c|49| <<host_cpu_enable_cpu_pm>> host_cpuid(5, 0, &cpu->mwait.eax, &cpu->mwait.ebx,
+ *   - target/i386/host-cpu.c|124| <<host_cpu_fill_model_id>> host_cpuid(0x80000002 + i, 0, &eax, &ebx, &ecx, &edx);
+ *   - target/i386/host-cpu.c|137| <<host_cpu_vendor_fms>> host_cpuid(0x0, 0, &eax, &ebx, &ecx, &edx);
+ *   - target/i386/host-cpu.c|140| <<host_cpu_vendor_fms>> host_cpuid(0x1, 0, &eax, &ebx, &ecx, &edx);
+ *   - target/i386/host-cpu.c|160| <<host_cpu_instance_init>> host_cpuid(0, 0, NULL, &ebx, &ecx, &edx);
+ *   - target/i386/hvf/x86_cpuid.c|54| <<hvf_get_supported_cpuid>> host_cpuid(func, idx, &eax, &ebx, &ecx, &edx);
+ *   - target/i386/kvm/kvm-cpu.c|110| <<kvm_cpu_xsave_init>> host_cpuid(0xd, i, &eax, &ebx, &ecx, &edx);
+ *   - target/i386/kvm/kvm.c|414| <<kvm_arch_get_supported_cpuid>> host_cpuid(7, 0, &unused, &ebx, &unused, &unused);
+ *   - target/i386/kvm/kvm.c|423| <<kvm_arch_get_supported_cpuid>> host_cpuid(7, 0, &unused, &unused, &unused, &edx);
+ *   - target/i386/kvm/kvm.c|437| <<kvm_arch_get_supported_cpuid>> host_cpuid(7, 1, &eax, &unused, &unused, &unused);
+ *   - target/i386/kvm/kvm.c|441| <<kvm_arch_get_supported_cpuid>> host_cpuid(7, 2, &unused, &unused, &unused, &edx);
+ *   - target/i386/kvm/kvm.c|5271| <<host_supports_vmx>> host_cpuid(1, 0, &unused, &unused, &ecx, &unused);
+ *   - target/i386/sev.c|607| <<sev_get_capabilities>> host_cpuid(0x8000001F, 0, NULL, &ebx, NULL, NULL);
+ *   - target/i386/sev.c|932| <<sev_kvm_init>> host_cpuid(0x8000001F, 0, NULL, &ebx, NULL, NULL);
+ */
 void host_cpuid(uint32_t function, uint32_t count,
                 uint32_t *eax, uint32_t *ebx, uint32_t *ecx, uint32_t *edx)
 {
@@ -5754,6 +5780,14 @@ static void x86_cpu_get_supported_cpuid(uint32_t func, uint32_t index,
     }
 }
 
+/*
+ * called by:
+ *   - target/i386/cpu.c|6072| <<cpu_x86_cpuid>> x86_cpu_get_cache_cpuid(index, 0, eax, ebx, ecx, edx);
+ *   - target/i386/cpu.c|6092| <<cpu_x86_cpuid>> x86_cpu_get_cache_cpuid(index, count, eax, ebx, ecx, edx);
+ *   - target/i386/cpu.c|6532| <<cpu_x86_cpuid>> x86_cpu_get_cache_cpuid(index, 0, eax, ebx, ecx, edx);
+ *   - target/i386/cpu.c|6545| <<cpu_x86_cpuid>> x86_cpu_get_cache_cpuid(index, 0, eax, ebx, ecx, edx);
+ *   - target/i386/cpu.c|6605| <<cpu_x86_cpuid>> x86_cpu_get_cache_cpuid(index, count, eax, ebx, ecx, edx);
+ */
 static void x86_cpu_get_cache_cpuid(uint32_t func, uint32_t index,
                                     uint32_t *eax, uint32_t *ebx,
                                     uint32_t *ecx, uint32_t *edx)
diff --git a/target/i386/host-cpu.c b/target/i386/host-cpu.c
index 92ecb7254..7b4c04bc6 100644
--- a/target/i386/host-cpu.c
+++ b/target/i386/host-cpu.c
@@ -130,6 +130,11 @@ static int host_cpu_fill_model_id(char *str)
     return 0;
 }
 
+/*
+ * called by:
+ *   - target/i386/host-cpu.c|175| <<host_cpu_max_instance_init>> host_cpu_vendor_fms(vendor, &family, &model, &stepping);
+ *   - target/i386/kvm/kvm.c|310| <<host_tsx_broken>> host_cpu_vendor_fms(vendor, &family, &model, &stepping);
+ */
 void host_cpu_vendor_fms(char *vendor, int *family, int *model, int *stepping)
 {
     uint32_t eax, ebx, ecx, edx;
@@ -149,6 +154,11 @@ void host_cpu_vendor_fms(char *vendor, int *family, int *model, int *stepping)
     }
 }
 
+/*
+ * called by:
+ *   - target/i386/hvf/hvf-cpu.c|65| <<hvf_cpu_instance_init>> host_cpu_instance_init(cpu);
+ *   - target/i386/kvm/kvm-cpu.c|169| <<kvm_cpu_instance_init>> host_cpu_instance_init(cpu);
+ */
 void host_cpu_instance_init(X86CPU *cpu)
 {
     X86CPUClass *xcc = X86_CPU_GET_CLASS(cpu);
diff --git a/target/i386/kvm/kvm.c b/target/i386/kvm/kvm.c
index e68cbe929..83d069c0f 100644
--- a/target/i386/kvm/kvm.c
+++ b/target/i386/kvm/kvm.c
@@ -87,6 +87,11 @@
 
 static void kvm_init_msrs(X86CPU *cpu);
 
+/*
+ * 在以下使用kvm_arch_required_capabilities[]:
+ *   - include/sysemu/kvm.h|318| <<global>> extern const KVMCapabilityInfo kvm_arch_required_capabilities[];
+ *   - accel/kvm/kvm-all.c|2598| <<kvm_init>> kvm_check_extension_list(s, kvm_arch_required_capabilities);
+ */
 const KVMCapabilityInfo kvm_arch_required_capabilities[] = {
     KVM_CAP_INFO(SET_TSS_ADDR),
     KVM_CAP_INFO(EXT_CPUID),
@@ -139,8 +144,145 @@ static bool has_msr_vmx_procbased_ctls2;
 static bool has_msr_perf_capabs;
 static bool has_msr_pkrs;
 
+/*
+ * 添加AMD PerfMonV2的虚拟化.
+ *
+ * 主要支持下面3个global寄存器.
+ *
+ * - MSR_AMD64_PERF_CNTR_GLOBAL_STATUS
+ * - MSR_AMD64_PERF_CNTR_GLOBAL_CTL
+ * - MSR_AMD64_PERF_CNTR_GLOBAL_STATUS_CLR
+ *
+ * 此外, 还支持4/6之外的gp寄存器数目.
+ *
+ * 1. 查看cpuid是否支持X86_FEATURE_PERFMON_V2.
+ *    如果支持, 根据0x80000022获取寄存器的数目.
+ *    此外, 3个global的也支持!
+ *    寄存器的base address和MSR_F15H_PERF_CTR5的一样(KVM svm其实限制了最多6个)
+ *
+ * 2. 如果不是ver=2, 如果支持X86_FEATURE_PERFCTR_CORE,
+ *    就是6个寄存器
+ *
+ * 3. 默认只支持4个
+ */
+/*
+ * CPUID.0AH是Intel PMU的version ID. SDM一共有5个version.
+ *
+ * version 1:
+ *
+ * IA32_PMCx MSRs 从 0x0c1开始
+ * IA32_PERFEVTSELx MSRs 从0x186开始
+ *
+ * 当IA_PERF_CAPABILITIES.FW_WRITE[bit 13] == 1的时候:
+ * IA32_PMCx从0x4c1开始
+ *
+ * --------------------
+ *
+ * version 2:
+ *
+ * 增加了3个fixed counter.
+ *
+ * IA32_FIXED_CTR0  在 0x309
+ * IA32_FIXED_CTR1  在 0x30a
+ * IA32_FIXED_CTR2  在 0x30b
+ *
+ * 这3个对应的只要一个selector来控制就好了
+ *
+ * IA32_FIXED_CTR_CTRL在0x38d
+ *
+ * 还有下面三个寄存器.
+ *
+ * IA32_PERF_GLOBAL_CTRL     : 控制fixed和gp的enable/disable
+ * IA32_PERF_GLOBAL_STATUS   : 负责query fixed和gp的overflow conditions
+ * IA32_PERF_GLOBAL_OVF_CTRL : 负责clear fixed和gp的overflow status
+ *
+ * --------------------
+ *
+ * version 3:
+ *
+ * 主要增加了AnyThread的feature.
+ * 在IA32_PERFEVTSELx和IA32_FIXED_CTR_CTRL增加了对应的bit,可以:
+ *
+ * enables counting the associated event conditions occurring across all logical
+ * processors sharing a processor core.
+ *
+ * --------------------
+ *
+ * version 4:
+ *
+ * 之前使用IA32_PERF_GLOBAL_OVF_CTRL来控制overflow status的clear.
+ * 现在又有了IA32_PERF_GLOBAL_STATUS_RESET, 功能更多.
+ *
+ * 还增加了IA32_PERF_GLOBAL_STATUS_SET. 这下, 可修改IA32_PERF_GLOBAL_STATUS了.
+ *
+ * 此外, The IA32_PERF_GLOBAL_INUSE MSR provides an "InUse" bit for each
+ * programmable performance counter and fixed counter in the processor.
+ * Additionally, it includes an indicator if the PMI mechanism has been configured
+ * by a profiling agent.
+ *
+ * --------------------
+ *
+ * version 5:
+ *
+ * 没太多东西.
+ *
+ * --------------------
+ *
+ * 820         if (rdmsr(MSR_IA32_PERF_CAPABILITIES) & PMU_CAP_FW_WRITES) {
+ * 821                 gp_counter_base = MSR_IA32_PMC0;
+ * 822                 report_prefix_push("full-width writes");
+ * 823                 check_counters();
+ * 824                 check_gp_counters_write_width();
+ * 825         }
+ */
+
+/*
+ * 1. 如果guest_vendor和host_vendor不一样, 不支持PMU.
+ * has_architectural_pmu_version = 0.
+ * num_architectural_pmu_gp_counters = 0.
+ * num_architectural_pmu_fixed_counters = 0.
+ *
+ * 2. 如果guest_vendor是Intel
+ * 完全按照cpuid来算
+ *
+ * 3. 如果guest_vendor是AMD
+ * 3.1. 查看cpuid是否支持X86_FEATURE_PERFMON_V2.
+ *      如果支持, 根据0x80000022获取寄存器的数目.
+ *      此外, 3个global的也支持!
+ *      寄存器的base address和MSR_F15H_PERF_CTR5的一样(KVM svm其实限制了最多6个)
+ * 3.2. 如果不是ver=2, 如果支持X86_FEATURE_PERFCTR_CORE,
+ *      就是6个寄存器
+ * 3.3. 默认只支持4个
+ */
+/*
+ * 在以下使用has_architectural_pmu_version:
+ *   - target/i386/kvm/kvm.c|2031| <<kvm_arch_init_vcpu>> has_architectural_pmu_version = eax & 0xff;
+ *   - target/i386/kvm/kvm.c|2032| <<kvm_arch_init_vcpu>> if (has_architectural_pmu_version > 0) {
+ *   - target/i386/kvm/kvm.c|2043| <<kvm_arch_init_vcpu>> if (has_architectural_pmu_version > 1) {
+ *   - target/i386/kvm/kvm.c|3349| <<kvm_put_msrs>> if (has_architectural_pmu_version > 0) {
+ *   - target/i386/kvm/kvm.c|3350| <<kvm_put_msrs>> if (has_architectural_pmu_version > 1) {
+ *   - target/i386/kvm/kvm.c|3367| <<kvm_put_msrs>> if (has_architectural_pmu_version > 1) {
+ *   - target/i386/kvm/kvm.c|3812| <<kvm_get_msrs>> if (has_architectural_pmu_version > 0) {
+ *   - target/i386/kvm/kvm.c|3813| <<kvm_get_msrs>> if (has_architectural_pmu_version > 1) {
+ */
 static uint32_t has_architectural_pmu_version;
+/*
+ * 在以下使用num_architectural_pmu_gp_counters:
+ *   - target/i386/kvm/kvm.c|2033| <<kvm_arch_init_vcpu>> num_architectural_pmu_gp_counters = (eax & 0xff00) >> 8;
+ *   - target/i386/kvm/kvm.c|2039| <<kvm_arch_init_vcpu>> if (num_architectural_pmu_gp_counters > MAX_GP_COUNTERS) {
+ *   - target/i386/kvm/kvm.c|2040| <<kvm_arch_init_vcpu>> num_architectural_pmu_gp_counters = MAX_GP_COUNTERS;
+ *   - target/i386/kvm/kvm.c|3361| <<kvm_put_msrs>> for (i = 0; i < num_architectural_pmu_gp_counters; i++) {
+ *   - target/i386/kvm/kvm.c|3822| <<kvm_get_msrs>> for (i = 0; i < num_architectural_pmu_gp_counters; i++) {
+ */
 static uint32_t num_architectural_pmu_gp_counters;
+/*
+ * 在以下使用num_architectural_pmu_fixed_counters:
+ *   - target/i386/kvm/kvm.c|2044| <<kvm_arch_init_vcpu>> num_architectural_pmu_fixed_counters = edx & 0x1f;
+ *   - target/i386/kvm/kvm.c|2046| <<kvm_arch_init_vcpu>> if (num_architectural_pmu_fixed_counters > MAX_FIXED_COUNTERS) {
+ *   - target/i386/kvm/kvm.c|2047| <<kvm_arch_init_vcpu>> num_architectural_pmu_fixed_counters = MAX_FIXED_COUNTERS;
+ *   - target/i386/kvm/kvm.c|3357| <<kvm_put_msrs>> for (i = 0; i < num_architectural_pmu_fixed_counters; i++) {
+ *   - target/i386/kvm/kvm.c|3819| <<kvm_get_msrs>> for (i = 0; i < num_architectural_pmu_fixed_counters; i++) {
+ */
 static uint32_t num_architectural_pmu_fixed_counters;
 
 static int has_xsave2;
@@ -203,6 +345,11 @@ bool kvm_has_x2apic_api(void)
     return has_x2apic_api;
 }
 
+/*
+ * called by:
+ *   - hw/i386/intel_iommu.c|4127| <<vtd_decide_config>> if (kvm_irqchip_is_split() && !kvm_enable_x2apic()) {
+ *   - hw/i386/x86.c|140| <<x86_cpus_init>> if (kvm_enabled() && x86ms->apic_id_limit > 255 && kvm_irqchip_in_kernel() && !kvm_enable_x2apic()) {
+ */
 bool kvm_enable_x2apic(void)
 {
     return MEMORIZE(
@@ -1706,6 +1853,14 @@ static void kvm_init_nested_state(CPUX86State *env)
     }
 }
 
+/*
+ * called by:
+ *   - accel/kvm/kvm-all.c|440| <<kvm_init_vcpu>> ret = kvm_arch_init_vcpu(cpu);
+ *
+ * 例子:
+ * CPUState *cpu = first_cpu;
+ * CPUX86State *env = cpu_env(cpu);
+ */
 int kvm_arch_init_vcpu(CPUState *cs)
 {
     struct {
@@ -2018,13 +2173,82 @@ int kvm_arch_init_vcpu(CPUState *cs)
         }
     }
 
+    /*
+     * 这个命令在amd上都是0
+     * # cpuid -1 -l 0xa
+     * CPU:
+     *    Architecture Performance Monitoring Features (0xa):
+     *       version ID                               = 0x3 (3)
+     *       number of counters per logical processor = 0x4 (4)
+     *       bit width of counter                     = 0x30 (48)
+     *       length of EBX bit vector                 = 0x7 (7)
+     *       core cycle event                         = available
+     *       instruction retired event                = available
+     *       reference cycles event                   = available
+     *       last-level cache ref event               = available
+     *       last-level cache miss event              = available
+     *       branch inst retired event                = available
+     *       branch mispred retired event             = available
+     *       top-down slots event                     = not available
+     *       fixed counter  0 supported               = false
+     *       fixed counter  1 supported               = false
+     *       fixed counter  2 supported               = false
+     *       fixed counter  3 supported               = false
+     *       fixed counter  4 supported               = false
+     *       fixed counter  5 supported               = false
+     *       ... ...
+     *       fixed counter 29 supported               = false
+     *       fixed counter 30 supported               = false
+     *       fixed counter 31 supported               = false
+     *       number of contiguous fixed counters      = 0x3 (3)
+     *       bit width of fixed counters              = 0x30 (48)
+     *       anythread deprecation                    = false
+     */
     if (limit >= 0x0a) {
         uint32_t eax, edx;
 
         cpu_x86_cpuid(env, 0x0a, 0, &eax, &unused, &unused, &edx);
 
+        /*
+	 * 1. 如果guest_vendor和host_vendor不一样, 不支持PMU.
+	 * has_architectural_pmu_version = 0.
+	 * num_architectural_pmu_gp_counters = 0.
+	 * num_architectural_pmu_fixed_counters = 0.
+	 *
+	 * 2. 如果guest_vendor是Intel
+	 * 完全按照cpuid来算
+	 *
+	 * 3. 如果guest_vendor是AMD
+	 * 3.1. 查看cpuid是否支持X86_FEATURE_PERFMON_V2.
+	 *      如果支持, 根据0x80000022获取寄存器的数目.
+         *      此外, 3个global的也支持!
+	 *      寄存器的base address和MSR_F15H_PERF_CTR5的一样(KVM svm其实限制了最多6个)
+	 * 3.2. 如果不是ver=2, 如果支持X86_FEATURE_PERFCTR_CORE,
+	 *      就是6个寄存器
+	 * 3.3. 默认只支持4个
+	 *
+	 * 在以下使用has_architectural_pmu_version:
+	 *   - target/i386/kvm/kvm.c|2031| <<kvm_arch_init_vcpu>> has_architectural_pmu_version = eax & 0xff;
+	 *   - target/i386/kvm/kvm.c|2032| <<kvm_arch_init_vcpu>> if (has_architectural_pmu_version > 0) {
+	 *   - target/i386/kvm/kvm.c|2043| <<kvm_arch_init_vcpu>> if (has_architectural_pmu_version > 1) {
+	 *   - target/i386/kvm/kvm.c|3349| <<kvm_put_msrs>> if (has_architectural_pmu_version > 0) {
+	 *   - target/i386/kvm/kvm.c|3350| <<kvm_put_msrs>> if (has_architectural_pmu_version > 1) {
+	 *   - target/i386/kvm/kvm.c|3367| <<kvm_put_msrs>> if (has_architectural_pmu_version > 1) {
+	 *   - target/i386/kvm/kvm.c|3812| <<kvm_get_msrs>> if (has_architectural_pmu_version > 0) {
+	 *   - target/i386/kvm/kvm.c|3813| <<kvm_get_msrs>> if (has_architectural_pmu_version > 1) {
+	 *
+	 * 如果在amd的机器上(cpu=index), 这里会返回什么呢??
+	 */
         has_architectural_pmu_version = eax & 0xff;
         if (has_architectural_pmu_version > 0) {
+            /*
+	     * 在以下使用num_architectural_pmu_gp_counters:
+	     *   - target/i386/kvm/kvm.c|2033| <<kvm_arch_init_vcpu>> num_architectural_pmu_gp_counters = (eax & 0xff00) >> 8;
+	     *   - target/i386/kvm/kvm.c|2039| <<kvm_arch_init_vcpu>> if (num_architectural_pmu_gp_counters > MAX_GP_COUNTERS) {
+	     *   - target/i386/kvm/kvm.c|2040| <<kvm_arch_init_vcpu>> num_architectural_pmu_gp_counters = MAX_GP_COUNTERS;
+	     *   - target/i386/kvm/kvm.c|3361| <<kvm_put_msrs>> for (i = 0; i < num_architectural_pmu_gp_counters; i++) {
+	     *   - target/i386/kvm/kvm.c|3822| <<kvm_get_msrs>> for (i = 0; i < num_architectural_pmu_gp_counters; i++) {
+	     */
             num_architectural_pmu_gp_counters = (eax & 0xff00) >> 8;
 
             /* Shouldn't be more than 32, since that's the number of bits
@@ -2036,6 +2260,14 @@ int kvm_arch_init_vcpu(CPUState *cs)
             }
 
             if (has_architectural_pmu_version > 1) {
+                /*
+		 * 在以下使用num_architectural_pmu_fixed_counters:
+		 *   - target/i386/kvm/kvm.c|2044| <<kvm_arch_init_vcpu>> num_architectural_pmu_fixed_counters = edx & 0x1f;
+		 *   - target/i386/kvm/kvm.c|2046| <<kvm_arch_init_vcpu>> if (num_architectural_pmu_fixed_counters > MAX_FIXED_COUNTERS) {
+		 *   - target/i386/kvm/kvm.c|2047| <<kvm_arch_init_vcpu>> num_architectural_pmu_fixed_counters = MAX_FIXED_COUNTERS;
+		 *   - target/i386/kvm/kvm.c|3357| <<kvm_put_msrs>> for (i = 0; i < num_architectural_pmu_fixed_counters; i++) {
+		 *   - target/i386/kvm/kvm.c|3819| <<kvm_get_msrs>> for (i = 0; i < num_architectural_pmu_fixed_counters; i++) {
+		 */
                 num_architectural_pmu_fixed_counters = edx & 0x1f;
 
                 if (num_architectural_pmu_fixed_counters > MAX_FIXED_COUNTERS) {
@@ -2518,6 +2750,21 @@ int kvm_arch_get_default_type(MachineState *ms)
     return 0;
 }
 
+/*
+ * (gdb) bt
+ * #0  kvm_arch_init (ms=0x5555573eb250, s=0x555557181bf0) at ../target/i386/kvm/kvm.c:2522
+ * #1  0x0000555555e77b96 in kvm_init (ms=0x5555573eb250) at ../accel/kvm/kvm-all.c:2568
+ * #2  0x0000555555c53a14 in accel_init_machine (accel=0x555557181bf0, ms=0x5555573eb250) at ../accel/accel-system.c:39
+ * #3  0x0000555555bca01c in do_configure_accelerator (opaque=0x7fffffffda05, opts=0x555557412b90, errp=0x5555570af7c0 <error_fatal>) at ../system/vl.c:2320
+ * #4  0x00005555560c439e in qemu_opts_foreach (list=0x555556f99220 <qemu_accel_opts>, func=0x555555bc9e9b <do_configure_accelerator>,
+ *                   opaque=0x7fffffffda05, errp=0x5555570af7c0 <error_fatal>) at ../util/qemu-option.c:1135
+ * #5  0x0000555555bca2ce in configure_accelerators (progname=0x7fffffffe04a "/home/zhang/kvm/qemu-9.0.0/build/qemu-system-x86_64") at ../system/vl.c:2389
+ * #6  0x0000555555bcd80c in qemu_init (argc=22, argv=0x7fffffffdca8) at ../system/vl.c:3682
+ * #7  0x0000555555e8a1ef in main (argc=22, argv=0x7fffffffdca8) at ../system/main.c:47
+ *
+ * called by:
+ *   - accel/kvm/kvm-all.c|2692| <<kvm_init>> ret = kvm_arch_init(ms, s);
+ */
 int kvm_arch_init(MachineState *ms, KVMState *s)
 {
     uint64_t identity_base = 0xfffbc000;
@@ -3341,8 +3588,42 @@ static int kvm_put_msrs(X86CPU *cpu, int level)
             kvm_msr_entry_add(cpu, MSR_KVM_POLL_CONTROL, env->poll_control_msr);
         }
 
+        /*
+	 * 1. 如果guest_vendor和host_vendor不一样, 不支持PMU.
+	 * has_architectural_pmu_version = 0.
+	 * num_architectural_pmu_gp_counters = 0.
+	 * num_architectural_pmu_fixed_counters = 0.
+	 *
+	 * 2. 如果guest_vendor是Intel
+	 * 完全按照cpuid来算
+	 *
+	 * 3. 如果guest_vendor是AMD
+	 * 3.1. 查看cpuid是否支持X86_FEATURE_PERFMON_V2.
+	 *      如果支持, 根据0x80000022获取寄存器的数目.
+	 *      此外, 3个global的也支持!
+	 *      寄存器的base address和MSR_F15H_PERF_CTR5的一样(KVM svm其实限制了最多6个)
+	 * 3.2. 如果不是ver=2, 如果支持X86_FEATURE_PERFCTR_CORE,
+	 *      就是6个寄存器
+	 * 3.3. 默认只支持4个
+	 *
+	 * 在以下使用has_architectural_pmu_version:
+	 *   - target/i386/kvm/kvm.c|2031| <<kvm_arch_init_vcpu>> has_architectural_pmu_version = eax & 0xff;
+	 *   - target/i386/kvm/kvm.c|2032| <<kvm_arch_init_vcpu>> if (has_architectural_pmu_version > 0) {
+	 *   - target/i386/kvm/kvm.c|2043| <<kvm_arch_init_vcpu>> if (has_architectural_pmu_version > 1) {
+	 *   - target/i386/kvm/kvm.c|3349| <<kvm_put_msrs>> if (has_architectural_pmu_version > 0) {
+	 *   - target/i386/kvm/kvm.c|3350| <<kvm_put_msrs>> if (has_architectural_pmu_version > 1) {
+	 *   - target/i386/kvm/kvm.c|3367| <<kvm_put_msrs>> if (has_architectural_pmu_version > 1) {
+	 *   - target/i386/kvm/kvm.c|3812| <<kvm_get_msrs>> if (has_architectural_pmu_version > 0) {
+	 *   - target/i386/kvm/kvm.c|3813| <<kvm_get_msrs>> if (has_architectural_pmu_version > 1) {
+	 */
         if (has_architectural_pmu_version > 0) {
             if (has_architectural_pmu_version > 1) {
+                /*
+		 * #define MSR_CORE_PERF_FIXED_CTR_CTRL    0x38d
+		 * #define MSR_CORE_PERF_GLOBAL_STATUS     0x38e
+		 * #define MSR_CORE_PERF_GLOBAL_CTRL       0x38f
+		 * #define MSR_CORE_PERF_GLOBAL_OVF_CTRL   0x390
+		 */
                 /* Stop the counter.  */
                 kvm_msr_entry_add(cpu, MSR_CORE_PERF_FIXED_CTR_CTRL, 0);
                 kvm_msr_entry_add(cpu, MSR_CORE_PERF_GLOBAL_CTRL, 0);
@@ -3360,6 +3641,12 @@ static int kvm_put_msrs(X86CPU *cpu, int level)
                                   env->msr_gp_evtsel[i]);
             }
             if (has_architectural_pmu_version > 1) {
+                /*
+		 * #define MSR_CORE_PERF_FIXED_CTR_CTRL    0x38d
+		 * #define MSR_CORE_PERF_GLOBAL_STATUS     0x38e
+		 * #define MSR_CORE_PERF_GLOBAL_CTRL       0x38f
+		 * #define MSR_CORE_PERF_GLOBAL_OVF_CTRL   0x390
+		 */
                 kvm_msr_entry_add(cpu, MSR_CORE_PERF_GLOBAL_STATUS,
                                   env->msr_global_status);
                 kvm_msr_entry_add(cpu, MSR_CORE_PERF_GLOBAL_OVF_CTRL,
@@ -3804,6 +4091,24 @@ static int kvm_get_msrs(X86CPU *cpu)
     if (env->features[FEAT_KVM] & (1 << KVM_FEATURE_POLL_CONTROL)) {
         kvm_msr_entry_add(cpu, MSR_KVM_POLL_CONTROL, 1);
     }
+    /*
+     * 1. 如果guest_vendor和host_vendor不一样, 不支持PMU.
+     * has_architectural_pmu_version = 0.
+     * num_architectural_pmu_gp_counters = 0.
+     * num_architectural_pmu_fixed_counters = 0.
+     *
+     * 2. 如果guest_vendor是Intel
+     * 完全按照cpuid来算
+     *
+     * 3. 如果guest_vendor是AMD
+     * 3.1. 查看cpuid是否支持X86_FEATURE_PERFMON_V2.
+     *      如果支持, 根据0x80000022获取寄存器的数目.
+     *      此外, 3个global的也支持!
+     *      寄存器的base address和MSR_F15H_PERF_CTR5的一样(KVM svm其实限制了最多6个)
+     * 3.2. 如果不是ver=2, 如果支持X86_FEATURE_PERFCTR_CORE,
+     *      就是6个寄存器
+     * 3.3. 默认只支持4个
+     */
     if (has_architectural_pmu_version > 0) {
         if (has_architectural_pmu_version > 1) {
             kvm_msr_entry_add(cpu, MSR_CORE_PERF_FIXED_CTR_CTRL, 0);
@@ -5381,6 +5686,10 @@ bool kvm_arch_stop_on_emulation_error(CPUState *cs)
            ((env->segs[R_CS].selector  & 3) != 3);
 }
 
+/*
+ * called by:
+ *   - accel/kvm/kvm-all.c|1823| <<kvm_init_irq_routing>> kvm_arch_init_irq_routing(s);
+ */
 void kvm_arch_init_irq_routing(KVMState *s)
 {
     /* We know at this point that we're using the in-kernel
@@ -5453,6 +5762,11 @@ uint64_t kvm_swizzle_msi_ext_dest_id(uint64_t address)
     return address;
 }
 
+/*
+ * called by:
+ *   - accel/kvm/kvm-all.c|2078| <<kvm_irqchip_add_msi_route>> if (kvm_arch_fixup_msi_route(&kroute, msg.address, msg.data, dev)) {
+ *   - accel/kvm/kvm-all.c|2129| <<kvm_irqchip_update_msi_route>> if (kvm_arch_fixup_msi_route(&kroute, msg.address, msg.data, dev)) {
+ */
 int kvm_arch_fixup_msi_route(struct kvm_irq_routing_entry *route,
                              uint64_t address, uint32_t data, PCIDevice *dev)
 {
diff --git a/util/aio-posix.c b/util/aio-posix.c
index 266c9dd35..4ec189cd3 100644
--- a/util/aio-posix.c
+++ b/util/aio-posix.c
@@ -192,6 +192,29 @@ static void aio_set_fd_poll(AioContext *ctx, int fd,
     node->io_poll_end = io_poll_end;
 }
 
+/*
+ * called by:
+ *   - block/linux-aio.c|435| <<laio_detach_aio_context>> aio_set_event_notifier(old_context, &s->e, NULL, NULL, NULL);
+  2 block/linux-aio.c|444| <<laio_attach_aio_context>> aio_set_event_notifier(new_context, &s->e,
+  3 block/nvme.c|873| <<nvme_init>> aio_set_event_notifier(bdrv_get_aio_context(bs),
+  4 block/nvme.c|959| <<nvme_close>> aio_set_event_notifier(bdrv_get_aio_context(bs),
+  5 block/nvme.c|1557| <<nvme_detach_aio_context>> aio_set_event_notifier(bdrv_get_aio_context(bs),
+  6 block/nvme.c|1568| <<nvme_attach_aio_context>> aio_set_event_notifier(new_context, &s->irq_notifier[MSIX_SHARED_IRQ_IDX],
+  7 block/win32-aio.c|177| <<win32_aio_detach_aio_context>> aio_set_event_notifier(old_context, &aio->e, NULL, NULL, NULL);
+  8 block/win32-aio.c|185| <<win32_aio_attach_aio_context>> aio_set_event_notifier(new_context, &aio->e, win32_aio_completion_cb,
+  9 hw/virtio/virtio.c|3614| <<virtio_queue_aio_attach_host_notifier>> aio_set_event_notifier(ctx, &vq->host_notifier,
+ 10 hw/virtio/virtio.c|3643| <<virtio_queue_aio_attach_host_notifier_no_poll>> aio_set_event_notifier(ctx, &vq->host_notifier,
+ *   - hw/virtio/virtio.c|3658| <<virtio_queue_aio_detach_host_notifier>> aio_set_event_notifier(ctx, &vq->host_notifier, NULL, NULL, NULL);
+ 12 include/block/aio.h|477| <<QSLIST_HEAD>> void aio_set_event_notifier(AioContext *ctx,
+ 13 tests/unit/test-aio.c|106| <<set_event_notifier>> aio_set_event_notifier(nctx, notifier, handler, NULL, NULL);
+ 14 tests/unit/test-nested-aio-poll.c|94| <<test>> aio_set_event_notifier(td.ctx, &td.poll_notifier,
+ 15 tests/unit/test-nested-aio-poll.c|99| <<test>> aio_set_event_notifier(td.ctx, &td.dummy_notifier,
+ 16 tests/unit/test-nested-aio-poll.c|117| <<test>> aio_set_event_notifier(td.ctx, &td.dummy_notifier, NULL, NULL, NULL);
+ 17 tests/unit/test-nested-aio-poll.c|118| <<test>> aio_set_event_notifier(td.ctx, &td.poll_notifier, NULL, NULL, NULL);
+ *   - util/async.c|414| <<aio_ctx_finalize>> aio_set_event_notifier(ctx, &ctx->notifier, NULL, NULL, NULL);
+ 21 util/async.c|595| <<aio_context_new>> aio_set_event_notifier(ctx, &ctx->notifier,
+ 22 util/main-loop.c|685| <<event_notifier_set_handler>> aio_set_event_notifier(iohandler_ctx, e, handler, NULL, NULL);
+ */
 void aio_set_event_notifier(AioContext *ctx,
                             EventNotifier *notifier,
                             EventNotifierHandler *io_read,
diff --git a/util/aio-wait.c b/util/aio-wait.c
index b5336cf5f..e9fc63fa3 100644
--- a/util/aio-wait.c
+++ b/util/aio-wait.c
@@ -26,6 +26,11 @@
 #include "qemu/main-loop.h"
 #include "block/aio-wait.h"
 
+/*
+ * typedef struct {
+ *     unsigned num_waiters;
+ * } AioWait;
+ */
 AioWait global_aio_wait;
 
 static void dummy_bh_cb(void *opaque)
diff --git a/util/async.c b/util/async.c
index 046789005..f5116912a 100644
--- a/util/async.c
+++ b/util/async.c
@@ -204,6 +204,15 @@ int aio_bh_poll(AioContext *ctx)
         QEMUBH *bh;
         unsigned flags;
 
+        /*
+	 * 在以下使用AioContext->bh_list:
+	 *   - util/async.c|93| <<aio_bh_enqueue>> QSLIST_INSERT_HEAD_ATOMIC(&ctx->bh_list, bh, next);
+	 *   - util/async.c|186| <<aio_bh_poll>> QSLIST_MOVE_ATOMIC(&slice.bh_list, &ctx->bh_list);
+	 *   - util/async.c|281| <<aio_compute_timeout>> timeout = aio_compute_bh_timeout(&ctx->bh_list, timeout);
+	 *   - util/async.c|336| <<aio_ctx_check>> QSLIST_FOREACH_RCU(bh, &ctx->bh_list, next) {
+	 *   - util/async.c|395| <<aio_ctx_finalize>> while ((bh = aio_bh_dequeue(&ctx->bh_list, &flags))) {
+	 *   - util/async.c|580| <<aio_context_new>> QSLIST_INIT(&ctx->bh_list);
+	 */
         bh = aio_bh_dequeue(&s->bh_list, &flags);
         if (!bh) {
             QSIMPLEQ_REMOVE_HEAD(&ctx->bh_slice_list, next);
@@ -571,6 +580,14 @@ static void co_schedule_bh_cb(void *opaque)
     }
 }
 
+/*
+ * called by:
+ *   - iothread.c|188| <<iothread_init>> iothread->ctx = aio_context_new(errp);
+ *   - tests/unit/iothread.c|51| <<iothread_run>> iothread->ctx = aio_context_new(&error_abort);
+ *   - tests/unit/test-nested-aio-poll.c|78| <<test>> .ctx = aio_context_new(&error_abort),
+ *   - util/main-loop.c|168| <<qemu_init_main_loop>> qemu_aio_context = aio_context_new(errp);
+ *   - util/main-loop.c|622| <<iohandler_init>> iohandler_ctx = aio_context_new(&error_abort);
+ */
 AioContext *aio_context_new(Error **errp)
 {
     int ret;
@@ -736,9 +753,21 @@ AioContext *qemu_get_current_aio_context(void)
     return NULL;
 }
 
+/*
+ * called by:
+ *   - iothread.c|49| <<iothread_run>> qemu_set_current_aio_context(iothread->ctx);
+ *   - tests/unit/iothread.c|52| <<iothread_run>> qemu_set_current_aio_context(iothread->ctx);
+ *   - tests/unit/test-nested-aio-poll.c|81| <<test>> qemu_set_current_aio_context(td.ctx);
+ *   - util/main-loop.c|172| <<qemu_init_main_loop>> qemu_set_current_aio_context(qemu_aio_context);
+ */
 void qemu_set_current_aio_context(AioContext *ctx)
 {
     assert(!get_my_aiocontext());
+    /*
+     * 参考QEMU_DEFINE_STATIC_CO_TLS(AioContext *, my_aiocontext)
+     *
+     * 只在此处调用
+     */
     set_my_aiocontext(ctx);
 }
 
diff --git a/util/event_notifier-posix.c b/util/event_notifier-posix.c
index 76420c5b5..1dfe9252a 100644
--- a/util/event_notifier-posix.c
+++ b/util/event_notifier-posix.c
@@ -32,6 +32,61 @@ void event_notifier_init_fd(EventNotifier *e, int fd)
 }
 #endif
 
+/*
+ * called by:
+ *   - block/linux-aio.c|456| <<laio_init>> rc = event_notifier_init(&s->e, false);
+ *   - block/nvme.c|761| <<nvme_init>> ret = event_notifier_init(&s->irq_notifier[MSIX_SHARED_IRQ_IDX], 0);
+ *   - block/win32-aio.c|194| <<win32_aio_init>> if (event_notifier_init(&s->e, false) < 0) {
+ *   - contrib/ivshmem-server/ivshmem-server.c|176| <<ivshmem_server_handle_new_conn>> if (event_notifier_init(&peer->vectors[i], FALSE) < 0) {
+ *   - hw/hyperv/hyperv.c|414| <<hyperv_sint_route_new>> r = event_notifier_init(ack_notifier, false);
+ *   - hw/hyperv/hyperv.c|428| <<hyperv_sint_route_new>> r = event_notifier_init(&sint_route->sint_set_notifier, false);
+ *   - hw/hyperv/hyperv_testdev.c|216| <<evt_conn_create>> assert(!event_notifier_init(&conn->notifier, false));
+ *   - hw/hyperv/vmbus.c|1426| <<open_channel>> if (event_notifier_init(&chan->notifier, 0)) {
+ *   - hw/hyperv/vmbus.c|2421| <<vmbus_realize>> ret = event_notifier_init(&vmbus->notifier, 0);
+ *   - hw/misc/pci-testdev.c|294| <<pci_testdev_realize>> r = event_notifier_init(&test->notifier, 0);
+ *   - hw/nvme/ctrl.c|4517| <<nvme_init_cq_ioeventfd>> ret = event_notifier_init(&cq->notifier, 0);
+ *   - hw/nvme/ctrl.c|4546| <<nvme_init_sq_ioeventfd>> ret = event_notifier_init(&sq->notifier, 0);
+ *   - hw/remote/proxy.c|56| <<setup_irqfd>> event_notifier_init(&dev->intr, 0);
+ *   - hw/remote/proxy.c|57| <<setup_irqfd>> event_notifier_init(&dev->resample, 0);
+ *   - hw/s390x/virtio-ccw.c|1028| <<virtio_ccw_set_guest_notifier>> int r = event_notifier_init(notifier, 0);
+ *   - hw/usb/ccid-card-emulated.c|406| <<init_event_notifier>> if (event_notifier_init(&card->notifier, false) < 0) {
+ *   - hw/usb/u2f-emulated.c|325| <<u2f_emulated_realize>> if (event_notifier_init(&key->notifier, false) < 0) {
+ *   - hw/vfio/ap.c|110| <<vfio_ap_register_irq_notifier>> if (event_notifier_init(notifier, 0)) {
+ *   - hw/vfio/ccw.c|427| <<vfio_ccw_register_irq_notifier>> if (event_notifier_init(notifier, 0)) {
+ *   - hw/vfio/pci-quirks.c|361| <<vfio_ioeventfd_init>> if (event_notifier_init(&ioeventfd->e, 0)) {
+ *   - hw/vfio/pci.c|137| <<vfio_intx_enable_kvm>> if (event_notifier_init(&vdev->intx.unmask, 0)) {
+ *   - hw/vfio/pci.c|290| <<vfio_intx_enable>> ret = event_notifier_init(&vdev->intx.interrupt, 0);
+ *   - hw/vfio/pci.c|479| <<vfio_connect_kvm_msi_virq>> if (event_notifier_init(&vector->kvm_interrupt, 0)) {
+ *   - hw/vfio/pci.c|528| <<vfio_msix_vector_do_use>> if (event_notifier_init(&vector->interrupt, 0)) {
+ *   - hw/vfio/pci.c|751| <<vfio_msi_enable>> if (event_notifier_init(&vector->interrupt, 0)) {
+ *   - hw/vfio/pci.c|2851| <<vfio_register_err_notifier>> if (event_notifier_init(&vdev->err_notifier, 0)) {
+ *   - hw/vfio/pci.c|2917| <<vfio_register_req_notifier>> if (event_notifier_init(&vdev->req_notifier, 0)) {
+ *   - hw/vfio/platform.c|77| <<vfio_init_intp>> ret = event_notifier_init(intp->interrupt, 0);
+ *   - hw/vfio/platform.c|88| <<vfio_init_intp>> ret = event_notifier_init(intp->unmask, 0);
+ *   - hw/virtio/vhost-vdpa.c|1054| <<vhost_vdpa_svq_set_fds>> r = event_notifier_init(&svq->hdev_kick, 0);
+ *   - hw/virtio/vhost-vdpa.c|1060| <<vhost_vdpa_svq_set_fds>> r = event_notifier_init(&svq->hdev_call, 0);
+ *   - hw/virtio/vhost.c|1385| <<vhost_virtqueue_init>> int r = event_notifier_init(&vq->masked_notifier, 0);
+ *   - hw/virtio/vhost.c|1400| <<vhost_virtqueue_init>> r = event_notifier_init(&vq->error_notifier, 0);
+ *   - hw/virtio/vhost.c|2031| <<vhost_dev_start>> r = event_notifier_init(
+ *   - hw/virtio/virtio-bus.c|290| <<virtio_bus_set_host_notifier>> r = event_notifier_init(notifier, 1);
+ *   - hw/virtio/virtio-mmio.c|658| <<virtio_mmio_set_guest_notifier>> int r = event_notifier_init(notifier, 0);
+ *   - hw/virtio/virtio-mmio.c|684| <<virtio_mmio_set_config_guest_notifier>> r = event_notifier_init(notifier, 0);
+ *   - hw/virtio/virtio-pci.c|1196| <<virtio_pci_set_guest_notifier>> int r = event_notifier_init(notifier, 0);
+ *   - tests/unit/test-aio.c|261| <<test_set_event_notifier>> event_notifier_init(&data.e, false);
+ *   - tests/unit/test-aio.c|275| <<test_wait_event_notifier>> event_notifier_init(&data.e, false);
+ *   - tests/unit/test-aio.c|300| <<test_flush_event_notifier>> event_notifier_init(&data.e, false);
+ *   - tests/unit/test-aio.c|327| <<test_wait_event_notifier_noflush>> event_notifier_init(&data.e, false);
+ *   - tests/unit/test-aio.c|340| <<test_wait_event_notifier_noflush>> event_notifier_init(&dummy.e, false);
+ *   - tests/unit/test-aio.c|381| <<test_timer_schedule>> event_notifier_init(&e, false);
+ *   - tests/unit/test-aio.c|592| <<test_source_set_event_notifier>> event_notifier_init(&data.e, false);
+ *   - tests/unit/test-aio.c|606| <<test_source_wait_event_notifier>> event_notifier_init(&data.e, false);
+ *   - tests/unit/test-aio.c|631| <<test_source_flush_event_notifier>> event_notifier_init(&data.e, false);
+ *   - tests/unit/test-aio.c|658| <<test_source_wait_event_notifier_noflush>> event_notifier_init(&data.e, false);
+ *   - tests/unit/test-aio.c|671| <<test_source_wait_event_notifier_noflush>> event_notifier_init(&dummy.e, false);
+ *   - tests/unit/test-nested-aio-poll.c|93| <<test>> event_notifier_init(&td.poll_notifier, 1);
+ *   - tests/unit/test-nested-aio-poll.c|98| <<test>> event_notifier_init(&td.dummy_notifier, 0);
+ *   - util/async.c|584| <<aio_context_new>> ret = event_notifier_init(&ctx->notifier, false);
+ */
 int event_notifier_init(EventNotifier *e, int active)
 {
     int fds[2];
diff --git a/util/main-loop.c b/util/main-loop.c
index a0386cfeb..87a02800b 100644
--- a/util/main-loop.c
+++ b/util/main-loop.c
@@ -128,6 +128,19 @@ static int qemu_signal_init(Error **errp)
 }
 #endif
 
+/*
+ * 在以下使用qemu_aio_context:
+ *   - util/main-loop.c|143| <<qemu_get_aio_context>> return qemu_aio_context;
+ *   - util/main-loop.c|148| <<qemu_notify_event>> if (!qemu_aio_context) {
+ *   - util/main-loop.c|168| <<qemu_init_main_loop>> qemu_aio_context = aio_context_new(errp);
+ *   - util/main-loop.c|169| <<qemu_init_main_loop>> if (!qemu_aio_context) {
+ *   - util/main-loop.c|172| <<qemu_init_main_loop>> qemu_set_current_aio_context(qemu_aio_context);
+ *   - util/main-loop.c|175| <<qemu_init_main_loop>> src = aio_get_g_source(qemu_aio_context);
+ *   - util/main-loop.c|190| <<main_loop_update_params>> if (!qemu_aio_context) {
+ *   - util/main-loop.c|195| <<main_loop_update_params>> aio_context_set_aio_params(qemu_aio_context, base->aio_max_batch);
+ *   - util/main-loop.c|197| <<main_loop_update_params>> aio_context_set_thread_pool_params(qemu_aio_context, base->thread_pool_min,
+ *   - util/main-loop.c|608| <<qemu_bh_new_full>> return aio_bh_new_full(qemu_aio_context, cb, opaque, name,
+ */
 static AioContext *qemu_aio_context;
 static QEMUBH *qemu_notify_bh;
 
@@ -635,6 +648,39 @@ GSource *iohandler_get_g_source(void)
     return aio_get_g_source(iohandler_ctx);
 }
 
+/*
+ * 一些例子:
+ *   - hw/net/vhost_net.c|284| <<vhost_net_start_one>> qemu_set_fd_handler(net->backend, NULL, NULL, NULL);
+ *   - hw/vfio/ap.c|118| <<vfio_ap_register_irq_notifier>> qemu_set_fd_handler(fd, fd_read, NULL, vapdev);
+ *   - hw/vfio/ap.c|122| <<vfio_ap_register_irq_notifier>> qemu_set_fd_handler(fd, NULL, NULL, vapdev);
+ *   - hw/vfio/ap.c|151| <<vfio_ap_unregister_irq_notifier>> qemu_set_fd_handler(event_notifier_get_fd(notifier), NULL, NULL, vapdev);
+ *   - hw/vfio/ccw.c|435| <<vfio_ccw_register_irq_notifier>> qemu_set_fd_handler(fd, fd_read, NULL, vcdev);
+ *   - hw/vfio/ccw.c|439| <<vfio_ccw_register_irq_notifier>> qemu_set_fd_handler(fd, NULL, NULL, vcdev);
+ *   - hw/vfio/ccw.c|473| <<vfio_ccw_unregister_irq_notifier>> qemu_set_fd_handler(event_notifier_get_fd(notifier), NULL, NULL, vcdev);
+ *   - hw/vfio/pci-quirks.c|312| <<vfio_ioeventfd_exit>> qemu_set_fd_handler(event_notifier_get_fd(&ioeventfd->e), NULL, NULL, NULL);
+ *   - hw/vfio/pci-quirks.c|397| <<vfio_ioeventfd_init>> qemu_set_fd_handler(event_notifier_get_fd(&ioeventfd->e), vfio_ioeventfd_handler, NULL, ioeventfd);
+ *   - hw/vfio/pci.c|131| <<vfio_intx_enable_kvm>> qemu_set_fd_handler(irq_fd, NULL, NULL, vdev);
+ *   - hw/vfio/pci.c|172| <<vfio_intx_enable_kvm>> qemu_set_fd_handler(irq_fd, vfio_intx_interrupt, NULL, vdev);
+ *   - hw/vfio/pci.c|202| <<vfio_intx_disable_kvm>> qemu_set_fd_handler(event_notifier_get_fd(&vdev->intx.interrupt), vfio_intx_interrupt, NULL, vdev);
+ *   - hw/vfio/pci.c|296| <<vfio_intx_enable>> qemu_set_fd_handler(fd, vfio_intx_interrupt, NULL, vdev);
+ *   - hw/vfio/pci.c|300| <<vfio_intx_enable>> qemu_set_fd_handler(fd, NULL, NULL, vdev);
+ *   - hw/vfio/pci.c|328| <<vfio_intx_disable>> qemu_set_fd_handler(fd, NULL, NULL, vdev);
+ *   - hw/vfio/pci.c|549| <<vfio_msix_vector_do_use>> qemu_set_fd_handler(event_notifier_get_fd(&vector->interrupt), handler, NULL, vector);
+ *   - hw/vfio/pci.c|795| <<vfio_msi_enable>> qemu_set_fd_handler(event_notifier_get_fd(&vector->interrupt), vfio_msi_interrupt, NULL, vector);
+ *   - hw/vfio/pci.c|849| <<vfio_msi_disable_common>> qemu_set_fd_handler(event_notifier_get_fd(&vector->interrupt), NULL, NULL, NULL);
+ *   - hw/vfio/pci.c|2902| <<vfio_register_err_notifier>> qemu_set_fd_handler(fd, vfio_err_notifier_handler, NULL, vdev);
+ *   - hw/vfio/pci.c|2907| <<vfio_register_err_notifier>> qemu_set_fd_handler(fd, NULL, NULL, vdev);
+ *   - hw/vfio/pci.c|2925| <<vfio_unregister_err_notifier>> qemu_set_fd_handler(event_notifier_get_fd(&vdev->err_notifier), NULL, NULL, vdev);
+ *   - hw/vfio/pci.c|2967| <<vfio_register_req_notifier>> qemu_set_fd_handler(fd, vfio_req_notifier_handler, NULL, vdev);
+ *   - hw/vfio/pci.c|2972| <<vfio_register_req_notifier>> qemu_set_fd_handler(fd, NULL, NULL, vdev);
+ *   - hw/vfio/pci.c|2991| <<vfio_unregister_req_notifier>> qemu_set_fd_handler(event_notifier_get_fd(&vdev->req_notifier), NULL, NULL, vdev);
+ *   - hw/vfio/platform.c|120| <<vfio_set_trigger_eventfd>> qemu_set_fd_handler(fd, (IOHandler *)handler, NULL, intp);
+ *   - hw/vfio/platform.c|126| <<vfio_set_trigger_eventfd>> qemu_set_fd_handler(fd, NULL, NULL, NULL);
+ *   - hw/vfio/platform.c|360| <<vfio_set_resample_eventfd>> qemu_set_fd_handler(fd, NULL, NULL, NULL);
+ *   - hw/virtio/vhost-backend.c|313| <<vhost_kernel_set_iotlb_callback>> qemu_set_fd_handler((uintptr_t)dev->opaque, vhost_kernel_iotlb_read, NULL, dev);
+ *   - hw/virtio/vhost-backend.c|316| <<vhost_kernel_set_iotlb_callback>> qemu_set_fd_handler((uintptr_t)dev->opaque, NULL, NULL, NULL);
+ *   - net/tap.c|75| <<tap_update_fd_handler>> qemu_set_fd_handler(s->fd, s->read_poll && s->enabled ? tap_send : NULL, s->write_poll && s->enabled ? tap_writable : NULL, s);
+ */
 void qemu_set_fd_handler(int fd,
                          IOHandler *fd_read,
                          IOHandler *fd_write,
diff --git a/util/osdep.c b/util/osdep.c
index e996c4744..fa790578c 100644
--- a/util/osdep.c
+++ b/util/osdep.c
@@ -116,6 +116,16 @@ int qemu_mprotect_none(void *addr, size_t size)
 
 #ifndef _WIN32
 
+/*
+ * 在以下使用fcntl_op_setlk:
+ *   - util/osdep.c|191| <<qemu_probe_lock_ops>> if (fcntl_op_setlk == -1) {
+ *   - util/osdep.c|207| <<qemu_probe_lock_ops>> fcntl_op_setlk = F_SETLK;
+ *   - util/osdep.c|214| <<qemu_probe_lock_ops>> fcntl_op_setlk = F_OFD_SETLK;
+ *   - util/osdep.c|217| <<qemu_probe_lock_ops>> fcntl_op_setlk = F_SETLK;
+ *   - util/osdep.c|221| <<qemu_probe_lock_ops>> fcntl_op_setlk = F_SETLK;
+ *   - util/osdep.c|231| <<qemu_has_ofd_lock>> return fcntl_op_setlk == F_OFD_SETLK;
+ *   - util/osdep.c|247| <<qemu_lock_fcntl>> ret = RETRY_ON_EINTR(fcntl(fd, fcntl_op_setlk, &fl));
+ */
 static int fcntl_op_setlk = -1;
 static int fcntl_op_getlk = -1;
 
@@ -234,6 +244,11 @@ bool qemu_has_ofd_lock(void)
 #endif
 }
 
+/*
+ * called by:
+ *   - util/osdep.c|292| <<qemu_lock_fd>> return qemu_lock_fcntl(fd, start, len, exclusive ? F_WRLCK : F_RDLCK);
+ *   - util/osdep.c|302| <<qemu_unlock_fd>> return qemu_lock_fcntl(fd, start, len, F_UNLCK);
+ */
 static int qemu_lock_fcntl(int fd, int64_t start, int64_t len, int fl_type)
 {
     int ret;
@@ -248,16 +263,63 @@ static int qemu_lock_fcntl(int fd, int64_t start, int64_t len, int fl_type)
     return ret == -1 ? -errno : 0;
 }
 
+/*
+ * [0] qemu_lock_fd
+ * [0] raw_handle_perm_lock
+ * [0] raw_check_perm
+ * [0] bdrv_drv_set_perm
+ * [0] bdrv_node_refresh_perm
+ * [0] bdrv_list_refresh_perms
+ * [0] bdrv_replace_node_common
+ * [0] mirror_start_job
+ * [0] commit_active_start
+ * [0] qmp_block_commit
+ * [0] qmp_marshal_block_commit
+ * [0] do_qmp_dispatch_bh
+ * [0] aio_bh_poll
+ * [0] aio_dispatch
+ * [0] aio_ctx_dispatch
+ * [0] g_main_context_dispatch
+ * [0] glib_pollfds_poll
+ * [0] os_host_main_loop_wait
+ * [0] main_loop_wait
+ * [0] qemu_main_loop
+ * [0] qemu_default_main
+ * [0] __libc_start_main
+ * [0] _start
+ *
+ * called by:
+ *   - block/file-posix.c|872| <<raw_apply_lock_bytes>> ret = qemu_lock_fd(fd, off, 1, false);
+ *   - block/file-posix.c|894| <<raw_apply_lock_bytes>> ret = qemu_lock_fd(fd, off, 1, false);
+ */
 int qemu_lock_fd(int fd, int64_t start, int64_t len, bool exclusive)
 {
+    /*
+     * called by:
+     *   - util/osdep.c|292| <<qemu_lock_fd>> return qemu_lock_fcntl(fd, start, len, exclusive ? F_WRLCK : F_RDLCK);
+     *   - util/osdep.c|302| <<qemu_unlock_fd>> return qemu_lock_fcntl(fd, start, len, F_UNLCK);
+     */
     return qemu_lock_fcntl(fd, start, len, exclusive ? F_WRLCK : F_RDLCK);
 }
 
+/*
+ * called by:
+ *   - block/file-posix.c|941| <<raw_apply_lock_bytes>> ret = qemu_unlock_fd(fd, off, 1);
+ *   - block/file-posix.c|964| <<raw_apply_lock_bytes>> ret = qemu_unlock_fd(fd, off, 1);
+ */
 int qemu_unlock_fd(int fd, int64_t start, int64_t len)
 {
     return qemu_lock_fcntl(fd, start, len, F_UNLCK);
 }
 
+/*
+ * called by:
+ *   - block/file-posix.c|987| <<raw_check_lock_bytes>> ret = qemu_lock_fd_test(fd, off, 1, true);
+ *   - block/file-posix.c|1003| <<raw_check_lock_bytes>> ret = qemu_lock_fd_test(fd, off, 1, true);
+ *   - tests/unit/test-image-locking.c|62| <<check_locked_bytes>> g_assert(!qemu_lock_fd_test(fd, 0, 0, true));
+ *   - tests/unit/test-image-locking.c|70| <<check_locked_bytes>> !!qemu_lock_fd_test(fd, 100 + i, 1, true));
+ *   - tests/unit/test-image-locking.c|72| <<check_locked_bytes>> !!qemu_lock_fd_test(fd, 200 + i, 1, true));
+ */
 int qemu_lock_fd_test(int fd, int64_t start, int64_t len, bool exclusive)
 {
     int ret;
@@ -277,6 +339,10 @@ int qemu_lock_fd_test(int fd, int64_t start, int64_t len, bool exclusive)
 }
 #endif
 
+/*
+ * called by:
+ *   - util/osdep.c|357| <<qemu_open_internal>> ret = qemu_open_cloexec(name, flags, mode);
+ */
 static int qemu_open_cloexec(const char *name, int flags, mode_t mode)
 {
     int ret;
@@ -294,6 +360,12 @@ static int qemu_open_cloexec(const char *name, int flags, mode_t mode)
 /*
  * Opens a file with FD_CLOEXEC set
  */
+/*
+ * called by:
+ *   - util/osdep.c|387| <<qemu_open>> return qemu_open_internal(name, flags, 0, errp);
+ *   - util/osdep.c|395| <<qemu_create>> return qemu_open_internal(name, flags | O_CREAT, mode, errp);
+ *   - util/osdep.c|411| <<qemu_open_old>> ret = qemu_open_internal(name, flags, mode, NULL);
+ */
 static int
 qemu_open_internal(const char *name, int flags, mode_t mode, Error **errp)
 {
@@ -351,6 +423,19 @@ qemu_open_internal(const char *name, int flags, mode_t mode, Error **errp)
 }
 
 
+/*
+ * called by:
+ *   - block/blkio.c|718| <<blkio_virtio_blk_connect>> fd = qemu_open(path, O_RDWR, NULL);
+ *   - block/file-posix.c|708| <<raw_open_common>> fd = qemu_open(filename, s->open_flags, errp);
+ *   - block/file-posix.c|1188| <<raw_reconfigure_getfd>> fd = qemu_open(normalized_filename, *open_flags, errp);
+ *   - block/file-posix.c|4191| <<setup_cdrom>> fd = qemu_open(test_partition, O_RDONLY | O_BINARY | O_LARGEFILE, NULL);
+ *   - block/file-posix.c|4510| <<cdrom_probe_device>> fd = qemu_open(filename, O_RDONLY | O_NONBLOCK, NULL);
+ *   - block/file-posix.c|4639| <<cdrom_reopen>> fd = qemu_open(bs->filename, s->open_flags, NULL);
+ *   - hw/smbios/smbios.c|1268| <<save_opt_one>> int fd = qemu_open(value, O_RDONLY, errp);
+ *   - hw/virtio/vdpa-dev.c|65| <<vhost_vdpa_device_realize>> v->vhostfd = qemu_open(v->vhostdev, O_RDWR, errp);
+ *   - net/vhost-vdpa.c|1802| <<net_init_vhost_vdpa>> vdpa_device_fd = qemu_open(opts->vhostdev, O_RDWR, errp);
+ *   - qga/commands-bsd.c|89| <<qmp_guest_fsfreeze_do_freeze_list>> ufssuspend_fd = qemu_open(_PATH_UFSSUSPEND, O_RDWR, errp);
+ */
 int qemu_open(const char *name, int flags, Error **errp)
 {
     assert(!(flags & O_CREAT));
@@ -367,6 +452,41 @@ int qemu_create(const char *name, int flags, mode_t mode, Error **errp)
 }
 
 
+/*
+ * called by:
+ *   - accel/kvm/kvm-all.c|2491| <<kvm_init>> s->fd = qemu_open_old(s->device ?: "/dev/kvm", O_RDWR);
+ *   - backends/hostmem-epc.c|32| <<sgx_epc_backend_memory_alloc>> fd = qemu_open_old("/dev/sgx_vepc", O_RDWR);
+ *   - backends/hostmem-epc.c|71| <<register_types>> int fd = qemu_open_old("/dev/sgx_vepc", O_RDWR);
+ *   - backends/iommufd.c|81| <<iommufd_backend_connect>> fd = qemu_open_old("/dev/iommu", O_RDWR);
+ *   - backends/rng-random.c|78| <<rng_random_opened>> s->fd = qemu_open_old(s->filename, O_RDONLY | O_NONBLOCK); 
+ *   - backends/tpm/tpm_passthrough.c|218| <<tpm_passthrough_open_sysfs_cancel>> fd = qemu_open_old(tpm_pt->options->cancel_path, O_WRONLY);
+ *   - backends/tpm/tpm_passthrough.c|236| <<tpm_passthrough_open_sysfs_cancel>> fd = qemu_open_old(path, O_WRONLY);
+ *   - backends/tpm/tpm_passthrough.c|240| <<tpm_passthrough_open_sysfs_cancel>> fd = qemu_open_old(path, O_WRONLY);
+ *   - backends/tpm/tpm_passthrough.c|270| <<tpm_passthrough_handle_device_opts>> tpm_pt->tpm_fd = qemu_open_old(tpm_pt->tpm_dev, O_RDWR);
+ *   - block/vvfat.c|1366| <<open_file>> int fd = qemu_open_old(mapping->path,
+ *   - block/vvfat.c|2531| <<commit_one_file>> fd = qemu_open_old(mapping->path, O_RDWR | O_CREAT | O_BINARY, 0666);
+ *   - chardev/char-fd.c|201| <<qmp_chardev_open_file_source>> fd = RETRY_ON_EINTR(qemu_open_old(src, flags, 0666));
+ *   - chardev/char-pipe.c|134| <<qemu_chr_open_pipe>> fd_in = RETRY_ON_EINTR(qemu_open_old(filename_in, O_RDWR | O_BINARY));
+ *   - chardev/char-pipe.c|135| <<qemu_chr_open_pipe>> fd_out = RETRY_ON_EINTR(qemu_open_old(filename_out, O_RDWR | O_BINARY));
+ *   - chardev/char-pipe.c|146| <<qemu_chr_open_pipe>> qemu_open_old(filename, O_RDWR | O_BINARY)
+ *   - hw/i386/sgx.c|161| <<qmp_query_sgx_capabilities>> int fd = qemu_open_old("/dev/sgx_vepc", O_RDWR);
+ *   - hw/s390x/s390-skeys.c|138| <<qmp_dump_skeys>> fd = qemu_open_old(filename, O_WRONLY | O_CREAT | O_TRUNC, 0600);
+ *   - hw/usb/bus.c|263| <<usb_qdev_realize>> int fd = qemu_open_old(dev->pcap_filename,
+ *   -  hw/usb/host-libusb.c|1215| <<usb_host_realize>> fd = qemu_open_old(s->hostdevice, O_RDWR);
+ *   - hw/usb/u2f-emulated.c|203| <<u2f_emulated_read>> fd = qemu_open_old(path, O_RDONLY);
+ *   - hw/usb/u2f-emulated.c|220| <<u2f_emulated_setup_counter>> fd = qemu_open_old(path, O_RDWR);
+ *   - hw/usb/u2f-passthru.c|386| <<u2f_passthru_open_from_device>> int fd = qemu_open_old(devnode, O_RDWR);
+ *   - hw/usb/u2f-passthru.c|485| <<u2f_passthru_realize>> fd = qemu_open_old(key->hidraw, O_RDWR);
+ *   - hw/vfio/container.c|599| <<vfio_connect_container>> fd = qemu_open_old("/dev/vfio/vfio", O_RDWR);
+ *   - hw/vfio/container.c|751| <<vfio_get_group>> group->fd = qemu_open_old(path, O_RDWR);
+ *   - io/channel-file.c|71| <<qio_channel_file_new_path>> ioc->fd = qemu_open_old(path, flags, mode);
+ *   - os-posix.c|290| <<os_setup_post>> fd = RETRY_ON_EINTR(qemu_open_old("/dev/null", O_RDWR));
+ *   - target/arm/kvm.c|108| <<kvm_arm_create_scratch_host_vcpu>> kvmfd = qemu_open_old("/dev/kvm", O_RDWR);
+ *   - target/i386/kvm/kvm.c|5248| <<__kvm_enable_sgx_provisioning>> fd = qemu_open_old("/dev/sgx_provision", O_RDONLY);
+ *   - target/riscv/kvm/kvm-cpu.c|874| <<kvm_riscv_create_scratch_vcpu>> kvmfd = qemu_open_old("/dev/kvm", O_RDWR);
+ *   - ui/ui-qmp-cmds.c|372| <<qmp_screendump>> fd = qemu_open_old(filename, O_WRONLY | O_CREAT | O_TRUNC | O_BINARY, 0666);
+ *   - util/chardev_open.c|48| <<open_cdev_internal>> fd = qemu_open_old(path, O_RDWR);
+ */
 int qemu_open_old(const char *name, int flags, ...)
 {
     va_list ap;
diff --git a/util/transactions.c b/util/transactions.c
index 2dbdedce9..f122e2e31 100644
--- a/util/transactions.c
+++ b/util/transactions.c
@@ -35,6 +35,22 @@ struct Transaction {
     QSLIST_HEAD(, TransactionAction) actions;
 };
 
+/*
+ * called by:
+ *   - block.c|2916| <<bdrv_refresh_perms>> tran = local_tran = tran_new();
+ *   - block.c|2932| <<bdrv_child_try_set_perm>> Transaction *tran = tran_new();
+ *   - block.c|3273| <<bdrv_attach_child_common_abort>> tran = tran_new();
+ *   - block.c|3347| <<bdrv_attach_child_common>> Transaction *aio_ctx_tran = tran_new();
+ *   - block.c|3468| <<bdrv_root_attach_child>> Transaction *tran = tran_new();
+ *   - block.c|3507| <<bdrv_attach_child>> Transaction *tran = tran_new();
+ *   - block.c|3791| <<bdrv_set_backing_hd_drained>> Transaction *tran = tran_new();
+ *   - block.c|4785| <<bdrv_reopen_multiple>> Transaction *tran = tran_new();
+ *   - block.c|5678| <<bdrv_replace_node_common>> Transaction *tran = tran_new();
+ *   - block.c|5833| <<bdrv_append>> Transaction *tran = tran_new();
+ *   - block.c|5897| <<bdrv_replace_child_bs>> Transaction *tran = tran_new();
+ *   - block.c|8154| <<bdrv_try_change_aio_context>> tran = tran_new();
+ *   - blockdev.c|2228| <<qmp_transaction>> tran = tran_new();
+ */
 Transaction *tran_new(void)
 {
     Transaction *tran = g_new(Transaction, 1);
@@ -44,6 +60,36 @@ Transaction *tran_new(void)
     return tran;
 }
 
+/*
+ * called by:
+ *   - block.c|2440| <<bdrv_child_set_perm>> tran_add(tran, &bdrv_child_set_pem_drv, s);
+ *   - block.c|2525| <<bdrv_drv_set_perm>> tran_add(tran, &bdrv_drv_set_perm_drv, bs);
+ *   - block.c|2604| <<bdrv_replace_child_tran>> tran_add(tran, &bdrv_replace_child_drv, s);
+ *   - block.c|3397| <<bdrv_attach_child_common>> tran_add(tran, &bdrv_attach_child_common_drv, s);
+ *   - block.c|3589| <<bdrv_set_inherits_from>> tran_add(tran, &bdrv_set_inherits_from_drv, s);
+ *   - block.c|5540| <<bdrv_remove_child>> tran_add(tran, &bdrv_remove_child_drv, child);
+ *   - block.c|8128| <<bdrv_change_aio_context>> tran_add(tran, &set_aio_context, state);
+ *   - block/block-backend.c|2827| <<blk_root_change_aio_ctx>> tran_add(tran, &set_blk_root_context, s);
+ *   - block/io.c|184| <<bdrv_refresh_limits>> tran_add(tran, &bdrv_refresh_limits_drv, s);
+ *   - blockdev.c|1248| <<internal_snapshot_action>> tran_add(tran, &internal_snapshot_drv, state);
+ *   - blockdev.c|1392| <<external_snapshot_action>> tran_add(tran, &external_snapshot_drv, state);
+ *   - blockdev.c|1638| <<drive_backup_action>> tran_add(tran, &drive_backup_drv, state);
+ *   - blockdev.c|1813| <<blockdev_backup_action>> tran_add(tran, &blockdev_backup_drv, state);
+ *   - blockdev.c|1890| <<block_dirty_bitmap_add_action>> tran_add(tran, &block_dirty_bitmap_add_drv, state);
+ *   - blockdev.c|1929| <<block_dirty_bitmap_clear_action>> tran_add(tran, &block_dirty_bitmap_clear_drv, state);
+ *   - blockdev.c|1973| <<block_dirty_bitmap_enable_action>> tran_add(tran, &block_dirty_bitmap_enable_drv, state);
+ *   - blockdev.c|2011| <<block_dirty_bitmap_disable_action>> tran_add(tran, &block_dirty_bitmap_disable_drv, state);
+ *   - blockdev.c|2049| <<block_dirty_bitmap_merge_action>> tran_add(tran, &block_dirty_bitmap_merge_drv, state);
+ *   - blockdev.c|2069| <<block_dirty_bitmap_remove_action>> tran_add(tran, &block_dirty_bitmap_remove_drv, state);
+ *   - blockdev.c|2105| <<abort_action>> tran_add(tran, &abort_drv, NULL);
+ *   - blockjob.c|169| <<child_job_change_aio_ctx>> tran_add(tran, &change_child_job_context, s);
+ *
+ * 1378 TransactionActionDrv external_snapshot_drv = {
+ * 1379     .commit = external_snapshot_commit,
+ * 1380     .abort = external_snapshot_abort,
+ * 1381     .clean = external_snapshot_clean,
+ * 1382 };
+ */
 void tran_add(Transaction *tran, TransactionActionDrv *drv, void *opaque)
 {
     TransactionAction *act;
@@ -57,6 +103,13 @@ void tran_add(Transaction *tran, TransactionActionDrv *drv, void *opaque)
     QSLIST_INSERT_HEAD(&tran->actions, act, entry);
 }
 
+/*
+ * called by:
+ *   - block.c|4865| <<bdrv_reopen_multiple>> tran_abort(tran);
+ *   - block.c|8171| <<bdrv_try_change_aio_context>> tran_abort(tran);
+ *   - blockdev.c|2246| <<qmp_transaction>> tran_abort(tran);
+ *   - include/qemu/transactions.h|60| <<tran_finalize>> tran_abort(tran);
+ */
 void tran_abort(Transaction *tran)
 {
     TransactionAction *act, *next;
@@ -78,6 +131,14 @@ void tran_abort(Transaction *tran)
     g_free(tran);
 }
 
+/*
+ * called by:
+ *   - block.c|3283| <<bdrv_attach_child_common_abort>> tran_commit(tran);
+ *   - block.c|4849| <<bdrv_reopen_multiple>> tran_commit(tran);
+ *   - block.c|8175| <<bdrv_try_change_aio_context>> tran_commit(tran);
+ *   - blockdev.c|2255| <<qmp_transaction>> tran_commit(tran);
+ *   - include/qemu/transactions.h|62| <<tran_finalize>> tran_commit(tran);
+ */
 void tran_commit(Transaction *tran)
 {
     TransactionAction *act, *next;
-- 
2.39.3 (Apple Git-146)

