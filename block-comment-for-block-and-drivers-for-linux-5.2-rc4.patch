From 24b5a4b5ed61eb0fb4856a0e282dc450b3112ae8 Mon Sep 17 00:00:00 2001
From: Dongli Zhang <dongli.zhang0129@gmail.com>
Date: Wed, 12 Jun 2019 15:48:29 +0800
Subject: [PATCH 1/1] block comment for block and drivers for linux-5.2-rc4

Signed-off-by: Dongli Zhang <dongli.zhang0129@gmail.com>
---
 arch/x86/kernel/apic/vector.c | 35 +++++++++++++++++++++++++++++++++++
 block/blk-mq-tag.h            |  7 +++++++
 block/blk-mq.c                | 26 ++++++++++++++++++++++++++
 block/blk-mq.h                |  9 +++++++++
 drivers/nvme/host/pci.c       |  4 ++++
 drivers/scsi/hosts.c          |  3 +++
 drivers/scsi/scsi_scan.c      |  4 ++++
 drivers/scsi/sd.c             | 22 ++++++++++++++++++++++
 drivers/scsi/virtio_scsi.c    | 22 ++++++++++++++++++++++
 include/linux/blk-mq.h        | 26 ++++++++++++++++++++++++++
 include/linux/dma-mapping.h   | 13 +++++++++++++
 include/linux/irq.h           |  7 +++++++
 kernel/irq/matrix.c           |  4 ++++
 13 files changed, 182 insertions(+)

diff --git a/arch/x86/kernel/apic/vector.c b/arch/x86/kernel/apic/vector.c
index 3173e07..ab8ce93 100644
--- a/arch/x86/kernel/apic/vector.c
+++ b/arch/x86/kernel/apic/vector.c
@@ -26,6 +26,37 @@
 
 #include <asm/trace/irq_vectors.h>
 
+/*
+ * struct irq_affinity_desc
+ *   unsigned int is_managed:1; 默认是1
+ *
+ *   - kernel/irq/affinity.c|318| <<irq_create_affinity_masks>> masks[i].is_managed = 1;
+ *   - kernel/irq/irqdesc.c|473| <<alloc_descs>> if (affinity->is_managed) {
+ *
+ *
+ * struct pci_dev
+ *   unsigned int is_managed:1; 默认是1
+ *
+ *   - drivers/pci/pci.c|1808| <<pcim_enable_device>> pdev->is_managed = 1;
+ *   - include/linux/pci.h|1107| <<pci_is_managed>> return pdev->is_managed;
+ *
+ *
+ * struct apic_chip_data
+ *   unsigned int is_managed:1; 默认是1
+ *
+ *   - arch/x86/kernel/apic/vector.c|194| <<reserve_managed_vector>> apicd->is_managed = true;
+ *   - arch/x86/kernel/apic/vector.c|367| <<x86_vector_deactivate>> trace_vector_deactivate(irqd->irq, apicd->is_managed,
+ *   - arch/x86/kernel/apic/vector.c|371| <<x86_vector_deactivate>> if (!apicd->is_managed && !apicd->can_reserve)
+ *   - arch/x86/kernel/apic/vector.c|438| <<x86_vector_activate>> trace_vector_activate(irqd->irq, apicd->is_managed,
+ *   - arch/x86/kernel/apic/vector.c|442| <<x86_vector_activate>> if (!apicd->can_reserve && !apicd->is_managed)
+ *   - arch/x86/kernel/apic/vector.c|448| <<x86_vector_activate>> else if (apicd->is_managed)
+ *   - arch/x86/kernel/apic/vector.c|461| <<vector_free_reserved_and_managed>> trace_vector_teardown(irqd->irq, apicd->is_managed,
+ *   - arch/x86/kernel/apic/vector.c|466| <<vector_free_reserved_and_managed>> if (apicd->is_managed)
+ *   - arch/x86/kernel/apic/vector.c|615| <<x86_vector_debug_show>> seq_printf(m, "%*sis_managed: %u\n", ind, "", apicd.is_managed ? 1 : 0);
+ *   - arch/x86/kernel/apic/vector.c|776| <<apic_set_affinity>> (apicd->is_managed || apicd->can_reserve))
+ *   - arch/x86/kernel/apic/vector.c|830| <<free_moved_vector>> bool managed = apicd->is_managed;
+ */
+
 struct apic_chip_data {
 	struct irq_cfg		hw_irq_cfg;
 	unsigned int		vector;
@@ -296,6 +327,10 @@ static int assign_irq_vector_any_locked(struct irq_data *irqd)
 static int
 assign_irq_vector_policy(struct irq_data *irqd, struct irq_alloc_info *info)
 {
+	/*
+	 * IRQD_AFFINITY_MANAGED在以下设置:
+	 *   - kernel/irq/irqdesc.c|474| <<alloc_descs>> flags = IRQD_AFFINITY_MANAGED |
+	 */
 	if (irqd_affinity_is_managed(irqd))
 		return reserve_managed_vector(irqd);
 	if (info->mask)
diff --git a/block/blk-mq-tag.h b/block/blk-mq-tag.h
index 61deab0..a9f4d7f 100644
--- a/block/blk-mq-tag.h
+++ b/block/blk-mq-tag.h
@@ -18,6 +18,13 @@ struct blk_mq_tags {
 
 	struct request **rqs;
 	struct request **static_rqs;
+	/*
+	 * 在以下使用:
+	 *   - block/blk-mq.c|2072| <<blk_mq_free_rqs>> while (!list_empty(&tags->page_list)) {
+	 *   - block/blk-mq.c|2073| <<blk_mq_free_rqs>> page = list_first_entry(&tags->page_list, struct page, lru);
+	 *   - block/blk-mq.c|2162| <<blk_mq_alloc_rqs>> INIT_LIST_HEAD(&tags->page_list);
+	 *   - block/blk-mq.c|2197| <<blk_mq_alloc_rqs>> list_add_tail(&page->lru, &tags->page_list);
+	 */
 	struct list_head page_list;
 };
 
diff --git a/block/blk-mq.c b/block/blk-mq.c
index ce0f5f4..a276cca 100644
--- a/block/blk-mq.c
+++ b/block/blk-mq.c
@@ -1611,6 +1611,16 @@ void blk_mq_start_stopped_hw_queues(struct request_queue *q, bool async)
 }
 EXPORT_SYMBOL(blk_mq_start_stopped_hw_queues);
 
+/*
+ * 在以下使用:
+ *   - block/blk-mq.c|2353| <<blk_mq_alloc_hctx>> INIT_DELAYED_WORK(&hctx->run_work, blk_mq_run_work_fn);
+ *
+ * 在以下调用:
+ *   - block/blk-mq-sysfs.c|39| <<blk_mq_hw_sysfs_release>> cancel_delayed_work_sync(&hctx->run_work);
+ *   - block/blk-mq.c|1469| <<__blk_mq_delay_run_hw_queue>> kblockd_mod_delayed_work_on(blk_mq_hctx_next_cpu(hctx), &hctx->run_work,
+ *   - block/blk-mq.c|1551| <<blk_mq_stop_hw_queue>> cancel_delayed_work(&hctx->run_work);
+ *   - block/blk-mq.c|1618| <<blk_mq_run_work_fn>> hctx = container_of(work, struct blk_mq_hw_ctx, run_work.work);
+ */
 static void blk_mq_run_work_fn(struct work_struct *work)
 {
 	struct blk_mq_hw_ctx *hctx;
@@ -2041,6 +2051,14 @@ static blk_qc_t blk_mq_make_request(struct request_queue *q, struct bio *bio)
 	return cookie;
 }
 
+/*
+ * called by:
+ *   - block/blk-mq-sched.c|453| <<blk_mq_sched_free_tags>> blk_mq_free_rqs(set, hctx->sched_tags, hctx_idx);
+ *   - block/blk-mq-sched.c|562| <<blk_mq_sched_free_requests>> blk_mq_free_rqs(q->tag_set, hctx->sched_tags, i);
+ *   - block/blk-mq-tag.c|505| <<blk_mq_tag_update_depth>> blk_mq_free_rqs(set, *tagsptr, hctx->queue_num);
+ *   - block/blk-mq.c|2224| <<blk_mq_alloc_rqs>> blk_mq_free_rqs(set, tags, hctx_idx);
+ *   - block/blk-mq.c|2473| <<blk_mq_free_map_and_requests>> blk_mq_free_rqs(set, set->tags[hctx_idx], hctx_idx);
+ */
 void blk_mq_free_rqs(struct blk_mq_tag_set *set, struct blk_mq_tags *tags,
 		     unsigned int hctx_idx)
 {
@@ -2429,10 +2447,18 @@ static void blk_mq_init_cpu_queues(struct request_queue *q,
 	}
 }
 
+/*
+ * called by:
+ *   - block/blk-mq.c|2488| <<blk_mq_map_swqueue>> !__blk_mq_alloc_rq_map(set, hctx_idx)) {
+ *   - block/blk-mq.c|2955| <<__blk_mq_alloc_rq_maps>> if (!__blk_mq_alloc_rq_map(set, i))
+ */
 static bool __blk_mq_alloc_rq_map(struct blk_mq_tag_set *set, int hctx_idx)
 {
 	int ret = 0;
 
+	/*
+	 * struct blk_mq_tags **tags;
+	 */
 	set->tags[hctx_idx] = blk_mq_alloc_rq_map(set, hctx_idx,
 					set->queue_depth, set->reserved_tags);
 	if (!set->tags[hctx_idx])
diff --git a/block/blk-mq.h b/block/blk-mq.h
index 633a5a7..850fd7d 100644
--- a/block/blk-mq.h
+++ b/block/blk-mq.h
@@ -149,6 +149,15 @@ static inline struct blk_mq_ctx *__blk_mq_get_ctx(struct request_queue *q,
  * care about preemption, since we know the ctx's are persistent. This does
  * mean that we can't rely on ctx always matching the currently running CPU.
  */
+/*
+ * called by:
+ *   - block/blk-mq-sched.c|324| <<__blk_mq_sched_bio_merge>> struct blk_mq_ctx *ctx = blk_mq_get_ctx(q);
+ *   - block/blk-mq-tag.c|172| <<blk_mq_get_tag>> data->ctx = blk_mq_get_ctx(data->q);
+ *   - block/blk-mq.c|363| <<blk_mq_get_request>> data->ctx = blk_mq_get_ctx(q);
+ *   - block/kyber-iosched.c|568| <<kyber_bio_merge>> struct blk_mq_ctx *ctx = blk_mq_get_ctx(hctx->queue);
+ *
+ * 这个函数会通过get_cpu()来disable preemption
+ */
 static inline struct blk_mq_ctx *blk_mq_get_ctx(struct request_queue *q)
 {
 	return __blk_mq_get_ctx(q, get_cpu());
diff --git a/drivers/nvme/host/pci.c b/drivers/nvme/host/pci.c
index 524d6bd..db63737 100644
--- a/drivers/nvme/host/pci.c
+++ b/drivers/nvme/host/pci.c
@@ -2464,6 +2464,10 @@ static void nvme_pci_free_ctrl(struct nvme_ctrl *ctrl)
 	kfree(dev);
 }
 
+/*
+ * called by only:
+ *   - drivers/nvme/host/pci.c|2600| <<nvme_reset_work>> nvme_remove_dead_ctrl(dev, result);
+ */
 static void nvme_remove_dead_ctrl(struct nvme_dev *dev, int status)
 {
 	dev_warn(dev->ctrl.device, "Removing after probe failure status: %d\n", status);
diff --git a/drivers/scsi/hosts.c b/drivers/scsi/hosts.c
index ff0d8c6..c5b19fe 100644
--- a/drivers/scsi/hosts.c
+++ b/drivers/scsi/hosts.c
@@ -365,6 +365,9 @@ static struct device_type scsi_host_type = {
  * Return value:
  * 	Pointer to a new Scsi_Host
  **/
+/*
+ * 会把分配的Scsi_Host->hostt设置为参数的struct scsi_host_template
+ */
 struct Scsi_Host *scsi_host_alloc(struct scsi_host_template *sht, int privsize)
 {
 	struct Scsi_Host *shost;
diff --git a/drivers/scsi/scsi_scan.c b/drivers/scsi/scsi_scan.c
index 058079f..c7dab87 100644
--- a/drivers/scsi/scsi_scan.c
+++ b/drivers/scsi/scsi_scan.c
@@ -1819,6 +1819,10 @@ static void do_scsi_scan_host(struct Scsi_Host *shost)
 	}
 }
 
+/*
+ * used only by:
+ *   - drivers/scsi/scsi_scan.c|1855| <<scsi_scan_host>> async_schedule(do_scan_async, data);
+ */
 static void do_scan_async(void *_data, async_cookie_t c)
 {
 	struct async_scan_data *data = _data;
diff --git a/drivers/scsi/sd.c b/drivers/scsi/sd.c
index a3406bd..3e447bd 100644
--- a/drivers/scsi/sd.c
+++ b/drivers/scsi/sd.c
@@ -563,7 +563,20 @@ static const struct dev_pm_ops sd_pm_ops = {
 	.runtime_resume		= sd_resume,
 };
 
+/*
+ * used by:
+ *   - drivers/scsi/sd.c|3381| <<sd_probe>> sdkp->driver = &sd_template;
+ *   - drivers/scsi/sd.c|3677| <<init_sd>> err = scsi_register_driver(&sd_template.gendrv);
+ *   - drivers/scsi/sd.c|3711| <<exit_sd>> scsi_unregister_driver(&sd_template.gendrv);
+ */
 static struct scsi_driver sd_template = {
+	/*
+	 * used by:
+	 *   - drivers/scsi/sd.c|3677| <<init_sd>> err = scsi_register_driver(&sd_template.gendrv);
+	 *   - drivers/scsi/sd.c|3711| <<exit_sd>> scsi_unregister_driver(&sd_template.gendrv);
+	 *
+	 * 这个struct device_driver被挂在struct bus_type scsi_bus_type
+	 */
 	.gendrv = {
 		.name		= "sd",
 		.owner		= THIS_MODULE,
@@ -572,6 +585,10 @@ static struct scsi_driver sd_template = {
 		.shutdown	= sd_shutdown,
 		.pm		= &sd_pm_ops,
 	},
+	/*
+	 * called by:
+	 *   - drivers/scsi/scsi_scan.c|1524| <<scsi_rescan_device>> drv->rescan(dev);
+	 */
 	.rescan			= sd_rescan,
 	.init_command		= sd_init_command,
 	.uninit_command		= sd_uninit_command,
@@ -3255,6 +3272,10 @@ static int sd_format_disk_name(char *prefix, int index, char *buf, int buflen)
 /*
  * The asynchronous part of sd_probe
  */
+/*
+ * called by only:
+ *   - drivers/scsi/sd.c|3408| <<sd_probe>> async_schedule_domain(sd_probe_async, sdkp, &scsi_sd_probe_domain);
+ */
 static void sd_probe_async(void *data, async_cookie_t cookie)
 {
 	struct scsi_disk *sdkp = data;
@@ -3361,6 +3382,7 @@ static int sd_probe(struct device *dev)
 	if (!sdkp)
 		goto out;
 
+	/* 分配gendisk? */
 	gd = alloc_disk(SD_MINORS);
 	if (!gd)
 		goto out_free;
diff --git a/drivers/scsi/virtio_scsi.c b/drivers/scsi/virtio_scsi.c
index 13f1b3b..a80e52f 100644
--- a/drivers/scsi/virtio_scsi.c
+++ b/drivers/scsi/virtio_scsi.c
@@ -379,6 +379,10 @@ static void virtscsi_event_done(struct virtqueue *vq)
  * @req_size	: size of the request buffer
  * @resp_size	: size of the response buffer
  */
+/*
+ * called by only:
+ *   - drivers/scsi/virtio_scsi.c|436| <<virtscsi_kick_cmd>> err = virtscsi_add_cmd(vq->vq, cmd, req_size, resp_size);
+ */
 static int virtscsi_add_cmd(struct virtqueue *vq,
 			    struct virtio_scsi_cmd *cmd,
 			    size_t req_size, size_t resp_size)
@@ -424,6 +428,11 @@ static int virtscsi_add_cmd(struct virtqueue *vq,
 	return virtqueue_add_sgs(vq, sgs, out_num, in_num, cmd, GFP_ATOMIC);
 }
 
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|531| <<virtscsi_queuecommand>> ret = virtscsi_kick_cmd(req_vq, cmd, req_size, sizeof(cmd->resp.cmd));
+ *   - drivers/scsi/virtio_scsi.c|549| <<virtscsi_tmf>> if (virtscsi_kick_cmd(&vscsi->ctrl_vq, cmd,
+ */
 static int virtscsi_kick_cmd(struct virtio_scsi_vq *vq,
 			     struct virtio_scsi_cmd *cmd,
 			     size_t req_size, size_t resp_size)
@@ -671,6 +680,10 @@ static enum blk_eh_timer_return virtscsi_eh_timed_out(struct scsi_cmnd *scmnd)
 	return BLK_EH_RESET_TIMER;
 }
 
+/*
+ * used by only:
+ *   - drivers/scsi/virtio_scsi.c|806| <<virtscsi_probe>> shost = scsi_host_alloc(&virtscsi_host_template,
+ */
 static struct scsi_host_template virtscsi_host_template = {
 	.module = THIS_MODULE,
 	.name = "Virtio SCSI HBA",
@@ -773,6 +786,12 @@ static int virtscsi_init(struct virtio_device *vdev,
 	return err;
 }
 
+/*
+ * 初始化一个scsi的大概流程:
+ * 1. scsi_host_alloc()
+ * 2. scsi_add_host()
+ * 3. scsi_scan_host()
+ */
 static int virtscsi_probe(struct virtio_device *vdev)
 {
 	struct Scsi_Host *shost;
@@ -794,6 +813,9 @@ static int virtscsi_probe(struct virtio_device *vdev)
 
 	num_targets = virtscsi_config_get(vdev, max_target) + 1;
 
+	/*
+	 * 会把分配的Scsi_Host->hostt设置为参数的struct scsi_host_template
+	 */
 	shost = scsi_host_alloc(&virtscsi_host_template,
 		sizeof(*vscsi) + sizeof(vscsi->req_vqs[0]) * num_queues);
 	if (!shost)
diff --git a/include/linux/blk-mq.h b/include/linux/blk-mq.h
index 15d1aa5..18126e0 100644
--- a/include/linux/blk-mq.h
+++ b/include/linux/blk-mq.h
@@ -218,12 +218,38 @@ struct blk_mq_ops {
 
 enum {
 	BLK_MQ_F_SHOULD_MERGE	= 1 << 0,
+	/*
+	 * 在以下设置或者清除BLK_MQ_F_TAG_SHARED:
+	 *   - block/blk-mq.c|2581| <<queue_set_hctx_shared>> hctx->flags |= BLK_MQ_F_TAG_SHARED;
+	 *   - block/blk-mq.c|2627| <<blk_mq_add_queue_tag_set>> set->flags |= BLK_MQ_F_TAG_SHARED;
+	 *   - block/blk-mq.c|2357| <<blk_mq_alloc_hctx>> hctx->flags = set->flags & ~BLK_MQ_F_TAG_SHARED;
+	 *   - block/blk-mq.c|2583| <<queue_set_hctx_shared>> hctx->flags &= ~BLK_MQ_F_TAG_SHARED;
+	 *   - block/blk-mq.c|2609| <<blk_mq_del_queue_tag_set>> set->flags &= ~BLK_MQ_F_TAG_SHARED;
+	 *
+	 * 在以下使用BLK_MQ_F_TAG_SHARED:
+	 *   - block/blk-mq-tag.c|75| <<hctx_may_queue>> if (!hctx || !(hctx->flags & BLK_MQ_F_TAG_SHARED))
+	 *   - block/blk-mq-tag.h|58| <<blk_mq_tag_busy>> if (!(hctx->flags & BLK_MQ_F_TAG_SHARED))
+	 *   - block/blk-mq-tag.h|66| <<blk_mq_tag_idle>> if (!(hctx->flags & BLK_MQ_F_TAG_SHARED))
+	 *   - block/blk-mq.c|304| <<blk_mq_rq_ctx_init>> if (data->hctx->flags & BLK_MQ_F_TAG_SHARED) {
+	 *   - block/blk-mq.c|1111| <<blk_mq_mark_tag_wait>> if (!(hctx->flags & BLK_MQ_F_TAG_SHARED)) {
+	 *   - block/blk-mq.c|1242| <<blk_mq_dispatch_rq_list>> if (hctx->flags & BLK_MQ_F_TAG_SHARED)
+	 *   - block/blk-mq.c|2626| <<blk_mq_add_queue_tag_set>> !(set->flags & BLK_MQ_F_TAG_SHARED)) {
+	 *   - block/blk-mq.c|2631| <<blk_mq_add_queue_tag_set>> if (set->flags & BLK_MQ_F_TAG_SHARED)
+	 */
 	BLK_MQ_F_TAG_SHARED	= 1 << 1,
 	BLK_MQ_F_BLOCKING	= 1 << 5,
 	BLK_MQ_F_NO_SCHED	= 1 << 6,
 	BLK_MQ_F_ALLOC_POLICY_START_BIT = 8,
 	BLK_MQ_F_ALLOC_POLICY_BITS = 1,
 
+	/*
+	 * 在以下使用:
+	 *   - block/blk-mq.c|1553| <<blk_mq_stop_hw_queue>> set_bit(BLK_MQ_S_STOPPED, &hctx->state);
+	 *   - block/blk-mq.c|1578| <<blk_mq_start_hw_queue>> clear_bit(BLK_MQ_S_STOPPED, &hctx->state);
+	 *   - block/blk-mq.c|1599| <<blk_mq_start_stopped_hw_queue>> clear_bit(BLK_MQ_S_STOPPED, &hctx->state);
+	 *   - block/blk-mq.c|1623| <<blk_mq_run_work_fn>> if (test_bit(BLK_MQ_S_STOPPED, &hctx->state))
+	 *   - block/blk-mq.h|184| <<blk_mq_hctx_stopped>> return test_bit(BLK_MQ_S_STOPPED, &hctx->state);
+	 */
 	BLK_MQ_S_STOPPED	= 0,
 	BLK_MQ_S_TAG_ACTIVE	= 1,
 	BLK_MQ_S_SCHED_RESTART	= 2,
diff --git a/include/linux/dma-mapping.h b/include/linux/dma-mapping.h
index 6309a72..a5c3d48 100644
--- a/include/linux/dma-mapping.h
+++ b/include/linux/dma-mapping.h
@@ -697,6 +697,13 @@ static inline void arch_teardown_dma_ops(struct device *dev)
 }
 #endif /* CONFIG_ARCH_HAS_TEARDOWN_DMA_OPS */
 
+/*
+ * x86下调用的几个例子:
+ *   - arch/x86/kernel/amd_gart_64.c|397| <<gart_map_sg>> max_seg_size = dma_get_max_seg_size(dev);
+ *   - drivers/iommu/dma-iommu.c|702| <<__finalise_sg>> unsigned int cur_len = 0, max_len = dma_get_max_seg_size(dev);
+ *   - kernel/dma/debug.c|349| <<bucket_find_contain>> unsigned int max_range = dma_get_max_seg_size(ref->dev);
+ *   - kernel/dma/debug.c|1212| <<check_sg_segment>> unsigned int max_seg = dma_get_max_seg_size(dev);
+ */
 static inline unsigned int dma_get_max_seg_size(struct device *dev)
 {
 	if (dev->dma_parms && dev->dma_parms->max_segment_size)
@@ -707,6 +714,12 @@ static inline unsigned int dma_get_max_seg_size(struct device *dev)
 static inline int dma_set_max_seg_size(struct device *dev, unsigned int size)
 {
 	if (dev->dma_parms) {
+		/*
+		 * 只在下面使用:
+		 *   - include/linux/dma-mapping.h|702| <<dma_get_max_seg_size>> if (dev->dma_parms && dev->dma_parms->max_segment_size)
+		 *   - include/linux/dma-mapping.h|703| <<dma_get_max_seg_size>> return dev->dma_parms->max_segment_size;
+		 *   - include/linux/dma-mapping.h|710| <<dma_set_max_seg_size>> dev->dma_parms->max_segment_size = size;
+		 */
 		dev->dma_parms->max_segment_size = size;
 		return 0;
 	}
diff --git a/include/linux/irq.h b/include/linux/irq.h
index fb301cf..cf4414e 100644
--- a/include/linux/irq.h
+++ b/include/linux/irq.h
@@ -225,6 +225,13 @@ enum {
 	IRQD_IRQ_INPROGRESS		= (1 << 18),
 	IRQD_WAKEUP_ARMED		= (1 << 19),
 	IRQD_FORWARDED_TO_VCPU		= (1 << 20),
+	/*
+	 * 在以下设置:
+	 *   - kernel/irq/irqdesc.c|474| <<alloc_descs>> flags = IRQD_AFFINITY_MANAGED |
+	 *
+	 * 在以下使用:
+	 *   - include/linux/irq.h|350| <<irqd_affinity_is_managed>> return __irqd_to_state(d) & IRQD_AFFINITY_MANAGED;
+	 */
 	IRQD_AFFINITY_MANAGED		= (1 << 21),
 	IRQD_IRQ_STARTED		= (1 << 22),
 	IRQD_MANAGED_SHUTDOWN		= (1 << 23),
diff --git a/kernel/irq/matrix.c b/kernel/irq/matrix.c
index 30cc217..ea7e885 100644
--- a/kernel/irq/matrix.c
+++ b/kernel/irq/matrix.c
@@ -374,6 +374,10 @@ void irq_matrix_remove_reserved(struct irq_matrix *m)
  * @reserved:	Allocate previously reserved interrupts
  * @mapped_cpu: Pointer to store the CPU for which the irq was allocated
  */
+/*
+ * called by:
+ *   - arch/x86/kernel/apic/vector.c|250| <<assign_vector_locked>> vector = irq_matrix_alloc(vector_matrix, dest, resvd, &cpu);
+ */
 int irq_matrix_alloc(struct irq_matrix *m, const struct cpumask *msk,
 		     bool reserved, unsigned int *mapped_cpu)
 {
-- 
2.7.4

