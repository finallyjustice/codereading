From da97d16c3506e0aa54eda48632c58e795e1df362 Mon Sep 17 00:00:00 2001
From: Dongli Zhang <dongli.zhang0129@gmail.com>
Date: Fri, 17 May 2019 20:14:46 +0800
Subject: [PATCH 1/1] linux-xen-interface-for-linux-4.9.168

xen specific interface linux-4.9.168

Signed-off-by: Dongli Zhang <dongli.zhang0129@gmail.com>
---
 arch/x86/include/asm/dma-mapping.h   |   4 +
 arch/x86/kernel/pci-swiotlb.c        |  67 ++++
 arch/x86/pci/xen.c                   | 590 ++++++++++++++++++++++++++++++
 arch/x86/xen/enlighten.c             |   8 +
 arch/x86/xen/irq.c                   |  53 +++
 arch/x86/xen/pci-swiotlb-xen.c       |  27 ++
 arch/x86/xen/platform-pci-unplug.c   |   5 +
 arch/x86/xen/smp.c                   |   4 +
 arch/x86/xen/spinlock.c              |  17 +
 arch/x86/xen/xen-asm_64.S            |   4 +
 drivers/block/xen-blkback/blkback.c  |  99 +++++
 drivers/block/xen-blkback/common.h   |  25 ++
 drivers/block/xen-blkfront.c         |  60 +++
 drivers/nvme/host/pci.c              |  32 ++
 drivers/xen/events/events_base.c     | 684 +++++++++++++++++++++++++++++++++++
 drivers/xen/events/events_internal.h |  13 +
 drivers/xen/pci.c                    |  29 ++
 drivers/xen/swiotlb-xen.c            | 348 +++++++++++++++++-
 drivers/xen/xenbus/xenbus_probe.c    |  17 +
 include/linux/device.h               |   2 +
 include/linux/dma-direction.h        |   8 +
 include/linux/dma-mapping.h          |  60 +++
 kernel/irq/chip.c                    |  10 +
 kernel/irq/manage.c                  |  90 +++++
 kernel/sched/core.c                  |   5 +
 lib/iommu-helper.c                   |  12 +
 lib/swiotlb.c                        | 470 +++++++++++++++++++++++-
 27 files changed, 2741 insertions(+), 2 deletions(-)

diff --git a/arch/x86/include/asm/dma-mapping.h b/arch/x86/include/asm/dma-mapping.h
index 4446162..55d09e2 100644
--- a/arch/x86/include/asm/dma-mapping.h
+++ b/arch/x86/include/asm/dma-mapping.h
@@ -85,6 +85,10 @@ dma_cache_sync(struct device *dev, void *vaddr, size_t size,
 	flush_write_buffers();
 }
 
+/*
+ * 如果dev->coherent_dma_mask已经有了就返回dev->coherent_dma_mask
+ * 否则根据gfp决定是DMA_BIT_MASK(24)还是DMA_BIT_MASK(32)
+ */
 static inline unsigned long dma_alloc_coherent_mask(struct device *dev,
 						    gfp_t gfp)
 {
diff --git a/arch/x86/kernel/pci-swiotlb.c b/arch/x86/kernel/pci-swiotlb.c
index 8da13d4..da7ad6e 100644
--- a/arch/x86/kernel/pci-swiotlb.c
+++ b/arch/x86/kernel/pci-swiotlb.c
@@ -12,8 +12,23 @@
 #include <asm/dma.h>
 #include <asm/xen/swiotlb-xen.h>
 #include <asm/iommu_table.h>
+/*
+ * 在以下修改swiotlb:
+ *   - arch/x86/kernel/amd_gart_64.c|853| <<gart_iommu_init>> swiotlb = 0;
+ *   - arch/x86/kernel/pci-dma.c|195| <<iommu_setup>> swiotlb = 1;
+ *   - arch/x86/kernel/pci-swiotlb.c|74| <<pci_swiotlb_detect_override>> swiotlb = 1;
+ *   - arch/x86/kernel/pci-swiotlb.c|92| <<pci_swiotlb_detect_4gb>> swiotlb = 1;
+ *   - arch/x86/kernel/tboot.c|528| <<tboot_force_iommu>> swiotlb = 0;
+ *   - arch/x86/xen/pci-swiotlb-xen.c|58| <<pci_xen_swiotlb_detect>> swiotlb = 0;
+ *   - drivers/iommu/amd_iommu.c|2869| <<amd_iommu_init_dma_ops>> swiotlb = iommu_pass_through ? 1 : 0;
+ *   - drivers/iommu/intel-iommu.c|4883| <<intel_iommu_init>> swiotlb = 0;
+ */
 int swiotlb __read_mostly;
 
+/*
+ * called by:
+ *   - include/linux/dma-mapping.h|467| <<dma_alloc_attrs>> cpu_addr = ops->alloc(dev, size, dma_handle, flag, attrs);
+ */
 void *x86_swiotlb_alloc_coherent(struct device *hwdev, size_t size,
 					dma_addr_t *dma_handle, gfp_t flags,
 					unsigned long attrs)
@@ -66,8 +81,28 @@ static struct dma_map_ops swiotlb_dma_ops = {
  * This returns non-zero if we are forced to use swiotlb (by the boot
  * option).
  */
+/*
+ * [0] pci_swiotlb_detect_override
+ * [0] pci_iommu_alloc
+ * [0] mem_init
+ * [0] start_kernel
+ * [0] secondary_startup_64
+ *
+ * 被IOMMU_INIT()和IOMMU_INIT_FINISH()使用
+ */
 int __init pci_swiotlb_detect_override(void)
 {
+	/*
+	 * 在以下修改swiotlb:
+	 *   - arch/x86/kernel/amd_gart_64.c|853| <<gart_iommu_init>> swiotlb = 0;
+	 *   - arch/x86/kernel/pci-dma.c|195| <<iommu_setup>> swiotlb = 1;
+	 *   - arch/x86/kernel/pci-swiotlb.c|74| <<pci_swiotlb_detect_override>> swiotlb = 1;
+	 *   - arch/x86/kernel/pci-swiotlb.c|92| <<pci_swiotlb_detect_4gb>> swiotlb = 1;
+	 *   - arch/x86/kernel/tboot.c|528| <<tboot_force_iommu>> swiotlb = 0;
+	 *   - arch/x86/xen/pci-swiotlb-xen.c|58| <<pci_xen_swiotlb_detect>> swiotlb = 0;
+	 *   - drivers/iommu/amd_iommu.c|2869| <<amd_iommu_init_dma_ops>> swiotlb = iommu_pass_through ? 1 : 0;
+	 *   - drivers/iommu/intel-iommu.c|4883| <<intel_iommu_init>> swiotlb = 0;
+	 */
 	int use_swiotlb = swiotlb | swiotlb_force;
 
 	if (swiotlb_force == SWIOTLB_FORCE)
@@ -84,10 +119,27 @@ IOMMU_INIT_FINISH(pci_swiotlb_detect_override,
  * if 4GB or more detected (and iommu=off not set) return 1
  * and set swiotlb to 1.
  */
+/*
+ * [0] pci_swiotlb_detect_4gb
+ * [0] pci_iommu_alloc
+ * [0] mem_init
+ * [0] start_kernel
+ * [0] secondary_startup_64
+ *
+ * 在kvm上此时swiotlb是0
+ */
 int __init pci_swiotlb_detect_4gb(void)
 {
 	/* don't initialize swiotlb if iommu=off (no_iommu=1) */
 #ifdef CONFIG_X86_64
+	/*
+	 * 在KVM的guest上:
+	 * no_iommu=0, max_possible_pfn=1542144, MAX_DMA32_PFN=1048576
+	 * 所以这里swiotlb设置为1
+	 *
+	 * pci_swiotlb_init()也调用了
+	 * 否则应该不会调用pci_swiotlb_init()
+	 */
 	if (!no_iommu && max_possible_pfn > MAX_DMA32_PFN)
 		swiotlb = 1;
 #endif
@@ -98,6 +150,13 @@ IOMMU_INIT(pci_swiotlb_detect_4gb,
 	   pci_swiotlb_init,
 	   pci_swiotlb_late_init);
 
+/*
+ * [0] pci_swiotlb_init
+ * [0] pci_iommu_alloc
+ * [0] mem_init
+ * [0] start_kernel
+ * [0] secondary_startup_64
+ */
 void __init pci_swiotlb_init(void)
 {
 	if (swiotlb) {
@@ -106,6 +165,14 @@ void __init pci_swiotlb_init(void)
 	}
 }
 
+/*
+ * [0] pci_swiotlb_late_init
+ * [0] pci_iommu_init
+ * [0] do_one_initcall
+ * [0] kernel_init_freeable
+ * [0] kernel_init
+ * [0] ret_from_fork
+ */
 void __init pci_swiotlb_late_init(void)
 {
 	/* An IOMMU turned us off. */
diff --git a/arch/x86/pci/xen.c b/arch/x86/pci/xen.c
index 4ea9f29..d3ed1f7 100644
--- a/arch/x86/pci/xen.c
+++ b/arch/x86/pci/xen.c
@@ -27,6 +27,63 @@
 #include <asm/apic.h>
 #include <asm/i8259.h>
 
+/*
+ * 下面主要是xen hypervisor的部分,
+ * 核心思想: xen有自己的irq, linux有自己的irq, pirq是domain相关的, linux和xen都认识
+ *
+ * 在arch/x86/x86_64/entry.S,
+ * autogen_entrypoints生成vector table, 每一个vector指向一个处理函数
+ * 函数都差不多 (每个cpu支持256个vector):
+ *
+ * 先"movb  $vec,4(%rsp)", 再"jmp   common_interrupt"
+ *
+ * 在arch/x86/x86_64/entry.S:
+ * 392 ENTRY(common_interrupt)
+ * 393         SAVE_ALL CLAC
+ * 394         CR4_PV32_RESTORE
+ * 395         movq %rsp,%rdi
+ * 396         callq do_IRQ
+ * 397         jmp ret_from_intr
+ *
+ * do_IRQ()如何把vector发送到guest?
+ *
+ * 1. 先通过vector查找percpu的vector_irq[vector]找到irq:
+ * int irq = __get_cpu_var(vector_irq[vector]);
+ *
+ * 2. 再通过irq找到对应的struct irq_desc, x86下就是&irq_desc[irq]:
+ * desc = irq_to_desc(irq);
+ *
+ * 3. 很可能desc->status & IRQ_GUEST是true, 就要调用__do_IRQ_guest(irq)了
+ *
+ * 4. 如果是dom0, 调用send_guest_pirq()往dom0插入event
+ *
+ *
+ * 重要的函数或者数据结构:
+ *
+ * - vector_irq[vector]: 把cpu的vector转换成irq, 索引&irq_desc[irq]
+ * - domain_irq_to_pirq(d, irq)负责将xen的irq转换成某个domain d的pirq
+ * - pirq_info(d, pirq)负责将某个domain d的pirq转换成'struct pirq'
+ *
+ * struct pirq {
+ *   int pirq;
+ *   u16 evtchn;
+ *   bool_t masked;
+ *   struct rcu_head rcu_head;
+ *   struct arch_pirq arch;
+ * };
+ *
+ * dom0 linux的核心函数感觉是__startup_pirq()
+ *
+ * xen有自己的irq, linux有自己的irq, pirq是domain相关的, linux和xen都认识
+ */
+
+/*
+ * used by:
+ *   - arch/x86/pci/xen.c|437| <<pci_xen_init>> pcibios_enable_irq = xen_pcifront_enable_irq;
+ *
+ * pcibios_enable_irq只在以下调用:
+ *   - arch/x86/pci/common.c|728| <<pcibios_enable_device>> return pcibios_enable_irq(dev);
+ */
 static int xen_pcifront_enable_irq(struct pci_dev *dev)
 {
 	int rc;
@@ -59,6 +116,356 @@ static int xen_pcifront_enable_irq(struct pci_dev *dev)
 }
 
 #ifdef CONFIG_ACPI
+/*
+ * orabug: xen_register_pirq(), gsi=1, gsi_override=-1, triggering=1, set_pirq=1
+ * xen: --> pirq=1 -> irq=1 (gsi=1)
+ * orabug: xen_register_pirq(), gsi=2, gsi_override=-1, triggering=1, set_pirq=1
+ * xen: --> pirq=2 -> irq=2 (gsi=2)
+ * orabug: xen_register_pirq(), gsi=3, gsi_override=-1, triggering=1, set_pirq=1
+ * xen: --> pirq=3 -> irq=3 (gsi=3)
+ * orabug: xen_register_pirq(), gsi=4, gsi_override=-1, triggering=1, set_pirq=1
+ * xen: --> pirq=4 -> irq=4 (gsi=4)
+ * orabug: xen_register_pirq(), gsi=5, gsi_override=-1, triggering=1, set_pirq=1
+ * xen: --> pirq=5 -> irq=5 (gsi=5)
+ * orabug: xen_register_pirq(), gsi=6, gsi_override=-1, triggering=1, set_pirq=1
+ * xen: --> pirq=6 -> irq=6 (gsi=6)
+ * orabug: xen_register_pirq(), gsi=7, gsi_override=-1, triggering=1, set_pirq=1
+ * xen: --> pirq=7 -> irq=7 (gsi=7)
+ * orabug: xen_register_pirq(), gsi=8, gsi_override=-1, triggering=1, set_pirq=1
+ * xen: --> pirq=8 -> irq=8 (gsi=8)
+ * orabug: xen_register_pirq(), gsi=9, gsi_override=-1, triggering=0, set_pirq=1
+ * xen: --> pirq=9 -> irq=9 (gsi=9)
+ * orabug: xen_register_pirq(), gsi=10, gsi_override=-1, triggering=1, set_pirq=1
+ * xen: --> pirq=10 -> irq=10 (gsi=10)
+ * orabug: xen_register_pirq(), gsi=11, gsi_override=-1, triggering=1, set_pirq=1
+ * xen: --> pirq=11 -> irq=11 (gsi=11)
+ * orabug: xen_register_pirq(), gsi=12, gsi_override=-1, triggering=1, set_pirq=1
+ * xen: --> pirq=12 -> irq=12 (gsi=12)
+ * orabug: xen_register_pirq(), gsi=13, gsi_override=-1, triggering=1, set_pirq=1
+ * xen: --> pirq=13 -> irq=13 (gsi=13)
+ * orabug: xen_register_pirq(), gsi=14, gsi_override=-1, triggering=1, set_pirq=1
+ * xen: --> pirq=14 -> irq=14 (gsi=14)
+ * orabug: xen_register_pirq(), gsi=15, gsi_override=-1, triggering=1, set_pirq=1
+ * xen: --> pirq=15 -> irq=15 (gsi=15)
+ * [0] xen_register_pirq.constprop.8
+ * [0] pci_xen_initial_domain
+ * [0] xen_init_IRQ
+ * [0] init_IRQ
+ * [0] start_kernel
+ * [0] x86_64_start_reservations
+ * [0] xen_start_kernel
+ *
+ * xen: registering gsi 9 triggering 0 polarity 0
+ * orabug: xen_register_pirq(), gsi=9, gsi_override=-1, triggering=0, set_pirq=1
+ * [0] xen_register_pirq.constprop.8
+ * [0] acpi_register_gsi_xen
+ * [0] acpi_gsi_to_irq
+ * [0] acpi_os_install_interrupt_handler
+ * [0] acpi_ev_install_sci_handler
+ * [0] acpi_ev_install_xrupt_handlers
+ * [0] acpi_enable_subsystem
+ * [0] acpi_init
+ * [0] do_one_initcall
+ * [0] kernel_init_freeable
+ * [0] kernel_init
+ * [0] ret_from_fork
+ *
+ * xen: registering gsi 13 triggering 1 polarity 0
+ * orabug: xen_register_pirq(), gsi=13, gsi_override=-1, triggering=1, set_pirq=1
+ * [0] xen_register_pirq.constprop.8
+ * [0] acpi_register_gsi_xen
+ * [0] acpi_register_gsi
+ * [0] acpi_dev_get_irqresource.part.2
+ * [0] acpi_dev_resource_interrupt
+ * [0] acpi_dev_process_resource
+ * [0] acpi_walk_resource_buffer
+ * [0] acpi_walk_resources
+ * [0] acpi_dev_get_resources
+ * [0] acpi_create_platform_device
+ * [0] acpi_default_enumeration
+ * [0] acpi_bus_attach
+ * [0] acpi_bus_attach
+ * [0] acpi_bus_attach
+ * [0] acpi_bus_attach
+ * [0] acpi_bus_attach
+ * [0] acpi_bus_scan
+ * [0] acpi_scan_init
+ * [0] acpi_init
+ * [0] do_one_initcall
+ * [0] kernel_init_freeable
+ * [0] kernel_init
+ * [0] ret_from_fork
+ *
+ * xen: registering gsi 4 triggering 1 polarity 0
+ * orabug: xen_register_pirq(), gsi=4, gsi_override=-1, triggering=1, set_pirq=1
+ * xen: registering gsi 1 triggering 1 polarity 0
+ * orabug: xen_register_pirq(), gsi=1, gsi_override=-1, triggering=1, set_pirq=1
+ * xen: registering gsi 12 triggering 1 polarity 0
+ * orabug: xen_register_pirq(), gsi=12, gsi_override=-1, triggering=1, set_pirq=1
+ * xen: registering gsi 8 triggering 1 polarity 0
+ * orabug: xen_register_pirq(), gsi=8, gsi_override=-1, triggering=1, set_pirq=1
+ * xen: registering gsi 14 triggering 0 polarity 1
+ * orabug: xen_register_pirq(), gsi=14, gsi_override=-1, triggering=0, set_pirq=1
+ * [0] dump_stack
+ * [0] xen_register_pirq.constprop.8
+ * [0] acpi_register_gsi_xen
+ * [0] acpi_register_gsi
+ * [0] acpi_dev_get_irqresource.part.2
+ * [0] acpi_dev_resource_interrupt
+ * [0] pnpacpi_allocated_resource
+ * [0] acpi_walk_resource_buffer
+ * [0] acpi_walk_resources
+ * [0] pnpacpi_parse_allocated_resource
+ * [0] pnpacpi_add_device_handler
+ * [0] acpi_ns_get_device_callback
+ * [0] acpi_ns_walk_namespace
+ * [0] acpi_get_devices
+ * [0] pnpacpi_init
+ * [0] do_one_initcall
+ * [0] kernel_init_freeable
+ * [0] kernel_init
+ * [0] ret_from_fork
+ *
+ * xen: registering gsi 21 triggering 0 polarity 1
+ * orabug: xen_register_pirq(), gsi=21, gsi_override=-1, triggering=0, set_pirq=1
+ * xen: --> pirq=21 -> irq=21 (gsi=21)
+ * [0] xen_register_pirq.constprop.8
+ * [0] acpi_register_gsi_xen
+ * [0] acpi_register_gsi
+ * [0] acpi_pci_irq_enable
+ * [0] pcibios_enable_device
+ * [0] do_pci_enable_device
+ * [0] pci_enable_device_flags
+ * [0] pci_enable_device
+ * [0] quirk_usb_early_handoff
+ * [0] pci_do_fixups
+ * [0] pci_apply_final_quirks
+ * [0] do_one_initcall
+ * [0] kernel_init_freeable
+ * [0] kernel_init
+ * [0] ret_from_fork
+ *
+ * xen: registering gsi 16 triggering 0 polarity 1
+ * orabug: xen_register_pirq(), gsi=16, gsi_override=-1, triggering=0, set_pirq=1
+ * xen: --> pirq=16 -> irq=16 (gsi=16)
+ * xen: registering gsi 16 triggering 0 polarity 1
+ * orabug: xen_register_pirq(), gsi=16, gsi_override=-1, triggering=0, set_pirq=1
+ * Already setup the GSI :16
+ * [0] xen_register_pirq.constprop.8
+ * [0] acpi_register_gsi_xen
+ * [0] acpi_register_gsi
+ * [0] acpi_pci_irq_enable
+ * [0] pcibios_enable_device
+ * [0] do_pci_enable_device
+ * [0] pci_enable_device_flags
+ * [0] pci_enable_device
+ * [0] pcie_port_device_register
+ * [0] pcie_portdrv_probe
+ * [0] local_pci_probe
+ * [0] pci_device_probe
+ * [0] driver_probe_device
+ * [0] __driver_attach
+ * [0] bus_for_each_dev
+ * [0] driver_attach
+ * [0] bus_add_driver
+ * [0] driver_register
+ * [0] __pci_register_driver
+ * [0] pcie_portdrv_init
+ * [0] do_one_initcall
+ * [0] kernel_init_freeable
+ * [0] kernel_init
+ * [0] ret_from_fork
+ *
+ * xen: registering gsi 16 triggering 0 polarity 1
+ * orabug: xen_register_pirq(), gsi=16, gsi_override=-1, triggering=0, set_pirq=1
+ * Already setup the GSI :16
+ * [0] xen_register_pirq.constprop.8
+ * [0] acpi_register_gsi_xen
+ * [0] acpi_register_gsi
+ * [0] acpi_pci_irq_enable
+ * [0] pcibios_enable_device
+ * [0] do_pci_enable_device
+ * [0] pci_enable_device_flags
+ * [0] pci_enable_device
+ * [0] i915_driver_load
+ * [0] i915_pci_probe
+ * [0] local_pci_probe
+ * [0] pci_device_probe
+ * [0] driver_probe_device
+ * [0] __driver_attach
+ * [0] bus_for_each_dev
+ * [0] driver_attach
+ * [0] bus_add_driver
+ * [0] driver_register
+ * [0] __pci_register_driver
+ * [0] i915_init
+ * [0] do_one_initcall
+ * [0] kernel_init_freeable
+ * [0] kernel_init
+ * [0] ret_from_fork
+ *
+ * xen: registering gsi 22 triggering 0 polarity 1
+ * orabug: xen_register_pirq(), gsi=22, gsi_override=-1, triggering=0, set_pirq=1
+ * xen: --> pirq=22 -> irq=22 (gsi=22)
+ * [0] xen_register_pirq.constprop.8
+ * [0] acpi_register_gsi_xen
+ * [0] acpi_register_gsi
+ * [0] acpi_pci_irq_enable
+ * [0] pcibios_enable_device
+ * [0] do_pci_enable_device
+ * [0] pci_enable_device_flags
+ * [0] pcim_enable_device
+ * [0] ahci_init_one
+ * [0] local_pci_probe
+ * [0] pci_device_probe
+ * [0] driver_probe_device
+ * [0] __driver_attach
+ * [0] bus_for_each_dev
+ * [0] driver_attach
+ * [0] bus_add_driver
+ * [0] driver_register
+ * [0] __pci_register_driver
+ * [0] ahci_pci_driver_init
+ * [0] do_one_initcall
+ * [0] kernel_init_freeable
+ * [0] kernel_init
+ * [0] ret_from_fork
+ *
+ * xen: registering gsi 20 triggering 0 polarity 1
+ * orabug: xen_register_pirq(), gsi=20, gsi_override=-1, triggering=0, set_pirq=1
+ * xen: --> pirq=20 -> irq=20 (gsi=20)
+ * [0] xen_register_pirq.constprop.8
+ * [0] acpi_register_gsi_xen
+ * [0] acpi_register_gsi
+ * [0] acpi_pci_irq_enable
+ * [0] pcibios_enable_device
+ * [0] do_pci_enable_device
+ * [0] pci_enable_device_flags
+ * [0] pci_enable_device_mem
+ * [0] e1000_probe
+ * [0] local_pci_probe
+ * [0] pci_device_probe
+ * [0] driver_probe_device
+ * [0] __driver_attach
+ * [0] bus_for_each_dev
+ * [0] driver_attach
+ * [0] bus_add_driver
+ * [0] driver_register
+ * [0] __pci_register_driver
+ * [0] e1000_init_module
+ * [0] do_one_initcall
+ * [0] kernel_init_freeable
+ * [0] kernel_init
+ * [0] ret_from_fork
+ *
+ * xen: registering gsi 23 triggering 0 polarity 1
+ * orabug: xen_register_pirq(), gsi=23, gsi_override=-1, triggering=0, set_pirq=1
+ * xen: --> pirq=23 -> irq=23 (gsi=23)
+ * [0] xen_register_pirq.constprop.8
+ * [0] acpi_register_gsi_xen
+ * [0] acpi_register_gsi
+ * [0] acpi_pci_irq_enable
+ * [0] pcibios_enable_device
+ * [0] do_pci_enable_device
+ * [0] pci_enable_device_flags
+ * [0] pcim_enable_device
+ * [0] i801_probe
+ * [0] local_pci_probe
+ * [0] pci_device_probe
+ * [0] driver_probe_device
+ * [0] __driver_attach
+ * [0] bus_for_each_dev
+ * [0] driver_attach
+ * [0] bus_add_driver
+ * [0] driver_register
+ * [0] __pci_register_driver
+ * [0] i2c_i801_init
+ * [0] do_one_initcall
+ * [0] kernel_init_freeable
+ * [0] kernel_init
+ * [0] ret_from_fork
+ *
+ * xen: registering gsi 21 triggering 0 polarity 1
+ * orabug: xen_register_pirq(), gsi=21, gsi_override=-1, triggering=0, set_pirq=1
+ * Already setup the GSI :21
+ * [0] xen_register_pirq.constprop.8
+ * [0] acpi_register_gsi_xen
+ * [0] acpi_register_gsi
+ * [0] acpi_pci_irq_enable
+ * [0] pcibios_enable_device
+ * [0] do_pci_enable_device
+ * [0] pci_enable_device_flags
+ * [0] pci_enable_device
+ * [0] azx_probe
+ * [0] local_pci_probe
+ * [0] pci_device_probe
+ * [0] driver_probe_device
+ * [0] __driver_attach
+ * [0] bus_for_each_dev
+ * [0] driver_attach
+ * [0] bus_add_driver
+ * [0] driver_register
+ * [0] __pci_register_driver
+ * [0] azx_driver_init
+ * [0] do_one_initcall
+ * [0] kernel_init_freeable
+ * [0] kernel_init
+ * [0] ret_from_fork
+ *
+ * xen: registering gsi 16 triggering 0 polarity 1
+ * orabug: xen_register_pirq(), gsi=16, gsi_override=-1, triggering=0, set_pirq=1
+ * Already setup the GSI :16
+ * [0] xen_register_pirq.constprop.8
+ * [0] acpi_register_gsi_xen
+ * [0] acpi_register_gsi
+ * [0] acpi_pci_irq_enable
+ * [0] pcibios_enable_device
+ * [0] do_pci_enable_device
+ * [0] pci_enable_device_flags
+ * [0] pci_enable_device_mem
+ * [0] nvme_reset_work [nvme]
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * xen: registering gsi 16 triggering 0 polarity 1
+ * orabug: xen_register_pirq(), gsi=16, gsi_override=-1, triggering=0, set_pirq=1
+ * Already setup the GSI :16
+ * xen: registering gsi 17 triggering 0 polarity 1
+ * orabug: xen_register_pirq(), gsi=17, gsi_override=-1, triggering=0, set_pirq=1
+ * xen: --> pirq=17 -> irq=17 (gsi=17)
+ * [0] xen_register_pirq.constprop.8
+ * [0] acpi_register_gsi_xen
+ * [0] acpi_register_gsi
+ * [0] acpi_pci_irq_enable
+ * [0] pcibios_enable_device
+ * [0] do_pci_enable_device
+ * [0] pci_enable_device_flags
+ * [0] pci_enable_device_mem
+ * [0] igb_probe [igb]
+ * [0] local_pci_probe
+ * [0] pci_device_probe
+ * [0] driver_probe_device
+ * [0] __driver_attach
+ * [0] bus_for_each_dev
+ * [0] driver_attach
+ * [0] bus_add_driver
+ * [0] driver_register
+ * [0] __pci_register_driver
+ * [0] igb_init_module [igb]
+ * [0] do_one_initcall
+ * [0] do_init_module
+ * [0] load_module
+ * [0] SYSC_finit_module
+ * [0] SyS_finit_module
+ * [0] do_syscall_64
+ *
+ * called by:
+ *   - arch/x86/pci/xen.c|114| <<acpi_register_gsi_xen_hvm>> return xen_register_pirq(gsi, -1 , trigger,
+ *   - arch/x86/pci/xen.c|130| <<xen_register_gsi>> irq = xen_register_pirq(gsi, gsi_override, triggering, true);
+ *   - arch/x86/pci/xen.c|495| <<pci_xen_initial_domain>> xen_register_pirq(irq, -1 ,
+ */
 static int xen_register_pirq(u32 gsi, int gsi_override, int triggering,
 			     bool set_pirq)
 {
@@ -105,6 +512,10 @@ static int xen_register_pirq(u32 gsi, int gsi_override, int triggering,
 	return irq;
 }
 
+/*
+ * used by:
+ *   - arch/x86/pci/xen.c|494| <<pci_xen_hvm_init>> __acpi_register_gsi = acpi_register_gsi_xen_hvm;
+ */
 static int acpi_register_gsi_xen_hvm(struct device *dev, u32 gsi,
 				     int trigger, int polarity)
 {
@@ -116,6 +527,10 @@ static int acpi_register_gsi_xen_hvm(struct device *dev, u32 gsi,
 }
 
 #ifdef CONFIG_XEN_DOM0
+/*
+ * used by:
+ *   - arch/x86/pci/xen.c|156| <<acpi_register_gsi_xen>> return xen_register_gsi(gsi, -1 , trigger, polarity);
+ */
 static int xen_register_gsi(u32 gsi, int gsi_override, int triggering, int polarity)
 {
 	int rc, irq;
@@ -144,6 +559,13 @@ static int xen_register_gsi(u32 gsi, int gsi_override, int triggering, int polar
 	return irq;
 }
 
+/*
+ * used by:
+ *   - arch/x86/pci/xen.c|523| <<pci_xen_initial_domain>> __acpi_register_gsi = acpi_register_gsi_xen;
+ *
+ * called by:
+ *   - arch/x86/kernel/acpi/boot.c|711| <<acpi_register_gsi>> return __acpi_register_gsi(dev, gsi, trigger, polarity);
+ */
 static int acpi_register_gsi_xen(struct device *dev, u32 gsi,
 				 int trigger, int polarity)
 {
@@ -159,6 +581,15 @@ static int acpi_register_gsi_xen(struct device *dev, u32 gsi,
 struct xen_pci_frontend_ops *xen_pci_frontend;
 EXPORT_SYMBOL_GPL(xen_pci_frontend);
 
+/*
+ * used by:
+ *   - arch/x86/pci/xen.c|446| <<pci_xen_init>> x86_msi.setup_msi_irqs = xen_setup_msi_irqs;
+ *
+ * called by:
+ *   - arch/x86/kernel/x86_init.c|121| <<arch_setup_msi_irqs>> return x86_msi.setup_msi_irqs(dev, nvec, type);
+ *
+ * 似乎用在pcifront
+ */
 static int xen_setup_msi_irqs(struct pci_dev *dev, int nvec, int type)
 {
 	int irq, ret, i;
@@ -208,6 +639,10 @@ static int xen_setup_msi_irqs(struct pci_dev *dev, int nvec, int type)
 #define XEN_PIRQ_MSI_DATA  (MSI_DATA_TRIGGER_EDGE | \
 		MSI_DATA_LEVEL_ASSERT | (3 << 8) | MSI_DATA_VECTOR(0))
 
+/*
+ * called by:
+ *   - arch/x86/pci/xen.c|248| <<xen_hvm_setup_msi_irqs>> xen_msi_compose_msg(dev, pirq, &msg);
+ */
 static void xen_msi_compose_msg(struct pci_dev *pdev, unsigned int pirq,
 		struct msi_msg *msg)
 {
@@ -224,6 +659,10 @@ static void xen_msi_compose_msg(struct pci_dev *pdev, unsigned int pirq,
 	msg->data = XEN_PIRQ_MSI_DATA;
 }
 
+/*
+ * used by:
+ *   - arch/x86/pci/xen.c|449| <<xen_msi_init>> x86_msi.setup_msi_irqs = xen_hvm_setup_msi_irqs;
+ */
 static int xen_hvm_setup_msi_irqs(struct pci_dev *dev, int nvec, int type)
 {
 	int irq, pirq;
@@ -261,17 +700,63 @@ static int xen_hvm_setup_msi_irqs(struct pci_dev *dev, int nvec, int type)
 }
 
 #ifdef CONFIG_XEN_DOM0
+/*
+ * 在以下修改:
+ *   - arch/x86/pci/xen.c|370| <<xen_initdom_setup_msi_irqs>> pci_seg_supported = false;
+ *   - arch/x86/pci/xen.c|407| <<xen_initdom_restore_msi_irqs>> pci_seg_supported = false;
+ */
 static bool __read_mostly pci_seg_supported = true;
 
+/*
+ * nvme调用了两次:
+ *
+ * nvme_reset_work()
+ * nvme_pci_enable()
+ * pci_alloc_irq_vectors(pdev, 1, 1, PCI_IRQ_ALL_TYPES);
+ *
+ * nvme_reset_work()
+ * nvme_setup_io_queues()  
+ * pci_alloc_irq_vectors(pdev, 1, nr_io_queues, PCI_IRQ_ALL_TYPES | PCI_IRQ_AFFINITY);
+ *
+ * [0] xen_initdom_setup_msi_irqs
+ * [0] arch_setup_msi_irqs
+ * [0] pci_msi_setup_msi_irqs
+ * [0] __pci_enable_msix
+ * [0] __pci_enable_msix_range
+ * [0] pci_alloc_irq_vectors
+ * [0] nvme_reset_work
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * used by:
+ *   - arch/x86/pci/xen.c|488| <<pci_xen_initial_domain>> x86_msi.setup_msi_irqs = xen_initdom_setup_msi_irqs;
+ *
+ * called by:
+ *   - arch/x86/kernel/x86_init.c|121| <<arch_setup_msi_irqs>> return x86_msi.setup_msi_irqs(dev, nvec, type);
+ */
 static int xen_initdom_setup_msi_irqs(struct pci_dev *dev, int nvec, int type)
 {
 	int ret = 0;
 	struct msi_desc *msidesc;
 
+	/*
+	 * nvme两次调用进来的时候type都是PCI_CAP_ID_MSIX
+	 */
 	for_each_pci_msi_entry(msidesc, dev) {
 		struct physdev_map_pirq map_irq;
 		domid_t domid;
 
+		/*
+		 * 对于nvme (8个vector), 共调用了8次, 有8个struct msi_desc
+		 * msidesc->msi_attrib.entry_nr先后是0, 1, 2, 3, 4, 5, 6, 7
+		 *
+		 * 在desktop上测试此时pci_domain_nr(dev->bus) == 0
+		 *
+		 * 此时pci_seg_supported也都是true
+		 */
+
 		domid = ret = xen_find_device_domain_owner(dev);
 		/* N.B. Casting int's -ENODEV to uint16_t results in 0xFFED,
 		 * hence check ret value for < 0. */
@@ -311,6 +796,12 @@ static int xen_initdom_setup_msi_irqs(struct pci_dev *dev, int nvec, int type)
 		if (pci_seg_supported)
 			ret = HYPERVISOR_physdev_op(PHYSDEVOP_map_pirq,
 						    &map_irq);
+
+		/*
+		 * 成功的话ret是0, 在desktop上的nvme测试的map_irq.pirq分别是:
+		 * 856, 857, 858, 859, 860, 861, 862, 872
+		 */
+
 		if (type == PCI_CAP_ID_MSI && nvec > 1 && ret) {
 			/*
 			 * If MAP_PIRQ_TYPE_MULTI_MSI is not available
@@ -328,6 +819,11 @@ static int xen_initdom_setup_msi_irqs(struct pci_dev *dev, int nvec, int type)
 			map_irq.bus = dev->bus->number;
 			ret = HYPERVISOR_physdev_op(PHYSDEVOP_map_pirq,
 						    &map_irq);
+			/*
+			 * 在以下修改:
+			 *   - arch/x86/pci/xen.c|370| <<xen_initdom_setup_msi_irqs>> pci_seg_supported = false;
+			 *   - arch/x86/pci/xen.c|407| <<xen_initdom_restore_msi_irqs>> pci_seg_supported = false;
+			 */
 			if (ret != -EINVAL)
 				pci_seg_supported = false;
 		}
@@ -337,6 +833,9 @@ static int xen_initdom_setup_msi_irqs(struct pci_dev *dev, int nvec, int type)
 			goto out;
 		}
 
+		/*
+		 * Bind an PSI pirq to an irq
+		 */
 		ret = xen_bind_pirq_msi_to_irq(dev, msidesc, map_irq.pirq,
 		                               (type == PCI_CAP_ID_MSI) ? nvec : 1,
 		                               (type == PCI_CAP_ID_MSIX) ? "msi-x" : "msi",
@@ -349,6 +848,13 @@ static int xen_initdom_setup_msi_irqs(struct pci_dev *dev, int nvec, int type)
 	return ret;
 }
 
+/*
+ * used by:
+ *   - arch/x86/pci/xen.c|520| <<pci_xen_initial_domain>> x86_msi.restore_msi_irqs = xen_initdom_restore_msi_irqs;
+ *
+ * called by:
+ *   - arch/x86/kernel/x86_init.c|136| <<arch_restore_msi_irqs>> x86_msi.restore_msi_irqs(dev);
+ */
 static void xen_initdom_restore_msi_irqs(struct pci_dev *dev)
 {
 	int ret = 0;
@@ -376,6 +882,10 @@ static void xen_initdom_restore_msi_irqs(struct pci_dev *dev)
 }
 #endif
 
+/*
+ * used by:
+ *   - arch/x86/pci/xen.c|448| <<pci_xen_init>> x86_msi.teardown_msi_irqs = xen_teardown_msi_irqs;
+ */
 static void xen_teardown_msi_irqs(struct pci_dev *dev)
 {
 	struct msi_desc *msidesc;
@@ -390,6 +900,12 @@ static void xen_teardown_msi_irqs(struct pci_dev *dev)
 	default_teardown_msi_irqs(dev);
 }
 
+/*
+ * used by:
+ *   - arch/x86/pci/xen.c|437| <<pci_xen_init>> x86_msi.teardown_msi_irq = xen_teardown_msi_irq;
+ *   - arch/x86/pci/xen.c|466| <<xen_msi_init>> x86_msi.teardown_msi_irq = xen_teardown_msi_irq;
+ *   - arch/x86/pci/xen.c|505| <<pci_xen_initial_domain>> x86_msi.teardown_msi_irq = xen_teardown_msi_irq;
+ */
 static void xen_teardown_msi_irq(unsigned int irq)
 {
 	xen_destroy_irq(irq);
@@ -397,6 +913,17 @@ static void xen_teardown_msi_irq(unsigned int irq)
 
 #endif
 
+/*
+ * used by:
+ *   - arch/x86/xen/enlighten.c|1743| <<xen_start_kernel>> x86_init.pci.arch_init = pci_xen_init;
+ *
+ * called by:
+ *   - arch/x86/pci/init.c|19| <<pci_arch_init>> if (x86_init.pci.arch_init && !x86_init.pci.arch_init())
+ *
+ * 如果不是pv或者是dom0返回-ENODEV
+ * 只用在hvm的guest???
+ * 成功了返回0
+ */
 int __init pci_xen_init(void)
 {
 	if (!xen_pv_domain() || xen_initial_domain())
@@ -424,6 +951,10 @@ int __init pci_xen_init(void)
 }
 
 #ifdef CONFIG_PCI_MSI
+/*
+ * used by:
+ *   - arch/x86/pci/xen.c|473| <<pci_xen_hvm_init>> x86_platform.apic_post_init = xen_msi_init;
+ */
 void __init xen_msi_init(void)
 {
 	if (!disable_apic) {
@@ -445,6 +976,10 @@ void __init xen_msi_init(void)
 }
 #endif
 
+/*
+ * called by:
+ *   - drivers/xen/events/events_base.c|1713| <<xen_init_IRQ>> pci_xen_hvm_init();
+ */
 int __init pci_xen_hvm_init(void)
 {
 	if (!xen_have_vector_callback || !xen_feature(XENFEAT_hvm_pirqs))
@@ -470,6 +1005,19 @@ int __init pci_xen_hvm_init(void)
 }
 
 #ifdef CONFIG_XEN_DOM0
+/*
+ * [0] pci_xen_initial_domain
+ * [0] xen_init_IRQ
+ * [0] init_IRQ
+ * [0] start_kernel
+ * [0] x86_64_start_reservations
+ * [0] xen_start_kernel
+ *
+ * called by:
+ *   - drivers/xen/events/events_base.c|1698| <<xen_init_IRQ>> pci_xen_initial_domain();
+ *
+ * 只在在init_IRQ()-->xen_init_IRQ()为dom0调用
+ */
 int __init pci_xen_initial_domain(void)
 {
 	int irq;
@@ -480,6 +1028,10 @@ int __init pci_xen_initial_domain(void)
 	x86_msi.restore_msi_irqs = xen_initdom_restore_msi_irqs;
 	pci_msi_ignore_mask = 1;
 #endif
+	/*
+	 * called by:
+	 *   - arch/x86/kernel/acpi/boot.c|711| <<acpi_register_gsi>> return __acpi_register_gsi(dev, gsi, trigger, polarity);
+	 */
 	__acpi_register_gsi = acpi_register_gsi_xen;
 	__acpi_unregister_gsi = NULL;
 	/*
@@ -496,6 +1048,9 @@ int __init pci_xen_initial_domain(void)
 			trigger ? ACPI_LEVEL_SENSITIVE : ACPI_EDGE_SENSITIVE,
 			true /* Map GSI to PIRQ */);
 	}
+	/*
+	 * 在dell测试机上nr_ioapics是1
+	 */
 	if (0 == nr_ioapics) {
 		for (irq = 0; irq < nr_legacy_irqs(); irq++)
 			xen_bind_pirq_gsi_to_irq(irq, irq, 0, "xt-pic");
@@ -503,6 +1058,10 @@ int __init pci_xen_initial_domain(void)
 	return 0;
 }
 
+/*
+ * 就是一个domain和struct pci_dev的pair,
+ * 通过list加入到dev_domain_list
+ */
 struct xen_device_domain_owner {
 	domid_t domain;
 	struct pci_dev *dev;
@@ -510,8 +1069,19 @@ struct xen_device_domain_owner {
 };
 
 static DEFINE_SPINLOCK(dev_domain_list_spinlock);
+/*
+ * used by:
+ *   - arch/x86/pci/xen.c|519| <<find_device>> list_for_each_entry(owner, &dev_domain_list, list) {
+ *   - arch/x86/pci/xen.c|556| <<xen_register_device_domain_owner>> list_add_tail(&owner->list, &dev_domain_list);
+ */
 static struct list_head dev_domain_list = LIST_HEAD_INIT(dev_domain_list);
 
+/*
+ * called by:
+ *   - arch/x86/pci/xen.c|532| <<xen_find_device_domain_owner>> owner = find_device(dev);
+ *   - arch/x86/pci/xen.c|549| <<xen_register_device_domain_owner>> if (find_device(dev)) {
+ *   - arch/x86/pci/xen.c|567| <<xen_unregister_device_domain_owner>> owner = find_device(dev);
+ */
 static struct xen_device_domain_owner *find_device(struct pci_dev *dev)
 {
 	struct xen_device_domain_owner *owner;
@@ -523,6 +1093,12 @@ static struct xen_device_domain_owner *find_device(struct pci_dev *dev)
 	return NULL;
 }
 
+/*
+ * called by:
+ *   - arch/x86/pci/xen.c|275| <<xen_initdom_setup_msi_irqs>> domid = ret = xen_find_device_domain_owner(dev);
+ *   - drivers/xen/xen-pciback/pci_stub.c|624| <<pcistub_remove>> int domid = xen_find_device_domain_owner(dev);
+ *   - drivers/xen/xen-pciback/xenbus.c|254| <<xen_pcibk_export_device>> xen_find_device_domain_owner(dev));
+ */
 int xen_find_device_domain_owner(struct pci_dev *dev)
 {
 	struct xen_device_domain_owner *owner;
@@ -537,6 +1113,13 @@ int xen_find_device_domain_owner(struct pci_dev *dev)
 }
 EXPORT_SYMBOL_GPL(xen_find_device_domain_owner);
 
+/*
+ * called by:
+ *   - drivers/xen/xen-pciback/xenbus.c|251| <<xen_pcibk_export_device>> if (xen_register_device_domain_owner(dev,
+ *   - drivers/xen/xen-pciback/xenbus.c|256| <<xen_pcibk_export_device>> xen_register_device_domain_owner(dev, pdev->xdev->otherend_id);
+ *
+ * 一个struct xen_device_domain_owner相当于是一个pci_dev和domain的pair
+ */
 int xen_register_device_domain_owner(struct pci_dev *dev, uint16_t domain)
 {
 	struct xen_device_domain_owner *owner;
@@ -559,6 +1142,13 @@ int xen_register_device_domain_owner(struct pci_dev *dev, uint16_t domain)
 }
 EXPORT_SYMBOL_GPL(xen_register_device_domain_owner);
 
+/*
+ * called by:
+ *   - drivers/xen/xen-pciback/pci_stub.c|103| <<pcistub_device_release>> xen_unregister_device_domain_owner(dev);
+ *   - drivers/xen/xen-pciback/pci_stub.c|306| <<pcistub_put_pci_dev>> xen_unregister_device_domain_owner(dev);
+ *   - drivers/xen/xen-pciback/xenbus.c|255| <<xen_pcibk_export_device>> xen_unregister_device_domain_owner(dev);
+ *   - drivers/xen/xen-pciback/xenbus.c|290| <<xen_pcibk_remove_device>> xen_unregister_device_domain_owner(dev);
+ */
 int xen_unregister_device_domain_owner(struct pci_dev *dev)
 {
 	struct xen_device_domain_owner *owner;
diff --git a/arch/x86/xen/enlighten.c b/arch/x86/xen/enlighten.c
index db7cf87..a800ad0 100644
--- a/arch/x86/xen/enlighten.c
+++ b/arch/x86/xen/enlighten.c
@@ -1773,6 +1773,14 @@ asmlinkage __visible void __init xen_start_kernel(void)
 	}
 #ifdef CONFIG_PCI
 	/* PCI BIOS service won't work from a PV guest. */
+	/*
+	 * 用到PCI_PROBE_BIOS的地方:
+	 *   - arch/x86/pci/common.c|22| <<global>> unsigned int pci_probe = PCI_PROBE_BIOS | PCI_PROBE_CONF1 | PCI_PROBE_CONF2 |
+	 *   - arch/x86/pci/common.c|546| <<pcibios_setup>> pci_probe = PCI_PROBE_BIOS;
+	 *   - arch/x86/pci/common.c|549| <<pcibios_setup>> pci_probe &= ~PCI_PROBE_BIOS;
+	 *   - arch/x86/pci/pcbios.c|421| <<pci_pcbios_init>> if ((pci_probe & PCI_PROBE_BIOS)
+	 *   - arch/x86/xen/enlighten.c|1776| <<xen_start_kernel>> pci_probe &= ~PCI_PROBE_BIOS;
+	 */
 	pci_probe &= ~PCI_PROBE_BIOS;
 #endif
 	xen_raw_console_write("about to get started...\n");
diff --git a/arch/x86/xen/irq.c b/arch/x86/xen/irq.c
index 33e9295..16a041f 100644
--- a/arch/x86/xen/irq.c
+++ b/arch/x86/xen/irq.c
@@ -18,11 +18,22 @@
  * callback mask. We do this in a very simple manner, by making a call
  * down into Xen. The pending flag will be checked by Xen on return.
  */
+/*
+ * called by:
+ *   - arch/x86/xen/irq.c|59| <<xen_restore_fl>> xen_force_evtchn_callback();
+ *   - arch/x86/xen/irq.c|96| <<xen_irq_enable>> xen_force_evtchn_callback();
+ */
 void xen_force_evtchn_callback(void)
 {
 	(void)HYPERVISOR_xen_version(0, NULL);
 }
 
+/*
+ * called by:
+ *   - arch/x86/include/asm/paravirt.h|763| <<arch_local_save_flags>> return PVOP_CALLEE0(unsigned long , pv_irq_ops.save_fl);
+ *
+ * struct pv_irq_ops xen_irq_ops.save_fl = xen_save_fl()
+ */
 asmlinkage __visible unsigned long xen_save_fl(void)
 {
 	struct vcpu_info *vcpu;
@@ -41,6 +52,12 @@ asmlinkage __visible unsigned long xen_save_fl(void)
 }
 PV_CALLEE_SAVE_REGS_THUNK(xen_save_fl);
 
+/*
+ * called by:
+ *   - arch/x86/include/asm/paravirt.h|768| <<arch_local_irq_restore>> PVOP_VCALLEE1(pv_irq_ops.restore_fl, f);
+ *
+ * struct pv_irq_ops xen_irq_ops.restore_fl = xen_restore_fl()
+ */
 __visible void xen_restore_fl(unsigned long flags)
 {
 	struct vcpu_info *vcpu;
@@ -63,6 +80,12 @@ __visible void xen_restore_fl(unsigned long flags)
 }
 PV_CALLEE_SAVE_REGS_THUNK(xen_restore_fl);
 
+/*
+ * called by:
+ *   - arch/x86/include/asm/paravirt.h|773| <<arch_local_irq_disable>> PVOP_VCALLEE0(pv_irq_ops.irq_disable);
+ *
+ * struct pv_irq_ops xen_irq_ops.irq_disable = xen_irq_disable()
+ */
 asmlinkage __visible void xen_irq_disable(void)
 {
 	/* There's a one instruction preempt window here.  We need to
@@ -74,6 +97,12 @@ asmlinkage __visible void xen_irq_disable(void)
 }
 PV_CALLEE_SAVE_REGS_THUNK(xen_irq_disable);
 
+/*
+ * called by:
+ *   - arch/x86/include/asm/paravirt.h|778| <<arch_local_irq_enable>> PVOP_VCALLEE0(pv_irq_ops.irq_enable);
+ *
+ * struct pv_irq_ops xen_irq_ops.irq_enable = xen_irq_enable()
+ */
 asmlinkage __visible void xen_irq_enable(void)
 {
 	struct vcpu_info *vcpu;
@@ -99,6 +128,12 @@ asmlinkage __visible void xen_irq_enable(void)
 }
 PV_CALLEE_SAVE_REGS_THUNK(xen_irq_enable);
 
+/*
+ * called by:
+ *   - arch/x86/include/asm/paravirt.h|104| <<arch_safe_halt>> PVOP_VCALL0(pv_irq_ops.safe_halt);
+ *
+ * struct pv_irq_ops xen_irq_ops.safe_halt = xen_safe_halt()
+ */
 static void xen_safe_halt(void)
 {
 	/* Blocking includes an implicit local_irq_enable(). */
@@ -106,6 +141,12 @@ static void xen_safe_halt(void)
 		BUG();
 }
 
+/*
+ * called by:
+ *   - arch/x86/include/asm/paravirt.h|109| <<halt>> PVOP_VCALL0(pv_irq_ops.halt);
+ *
+ * struct pv_irq_ops xen_irq_ops.halt = xen_halt()
+ */
 static void xen_halt(void)
 {
 	if (irqs_disabled())
@@ -115,6 +156,10 @@ static void xen_halt(void)
 		xen_safe_halt();
 }
 
+/*
+ * used only by这个文件本身:
+ *   - arch/x86/xen/irq.c|166| <<xen_init_irq_ops>> pv_irq_ops = xen_irq_ops;
+ */
 static const struct pv_irq_ops xen_irq_ops __initconst = {
 	.save_fl = PV_CALLEE_SAVE(xen_save_fl),
 	.restore_fl = PV_CALLEE_SAVE(xen_restore_fl),
@@ -124,12 +169,20 @@ static const struct pv_irq_ops xen_irq_ops __initconst = {
 	.safe_halt = xen_safe_halt,
 	.halt = xen_halt,
 #ifdef CONFIG_X86_64
+	/* 在arch/x86/xen/xen-asm_64.S中定义 */
 	.adjust_exception_frame = xen_adjust_exception_frame,
 #endif
 };
 
+/*
+ * called by only:
+ *   - arch/x86/xen/enlighten.c|1642| <<xen_start_kernel>> xen_init_irq_ops();
+ */
 void __init xen_init_irq_ops(void)
 {
+	/*
+	 * xen_irq_ops的定义就在上面
+	 */
 	/* For PVH we use default pv_irq_ops settings. */
 	if (!xen_feature(XENFEAT_hvm_callback_vector))
 		pv_irq_ops = xen_irq_ops;
diff --git a/arch/x86/xen/pci-swiotlb-xen.c b/arch/x86/xen/pci-swiotlb-xen.c
index 5f8b4b0..c125e99 100644
--- a/arch/x86/xen/pci-swiotlb-xen.c
+++ b/arch/x86/xen/pci-swiotlb-xen.c
@@ -16,6 +16,12 @@
 #endif
 #include <linux/export.h>
 
+/*
+ * 只在以下修改xen_swiotlb:
+ *   - arch/x86/xen/pci-swiotlb-xen.c|53| <<pci_xen_swiotlb_detect>> xen_swiotlb = 1;
+ *
+ * 在xen的测试机上是1
+ */
 int xen_swiotlb __read_mostly;
 
 static struct dma_map_ops xen_swiotlb_dma_ops = {
@@ -49,12 +55,27 @@ int __init pci_xen_swiotlb_detect(void)
 	 * activate this IOMMU. If running as PV privileged, activate it
 	 * irregardless.
 	 */
+	/*
+	 * 在以下修改swiotlb:
+	 *   - arch/x86/kernel/amd_gart_64.c|853| <<gart_iommu_init>> swiotlb = 0;
+	 *   - arch/x86/kernel/pci-dma.c|195| <<iommu_setup>> swiotlb = 1;
+	 *   - arch/x86/kernel/pci-swiotlb.c|74| <<pci_swiotlb_detect_override>> swiotlb = 1;
+	 *   - arch/x86/kernel/pci-swiotlb.c|92| <<pci_swiotlb_detect_4gb>> swiotlb = 1;
+	 *   - arch/x86/kernel/tboot.c|528| <<tboot_force_iommu>> swiotlb = 0;
+	 *   - arch/x86/xen/pci-swiotlb-xen.c|58| <<pci_xen_swiotlb_detect>> swiotlb = 0;
+	 *   - drivers/iommu/amd_iommu.c|2869| <<amd_iommu_init_dma_ops>> swiotlb = iommu_pass_through ? 1 : 0;
+	 *   - drivers/iommu/intel-iommu.c|4883| <<intel_iommu_init>> swiotlb = 0;
+	 *
+	 * 这里是唯一可能修改xen_swiotlb的地方:
+	 *   - arch/x86/xen/pci-swiotlb-xen.c|53| <<pci_xen_swiotlb_detect>> xen_swiotlb = 1;
+	 */
 	if (xen_initial_domain() || swiotlb || swiotlb_force == SWIOTLB_FORCE)
 		xen_swiotlb = 1;
 
 	/* If we are running under Xen, we MUST disable the native SWIOTLB.
 	 * Don't worry about swiotlb_force flag activating the native, as
 	 * the 'swiotlb' flag is the only one turning it on. */
+	/* 在xen上是0 */
 	swiotlb = 0;
 
 #ifdef CONFIG_X86_64
@@ -82,6 +103,12 @@ void __init pci_xen_swiotlb_init(void)
 	}
 }
 
+/*
+ * called only by:
+ *   - drivers/pci/xen-pcifront.c|703| <<pcifront_connect_and_init_dma>> err = pci_xen_swiotlb_init_late();
+ *
+ * domU应该不使用这个
+ */
 int pci_xen_swiotlb_init_late(void)
 {
 	int rc;
diff --git a/arch/x86/xen/platform-pci-unplug.c b/arch/x86/xen/platform-pci-unplug.c
index 90d1b83..290eb7f 100644
--- a/arch/x86/xen/platform-pci-unplug.c
+++ b/arch/x86/xen/platform-pci-unplug.c
@@ -142,6 +142,11 @@ bool xen_has_pv_and_legacy_disk_devices(void)
 }
 EXPORT_SYMBOL_GPL(xen_has_pv_and_legacy_disk_devices);
 
+/*
+ * called by:
+ *   - arch/x86/xen/enlighten.c|1948| <<xen_hvm_guest_init>> xen_unplug_emulated_devices();
+ *   - arch/x86/xen/suspend.c|43| <<xen_hvm_post_suspend>> xen_unplug_emulated_devices();
+ */
 void xen_unplug_emulated_devices(void)
 {
 	int r;
diff --git a/arch/x86/xen/smp.c b/arch/x86/xen/smp.c
index 8eca26e..f427061 100644
--- a/arch/x86/xen/smp.c
+++ b/arch/x86/xen/smp.c
@@ -765,6 +765,10 @@ static const struct smp_ops xen_smp_ops __initconst = {
 	.send_call_func_single_ipi = xen_smp_send_call_function_single_ipi,
 };
 
+/*
+ * called only by:
+ *   - arch/x86/xen/enlighten.c|1667| <<xen_start_kernel>> xen_smp_init();
+ */
 void __init xen_smp_init(void)
 {
 	smp_ops = xen_smp_ops;
diff --git a/arch/x86/xen/spinlock.c b/arch/x86/xen/spinlock.c
index 8d2c6f0..aac7a1b 100644
--- a/arch/x86/xen/spinlock.c
+++ b/arch/x86/xen/spinlock.c
@@ -18,13 +18,30 @@
 #include "xen-ops.h"
 #include "debugfs.h"
 
+/*
+ * used by:
+ *   - arch/x86/xen/spinlock.c|30| <<xen_qlock_kick>> int irq = per_cpu(lock_kicker_irq, cpu);
+ *   - arch/x86/xen/spinlock.c|44| <<xen_qlock_wait>> int irq = __this_cpu_read(lock_kicker_irq);
+ *   - arch/x86/xen/spinlock.c|79| <<xen_init_lock_cpu>> WARN(per_cpu(lock_kicker_irq, cpu) >= 0, "spinlock on CPU%d exists on IRQ%d!\n",
+ *   - arch/x86/xen/spinlock.c|80| <<xen_init_lock_cpu>> cpu, per_cpu(lock_kicker_irq, cpu));
+ *   - arch/x86/xen/spinlock.c|92| <<xen_init_lock_cpu>> per_cpu(lock_kicker_irq, cpu) = irq;
+ *   - arch/x86/xen/spinlock.c|104| <<xen_uninit_lock_cpu>> unbind_from_irqhandler(per_cpu(lock_kicker_irq, cpu), NULL);
+ *   - arch/x86/xen/spinlock.c|105| <<xen_uninit_lock_cpu>> per_cpu(lock_kicker_irq, cpu) = -1;
+ */
 static DEFINE_PER_CPU(int, lock_kicker_irq) = -1;
 static DEFINE_PER_CPU(char *, irq_name);
+/*
+ * used by:
+ *   - arch/x86/xen/spinlock.c|45| <<xen_qlock_wait>> atomic_t *nest_cnt = this_cpu_ptr(&xen_qlock_wait_nest);
+ */
 static DEFINE_PER_CPU(atomic_t, xen_qlock_wait_nest);
 static bool xen_pvspin = true;
 
 #include <asm/qspinlock.h>
 
+/*
+ * 向要唤醒的cpu发送XEN_SPIN_UNLOCK_VECTOR
+ */
 static void xen_qlock_kick(int cpu)
 {
 	int irq = per_cpu(lock_kicker_irq, cpu);
diff --git a/arch/x86/xen/xen-asm_64.S b/arch/x86/xen/xen-asm_64.S
index c3df431..769269c 100644
--- a/arch/x86/xen/xen-asm_64.S
+++ b/arch/x86/xen/xen-asm_64.S
@@ -22,6 +22,10 @@
 
 #include "xen-asm.h"
 
+/*
+ * 在arch/x86/xen/irq.c中:
+ * struct pv_irq_ops xen_irq_ops.adjust_eception_frame = xen_adjust_exception_frame()
+ */
 ENTRY(xen_adjust_exception_frame)
 	mov 8+0(%rsp), %rcx
 	mov 8+8(%rsp), %r11
diff --git a/drivers/block/xen-blkback/blkback.c b/drivers/block/xen-blkback/blkback.c
index d6eaaa2..c2d9578 100644
--- a/drivers/block/xen-blkback/blkback.c
+++ b/drivers/block/xen-blkback/blkback.c
@@ -155,6 +155,11 @@ static inline void put_free_pages(struct xen_blkif_ring *ring, struct page **pag
 	spin_unlock_irqrestore(&ring->free_pages_lock, flags);
 }
 
+/*
+ * called by:
+ *   - drivers/block/xen-blkback/blkback.c|653| <<xen_blkif_schedule>> shrink_free_pagepool(ring, xen_blkif_max_buffer_pages);
+ *   - drivers/block/xen-blkback/blkback.c|694| <<xen_blkbk_free_caches>> shrink_free_pagepool(ring, 0 );
+ */
 static inline void shrink_free_pagepool(struct xen_blkif_ring *ring, int num)
 {
 	/* Remove requested pages in batches of NUM_BATCH_FREE_PAGES */
@@ -208,6 +213,21 @@ static void make_response(struct xen_blkif_ring *ring, u64 id,
  * bit operations to modify the flags of a persistent grant and to count
  * the number of used grants.
  */
+/*
+ * xen_blkif_schedule()
+ *  -> do_block_io_op()
+ *      -> __do_block_io_op()
+ *          -> dispatch_rw_block_io()
+ *              -> xen_blkbk_map_seg
+ *		    -> xen_blkbk_map()
+ *                      -> add_persistent_gnt()
+ *              -> xen_blkbk_parse_indirect()
+ *                  -> xen_blkbk_map()
+ *                      -> add_persistent_gnt()
+ *
+ * called by only:
+ *   - drivers/block/xen-blkback/blkback.c|908| <<xen_blkbk_map>> if (add_persistent_gnt(ring,
+ */
 static int add_persistent_gnt(struct xen_blkif_ring *ring,
 			       struct persistent_gnt *persistent_gnt)
 {
@@ -215,6 +235,9 @@ static int add_persistent_gnt(struct xen_blkif_ring *ring,
 	struct persistent_gnt *this;
 	struct xen_blkif *blkif = ring->blkif;
 
+	/*
+	 * 超过了默认1056个就不能添加了
+	 */
 	if (ring->persistent_gnt_c >= xen_blkif_max_pgrants) {
 		if (!blkif->vbd.overflow_max_grants)
 			blkif->vbd.overflow_max_grants = 1;
@@ -240,6 +263,17 @@ static int add_persistent_gnt(struct xen_blkif_ring *ring,
 	set_bit(PERSISTENT_GNT_ACTIVE, persistent_gnt->flags);
 	/* Add new node and rebalance tree. */
 	rb_link_node(&(persistent_gnt->node), parent, new);
+	/*
+	 * ring->persistent_gnts在以下使用:
+	 *   - drivers/block/xen-blkback/blkback.c|224| <<add_persistent_gnt>> new = &ring->persistent_gnts.rb_node;
+	 *   - drivers/block/xen-blkback/blkback.c|243| <<add_persistent_gnt>> rb_insert_color(&(persistent_gnt->node), &ring->persistent_gnts);
+	 *   - drivers/block/xen-blkback/blkback.c|255| <<get_persistent_gnt>> node = ring->persistent_gnts.rb_node;
+	 *   - drivers/block/xen-blkback/blkback.c|409| <<purge_persistent_gnt>> root = &ring->persistent_gnts;
+	 *   - drivers/block/xen-blkback/blkback.c|676| <<xen_blkbk_free_caches>> if (!RB_EMPTY_ROOT(&ring->persistent_gnts))
+	 *   - drivers/block/xen-blkback/blkback.c|677| <<xen_blkbk_free_caches>> free_persistent_gnts(ring, &ring->persistent_gnts,
+	 *   - drivers/block/xen-blkback/blkback.c|680| <<xen_blkbk_free_caches>> BUG_ON(!RB_EMPTY_ROOT(&ring->persistent_gnts));
+	 *   - drivers/block/xen-blkback/xenbus.c|296| <<xen_blkif_disconnect>> BUG_ON(!RB_EMPTY_ROOT(&ring->persistent_gnts));
+	 */
 	rb_insert_color(&(persistent_gnt->node), &ring->persistent_gnts);
 	ring->persistent_gnt_c++;
 	atomic_inc(&ring->persistent_gnt_in_use);
@@ -283,6 +317,14 @@ static void put_persistent_gnt(struct xen_blkif_ring *ring,
 	atomic_dec(&ring->persistent_gnt_in_use);
 }
 
+/*
+ * called by only:
+ *   - drivers/block/xen-blkback/blkback.c|734| <<xen_blkbk_free_caches>> free_persistent_gnts(ring, &ring->persistent_gnts,
+ *
+ * 因为植被xen_blkbk_free_caches()调用, 进来的时候:
+ *   root是&ring->persistent_gnts
+ *   num是ring->persistent_gnt_c
+ */
 static void free_persistent_gnts(struct xen_blkif_ring *ring, struct rb_root *root,
                                  unsigned int num)
 {
@@ -300,6 +342,9 @@ static void free_persistent_gnts(struct xen_blkif_ring *ring, struct rb_root *ro
 	foreach_grant_safe(persistent_gnt, n, root, node) {
 		BUG_ON(persistent_gnt->handle ==
 			BLKBACK_INVALID_HANDLE);
+		/*
+		 * 这里只用handle, 不用grant ref!
+		 */
 		gnttab_set_unmap_op(&unmap[segs_to_unmap],
 			(unsigned long) pfn_to_kaddr(page_to_pfn(
 				persistent_gnt->page)),
@@ -325,6 +370,17 @@ static void free_persistent_gnts(struct xen_blkif_ring *ring, struct rb_root *ro
 	BUG_ON(num != 0);
 }
 
+/*
+ * used by:
+ *   - drivers/block/xen-blkback/xenbus.c|153| <<xen_blkif_alloc_rings>> INIT_WORK(&ring->persistent_purge_work, xen_blkbk_unmap_purged_grants);
+ *
+ * ring->persistent_purge_work在以下被使用:
+ *   - drivers/block/xen-blkback/blkback.c|368| <<xen_blkbk_unmap_purged_grants>> struct xen_blkif_ring *ring = container_of(work, typeof(*ring), persistent_purge_work);
+ *   - drivers/block/xen-blkback/blkback.c|417| <<purge_persistent_gnt>> if (work_busy(&ring->persistent_purge_work)) {
+ *   - drivers/block/xen-blkback/blkback.c|487| <<purge_persistent_gnt>> schedule_work(&ring->persistent_purge_work);
+ *   - drivers/block/xen-blkback/blkback.c|694| <<xen_blkif_schedule>> flush_work(&ring->persistent_purge_work);
+ *   - drivers/block/xen-blkback/xenbus.c|153| <<xen_blkif_alloc_rings>> INIT_WORK(&ring->persistent_purge_work, xen_blkbk_unmap_purged_grants);
+ */
 void xen_blkbk_unmap_purged_grants(struct work_struct *work)
 {
 	struct gnttab_unmap_grant_ref unmap[BLKIF_MAX_SEGMENTS_PER_REQUEST];
@@ -657,6 +713,14 @@ int xen_blkif_schedule(void *arg)
 	}
 
 	/* Drain pending purge work */
+	/*
+	 * ring->persistent_purge_work在以下使用:
+	 *   - drivers/block/xen-blkback/blkback.c|368| <<xen_blkbk_unmap_purged_grants>> struct xen_blkif_ring *ring = container_of(work, typeof(*ring), persistent_purge_work);
+	 *   - drivers/block/xen-blkback/blkback.c|417| <<purge_persistent_gnt>> if (work_busy(&ring->persistent_purge_work)) {
+	 *   - drivers/block/xen-blkback/blkback.c|487| <<purge_persistent_gnt>> schedule_work(&ring->persistent_purge_work);
+	 *   - drivers/block/xen-blkback/blkback.c|694| <<xen_blkif_schedule>> flush_work(&ring->persistent_purge_work);
+	 *   - drivers/block/xen-blkback/xenbus.c|153| <<xen_blkif_alloc_rings>> INIT_WORK(&ring->persistent_purge_work, xen_blkbk_unmap_purged_grants);
+	 */
 	flush_work(&ring->persistent_purge_work);
 
 	if (log_stats)
@@ -670,6 +734,10 @@ int xen_blkif_schedule(void *arg)
 /*
  * Remove persistent grants and empty the pool of free pages
  */
+/*
+ * 只在以下调用:
+ *   - drivers/block/xen-blkback/xenbus.c|278| <<xen_blkif_disconnect>> xen_blkbk_free_caches(ring);
+ */
 void xen_blkbk_free_caches(struct xen_blkif_ring *ring)
 {
 	/* Free all persistent grant pages */
@@ -678,6 +746,12 @@ void xen_blkbk_free_caches(struct xen_blkif_ring *ring)
 			ring->persistent_gnt_c);
 
 	BUG_ON(!RB_EMPTY_ROOT(&ring->persistent_gnts));
+	/*
+	 * 修改的地方:
+	 *   - drivers/block/xen-blkback/blkback.c|244| <<add_persistent_gnt>> ring->persistent_gnt_c++;
+	 *   - drivers/block/xen-blkback/blkback.c|449| <<purge_persistent_gnt>> ring->persistent_gnt_c -= (total - num_clean);
+	 *   - drivers/block/xen-blkback/blkback.c|681| <<xen_blkbk_free_caches>> ring->persistent_gnt_c = 0;
+	 */
 	ring->persistent_gnt_c = 0;
 
 	/* Since we are shutting down remove all pages from the buffer */
@@ -794,6 +868,11 @@ static void xen_blkbk_unmap(struct xen_blkif_ring *ring,
 	}
 }
 
+/*
+ * called by:
+ *   - drivers/block/xen-blkback/blkback.c|958| <<xen_blkbk_map_seg>> rc = xen_blkbk_map(pending_req->ring, pending_req->segments,
+ *   - drivers/block/xen-blkback/blkback.c|982| <<xen_blkbk_parse_indirect>> rc = xen_blkbk_map(ring, pages, indirect_grefs, true);
+ */
 static int xen_blkbk_map(struct xen_blkif_ring *ring,
 			 struct grant_page *pages[],
 			 int num, bool ro)
@@ -932,6 +1011,10 @@ static int xen_blkbk_map(struct xen_blkif_ring *ring,
 	return -ENOMEM;
 }
 
+/*
+ * called by only:
+ *   - drivers/block/xen-blkback/blkback.c|1364| <<dispatch_rw_block_io>> if (xen_blkbk_map_seg(pending_req))
+ */
 static int xen_blkbk_map_seg(struct pending_req *pending_req)
 {
 	int rc;
@@ -943,6 +1026,10 @@ static int xen_blkbk_map_seg(struct pending_req *pending_req)
 	return rc;
 }
 
+/*
+ * called by only:
+ *   - drivers/block/xen-blkback/blkback.c|1326| <<dispatch_rw_block_io>> if (xen_blkbk_parse_indirect(req, pending_req, seg, &preq))
+ */
 static int xen_blkbk_parse_indirect(struct blkif_request *req,
 				    struct pending_req *pending_req,
 				    struct seg_buf seg[],
@@ -1114,6 +1201,10 @@ static void end_block_io_op(struct bio *bio)
  * (which has the sectors we want, number of them, grant references, etc),
  * and transmute  it to the block API to hand it over to the proper block disk.
  */
+/*
+ * called by only:
+ *   - drivers/block/xen-blkback/blkback.c|1237| <<do_block_io_op>> more_to_do = __do_block_io_op(ring);
+ */
 static int
 __do_block_io_op(struct xen_blkif_ring *ring)
 {
@@ -1195,6 +1286,10 @@ __do_block_io_op(struct xen_blkif_ring *ring)
 	return more_to_do;
 }
 
+/*
+ * called by:
+ *   - drivers/block/xen-blkback/blkback.c|647| <<xen_blkif_schedule>> ret = do_block_io_op(ring);
+ */
 static int
 do_block_io_op(struct xen_blkif_ring *ring)
 {
@@ -1215,6 +1310,10 @@ do_block_io_op(struct xen_blkif_ring *ring)
  * Transmutation of the 'struct blkif_request' to a proper 'struct bio'
  * and call the 'submit_bio' to pass it to the underlying storage.
  */
+/*
+ * called by only:
+ *   - drivers/block/xen-blkback/blkback.c|1196| <<__do_block_io_op>> if (dispatch_rw_block_io(ring, &req, pending_req))
+ */
 static int dispatch_rw_block_io(struct xen_blkif_ring *ring,
 				struct blkif_request *req,
 				struct pending_req *pending_req)
diff --git a/drivers/block/xen-blkback/common.h b/drivers/block/xen-blkback/common.h
index ecb35fe..4073c5f 100644
--- a/drivers/block/xen-blkback/common.h
+++ b/drivers/block/xen-blkback/common.h
@@ -279,7 +279,24 @@ struct xen_blkif_ring {
 
 	/* Tree to store persistent grants. */
 	spinlock_t		pers_gnts_lock;
+	/*
+	 * used by:
+	 *   - drivers/block/xen-blkback/blkback.c|224| <<add_persistent_gnt>> new = &ring->persistent_gnts.rb_node;
+	 *   - drivers/block/xen-blkback/blkback.c|243| <<add_persistent_gnt>> rb_insert_color(&(persistent_gnt->node), &ring->persistent_gnts);
+	 *   - drivers/block/xen-blkback/blkback.c|255| <<get_persistent_gnt>> node = ring->persistent_gnts.rb_node;
+	 *   - drivers/block/xen-blkback/blkback.c|409| <<purge_persistent_gnt>> root = &ring->persistent_gnts;
+	 *   - drivers/block/xen-blkback/blkback.c|676| <<xen_blkbk_free_caches>> if (!RB_EMPTY_ROOT(&ring->persistent_gnts))
+	 *   - drivers/block/xen-blkback/blkback.c|677| <<xen_blkbk_free_caches>> free_persistent_gnts(ring, &ring->persistent_gnts,
+	 *   - drivers/block/xen-blkback/blkback.c|680| <<xen_blkbk_free_caches>> BUG_ON(!RB_EMPTY_ROOT(&ring->persistent_gnts));
+	 *   - drivers/block/xen-blkback/xenbus.c|296| <<xen_blkif_disconnect>> BUG_ON(!RB_EMPTY_ROOT(&ring->persistent_gnts));
+	 */
 	struct rb_root		persistent_gnts;
+	/*
+	 * 修改的地方:
+	 *   - drivers/block/xen-blkback/blkback.c|244| <<add_persistent_gnt>> ring->persistent_gnt_c++;
+	 *   - drivers/block/xen-blkback/blkback.c|449| <<purge_persistent_gnt>> ring->persistent_gnt_c -= (total - num_clean);
+	 *   - drivers/block/xen-blkback/blkback.c|681| <<xen_blkbk_free_caches>> ring->persistent_gnt_c = 0;
+	 */
 	unsigned int		persistent_gnt_c;
 	atomic_t		persistent_gnt_in_use;
 	unsigned long           next_lru;
@@ -296,6 +313,14 @@ struct xen_blkif_ring {
 
 	/* Used by the kworker that offload work from the persistent purge. */
 	struct list_head	persistent_purge_list;
+	/*
+	 * used by:
+	 *   - drivers/block/xen-blkback/blkback.c|368| <<xen_blkbk_unmap_purged_grants>> struct xen_blkif_ring *ring = container_of(work, typeof(*ring), persistent_purge_work);
+	 *   - drivers/block/xen-blkback/blkback.c|417| <<purge_persistent_gnt>> if (work_busy(&ring->persistent_purge_work)) {
+	 *   - drivers/block/xen-blkback/blkback.c|487| <<purge_persistent_gnt>> schedule_work(&ring->persistent_purge_work);
+	 *   - drivers/block/xen-blkback/blkback.c|694| <<xen_blkif_schedule>> flush_work(&ring->persistent_purge_work);
+	 *   - drivers/block/xen-blkback/xenbus.c|153| <<xen_blkif_alloc_rings>> INIT_WORK(&ring->persistent_purge_work, xen_blkbk_unmap_purged_grants);
+	 */
 	struct work_struct	persistent_purge_work;
 
 	/* Buffer of free pages to map grant refs. */
diff --git a/drivers/block/xen-blkfront.c b/drivers/block/xen-blkfront.c
index c08ee8c..a462c8c 100644
--- a/drivers/block/xen-blkfront.c
+++ b/drivers/block/xen-blkfront.c
@@ -1172,6 +1172,13 @@ static int xlvbd_alloc_gendisk(blkif_sector_t capacity,
 	return err;
 }
 
+/*
+ * called by:
+ *   - drivers/block/xen-blkfront.c|2185| <<blkfront_closing>> xlvbd_release_gendisk(info);
+ *   - drivers/block/xen-blkfront.c|2566| <<blkfront_remove>> xlvbd_release_gendisk(info);
+ *   - drivers/block/xen-blkfront.c|2640| <<blkif_release>> xlvbd_release_gendisk(info);
+ *   - drivers/block/xen-blkfront.c|2649| <<blkif_release>> xlvbd_release_gendisk(info);
+ */
 static void xlvbd_release_gendisk(struct blkfront_info *info)
 {
 	unsigned int minor, nr_minors, i;
@@ -2153,6 +2160,18 @@ static int blkfront_resume(struct xenbus_device *dev)
 	return err;
 }
 
+/*
+ * callstack的一个例子:
+ * 先xl block-attach 3 file:/home/zhang/img/ubuntu/test.img xvdb rw
+ * 再xl block-detach 3 51728
+ * [0] blkfront_closing
+ * [0] blkback_changed
+ * [0] xenbus_otherend_changed
+ * [0] backend_changed
+ * [0] xenwatch_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ */
 static void blkfront_closing(struct blkfront_info *info)
 {
 	struct xenbus_device *xbdev = info->xbdev;
@@ -2464,6 +2483,12 @@ static void blkfront_connect(struct blkfront_info *info)
 /**
  * Callback received when the backend's state changes.
  */
+/*
+ * called by only:
+ *   - drivers/xen/xenbus/xenbus_probe.c|208| <<xenbus_otherend_changed>> drv->otherend_changed(dev, state);
+ *
+ * struct xenbus_driver blkfront_driver.otherend_changed = blkback_changed()
+ */
 static void blkback_changed(struct xenbus_device *dev,
 			    enum xenbus_state backend_state)
 {
@@ -2516,6 +2541,28 @@ static void blkback_changed(struct xenbus_device *dev,
 	}
 }
 
+/*
+ * callstack的一个例子:
+ * 先xl block-attach 3 file:/home/zhang/img/ubuntu/test.img xvdb rw
+ * 再xl block-detach 3 51728
+ * [0] blkfront_remove
+ * [0] xenbus_dev_remove
+ * [0] __device_release_driver
+ * [0] device_release_driver
+ * [0] bus_remove_device
+ * [0] device_del
+ * [0] device_unregister
+ * [0] xenbus_dev_changed
+ * [0] frontend_changed
+ * [0] xenwatch_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * called by:
+ *   - drivers/xen/xenbus/xenbus_probe.c|273| <<xenbus_dev_remove>> drv->remove(dev);
+ *
+ * struct xenbus_driver blkfront_driver.remove = blkfront_remove()
+ */
 static int blkfront_remove(struct xenbus_device *xbdev)
 {
 	struct blkfront_info *info = dev_get_drvdata(&xbdev->dev);
@@ -2603,6 +2650,19 @@ static int blkif_open(struct block_device *bdev, fmode_t mode)
 	return err;
 }
 
+/*
+ * callstack的一个例子:
+ * [0] blkif_release
+ * [0] __blkdev_put
+ * [0] blkdev_put
+ * [0] blkdev_close
+ * [0] __fput
+ * [0] ____fput
+ * [0] task_work_run
+ * [0] exit_to_usermode_loop
+ * [0] do_syscall_64
+ * [0] entry_SYSCALL_64_after_swapgs
+ */
 static void blkif_release(struct gendisk *disk, fmode_t mode)
 {
 	struct blkfront_info *info = disk->private_data;
diff --git a/drivers/nvme/host/pci.c b/drivers/nvme/host/pci.c
index 1ac4cec..1698885 100644
--- a/drivers/nvme/host/pci.c
+++ b/drivers/nvme/host/pci.c
@@ -736,6 +736,13 @@ static void nvme_process_cq(struct nvme_queue *nvmeq)
 	__nvme_process_cq(nvmeq, NULL);
 }
 
+/*
+ * [0] nvme_irq
+ * [0] irq_thread_fn
+ * [0] irq_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ */
 static irqreturn_t nvme_irq(int irq, void *data)
 {
 	irqreturn_t result;
@@ -748,6 +755,28 @@ static irqreturn_t nvme_irq(int irq, void *data)
 	return result;
 }
 
+/*
+ * [0] nvme_irq_check
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_edge_irq
+ * [0] handle_irq
+ * [0] do_IRQ
+ * [0] common_interrupt
+ * [0] irq_exit
+ * [0] smp_reschedule_interrupt
+ * [0] reschedule_interrupt
+ *
+ * [0] nvme_irq_check
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_edge_irq
+ * [0] handle_irq
+ * [0] do_IRQ
+ * [0] common_interrupt
+ */
 static irqreturn_t nvme_irq_check(int irq, void *data)
 {
 	struct nvme_queue *nvmeq = data;
@@ -1582,6 +1611,9 @@ static int nvme_dev_add(struct nvme_dev *dev)
 	return 0;
 }
 
+/*
+ * 有一个result = pci_alloc_irq_vectors(pdev, 1, 1, PCI_IRQ_ALL_TYPES);
+ */
 static int nvme_pci_enable(struct nvme_dev *dev)
 {
 	u64 cap;
diff --git a/drivers/xen/events/events_base.c b/drivers/xen/events/events_base.c
index 4b0cc9d..a7bf0a0 100644
--- a/drivers/xen/events/events_base.c
+++ b/drivers/xen/events/events_base.c
@@ -65,23 +65,85 @@
 const struct evtchn_ops *evtchn_ops;
 
 /*
+ * handle_edge_irq()被xen在以下调用:
+ *   - drivers/xen/events/events_base.c|1057| <<xen_bind_pirq_gsi_to_irq>> handle_edge_irq, name);
+ *   - drivers/xen/events/events_base.c|1120| <<xen_bind_pirq_msi_to_irq>> irq_set_chip_and_handler_name(irq + i, &xen_pirq_chip, handle_edge_irq, name);
+ *   - drivers/xen/events/events_base.c|1258| <<bind_evtchn_to_irq>> handle_edge_irq, "event");
+ *   - drivers/xen/events/events_base.c|1412| <<bind_virq_to_irq>> handle_edge_irq, "virq");
+ */
+
+/*
  * This lock protects updates to the following mapping and reference-count
  * arrays. The lock does not need to be acquired to read the mapping tables.
  */
 static DEFINE_MUTEX(irq_mapping_update_lock);
 
+/*
+ * 在以下使用xen_irq_list_head:
+ *   - drivers/xen/events/events_base.c|406| <<xen_irq_init>> list_add_tail(&info->list, &xen_irq_list_head);
+ *   - drivers/xen/events/events_base.c|615| <<xen_irq_from_gsi>> list_for_each_entry(info, &xen_irq_list_head, list) {
+ *   - drivers/xen/events/events_base.c|854| <<xen_irq_from_pirq>> list_for_each_entry(info, &xen_irq_list_head, list) {
+ *   - drivers/xen/events/events_base.c|1452| <<restore_pirqs>> list_for_each_entry(info, &xen_irq_list_head, list) {
+ *   - drivers/xen/events/events_base.c|1613| <<xen_irq_resume>> list_for_each_entry(info, &xen_irq_list_head, list)
+ *
+ * xen_irq_init()是唯一添加的地方
+ */
 static LIST_HEAD(xen_irq_list_head);
 
 /* IRQ <-> VIRQ mapping. */
+/*
+ * used by:
+ *   - drivers/xen/events/events_base.c|242| <<xen_irq_info_virq_setup>> per_cpu(virq_to_irq, cpu)[virq] = irq;
+ *   - drivers/xen/events/events_base.c|289| <<irq_from_virq>> return per_cpu(virq_to_irq, cpu)[virq];
+ *   - drivers/xen/events/events_base.c|708| <<__unbind_from_irq>> per_cpu(virq_to_irq, cpu)[virq_from_irq(irq)] = -1;
+ *   - drivers/xen/events/events_base.c|1085| <<bind_virq_to_irq>> irq = per_cpu(virq_to_irq, cpu)[virq];
+ *   - drivers/xen/events/events_base.c|1561| <<restore_cpu_virqs>> if ((irq = per_cpu(virq_to_irq, cpu)[virq]) == -1)
+ */
 static DEFINE_PER_CPU(int [NR_VIRQS], virq_to_irq) = {[0 ... NR_VIRQS-1] = -1};
 
 /* IRQ <-> IPI mapping */
+/*
+ * used by:
+ *   - drivers/xen/events/events_base.c|228| <<xen_irq_info_ipi_setup>> per_cpu(ipi_to_irq, cpu)[ipi] = irq;
+ *   - drivers/xen/events/events_base.c|711| <<__unbind_from_irq>> per_cpu(ipi_to_irq, cpu)[ipi_from_irq(irq)] = -1;
+ *   - drivers/xen/events/events_base.c|994| <<bind_ipi_to_irq>> irq = per_cpu(ipi_to_irq, cpu)[ipi];
+ *   - drivers/xen/events/events_base.c|1327| <<xen_send_IPI_one>> irq = per_cpu(ipi_to_irq, cpu)[vector];
+ *   - drivers/xen/events/events_base.c|1586| <<restore_cpu_ipis>> if ((irq = per_cpu(ipi_to_irq, cpu)[ipi]) == -1)
+ */
 static DEFINE_PER_CPU(int [XEN_NR_IPIS], ipi_to_irq) = {[0 ... XEN_NR_IPIS-1] = -1};
 
+/*
+ * used by:
+ *   - drivers/xen/events/events_base.c|95| <<EVTCHN_ROW>> #define EVTCHN_ROW(e) (e / (PAGE_SIZE/sizeof(**evtchn_to_irq)))
+ *   - drivers/xen/events/events_base.c|96| <<EVTCHN_COL>> #define EVTCHN_COL(e) (e % (PAGE_SIZE/sizeof(**evtchn_to_irq)))
+ *   - drivers/xen/events/events_base.c|97| <<EVTCHN_PER_ROW>> #define EVTCHN_PER_ROW (PAGE_SIZE / sizeof(**evtchn_to_irq))
+ *   - drivers/xen/events/events_base.c|113| <<clear_evtchn_to_irq_row>> evtchn_to_irq[row][col] = -1;
+ *   - drivers/xen/events/events_base.c|121| <<clear_evtchn_to_irq_all>> if (evtchn_to_irq[row] == NULL)
+ *   - drivers/xen/events/events_base.c|142| <<set_evtchn_to_irq>> if (evtchn_to_irq[row] == NULL) {
+ *   - drivers/xen/events/events_base.c|147| <<set_evtchn_to_irq>> evtchn_to_irq[row] = (int *)get_zeroed_page(GFP_KERNEL);
+ *   - drivers/xen/events/events_base.c|148| <<set_evtchn_to_irq>> if (evtchn_to_irq[row] == NULL)
+ *   - drivers/xen/events/events_base.c|154| <<set_evtchn_to_irq>> evtchn_to_irq[row][col] = irq;
+ *   - drivers/xen/events/events_base.c|162| <<get_evtchn_to_irq>> if (evtchn_to_irq[EVTCHN_ROW(evtchn)] == NULL)
+ *   - drivers/xen/events/events_base.c|164| <<get_evtchn_to_irq>> return evtchn_to_irq[EVTCHN_ROW(evtchn)][EVTCHN_COL(evtchn)];
+ */
 int **evtchn_to_irq;
 #ifdef CONFIG_X86
+/*
+ * used by:
+ *   - drivers/xen/events/events_base.c|376| <<pirq_check_eoi_map>> return test_bit(pirq_from_irq(irq), pirq_eoi_map);
+ *   - drivers/xen/events/events_base.c|1858| <<xen_init_IRQ>> pirq_eoi_map = (void *)__get_free_page(GFP_KERNEL|__GFP_ZERO);
+ *   - drivers/xen/events/events_base.c|1859| <<xen_init_IRQ>> eoi_gmfn.gmfn = virt_to_gfn(pirq_eoi_map);
+ *   - drivers/xen/events/events_base.c|1863| <<xen_init_IRQ>> free_page((unsigned long ) pirq_eoi_map);
+ *   - drivers/xen/events/events_base.c|1864| <<xen_init_IRQ>> pirq_eoi_map = NULL;
+ */
 static unsigned long *pirq_eoi_map;
 #endif
+/*
+ * used by:
+ *   - drivers/xen/events/events_base.c|608| <<eoi_pirq>> if (pirq_needs_eoi(data->irq)) {
+ *   - drivers/xen/events/events_base.c|1838| <<xen_init_IRQ>> pirq_needs_eoi = pirq_needs_eoi_flag;
+ *   - drivers/xen/events/events_base.c|1866| <<xen_init_IRQ>> pirq_needs_eoi = pirq_check_eoi_map;
+ */
 static bool (*pirq_needs_eoi)(unsigned irq);
 
 #define EVTCHN_ROW(e)  (e / (PAGE_SIZE/sizeof(**evtchn_to_irq)))
@@ -105,6 +167,10 @@ static void clear_evtchn_to_irq_row(unsigned row)
 		evtchn_to_irq[row][col] = -1;
 }
 
+/*
+ * called only by:
+ *   - drivers/xen/events/events_base.c|1946| <<xen_irq_resume>> clear_evtchn_to_irq_all();
+ */
 static void clear_evtchn_to_irq_all(void)
 {
 	unsigned row;
@@ -116,6 +182,15 @@ static void clear_evtchn_to_irq_all(void)
 	}
 }
 
+/*
+ * called by:
+ *   - drivers/xen/events/events_base.c|264| <<xen_irq_info_common_setup>> ret = set_evtchn_to_irq(evtchn, irq);
+ *   - drivers/xen/events/events_base.c|379| <<xen_irq_info_cleanup>> set_evtchn_to_irq(info->evtchn, -1);
+ *   - drivers/xen/events/events_base.c|791| <<__startup_pirq>> rc = set_evtchn_to_irq(evtchn, irq);
+ *
+ * 核心思想是: evtchn_to_irq[row][col] = irq;
+ * row和col通过evtchn计算
+ */
 static int set_evtchn_to_irq(unsigned evtchn, unsigned irq)
 {
 	unsigned row;
@@ -132,6 +207,7 @@ static int set_evtchn_to_irq(unsigned evtchn, unsigned irq)
 		if (irq == -1)
 			return 0;
 
+		/* 如果某一个row还没分配, 现场分配内存 -- on demand */
 		evtchn_to_irq[row] = (int *)get_zeroed_page(GFP_KERNEL);
 		if (evtchn_to_irq[row] == NULL)
 			return -ENOMEM;
@@ -143,12 +219,29 @@ static int set_evtchn_to_irq(unsigned evtchn, unsigned irq)
 	return 0;
 }
 
+/*
+ * 返回evtchn_to_irq[EVTCHN_ROW(evtchn)][EVTCHN_COL(evtchn)]
+ */
 int get_evtchn_to_irq(unsigned evtchn)
 {
 	if (evtchn >= xen_evtchn_max_channels())
 		return -1;
 	if (evtchn_to_irq[EVTCHN_ROW(evtchn)] == NULL)
 		return -1;
+	/*
+	 * used by:
+	 *   - drivers/xen/events/events_base.c|95| <<EVTCHN_ROW>> #define EVTCHN_ROW(e) (e / (PAGE_SIZE/sizeof(**evtchn_to_irq)))
+	 *   - drivers/xen/events/events_base.c|96| <<EVTCHN_COL>> #define EVTCHN_COL(e) (e % (PAGE_SIZE/sizeof(**evtchn_to_irq)))
+	 *   - drivers/xen/events/events_base.c|97| <<EVTCHN_PER_ROW>> #define EVTCHN_PER_ROW (PAGE_SIZE / sizeof(**evtchn_to_irq))
+	 *   - drivers/xen/events/events_base.c|113| <<clear_evtchn_to_irq_row>> evtchn_to_irq[row][col] = -1;
+	 *   - drivers/xen/events/events_base.c|121| <<clear_evtchn_to_irq_all>> if (evtchn_to_irq[row] == NULL)
+	 *   - drivers/xen/events/events_base.c|142| <<set_evtchn_to_irq>> if (evtchn_to_irq[row] == NULL) {
+	 *   - drivers/xen/events/events_base.c|147| <<set_evtchn_to_irq>> evtchn_to_irq[row] = (int *)get_zeroed_page(GFP_KERNEL);
+	 *   - drivers/xen/events/events_base.c|148| <<set_evtchn_to_irq>> if (evtchn_to_irq[row] == NULL)
+	 *   - drivers/xen/events/events_base.c|154| <<set_evtchn_to_irq>> evtchn_to_irq[row][col] = irq;
+	 *   - drivers/xen/events/events_base.c|162| <<get_evtchn_to_irq>> if (evtchn_to_irq[EVTCHN_ROW(evtchn)] == NULL)
+	 *   - drivers/xen/events/events_base.c|164| <<get_evtchn_to_irq>> return evtchn_to_irq[EVTCHN_ROW(evtchn)][EVTCHN_COL(evtchn)];
+	 */
 	return evtchn_to_irq[EVTCHN_ROW(evtchn)][EVTCHN_COL(evtchn)];
 }
 
@@ -159,6 +252,18 @@ struct irq_info *info_for_irq(unsigned irq)
 }
 
 /* Constructors for packed IRQ information. */
+/*
+ * called by:
+ *   - drivers/xen/events/events_base.c|262| <<xen_irq_info_evtchn_setup>> return xen_irq_info_common_setup(info, irq, IRQT_EVTCHN, evtchn, 0);
+ *   - drivers/xen/events/events_base.c|276| <<xen_irq_info_ipi_setup>> return xen_irq_info_common_setup(info, irq, IRQT_IPI, evtchn, 0);
+ *   - drivers/xen/events/events_base.c|290| <<xen_irq_info_virq_setup>> return xen_irq_info_common_setup(info, irq, IRQT_VIRQ, evtchn, 0);
+ *   - drivers/xen/events/events_base.c|307| <<xen_irq_info_pirq_setup>> return xen_irq_info_common_setup(info, irq, IRQT_PIRQ, evtchn, 0);
+ *
+ * 核心思想:
+ * 填充struct irq_info (第一个参数)
+ * evtchn_to_irq[row][col] = irq; row和col通过evtchn计算
+ * 调用evtchn_ops->setup(info), 只有fifo支持
+ */
 static int xen_irq_info_common_setup(struct irq_info *info,
 				     unsigned irq,
 				     enum xen_irq_type type,
@@ -169,28 +274,73 @@ static int xen_irq_info_common_setup(struct irq_info *info,
 
 	BUG_ON(info->type != IRQT_UNBOUND && info->type != type);
 
+	/*
+	 * type的例子:
+	 *   - IRQT_EVTCHN
+	 *   - IRQT_IPI
+	 *   - IRQT_VIRQ
+	 *   - IRQT_PIRQ
+	 */
 	info->type = type;
 	info->irq = irq;
 	info->evtchn = evtchn;
 	info->cpu = cpu;
 
+	/*
+	 * 核心思想是: evtchn_to_irq[row][col] = irq;
+	 * row和col通过evtchn计算
+	 */
 	ret = set_evtchn_to_irq(evtchn, irq);
 	if (ret < 0)
 		return ret;
 
+	/* linux的函数, 不是xen的 */
 	irq_clear_status_flags(irq, IRQ_NOREQUEST|IRQ_NOAUTOEN);
 
+	/*
+	 * 调用evtchn_ops->setup(info), 只有fifo支持
+	 */
 	return xen_evtchn_port_setup(info);
 }
 
+/*
+ * called by:
+ *   - drivers/xen/events/events_base.c|1012| <<bind_evtchn_to_irq>> ret = xen_irq_info_evtchn_setup(irq, evtchn);
+ *   - drivers/xen/events/events_base.c|1447| <<rebind_evtchn_irq>> (void )xen_irq_info_evtchn_setup(irq, evtchn);
+ *
+ * 核心思想:
+ * 根据参数的irq找到对应的struct irq_info
+ * 填充struct irq_info
+ * evtchn_to_irq[row][col] = irq; row和col通过evtchn计算
+ * 调用evtchn_ops->setup(info), 只有fifo支持
+ */
 static int xen_irq_info_evtchn_setup(unsigned irq,
 				     unsigned evtchn)
 {
+	/* Get info for IRQ */
 	struct irq_info *info = info_for_irq(irq);
 
+	/*
+	 * 核心思想:
+	 * 填充struct irq_info (第一个参数)
+	 * evtchn_to_irq[row][col] = irq; row和col通过evtchn计算
+	 * 调用evtchn_ops->setup(info), 只有fifo支持
+	 */
 	return xen_irq_info_common_setup(info, irq, IRQT_EVTCHN, evtchn, 0);
 }
 
+/*
+ * called by:
+ *   - drivers/xen/events/events_base.c|1237| <<bind_ipi_to_irq>> ret = xen_irq_info_ipi_setup(cpu, irq, evtchn, ipi);
+ *   - drivers/xen/events/events_base.c|1858| <<restore_cpu_ipis>> (void )xen_irq_info_ipi_setup(cpu, irq, evtchn, ipi);
+ *
+ * 核心思想:
+ * 根据参数irq找到对应的struct irq_info, 填充info->u.ipi = ipi
+ * 设置ipi_to_irq
+ * 填充struct irq_info
+ * evtchn_to_irq[row][col] = irq; row和col通过evtchn计算
+ * 调用evtchn_ops->setup(info), 只有fifo支持
+ */
 static int xen_irq_info_ipi_setup(unsigned cpu,
 				  unsigned irq,
 				  unsigned evtchn,
@@ -200,11 +350,37 @@ static int xen_irq_info_ipi_setup(unsigned cpu,
 
 	info->u.ipi = ipi;
 
+	/*
+	 * used by:
+	 *   - drivers/xen/events/events_base.c|228| <<xen_irq_info_ipi_setup>> per_cpu(ipi_to_irq, cpu)[ipi] = irq;
+	 *   - drivers/xen/events/events_base.c|711| <<__unbind_from_irq>> per_cpu(ipi_to_irq, cpu)[ipi_from_irq(irq)] = -1;
+	 *   - drivers/xen/events/events_base.c|994| <<bind_ipi_to_irq>> irq = per_cpu(ipi_to_irq, cpu)[ipi];
+	 *   - drivers/xen/events/events_base.c|1327| <<xen_send_IPI_one>> irq = per_cpu(ipi_to_irq, cpu)[vector];
+	 *   - drivers/xen/events/events_base.c|1586| <<restore_cpu_ipis>> if ((irq = per_cpu(ipi_to_irq, cpu)[ipi]) == -1)
+	 */
 	per_cpu(ipi_to_irq, cpu)[ipi] = irq;
 
+	/*
+	 * 核心思想:
+	 * 填充struct irq_info (第一个参数)
+	 * evtchn_to_irq[row][col] = irq; row和col通过evtchn计算
+	 * 调用evtchn_ops->setup(info), 只有fifo支持
+	 */
 	return xen_irq_info_common_setup(info, irq, IRQT_IPI, evtchn, 0);
 }
 
+/*
+ * called by:
+ *   - drivers/xen/events/events_base.c|1194| <<bind_virq_to_irq>> ret = xen_irq_info_virq_setup(cpu, irq, evtchn, virq);
+ *   - drivers/xen/events/events_base.c|1657| <<restore_cpu_virqs>> (void )xen_irq_info_virq_setup(cpu, irq, evtchn, virq);
+ *
+ * 核心思想:
+ * 根据参数irq找到对应的struct irq_info, 填充info->u.virq = virq
+ * 设置virq_to_irq
+ * 填充struct irq_info
+ * evtchn_to_irq[row][col] = irq; row和col通过evtchn计算
+ * 调用evtchn_ops->setup(info), 只有fifo支持
+ */
 static int xen_irq_info_virq_setup(unsigned cpu,
 				   unsigned irq,
 				   unsigned evtchn,
@@ -216,9 +392,26 @@ static int xen_irq_info_virq_setup(unsigned cpu,
 
 	per_cpu(virq_to_irq, cpu)[virq] = irq;
 
+	/*
+	 * 核心思想:
+	 * 填充struct irq_info (第一个参数)
+	 * evtchn_to_irq[row][col] = irq; row和col通过evtchn计算
+	 * 调用evtchn_ops->setup(info), 只有fifo支持
+	 */
 	return xen_irq_info_common_setup(info, irq, IRQT_VIRQ, evtchn, 0);
 }
 
+/*
+ * called by:
+ *   - drivers/xen/events/events_base.c|854| <<xen_bind_pirq_gsi_to_irq>> ret = xen_irq_info_pirq_setup(irq, 0, pirq, gsi, DOMID_SELF,
+ *   - drivers/xen/events/events_base.c|934| <<xen_bind_pirq_msi_to_irq>> ret = xen_irq_info_pirq_setup(irq + i, 0, pirq + i, 0, domid,
+ *
+ * 核心思想:
+ * 根据irq找到对应的struct irq_info
+ * 设置nfo->u.pirq, 填充struct irq_info
+ * evtchn_to_irq[row][col] = irq; row和col通过evtchn计算
+ * 调用evtchn_ops->setup(info), 只有fifo支持
+ */
 static int xen_irq_info_pirq_setup(unsigned irq,
 				   unsigned evtchn,
 				   unsigned pirq,
@@ -226,6 +419,7 @@ static int xen_irq_info_pirq_setup(unsigned irq,
 				   uint16_t domid,
 				   unsigned char flags)
 {
+	/* Get info for IRQ */
 	struct irq_info *info = info_for_irq(irq);
 
 	info->u.pirq.pirq = pirq;
@@ -233,9 +427,20 @@ static int xen_irq_info_pirq_setup(unsigned irq,
 	info->u.pirq.domid = domid;
 	info->u.pirq.flags = flags;
 
+	/*
+	 * 核心思想:
+	 * 填充struct irq_info (第一个参数)
+	 * evtchn_to_irq[row][col] = irq; row和col通过evtchn计算
+	 * 调用evtchn_ops->setup(info), 只有fifo支持
+	 */
 	return xen_irq_info_common_setup(info, irq, IRQT_PIRQ, evtchn, 0);
 }
 
+/*
+ * called by:
+ *   - drivers/xen/events/events_base.c|842| <<shutdown_pirq>> xen_irq_info_cleanup(info);
+ *   - drivers/xen/events/events_base.c|906| <<__unbind_from_irq>> xen_irq_info_cleanup(info);
+ */
 static void xen_irq_info_cleanup(struct irq_info *info)
 {
 	set_evtchn_to_irq(info->evtchn, -1);
@@ -245,6 +450,9 @@ static void xen_irq_info_cleanup(struct irq_info *info)
 /*
  * Accessors for packed IRQ information.
  */
+/*
+ * 返回info_for_irq(irq)->evtchn
+ */
 unsigned int evtchn_from_irq(unsigned irq)
 {
 	if (unlikely(WARN(irq >= nr_irqs, "Invalid irq %d!\n", irq)))
@@ -253,6 +461,9 @@ unsigned int evtchn_from_irq(unsigned irq)
 	return info_for_irq(irq)->evtchn;
 }
 
+/*
+ * 返回evtchn_to_irq[EVTCHN_ROW(evtchn)][EVTCHN_COL(evtchn)]
+ */
 unsigned irq_from_evtchn(unsigned int evtchn)
 {
 	return get_evtchn_to_irq(evtchn);
@@ -294,6 +505,18 @@ static unsigned pirq_from_irq(unsigned irq)
 	return info->u.pirq.pirq;
 }
 
+/*
+ * enum xen_irq_type {
+ *     IRQT_UNBOUND = 0,
+ *     IRQT_PIRQ,
+ *     IRQT_VIRQ,
+ *     IRQT_IPI,
+ *     IRQT_EVTCHN
+ * };
+ *
+ * called by:
+ *   - drivers/xen/events/events_base.c|895| <<__unbind_from_irq>> switch (type_from_irq(irq)) {
+ */
 static enum xen_irq_type type_from_irq(unsigned irq)
 {
 	return info_for_irq(irq)->type;
@@ -316,12 +539,34 @@ unsigned int cpu_from_evtchn(unsigned int evtchn)
 }
 
 #ifdef CONFIG_X86
+/*
+ * used by:
+ *   - drivers/xen/events/events_base.c|1918| <<xen_init_IRQ>> pirq_needs_eoi = pirq_check_eoi_map;
+ *
+ * called by:
+ *   - drivers/xen/events/events_base.c|660| <<eoi_pirq>> if (pirq_needs_eoi(data->irq)) {
+ */
 static bool pirq_check_eoi_map(unsigned irq)
 {
+	/*
+	 * used by:
+	 *   - drivers/xen/events/events_base.c|376| <<pirq_check_eoi_map>> return test_bit(pirq_from_irq(irq), pirq_eoi_map);
+	 *   - drivers/xen/events/events_base.c|1858| <<xen_init_IRQ>> pirq_eoi_map = (void *)__get_free_page(GFP_KERNEL|__GFP_ZERO);
+	 *   - drivers/xen/events/events_base.c|1859| <<xen_init_IRQ>> eoi_gmfn.gmfn = virt_to_gfn(pirq_eoi_map);
+	 *   - drivers/xen/events/events_base.c|1863| <<xen_init_IRQ>> free_page((unsigned long ) pirq_eoi_map);
+	 *   - drivers/xen/events/events_base.c|1864| <<xen_init_IRQ>> pirq_eoi_map = NULL;
+	 */
 	return test_bit(pirq_from_irq(irq), pirq_eoi_map);
 }
 #endif
 
+/*
+ * used by:
+ *   - drivers/xen/events/events_base.c|1916| <<xen_init_IRQ>> pirq_needs_eoi = pirq_needs_eoi_flag;
+ *
+ * called by:
+ *   - drivers/xen/events/events_base.c|686| <<eoi_pirq>> if (pirq_needs_eoi(data->irq)) {
+ */
 static bool pirq_needs_eoi_flag(unsigned irq)
 {
 	struct irq_info *info = info_for_irq(irq);
@@ -330,6 +575,17 @@ static bool pirq_needs_eoi_flag(unsigned irq)
 	return info->u.pirq.flags & PIRQ_NEEDS_EOI;
 }
 
+/*
+ * called by:
+ *   - drivers/xen/events/events_base.c|899| <<__startup_pirq>> bind_evtchn_to_cpu(evtchn, 0);
+ *   - drivers/xen/events/events_base.c|1333| <<bind_evtchn_to_irq>> bind_evtchn_to_cpu(evtchn, 0);
+ *   - drivers/xen/events/events_base.c|1380| <<bind_ipi_to_irq>> bind_evtchn_to_cpu(evtchn, cpu);
+ *   - drivers/xen/events/events_base.c|1500| <<bind_virq_to_irq>> bind_evtchn_to_cpu(evtchn, cpu);
+ *   - drivers/xen/events/events_base.c|1835| <<rebind_evtchn_irq>> bind_evtchn_to_cpu(evtchn, info->cpu);
+ *   - drivers/xen/events/events_base.c|1876| <<rebind_irq_to_cpu>> bind_evtchn_to_cpu(evtchn, tcpu);
+ *   - drivers/xen/events/events_base.c|2041| <<restore_cpu_virqs>> bind_evtchn_to_cpu(evtchn, cpu);
+ *   - drivers/xen/events/events_base.c|2065| <<restore_cpu_ipis>> bind_evtchn_to_cpu(evtchn, cpu);
+ */
 static void bind_evtchn_to_cpu(unsigned int chn, unsigned int cpu)
 {
 	int irq = get_evtchn_to_irq(chn);
@@ -339,6 +595,7 @@ static void bind_evtchn_to_cpu(unsigned int chn, unsigned int cpu)
 #ifdef CONFIG_SMP
 	cpumask_copy(irq_get_affinity_mask(irq), cpumask_of(cpu));
 #endif
+	/* 调用evtchn_ops->bind_to_cpu(info, cpu) */
 	xen_evtchn_port_bind_to_cpu(info, cpu);
 
 	info->cpu = cpu;
@@ -348,6 +605,7 @@ static void xen_evtchn_mask_all(void)
 {
 	unsigned int evtchn;
 
+	/* 调用evtchn_ops->mask(port) */
 	for (evtchn = 0; evtchn < xen_evtchn_nr_channels(); evtchn++)
 		mask_evtchn(evtchn);
 }
@@ -369,11 +627,24 @@ void notify_remote_via_irq(int irq)
 }
 EXPORT_SYMBOL_GPL(notify_remote_via_irq);
 
+/*
+ * called by:
+ *   - drivers/xen/events/events_base.c|442| <<xen_allocate_irqs_dynamic>> xen_irq_init(irq + i);
+ *   - drivers/xen/events/events_base.c|480| <<xen_allocate_irq_gsi>> xen_irq_init(irq);
+ *
+ * 分配一个struct irq_info *info
+ * 把info(struct irq_info)设置为irq对应的desc->irq_common_data.handler_data
+ * 最后把info插入xen_irq_list_head
+ *
+ * 这个函数是唯一把info插入xen_irq_list_head的地方
+ */
 static void xen_irq_init(unsigned irq)
 {
+	/* 是xen特有的一个结构 */
 	struct irq_info *info;
 #ifdef CONFIG_SMP
 	/* By default all event channels notify CPU#0. */
+	/* 默认在cpu 0 */
 	cpumask_copy(irq_get_affinity_mask(irq), cpumask_of(0));
 #endif
 
@@ -384,16 +655,46 @@ static void xen_irq_init(unsigned irq)
 	info->type = IRQT_UNBOUND;
 	info->refcnt = -1;
 
+	/* 把info(struct irq_info)设置为irq对应的desc->irq_common_data.handler_data */
 	irq_set_handler_data(irq, info);
 
+	/*
+	 * 在以下使用xen_irq_list_head:
+	 *   - drivers/xen/events/events_base.c|406| <<xen_irq_init>> list_add_tail(&info->list, &xen_irq_list_head);
+	 *   - drivers/xen/events/events_base.c|615| <<xen_irq_from_gsi>> list_for_each_entry(info, &xen_irq_list_head, list) {
+	 *   - drivers/xen/events/events_base.c|854| <<xen_irq_from_pirq>> list_for_each_entry(info, &xen_irq_list_head, list) {
+	 *   - drivers/xen/events/events_base.c|1452| <<restore_pirqs>> list_for_each_entry(info, &xen_irq_list_head, list) {
+	 *   - drivers/xen/events/events_base.c|1613| <<xen_irq_resume>> list_for_each_entry(info, &xen_irq_list_head, list)
+	 * 
+	 * 这个函数是唯一把info插入xen_irq_list_head的地方
+	 */
 	list_add_tail(&info->list, &xen_irq_list_head);
 }
 
+/*
+ * called by:
+ *   - drivers/xen/events/events_base.c|440| <<xen_allocate_irq_dynamic>> return xen_allocate_irqs_dynamic(1);
+ *   - drivers/xen/events/events_base.c|798| <<xen_bind_pirq_msi_to_irq>> irq = xen_allocate_irqs_dynamic(nvec);
+ *
+ * 分配nvec个irq, 也就是nvec个desc, 对于每一个分配的irq
+ * 分配一个struct irq_info *info
+ * 把info(struct irq_info)设置为irq对应的desc->irq_common_data.handler_data
+ * 最后把info插入xen_irq_list_head
+ */
 static int __must_check xen_allocate_irqs_dynamic(int nvec)
 {
+	/*
+	 * allocate and initialize a range of irq descriptors
+	 * return the first irq number or error code
+	 */
 	int i, irq = irq_alloc_descs(-1, 0, nvec, -1);
 
 	if (irq >= 0) {
+		/*
+		 * 分配一个struct irq_info *info
+		 * 把info(struct irq_info)设置为irq对应的desc->irq_common_data.handler_data
+		 * 最后把info插入xen_irq_list_head
+		 */
 		for (i = 0; i < nvec; i++)
 			xen_irq_init(irq + i);
 	}
@@ -401,12 +702,33 @@ static int __must_check xen_allocate_irqs_dynamic(int nvec)
 	return irq;
 }
 
+/*
+ * called by:
+ *   - drivers/xen/events/events_base.c|454| <<xen_allocate_irq_gsi>> return xen_allocate_irq_dynamic();
+ *   - drivers/xen/events/events_base.c|917| <<bind_evtchn_to_irq>> irq = xen_allocate_irq_dynamic();
+ *   - drivers/xen/events/events_base.c|955| <<bind_ipi_to_irq>> irq = xen_allocate_irq_dynamic();
+ *   - drivers/xen/events/events_base.c|1046| <<bind_virq_to_irq>> irq = xen_allocate_irq_dynamic();
+ *
+ * 分配1个irq, 也就是1个desc, 对于分配的irq
+ * 分配一个struct irq_info *info
+ * 把info(struct irq_info)设置为irq对应的desc->irq_common_data.handler_data
+ * 最后把info插入xen_irq_list_head
+ */
 static inline int __must_check xen_allocate_irq_dynamic(void)
 {
 
 	return xen_allocate_irqs_dynamic(1);
 }
 
+/*
+ * called by only:
+ *   - drivers/xen/events/events_base.c|741| <<xen_bind_pirq_gsi_to_irq>> irq = xen_allocate_irq_gsi(gsi);
+ *
+ * 对于dom0, 核心思想是:
+ * 分配一个struct irq_info *info
+ * 把info(struct irq_info)设置为irq对应的desc->irq_common_data.handler_data
+ * 最后把info插入xen_irq_list_head
+ */
 static int __must_check xen_allocate_irq_gsi(unsigned gsi)
 {
 	int irq;
@@ -417,6 +739,12 @@ static int __must_check xen_allocate_irq_gsi(unsigned gsi)
 	 * all IRQs are dynamically allocated from the entire IRQ
 	 * space.
 	 */
+	/*
+	 * 分配1个irq, 也就是1个desc, 对于分配的irq
+	 * 分配一个struct irq_info *info
+	 * 把info(struct irq_info)设置为irq对应的desc->irq_common_data.handler_data
+	 * 最后把info插入xen_irq_list_head
+	 */
 	if (xen_pv_domain() && !xen_initial_domain())
 		return xen_allocate_irq_dynamic();
 
@@ -426,11 +754,23 @@ static int __must_check xen_allocate_irq_gsi(unsigned gsi)
 	else
 		irq = irq_alloc_desc_at(gsi, -1);
 
+	/*
+	 * 分配一个struct irq_info *info
+	 * 把info(struct irq_info)设置为irq对应的desc->irq_common_data.handler_data
+	 * 最后把info插入xen_irq_list_head
+	 */
 	xen_irq_init(irq);
 
 	return irq;
 }
 
+/*
+ * called by:
+ *   - drivers/xen/events/events_base.c|828| <<__unbind_from_irq>> xen_free_irq(irq);
+ *   - drivers/xen/events/events_base.c|875| <<xen_bind_pirq_gsi_to_irq>> xen_free_irq(irq);
+ *   - drivers/xen/events/events_base.c|1010| <<xen_destroy_irq>> xen_free_irq(irq);
+ *   - drivers/xen/events/events_base.c|1653| <<restore_pirqs>> xen_free_irq(irq);
+ */
 static void xen_free_irq(unsigned irq)
 {
 	struct irq_info *info = irq_get_handler_data(irq);
@@ -462,6 +802,11 @@ static void xen_evtchn_close(unsigned int port)
 		BUG();
 }
 
+/*
+ * called by:
+ *   - drivers/xen/events/events_base.c|747| <<__startup_pirq>> pirq_query_unmask(irq);
+ *   - drivers/xen/events/events_base.c|914| <<xen_bind_pirq_gsi_to_irq>> pirq_query_unmask(irq);
+ */
 static void pirq_query_unmask(int irq)
 {
 	struct physdev_irq_status_query irq_status;
@@ -474,10 +819,15 @@ static void pirq_query_unmask(int irq)
 		irq_status.flags = 0;
 
 	info->u.pirq.flags &= ~PIRQ_NEEDS_EOI;
+	/* Need to call PHYSDEVOP_eoi when the IRQ has been serviced? */
 	if (irq_status.flags & XENIRQSTAT_needs_eoi)
 		info->u.pirq.flags |= PIRQ_NEEDS_EOI;
 }
 
+/*
+ * struct irq_chip xen_pirq_chip.irq_ack = eoi_pirq()
+ * struct irq_chip xen_pirq_chip.irq_eoi = eoi_pirq()
+ */
 static void eoi_pirq(struct irq_data *data)
 {
 	int evtchn = evtchn_from_irq(data->irq);
@@ -500,18 +850,52 @@ static void eoi_pirq(struct irq_data *data)
 	} else
 		clear_evtchn(evtchn);
 
+	/*
+	 * used by:     
+	 *   - drivers/xen/events/events_base.c|608| <<eoi_pirq>> if (pirq_needs_eoi(data->irq)) {
+	 *   - drivers/xen/events/events_base.c|1838| <<xen_init_IRQ>> pirq_needs_eoi = pirq_needs_eoi_flag;
+	 *   - drivers/xen/events/events_base.c|1866| <<xen_init_IRQ>> pirq_needs_eoi = pirq_check_eoi_map;
+	 */
 	if (pirq_needs_eoi(data->irq)) {
 		rc = HYPERVISOR_physdev_op(PHYSDEVOP_eoi, &eoi);
 		WARN_ON(rc);
 	}
 }
 
+/*
+ * struct irq_chip xen_pirq_chip.irq_mask_ack = mask_ack_pirq()
+ */
 static void mask_ack_pirq(struct irq_data *data)
 {
 	disable_dynirq(data);
 	eoi_pirq(data);
 }
 
+/*
+ * [    4.348949] Call Trace:
+ * [    4.349446]  [<ffffffff8135118e>] dump_stack+0x63/0x85
+ * [    4.349941]  [<ffffffff813fc922>] __startup_pirq+0x42/0x150
+ * [    4.350431]  [<ffffffff8137a8cb>] ? pci_bus_write_config_word.part.8+0x5b/0x70
+ * [    4.350919]  [<ffffffff813fca3c>] startup_pirq+0xc/0x10
+ * [    4.351404]  [<ffffffff810c1575>] irq_startup+0x45/0x80
+ * [    4.351881]  [<ffffffff810bfe94>] __setup_irq+0x564/0x610
+ * [    4.352352]  [<ffffffff810c010d>] request_threaded_irq+0x10d/0x1e0
+ * [    4.352822]  [<ffffffffa000c9e9>] queue_request_irq+0x49/0x80 [nvme]
+ * [    4.353292]  [<ffffffffa000e0b3>] nvme_reset_work+0x7a3/0xe20 [nvme]
+ * [    4.353758]  [<ffffffff8102b6a4>] ? __switch_to+0x1f4/0x660
+ * [    4.354216]  [<ffffffff8196e760>] ? __switch_to_asm+0x30/0x60
+ * [    4.354668]  [<ffffffff8109446c>] ? finish_task_switch+0x6c/0x1d0
+ * [    4.355116]  [<ffffffff81087bb7>] process_one_work+0x167/0x490
+ * [    4.355562]  [<ffffffff81087f26>] worker_thread+0x46/0x4f0
+ * [    4.356005]  [<ffffffff81087ee0>] ? process_one_work+0x490/0x490
+ * [    4.356444]  [<ffffffff8108da94>] kthread+0xd4/0xf0
+ * [    4.356881]  [<ffffffff8108d9c0>] ? kthread_park+0x60/0x60
+ * [    4.357317]  [<ffffffff8196e7e7>] ret_from_fork+0x57/0x70
+ *
+ * called by:
+ *   - drivers/xen/events/events_base.c|774| <<startup_pirq>> return __startup_pirq(data->irq);
+ *   - drivers/xen/events/events_base.c|1685| <<restore_pirqs>> __startup_pirq(irq);
+ */
 static unsigned int __startup_pirq(unsigned int irq)
 {
 	struct evtchn_bind_pirq bind_pirq;
@@ -528,6 +912,7 @@ static unsigned int __startup_pirq(unsigned int irq)
 	/* NB. We are happy to share unless we are probing. */
 	bind_pirq.flags = info->u.pirq.flags & PIRQ_SHAREABLE ?
 					BIND_PIRQ__WILL_SHARE : 0;
+	/* Bind a local event channel to PIRQ <irq> */
 	rc = HYPERVISOR_event_channel_op(EVTCHNOP_bind_pirq, &bind_pirq);
 	if (rc != 0) {
 		pr_warn("Failed to obtain physical IRQ %d\n", irq);
@@ -544,6 +929,7 @@ static unsigned int __startup_pirq(unsigned int irq)
 	info->evtchn = evtchn;
 	bind_evtchn_to_cpu(evtchn, 0);
 
+	/* 调用evtchn_ops->setup(info), 只有fifo支持 */
 	rc = xen_evtchn_port_setup(info);
 	if (rc)
 		goto err;
@@ -560,11 +946,17 @@ static unsigned int __startup_pirq(unsigned int irq)
 	return 0;
 }
 
+/*
+ * struct irq_chip xen_pirq_chip.irq_startup = startup_pirq()
+ */
 static unsigned int startup_pirq(struct irq_data *data)
 {
 	return __startup_pirq(data->irq);
 }
 
+/*
+ * struct irq_chip xen_pirq_chip.irq_shutdown = shutdown_pirq()
+ */
 static void shutdown_pirq(struct irq_data *data)
 {
 	unsigned int irq = data->irq;
@@ -581,16 +973,30 @@ static void shutdown_pirq(struct irq_data *data)
 	xen_irq_info_cleanup(info);
 }
 
+/*
+ * struct irq_chip xen_pirq_chip.irq_enable = enable_pirq()
+ */
 static void enable_pirq(struct irq_data *data)
 {
 	startup_pirq(data);
 }
 
+/*
+ * struct irq_chip xen_pirq_chip.irq_disable = disable_pirq()
+ */
 static void disable_pirq(struct irq_data *data)
 {
 	disable_dynirq(data);
 }
 
+/*
+ * called by:
+ *   - arch/x86/pci/xen.c|133| <<xen_register_pirq>> irq = xen_irq_from_gsi(gsi);
+ *   - drivers/xen/events/events_base.c|685| <<xen_bind_pirq_gsi_to_irq>> irq = xen_irq_from_gsi(gsi);
+ *
+ * 遍历xen_irq_list_head上的所有struct irq_info,
+ * 返回info->irq (谁的info->u.pirq.gsi是参数的gsi)
+ */
 int xen_irq_from_gsi(unsigned gsi)
 {
 	struct irq_info *info;
@@ -607,6 +1013,15 @@ int xen_irq_from_gsi(unsigned gsi)
 }
 EXPORT_SYMBOL_GPL(xen_irq_from_gsi);
 
+/*
+ * called by:
+ *   - drivers/xen/events/events_base.c|1022| <<xen_bind_pirq_gsi_to_irq>> __unbind_from_irq(irq);
+ *   - drivers/xen/events/events_base.c|1119| <<xen_bind_pirq_msi_to_irq>> __unbind_from_irq(irq + nvec);
+ *   - drivers/xen/events/events_base.c|1235| <<bind_evtchn_to_irq>> __unbind_from_irq(irq);
+ *   - drivers/xen/events/events_base.c|1279| <<bind_ipi_to_irq>> __unbind_from_irq(irq);
+ *   - drivers/xen/events/events_base.c|1381| <<bind_virq_to_irq>> __unbind_from_irq(irq);
+ *   - drivers/xen/events/events_base.c|1401| <<unbind_from_irq>> __unbind_from_irq(irq);
+ */
 static void __unbind_from_irq(unsigned int irq)
 {
 	int evtchn = evtchn_from_irq(irq);
@@ -650,6 +1065,12 @@ static void __unbind_from_irq(unsigned int irq)
  * Shareable implies level triggered, not shareable implies edge
  * triggered here.
  */
+/*
+ * called by:
+ *   - arch/x86/pci/xen.c|49| <<xen_pcifront_enable_irq>> rc = xen_bind_pirq_gsi_to_irq(gsi, pirq, share, "pcifront");
+ *   - arch/x86/pci/xen.c|99| <<xen_register_pirq>> irq = xen_bind_pirq_gsi_to_irq(gsi, map_irq.pirq, shareable, name);
+ *   - arch/x86/pci/xen.c|501| <<pci_xen_initial_domain>> xen_bind_pirq_gsi_to_irq(irq, irq, 0, "xt-pic");
+ */
 int xen_bind_pirq_gsi_to_irq(unsigned gsi,
 			     unsigned pirq, int shareable, char *name)
 {
@@ -659,13 +1080,24 @@ int xen_bind_pirq_gsi_to_irq(unsigned gsi,
 
 	mutex_lock(&irq_mapping_update_lock);
 
+	/*
+	 * 遍历xen_irq_list_head上的所有struct irq_info,
+	 * 返回info->irq (谁的info->u.pirq.gsi是参数的gsi)
+	 */
 	irq = xen_irq_from_gsi(gsi);
+	/* 如果找到了 */
 	if (irq != -1) {
 		pr_info("%s: returning irq %d for gsi %u\n",
 			__func__, irq, gsi);
 		goto out;
 	}
 
+	/*
+	 * 对于dom0, 核心思想是:
+	 * 分配一个struct irq_info *info
+	 * 把info(struct irq_info)设置为irq对应的desc->irq_common_data.handler_data
+	 * 最后把info插入xen_irq_list_head
+	 */
 	irq = xen_allocate_irq_gsi(gsi);
 	if (irq < 0)
 		goto out;
@@ -683,6 +1115,13 @@ int xen_bind_pirq_gsi_to_irq(unsigned gsi,
 		goto out;
 	}
 
+	/*
+	 * 核心思想:
+	 * 根据irq找到对应的struct irq_info
+	 * 设置nfo->u.pirq, 填充struct irq_info
+	 * evtchn_to_irq[row][col] = irq; row和col通过evtchn计算
+	 * 调用evtchn_ops->setup(info), 只有fifo支持
+	 */
 	ret = xen_irq_info_pirq_setup(irq, 0, pirq, gsi, DOMID_SELF,
 			       shareable ? PIRQ_SHAREABLE : 0);
 	if (ret < 0) {
@@ -721,11 +1160,25 @@ int xen_bind_pirq_gsi_to_irq(unsigned gsi,
 }
 
 #ifdef CONFIG_PCI_MSI
+/*
+ * Allocate a pirq for a MSI style physical interrupt
+ *
+ * called by:
+ *   - arch/x86/pci/xen.c|327| <<xen_hvm_setup_msi_irqs>> pirq = xen_allocate_pirq_msi(dev, msidesc);
+ */
 int xen_allocate_pirq_msi(struct pci_dev *dev, struct msi_desc *msidesc)
 {
 	int rc;
 	struct physdev_get_free_pirq op_get_free_pirq;
 
+	/*
+	 * type可能有如下的类型:
+	 * #define MAP_PIRQ_TYPE_MSI               0x0
+	 * #define MAP_PIRQ_TYPE_GSI               0x1
+	 * #define MAP_PIRQ_TYPE_UNKNOWN           0x2
+	 * #define MAP_PIRQ_TYPE_MSI_SEG           0x3
+	 * #define MAP_PIRQ_TYPE_MULTI_MSI         0x4
+	 */
 	op_get_free_pirq.type = MAP_PIRQ_TYPE_MSI;
 	rc = HYPERVISOR_physdev_op(PHYSDEVOP_get_free_pirq, &op_get_free_pirq);
 
@@ -735,6 +1188,14 @@ int xen_allocate_pirq_msi(struct pci_dev *dev, struct msi_desc *msidesc)
 	return rc ? -1 : op_get_free_pirq.pirq;
 }
 
+/*
+ * called by:
+ *   - arch/x86/pci/xen.c|212| <<xen_setup_msi_irqs>> irq = xen_bind_pirq_msi_to_irq(dev, msidesc, v[i],
+ *   - arch/x86/pci/xen.c|282| <<xen_hvm_setup_msi_irqs>> irq = xen_bind_pirq_msi_to_irq(dev, msidesc, pirq,
+ *   - arch/x86/pci/xen.c|434| <<xen_initdom_setup_msi_irqs>> ret = xen_bind_pirq_msi_to_irq(dev, msidesc, map_irq.pirq,
+ *
+ * Bind an PSI pirq to an irq
+ */
 int xen_bind_pirq_msi_to_irq(struct pci_dev *dev, struct msi_desc *msidesc,
 			     int pirq, int nvec, const char *name, domid_t domid)
 {
@@ -742,6 +1203,12 @@ int xen_bind_pirq_msi_to_irq(struct pci_dev *dev, struct msi_desc *msidesc,
 
 	mutex_lock(&irq_mapping_update_lock);
 
+	/*
+	 * 分配nvec个irq, 也就是nvec个desc, 对于每一个分配的irq
+	 * 分配一个struct irq_info *info
+	 * 把info(struct irq_info)设置为irq对应的desc->irq_common_data.handler_data
+	 * 最后把info插入xen_irq_list_head
+	 */
 	irq = xen_allocate_irqs_dynamic(nvec);
 	if (irq < 0)
 		goto out;
@@ -749,6 +1216,11 @@ int xen_bind_pirq_msi_to_irq(struct pci_dev *dev, struct msi_desc *msidesc,
 	for (i = 0; i < nvec; i++) {
 		irq_set_chip_and_handler_name(irq + i, &xen_pirq_chip, handle_edge_irq, name);
 
+		/*
+		 * 核心思想: 填充struct irq_info (第一个参数), 先为irq设置struct irq_info
+		 * evtchn_to_irq[row][col] = irq; row和col通过evtchn计算
+		 * 调用evtchn_ops->setup(info), 只有fifo支持
+		 */
 		ret = xen_irq_info_pirq_setup(irq + i, 0, pirq + i, 0, domid,
 					      i == 0 ? 0 : PIRQ_MSI_GROUP);
 		if (ret < 0)
@@ -769,6 +1241,10 @@ int xen_bind_pirq_msi_to_irq(struct pci_dev *dev, struct msi_desc *msidesc,
 }
 #endif
 
+/*
+ * called by:
+ *   - arch/x86/pci/xen.c|909| <<xen_teardown_msi_irq>> xen_destroy_irq(irq);
+ */
 int xen_destroy_irq(int irq)
 {
 	struct physdev_unmap_pirq unmap_irq;
@@ -814,6 +1290,14 @@ int xen_irq_from_pirq(unsigned pirq)
 
 	mutex_lock(&irq_mapping_update_lock);
 
+	/*
+	 * 在以下使用xen_irq_list_head:
+	 *   - drivers/xen/events/events_base.c|406| <<xen_irq_init>> list_add_tail(&info->list, &xen_irq_list_head);
+	 *   - drivers/xen/events/events_base.c|615| <<xen_irq_from_gsi>> list_for_each_entry(info, &xen_irq_list_head, list) {
+	 *   - drivers/xen/events/events_base.c|854| <<xen_irq_from_pirq>> list_for_each_entry(info, &xen_irq_list_head, list) {
+	 *   - drivers/xen/events/events_base.c|1452| <<restore_pirqs>> list_for_each_entry(info, &xen_irq_list_head, list) {
+	 *   - drivers/xen/events/events_base.c|1613| <<xen_irq_resume>> list_for_each_entry(info, &xen_irq_list_head, list)
+	 */
 	list_for_each_entry(info, &xen_irq_list_head, list) {
 		if (info->type != IRQT_PIRQ)
 			continue;
@@ -835,6 +1319,14 @@ int xen_pirq_from_irq(unsigned irq)
 }
 EXPORT_SYMBOL_GPL(xen_pirq_from_irq);
 
+/*
+ * called by:
+ *   - drivers/scsi/xen-scsifront.c|757| <<scsifront_alloc_ring>> err = bind_evtchn_to_irq(info->evtchn);
+ *   - drivers/tty/hvc/hvc_xen.c|391| <<xencons_connect_backend>> irq = bind_evtchn_to_irq(evtchn);
+ *   - drivers/tty/hvc/hvc_xen.c|555| <<xen_hvc_init>> info->irq = bind_evtchn_to_irq(info->evtchn);
+ *   - drivers/xen/events/events_base.c|1184| <<bind_interdomain_evtchn_to_irq>> return err ? : bind_evtchn_to_irq(bind_interdomain.local_port);
+ *   - drivers/xen/events/events_base.c|1290| <<bind_evtchn_to_irqhandler>> irq = bind_evtchn_to_irq(evtchn);
+ */
 int bind_evtchn_to_irq(unsigned int evtchn)
 {
 	int irq;
@@ -845,9 +1337,16 @@ int bind_evtchn_to_irq(unsigned int evtchn)
 
 	mutex_lock(&irq_mapping_update_lock);
 
+	/* 返回evtchn_to_irq[EVTCHN_ROW(evtchn)][EVTCHN_COL(evtchn)] */
 	irq = get_evtchn_to_irq(evtchn);
 
 	if (irq == -1) {
+		/*
+		 * 分配1个irq, 也就是1个desc, 对于分配的irq
+		 * 分配一个struct irq_info *info
+		 * 把info(struct irq_info)设置为irq对应的desc->irq_common_data.handler_data
+		 * 最后把info插入xen_irq_list_head
+		 */
 		irq = xen_allocate_irq_dynamic();
 		if (irq < 0)
 			goto out;
@@ -875,6 +1374,10 @@ int bind_evtchn_to_irq(unsigned int evtchn)
 }
 EXPORT_SYMBOL_GPL(bind_evtchn_to_irq);
 
+/*
+ * called by:
+ *   - drivers/xen/events/events_base.c|1502| <<bind_ipi_to_irqhandler>> irq = bind_ipi_to_irq(ipi, cpu);
+ */
 static int bind_ipi_to_irq(unsigned int ipi, unsigned int cpu)
 {
 	struct evtchn_bind_ipi bind_ipi;
@@ -916,6 +1419,12 @@ static int bind_ipi_to_irq(unsigned int ipi, unsigned int cpu)
 	return irq;
 }
 
+/*
+ * called by:
+ *   - drivers/net/xen-netback/interface.c|585| <<xenvif_connect_ctrl>> err = bind_interdomain_evtchn_to_irq(vif->domid, evtchn);
+ *   - drivers/xen/events/events_base.c|1460| <<bind_interdomain_evtchn_to_irqhandler>> irq = bind_interdomain_evtchn_to_irq(remote_domain, remote_port);
+ *   - drivers/xen/xen-scsiback.c|833| <<scsiback_init_sring>> err = bind_interdomain_evtchn_to_irq(info->domid, evtchn);
+ */
 int bind_interdomain_evtchn_to_irq(unsigned int remote_domain,
 				   unsigned int remote_port)
 {
@@ -932,6 +1441,12 @@ int bind_interdomain_evtchn_to_irq(unsigned int remote_domain,
 }
 EXPORT_SYMBOL_GPL(bind_interdomain_evtchn_to_irq);
 
+/*
+ * called by:
+ *   - drivers/xen/events/events_base.c|1400| <<bind_virq_to_irq>> ret = find_virq(virq, cpu);
+ *
+ * 返回的是evtchn??
+ */
 static int find_virq(unsigned int virq, unsigned int cpu)
 {
 	struct evtchn_status status;
@@ -967,6 +1482,11 @@ unsigned xen_evtchn_nr_channels(void)
 }
 EXPORT_SYMBOL_GPL(xen_evtchn_nr_channels);
 
+/*
+ * called by:
+ *   - drivers/tty/hvc/hvc_xen.c|301| <<xen_initial_domain_console_init>> info->irq = bind_virq_to_irq(VIRQ_CONSOLE, 0, false);
+ *   - drivers/xen/events/events_base.c|1497| <<bind_virq_to_irqhandler>> irq = bind_virq_to_irq(virq, cpu, irqflags & IRQF_PERCPU);
+ */
 int bind_virq_to_irq(unsigned int virq, unsigned int cpu, bool percpu)
 {
 	struct evtchn_bind_virq bind_virq;
@@ -1027,6 +1547,19 @@ static void unbind_from_irq(unsigned int irq)
 	mutex_unlock(&irq_mapping_update_lock);
 }
 
+/*
+ * called by:
+ *   - drivers/block/xen-blkfront.c|1698| <<setup_blkring>> err = bind_evtchn_to_irqhandler(rinfo->evtchn, blkif_interrupt, 0,
+ *   - drivers/char/tpm/xen-tpmfront.c|216| <<setup_ring>> rv = bind_evtchn_to_irqhandler(priv->evtchn, tpmif_interrupt, 0,
+ *   - drivers/input/misc/xen-kbdfront.c|249| <<xenkbd_connect_backend>> ret = bind_evtchn_to_irqhandler(evtchn, input_handler,
+ *   - drivers/net/xen-netfront.c|1491| <<setup_netfront_single>> err = bind_evtchn_to_irqhandler(queue->tx_evtchn,
+ *   - drivers/net/xen-netfront.c|1521| <<setup_netfront_split>> err = bind_evtchn_to_irqhandler(queue->tx_evtchn,
+ *   - drivers/net/xen-netfront.c|1530| <<setup_netfront_split>> err = bind_evtchn_to_irqhandler(queue->rx_evtchn,
+ *   - drivers/pci/xen-pcifront.c|802| <<pcifront_publish_info>> err = bind_evtchn_to_irqhandler(pdev->evtchn, pcifront_handler_aer,
+ *   - drivers/video/fbdev/xen-fbfront.c|575| <<xenfb_connect_backend>> irq = bind_evtchn_to_irqhandler(evtchn, xenfb_event_handler,
+ *   - drivers/xen/evtchn.c|407| <<evtchn_bind_to_user>> rc = bind_evtchn_to_irqhandler(port, evtchn_interrupt, 0,
+ *   - drivers/xen/xenbus/xenbus_comms.c|226| <<xb_init_comms>> err = bind_evtchn_to_irqhandler(xen_store_evtchn, wake_waiting,
+ */
 int bind_evtchn_to_irqhandler(unsigned int evtchn,
 			      irq_handler_t handler,
 			      unsigned long irqflags,
@@ -1161,6 +1694,11 @@ int evtchn_make_refcounted(unsigned int evtchn)
 }
 EXPORT_SYMBOL_GPL(evtchn_make_refcounted);
 
+/*
+ * called by:
+ *   - drivers/xen/gntalloc.c|418| <<gntalloc_ioctl_unmap_notify>> if (evtchn_get(op.event_channel_port)) {
+ *   - drivers/xen/gntdev.c|705| <<gntdev_ioctl_notify>> if (evtchn_get(op.event_channel_port))
+ */
 int evtchn_get(unsigned int evtchn)
 {
 	int irq;
@@ -1194,6 +1732,13 @@ int evtchn_get(unsigned int evtchn)
 }
 EXPORT_SYMBOL_GPL(evtchn_get);
 
+/*
+ * called by:
+ *   - drivers/xen/gntalloc.c|190| <<__del_gref>> evtchn_put(gref->notify.event);
+ *   - drivers/xen/gntalloc.c|425| <<gntalloc_ioctl_unmap_notify>> evtchn_put(gref->notify.event);
+ *   - drivers/xen/gntdev.c|221| <<gntdev_put_map>> evtchn_put(map->notify.event);
+ *   - drivers/xen/gntdev.c|744| <<gntdev_ioctl_notify>> evtchn_put(out_event);
+ */
 void evtchn_put(unsigned int evtchn)
 {
 	int irq = get_evtchn_to_irq(evtchn);
@@ -1221,8 +1766,19 @@ void xen_send_IPI_one(unsigned int cpu, enum ipi_vector vector)
 	notify_remote_via_irq(irq);
 }
 
+/*
+ * used by:
+ *   - drivers/xen/events/events_base.c|1539| <<__xen_evtchn_do_upcall>> if (__this_cpu_inc_return(xed_nesting_count) - 1)
+ *   - drivers/xen/events/events_base.c|1546| <<__xen_evtchn_do_upcall>> count = __this_cpu_read(xed_nesting_count);
+ *   - drivers/xen/events/events_base.c|1547| <<__xen_evtchn_do_upcall>> __this_cpu_write(xed_nesting_count, 0);
+ */
 static DEFINE_PER_CPU(unsigned, xed_nesting_count);
 
+/*
+ * called by:
+ *   - drivers/xen/events/events_base.c|1548| <<xen_evtchn_do_upcall>> __xen_evtchn_do_upcall();
+ *   - drivers/xen/events/events_base.c|1556| <<xen_hvm_evtchn_do_upcall>> __xen_evtchn_do_upcall();
+ */
 static void __xen_evtchn_do_upcall(void)
 {
 	struct vcpu_info *vcpu_info = __this_cpu_read(xen_vcpu);
@@ -1248,6 +1804,9 @@ static void __xen_evtchn_do_upcall(void)
 	put_cpu();
 }
 
+/*
+ * 从arch/x86/entry/entry_64.S调用过来
+ */
 void xen_evtchn_do_upcall(struct pt_regs *regs)
 {
 	struct pt_regs *old_regs = set_irq_regs(regs);
@@ -1264,6 +1823,11 @@ void xen_evtchn_do_upcall(struct pt_regs *regs)
 	set_irq_regs(old_regs);
 }
 
+/*
+ * called by:
+ *   - arch/arm/xen/enlighten.c|212| <<xen_arm_callback>> xen_hvm_evtchn_do_upcall();
+ *   - drivers/xen/platform-pci.c|79| <<do_hvm_evtchn_intr>> xen_hvm_evtchn_do_upcall();
+ */
 void xen_hvm_evtchn_do_upcall(void)
 {
 	__xen_evtchn_do_upcall();
@@ -1271,6 +1835,11 @@ void xen_hvm_evtchn_do_upcall(void)
 EXPORT_SYMBOL_GPL(xen_hvm_evtchn_do_upcall);
 
 /* Rebind a new event channel to an existing irq. */
+/*
+ * called by:
+ *   - drivers/tty/hvc/hvc_xen.c|330| <<xen_console_resume>> rebind_evtchn_irq(info->evtchn, info->irq);
+ *   - drivers/xen/xenbus/xenbus_comms.c|223| <<xb_init_comms>> rebind_evtchn_irq(xen_store_evtchn, xenbus_irq);
+ */
 void rebind_evtchn_irq(int evtchn, int irq)
 {
 	struct irq_info *info = info_for_irq(irq);
@@ -1303,6 +1872,10 @@ void rebind_evtchn_irq(int evtchn, int irq)
 }
 
 /* Rebind an evtchn so that it gets delivered to a specific cpu */
+/*
+ * called by:
+ *   - drivers/xen/events/events_base.c|1651| <<set_affinity_irq>> return rebind_irq_to_cpu(data->irq, tcpu);
+ */
 static int rebind_irq_to_cpu(unsigned irq, unsigned tcpu)
 {
 	struct evtchn_bind_vcpu bind_vcpu;
@@ -1339,6 +1912,10 @@ static int rebind_irq_to_cpu(unsigned irq, unsigned tcpu)
 	return 0;
 }
 
+/*
+ * struct irq_chip xen_pirq_chip.irq_set_affinity = set_affinity_irq()
+ * struct irq_chip xen_dynamic_chip.irq_set_affinity = set_affinity_irq()
+ */
 static int set_affinity_irq(struct irq_data *data, const struct cpumask *dest,
 			    bool force)
 {
@@ -1347,6 +1924,11 @@ static int set_affinity_irq(struct irq_data *data, const struct cpumask *dest,
 	return rebind_irq_to_cpu(data->irq, tcpu);
 }
 
+/*
+ * struct irq_chip xen_percpu_chip.irq_unmask = enable_dynirq()
+ * struct irq_chip xen_pirq_chip.irq_unmask = enable_dynirq()
+ * struct irq_chip xen_dynamic_chip.irq_unmask = enable_dynirq()
+ */
 static void enable_dynirq(struct irq_data *data)
 {
 	int evtchn = evtchn_from_irq(data->irq);
@@ -1355,6 +1937,13 @@ static void enable_dynirq(struct irq_data *data)
 		unmask_evtchn(evtchn);
 }
 
+/*
+ * struct irq_chip xen_percpu_chip.irq_disable = disable_dynirq()
+ * struct irq_chip xen_percpu_chip.irq_mask = disable_dynirq()
+ * struct irq_chip xen_pirq_chip.irq_mask = disable_dynirq()
+ * struct irq_chip xen_dynamic_chip.irq_disable = disable_dynirq()
+ * struct irq_chip xen_dynamic_chip.irq_mask = disable_dynirq()
+ */
 static void disable_dynirq(struct irq_data *data)
 {
 	int evtchn = evtchn_from_irq(data->irq);
@@ -1363,6 +1952,10 @@ static void disable_dynirq(struct irq_data *data)
 		mask_evtchn(evtchn);
 }
 
+/*
+ * struct irq_chip xen_percpu_chip.irq_ack = ack_dynirq()
+ * struct irq_chip xen_dynamic_chip.irq_ack = ack_dynirq()
+ */
 static void ack_dynirq(struct irq_data *data)
 {
 	int evtchn = evtchn_from_irq(data->irq);
@@ -1384,12 +1977,19 @@ static void ack_dynirq(struct irq_data *data)
 		clear_evtchn(evtchn);
 }
 
+/*
+ * struct irq_chip xen_dynamic_chip.irq_mask_ack = mask_ack_dynirq()
+ */
 static void mask_ack_dynirq(struct irq_data *data)
 {
 	disable_dynirq(data);
 	ack_dynirq(data);
 }
 
+/*
+ * struct irq_chip xen_pirq_chip.irq_retrigger = retrigger_dynirq()
+ * struct irq_chip xen_dynamic_chip.irq_retrigger = retrigger_dynirq()
+ */
 static int retrigger_dynirq(struct irq_data *data)
 {
 	unsigned int evtchn = evtchn_from_irq(data->irq);
@@ -1406,6 +2006,10 @@ static int retrigger_dynirq(struct irq_data *data)
 	return 1;
 }
 
+/*
+ * called by only:
+ *   - drivers/xen/events/events_base.c|2122| <<xen_irq_resume>> restore_pirqs();
+ */
 static void restore_pirqs(void)
 {
 	int pirq, rc, irq, gsi;
@@ -1523,6 +2127,11 @@ bool xen_test_irq_pending(int irq)
 
 /* Poll waiting for an irq to become pending with timeout.  In the usual case,
  * the irq will be disabled so it won't deliver an interrupt. */
+/*
+ * called by:
+ *   - drivers/pci/xen-pcifront.c|143| <<do_pci_op>> xen_poll_irq_timeout(irq, jiffies + 3*HZ);
+ *   - drivers/xen/events/events_base.c|1850| <<xen_poll_irq>> xen_poll_irq_timeout(irq, 0 );
+ */
 void xen_poll_irq_timeout(int irq, u64 timeout)
 {
 	evtchn_port_t evtchn = evtchn_from_irq(irq);
@@ -1541,6 +2150,10 @@ void xen_poll_irq_timeout(int irq, u64 timeout)
 EXPORT_SYMBOL(xen_poll_irq_timeout);
 /* Poll waiting for an irq to become pending.  In the usual case, the
  * irq will be disabled so it won't deliver an interrupt. */
+/*
+ * called only by:
+ *   - arch/x86/xen/spinlock.c|59| <<xen_qlock_wait>> xen_poll_irq(irq);
+ */
 void xen_poll_irq(int irq)
 {
 	xen_poll_irq_timeout(irq, 0 /* no timeout */);
@@ -1563,6 +2176,10 @@ int xen_test_irq_shared(int irq)
 }
 EXPORT_SYMBOL_GPL(xen_test_irq_shared);
 
+/*
+ * called by:
+ *   - drivers/xen/manage.c|90| <<xen_suspend>> xen_irq_resume();
+ */
 void xen_irq_resume(void)
 {
 	unsigned int cpu;
@@ -1586,6 +2203,12 @@ void xen_irq_resume(void)
 	restore_pirqs();
 }
 
+/*
+ * used by:
+ *   - drivers/xen/events/events_base.c|146| <<bool>> static struct irq_chip xen_dynamic_chip;
+ *   - drivers/xen/events/events_base.c|1142| <<bind_evtchn_to_irq>> irq_set_chip_and_handler_name(irq, &xen_dynamic_chip,
+ *   - drivers/xen/events/events_base.c|1275| <<bind_virq_to_irq>> irq_set_chip_and_handler_name(irq, &xen_dynamic_chip,
+ */
 static struct irq_chip xen_dynamic_chip __read_mostly = {
 	.name			= "xen-dyn",
 
@@ -1600,6 +2223,12 @@ static struct irq_chip xen_dynamic_chip __read_mostly = {
 	.irq_retrigger		= retrigger_dynirq,
 };
 
+/*
+ * used by:
+ *   - drivers/xen/events/events_base.c|956| <<xen_bind_pirq_gsi_to_irq>> irq_set_chip_and_handler_name(irq, &xen_pirq_chip,
+ *   - drivers/xen/events/events_base.c|959| <<xen_bind_pirq_gsi_to_irq>> irq_set_chip_and_handler_name(irq, &xen_pirq_chip,
+ *   - drivers/xen/events/events_base.c|1010| <<xen_bind_pirq_msi_to_irq>> irq_set_chip_and_handler_name(irq + i, &xen_pirq_chip, handle_edge_irq, name);
+ */
 static struct irq_chip xen_pirq_chip __read_mostly = {
 	.name			= "xen-pirq",
 
@@ -1620,6 +2249,11 @@ static struct irq_chip xen_pirq_chip __read_mostly = {
 	.irq_retrigger		= retrigger_dynirq,
 };
 
+/*
+ * used by:
+ *   - drivers/xen/events/events_base.c|1180| <<bind_ipi_to_irq>> irq_set_chip_and_handler_name(irq, &xen_percpu_chip,
+ *   - drivers/xen/events/events_base.c|1272| <<bind_virq_to_irq>> irq_set_chip_and_handler_name(irq, &xen_percpu_chip,
+ */
 static struct irq_chip xen_percpu_chip __read_mostly = {
 	.name			= "xen-percpu",
 
@@ -1630,6 +2264,12 @@ static struct irq_chip xen_percpu_chip __read_mostly = {
 	.irq_ack		= ack_dynirq,
 };
 
+/*
+ * called by:
+ *   - drivers/xen/events/events_base.c|1981| <<xen_callback_vector>> rc = xen_set_callback_via(callback_via);
+ *   - drivers/xen/platform-pci.c|95| <<platform_pci_resume>> err = xen_set_callback_via(callback_via);
+ *   - drivers/xen/platform-pci.c|148| <<platform_pci_probe>> ret = xen_set_callback_via(callback_via);
+ */
 int xen_set_callback_via(uint64_t via)
 {
 	struct xen_hvm_param a;
@@ -1644,6 +2284,11 @@ EXPORT_SYMBOL_GPL(xen_set_callback_via);
 /* Vector callbacks are better than PCI interrupts to receive event
  * channel notifications because we can receive vector callbacks on any
  * vcpu and we don't need PCI support or APIC interactions. */
+/*
+ * called by:
+ *   - arch/x86/xen/suspend.c|42| <<xen_hvm_post_suspend>> xen_callback_vector();
+ *   - drivers/xen/events/events_base.c|2043| <<xen_init_IRQ>> xen_callback_vector();
+ */
 void xen_callback_vector(void)
 {
 	int rc;
@@ -1673,6 +2318,21 @@ void xen_callback_vector(void) {}
 static bool fifo_events = true;
 module_param(fifo_events, bool, 0);
 
+/*
+ * [0] pci_xen_initial_domain
+ * [0] xen_init_IRQ
+ * [0] init_IRQ
+ * [0] start_kernel
+ * [0] x86_64_start_reservations
+ * [0] xen_start_kernel
+ *
+ * used by:
+ *   - arch/x86/xen/enlighten.c|1949| <<xen_hvm_guest_init>> x86_init.irqs.intr_init = xen_init_IRQ;
+ *   - arch/x86/xen/irq.c|189| <<xen_init_irq_ops>> x86_init.irqs.intr_init = xen_init_IRQ;
+ *
+ * called by:
+ *   - arch/x86/kernel/irqinit.c|100| <<init_IRQ>> x86_init.irqs.intr_init();
+ */
 void __init xen_init_IRQ(void)
 {
 	int ret = -EINVAL;
@@ -1689,11 +2349,24 @@ void __init xen_init_IRQ(void)
 	/* No event channels are 'live' right now. */
 	xen_evtchn_mask_all();
 
+	/*
+	 * called by:
+	 *   - drivers/xen/events/events_base.c|686| <<eoi_pirq>> if (pirq_needs_eoi(data->irq)) {
+	 *
+	 * used by:     
+	 *   - drivers/xen/events/events_base.c|608| <<eoi_pirq>> if (pirq_needs_eoi(data->irq)) {
+	 *   - drivers/xen/events/events_base.c|1838| <<xen_init_IRQ>> pirq_needs_eoi = pirq_needs_eoi_flag;
+	 *   - drivers/xen/events/events_base.c|1866| <<xen_init_IRQ>> pirq_needs_eoi = pirq_check_eoi_map;
+	 */
 	pirq_needs_eoi = pirq_needs_eoi_flag;
 
 #ifdef CONFIG_X86
 	if (xen_pv_domain()) {
+		/* 64-bit下好像什么也不做 */
 		irq_ctx_init(smp_processor_id());
+		/*
+		 * pci_xen_initial_domain()只在这里针对dom0被调用
+		 */
 		if (xen_initial_domain())
 			pci_xen_initial_domain();
 	}
@@ -1711,8 +2384,19 @@ void __init xen_init_IRQ(void)
 
 		pirq_eoi_map = (void *)__get_free_page(GFP_KERNEL|__GFP_ZERO);
 		eoi_gmfn.gmfn = virt_to_gfn(pirq_eoi_map);
+		/*
+		 * Register a shared page for the hypervisor to indicate whether the
+		 * guest must issue PHYSDEVOP_eoi. This hypercall is very similar to
+		 * PHYSDEVOP_pirq_eoi_gmfn_v1 but it doesn't change the semantics of
+		 * PHYSDEVOP_eoi. The page registered is used as a bit array indexed by
+		 * Xen's PIRQ value
+		 */
 		rc = HYPERVISOR_physdev_op(PHYSDEVOP_pirq_eoi_gmfn_v2, &eoi_gmfn);
 		/* TODO: No PVH support for PIRQ EOI */
+		/*
+		 * pirq_needs_eoi = pirq_check_eoi_map在以下被调用:
+		 *   - drivers/xen/events/events_base.c|660| <<eoi_pirq>> if (pirq_needs_eoi(data->irq)) {
+		 */
 		if (rc != 0) {
 			free_page((unsigned long) pirq_eoi_map);
 			pirq_eoi_map = NULL;
diff --git a/drivers/xen/events/events_internal.h b/drivers/xen/events/events_internal.h
index 50c2050..915aed5 100644
--- a/drivers/xen/events/events_internal.h
+++ b/drivers/xen/events/events_internal.h
@@ -91,6 +91,9 @@ static inline unsigned xen_evtchn_max_channels(void)
  * Do any ABI specific setup for a bound event channel before it can
  * be unmasked and used.
  */
+/*
+ * 调用evtchn_ops->setup(info), 只有fifo支持
+ */
 static inline int xen_evtchn_port_setup(struct irq_info *info)
 {
 	if (evtchn_ops->setup)
@@ -98,6 +101,9 @@ static inline int xen_evtchn_port_setup(struct irq_info *info)
 	return 0;
 }
 
+/*
+ * 调用evtchn_ops->bind_to_cpu(info, cpu)
+ */
 static inline void xen_evtchn_port_bind_to_cpu(struct irq_info *info,
 					       unsigned cpu)
 {
@@ -124,6 +130,9 @@ static inline bool test_and_set_mask(unsigned port)
 	return evtchn_ops->test_and_set_mask(port);
 }
 
+/*
+ * 调用evtchn_ops->mask(port)
+ */
 static inline void mask_evtchn(unsigned port)
 {
 	return evtchn_ops->mask(port);
@@ -136,6 +145,10 @@ static inline void unmask_evtchn(unsigned port)
 
 static inline void xen_evtchn_handle_events(unsigned cpu)
 {
+	/*
+	 * evtchn_2l_handle_events()
+	 * evtchn_fifo_handle_events()
+	 */
 	return evtchn_ops->handle_events(cpu);
 }
 
diff --git a/drivers/xen/pci.c b/drivers/xen/pci.c
index 7494dbe..d6f2b11 100644
--- a/drivers/xen/pci.c
+++ b/drivers/xen/pci.c
@@ -31,8 +31,16 @@
 #include <asm/pci_x86.h>
 #endif
 
+/*
+ * 只在以下修改:
+ *   - drivers/xen/pci.c|112| <<xen_add_device>> pci_seg_supported = false;
+ */
 static bool __read_mostly pci_seg_supported = true;
 
+/*
+ * called by (处理BUS_NOTIFY_ADD_DEVICE):
+ *   - drivers/xen/pci.c|186| <<xen_pci_notifier>> r = xen_add_device(dev);
+ */
 static int xen_add_device(struct device *dev)
 {
 	int r;
@@ -146,6 +154,10 @@ static int xen_add_device(struct device *dev)
 	return r;
 }
 
+/*
+ * calle by only (处理BUS_NOTIFY_DEL_DEVICE):
+ *   - drivers/xen/pci.c|200| <<xen_pci_notifier>> r = xen_remove_device(dev);
+ */
 static int xen_remove_device(struct device *dev)
 {
 	int r;
@@ -175,6 +187,9 @@ static int xen_remove_device(struct device *dev)
 	return r;
 }
 
+/*
+ * struct notifier_block device_nb.notifier_call = xen_pci_notifier()
+ */
 static int xen_pci_notifier(struct notifier_block *nb,
 			    unsigned long action, void *data)
 {
@@ -202,8 +217,12 @@ static struct notifier_block device_nb = {
 	.notifier_call = xen_pci_notifier,
 };
 
+/*
+ * 必须是dom0才能进行下去
+ */
 static int __init register_xen_pci_notifier(void)
 {
+	/* 必须是dom0才能进行下去 */
 	if (!xen_initial_domain())
 		return 0;
 
@@ -213,11 +232,17 @@ static int __init register_xen_pci_notifier(void)
 arch_initcall(register_xen_pci_notifier);
 
 #ifdef CONFIG_PCI_MMCONFIG
+/*
+ * 必须是dom0才能进行下去
+ */
 static int __init xen_mcfg_late(void)
 {
 	struct pci_mmcfg_region *cfg;
 	int rc;
 
+	/*
+	 * 必须是dom0才能进行下去
+	 */
 	if (!xen_initial_domain())
 		return 0;
 
@@ -228,6 +253,10 @@ static int __init xen_mcfg_late(void)
 		return 0;
 
 	/* Check whether they are in the right area. */
+	/*
+	 * 只在以下添加新元素到pci_mmcfg_list:
+	 *   - arch/x86/pci/mmconfig-shared.c|64| <<list_add_sorted>> list_add_tail_rcu(&new->list, &pci_mmcfg_list);
+	 */
 	list_for_each_entry(cfg, &pci_mmcfg_list, list) {
 		struct physdev_pci_mmcfg_reserved r;
 
diff --git a/drivers/xen/swiotlb-xen.c b/drivers/xen/swiotlb-xen.c
index 5d04b36..5610617 100644
--- a/drivers/xen/swiotlb-xen.c
+++ b/drivers/xen/swiotlb-xen.c
@@ -33,6 +33,14 @@
  *
  */
 
+/*
+ * iommu (iommu_setup) is configured at arch/x86/kernel/pci-dma.c
+ *
+ * iommu=soft 似乎在所有操作系统上是default (swiotlb = 1)
+ *
+ * 在xen上swiotlb = 0
+ */
+
 #define pr_fmt(fmt) "xen:" KBUILD_MODNAME ": " fmt
 
 #include <linux/bootmem.h>
@@ -53,6 +61,12 @@
  * API.
  */
 
+/*
+ * 忽略吧 和x86无关
+ *
+ * 对于x86 如果dev->coherent_dma_mask已经有了就返回dev->coherent_dma_mask
+ * 否则根据gfp决定是DMA_BIT_MASK(24)还是DMA_BIT_MASK(32)
+ */
 #ifndef CONFIG_X86
 static unsigned long dma_alloc_coherent_mask(struct device *dev,
 					    gfp_t gfp)
@@ -67,12 +81,26 @@ static unsigned long dma_alloc_coherent_mask(struct device *dev,
 }
 #endif
 
+/*
+ * xen_io_tlb_start: swiotlb预留map用的起始虚拟地址
+ * xen_io_tlb_end: swiotlb预留map用的终止虚拟地址
+ *
+ * 在测试机器上 (start和end之间是64MB):
+ * xen_io_tlb_start  = 0xffff8804a2a00000
+ * xen_io_tlb_end    = 0xffff8804a6a00000
+ * xen_io_tlb_nslabs = 32768
+ */
 static char *xen_io_tlb_start, *xen_io_tlb_end;
 static unsigned long xen_io_tlb_nslabs;
 /*
  * Quick lookup value of the bus address of the IOTLB.
  */
 
+/*
+ * 在测试机上是0x1c0000
+ *
+ * 在xen_swiotlb_init()被配置成xen_virt_to_bus(xen_io_tlb_start)
+ */
 static u64 start_dma_addr;
 
 /*
@@ -106,6 +134,11 @@ static inline dma_addr_t xen_virt_to_bus(void *address)
 	return xen_phys_to_bus(virt_to_phys(address));
 }
 
+/*
+ * 检查xen_pfn们对应的mfn是否机器连续
+ *
+ * 返回 1 说明连续
+ */
 static int check_pages_physically_contiguous(unsigned long xen_pfn,
 					     unsigned int offset,
 					     size_t length)
@@ -124,6 +157,9 @@ static int check_pages_physically_contiguous(unsigned long xen_pfn,
 	return 1;
 }
 
+/*
+ * 返回 0 说明连续
+ */
 static inline int range_straddles_page_boundary(phys_addr_t p, size_t size)
 {
 	unsigned long xen_pfn = XEN_PFN_DOWN(p);
@@ -131,11 +167,16 @@ static inline int range_straddles_page_boundary(phys_addr_t p, size_t size)
 
 	if (offset + size <= XEN_PAGE_SIZE)
 		return 0;
+	/*
+	 * 检查xen_pfn们对应的mfn是否机器连续
+	 * 返回1说明连续
+	 */
 	if (check_pages_physically_contiguous(xen_pfn, offset, size))
 		return 0;
 	return 1;
 }
 
+/* 判断地址是否在swiotlb预留范围内 */
 static int is_xen_swiotlb_buffer(dma_addr_t dma_addr)
 {
 	unsigned long bfn = XEN_PFN_DOWN(dma_addr);
@@ -153,23 +194,76 @@ static int is_xen_swiotlb_buffer(dma_addr_t dma_addr)
 	return 0;
 }
 
+/*
+ * 只在以下使用:
+ *   - drivers/xen/swiotlb-xen.c|241| <<xen_swiotlb_fixup>> } while (rc && dma_bits++ < max_dma_bits);
+ */
 static int max_dma_bits = 32;
 
+/*
+ * called only by:
+ *   - drivers/xen/swiotlb-xen.c|285| <<xen_swiotlb_init>> rc = xen_swiotlb_fixup(xen_io_tlb_start,
+ *
+ * 把预分配的页面换成连续的
+ *
+ * 在测试机上,
+ *
+ * buf    = 0xffff8804a2a00000 
+ * size   = 64MB
+ * nslabs = 32768
+ */
 static int
 xen_swiotlb_fixup(void *buf, size_t size, unsigned long nslabs)
 {
 	int i, rc;
 	int dma_bits;
 	dma_addr_t dma_handle;
+	/* 物理地址应该是0x4a2a00000 */
 	phys_addr_t p = virt_to_phys(buf);
 
+	/*
+	 * IO_TLB_SEGSIZE: Maximum allowable number of contiguous slabs to map
+	 * IO_TLB_SHIFT: log of the size of each IO TLB slab
+	 *
+	 * IO_TLB_SEGSIZE = 128, 左移11位是262144=0x40000 (256KB) ---> 1000000000000000000
+	 * order是6, 加上PAGE_SHIFT后, dma_bits = 18
+	 */
 	dma_bits = get_order(IO_TLB_SEGSIZE << IO_TLB_SHIFT) + PAGE_SHIFT;
 
+	/*
+	 * 下面是2个循环
+	 *
+	 * 第一个循环是分配每一个连续的128 slot
+	 *
+	 * 假设默认是64MB = 65536KB, 每个slot是 2K, 一共65536 / 2 = 32768 slot
+	 * 每次分配连续的128 slot, 所以一共分配 32768 / 128 = 256次
+	 * 也就是说, 默认第一个循环跑256次
+	 *
+	 * 第二个循环的原因是每次分配可能会失败, 比如第一次在测试机器上分配128个slot的时候第四次才成功:
+	 *
+	 * [    0.000000] xen:swiotlb_xen: orabug: xen_swiotlb_fixup() 2c400000, 6, 12
+	 * [    0.000000] xen:swiotlb_xen: orabug: xen_swiotlb_fixup() 2c400000, 6, 13
+	 * [    0.000000] xen:swiotlb_xen: orabug: xen_swiotlb_fixup() 2c400000, 6, 14
+	 * [    0.000000] xen:swiotlb_xen: orabug: xen_swiotlb_fixup() 2c400000, 6, 15
+	 *
+	 * 2c400000 : p + (i << IO_TLB_SHIFT)
+	 * 6        : get_order(slabs << IO_TLB_SHIFT),  --> 2^6 = 64 page = 128 slots
+	 * 12       : dma_bits
+	 *
+	 * 一开始12个bit的mask分不到, 要0x15个才行
+	 *
+	 * 最后一次分配到了0x1b个bit的mask
+	 * [    0.000000] xen:swiotlb_xen: orabug: xen_swiotlb_fixup() 303c0000, 6, 1b
+	 */
+
 	i = 0;
 	do {
 		int slabs = min(nslabs - i, (unsigned long)IO_TLB_SEGSIZE);
 
 		do {
+			/*
+			 * 我们期待rc返回0
+			 */
 			rc = xen_create_contiguous_region(
 				p + (i << IO_TLB_SHIFT),
 				get_order(slabs << IO_TLB_SHIFT),
@@ -182,6 +276,12 @@ xen_swiotlb_fixup(void *buf, size_t size, unsigned long nslabs)
 	} while (i < nslabs);
 	return 0;
 }
+/*
+ * called by only:
+ *   - drivers/xen/swiotlb-xen.c|290| <<xen_swiotlb_init>> bytes = xen_set_nslabs(xen_io_tlb_nslabs);
+ *
+ * nr_tlb在测试机是32768不为空, 左移11位返回67108864=0x4000000 (64MB)
+ */
 static unsigned long xen_set_nslabs(unsigned long nr_tbl)
 {
 	if (!nr_tbl) {
@@ -190,6 +290,7 @@ static unsigned long xen_set_nslabs(unsigned long nr_tbl)
 	} else
 		xen_io_tlb_nslabs = nr_tbl;
 
+	/* xen_io_tlb_nslabs在测试机是32768, 左移11位是67108864=0x4000000 (64MB) */
 	return xen_io_tlb_nslabs << IO_TLB_SHIFT;
 }
 
@@ -199,6 +300,11 @@ enum xen_swiotlb_err {
 	XEN_SWIOTLB_EFIXUP
 };
 
+/*
+ * called by:
+ *   - drivers/xen/swiotlb-xen.c|351| <<xen_swiotlb_init>> pr_err("%s (rc:%d)\n", xen_swiotlb_error(m_ret), rc);
+ *   - drivers/xen/swiotlb-xen.c|353| <<xen_swiotlb_init>> panic("%s (rc:%d)", xen_swiotlb_error(m_ret), rc);
+ */
 static const char *xen_swiotlb_error(enum xen_swiotlb_err err)
 {
 	switch (err) {
@@ -214,6 +320,20 @@ static const char *xen_swiotlb_error(enum xen_swiotlb_err err)
 	}
 	return "";
 }
+/*
+ * called by:
+ *   - arch/x86/xen/pci-swiotlb-xen.c|96| <<pci_xen_swiotlb_init>> xen_swiotlb_init(1, true );
+ *   - arch/x86/xen/pci-swiotlb-xen.c|119| <<pci_xen_swiotlb_init_late>> rc = xen_swiotlb_init(1, false ); --> xen-pcifront.c使用
+ *
+ * 在virtualbox上测试upstream linux, xen_swiotlb_init()只调用一次, early=true!
+ *
+ * [    0.275532]  xen_swiotlb_init+0x47/0x4e0
+ * [    0.275538]  pci_xen_swiotlb_init+0x18/0x29
+ * [    0.275541]  pci_iommu_alloc+0x5f/0x67
+ * [    0.275543]  mem_init+0xb/0x98
+ * [    0.275546]  start_kernel+0x23b/0x4da
+ * [    0.275548]  xen_start_kernel+0x561/0x56b
+ */
 int __ref xen_swiotlb_init(int verbose, bool early)
 {
 	unsigned long bytes, order;
@@ -221,13 +341,35 @@ int __ref xen_swiotlb_init(int verbose, bool early)
 	enum xen_swiotlb_err m_ret = XEN_SWIOTLB_UNKNOWN;
 	unsigned int repeat = 3;
 
+	/*
+	 * 返回io_tlb_nslabs, 在测试机是32768
+	 *
+	 * xen_io_tlb_nslabs最终在测试机也是32768 (不知道后面逻辑有没有影响)
+	 *
+	 * 另外 在测试机上 (start和end之间是64MB):
+	 *   io_tlb_start: 0x4a2a00000
+	 *   io_tlb_end  : 0x4a6a00000
+	 */
 	xen_io_tlb_nslabs = swiotlb_nr_tbl();
 retry:
+	/*
+	 * nr_tlb在测试机是32768不为空, 左移11位返回67108864=0x4000000 (64MB)
+	 *
+	 * 因此bytes=64MB
+	 */
 	bytes = xen_set_nslabs(xen_io_tlb_nslabs);
+	/*
+	 * xen_io_tlb_nslabs左移11位是67108864=0x4000000 (64MB)
+	 *
+	 * order是14, 2^14是16384个4k的page, 总数是67108864
+	 */
 	order = get_order(xen_io_tlb_nslabs << IO_TLB_SHIFT);
 	/*
 	 * Get IO TLB memory from any location.
 	 */
+	/*
+	 * 因为在upstream linux上early=true, 在bootmem分配64MB内存
+	 */
 	if (early)
 		xen_io_tlb_start = alloc_bootmem_pages(PAGE_ALIGN(bytes));
 	else {
@@ -250,14 +392,24 @@ int __ref xen_swiotlb_init(int verbose, bool early)
 		m_ret = XEN_SWIOTLB_ENOMEM;
 		goto error;
 	}
+	/*
+	 * 在测试机 上面bytes在xen_set_nslabs()推算的是64MB
+	 *
+	 * 于是, 我们在测试机得到如下结果 (start和end之间是64MB):
+	 *   xen_io_tlb_start  = 0xffff8804a2a00000
+	 *   xen_io_tlb_end    = 0xffff8804a6a00000
+	 *   xen_io_tlb_nslabs = 32768
+	 */
 	xen_io_tlb_end = xen_io_tlb_start + bytes;
 	/*
 	 * And replace that memory with pages under 4GB.
 	 */
+	/* 把预分配的页面换成连续的 */
 	rc = xen_swiotlb_fixup(xen_io_tlb_start,
 			       bytes,
 			       xen_io_tlb_nslabs);
 	if (rc) {
+		/* 下面是错误的时候 */
 		if (early)
 			free_bootmem(__pa(xen_io_tlb_start), PAGE_ALIGN(bytes));
 		else {
@@ -267,6 +419,7 @@ int __ref xen_swiotlb_init(int verbose, bool early)
 		m_ret = XEN_SWIOTLB_EFIXUP;
 		goto error;
 	}
+	 /* start_dma_addr在测试机是0x1c0000 */
 	start_dma_addr = xen_virt_to_bus(xen_io_tlb_start);
 	if (early) {
 		if (swiotlb_init_with_tbl(xen_io_tlb_start, xen_io_tlb_nslabs,
@@ -275,6 +428,12 @@ int __ref xen_swiotlb_init(int verbose, bool early)
 		rc = 0;
 	} else
 		rc = swiotlb_late_init_with_tbl(xen_io_tlb_start, xen_io_tlb_nslabs);
+	/*
+	 * 在测试机器上 (start和end之间是64MB):
+	 *    xen_io_tlb_start  = 0xffff8804a2a00000
+	 *    xen_io_tlb_end    = 0xffff8804a6a00000
+	 *    xen_io_tlb_nslabs = 32768
+	 */
 	return rc;
 error:
 	if (repeat--) {
@@ -291,6 +450,12 @@ int __ref xen_swiotlb_init(int verbose, bool early)
 		free_pages((unsigned long)xen_io_tlb_start, order);
 	return rc;
 }
+/*
+ * called by:
+ *   - include/linux/dma-mapping.h|467| <<dma_alloc_attrs>> cpu_addr = ops->alloc(dev, size, dma_handle, flag, attrs);
+ *  
+ * struct dma_map_ops xen_swiotlb_dma_ops.alloc = xen_swiotlb_alloc_coherent()
+ */
 void *
 xen_swiotlb_alloc_coherent(struct device *hwdev, size_t size,
 			   dma_addr_t *dma_handle, gfp_t flags,
@@ -318,11 +483,24 @@ xen_swiotlb_alloc_coherent(struct device *hwdev, size_t size,
 	 * address. In fact on ARM virt_to_phys only works for kernel direct
 	 * mapped RAM memory. Also see comment below.
 	 */
+	/* 就是调用__get_free_pages(), 然后转成物理地址存在dma_handle, 返回虚拟地址 */
 	ret = xen_alloc_coherent_pages(hwdev, size, dma_handle, flags, attrs);
 
+	/*
+	 * 到了这里:
+	 *   ret 是虚拟地址
+	 *   dma_handle是物理地址
+	 */
 	if (!ret)
 		return ret;
 
+	/*
+	 * 如果dev->coherent_dma_mask已经有了就返回dev->coherent_dma_mask
+	 * 否则根据gfp决定是DMA_BIT_MASK(24)还是DMA_BIT_MASK(32)
+	 *
+	 * 在这里, 如果dev->coherent_dma_mask已经有了就返回dev->coherent_dma_mask
+	 * 否则用开始的32位
+	 */
 	if (hwdev && hwdev->coherent_dma_mask)
 		dma_mask = dma_alloc_coherent_mask(hwdev, flags);
 
@@ -332,6 +510,10 @@ xen_swiotlb_alloc_coherent(struct device *hwdev, size_t size,
 	 * to *dma_handle. */
 	phys = *dma_handle;
 	dev_addr = xen_phys_to_bus(phys);
+	/*
+	 * 如果地址在dma_mask范围内而且机器连续就直接使用
+	 * 否则exchange成机器连续的
+	 */
 	if (((dev_addr + size - 1 <= dma_mask)) &&
 	    !range_straddles_page_boundary(phys, size))
 		*dma_handle = dev_addr;
@@ -347,6 +529,12 @@ xen_swiotlb_alloc_coherent(struct device *hwdev, size_t size,
 }
 EXPORT_SYMBOL_GPL(xen_swiotlb_alloc_coherent);
 
+/*
+ * called by:
+ *   - include/linux/dma-mapping.h|507| <<dma_free_attrs>> ops->free(dev, size, cpu_addr, dma_handle, attrs);
+ *
+ * struct dma_map_ops xen_swiotlb_dma_ops.free = xen_swiotlb_free_coherent()
+ */
 void
 xen_swiotlb_free_coherent(struct device *hwdev, size_t size, void *vaddr,
 			  dma_addr_t dev_addr, unsigned long attrs)
@@ -369,6 +557,7 @@ xen_swiotlb_free_coherent(struct device *hwdev, size_t size, void *vaddr,
 	    range_straddles_page_boundary(phys, size))
 		xen_destroy_contiguous_region(phys, order);
 
+	/* 就是用free_pages()释放pages */
 	xen_free_coherent_pages(hwdev, size, vaddr, (dma_addr_t)phys, attrs);
 }
 EXPORT_SYMBOL_GPL(xen_swiotlb_free_coherent);
@@ -381,12 +570,41 @@ EXPORT_SYMBOL_GPL(xen_swiotlb_free_coherent);
  * Once the device is given the dma address, the device owns this memory until
  * either xen_swiotlb_unmap_page or xen_swiotlb_dma_sync_single is performed.
  */
+/*
+ * 来自LDD
+ *
+ * Once a buffer has been mapped, it belongs to the device, not the processor. Until
+ * the buffer has been unmapped, the driver should not touch its contents in any
+ * way. Only after dma_unmap_single has been called is it safe for the driver to
+ * access the contents of the buffer.
+ *
+ * Occasionally a driver needs to access the contents of a streaming DMA buffer
+ * without numapping it.
+ *
+ * dma_sync_single_for_cpu() should be called before the processor accesses a streaming
+ * DMA buffer. Once the call has been made, the CPU "owns" the DMA buffer and can work
+ * with it as needed.
+ *
+ * Before the device accesses the buffer, however, ownership should be transferred to 
+ * the device with dma_sync_single_for_device(). The processor, once again, should not
+ * access the DMA buffer after this call has been made.
+ */
+/*
+ * called by:
+ *   - include/linux/dma-mapping.h|230| <<dma_map_single_attrs>> addr = ops->map_page(dev, virt_to_page(ptr),
+ *   - include/linux/dma-mapping.h|295| <<dma_map_page>> addr = ops->map_page(dev, page, offset, size, dir, 0);
+ *   - include/rdma/ib_verbs.h|3001| <<ib_dma_map_page>> return dev->dma_ops->map_page(dev, page, offset, size, direction);
+ *
+ * struct dma_map_ops xen_swiotlb_dma_ops.map_page = xen_swiotlb_map_page()
+ */
 dma_addr_t xen_swiotlb_map_page(struct device *dev, struct page *page,
 				unsigned long offset, size_t size,
 				enum dma_data_direction dir,
 				unsigned long attrs)
 {
+	/* phys是page中offset的物理地址 */
 	phys_addr_t map, phys = page_to_phys(page) + offset;
+	/* 物理地址转换成机器地址 */
 	dma_addr_t dev_addr = xen_phys_to_bus(phys);
 
 	BUG_ON(dir == DMA_NONE);
@@ -395,6 +613,13 @@ dma_addr_t xen_swiotlb_map_page(struct device *dev, struct page *page,
 	 * we can safely return the device addr and not worry about bounce
 	 * buffering it.
 	 */
+	/*
+	 * range_straddles_page_boundary()返回0说明连续
+	 *
+	 * xen_arch_need_swiotlb()对于x86永远是false
+	 *
+	 * 满足这些条件直接返回机器地址就可以了
+	 */
 	if (dma_capable(dev, dev_addr, size) &&
 	    !range_straddles_page_boundary(phys, size) &&
 		!xen_arch_need_swiotlb(dev, phys, dev_addr) &&
@@ -402,6 +627,7 @@ dma_addr_t xen_swiotlb_map_page(struct device *dev, struct page *page,
 		/* we are not interested in the dma_addr returned by
 		 * xen_dma_map_page, only in the potential cache flushes executed
 		 * by the function. */
+		/* xen_dma_map_page()对于x86什么也不做 */
 		xen_dma_map_page(dev, page, dev_addr, offset, size, dir, attrs);
 		return dev_addr;
 	}
@@ -411,11 +637,18 @@ dma_addr_t xen_swiotlb_map_page(struct device *dev, struct page *page,
 	 */
 	trace_swiotlb_bounced(dev, dev_addr, size, swiotlb_force);
 
+	/*
+	 * map是物理地址
+	 *
+	 * 主要就是这个函数
+	 */
 	map = swiotlb_tbl_map_single(dev, start_dma_addr, phys, size, dir);
 	if (map == SWIOTLB_MAP_ERROR)
 		return DMA_ERROR_CODE;
 
+	/* map是物理地址 转换为机器地址 */
 	dev_addr = xen_phys_to_bus(map);
+	/* xen_dma_map_page()对于x86什么也不做 */
 	xen_dma_map_page(dev, pfn_to_page(map >> PAGE_SHIFT),
 					dev_addr, map & ~PAGE_MASK, size, dir, attrs);
 
@@ -438,6 +671,11 @@ EXPORT_SYMBOL_GPL(xen_swiotlb_map_page);
  * After this call, reads by the cpu to the buffer are guaranteed to see
  * whatever the device wrote there.
  */
+/*
+ * called by:
+ *   - drivers/xen/swiotlb-xen.c|684| <<xen_swiotlb_unmap_page>> xen_unmap_single(hwdev, dev_addr, size, dir, attrs);
+ *   - drivers/xen/swiotlb-xen.c|858| <<xen_swiotlb_unmap_sg_attrs>> xen_unmap_single(hwdev, sg->dma_address, sg_dma_len(sg), dir, attrs);
+ */
 static void xen_unmap_single(struct device *hwdev, dma_addr_t dev_addr,
 			     size_t size, enum dma_data_direction dir,
 			     unsigned long attrs)
@@ -446,9 +684,11 @@ static void xen_unmap_single(struct device *hwdev, dma_addr_t dev_addr,
 
 	BUG_ON(dir == DMA_NONE);
 
+	/* xen_dma_unmap_page()对于x86什么也不做 */
 	xen_dma_unmap_page(hwdev, dev_addr, size, dir, attrs);
 
 	/* NOTE: We use dev_addr here, not paddr! */
+	/* 判断地址是否在swiotlb预留范围内 */
 	if (is_xen_swiotlb_buffer(dev_addr)) {
 		swiotlb_tbl_unmap_single(hwdev, paddr, size, dir);
 		return;
@@ -463,9 +703,18 @@ static void xen_unmap_single(struct device *hwdev, dma_addr_t dev_addr,
 	 * are fine since dma_mark_clean() is null on POWERPC. We can
 	 * make dma_mark_clean() take a physical address if necessary.
 	 */
+	/* 对于x86什么也不做 */
 	dma_mark_clean(phys_to_virt(paddr), size);
 }
 
+/*
+ * called by:
+ *   - include/linux/dma-mapping.h|212| <<dma_unmap_single_attrs>> ops->unmap_page(dev, addr, size, dir, attrs);
+ *   - include/linux/dma-mapping.h|272| <<dma_unmap_page>> ops->unmap_page(dev, addr, size, dir, 0);
+ *   - include/rdma/ib_verbs.h|3017| <<ib_dma_unmap_page>> dev->dma_ops->unmap_page(dev, addr, size, direction);
+ *
+ * struct dma_map_ops xen_swiotlb_dma_ops.unmap_page = xen_swiotlb_unmap_page()
+ */
 void xen_swiotlb_unmap_page(struct device *hwdev, dma_addr_t dev_addr,
 			    size_t size, enum dma_data_direction dir,
 			    unsigned long attrs)
@@ -484,6 +733,31 @@ EXPORT_SYMBOL_GPL(xen_swiotlb_unmap_page);
  * address back to the card, you must first perform a
  * xen_swiotlb_dma_sync_for_device, and then the device again owns the buffer
  */
+/*
+ * 来自LDD
+ *
+ * Once a buffer has been mapped, it belongs to the device, not the processor. Until
+ * the buffer has been unmapped, the driver should not touch its contents in any
+ * way. Only after dma_unmap_single has been called is it safe for the driver to
+ * access the contents of the buffer.
+ *
+ * Occasionally a driver needs to access the contents of a streaming DMA buffer
+ * without numapping it.
+ *
+ * dma_sync_single_for_cpu() should be called before the processor accesses a streaming
+ * DMA buffer. Once the call has been made, the CPU "owns" the DMA buffer and can work
+ * with it as needed.
+ *
+ * Before the device accesses the buffer, however, ownership should be transferred to 
+ * the device with dma_sync_single_for_device(). The processor, once again, should not
+ * access the DMA buffer after this call has been made.
+ */
+/*
+ * called by:
+ *   - drivers/xen/swiotlb-xen.c|735| <<xen_swiotlb_sync_single_for_cpu>> xen_swiotlb_sync_single(hwdev, dev_addr, size, dir, SYNC_FOR_CPU);
+ *   - drivers/xen/swiotlb-xen.c|751| <<xen_swiotlb_sync_single_for_device>> xen_swiotlb_sync_single(hwdev, dev_addr, size, dir, SYNC_FOR_DEVICE);
+ *   - drivers/xen/swiotlb-xen.c|879| <<xen_swiotlb_sync_sg>> xen_swiotlb_sync_single(hwdev, sg->dma_address,
+ */
 static void
 xen_swiotlb_sync_single(struct device *hwdev, dma_addr_t dev_addr,
 			size_t size, enum dma_data_direction dir,
@@ -493,22 +767,38 @@ xen_swiotlb_sync_single(struct device *hwdev, dma_addr_t dev_addr,
 
 	BUG_ON(dir == DMA_NONE);
 
+	/* xen_dma_sync_single_for_cpu()在x86下什么也不做 */
 	if (target == SYNC_FOR_CPU)
 		xen_dma_sync_single_for_cpu(hwdev, dev_addr, size, dir);
 
 	/* NOTE: We use dev_addr here, not paddr! */
+	/*
+	 * 判断地址是否在swiotlb预留范围内
+	 *
+	 * dev_addr是machine address
+	 */
 	if (is_xen_swiotlb_buffer(dev_addr))
-		swiotlb_tbl_sync_single(hwdev, paddr, size, dir, target);
+		swiotlb_tbl_sync_single(hwdev, paddr, size, dir, target); // --> 参数paddr是物理地址
 
+	/* xen_dma_sync_single_for_device()在x86下什么也不做 */
 	if (target == SYNC_FOR_DEVICE)
 		xen_dma_sync_single_for_device(hwdev, dev_addr, size, dir);
 
 	if (dir != DMA_FROM_DEVICE)
 		return;
 
+	/* dma_mark_clean()在x86下什么也不做 */
 	dma_mark_clean(phys_to_virt(paddr), size);
 }
 
+/*
+ * called by:
+ *   - include/linux/dma-mapping.h|343| <<dma_sync_single_for_cpu>> ops->sync_single_for_cpu(dev, addr, size, dir);
+ *   - include/linux/dma-mapping.h|369| <<dma_sync_single_range_for_cpu>> ops->sync_single_for_cpu(dev, addr + offset, size, dir);
+ *   - include/rdma/ib_verbs.h|3121| <<ib_dma_sync_single_for_cpu>> dev->dma_ops->sync_single_for_cpu(dev, addr, size, dir);
+ *
+ * struct dma_map_ops xen_swiotlb_dma_ops.sync_single_for_cpu = xen_swiotlb_sync_single_for_cpu()
+ */
 void
 xen_swiotlb_sync_single_for_cpu(struct device *hwdev, dma_addr_t dev_addr,
 				size_t size, enum dma_data_direction dir)
@@ -517,6 +807,14 @@ xen_swiotlb_sync_single_for_cpu(struct device *hwdev, dma_addr_t dev_addr,
 }
 EXPORT_SYMBOL_GPL(xen_swiotlb_sync_single_for_cpu);
 
+/*
+ * called by:
+ *   - include/linux/dma-mapping.h|355| <<dma_sync_single_for_device>> ops->sync_single_for_device(dev, addr, size, dir);
+ *   - include/linux/dma-mapping.h|383| <<dma_sync_single_range_for_device>> ops->sync_single_for_device(dev, addr + offset, size, dir);
+ *   - include/rdma/ib_verbs.h|3139| <<ib_dma_sync_single_for_device>> dev->dma_ops->sync_single_for_device(dev, addr, size, dir);
+ *
+ * struct dma_map_ops xen_swiotlb_dma_ops.sync_single_for_device = xen_swiotlb_sync_for_device()
+ */
 void
 xen_swiotlb_sync_single_for_device(struct device *hwdev, dma_addr_t dev_addr,
 				   size_t size, enum dma_data_direction dir)
@@ -541,6 +839,13 @@ EXPORT_SYMBOL_GPL(xen_swiotlb_sync_single_for_device);
  * Device ownership issues as mentioned above for xen_swiotlb_map_page are the
  * same here.
  */
+/*
+ * called by:
+ *   - include/linux/dma-mapping.h|267| <<dma_map_sg_attrs>> ents = ops->map_sg(dev, sg, nents, dir, attrs);
+ *   - include/rdma/ib_verbs.h|3034| <<ib_dma_map_sg>> return dev->dma_ops->map_sg(dev, sg, nents, direction);
+ *
+ * struct dma_map_ops xen_swiotlb_dma_ops.map_sg = xen_swiotlb_map_sg_attrs()
+ */
 int
 xen_swiotlb_map_sg_attrs(struct device *hwdev, struct scatterlist *sgl,
 			 int nelems, enum dma_data_direction dir,
@@ -603,6 +908,13 @@ EXPORT_SYMBOL_GPL(xen_swiotlb_map_sg_attrs);
  * Unmap a set of streaming mode DMA translations.  Again, cpu read rules
  * concerning calls here are the same as for swiotlb_unmap_page() above.
  */
+/*
+ * called by:
+ *   - include/linux/dma-mapping.h|283| <<dma_unmap_sg_attrs>> ops->unmap_sg(dev, sg, nents, dir, attrs);
+ *   - include/rdma/ib_verbs.h|3050| <<ib_dma_unmap_sg>> dev->dma_ops->unmap_sg(dev, sg, nents, direction);
+ *
+ * struct dma_map_ops xen_swiotlb_dma_ops.unmap_sg = xen_swiotlb_unmap_sg_attrs()
+ */
 void
 xen_swiotlb_unmap_sg_attrs(struct device *hwdev, struct scatterlist *sgl,
 			   int nelems, enum dma_data_direction dir,
@@ -626,6 +938,11 @@ EXPORT_SYMBOL_GPL(xen_swiotlb_unmap_sg_attrs);
  * The same as swiotlb_sync_single_* but for a scatter-gather list, same rules
  * and usage.
  */
+/*
+ * called by (就在下面):
+ *   - drivers/xen/swiotlb-xen.c|893| <<xen_swiotlb_sync_sg_for_cpu>> xen_swiotlb_sync_sg(hwdev, sg, nelems, dir, SYNC_FOR_CPU);
+ *   - drivers/xen/swiotlb-xen.c|907| <<xen_swiotlb_sync_sg_for_device>> xen_swiotlb_sync_sg(hwdev, sg, nelems, dir, SYNC_FOR_DEVICE);
+ */
 static void
 xen_swiotlb_sync_sg(struct device *hwdev, struct scatterlist *sgl,
 		    int nelems, enum dma_data_direction dir,
@@ -639,6 +956,12 @@ xen_swiotlb_sync_sg(struct device *hwdev, struct scatterlist *sgl,
 					sg_dma_len(sg), dir, target);
 }
 
+/*
+ * called by:
+ *   - include/linux/dma-mapping.h|407| <<dma_sync_sg_for_cpu>> ops->sync_sg_for_cpu(dev, sg, nelems, dir);
+ *
+ * struct dma_map_ops xen_swiotlb_dma_ops.sync_sg_for_cpu = xen_swiotlb_sync_sg_for_cpu()
+ */
 void
 xen_swiotlb_sync_sg_for_cpu(struct device *hwdev, struct scatterlist *sg,
 			    int nelems, enum dma_data_direction dir)
@@ -647,6 +970,12 @@ xen_swiotlb_sync_sg_for_cpu(struct device *hwdev, struct scatterlist *sg,
 }
 EXPORT_SYMBOL_GPL(xen_swiotlb_sync_sg_for_cpu);
 
+/*
+ * called by:
+ *   - include/linux/dma-mapping.h|419| <<dma_sync_sg_for_device>> ops->sync_sg_for_device(dev, sg, nelems, dir);
+ *
+ * struct dma_map_ops xen_swiotlb_dma_ops.sync_sg_for_device = xen_swiotlb_sync_sg_for_device()
+ */
 void
 xen_swiotlb_sync_sg_for_device(struct device *hwdev, struct scatterlist *sg,
 			       int nelems, enum dma_data_direction dir)
@@ -655,6 +984,13 @@ xen_swiotlb_sync_sg_for_device(struct device *hwdev, struct scatterlist *sg,
 }
 EXPORT_SYMBOL_GPL(xen_swiotlb_sync_sg_for_device);
 
+/*
+ * called by:
+ *   - include/linux/dma-mapping.h|541| <<dma_mapping_error>> return get_dma_ops(dev)->mapping_error(dev, dma_addr);
+ *   - include/rdma/ib_verbs.h|2931| <<ib_dma_mapping_error>> return dev->dma_ops->mapping_error(dev, dma_addr);
+ *
+ * struct dma_map_ops xen_swiotlb_dma_ops.mapping_error = xen_swiotlb_dma_mapping_error()
+ */
 int
 xen_swiotlb_dma_mapping_error(struct device *hwdev, dma_addr_t dma_addr)
 {
@@ -668,6 +1004,13 @@ EXPORT_SYMBOL_GPL(xen_swiotlb_dma_mapping_error);
  * during bus mastering, then you would pass 0x00ffffff as the mask to
  * this function.
  */
+/*
+ * called by:
+ *   - arch/x86/kernel/pci-dma.c|227| <<dma_supported>> return ops->dma_supported(dev, mask);
+ *   - include/linux/dma-mapping.h|544| <<dma_supported>> return ops->dma_supported(dev, mask);
+ *
+ * struct dma_map_ops xen_swiotlb_dma_ops.dma_supported = xen_swiotlb_dma_supported()
+ */
 int
 xen_swiotlb_dma_supported(struct device *hwdev, u64 mask)
 {
@@ -675,6 +1018,9 @@ xen_swiotlb_dma_supported(struct device *hwdev, u64 mask)
 }
 EXPORT_SYMBOL_GPL(xen_swiotlb_dma_supported);
 
+/*
+ * 这个函数只和arm相关
+ */
 int
 xen_swiotlb_set_dma_mask(struct device *dev, u64 dma_mask)
 {
diff --git a/drivers/xen/xenbus/xenbus_probe.c b/drivers/xen/xenbus/xenbus_probe.c
index c2d4476..e210a92 100644
--- a/drivers/xen/xenbus/xenbus_probe.c
+++ b/drivers/xen/xenbus/xenbus_probe.c
@@ -169,6 +169,11 @@ int xenbus_read_otherend_details(struct xenbus_device *xendev,
 }
 EXPORT_SYMBOL_GPL(xenbus_read_otherend_details);
 
+/*
+ * called by:
+ *   - drivers/xen/xenbus/xenbus_probe_backend.c|187| <<frontend_changed>> xenbus_otherend_changed(watch, vec, len, 0);
+ *   - drivers/xen/xenbus/xenbus_probe_frontend.c|92| <<backend_changed>> xenbus_otherend_changed(watch, vec, len, 1);
+ */
 void xenbus_otherend_changed(struct xenbus_watch *watch,
 			     const char **vec, unsigned int len,
 			     int ignore_on_shutdown)
@@ -255,6 +260,12 @@ int xenbus_dev_probe(struct device *_dev)
 }
 EXPORT_SYMBOL_GPL(xenbus_dev_probe);
 
+/*
+ * drivers/xen/xenbus/xenbus_probe_backend.c
+ *   struct xen_bus_type xenbus_backend.bus.remove = xenbus_dev_remove()
+ * drivers/xen/xenbus/xenbus_probe_frontend.c
+ *   struct xen_bus_type xenbus_frontend.bus.remove = xenbus_dev_remove()
+ */
 int xenbus_dev_remove(struct device *_dev)
 {
 	struct xenbus_device *dev = to_xenbus_device(_dev);
@@ -274,6 +285,12 @@ int xenbus_dev_remove(struct device *_dev)
 }
 EXPORT_SYMBOL_GPL(xenbus_dev_remove);
 
+/*
+ * drivers/xen/xenbus/xenbus_probe_backend.c
+ *   struct xen_bus_type xenbus_backend.bus.shutdown = xenbus_dev_shutdown()
+ * drivers/xen/xenbus/xenbus_probe_frontend.c
+ *   struct xen_bus_type xenbus_frontend.bus.shutdown = xenbus_dev_shutdown()
+ */
 void xenbus_dev_shutdown(struct device *_dev)
 {
 	struct xenbus_device *dev = to_xenbus_device(_dev);
diff --git a/include/linux/device.h b/include/linux/device.h
index 8d73296..f26fcd0 100644
--- a/include/linux/device.h
+++ b/include/linux/device.h
@@ -817,7 +817,9 @@ struct device {
 #ifdef CONFIG_NUMA
 	int		numa_node;	/* NUMA node this device is close to */
 #endif
+	/* 是设备DMA可以寻址的范围 */
 	u64		*dma_mask;	/* dma mask (if dma'able device) */
+	/* 用于申请一致性的内存区域 */
 	u64		coherent_dma_mask;/* Like dma_mask, but for
 					     alloc_coherent mappings as
 					     not all hardware supports
diff --git a/include/linux/dma-direction.h b/include/linux/dma-direction.h
index 95b6a82..9b74576 100644
--- a/include/linux/dma-direction.h
+++ b/include/linux/dma-direction.h
@@ -4,6 +4,14 @@
  * These definitions mirror those in pci.h, so they can be used
  * interchangeably with their PCI_ counterparts.
  */
+/*
+ * DMA_TO_DEVICE:
+ * If data is being sent to the device (in response, perhaps, to
+ * a write system call)
+ *
+ * DMA_FROM_DEVICE:
+ * data going to the CPU
+ */
 enum dma_data_direction {
 	DMA_BIDIRECTIONAL = 0,
 	DMA_TO_DEVICE = 1,
diff --git a/include/linux/dma-mapping.h b/include/linux/dma-mapping.h
index 704caae..8aed9cb 100644
--- a/include/linux/dma-mapping.h
+++ b/include/linux/dma-mapping.h
@@ -69,9 +69,17 @@
  * its physical address space and the bus address space.
  */
 struct dma_map_ops {
+	/*
+	 * called by:
+	 *   - include/linux/dma-mapping.h|467| <<dma_alloc_attrs>> cpu_addr = ops->alloc(dev, size, dma_handle, flag, attrs);
+	 */
 	void* (*alloc)(struct device *dev, size_t size,
 				dma_addr_t *dma_handle, gfp_t gfp,
 				unsigned long attrs);
+	/*
+	 * called by:
+	 *   - include/linux/dma-mapping.h|507| <<dma_free_attrs>> ops->free(dev, size, cpu_addr, dma_handle, attrs);
+	 */
 	void (*free)(struct device *dev, size_t size,
 			      void *vaddr, dma_addr_t dma_handle,
 			      unsigned long attrs);
@@ -82,10 +90,22 @@ struct dma_map_ops {
 	int (*get_sgtable)(struct device *dev, struct sg_table *sgt, void *,
 			   dma_addr_t, size_t, unsigned long attrs);
 
+	/*
+	 * called by:
+	 *   - include/linux/dma-mapping.h|194| <<dma_map_single_attrs>> addr = ops->map_page(dev, virt_to_page(ptr),
+	 *   - include/linux/dma-mapping.h|259| <<dma_map_page>> addr = ops->map_page(dev, page, offset, size, dir, 0);
+	 *   - include/rdma/ib_verbs.h|3001| <<ib_dma_map_page>> return dev->dma_ops->map_page(dev, page, offset, size, direction);
+	 */
 	dma_addr_t (*map_page)(struct device *dev, struct page *page,
 			       unsigned long offset, size_t size,
 			       enum dma_data_direction dir,
 			       unsigned long attrs);
+	/*
+	 * called by:
+	 *   - include/linux/dma-mapping.h|212| <<dma_unmap_single_attrs>> ops->unmap_page(dev, addr, size, dir, attrs);
+	 *   - include/linux/dma-mapping.h|272| <<dma_unmap_page>> ops->unmap_page(dev, addr, size, dir, 0);
+	 *   - include/rdma/ib_verbs.h|3017| <<ib_dma_unmap_page>> dev->dma_ops->unmap_page(dev, addr, size, direction);
+	 */
 	void (*unmap_page)(struct device *dev, dma_addr_t dma_handle,
 			   size_t size, enum dma_data_direction dir,
 			   unsigned long attrs);
@@ -93,9 +113,19 @@ struct dma_map_ops {
 	 * map_sg returns 0 on error and a value > 0 on success.
 	 * It should never return a value < 0.
 	 */
+	/*
+	 * called by:
+	 *   - include/linux/dma-mapping.h|267| <<dma_map_sg_attrs>> ents = ops->map_sg(dev, sg, nents, dir, attrs);
+	 *   - include/rdma/ib_verbs.h|3034| <<ib_dma_map_sg>> return dev->dma_ops->map_sg(dev, sg, nents, direction);
+	 */
 	int (*map_sg)(struct device *dev, struct scatterlist *sg,
 		      int nents, enum dma_data_direction dir,
 		      unsigned long attrs);
+	/*
+	 * called by:
+	 *   - include/linux/dma-mapping.h|283| <<dma_unmap_sg_attrs>> ops->unmap_sg(dev, sg, nents, dir, attrs);
+	 *   - include/rdma/ib_verbs.h|3050| <<ib_dma_unmap_sg>> dev->dma_ops->unmap_sg(dev, sg, nents, direction);
+	 */
 	void (*unmap_sg)(struct device *dev,
 			 struct scatterlist *sg, int nents,
 			 enum dma_data_direction dir,
@@ -106,19 +136,49 @@ struct dma_map_ops {
 	void (*unmap_resource)(struct device *dev, dma_addr_t dma_handle,
 			   size_t size, enum dma_data_direction dir,
 			   unsigned long attrs);
+	/*
+	 * called by:
+	 *   - include/linux/dma-mapping.h|343| <<dma_sync_single_for_cpu>> ops->sync_single_for_cpu(dev, addr, size, dir);
+	 *   - include/linux/dma-mapping.h|369| <<dma_sync_single_range_for_cpu>> ops->sync_single_for_cpu(dev, addr + offset, size, dir);
+	 *   - include/rdma/ib_verbs.h|3121| <<ib_dma_sync_single_for_cpu>> dev->dma_ops->sync_single_for_cpu(dev, addr, size, dir);
+	 */
 	void (*sync_single_for_cpu)(struct device *dev,
 				    dma_addr_t dma_handle, size_t size,
 				    enum dma_data_direction dir);
+	/*
+	 * called by:
+	 *   - include/linux/dma-mapping.h|355| <<dma_sync_single_for_device>> ops->sync_single_for_device(dev, addr, size, dir);
+	 *   - include/linux/dma-mapping.h|383| <<dma_sync_single_range_for_device>> ops->sync_single_for_device(dev, addr + offset, size, dir);
+	 *   - include/rdma/ib_verbs.h|3139| <<ib_dma_sync_single_for_device>> dev->dma_ops->sync_single_for_device(dev, addr, size, dir);
+	 */
 	void (*sync_single_for_device)(struct device *dev,
 				       dma_addr_t dma_handle, size_t size,
 				       enum dma_data_direction dir);
+	/*
+	 * called by:
+	 *   - include/linux/dma-mapping.h|407| <<dma_sync_sg_for_cpu>> ops->sync_sg_for_cpu(dev, sg, nelems, dir);
+	 */
 	void (*sync_sg_for_cpu)(struct device *dev,
 				struct scatterlist *sg, int nents,
 				enum dma_data_direction dir);
+	/*
+	 * called by:
+	 *   - include/linux/dma-mapping.h|419| <<dma_sync_sg_for_device>> ops->sync_sg_for_device(dev, sg, nelems, dir);
+	 */
 	void (*sync_sg_for_device)(struct device *dev,
 				   struct scatterlist *sg, int nents,
 				   enum dma_data_direction dir);
+	/*
+	 * called by:
+	 *   - include/linux/dma-mapping.h|541| <<dma_mapping_error>> return get_dma_ops(dev)->mapping_error(dev, dma_addr);
+	 *   - include/rdma/ib_verbs.h|2931| <<ib_dma_mapping_error>> return dev->dma_ops->mapping_error(dev, dma_addr);
+	 */
 	int (*mapping_error)(struct device *dev, dma_addr_t dma_addr);
+	/*
+	 * called by:
+	 *   - arch/x86/kernel/pci-dma.c|227| <<dma_supported>> return ops->dma_supported(dev, mask);
+	 *   - include/linux/dma-mapping.h|544| <<dma_supported>> return ops->dma_supported(dev, mask);
+	 */
 	int (*dma_supported)(struct device *dev, u64 mask);
 	int (*set_dma_mask)(struct device *dev, u64 mask);
 #ifdef ARCH_HAS_DMA_GET_REQUIRED_MASK
diff --git a/kernel/irq/chip.c b/kernel/irq/chip.c
index 9e745cc..2078bb5 100644
--- a/kernel/irq/chip.c
+++ b/kernel/irq/chip.c
@@ -89,6 +89,9 @@ EXPORT_SYMBOL(irq_set_irq_type);
  *
  *	Set the hardware irq controller data for an irq
  */
+/*
+ * 把data设置为irq对应的desc->irq_common_data.handler_data
+ */
 int irq_set_handler_data(unsigned int irq, void *data)
 {
 	unsigned long flags;
@@ -618,6 +621,13 @@ EXPORT_SYMBOL_GPL(handle_fasteoi_irq);
  *	the handler was running. If all pending interrupts are handled, the
  *	loop is left.
  */
+/*
+ * 被xen在以下调用:
+ *   - drivers/xen/events/events_base.c|1057| <<xen_bind_pirq_gsi_to_irq>> handle_edge_irq, name);
+ *   - drivers/xen/events/events_base.c|1120| <<xen_bind_pirq_msi_to_irq>> irq_set_chip_and_handler_name(irq + i, &xen_pirq_chip, handle_edge_irq, name);
+ *   - drivers/xen/events/events_base.c|1258| <<bind_evtchn_to_irq>> handle_edge_irq, "event");
+ *   - drivers/xen/events/events_base.c|1412| <<bind_virq_to_irq>> handle_edge_irq, "virq");
+ */
 void handle_edge_irq(struct irq_desc *desc)
 {
 	raw_spin_lock(&desc->lock);
diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index cf94460..f44a64e 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -1079,6 +1079,11 @@ static void irq_release_resources(struct irq_desc *desc)
 		c->irq_release_resources(d);
 }
 
+/*
+ * called by:
+ *   - kernel/irq/manage.c|1183| <<__setup_irq>> ret = setup_irq_thread(new, irq, false);
+ *   - kernel/irq/manage.c|1187| <<__setup_irq>> ret = setup_irq_thread(new->secondary, irq, true);
+ */
 static int
 setup_irq_thread(struct irqaction *new, unsigned int irq, bool secondary)
 {
@@ -1088,6 +1093,13 @@ setup_irq_thread(struct irqaction *new, unsigned int irq, bool secondary)
 	};
 
 	if (!secondary) {
+		/*
+		 * root       900  0.2  0.0      0     0 ?        S    11:03   0:00 [irq/24-nvme0q0]
+		 * root       902  0.0  0.0      0     0 ?        S    11:03   0:00 [irq/24-nvme0q1]
+		 * root      1012  0.0  0.0      0     0 ?        S    11:03   0:00 [irq/25-nvme0q2]
+		 * root      1015  0.0  0.0      0     0 ?        S    11:03   0:00 [irq/26-nvme0q3]
+		 * root      1016  0.0  0.0      0     0 ?        S    11:03   0:00 [irq/27-nvme0q4]
+		 */
 		t = kthread_create(irq_thread, new, "irq/%d-%s", irq,
 				   new->name);
 	} else {
@@ -1125,6 +1137,13 @@ setup_irq_thread(struct irqaction *new, unsigned int irq, bool secondary)
  * Internal function to register an irqaction - typically used to
  * allocate special interrupts that are part of the architecture.
  */
+/*
+ * called by:
+ *   - kernel/irq/manage.c|1459| <<setup_irq>> retval = __setup_irq(irq, desc, act);
+ *   - kernel/irq/manage.c|1720| <<request_threaded_irq>> retval = __setup_irq(irq, desc, action);
+ *   - kernel/irq/manage.c|1970| <<setup_percpu_irq>> retval = __setup_irq(irq, desc, act);
+ *   - kernel/irq/manage.c|2026| <<request_percpu_irq>> retval = __setup_irq(irq, desc, action);
+ */
 static int
 __setup_irq(unsigned int irq, struct irq_desc *desc, struct irqaction *new)
 {
@@ -1644,6 +1663,76 @@ EXPORT_SYMBOL(free_irq);
  *	IRQF_TRIGGER_*		Specify active edge(s) or level
  *
  */
+/*
+ * nvme申请threaded irq的例子:
+ *
+ *
+ * 1118 static int queue_request_irq(struct nvme_queue *nvmeq)
+ * 1119 {
+ * 1120         if (use_threaded_interrupts)
+ * 1121                 return request_threaded_irq(nvmeq_irq(nvmeq), nvme_irq_check,
+ * 1122                                 nvme_irq, IRQF_SHARED, nvmeq->irqname, nvmeq);
+ * 1123         else
+ * 1124                 return request_irq(nvmeq_irq(nvmeq), nvme_irq, IRQF_SHARED,
+ * 1125                                 nvmeq->irqname, nvmeq);
+ * 1126 }
+ *
+ *
+ * 1678 int request_threaded_irq(unsigned int irq, irq_handler_t handler,
+ * 1679                          irq_handler_t thread_fn, unsigned long irqflags,
+ * 1680                          const char *devname, void *dev_id)
+ * 1681 {
+ *
+ *
+ * handler = nvme_irq_check()在中断处理执行,
+ *
+ * [0] nvme_irq_check
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_edge_irq
+ * [0] handle_irq
+ * [0] do_IRQ
+ * [0] common_interrupt
+ * [0] irq_exit
+ * [0] smp_reschedule_interrupt
+ * [0] reschedule_interrupt
+ *
+ * [0] nvme_irq_check
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event_percpu
+ * [0] handle_irq_event 
+ * [0] handle_edge_irq 
+ * [0] handle_irq
+ * [0] do_IRQ
+ * [0] common_interrupt
+ *
+ *
+ * thread_fn = nvme_irq()在中断线程执行
+ *
+ * [0] nvme_irq
+ * [0] irq_thread_fn
+ * [0] irq_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ *
+ * request_threaded_irq()
+ *   -> __setup_irq()
+ *        -> setup_irq_thread()
+ * 会为每一个中断创建内核线程, 内核线程记录在irqaction->thread
+ *
+ * root       900  0.2  0.0      0     0 ?        S    11:03   0:00 [irq/24-nvme0q0]
+ * root       902  0.0  0.0      0     0 ?        S    11:03   0:00 [irq/24-nvme0q1]
+ * root      1012  0.0  0.0      0     0 ?        S    11:03   0:00 [irq/25-nvme0q2]
+ * root      1015  0.0  0.0      0     0 ?        S    11:03   0:00 [irq/26-nvme0q3]
+ * root      1016  0.0  0.0      0     0 ?        S    11:03   0:00 [irq/27-nvme0q4]
+ *
+ * 中断发生时, action->handler = nvme_irq_check()会检查cq的
+ * ring buffer是否有数据. 如果有数据就返回IRQ_WAKE_THREAD.
+ * __handle_irq_event_percpu()就会使用
+ * __irq_wake_thread()-->wake_up_process()唤醒中断内核线程.
+ */
 int request_threaded_irq(unsigned int irq, irq_handler_t handler,
 			 irq_handler_t thread_fn, unsigned long irqflags,
 			 const char *devname, void *dev_id)
@@ -1680,6 +1769,7 @@ int request_threaded_irq(unsigned int irq, irq_handler_t handler,
 	if (!handler) {
 		if (!thread_fn)
 			return -EINVAL;
+		/* 默认返回 IRQ_WAKE_THREAD */
 		handler = irq_default_primary_handler;
 	}
 
diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index 6b3fff6..59cab21 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -3243,6 +3243,11 @@ static inline void schedule_debug(struct task_struct *prev)
 		panic("corrupted stack end detected inside scheduler\n");
 #endif
 
+	/*
+	 * 检查是否(preempt_count() != PREEMPT_DISABLE_OFFSET)
+	 *
+	 * PREEMPT_DISABLE_OFFSET是The preempt_count offset after preempt_disable();
+	 */
 	if (unlikely(in_atomic_preempt_off())) {
 		__schedule_bug(prev);
 		preempt_count_set(PREEMPT_DISABLED);
diff --git a/lib/iommu-helper.c b/lib/iommu-helper.c
index a816f3a..cad34b4 100644
--- a/lib/iommu-helper.c
+++ b/lib/iommu-helper.c
@@ -6,10 +6,22 @@
 #include <linux/bitmap.h>
 #include <linux/bug.h>
 
+/*
+ * 在swiotlb_tbl_map_single()调用的例子:
+ *  731                 while (iommu_is_span_boundary(index, nslots, offset_slots,
+ *  732                                               max_slots)) {
+ *
+ * 如果是swiotlb_tbl_map_single()调用进来的:
+ *   index         = index
+ *   nr            = nslots
+ *   shift         = offset_slots
+ *   boundary_size = max_slots
+ */
 int iommu_is_span_boundary(unsigned int index, unsigned int nr,
 			   unsigned long shift,
 			   unsigned long boundary_size)
 {
+	/* boundary_size必须是2的N次方 */
 	BUG_ON(!is_power_of_2(boundary_size));
 
 	shift = (shift + index) & (boundary_size - 1);
diff --git a/lib/swiotlb.c b/lib/swiotlb.c
index 7ff9dc3..dc58b64 100644
--- a/lib/swiotlb.c
+++ b/lib/swiotlb.c
@@ -43,9 +43,36 @@
 #define CREATE_TRACE_POINTS
 #include <trace/events/swiotlb.h>
 
+/*
+ * OFFSET(0, IO_TLB_SEGSIZE) = 0
+ * OFFSET(1, IO_TLB_SEGSIZE) = 1
+ * OFFSET(2, IO_TLB_SEGSIZE) = 2
+ * OFFSET(3, IO_TLB_SEGSIZE) = 3
+ * OFFSET(4, IO_TLB_SEGSIZE) = 4
+ * OFFSET(5, IO_TLB_SEGSIZE) = 5
+ * OFFSET(6, IO_TLB_SEGSIZE) = 6
+ * OFFSET(7, IO_TLB_SEGSIZE) = 7
+ * ... ...
+ * OFFSET(124, IO_TLB_SEGSIZE)=124
+ * OFFSET(125, IO_TLB_SEGSIZE)=125
+ * OFFSET(126, IO_TLB_SEGSIZE)=126
+ * OFFSET(127, IO_TLB_SEGSIZE)=127
+ * OFFSET(128, IO_TLB_SEGSIZE)=0
+ */
 #define OFFSET(val,align) ((unsigned long)	\
 	                   ( (val) & ( (align) - 1)))
 
+/*
+ * used by:
+ *   - lib/swiotlb.c|261| <<swiotlb_late_init_with_default_size>> io_tlb_nslabs = SLABS_PER_PAGE << order;
+ *   - lib/swiotlb.c|264| <<swiotlb_late_init_with_default_size>> while ((SLABS_PER_PAGE << order) > IO_TLB_MIN_SLABS) {
+ *   - lib/swiotlb.c|279| <<swiotlb_late_init_with_default_size>> io_tlb_nslabs = SLABS_PER_PAGE << order;
+ *
+ * PAGE_SHIFT     = 12 (1 << 12 = 4K)
+ * IO_TLB_SHIFT   = 11 (1 << 11 = 2K)
+ * SLABS_PER_PAGE = 1 << (12 - 11) = 1 << 1 = 2
+ * 每个page有2个slot
+ */
 #define SLABS_PER_PAGE (1 << (PAGE_SHIFT - IO_TLB_SHIFT))
 
 /*
@@ -53,8 +80,15 @@
  * 64bit capable cards will only lightly use the swiotlb.  If we can't
  * allocate a contiguous 1MB, we're probably in trouble anyway.
  */
+/*
+ * used only by:
+ *   - lib/swiotlb.c|264| <<swiotlb_late_init_with_default_size>> while ((SLABS_PER_PAGE << order) > IO_TLB_MIN_SLABS) {
+ *
+ * 1 << 9 = 512
+ */
 #define IO_TLB_MIN_SLABS ((1<<20) >> IO_TLB_SHIFT)
 
+/* 在测试机上是 0 */
 enum swiotlb_force swiotlb_force;
 
 /*
@@ -62,12 +96,25 @@ enum swiotlb_force swiotlb_force;
  * swiotlb_tbl_sync_single_*, to see if the memory was in fact allocated by this
  * API.
  */
+/*
+ * io_tlb_start在以下设置:
+ *   - lib/swiotlb.c|172| <<swiotlb_init_with_tbl>> io_tlb_start = __pa(tlb);
+ *   - lib/swiotlb.c|296| <<swiotlb_late_init_with_tbl>> io_tlb_start = virt_to_phys(tlb);
+ *   - lib/swiotlb.c|350| <<swiotlb_late_init_with_tbl>> io_tlb_start = 0;
+ *
+ * 在测试机上 (start和end之间是64MB):
+ * io_tlb_start: 0x4a2a00000
+ * io_tlb_end  : 0x4a6a00000
+ */
 static phys_addr_t io_tlb_start, io_tlb_end;
 
 /*
  * The number of IO TLB blocks (in groups of 64) between io_tlb_start and
  * io_tlb_end.  This is command line adjustable via setup_io_tlb_npages.
  */
+/*
+ * io_tlb_nslabs在测试机是32768
+ */
 static unsigned long io_tlb_nslabs;
 
 /*
@@ -75,13 +122,28 @@ static unsigned long io_tlb_nslabs;
  */
 static unsigned long io_tlb_overflow = 32*1024;
 
+/*
+ * 测试机是0x7bff8000
+ */
 static phys_addr_t io_tlb_overflow_buffer;
 
 /*
  * This is a free list describing the number of free entries available from
  * each index
  */
+/*
+ * io_tlb_list[i]存的好像是从当前开始连续的free的slot的数量
+ */
 static unsigned int *io_tlb_list;
+/*
+ * used by:
+ *   - lib/swiotlb.c|291| <<swiotlb_init_with_tbl>> io_tlb_index = 0;
+ *   - lib/swiotlb.c|458| <<swiotlb_late_init_with_tbl>> io_tlb_index = 0;
+ *   - lib/swiotlb.c|739| <<swiotlb_tbl_map_single>> index = ALIGN(io_tlb_index, stride);
+ *   - lib/swiotlb.c|802| <<swiotlb_tbl_map_single>> io_tlb_index = ((index + nslots) < io_tlb_nslabs
+ *
+ * io_tlb_index除了初始化 只在swiotlb_tbl_map_single()中修改过
+ */
 static unsigned int io_tlb_index;
 
 /*
@@ -120,6 +182,13 @@ setup_io_tlb_npages(char *str)
 early_param("swiotlb", setup_io_tlb_npages);
 /* make io_tlb_overflow tunable too? */
 
+/*
+ * 返回io_tlb_nslabs, 在测试机是32768
+ *
+ * 另外 在测试机上 (start和end之间是64MB):
+ *   io_tlb_start: 0x4a2a00000
+ *   io_tlb_end  : 0x4a6a00000
+ */
 unsigned long swiotlb_nr_tbl(void)
 {
 	return io_tlb_nslabs;
@@ -141,11 +210,19 @@ unsigned long swiotlb_size_or_default(void)
 static dma_addr_t swiotlb_virt_to_bus(struct device *hwdev,
 				      volatile void *address)
 {
+	/* x86直接返回virt_to_phys(address) */
 	return phys_to_dma(hwdev, virt_to_phys(address));
 }
 
+/* 测试机上是false */
 static bool no_iotlb_memory;
 
+/*
+ * called by:
+ *   - arch/x86/kernel/pci-swiotlb.c|184| <<pci_swiotlb_late_init>> swiotlb_print_info();
+ *   - lib/swiotlb.c|227| <<swiotlb_init_with_tbl>> swiotlb_print_info();
+ *   - lib/swiotlb.c|361| <<swiotlb_late_init_with_tbl>> swiotlb_print_info();
+ */
 void swiotlb_print_info(void)
 {
 	unsigned long bytes = io_tlb_nslabs << IO_TLB_SHIFT;
@@ -161,6 +238,21 @@ void swiotlb_print_info(void)
 	       bytes >> 20);
 }
 
+/*
+ * caled by:
+ *   - drivers/xen/swiotlb-xen.c|425| <<xen_swiotlb_init>> if (swiotlb_init_with_tbl(xen_io_tlb_start, xen_io_tlb_nslabs,
+ *   - lib/swiotlb.c|286| <<swiotlb_init>> if (vstart && !swiotlb_init_with_tbl(vstart, io_tlb_nslabs, verbose)) --> xen上似乎不用
+ *
+ * upstream linux在virtualbox xen上
+ * [    0.294544]  dump_stack
+ * [    0.294547]  swiotlb_init_with_tbl
+ * [    0.294551]  xen_swiotlb_init
+ * [    0.294554]  pci_xen_swiotlb_init
+ * [    0.294556]  pci_iommu_alloc
+ * [    0.294559]  mem_init
+ * [    0.294561]  start_kernel
+ * [    0.294563]  xen_start_kernel
+ */
 int __init swiotlb_init_with_tbl(char *tlb, unsigned long nslabs, int verbose)
 {
 	void *v_overflow_buffer;
@@ -195,6 +287,10 @@ int __init swiotlb_init_with_tbl(char *tlb, unsigned long nslabs, int verbose)
 				PAGE_ALIGN(io_tlb_nslabs * sizeof(phys_addr_t)),
 				PAGE_SIZE);
 	for (i = 0; i < io_tlb_nslabs; i++) {
+		/*
+		 * 初始化后, 大概如下pattern:
+		 * 128, 127, ..., 3, 2, 1, 128, 127, ... , 3, 2, 1..
+		 */
 		io_tlb_list[i] = IO_TLB_SEGSIZE - OFFSET(i, IO_TLB_SEGSIZE);
 		io_tlb_orig_addr[i] = INVALID_PHYS_ADDR;
 	}
@@ -210,6 +306,12 @@ int __init swiotlb_init_with_tbl(char *tlb, unsigned long nslabs, int verbose)
  * Statically reserve bounce buffer space and initialize bounce buffer data
  * structures for the software IO TLB used to implement the DMA API.
  */
+/*
+ * called by:
+ *   - arch/x86/kernel/pci-swiotlb.c|104| <<pci_swiotlb_init>> swiotlb_init(0);
+ *
+ * 似乎在xen上用不到
+ */
 void  __init
 swiotlb_init(int verbose)
 {
@@ -241,6 +343,9 @@ swiotlb_init(int verbose)
  * initialize the swiotlb later using the slab allocator if needed.
  * This should be just like above, but with some error catching.
  */
+/*
+ * 猜测xen上用不到
+ */
 int
 swiotlb_late_init_with_default_size(size_t default_size)
 {
@@ -284,6 +389,16 @@ swiotlb_late_init_with_default_size(size_t default_size)
 	return rc;
 }
 
+/*
+ * called by:
+ *   - drivers/xen/swiotlb-xen.c|430| <<xen_swiotlb_init>> rc = swiotlb_late_init_with_tbl(xen_io_tlb_start, xen_io_tlb_nslabs);
+ *   - lib/swiotlb.c|364| <<swiotlb_late_init_with_default_size>> rc = swiotlb_late_init_with_tbl(vstart, io_tlb_nslabs);
+ *
+ * 对于xen来说, 在测试机器上 (start和end之间是64MB)wiotlb_init_with_tbl
+ *    tlb是     ---> xen_io_tlb_start  = 0xffff8804a2a00000
+ *                   xen_io_tlb_end    = 0xffff8804a6a00000
+ *    nslabs是  ---> xen_io_tlb_nslabs = 32768
+ */
 int
 swiotlb_late_init_with_tbl(char *tlb, unsigned long nslabs)
 {
@@ -292,6 +407,11 @@ swiotlb_late_init_with_tbl(char *tlb, unsigned long nslabs)
 
 	bytes = nslabs << IO_TLB_SHIFT;
 
+	/*
+	 * 在测试机上 (start和end之间是64MB):
+	 *    io_tlb_start: 0x4a2a00000
+	 *    io_tlb_end  : 0x4a6a00000
+	 */
 	io_tlb_nslabs = nslabs;
 	io_tlb_start = virt_to_phys(tlb);
 	io_tlb_end = io_tlb_start + bytes;
@@ -313,11 +433,21 @@ swiotlb_late_init_with_tbl(char *tlb, unsigned long nslabs)
 	 * to find contiguous free memory regions of size up to IO_TLB_SEGSIZE
 	 * between io_tlb_start and io_tlb_end.
 	 */
+	/*
+	 * 分配一些page用来存储io_tlb_list数组
+	 * 这些page一共占用 io_tlb_nslabs=32768个int
+	 * 每个io_tlb_list[32768]是一个int
+	 */
 	io_tlb_list = (unsigned int *)__get_free_pages(GFP_KERNEL,
 	                              get_order(io_tlb_nslabs * sizeof(int)));
 	if (!io_tlb_list)
 		goto cleanup3;
 
+	/*
+	 * 分配一些page用来存储io_tlb_orig_addr
+	 * 这些page一共占用 io_tlb_nslabs=32768个phys_addr_t
+	 * 每个io_tlb_orig_addr[32768]是一个phys_addr_t
+	 */
 	io_tlb_orig_addr = (phys_addr_t *)
 		__get_free_pages(GFP_KERNEL,
 				 get_order(io_tlb_nslabs *
@@ -325,7 +455,9 @@ swiotlb_late_init_with_tbl(char *tlb, unsigned long nslabs)
 	if (!io_tlb_orig_addr)
 		goto cleanup4;
 
+	/* for 32768次 */
 	for (i = 0; i < io_tlb_nslabs; i++) {
+		/* 似乎io_tlb_list[]就是从0-127不停轮循 */
 		io_tlb_list[i] = IO_TLB_SEGSIZE - OFFSET(i, IO_TLB_SEGSIZE);
 		io_tlb_orig_addr[i] = INVALID_PHYS_ADDR;
 	}
@@ -352,6 +484,10 @@ swiotlb_late_init_with_tbl(char *tlb, unsigned long nslabs)
 	return -ENOMEM;
 }
 
+/*
+ * called by only:
+ *   - arch/x86/kernel/pci-swiotlb.c|180| <<pci_swiotlb_late_init>> swiotlb_free();
+ */
 void __init swiotlb_free(void)
 {
 	if (!io_tlb_orig_addr)
@@ -379,6 +515,13 @@ void __init swiotlb_free(void)
 	io_tlb_nslabs = 0;
 }
 
+/*
+ * called by:
+ *   - arch/x86/kernel/pci-swiotlb.c|57| <<x86_swiotlb_free_coherent>> if (is_swiotlb_buffer(dma_to_phys(dev, dma_addr)))
+ *   - lib/swiotlb.c|845| <<swiotlb_free_coherent>> if (!is_swiotlb_buffer(paddr))
+ *   - lib/swiotlb.c|941| <<unmap_single>> if (is_swiotlb_buffer(paddr)) {
+ *   - lib/swiotlb.c|985| <<swiotlb_sync_single>> if (is_swiotlb_buffer(paddr)) {
+ */
 int is_swiotlb_buffer(phys_addr_t paddr)
 {
 	return paddr >= io_tlb_start && paddr < io_tlb_end;
@@ -387,12 +530,29 @@ int is_swiotlb_buffer(phys_addr_t paddr)
 /*
  * Bounce: copy the swiotlb buffer back to the original dma location
  */
+/*
+ * called by:
+ *   - lib/swiotlb.c|555| <<swiotlb_tbl_map_single>> swiotlb_bounce(orig_addr, tlb_addr, size, DMA_TO_DEVICE);
+ *   - lib/swiotlb.c|597| <<swiotlb_tbl_unmap_single>> swiotlb_bounce(orig_addr, tlb_addr, size, DMA_FROM_DEVICE);
+ *   - lib/swiotlb.c|642| <<swiotlb_tbl_sync_single>> swiotlb_bounce(orig_addr, tlb_addr,
+ *   - lib/swiotlb.c|649| <<swiotlb_tbl_sync_single>> swiotlb_bounce(orig_addr, tlb_addr,
+ *
+ * 如果是DMA_TO_DEVICE就要从原始内存拷贝到bounce buffer
+ * 如果是其他 (比如DMA_FROM_DEVICE) 就要从bounce buffer拷贝到原始内存
+ *
+ * vaddr来自函数参数的tlb_addr, 说明tlb_addr是bounce buffer (预分配的)
+ *
+ * tlb_addr是物理地址
+ */
 static void swiotlb_bounce(phys_addr_t orig_addr, phys_addr_t tlb_addr,
 			   size_t size, enum dma_data_direction dir)
 {
 	unsigned long pfn = PFN_DOWN(orig_addr);
 	unsigned char *vaddr = phys_to_virt(tlb_addr);
 
+	/*
+	 * 这里pfn是orig_addr的
+	 */
 	if (PageHighMem(pfn_to_page(pfn))) {
 		/* The buffer does not have a mapping.  Map it in and copy */
 		unsigned int offset = orig_addr & ~PAGE_MASK;
@@ -418,12 +578,104 @@ static void swiotlb_bounce(phys_addr_t orig_addr, phys_addr_t tlb_addr,
 			offset = 0;
 		}
 	} else if (dir == DMA_TO_DEVICE) {
+		/*
+		 * 如果是DMA_TO_DEVICE就要从原始内存拷贝到bounce buffer
+		 * 如果是其他就要从bounce buffer拷贝到原始内存
+		 *
+		 * vaddr来自函数参数的tlb_addr, 说明tlb_addr是bounce buffer (预分配的)
+		 */
 		memcpy(vaddr, phys_to_virt(orig_addr), size);
 	} else {
 		memcpy(phys_to_virt(orig_addr), vaddr, size);
 	}
 }
 
+/*
+ * called by:
+ *   - drivers/xen/swiotlb-xen.c|615| <<xen_swiotlb_map_page>> map = swiotlb_tbl_map_single(dev, start_dma_addr, phys, size, dir);
+ *   - drivers/xen/swiotlb-xen.c|837| <<xen_swiotlb_map_sg_attrs>> phys_addr_t map = swiotlb_tbl_map_single(hwdev,
+ *   - lib/swiotlb.c|595| <<map_single>> return swiotlb_tbl_map_single(hwdev, start_dma_addr, phys, size, dir);
+ *
+ * 返回值是物理地址
+ *
+ * io_tlb_list[]存着从当前开始有几个连续的slot
+ *
+ * 假设开始状态 index = 5, nslots = 4:
+ *
+ * io_tlb_list[]  OFFSET(i, IO_TLB_SEGSIZE)
+ *      .                 .
+ *      .                 .
+ *      .                 .
+ *      2                126
+ *      1                127
+ *     128 (index = 0)    0 <------ index = 0
+ *     127                1
+ *     126                2
+ *     125                3
+ *     124                4
+ *     123 (index = 5)    5 <------ index = 5
+ *     122                6
+ *     121                7
+ *     122                8
+ *     123                9
+ *      .                 .
+ *      .                 .
+ *      .                 .
+ *
+ *
+ * 第一步:
+ * for (i = index; i < (int) (index + nslots); i++)
+ *     io_tlb_list[i] = 0;
+ *
+ * 把io_tlb_list[5-8]全设置成0
+ *
+ * io_tlb_list[]  OFFSET(i, IO_TLB_SEGSIZE)
+ *     .                 .
+ *     .                 .
+ *     .                 .
+ *     2                126
+ *     1                127
+ *    128 (index = 0)    0 <------ index = 0
+ *    127                1
+ *    126                2
+ *    125                3
+ *    124                4
+ *     0  (index = 5)    5 <------ index = 5
+ *     0                 6
+ *     0                 7
+ *     0                 8
+ *    123                9
+ *     .                 .
+ *     .                 .
+ *     .                 .
+ *
+ *
+ * 第二步:
+ * for (i = index - 1; (OFFSET(i, IO_TLB_SEGSIZE) != IO_TLB_SEGSIZE - 1) && io_tlb_list[i]; i--)
+ *     io_tlb_list[i] = ++count;
+ *
+ * 把io_tlb_list[4-0]设置成1-5 (++count)
+ * 
+ * io_tlb_list[]  OFFSET(i, IO_TLB_SEGSIZE)
+ *     .                 .
+ *     .                 .
+ *     .                 .
+ *     2                126
+ *     1                127
+ *     5  (index = 0)    0 <------ index = 0
+ *     4                 1
+ *     3                 2
+ *     2                 3
+ *     1                 4
+ *     0  (index = 5)    5 <------ index = 5
+ *     0                 6
+ *     0                 7
+ *     0                 8
+ *    123                9
+ *     .                 .
+ *     .                 .
+ *     .                 .
+ */
 phys_addr_t swiotlb_tbl_map_single(struct device *hwdev,
 				   dma_addr_t tbl_dma_addr,
 				   phys_addr_t orig_addr, size_t size,
@@ -444,11 +696,27 @@ phys_addr_t swiotlb_tbl_map_single(struct device *hwdev,
 
 	tbl_dma_addr &= mask;
 
+	/* slots的index ? */
 	offset_slots = ALIGN(tbl_dma_addr, 1 << IO_TLB_SHIFT) >> IO_TLB_SHIFT;
 
 	/*
+	 * 在xen测试机上, 总是tbl_dma_addr=0x1c0000
+	 * 所以总是offset_slots=896
+	 */
+
+	/*
  	 * Carefully handle integer overflow which can occur when mask == ~0UL.
  	 */
+	/*
+	 * 在xen的测试机器上:
+	 * max_slots = 2097152=0x200000, mask=0x00000000ffffffff
+	 *
+	 * 这里是前者条件满足
+	 * mask = 0xffffffff
+	 * mask + 1 = 0x100000000
+	 * ALIGN(mask + 1, 1 << IO_TLB_SHIFT) >> IO_TLB_SHIFT = 0x0000000000200000
+	 * 1UL << (BITS_PER_LONG - IO_TLB_SHIFT) = 0x0020000000000000
+	 */
 	max_slots = mask + 1
 		    ? ALIGN(mask + 1, 1 << IO_TLB_SHIFT) >> IO_TLB_SHIFT
 		    : 1UL << (BITS_PER_LONG - IO_TLB_SHIFT);
@@ -457,7 +725,16 @@ phys_addr_t swiotlb_tbl_map_single(struct device *hwdev,
 	 * For mappings greater than or equal to a page, we limit the stride
 	 * (and hence alignment) to a page size.
 	 */
+	/*
+	 * 一个slot是2K??
+	 *
+	 * 看看这些size占用几个slot
+	 */
 	nslots = ALIGN(size, 1 << IO_TLB_SHIFT) >> IO_TLB_SHIFT;
+	/*
+	 * 当申请的内存大于PAGE_SIZE时, stride是1<<1=2
+	 * 否则, stride是1
+	 */
 	if (size >= PAGE_SIZE)
 		stride = (1 << (PAGE_SHIFT - IO_TLB_SHIFT));
 	else
@@ -470,12 +747,34 @@ phys_addr_t swiotlb_tbl_map_single(struct device *hwdev,
 	 * request and allocate a buffer from that IO TLB pool.
 	 */
 	spin_lock_irqsave(&io_tlb_lock, flags);
+	/*
+	 * io_tlb_nslabs在测试机是32768
+	 *
+	 * io_tlb_index除了初始化 只在swiotlb_tbl_map_single()中修改过
+	 *
+	 * used by:
+	 *   - lib/swiotlb.c|291| <<swiotlb_init_with_tbl>> io_tlb_index = 0;
+	 *   - lib/swiotlb.c|458| <<swiotlb_late_init_with_tbl>> io_tlb_index = 0;
+	 *   - lib/swiotlb.c|739| <<swiotlb_tbl_map_single>> index = ALIGN(io_tlb_index, stride);
+	 *   - lib/swiotlb.c|802| <<swiotlb_tbl_map_single>> io_tlb_index = ((index + nslots) < io_tlb_nslabs
+	 */
 	index = ALIGN(io_tlb_index, stride);
 	if (index >= io_tlb_nslabs)
 		index = 0;
 	wrap = index;
 
+	/*
+	 * offset_slots是做什么用的??
+	 */
+
 	do {
+		/*
+		 * 下面的while循环应该是在不停调整index
+		 *
+		 * iommu_is_span_boundary()会做一些检查:
+		 * 1. max_slots必须是2的N次方
+		 * 2. offset_slots + nslots > max_slots??? 大于肯定不对!
+		 */
 		while (iommu_is_span_boundary(index, nslots, offset_slots,
 					      max_slots)) {
 			index += stride;
@@ -486,32 +785,81 @@ phys_addr_t swiotlb_tbl_map_single(struct device *hwdev,
 		}
 
 		/*
+		 * 上面的while循环把index更新到了一个可以接受的值
+		 */
+
+		/*
 		 * If we find a slot that indicates we have 'nslots' number of
 		 * contiguous buffers, we allocate the buffers from that slot
 		 * and mark the entries as '0' indicating unavailable.
 		 */
+		/*
+		 * 下面的if语句进去就goto found了
+		 * 所以进入if语句就一定能找到
+		 */
 		if (io_tlb_list[index] >= nslots) {
 			int count = 0;
 
 			for (i = index; i < (int) (index + nslots); i++)
 				io_tlb_list[i] = 0;
+			/*
+			 * (OFFSET(i, IO_TLB_SEGSIZE)是不能改变的
+			 *
+			 * OFFSET(0, IO_TLB_SEGSIZE) = 0
+			 * OFFSET(1, IO_TLB_SEGSIZE) = 1
+			 * OFFSET(2, IO_TLB_SEGSIZE) = 2
+			 * OFFSET(3, IO_TLB_SEGSIZE) = 3
+			 * OFFSET(4, IO_TLB_SEGSIZE) = 4
+			 * OFFSET(5, IO_TLB_SEGSIZE) = 5
+			 * OFFSET(6, IO_TLB_SEGSIZE) = 6
+			 * OFFSET(7, IO_TLB_SEGSIZE) = 7
+			 * ... ...
+			 * OFFSET(124, IO_TLB_SEGSIZE)=124
+			 * OFFSET(125, IO_TLB_SEGSIZE)=125
+			 * OFFSET(126, IO_TLB_SEGSIZE)=126
+			 * OFFSET(127, IO_TLB_SEGSIZE)=127
+			 * OFFSET(128, IO_TLB_SEGSIZE)=0
+			 */
 			for (i = index - 1; (OFFSET(i, IO_TLB_SEGSIZE) != IO_TLB_SEGSIZE - 1) && io_tlb_list[i]; i--)
 				io_tlb_list[i] = ++count;
+			/*
+			 * 在测试机上 (start和end之间是64MB):
+			 *   io_tlb_start: 0x4a2a00000
+			 *   io_tlb_end  : 0x4a6a00000
+			 */
 			tlb_addr = io_tlb_start + (index << IO_TLB_SHIFT);
 
 			/*
 			 * Update the indices to avoid searching in the next
 			 * round.
 			 */
+			/*
+			 * io_tlb_index除了初始化 只在swiotlb_tbl_map_single()中修改过!!!!!!!
+			 *
+			 * used by:
+			 *   - lib/swiotlb.c|291| <<swiotlb_init_with_tbl>> io_tlb_index = 0;
+			 *   - lib/swiotlb.c|458| <<swiotlb_late_init_with_tbl>> io_tlb_index = 0;
+			 *   - lib/swiotlb.c|739| <<swiotlb_tbl_map_single>> index = ALIGN(io_tlb_index, stride);
+			 *   - lib/swiotlb.c|802| <<swiotlb_tbl_map_single>> io_tlb_index = ((index + nslots) < io_tlb_nslabs
+			 *
+			 * io_tlb_nslabs在测试机是32768
+			 */
 			io_tlb_index = ((index + nslots) < io_tlb_nslabs
 					? (index + nslots) : 0);
 
 			goto found;
 		}
+		/*
+		 * 增加index 查看下一个是否符合条件
+		 *
+		 * 上面计算stride的时候:
+		 * 当申请的内存大于PAGE_SIZE时, stride是1<<1=2
+		 * 否则, stride是1
+		 */
 		index += stride;
 		if (index >= io_tlb_nslabs)
 			index = 0;
-	} while (index != wrap);
+	} while (index != wrap); // wrap是最初的index, 如果转了一圈还没找到合适的就退出
 
 not_found:
 	spin_unlock_irqrestore(&io_tlb_lock, flags);
@@ -526,8 +874,14 @@ phys_addr_t swiotlb_tbl_map_single(struct device *hwdev,
 	 * This is needed when we sync the memory.  Then we sync the buffer if
 	 * needed.
 	 */
+	/* 每个slot是2k??? */
 	for (i = 0; i < nslots; i++)
 		io_tlb_orig_addr[index+i] = orig_addr + (i << IO_TLB_SHIFT);
+	/* Bounce: copy the swiotlb buffer from the original dma location */
+	/*
+	 * 如果是DMA_TO_DEVICE就要从原始内存拷贝到bounce buffer
+	 * 如果是其他 (比如DMA_FROM_DEVICE) 就要从bounce buffer拷贝到原始内存
+	 */
 	if (dir == DMA_TO_DEVICE || dir == DMA_BIDIRECTIONAL)
 		swiotlb_bounce(orig_addr, tlb_addr, size, DMA_TO_DEVICE);
 
@@ -539,6 +893,12 @@ EXPORT_SYMBOL_GPL(swiotlb_tbl_map_single);
  * Allocates bounce buffer and returns its kernel virtual address.
  */
 
+/*
+ * called by:
+ *   - lib/swiotlb.c|700| <<swiotlb_alloc_coherent>> phys_addr_t paddr = map_single(hwdev, 0, size, DMA_FROM_DEVICE);
+ *   - lib/swiotlb.c|804| <<swiotlb_map_page>> map = map_single(dev, phys, size, dir);
+ *   - lib/swiotlb.c|939| <<swiotlb_map_sg_attrs>> phys_addr_t map = map_single(hwdev, sg_phys(sg),
+ */
 static phys_addr_t
 map_single(struct device *hwdev, phys_addr_t phys, size_t size,
 	   enum dma_data_direction dir)
@@ -551,6 +911,13 @@ map_single(struct device *hwdev, phys_addr_t phys, size_t size,
 		return SWIOTLB_MAP_ERROR;
 	}
 
+	/*
+	 * phys_to_dma()直接返回io_tlb_start
+	 *
+	 * 在测试机上 (start和end之间是64MB):
+	 *    io_tlb_start: 0x4a2a00000
+	 *    io_tlb_end  : 0x4a6a00000
+	 */
 	start_dma_addr = phys_to_dma(hwdev, io_tlb_start);
 	return swiotlb_tbl_map_single(hwdev, start_dma_addr, phys, size, dir);
 }
@@ -558,17 +925,44 @@ map_single(struct device *hwdev, phys_addr_t phys, size_t size,
 /*
  * dma_addr is the kernel virtual address of the bounce buffer to unmap.
  */
+/*
+ * called by:
+ *   - drivers/xen/swiotlb-xen.c|659| <<xen_swiotlb_map_page>> swiotlb_tbl_unmap_single(dev, map, size, dir);
+ *   - drivers/xen/swiotlb-xen.c|693| <<xen_unmap_single>> swiotlb_tbl_unmap_single(hwdev, paddr, size, dir);
+ *   - lib/swiotlb.c|944| <<swiotlb_alloc_coherent>> swiotlb_tbl_unmap_single(hwdev, paddr,
+ *   - lib/swiotlb.c|975| <<swiotlb_free_coherent>> swiotlb_tbl_unmap_single(hwdev, paddr, size, DMA_TO_DEVICE);
+ *   - lib/swiotlb.c|1044| <<swiotlb_map_page>> swiotlb_tbl_unmap_single(dev, map, size, dir);
+ *   - lib/swiotlb.c|1068| <<unmap_single>> swiotlb_tbl_unmap_single(hwdev, paddr, size, dir);
+ *
+ * tlb_addr是要unmap的物理地址
+ */
 void swiotlb_tbl_unmap_single(struct device *hwdev, phys_addr_t tlb_addr,
 			      size_t size, enum dma_data_direction dir)
 {
 	unsigned long flags;
+	/*
+	 * 根据size来计算有多少个slot要释放
+	 *
+	 * 因为分配的时候没有超出128个slot的范围, 释放的前提也不会超出
+	 */
 	int i, count, nslots = ALIGN(size, 1 << IO_TLB_SHIFT) >> IO_TLB_SHIFT;
+	/*
+	 * tlb_addr是要unmap的物理地址
+	 *
+	 * tlb_addr在测试机上 (start和end之间是64MB):
+	 * io_tlb_start: 0x4a2a00000
+	 * io_tlb_end  : 0x4a6a00000
+	 *
+	 * 根据物理地址距离base的diff可以的到index
+	 */
 	int index = (tlb_addr - io_tlb_start) >> IO_TLB_SHIFT;
 	phys_addr_t orig_addr = io_tlb_orig_addr[index];
 
 	/*
 	 * First, sync the memory before unmapping the entry
 	 */
+	/* Bounce: copy the swiotlb buffer back to the original dma location */
+	/* 从tlb拷贝到orig的地址 */
 	if (orig_addr != INVALID_PHYS_ADDR &&
 	    ((dir == DMA_FROM_DEVICE) || (dir == DMA_BIDIRECTIONAL)))
 		swiotlb_bounce(orig_addr, tlb_addr, size, DMA_FROM_DEVICE);
@@ -581,12 +975,31 @@ void swiotlb_tbl_unmap_single(struct device *hwdev, phys_addr_t tlb_addr,
 	 */
 	spin_lock_irqsave(&io_tlb_lock, flags);
 	{
+		/*
+		 * count的结果有两种可能:
+		 * 1. io_tlb_list[index + nslots]
+		 * 2. 0
+		 *
+		 * (index + nslots) < ALIGN(index + 1, IO_TLB_SEGSIZE)有三种可能
+		 *
+		 * 1. (index + nslots) < ALIGN(index + 1, IO_TLB_SEGSIZE)
+		 * 这种情况是当前segment (128个slot一组)没到头, 回收的开始和中间部分
+		 *
+		 * 2. (index + nslots) == ALIGN(index + 1, IO_TLB_SEGSIZE)
+		 * 这种情况是当前segment到头了, 从最后一个(127)开始回收, 所以是用的count=0
+		 *
+		 * 3. (index + nslots) > ALIGN(index + 1, IO_TLB_SEGSIZE)
+		 * 这个不可能, 一定是bug!!!!
+		 */
 		count = ((index + nslots) < ALIGN(index + 1, IO_TLB_SEGSIZE) ?
 			 io_tlb_list[index + nslots] : 0);
 		/*
 		 * Step 1: return the slots to the free list, merging the
 		 * slots with superceeding slots
 		 */
+		/*
+		 * 这里是从forward往当前的点后退, 一个一个回收
+		 */
 		for (i = index + nslots - 1; i >= index; i--) {
 			io_tlb_list[i] = ++count;
 			io_tlb_orig_addr[i] = INVALID_PHYS_ADDR;
@@ -595,6 +1008,25 @@ void swiotlb_tbl_unmap_single(struct device *hwdev, phys_addr_t tlb_addr,
 		 * Step 2: merge the returned slots with the preceding slots,
 		 * if available (non zero)
 		 */
+		/*
+		 * OFFSET(0, IO_TLB_SEGSIZE) = 0
+		 * OFFSET(1, IO_TLB_SEGSIZE) = 1
+		 * OFFSET(2, IO_TLB_SEGSIZE) = 2
+		 * OFFSET(3, IO_TLB_SEGSIZE) = 3
+		 * OFFSET(4, IO_TLB_SEGSIZE) = 4
+		 * OFFSET(5, IO_TLB_SEGSIZE) = 5
+		 * OFFSET(6, IO_TLB_SEGSIZE) = 6
+		 * OFFSET(7, IO_TLB_SEGSIZE) = 7
+		 * ... ...
+		 * OFFSET(124, IO_TLB_SEGSIZE)=124
+		 * OFFSET(125, IO_TLB_SEGSIZE)=125
+		 * OFFSET(126, IO_TLB_SEGSIZE)=126
+		 * OFFSET(127, IO_TLB_SEGSIZE)=127
+		 * OFFSET(128, IO_TLB_SEGSIZE)=0
+		 *
+		 * 这里是从当前位置backward, 回收前面的部分
+		 * (OFFSET(i, IO_TLB_SEGSIZE) != IO_TLB_SEGSIZE -1)可以保证不会回收到上一个segment (128 slot一个segment)
+		 */
 		for (i = index - 1; (OFFSET(i, IO_TLB_SEGSIZE) != IO_TLB_SEGSIZE -1) && io_tlb_list[i]; i--)
 			io_tlb_list[i] = ++count;
 	}
@@ -602,6 +1034,15 @@ void swiotlb_tbl_unmap_single(struct device *hwdev, phys_addr_t tlb_addr,
 }
 EXPORT_SYMBOL_GPL(swiotlb_tbl_unmap_single);
 
+/*
+ * called by:
+ *   - drivers/xen/swiotlb-xen.c|781| <<xen_swiotlb_sync_single>> swiotlb_tbl_sync_single(hwdev, paddr, size, dir, target);
+ *   - lib/swiotlb.c|1133| <<swiotlb_sync_single>> swiotlb_tbl_sync_single(hwdev, paddr, size, dir, target);
+ *
+ * tlb_addr是物理地址
+ *
+ * 会调用到swiotlb_bounce()
+ */
 void swiotlb_tbl_sync_single(struct device *hwdev, phys_addr_t tlb_addr,
 			     size_t size, enum dma_data_direction dir,
 			     enum dma_sync_target target)
@@ -615,6 +1056,10 @@ void swiotlb_tbl_sync_single(struct device *hwdev, phys_addr_t tlb_addr,
 
 	switch (target) {
 	case SYNC_FOR_CPU:
+		/*
+		 * 如果是DMA_TO_DEVICE就要从原始内存拷贝到bounce buffer
+		 * 如果是其他 (比如DMA_FROM_DEVICE) 就要从bounce buffer拷贝到原始内存
+		 */
 		if (likely(dir == DMA_FROM_DEVICE || dir == DMA_BIDIRECTIONAL))
 			swiotlb_bounce(orig_addr, tlb_addr,
 				       size, DMA_FROM_DEVICE);
@@ -622,6 +1067,10 @@ void swiotlb_tbl_sync_single(struct device *hwdev, phys_addr_t tlb_addr,
 			BUG_ON(dir != DMA_TO_DEVICE);
 		break;
 	case SYNC_FOR_DEVICE:
+		/*
+		 * 如果是DMA_TO_DEVICE就要从原始内存拷贝到bounce buffer
+		 * 如果是其他 (比如DMA_FROM_DEVICE) 就要从bounce buffer拷贝到原始内存
+		 */
 		if (likely(dir == DMA_TO_DEVICE || dir == DMA_BIDIRECTIONAL))
 			swiotlb_bounce(orig_addr, tlb_addr,
 				       size, DMA_TO_DEVICE);
@@ -634,6 +1083,11 @@ void swiotlb_tbl_sync_single(struct device *hwdev, phys_addr_t tlb_addr,
 }
 EXPORT_SYMBOL_GPL(swiotlb_tbl_sync_single);
 
+/*
+ * called by:
+ *   - arch/x86/kernel/pci-swiotlb.c|46| <<x86_swiotlb_alloc_coherent>> return swiotlb_alloc_coherent(hwdev, size, dma_handle, flags);
+ *   - lib/swiotlb.c|672| <<swiotlb_alloc_coherent>> swiotlb_alloc_coherent(struct device *hwdev, size_t size,
+ */
 void *
 swiotlb_alloc_coherent(struct device *hwdev, size_t size,
 		       dma_addr_t *dma_handle, gfp_t flags)
@@ -697,6 +1151,10 @@ swiotlb_alloc_coherent(struct device *hwdev, size_t size,
 }
 EXPORT_SYMBOL(swiotlb_alloc_coherent);
 
+/*
+ * called by:
+ *   - arch/x86/kernel/pci-swiotlb.c|58| <<x86_swiotlb_free_coherent>> swiotlb_free_coherent(dev, size, vaddr, dma_addr);
+ */
 void
 swiotlb_free_coherent(struct device *hwdev, size_t size, void *vaddr,
 		      dma_addr_t dev_addr)
@@ -712,6 +1170,11 @@ swiotlb_free_coherent(struct device *hwdev, size_t size, void *vaddr,
 }
 EXPORT_SYMBOL(swiotlb_free_coherent);
 
+/*
+ * called by:
+ *   - lib/swiotlb.c|1074| <<swiotlb_map_page>> swiotlb_full(dev, size, dir, 1); -- 不是xen的swiotlb
+ *   - lib/swiotlb.c|1212| <<swiotlb_map_sg_attrs>> swiotlb_full(hwdev, sg->length, dir, 0); -- caller不是没有caller, 就是不是xen的swiotlb
+ */
 static void
 swiotlb_full(struct device *dev, size_t size, enum dma_data_direction dir,
 	     int do_panic)
@@ -1007,6 +1470,11 @@ EXPORT_SYMBOL(swiotlb_dma_mapping_error);
  * during bus mastering, then you would pass 0x00ffffff as the mask to
  * this function.
  */
+/*
+ * 对于x86, 判断io_tlb_end是不是小于设备的mask
+ *
+ * 但在x86上没看到调用者
+ */
 int
 swiotlb_dma_supported(struct device *hwdev, u64 mask)
 {
-- 
2.7.4

