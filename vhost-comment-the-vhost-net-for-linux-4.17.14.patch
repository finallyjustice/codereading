From 922d212072c811e76aee12247a1f324e657dd055 Mon Sep 17 00:00:00 2001
From: Dongli Zhang <dongli.zhang0129@gmail.com>
Date: Fri, 14 Aug 2020 14:34:27 -0700
Subject: [PATCH 1/1] vhost: comment the vhost-net for linux-4.17.14

Signed-off-by: Dongli Zhang <dongli.zhang0129@gmail.com>
---
 block/blk-mq-virtio.c                  |   5 +
 drivers/net/macvlan.c                  |  25 +
 drivers/net/macvtap.c                  |  58 ++
 drivers/net/tap.c                      |  85 +++
 drivers/net/tun.c                      |   4 +
 drivers/scsi/virtio_scsi.c             | 320 +++++++++++
 drivers/target/target_core_configfs.c  |  14 +
 drivers/target/target_core_file.c      |  28 +
 drivers/target/target_core_hba.c       |   8 +
 drivers/target/target_core_transport.c |  56 ++
 drivers/vhost/net.c                    | 244 ++++++++-
 drivers/vhost/scsi.c                   | 715 +++++++++++++++++++++++++
 drivers/vhost/vhost.c                  | 650 +++++++++++++++++++++-
 drivers/vhost/vhost.h                  |  61 ++-
 drivers/vhost/vringh.c                 | 235 ++++++++
 include/linux/ptr_ring.h               |  18 +
 include/uapi/linux/vhost.h             |   3 +
 include/uapi/linux/virtio_config.h     |   1 +
 net/core/dev.c                         |  46 ++
 19 files changed, 2546 insertions(+), 30 deletions(-)

diff --git a/block/blk-mq-virtio.c b/block/blk-mq-virtio.c
index c3afbca1..0d1f75d6 100644
--- a/block/blk-mq-virtio.c
+++ b/block/blk-mq-virtio.c
@@ -29,6 +29,11 @@
  * that maps a queue to the CPUs that have irq affinity for the corresponding
  * vector.
  */
+/*
+ * called by:
+ *   - drivers/block/virtio_blk.c|602| <<virtblk_map_queues>> return blk_mq_virtio_map_queues(set, vblk->vdev, 0);
+ *   - drivers/scsi/virtio_scsi.c|919| <<virtscsi_map_queues>> return blk_mq_virtio_map_queues(&shost->tag_set, vscsi->vdev, 2);
+ */
 int blk_mq_virtio_map_queues(struct blk_mq_tag_set *set,
 		struct virtio_device *vdev, int first_vec)
 {
diff --git a/drivers/net/macvlan.c b/drivers/net/macvlan.c
index 725f4b4a..9a931149 100644
--- a/drivers/net/macvlan.c
+++ b/drivers/net/macvlan.c
@@ -1148,6 +1148,10 @@ static void macvlan_setup(struct net_device *dev)
 	dev->priv_flags |= IFF_NO_QUEUE;
 }
 
+/*
+ * called by:
+ *   - drivers/net/macvlan.c|1387| <<macvlan_common_newlink>> err = macvlan_port_create(lowerdev);
+ */
 static int macvlan_port_create(struct net_device *dev)
 {
 	struct macvlan_port *port;
@@ -1342,6 +1346,27 @@ static int macvlan_changelink_sources(struct macvlan_dev *vlan, u32 mode,
 	return 0;
 }
 
+/*
+ * macvtap的例子:
+ *  => macvlan_common_newlink
+ *  => macvtap_newlink
+ *  => rtnl_newlink
+ *  => rtnetlink_rcv_msg
+ *  => netlink_rcv_skb
+ *  => rtnetlink_rcv
+ *  => netlink_unicast
+ *  => netlink_sendmsg
+ *  => sock_sendmsg
+ *  => ___sys_sendmsg
+ *  => __sys_sendmsg
+ *  => SyS_sendmsg
+ *  => do_syscall_64
+ *  => entry_SYSCALL_64_after_hwframe
+ *
+ * called by:
+ *   - drivers/net/macvlan.c|1464| <<macvlan_newlink>> return macvlan_common_newlink(src_net, dev, tb, data, extack);
+ *   - drivers/net/macvtap.c|145| <<macvtap_newlink>> err = macvlan_common_newlink(src_net, dev, tb, data, extack);
+ */
 int macvlan_common_newlink(struct net *src_net, struct net_device *dev,
 			   struct nlattr *tb[], struct nlattr *data[],
 			   struct netlink_ext_ack *extack)
diff --git a/drivers/net/macvtap.c b/drivers/net/macvtap.c
index 9a10029c..7295390c 100644
--- a/drivers/net/macvtap.c
+++ b/drivers/net/macvtap.c
@@ -34,6 +34,9 @@ struct macvtap_dev {
  */
 static dev_t macvtap_major;
 
+/*
+ * struct class macvtap_class.namespace = macvtap_net_namespace()
+ */
 static const void *macvtap_net_namespace(struct device *d)
 {
 	struct net_device *dev = to_net_dev(d->parent);
@@ -46,11 +49,21 @@ static struct class macvtap_class = {
 	.ns_type = &net_ns_type_operations,
 	.namespace = macvtap_net_namespace,
 };
+/*
+ * 在以下使用macvtap_cdev:
+ *   - drivers/net/macvtap.c|207| <<macvtap_init>> err = tap_create_cdev(&macvtap_cdev, &macvtap_major, "macvtap",
+ *   - drivers/net/macvtap.c|231| <<macvtap_init>> tap_destroy_cdev(macvtap_major, &macvtap_cdev);
+ *   - drivers/net/macvtap.c|242| <<macvtap_exit>> tap_destroy_cdev(macvtap_major, &macvtap_cdev);
+ */
 static struct cdev macvtap_cdev;
 
 #define TUN_OFFLOADS (NETIF_F_HW_CSUM | NETIF_F_TSO_ECN | NETIF_F_TSO | \
 		      NETIF_F_TSO6)
 
+/*
+ * 在以下使用macvtap_count_tx_dropped():
+ *   - drivers/net/macvtap.c|110| <<macvtap_newlink>> vlantap->tap.count_tx_dropped = macvtap_count_tx_dropped;
+ */
 static void macvtap_count_tx_dropped(struct tap_dev *tap)
 {
 	struct macvtap_dev *vlantap = container_of(tap, struct macvtap_dev, tap);
@@ -59,14 +72,30 @@ static void macvtap_count_tx_dropped(struct tap_dev *tap)
 	this_cpu_inc(vlan->pcpu_stats->tx_dropped);
 }
 
+/*
+ * 在以下使用macvtap_count_rx_dropped():
+ *   - drivers/net/macvtap.c|98| <<macvtap_newlink>> vlantap->tap.count_rx_dropped = macvtap_count_rx_dropped;
+ */
 static void macvtap_count_rx_dropped(struct tap_dev *tap)
 {
 	struct macvtap_dev *vlantap = container_of(tap, struct macvtap_dev, tap);
 	struct macvlan_dev *vlan = &vlantap->vlan;
 
+	/*
+	 * struct macvtap_dev:
+	 *   - struct macvlan_dev vlan;
+	 *      -> struct net_device       *lowerdev;
+	 *           -> void                    *fwd_priv;
+	 *           -> struct vlan_pcpu_stats __percpu *pcpu_stats;
+	 *   - struct tap_dev    tap;
+	 */
 	macvlan_count_rx(vlan, 0, 0, 0);
 }
 
+/*
+ * 在以下使用macvtap_update_features():
+ *   - drivers/net/macvtap.c|112| <<macvtap_newlink>> vlantap->tap.update_features = macvtap_update_features;
+ */
 static void macvtap_update_features(struct tap_dev *tap,
 				    netdev_features_t features)
 {
@@ -77,6 +106,10 @@ static void macvtap_update_features(struct tap_dev *tap,
 	netdev_update_features(vlan->dev);
 }
 
+/*
+ * called by:
+ *   - net/core/rtnetlink.c|3037| <<rtnl_newlink>> err = ops->newlink(link_net ? : net, dev, tb, data,
+ */
 static int macvtap_newlink(struct net *src_net, struct net_device *dev,
 			   struct nlattr *tb[], struct nlattr *data[],
 			   struct netlink_ext_ack *extack)
@@ -98,6 +131,31 @@ static int macvtap_newlink(struct net *src_net, struct net_device *dev,
 	vlantap->tap.count_rx_dropped = macvtap_count_rx_dropped;
 	vlantap->tap.update_features  = macvtap_update_features;
 
+	/*
+	 * called by:
+	 *   - drivers/net/bonding/bond_main.c|1675| <<bond_enslave>> res = netdev_rx_handler_register(slave_dev, bond_handle_frame,
+	 *   - drivers/net/ethernet/qualcomm/rmnet/rmnet_config.c|95| <<rmnet_register_real_device>> rc = netdev_rx_handler_register(real_dev, rmnet_rx_handler, port);
+	 *   - drivers/net/hyperv/netvsc_drv.c|1840| <<netvsc_vf_join>> ret = netdev_rx_handler_register(vf_netdev,
+	 *   - drivers/net/ipvlan/ipvlan_main.c|128| <<ipvlan_port_create>> err = netdev_rx_handler_register(dev, ipvlan_handle_frame, port);
+	 *   - drivers/net/ipvlan/ipvtap.c|93| <<ipvtap_newlink>> err = netdev_rx_handler_register(dev, tap_handle_frame, &vlantap->tap);
+	 *   - drivers/net/macsec.c|3170| <<register_macsec_dev>> err = netdev_rx_handler_register(real_dev, macsec_handle_frame,
+	 *   - drivers/net/macvlan.c|1178| <<macvlan_port_create>> err = netdev_rx_handler_register(dev, macvlan_handle_frame, port);
+	 *   - drivers/net/macvtap.c|138| <<macvtap_newlink>> err = netdev_rx_handler_register(dev, tap_handle_frame, &vlantap->tap);
+	 *   - drivers/net/team/team.c|1240| <<team_port_add>> err = netdev_rx_handler_register(port_dev, team_handle_frame,
+	 *   - net/bridge/br_if.c|555| <<br_add_if>> err = netdev_rx_handler_register(dev, br_handle_frame, p);
+	 *   - net/hsr/hsr_slave.c|118| <<hsr_portdev_setup>> res = netdev_rx_handler_register(dev, hsr_handle_frame, port);
+	 *   - net/openvswitch/vport-netdev.c|116| <<ovs_netdev_link>> err = netdev_rx_handler_register(vport->dev, netdev_frame_hook,
+	 *
+	 * 注册tap_handle_frame为dev->rx_handler
+	 * 注册&vlantap->tap为dev->rx_handler_data
+	 *
+	 * struct macvtap_dev *vlantap:
+	 *  -> struct macvlan_dev vlan;
+	 *  -> struct tap_dev    tap;
+	 *
+	 * ip link add link enp0s3 name macvtap0 type macvtap
+	 * 此处dev是"macvtap0"
+	 */
 	err = netdev_rx_handler_register(dev, tap_handle_frame, &vlantap->tap);
 	if (err)
 		return err;
diff --git a/drivers/net/tap.c b/drivers/net/tap.c
index f0f7cd97..87fd55a8 100644
--- a/drivers/net/tap.c
+++ b/drivers/net/tap.c
@@ -100,6 +100,12 @@ static struct proto tap_proto = {
 
 #define TAP_NUM_DEVS (1U << MINORBITS)
 
+/*
+ * 在以下使用major_list:
+ *   - drivers/net/tap.c|401| <<tap_get_major>> list_for_each_entry_rcu(tap_major, &major_list, next) {
+ *   - drivers/net/tap.c|1275| <<tap_list_add>> list_add_tail_rcu(&tap_major->next, &major_list);
+ *   - drivers/net/tap.c|1320| <<tap_destroy_cdev>> list_for_each_entry_safe(tap_major, tmp, &major_list, next) {
+ */
 static LIST_HEAD(major_list);
 
 struct major_info {
@@ -140,6 +146,10 @@ static struct tap_dev *tap_dev_get_rcu(const struct net_device *dev)
  * when both our references and any pending SKBs are gone.
  */
 
+/*
+ * called by:
+ *   - drivers/net/tap.c|934| <<tap_ioctl_set_queue>> ret = tap_enable_queue(tap, file, q);
+ */
 static int tap_enable_queue(struct tap_dev *tap, struct file *file,
 			    struct tap_queue *q)
 {
@@ -314,6 +324,54 @@ void tap_del_queues(struct tap_dev *tap)
 }
 EXPORT_SYMBOL_GPL(tap_del_queues);
 
+/*
+ * 部分例子:
+ *  => tap_handle_frame
+ *  => __netif_receive_skb_core
+ *  => __netif_receive_skb
+ *  => netif_receive_skb_internal
+ *  => napi_gro_receive
+ *  => receive_buf
+ *  => virtnet_poll
+ *  => net_rx_action
+ *  => __do_softirq
+ *  => irq_exit
+ *  => do_IRQ
+ *  => ret_from_intr
+ *  => native_safe_halt
+ *  => default_idle
+ *  => arch_cpu_idle
+ *  => default_idle_call
+ *  => do_idle
+ *  => cpu_startup_entry
+ *  => start_secondary
+ *  => secondary_startup_64
+ *
+ * => macvlan_handle_frame
+ * => __netif_receive_skb_core
+ * => __netif_receive_skb
+ * => netif_receive_skb_internal
+ * => napi_gro_receive
+ * => receive_buf
+ * => virtnet_poll
+ * => net_rx_action
+ * => __do_softirq
+ * => irq_exit
+ * => do_IRQ
+ * => ret_from_intr
+ * => native_safe_halt
+ * => default_idle
+ * => arch_cpu_idle
+ * => default_idle_call
+ * => do_idle
+ * => cpu_startup_entry
+ * => start_secondary
+ * => secondary_startup_64
+ *
+ * 在以下使用tap_handle_frame():
+ *   - drivers/net/ipvlan/ipvtap.c|93| <<ipvtap_newlink>> err = netdev_rx_handler_register(dev, tap_handle_frame, &vlantap->tap);
+ *   - drivers/net/macvtap.c|114| <<macvtap_newlink>> err = netdev_rx_handler_register(dev, tap_handle_frame, &vlantap->tap);
+ */
 rx_handler_result_t tap_handle_frame(struct sk_buff **pskb)
 {
 	struct sk_buff *skb = *pskb;
@@ -592,6 +650,10 @@ static __poll_t tap_poll(struct file *file, poll_table *wait)
 	return mask;
 }
 
+/*
+ * called by:
+ *   - drivers/net/tap.c|696| <<tap_get_user>> skb = tap_alloc_skb(&q->sk, TAP_RESERVE, copylen,
+ */
 static inline struct sk_buff *tap_alloc_skb(struct sock *sk, size_t prepad,
 					    size_t len, size_t linear,
 						int noblock, int *err)
@@ -619,6 +681,11 @@ static inline struct sk_buff *tap_alloc_skb(struct sock *sk, size_t prepad,
 #define TAP_RESERVE HH_DATA_OFF(ETH_HLEN)
 
 /* Get packet from user space buffer */
+/*
+ * called by:
+ *   - drivers/net/tap.c|772| <<tap_write_iter>> return tap_get_user(q, NULL, from, file->f_flags & O_NONBLOCK);
+ *   - drivers/net/tap.c|1162| <<tap_sendmsg>> return tap_get_user(q, m, &m->msg_iter, m->msg_flags & MSG_DONTWAIT);
+ */
 static ssize_t tap_get_user(struct tap_queue *q, struct msghdr *m,
 			    struct iov_iter *from, int noblock)
 {
@@ -721,6 +788,10 @@ static ssize_t tap_get_user(struct tap_queue *q, struct msghdr *m,
 		skb_set_network_header(skb, depth);
 
 	rcu_read_lock();
+	/*
+	 * struct tap_queue *q:
+	 *   -> struct tap_dev __rcu *tap;
+	 */
 	tap = rcu_dereference(q->tap);
 	/* copy skb_ubuf_info for callback when skb has no error */
 	if (zerocopy) {
@@ -822,6 +893,11 @@ static ssize_t tap_put_user(struct tap_queue *q,
 	return ret ? ret : total;
 }
 
+/*
+ * called by:
+ *   - drivers/net/tap.c|952| <<tap_read_iter>> ret = tap_do_read(q, to, file->f_flags & O_NONBLOCK, NULL);
+ *   - drivers/net/tap.c|1238| <<tap_recvmsg>> ret = tap_do_read(q, &m->msg_iter, flags & MSG_DONTWAIT, skb);
+ */
 static ssize_t tap_do_read(struct tap_queue *q,
 			   struct iov_iter *to,
 			   int noblock, struct sk_buff *skb)
@@ -1239,6 +1315,10 @@ int tap_queue_resize(struct tap_dev *tap)
 }
 EXPORT_SYMBOL_GPL(tap_queue_resize);
 
+/*
+ * called by:
+ *   - drivers/net/tap.c|1299| <<tap_create_cdev>> err = tap_list_add(*tap_major, device_name);
+ */
 static int tap_list_add(dev_t major, const char *device_name)
 {
 	struct major_info *tap_major;
@@ -1258,6 +1338,11 @@ static int tap_list_add(dev_t major, const char *device_name)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/net/ipvlan/ipvtap.c|200| <<ipvtap_init>> err = tap_create_cdev(&ipvtap_cdev, &ipvtap_major, "ipvtap",
+ *   - drivers/net/macvtap.c|207| <<macvtap_init>> err = tap_create_cdev(&macvtap_cdev, &macvtap_major, "macvtap",
+ */
 int tap_create_cdev(struct cdev *tap_cdev, dev_t *tap_major,
 		    const char *device_name, struct module *module)
 {
diff --git a/drivers/net/tun.c b/drivers/net/tun.c
index 409eb8b7..0f908567 100644
--- a/drivers/net/tun.c
+++ b/drivers/net/tun.c
@@ -2523,6 +2523,10 @@ static const struct attribute_group tun_attr_group = {
 	.attrs = tun_dev_attrs
 };
 
+/*
+ * called by:
+ *   - drivers/net/tun.c|2898| <<__tun_chr_ioctl>> ret = tun_set_iff(net, file, &ifr);
+ */
 static int tun_set_iff(struct net *net, struct file *file, struct ifreq *ifr)
 {
 	struct tun_struct *tun;
diff --git a/drivers/scsi/virtio_scsi.c b/drivers/scsi/virtio_scsi.c
index 45d04631..19ced756 100644
--- a/drivers/scsi/virtio_scsi.c
+++ b/drivers/scsi/virtio_scsi.c
@@ -35,9 +35,20 @@
 
 #define VIRTIO_SCSI_MEMPOOL_SZ 64
 #define VIRTIO_SCSI_EVENT_LEN 8
+/*
+ * 在以下使用VIRTIO_SCSI_VQ_BASE:
+ *   - drivers/scsi/virtio_scsi.c|312| <<virtscsi_req_done>> int index = vq->index - VIRTIO_SCSI_VQ_BASE;
+ *   - drivers/scsi/virtio_scsi.c|1030| <<virtscsi_init>> num_vqs = vscsi->num_queues + VIRTIO_SCSI_VQ_BASE;
+ *   - drivers/scsi/virtio_scsi.c|1044| <<virtscsi_init>> for (i = VIRTIO_SCSI_VQ_BASE; i < num_vqs; i++) {
+ *   - drivers/scsi/virtio_scsi.c|1056| <<virtscsi_init>> for (i = VIRTIO_SCSI_VQ_BASE; i < num_vqs; i++)
+ *   - drivers/scsi/virtio_scsi.c|1057| <<virtscsi_init>> virtscsi_init_vq(&vscsi->req_vqs[i - VIRTIO_SCSI_VQ_BASE],
+ */
 #define VIRTIO_SCSI_VQ_BASE 2
 
 /* Command queue element */
+/*
+ * struct scsi_host_template virtscsi_host_template.cmd_size = sizeof(struct virtio_scsi_cmd)
+ */
 struct virtio_scsi_cmd {
 	struct scsi_cmnd *sc;
 	struct completion *comp;
@@ -63,6 +74,20 @@ struct virtio_scsi_event_node {
 
 struct virtio_scsi_vq {
 	/* Protects vq */
+	/*
+	 * 在以下使用virtio_scsi_vq->vq_lock:
+	 *   - drivers/scsi/virtio_scsi.c|292| <<virtscsi_vq_done>> spin_lock_irqsave(&virtscsi_vq->vq_lock, flags);
+	 *   - drivers/scsi/virtio_scsi.c|301| <<virtscsi_vq_done>> spin_unlock_irqrestore(&virtscsi_vq->vq_lock, flags);
+	 *   - drivers/scsi/virtio_scsi.c|380| <<virtscsi_kick_event>> spin_lock_irqsave(&vscsi->event_vq.vq_lock, flags);
+	 *   - drivers/scsi/virtio_scsi.c|387| <<virtscsi_kick_event>> spin_unlock_irqrestore(&vscsi->event_vq.vq_lock, flags);
+	 *   - drivers/scsi/virtio_scsi.c|422| <<virtscsi_cancel_event_work>> spin_lock_irq(&vscsi->event_vq.vq_lock);
+	 *   - drivers/scsi/virtio_scsi.c|424| <<virtscsi_cancel_event_work>> spin_unlock_irq(&vscsi->event_vq.vq_lock);
+	 *   - drivers/scsi/virtio_scsi.c|621| <<virtscsi_kick_cmd>> spin_lock_irqsave(&vq->vq_lock, flags);
+	 *   - drivers/scsi/virtio_scsi.c|626| <<virtscsi_kick_cmd>> spin_unlock_irqrestore(&vq->vq_lock, flags);
+	 *   - drivers/scsi/virtio_scsi.c|742| <<virtscsi_queuecommand>> spin_lock_irqsave(&req_vq->vq_lock, flags);
+	 *   - drivers/scsi/virtio_scsi.c|744| <<virtscsi_queuecommand>> spin_unlock_irqrestore(&req_vq->vq_lock, flags);
+	 *   - drivers/scsi/virtio_scsi.c|997| <<virtscsi_init_vq>> spin_lock_init(&virtscsi_vq->vq_lock);
+	 */
 	spinlock_t vq_lock;
 
 	struct virtqueue *vq;
@@ -89,6 +114,10 @@ struct virtio_scsi_vq {
  * an atomic_t.
  */
 struct virtio_scsi_target_state {
+	/*
+	 * 在以下使用virtio_scsi_target_state->tgt_seq:
+	 *   - drivers/scsi/virtio_scsi.c|896| <<virtscsi_target_alloc>> seqcount_init(&tgt->tgt_seq);
+	 */
 	seqcount_t tgt_seq;
 
 	/* Currently active virtqueue for requests sent to this target. */
@@ -100,6 +129,14 @@ struct virtio_scsi {
 	struct virtio_device *vdev;
 
 	/* Get some buffers ready for event vq */
+	/*
+	 * #define VIRTIO_SCSI_EVENT_LEN 8
+	 *
+	 * 在以下使用virtio_scsi->event_list:
+	 *   - drivers/scsi/virtio_scsi.c|322| <<virtscsi_kick_event_all>> vscsi->event_list[i].vscsi = vscsi;
+	 *   - drivers/scsi/virtio_scsi.c|323| <<virtscsi_kick_event_all>> virtscsi_kick_event(vscsi, &vscsi->event_list[i]);
+	 *   - drivers/scsi/virtio_scsi.c|339| <<virtscsi_cancel_event_work>> cancel_work_sync(&vscsi->event_list[i].work);
+	 */
 	struct virtio_scsi_event_node event_list[VIRTIO_SCSI_EVENT_LEN];
 
 	u32 num_queues;
@@ -110,21 +147,80 @@ struct virtio_scsi {
 	struct hlist_node node;
 
 	/* Protected by event_vq lock */
+	/*
+	 * 在以下使用virtio_scsi->stop_events:
+	 *   - drivers/scsi/virtio_scsi.c|335| <<virtscsi_cancel_event_work>> vscsi->stop_events = true;
+	 *   - drivers/scsi/virtio_scsi.c|435| <<virtscsi_complete_event>> if (!vscsi->stop_events)
+	 */
 	bool stop_events;
 
+	/*
+	 * 使用virtio_scsi->ctrl_vq的地方:
+	 *   - drivers/scsi/virtio_scsi.c|285| <<virtscsi_ctrl_done>> virtscsi_vq_done(vscsi, &vscsi->ctrl_vq, virtscsi_complete_free);
+	 *   - drivers/scsi/virtio_scsi.c|661| <<virtscsi_tmf>> if (virtscsi_kick_cmd(&vscsi->ctrl_vq, cmd,
+	 *   - drivers/scsi/virtio_scsi.c|953| <<virtscsi_init>> virtscsi_init_vq(&vscsi->ctrl_vq, vqs[0]);
+	 */
 	struct virtio_scsi_vq ctrl_vq;
+	/*
+	 * 使用virtio_scsi->event_vq的地方:
+	 *   - drivers/scsi/virtio_scsi.c|305| <<virtscsi_kick_event>> spin_lock_irqsave(&vscsi->event_vq.vq_lock, flags);
+	 *   - drivers/scsi/virtio_scsi.c|307| <<virtscsi_kick_event>> err = virtqueue_add_inbuf(vscsi->event_vq.vq, &sg, 1, event_node,
+	 *   - drivers/scsi/virtio_scsi.c|310| <<virtscsi_kick_event>> virtqueue_kick(vscsi->event_vq.vq);
+	 *   - drivers/scsi/virtio_scsi.c|312| <<virtscsi_kick_event>> spin_unlock_irqrestore(&vscsi->event_vq.vq_lock, flags);
+	 *   - drivers/scsi/virtio_scsi.c|334| <<virtscsi_cancel_event_work>> spin_lock_irq(&vscsi->event_vq.vq_lock);
+	 *   - drivers/scsi/virtio_scsi.c|336| <<virtscsi_cancel_event_work>> spin_unlock_irq(&vscsi->event_vq.vq_lock);
+	 *   - drivers/scsi/virtio_scsi.c|448| <<virtscsi_event_done>> virtscsi_vq_done(vscsi, &vscsi->event_vq, virtscsi_complete_event);
+	 *   - drivers/scsi/virtio_scsi.c|954| <<virtscsi_init>> virtscsi_init_vq(&vscsi->event_vq, vqs[1]);
+	 */
 	struct virtio_scsi_vq event_vq;
+	/*
+	 * 在以下使用virtio_scsi->req_vqs[]:
+	 *   - drivers/scsi/virtio_scsi.c|339| <<virtscsi_req_done>> struct virtio_scsi_vq *req_vq = &vscsi->req_vqs[index];
+	 *   - drivers/scsi/virtio_scsi.c|354| <<virtscsi_poll_requests>> virtscsi_vq_done(vscsi, &vscsi->req_vqs[i],
+	 *   - drivers/scsi/virtio_scsi.c|720| <<virtscsi_pick_vq_mq>> return &vscsi->req_vqs[hwq];
+	 *   - drivers/scsi/virtio_scsi.c|925| <<virtscsi_target_alloc>> tgt->req_vq = &vscsi->req_vqs[0];
+	 *   - drivers/scsi/virtio_scsi.c|1088| <<virtscsi_init>> virtscsi_init_vq(&vscsi->req_vqs[i - VIRTIO_SCSI_VQ_BASE],
+	 *   - drivers/scsi/virtio_scsi.c|1129| <<virtscsi_probe>> sizeof(*vscsi) + sizeof(vscsi->req_vqs[0]) * num_queues);
+	 *   - drivers/scsi/virtio_scsi.c|1144| <<virtscsi_probe>> shost->can_queue = virtqueue_get_vring_size(vscsi->req_vqs[0].vq);
+	 */
 	struct virtio_scsi_vq req_vqs[];
 };
 
 static struct kmem_cache *virtscsi_cmd_cache;
+/*
+ * 在以下使用virtscsi_cmd_pool:
+ *   - drivers/scsi/virtio_scsi.c|633| <<virtscsi_tmf>> mempool_free(cmd, virtscsi_cmd_pool);
+ *   - drivers/scsi/virtio_scsi.c|643| <<virtscsi_device_reset>> cmd = mempool_alloc(virtscsi_cmd_pool, GFP_NOIO);
+ *   - drivers/scsi/virtio_scsi.c|702| <<virtscsi_abort>> cmd = mempool_alloc(virtscsi_cmd_pool, GFP_NOIO);
+ *   - drivers/scsi/virtio_scsi.c|1024| <<init>> virtscsi_cmd_pool =
+ *   - drivers/scsi/virtio_scsi.c|1027| <<init>> if (!virtscsi_cmd_pool) {
+ *   - drivers/scsi/virtio_scsi.c|1038| <<init>> if (virtscsi_cmd_pool) {
+ *   - drivers/scsi/virtio_scsi.c|1039| <<init>> mempool_destroy(virtscsi_cmd_pool);
+ *   - drivers/scsi/virtio_scsi.c|1040| <<init>> virtscsi_cmd_pool = NULL;
+ *   - drivers/scsi/virtio_scsi.c|1052| <<fini>> mempool_destroy(virtscsi_cmd_pool);
+ */
 static mempool_t *virtscsi_cmd_pool;
 
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|254| <<virtscsi_req_done>> struct Scsi_Host *sh = virtio_scsi_host(vq->vdev);
+ *   - drivers/scsi/virtio_scsi.c|282| <<virtscsi_ctrl_done>> struct Scsi_Host *sh = virtio_scsi_host(vq->vdev);
+ *   - drivers/scsi/virtio_scsi.c|346| <<virtscsi_handle_transport_reset>> struct Scsi_Host *shost = virtio_scsi_host(vscsi->vdev);
+ *   - drivers/scsi/virtio_scsi.c|373| <<virtscsi_handle_param_change>> struct Scsi_Host *shost = virtio_scsi_host(vscsi->vdev);
+ *   - drivers/scsi/virtio_scsi.c|409| <<virtscsi_handle_event>> scsi_scan_host(virtio_scsi_host(vscsi->vdev));
+ *   - drivers/scsi/virtio_scsi.c|445| <<virtscsi_event_done>> struct Scsi_Host *sh = virtio_scsi_host(vq->vdev);
+ *   - drivers/scsi/virtio_scsi.c|1064| <<virtscsi_remove>> struct Scsi_Host *shost = virtio_scsi_host(vdev);
+ *   - drivers/scsi/virtio_scsi.c|1090| <<virtscsi_restore>> struct Scsi_Host *sh = virtio_scsi_host(vdev);
+ */
 static inline struct Scsi_Host *virtio_scsi_host(struct virtio_device *vdev)
 {
 	return vdev->priv;
 }
 
+/*
+ * called by;
+ *   - drivers/scsi/virtio_scsi.c|179| <<virtscsi_complete_cmd>> virtscsi_compute_resid(sc, virtio32_to_cpu(vscsi->vdev, resp->resid));
+ */
 static void virtscsi_compute_resid(struct scsi_cmnd *sc, u32 resid)
 {
 	if (!resid)
@@ -144,6 +240,12 @@ static void virtscsi_compute_resid(struct scsi_cmnd *sc, u32 resid)
  *
  * Called with vq_lock held.
  */
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|250| <<virtscsi_req_done>> virtscsi_vq_done(vscsi, req_vq, virtscsi_complete_cmd);
+ *   - drivers/scsi/virtio_scsi.c|260| <<virtscsi_poll_requests>> virtscsi_complete_cmd);
+ *   - drivers/scsi/virtio_scsi.c|609| <<virtscsi_queuecommand>> virtscsi_complete_cmd(vscsi, cmd);
+ */
 static void virtscsi_complete_cmd(struct virtio_scsi *vscsi, void *buf)
 {
 	struct virtio_scsi_cmd *cmd = buf;
@@ -207,6 +309,13 @@ static void virtscsi_complete_cmd(struct virtio_scsi *vscsi, void *buf)
 	sc->scsi_done(sc);
 }
 
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|259| <<virtscsi_req_done>> virtscsi_vq_done(vscsi, req_vq, virtscsi_complete_cmd);
+ *   - drivers/scsi/virtio_scsi.c|268| <<virtscsi_poll_requests>> virtscsi_vq_done(vscsi, &vscsi->req_vqs[i],
+ *   - drivers/scsi/virtio_scsi.c|285| <<virtscsi_ctrl_done>> virtscsi_vq_done(vscsi, &vscsi->ctrl_vq, virtscsi_complete_free);
+ *   - drivers/scsi/virtio_scsi.c|448| <<virtscsi_event_done>> virtscsi_vq_done(vscsi, &vscsi->event_vq, virtscsi_complete_event);
+ */
 static void virtscsi_vq_done(struct virtio_scsi *vscsi,
 			     struct virtio_scsi_vq *virtscsi_vq,
 			     void (*fn)(struct virtio_scsi *vscsi, void *buf))
@@ -228,6 +337,10 @@ static void virtscsi_vq_done(struct virtio_scsi *vscsi,
 	spin_unlock_irqrestore(&virtscsi_vq->vq_lock, flags);
 }
 
+/*
+ * 在以下使用virtscsi_req_done():
+ *   - drivers/scsi/virtio_scsi.c|944| <<virtscsi_init>> callbacks[i] = virtscsi_req_done;
+ */
 static void virtscsi_req_done(struct virtqueue *vq)
 {
 	struct Scsi_Host *sh = virtio_scsi_host(vq->vdev);
@@ -238,6 +351,10 @@ static void virtscsi_req_done(struct virtqueue *vq)
 	virtscsi_vq_done(vscsi, req_vq, virtscsi_complete_cmd);
 };
 
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|680| <<virtscsi_tmf>> virtscsi_poll_requests(vscsi);
+ */
 static void virtscsi_poll_requests(struct virtio_scsi *vscsi)
 {
 	int i, num_vqs;
@@ -248,14 +365,25 @@ static void virtscsi_poll_requests(struct virtio_scsi *vscsi)
 				 virtscsi_complete_cmd);
 }
 
+/*
+ * 在以下使用virtscsi_complete_free():
+ *   - drivers/scsi/virtio_scsi.c|285| <<virtscsi_ctrl_done>> virtscsi_vq_done(vscsi, &vscsi->ctrl_vq, virtscsi_complete_free);
+ */
 static void virtscsi_complete_free(struct virtio_scsi *vscsi, void *buf)
 {
 	struct virtio_scsi_cmd *cmd = buf;
 
+	/*
+	 * 唤醒virtscsi_tmf()中的wait_for_completion()
+	 */
 	if (cmd->comp)
 		complete(cmd->comp);
 }
 
+/*
+ * 在以下使用virtscsi_ctrl_done():
+ *   - drivers/scsi/virtio_scsi.c|939| <<virtscsi_init>> callbacks[0] = virtscsi_ctrl_done;
+ */
 static void virtscsi_ctrl_done(struct virtqueue *vq)
 {
 	struct Scsi_Host *sh = virtio_scsi_host(vq->vdev);
@@ -266,6 +394,11 @@ static void virtscsi_ctrl_done(struct virtqueue *vq)
 
 static void virtscsi_handle_event(struct work_struct *work);
 
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|297| <<virtscsi_kick_event_all>> virtscsi_kick_event(vscsi, &vscsi->event_list[i]);
+ *   - drivers/scsi/virtio_scsi.c|394| <<virtscsi_handle_event>> virtscsi_kick_event(vscsi, event_node);
+ */
 static int virtscsi_kick_event(struct virtio_scsi *vscsi,
 			       struct virtio_scsi_event_node *event_node)
 {
@@ -273,6 +406,13 @@ static int virtscsi_kick_event(struct virtio_scsi *vscsi,
 	struct scatterlist sg;
 	unsigned long flags;
 
+	/*
+	 * struct virtio_scsi_event_node {
+	 *     struct virtio_scsi *vscsi;
+	 *     struct virtio_scsi_event event;
+	 *     struct work_struct work;
+	 * };
+	 */
 	INIT_WORK(&event_node->work, virtscsi_handle_event);
 	sg_init_one(&sg, &event_node->event, sizeof(struct virtio_scsi_event));
 
@@ -288,11 +428,22 @@ static int virtscsi_kick_event(struct virtio_scsi *vscsi,
 	return err;
 }
 
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|1047| <<virtscsi_probe>> virtscsi_kick_event_all(vscsi);
+ *   - drivers/scsi/virtio_scsi.c|1101| <<virtscsi_restore>> virtscsi_kick_event_all(vscsi);
+ *
+ * 在probe和restore只有virtio_has_feature(vdev, VIRTIO_SCSI_F_HOTPLUG)才调用
+ */
 static int virtscsi_kick_event_all(struct virtio_scsi *vscsi)
 {
 	int i;
 
 	for (i = 0; i < VIRTIO_SCSI_EVENT_LEN; i++) {
+		/*
+		 * struct virtio_scsi:
+		 *  -> struct virtio_scsi_event_node event_list[VIRTIO_SCSI_EVENT_LEN];
+		 */
 		vscsi->event_list[i].vscsi = vscsi;
 		virtscsi_kick_event(vscsi, &vscsi->event_list[i]);
 	}
@@ -300,6 +451,10 @@ static int virtscsi_kick_event_all(struct virtio_scsi *vscsi)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|1068| <<virtscsi_remove>> virtscsi_cancel_event_work(vscsi);
+ */
 static void virtscsi_cancel_event_work(struct virtio_scsi *vscsi)
 {
 	int i;
@@ -313,6 +468,10 @@ static void virtscsi_cancel_event_work(struct virtio_scsi *vscsi)
 		cancel_work_sync(&vscsi->event_list[i].work);
 }
 
+/*
+ * called by (处理VIRTIO_SCSI_T_TRANSPORT_RESET):
+ *   - drivers/scsi/virtio_scsi.c|416| <<virtscsi_handle_event>> virtscsi_handle_transport_reset(vscsi, event);
+ */
 static void virtscsi_handle_transport_reset(struct virtio_scsi *vscsi,
 					    struct virtio_scsi_event *event)
 {
@@ -340,6 +499,10 @@ static void virtscsi_handle_transport_reset(struct virtio_scsi *vscsi,
 	}
 }
 
+/*
+ * called by (处理VIRTIO_SCSI_T_PARAM_CHANGE):
+ *   - drivers/scsi/virtio_scsi.c|419| <<virtscsi_handle_event>> virtscsi_handle_param_change(vscsi, event);
+ */
 static void virtscsi_handle_param_change(struct virtio_scsi *vscsi,
 					 struct virtio_scsi_event *event)
 {
@@ -365,6 +528,10 @@ static void virtscsi_handle_param_change(struct virtio_scsi *vscsi,
 	scsi_device_put(sdev);
 }
 
+/*
+ * 在以下使用virtscsi_handle_event():
+ *   - drivers/scsi/virtio_scsi.c|276| <<virtscsi_kick_event>> INIT_WORK(&event_node->work, virtscsi_handle_event);
+ */
 static void virtscsi_handle_event(struct work_struct *work)
 {
 	struct virtio_scsi_event_node *event_node =
@@ -394,14 +561,29 @@ static void virtscsi_handle_event(struct work_struct *work)
 	virtscsi_kick_event(vscsi, event_node);
 }
 
+/*
+ * 在以下使用virtscsi_complete_event():
+ *   - drivers/scsi/virtio_scsi.c|431| <<virtscsi_event_done>> virtscsi_vq_done(vscsi, &vscsi->event_vq, virtscsi_complete_event);
+ */
 static void virtscsi_complete_event(struct virtio_scsi *vscsi, void *buf)
 {
 	struct virtio_scsi_event_node *event_node = buf;
 
+	/*
+	 * 在以下使用virtio_scsi->stop_events:
+	 *   - drivers/scsi/virtio_scsi.c|335| <<virtscsi_cancel_event_work>> vscsi->stop_events = true;
+	 *   - drivers/scsi/virtio_scsi.c|435| <<virtscsi_complete_event>> if (!vscsi->stop_events)
+	 *
+	 * work是virtscsi_handle_event()
+	 */
 	if (!vscsi->stop_events)
 		queue_work(system_freezable_wq, &event_node->work);
 }
 
+/*
+ * 在以下使用virtscsi_event_done():
+ *   - drivers/scsi/virtio_scsi.c|878| <<virtscsi_init>> callbacks[1] = virtscsi_event_done;
+ */
 static void virtscsi_event_done(struct virtqueue *vq)
 {
 	struct Scsi_Host *sh = virtio_scsi_host(vq->vdev);
@@ -417,6 +599,10 @@ static void virtscsi_event_done(struct virtqueue *vq)
  * @req_size	: size of the request buffer
  * @resp_size	: size of the response buffer
  */
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|474| <<virtscsi_kick_cmd>> err = virtscsi_add_cmd(vq->vq, cmd, req_size, resp_size);
+ */
 static int virtscsi_add_cmd(struct virtqueue *vq,
 			    struct virtio_scsi_cmd *cmd,
 			    size_t req_size, size_t resp_size)
@@ -462,6 +648,11 @@ static int virtscsi_add_cmd(struct virtqueue *vq,
 	return virtqueue_add_sgs(vq, sgs, out_num, in_num, cmd, GFP_ATOMIC);
 }
 
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|569| <<virtscsi_queuecommand>> ret = virtscsi_kick_cmd(req_vq, cmd, req_size, sizeof(cmd->resp.cmd));
+ *   - drivers/scsi/virtio_scsi.c|587| <<virtscsi_tmf>> if (virtscsi_kick_cmd(&vscsi->ctrl_vq, cmd,
+ */
 static int virtscsi_kick_cmd(struct virtio_scsi_vq *vq,
 			     struct virtio_scsi_cmd *cmd,
 			     size_t req_size, size_t resp_size)
@@ -482,6 +673,11 @@ static int virtscsi_kick_cmd(struct virtio_scsi_vq *vq,
 	return err;
 }
 
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|537| <<virtio_scsi_init_hdr_pi>> virtio_scsi_init_hdr(vdev, (struct virtio_scsi_cmd_req *)cmd_pi, sc);
+ *   - drivers/scsi/virtio_scsi.c|600| <<virtscsi_queuecommand>> virtio_scsi_init_hdr(vscsi->vdev, &cmd->req.cmd, sc);
+ */
 static void virtio_scsi_init_hdr(struct virtio_device *vdev,
 				 struct virtio_scsi_cmd_req *cmd,
 				 struct scsi_cmnd *sc)
@@ -490,6 +686,7 @@ static void virtio_scsi_init_hdr(struct virtio_device *vdev,
 	cmd->lun[1] = sc->device->id;
 	cmd->lun[2] = (sc->device->lun >> 8) | 0x40;
 	cmd->lun[3] = sc->device->lun & 0xff;
+	/* Command Identifier */
 	cmd->tag = cpu_to_virtio64(vdev, (unsigned long)sc);
 	cmd->task_attr = VIRTIO_SCSI_S_SIMPLE;
 	cmd->prio = 0;
@@ -497,6 +694,10 @@ static void virtio_scsi_init_hdr(struct virtio_device *vdev,
 }
 
 #ifdef CONFIG_BLK_DEV_INTEGRITY
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|588| <<virtscsi_queuecommand>> virtio_scsi_init_hdr_pi(vscsi->vdev, &cmd->req.cmd_pi, sc);
+ */
 static void virtio_scsi_init_hdr_pi(struct virtio_device *vdev,
 				    struct virtio_scsi_cmd_req_pi *cmd_pi,
 				    struct scsi_cmnd *sc)
@@ -522,6 +723,10 @@ static void virtio_scsi_init_hdr_pi(struct virtio_device *vdev,
 }
 #endif
 
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|568| <<virtscsi_queuecommand>> struct virtio_scsi_vq *req_vq = virtscsi_pick_vq_mq(vscsi, sc);
+ */
 static struct virtio_scsi_vq *virtscsi_pick_vq_mq(struct virtio_scsi *vscsi,
 						  struct scsi_cmnd *sc)
 {
@@ -531,9 +736,15 @@ static struct virtio_scsi_vq *virtscsi_pick_vq_mq(struct virtio_scsi *vscsi,
 	return &vscsi->req_vqs[hwq];
 }
 
+/*
+ * struct scsi_host_template virtscsi_host_template.queuecommand = virtscsi_queuecommand()
+ */
 static int virtscsi_queuecommand(struct Scsi_Host *shost,
 				 struct scsi_cmnd *sc)
 {
+	/*
+	 * 返回Scsi_Host->hostdata
+	 */
 	struct virtio_scsi *vscsi = shost_priv(shost);
 	struct virtio_scsi_vq *req_vq = virtscsi_pick_vq_mq(vscsi, sc);
 	struct virtio_scsi_cmd *cmd = scsi_cmd_priv(sc);
@@ -541,6 +752,9 @@ static int virtscsi_queuecommand(struct Scsi_Host *shost,
 	int req_size;
 	int ret;
 
+	/*
+	 * shost->sg_tablesize来自sg_elems = virtscsi_config_get(vdev, seg_max) ?: 1;
+	 */
 	BUG_ON(scsi_sg_count(sc) > shost->sg_tablesize);
 
 	/* TODO: check feature bit and fail if unsupported?  */
@@ -561,6 +775,12 @@ static int virtscsi_queuecommand(struct Scsi_Host *shost,
 	} else
 #endif
 	{
+		/*
+		 * struct virtio_scsi_cmd *cmd:
+		 *   ----> struct virtio_scsi_cmd_req cmd;
+		 *   ... ...
+		 *   ----> struct virtio_scsi_cmd_resp cmd;
+		 */
 		virtio_scsi_init_hdr(vscsi->vdev, &cmd->req.cmd, sc);
 		memcpy(cmd->req.cmd.cdb, sc->cmnd, sc->cmd_len);
 		req_size = sizeof(cmd->req.cmd);
@@ -578,6 +798,11 @@ static int virtscsi_queuecommand(struct Scsi_Host *shost,
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|670| <<virtscsi_device_reset>> return virtscsi_tmf(vscsi, cmd);
+ *   - drivers/scsi/virtio_scsi.c|729| <<virtscsi_abort>> return virtscsi_tmf(vscsi, cmd);
+ */
 static int virtscsi_tmf(struct virtio_scsi *vscsi, struct virtio_scsi_cmd *cmd)
 {
 	DECLARE_COMPLETION_ONSTACK(comp);
@@ -610,6 +835,9 @@ static int virtscsi_tmf(struct virtio_scsi *vscsi, struct virtio_scsi_cmd *cmd)
 	return ret;
 }
 
+/*
+ * struct scsi_host_template virtscsi_host_template.eh_device_reset_handler = virtscsi_device_reset()
+ */
 static int virtscsi_device_reset(struct scsi_cmnd *sc)
 {
 	struct virtio_scsi *vscsi = shost_priv(sc->device->host);
@@ -634,6 +862,9 @@ static int virtscsi_device_reset(struct scsi_cmnd *sc)
 	return virtscsi_tmf(vscsi, cmd);
 }
 
+/*
+ * struct scsi_host_template virtscsi_host_template.slave_alloc = virtscsi_device_alloc()
+ */
 static int virtscsi_device_alloc(struct scsi_device *sdevice)
 {
 	/*
@@ -661,6 +892,9 @@ static int virtscsi_device_alloc(struct scsi_device *sdevice)
  * @sdev:	Virtscsi target whose queue depth to change
  * @qdepth:	New queue depth
  */
+/*
+ * struct scsi_host_template virtscsi_host_template.change_queue_depth = virtscsi_change_queue_depth()
+ */
 static int virtscsi_change_queue_depth(struct scsi_device *sdev, int qdepth)
 {
 	struct Scsi_Host *shost = sdev->host;
@@ -669,6 +903,9 @@ static int virtscsi_change_queue_depth(struct scsi_device *sdev, int qdepth)
 	return scsi_change_queue_depth(sdev, min(max_depth, qdepth));
 }
 
+/*
+ * struct scsi_host_template virtscsi_host_template.eh_abort_handler = virtscsi_abort()
+ */
 static int virtscsi_abort(struct scsi_cmnd *sc)
 {
 	struct virtio_scsi *vscsi = shost_priv(sc->device->host);
@@ -679,6 +916,13 @@ static int virtscsi_abort(struct scsi_cmnd *sc)
 	if (!cmd)
 		return FAILED;
 
+	/*
+	 * struct scsi_cmnd *sc:
+	 *  -> struct scsi_device *device;
+	 *      -> unsigned int id, channel;
+	 *      -> u64 lun;
+	 */
+
 	memset(cmd, 0, sizeof(*cmd));
 	cmd->sc = sc;
 	cmd->req.tmf = (struct virtio_scsi_ctrl_tmf_req){
@@ -693,6 +937,9 @@ static int virtscsi_abort(struct scsi_cmnd *sc)
 	return virtscsi_tmf(vscsi, cmd);
 }
 
+/*
+ * struct scsi_host_template virtscsi_host_template.target_alloc = virtscsi_target_alloc()
+ */
 static int virtscsi_target_alloc(struct scsi_target *starget)
 {
 	struct Scsi_Host *sh = dev_to_shost(starget->dev.parent);
@@ -710,12 +957,18 @@ static int virtscsi_target_alloc(struct scsi_target *starget)
 	return 0;
 }
 
+/*
+ * struct scsi_host_template virtscsi_host_template.target_destroy = virtscsi_target_destroy()
+ */
 static void virtscsi_target_destroy(struct scsi_target *starget)
 {
 	struct virtio_scsi_target_state *tgt = starget->hostdata;
 	kfree(tgt);
 }
 
+/*
+ * struct scsi_host_template virtscsi_host_template.map_queues = virtscsi_map_queues()
+ */
 static int virtscsi_map_queues(struct Scsi_Host *shost)
 {
 	struct virtio_scsi *vscsi = shost_priv(shost);
@@ -728,11 +981,18 @@ static int virtscsi_map_queues(struct Scsi_Host *shost)
  * latencies might be higher than on bare metal.  Reset the timer
  * unconditionally to give the host a chance to perform EH.
  */
+/*
+ * struct scsi_host_template virtscsi_host_template.eh_timed_out = virtscsi_eh_timed_out()
+ */
 static enum blk_eh_timer_return virtscsi_eh_timed_out(struct scsi_cmnd *scmnd)
 {
 	return BLK_EH_RESET_TIMER;
 }
 
+/*
+ * 在以下使用virtscsi_host_template:
+ *   - drivers/scsi/virtio_scsi.c|884| <<virtscsi_probe>> shost = scsi_host_alloc(&virtscsi_host_template,
+ */
 static struct scsi_host_template virtscsi_host_template = {
 	.module = THIS_MODULE,
 	.name = "Virtio SCSI HBA",
@@ -755,6 +1015,15 @@ static struct scsi_host_template virtscsi_host_template = {
 	.force_blk_mq = 1,
 };
 
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|880| <<virtscsi_probe>> num_queues = virtscsi_config_get(vdev, num_queues) ? : 1;
+ *   - drivers/scsi/virtio_scsi.c|882| <<virtscsi_probe>> num_targets = virtscsi_config_get(vdev, max_target) + 1;
+ *   - drivers/scsi/virtio_scsi.c|889| <<virtscsi_probe>> sg_elems = virtscsi_config_get(vdev, seg_max) ?: 1;
+ *   - drivers/scsi/virtio_scsi.c|902| <<virtscsi_probe>> cmd_per_lun = virtscsi_config_get(vdev, cmd_per_lun) ?: 1;
+ *   - drivers/scsi/virtio_scsi.c|904| <<virtscsi_probe>> shost->max_sectors = virtscsi_config_get(vdev, max_sectors) ?: 0xFFFF;
+ *   - drivers/scsi/virtio_scsi.c|909| <<virtscsi_probe>> shost->max_lun = virtscsi_config_get(vdev, max_lun) + 1 + 0x4000;
+ */
 #define virtscsi_config_get(vdev, fld) \
 	({ \
 		typeof(((struct virtio_scsi_config *)0)->fld) __val; \
@@ -762,12 +1031,23 @@ static struct scsi_host_template virtscsi_host_template = {
 		__val; \
 	})
 
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|850| <<virtscsi_init>> virtscsi_config_set(vdev, cdb_size, VIRTIO_SCSI_CDB_SIZE);
+ *   - drivers/scsi/virtio_scsi.c|851| <<virtscsi_init>> virtscsi_config_set(vdev, sense_size, VIRTIO_SCSI_SENSE_SIZE);
+ */
 #define virtscsi_config_set(vdev, fld, val) \
 	do { \
 		typeof(((struct virtio_scsi_config *)0)->fld) __val = (val); \
 		virtio_cwrite(vdev, struct virtio_scsi_config, fld, &__val); \
 	} while(0)
 
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|844| <<virtscsi_init>> virtscsi_init_vq(&vscsi->ctrl_vq, vqs[0]);
+ *   - drivers/scsi/virtio_scsi.c|845| <<virtscsi_init>> virtscsi_init_vq(&vscsi->event_vq, vqs[1]);
+ *   - drivers/scsi/virtio_scsi.c|847| <<virtscsi_init>> virtscsi_init_vq(&vscsi->req_vqs[i - VIRTIO_SCSI_VQ_BASE],
+ */
 static void virtscsi_init_vq(struct virtio_scsi_vq *virtscsi_vq,
 			     struct virtqueue *vq)
 {
@@ -775,6 +1055,12 @@ static void virtscsi_init_vq(struct virtio_scsi_vq *virtscsi_vq,
 	virtscsi_vq->vq = vq;
 }
 
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|860| <<virtscsi_init>> virtscsi_remove_vqs(vdev);
+ *   - drivers/scsi/virtio_scsi.c|956| <<virtscsi_remove>> virtscsi_remove_vqs(vdev);
+ *   - drivers/scsi/virtio_scsi.c|963| <<virtscsi_freeze>> virtscsi_remove_vqs(vdev);
+ */
 static void virtscsi_remove_vqs(struct virtio_device *vdev)
 {
 	/* Stop all the virtqueues. */
@@ -782,6 +1068,11 @@ static void virtscsi_remove_vqs(struct virtio_device *vdev)
 	vdev->config->del_vqs(vdev);
 }
 
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|896| <<virtscsi_probe>> err = virtscsi_init(vdev, vscsi);
+ *   - drivers/scsi/virtio_scsi.c|973| <<virtscsi_restore>> err = virtscsi_init(vdev, vscsi);
+ */
 static int virtscsi_init(struct virtio_device *vdev,
 			 struct virtio_scsi *vscsi)
 {
@@ -793,6 +1084,9 @@ static int virtscsi_init(struct virtio_device *vdev,
 	struct virtqueue **vqs;
 	struct irq_affinity desc = { .pre_vectors = 2 };
 
+	/*
+	 * #define VIRTIO_SCSI_VQ_BASE 2
+	 */
 	num_vqs = vscsi->num_queues + VIRTIO_SCSI_VQ_BASE;
 	vqs = kmalloc(num_vqs * sizeof(struct virtqueue *), GFP_KERNEL);
 	callbacks = kmalloc(num_vqs * sizeof(vq_callback_t *), GFP_KERNEL);
@@ -837,6 +1131,9 @@ static int virtscsi_init(struct virtio_device *vdev,
 	return err;
 }
 
+/*
+ * struct virtio_driver virtio_scsi_driver.probe = virtscsi_probe()
+ */
 static int virtscsi_probe(struct virtio_device *vdev)
 {
 	struct Scsi_Host *shost;
@@ -920,6 +1217,9 @@ static int virtscsi_probe(struct virtio_device *vdev)
 	return err;
 }
 
+/*
+ * struct virtio_driver virtio_scsi_driver.remove = virtscsi_remove()
+ */
 static void virtscsi_remove(struct virtio_device *vdev)
 {
 	struct Scsi_Host *shost = virtio_scsi_host(vdev);
@@ -934,12 +1234,18 @@ static void virtscsi_remove(struct virtio_device *vdev)
 }
 
 #ifdef CONFIG_PM_SLEEP
+/*
+ * struct virtio_driver virtio_scsi_driver.freeze = virtscsi_freeze()
+ */
 static int virtscsi_freeze(struct virtio_device *vdev)
 {
 	virtscsi_remove_vqs(vdev);
 	return 0;
 }
 
+/*
+ * struct virtio_driver virtio_scsi_driver.restore = virtscsi_restore()
+ */
 static int virtscsi_restore(struct virtio_device *vdev)
 {
 	struct Scsi_Host *sh = virtio_scsi_host(vdev);
@@ -959,11 +1265,13 @@ static int virtscsi_restore(struct virtio_device *vdev)
 }
 #endif
 
+/* struct virtio_driver virtio_scsi_driver.id_table = id_table[] */
 static struct virtio_device_id id_table[] = {
 	{ VIRTIO_ID_SCSI, VIRTIO_DEV_ANY_ID },
 	{ 0 },
 };
 
+/* struct virtio_driver virtio_scsi_driver.feature_table = features[] */
 static unsigned int features[] = {
 	VIRTIO_SCSI_F_HOTPLUG,
 	VIRTIO_SCSI_F_CHANGE,
@@ -997,6 +1305,18 @@ static int __init init(void)
 	}
 
 
+	/*
+	 * 在以下使用virtscsi_cmd_pool:
+	 *   - drivers/scsi/virtio_scsi.c|633| <<virtscsi_tmf>> mempool_free(cmd, virtscsi_cmd_pool);
+	 *   - drivers/scsi/virtio_scsi.c|643| <<virtscsi_device_reset>> cmd = mempool_alloc(virtscsi_cmd_pool, GFP_NOIO);
+	 *   - drivers/scsi/virtio_scsi.c|702| <<virtscsi_abort>> cmd = mempool_alloc(virtscsi_cmd_pool, GFP_NOIO);
+	 *   - drivers/scsi/virtio_scsi.c|1024| <<init>> virtscsi_cmd_pool =
+	 *   - drivers/scsi/virtio_scsi.c|1027| <<init>> if (!virtscsi_cmd_pool) {
+	 *   - drivers/scsi/virtio_scsi.c|1038| <<init>> if (virtscsi_cmd_pool) {
+	 *   - drivers/scsi/virtio_scsi.c|1039| <<init>> mempool_destroy(virtscsi_cmd_pool);
+	 *   - drivers/scsi/virtio_scsi.c|1040| <<init>> virtscsi_cmd_pool = NULL;
+	 *   - drivers/scsi/virtio_scsi.c|1052| <<fini>> mempool_destroy(virtscsi_cmd_pool);
+	 */
 	virtscsi_cmd_pool =
 		mempool_create_slab_pool(VIRTIO_SCSI_MEMPOOL_SZ,
 					 virtscsi_cmd_cache);
diff --git a/drivers/target/target_core_configfs.c b/drivers/target/target_core_configfs.c
index 3f4bf126..d06c8239 100644
--- a/drivers/target/target_core_configfs.c
+++ b/drivers/target/target_core_configfs.c
@@ -450,6 +450,20 @@ static int target_fabric_tf_ops_check(const struct target_core_fabric_ops *tfo)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/infiniband/ulp/srpt/ib_srpt.c|3735| <<srpt_init_module>> ret = target_register_template(&srpt_template);
+ *   - drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c|4146| <<ibmvscsis_init>> rc = target_register_template(&ibmvscsis_ops);
+ *   - drivers/scsi/qla2xxx/tcm_qla2xxx.c|1964| <<tcm_qla2xxx_register_configfs>> ret = target_register_template(&tcm_qla2xxx_ops);
+ *   - drivers/scsi/qla2xxx/tcm_qla2xxx.c|1968| <<tcm_qla2xxx_register_configfs>> ret = target_register_template(&tcm_qla2xxx_npiv_ops);
+ *   - drivers/target/iscsi/iscsi_target.c|707| <<iscsi_target_init_module>> ret = target_register_template(&iscsi_ops);
+ *   - drivers/target/loopback/tcm_loop.c|1212| <<tcm_loop_fabric_init>> ret = target_register_template(&loop_ops);
+ *   - drivers/target/sbp/sbp_target.c|2366| <<sbp_init>> return target_register_template(&sbp_ops);
+ *   - drivers/target/tcm_fc/tfc_conf.c|478| <<ft_init>> ret = target_register_template(&ft_fabric_ops);
+ *   - drivers/usb/gadget/function/f_tcm.c|2338| <<tcm_init>> ret = target_register_template(&usbg_ops);
+ *   - drivers/vhost/scsi.c|2149| <<vhost_scsi_init>> ret = target_register_template(&vhost_scsi_ops);
+ *   - drivers/xen/xen-scsiback.c|1868| <<scsiback_init>> ret = target_register_template(&scsiback_ops);
+ */
 int target_register_template(const struct target_core_fabric_ops *fo)
 {
 	struct target_fabric_configfs *tf;
diff --git a/drivers/target/target_core_file.c b/drivers/target/target_core_file.c
index 9b2c0c77..3f25b3ec 100644
--- a/drivers/target/target_core_file.c
+++ b/drivers/target/target_core_file.c
@@ -526,6 +526,34 @@ fd_execute_unmap(struct se_cmd *cmd, sector_t lba, sector_t nolb)
 	return 0;
 }
 
+/*
+ * 两个callstack的例子 (第一个次数少,第二个次数多):
+ *
+ * [0] fd_execute_rw
+ * [0] __target_execute_cmd
+ * [0] target_execute_cmd
+ * [0] vhost_scsi_write_pending
+ * [0] transport_generic_new_cmd
+ * [0] transport_handle_cdb_direct
+ * [0] target_submit_cmd_map_sgls
+ * [0] vhost_scsi_submission_work
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] fd_execute_rw
+ * [0] __target_execute_cmd
+ * [0] target_execute_cmd
+ * [0] transport_generic_new_cmd
+ * [0] transport_handle_cdb_direct
+ * [0] target_submit_cmd_map_sgls
+ * [0] vhost_scsi_submission_work
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ */
 static sense_reason_t
 fd_execute_rw(struct se_cmd *cmd, struct scatterlist *sgl, u32 sgl_nents,
 	      enum dma_data_direction data_direction)
diff --git a/drivers/target/target_core_hba.c b/drivers/target/target_core_hba.c
index 22390e0e..9acd1f06 100644
--- a/drivers/target/target_core_hba.c
+++ b/drivers/target/target_core_hba.c
@@ -48,6 +48,14 @@ static DEFINE_SPINLOCK(hba_lock);
 static LIST_HEAD(hba_list);
 
 
+/*
+ * called by:
+ *   - drivers/target/target_core_file.c|852| <<fileio_module_init>> return transport_backend_register(&fileio_ops);
+ *   - drivers/target/target_core_iblock.c|881| <<iblock_module_init>> return transport_backend_register(&iblock_ops);
+ *   - drivers/target/target_core_pscsi.c|1103| <<pscsi_module_init>> return transport_backend_register(&pscsi_ops);
+ *   - drivers/target/target_core_rd.c|672| <<rd_module_init>> return transport_backend_register(&rd_mcp_ops);
+ *   - drivers/target/target_core_user.c|2524| <<tcmu_module_init>> ret = transport_backend_register(&tcmu_ops);
+ */
 int transport_backend_register(const struct target_backend_ops *ops)
 {
 	struct target_backend *tb, *old;
diff --git a/drivers/target/target_core_transport.c b/drivers/target/target_core_transport.c
index 4558f2e1..b22b46f7 100644
--- a/drivers/target/target_core_transport.c
+++ b/drivers/target/target_core_transport.c
@@ -721,6 +721,22 @@ void transport_copy_sense_to_cmd(struct se_cmd *cmd, unsigned char *sense)
 }
 EXPORT_SYMBOL(transport_copy_sense_to_cmd);
 
+/*
+ * 调用的例子:
+ * [0] target_complete_cmd
+ * [0] fd_execute_rw
+ * [0] sbc_execute_rw
+ * [0] __target_execute_cmd
+ * [0] target_execute_cmd
+ * [0] transport_generic_new_cmd
+ * [0] transport_handle_cdb_direct
+ * [0] target_submit_cmd_map_sgls
+ * [0] vhost_scsi_submission_work
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ */
 void target_complete_cmd(struct se_cmd *cmd, u8 scsi_status)
 {
 	struct se_device *dev = cmd->se_dev;
@@ -1460,6 +1476,14 @@ transport_generic_map_mem_to_cmd(struct se_cmd *cmd, struct scatterlist *sgl,
  * This may only be called from process context, and also currently
  * assumes internal allocation of fabric payload buffer by target-core.
  */
+/*
+ * called by:
+ *   - drivers/infiniband/ulp/srpt/ib_srpt.c|1468| <<srpt_handle_cmd>> rc = target_submit_cmd_map_sgls(cmd, ch->sess, srp_cmd->cdb,
+ *   - drivers/target/loopback/tcm_loop.c|153| <<tcm_loop_submission_work>> rc = target_submit_cmd_map_sgls(se_cmd, tl_nexus->se_sess, sc->cmnd,
+ *   - drivers/target/target_core_transport.c|1609| <<target_submit_cmd>> return target_submit_cmd_map_sgls(se_cmd, se_sess, cdb, sense,
+ *   - drivers/vhost/scsi.c|770| <<vhost_scsi_submission_work>> rc = target_submit_cmd_map_sgls(se_cmd, tv_nexus->tvn_se_sess,
+ *   - drivers/xen/xen-scsiback.c|404| <<scsiback_cmd_exec>> rc = target_submit_cmd_map_sgls(se_cmd, sess, pending_req->cmnd,
+ */
 int target_submit_cmd_map_sgls(struct se_cmd *se_cmd, struct se_session *se_sess,
 		unsigned char *cdb, unsigned char *sense, u64 unpacked_lun,
 		u32 data_length, int task_attr, int data_dir, int flags,
@@ -1602,6 +1626,15 @@ EXPORT_SYMBOL(target_submit_cmd_map_sgls);
  *
  * It also assumes interal target core SGL memory allocation.
  */
+/*
+ * called by:
+ *   - drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c|2740| <<ibmvscsis_parse_cmd>> rc = target_submit_cmd(&cmd->se_cmd, nexus->se_sess, srp->cdb,
+ *   - drivers/scsi/qla2xxx/tcm_qla2xxx.c|495| <<tcm_qla2xxx_handle_cmd>> return target_submit_cmd(se_cmd, se_sess, cdb, &cmd->sense_buffer[0],
+ *   - drivers/target/sbp/sbp_target.c|1234| <<sbp_handle_command>> if (target_submit_cmd(&req->se_cmd, sess->se_sess, req->cmd_buf,
+ *   - drivers/target/tcm_fc/tfc_cmd.c|570| <<ft_send_work>> if (target_submit_cmd(&cmd->se_cmd, cmd->sess->se_sess, fcp->fc_cdb,
+ *   - drivers/usb/gadget/function/f_tcm.c|1056| <<usbg_cmd_work>> if (target_submit_cmd(se_cmd, tv_nexus->tvn_se_sess, cmd->cmd_buf,
+ *   - drivers/usb/gadget/function/f_tcm.c|1185| <<bot_cmd_work>> if (target_submit_cmd(se_cmd, tv_nexus->tvn_se_sess,
+ */
 int target_submit_cmd(struct se_cmd *se_cmd, struct se_session *se_sess,
 		unsigned char *cdb, unsigned char *sense, u64 unpacked_lun,
 		u32 data_length, int task_attr, int data_dir, int flags)
@@ -1955,6 +1988,25 @@ static bool target_handle_task_attr(struct se_cmd *cmd)
 
 static int __transport_check_aborted_status(struct se_cmd *, int);
 
+/*
+ * called by:
+ *   - drivers/infiniband/ulp/isert/ib_isert.c|1743| <<isert_rdma_read_done>> target_execute_cmd(se_cmd);
+ *   - drivers/infiniband/ulp/srpt/ib_srpt.c|1304| <<srpt_rdma_read_done>> target_execute_cmd(&ioctx->cmd);
+ *   - drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c|3795| <<ibmvscsis_write_pending>> target_execute_cmd(se_cmd);
+ *   - drivers/scsi/qla2xxx/tcm_qla2xxx.c|549| <<tcm_qla2xxx_handle_data_work>> return target_execute_cmd(&cmd->se_cmd);
+ *   - drivers/target/iscsi/iscsi_target.c|1668| <<iscsit_check_dataout_payload>> target_execute_cmd(&cmd->se_cmd);
+ *   - drivers/target/iscsi/iscsi_target_erl1.c|970| <<iscsit_execute_cmd>> target_execute_cmd(&cmd->se_cmd);
+ *   - drivers/target/iscsi/iscsi_target_tmr.c|264| <<iscsit_task_reassign_complete_write>> target_execute_cmd(se_cmd);
+ *   - drivers/target/loopback/tcm_loop.c|567| <<tcm_loop_write_pending>> target_execute_cmd(se_cmd);
+ *   - drivers/target/sbp/sbp_target.c|1753| <<sbp_write_pending>> target_execute_cmd(se_cmd);
+ *   - drivers/target/target_core_transport.c|2509| <<transport_generic_new_cmd>> target_execute_cmd(cmd);
+ *   - drivers/target/target_core_xcopy.c|659| <<target_xcopy_issue_pt_cmd>> target_execute_cmd(se_cmd);
+ *   - drivers/target/tcm_fc/tfc_io.c|203| <<ft_execute_work>> target_execute_cmd(&cmd->se_cmd);
+ *   - drivers/usb/gadget/function/f_tcm.c|283| <<bot_send_write_request>> target_execute_cmd(se_cmd);
+ *   - drivers/usb/gadget/function/f_tcm.c|712| <<uasp_send_write_request>> target_execute_cmd(se_cmd);
+ *   - drivers/vhost/scsi.c|351| <<vhost_scsi_write_pending>> target_execute_cmd(se_cmd);
+ *   - drivers/xen/xen-scsiback.c|1393| <<scsiback_write_pending>> target_execute_cmd(se_cmd);
+ */
 void target_execute_cmd(struct se_cmd *cmd)
 {
 	/*
@@ -2173,6 +2225,10 @@ static bool target_read_prot_action(struct se_cmd *cmd)
 	return false;
 }
 
+/*
+ * 在以下使用target_complete_ok_work():
+ *   - drivers/target/target_core_transport.c|766| <<target_complete_cmd>> INIT_WORK(&cmd->work, target_complete_ok_work);
+ */
 static void target_complete_ok_work(struct work_struct *work)
 {
 	struct se_cmd *cmd = container_of(work, struct se_cmd, work);
diff --git a/drivers/vhost/net.c b/drivers/vhost/net.c
index dd4eb986..923a32c6 100644
--- a/drivers/vhost/net.c
+++ b/drivers/vhost/net.c
@@ -93,15 +93,15 @@ struct vhost_net_ubuf_ref {
 
 #define VHOST_RX_BATCH 64
 struct vhost_net_buf {
-	void **queue;
+	void **queue; // queue是一个void指针数组 指针内容应该在vhost_net_virtqueue.rx_ring (似乎是sk_buff)
 	int tail;
-	int head;
+	int head;  // head里是下一个可用的
 };
 
 struct vhost_net_virtqueue {
 	struct vhost_virtqueue vq;
-	size_t vhost_hlen;
-	size_t sock_hlen;
+	size_t vhost_hlen; /* 在vhost_net_set_features()中设置 */
+	size_t sock_hlen; /* 在vhost_net_set_features()中设置 */
 	/* vhost zerocopy support fields below: */
 	/* last used idx for outstanding DMA zerocopy buffers */
 	int upend_idx;
@@ -114,8 +114,9 @@ struct vhost_net_virtqueue {
 	/* Reference counting for outstanding ubufs.
 	 * Protected by vq mutex. Writers must also take device mutex. */
 	struct vhost_net_ubuf_ref *ubufs;
-	struct ptr_ring *rx_ring;
-	struct vhost_net_buf rxq;
+	/* 这里rx_ring和上面ubufs.queue相关的 似乎存的sk_buff */
+	struct ptr_ring *rx_ring; // 在VHOST_NET_SET_BACKEND:vhost_net_set_backend()设置为get_tap_ptr_ring(fd)
+	struct vhost_net_buf rxq; // queue里有64个元素
 };
 
 struct vhost_net {
@@ -132,8 +133,18 @@ struct vhost_net {
 	bool tx_flush;
 };
 
+/*
+ * 在以下使用vhost_net_zcopy_mask:
+ *   - drivers/vhost/net.c|253| <<vhost_net_enable_zcopy>> vhost_net_zcopy_mask |= 0x1 << vq;
+ *   - drivers/vhost/net.c|315| <<vhost_net_set_ubuf_info>> zcopy = vhost_net_zcopy_mask & (0x1 << i);
+ */
 static unsigned vhost_net_zcopy_mask __read_mostly;
 
+/*
+ * 如果还有能用的 返回下一个可用的 head是下一个能用的
+ *
+ * queue是一个void指针数组 指针内容应该在vhost_net_virtqueue.rx_ring (似乎是sk_buff)
+ */
 static void *vhost_net_buf_get_ptr(struct vhost_net_buf *rxq)
 {
 	if (rxq->tail != rxq->head)
@@ -147,18 +158,34 @@ static int vhost_net_buf_get_size(struct vhost_net_buf *rxq)
 	return rxq->tail - rxq->head;
 }
 
+/* tail和head相等的时候为empty! */
 static int vhost_net_buf_is_empty(struct vhost_net_buf *rxq)
 {
 	return rxq->tail == rxq->head;
 }
 
+/*
+ * 如果还有能用的 返回下一个可用的
+ * 然后把head++ head里是下一个可用的
+ *
+ * consume是消耗head
+ *
+ * called only by handle_rx()
+ */
 static void *vhost_net_buf_consume(struct vhost_net_buf *rxq)
 {
+	/* 如果还有能用的 返回下一个可用的 */
 	void *ret = vhost_net_buf_get_ptr(rxq);
+	/* 然后把head++ head里是下一个可用的 */
 	++rxq->head;
 	return ret;
 }
 
+/*
+ * produce就是head设置成0 然后设置tail head和tail之间距离很大
+ *
+ * called only by vhost_net_buf_peek()
+ */
 static int vhost_net_buf_produce(struct vhost_net_virtqueue *nvq)
 {
 	struct vhost_net_buf *rxq = &nvq->rxq;
@@ -169,6 +196,11 @@ static int vhost_net_buf_produce(struct vhost_net_virtqueue *nvq)
 	return rxq->tail;
 }
 
+/*
+ * 就两个地方用到了 (都和初始化相关吧):
+ *   - vhost_net_stop_vq()
+ *   - VHOST_NET_SET_BACKEND: vhost_net_set_backend()
+ */
 static void vhost_net_buf_unproduce(struct vhost_net_virtqueue *nvq)
 {
 	struct vhost_net_buf *rxq = &nvq->rxq;
@@ -181,6 +213,11 @@ static void vhost_net_buf_unproduce(struct vhost_net_virtqueue *nvq)
 	}
 }
 
+/*
+ * called only by vhost_net_buf_peek()
+ *
+ * ptr是vhost_net_buf.queue中的一个元素 (void指针 从rx_ring获得的)
+ */
 static int vhost_net_buf_peek_len(void *ptr)
 {
 	if (tun_is_xdp_buff(ptr)) {
@@ -192,17 +229,21 @@ static int vhost_net_buf_peek_len(void *ptr)
 	return __skb_array_len_with_tag(ptr);
 }
 
+/* called only by peek_head_len() */
 static int vhost_net_buf_peek(struct vhost_net_virtqueue *nvq)
 {
 	struct vhost_net_buf *rxq = &nvq->rxq;
 
+	/* tail和head相等的时候为empty! */
 	if (!vhost_net_buf_is_empty(rxq))
 		goto out;
 
+	/* produce就是head设置成0 然后设置tail head和tail之间距离很大 */
 	if (!vhost_net_buf_produce(nvq))
 		return 0;
 
 out:
+	/* vhost_net_buf_get_ptr(rxq)是如果还有能用的 返回下一个可用的 */
 	return vhost_net_buf_peek_len(vhost_net_buf_get_ptr(rxq));
 }
 
@@ -211,8 +252,14 @@ static void vhost_net_buf_init(struct vhost_net_buf *rxq)
 	rxq->head = rxq->tail = 0;
 }
 
+/* called only by vhost_net_init() */
 static void vhost_net_enable_zcopy(int vq)
 {
+	/*
+	 * 在以下使用vhost_net_zcopy_mask:
+	 *   - drivers/vhost/net.c|253| <<vhost_net_enable_zcopy>> vhost_net_zcopy_mask |= 0x1 << vq;
+	 *   - drivers/vhost/net.c|315| <<vhost_net_set_ubuf_info>> zcopy = vhost_net_zcopy_mask & (0x1 << i);
+	 */
 	vhost_net_zcopy_mask |= 0x1 << vq;
 }
 
@@ -240,12 +287,18 @@ static int vhost_net_ubuf_put(struct vhost_net_ubuf_ref *ubufs)
 	return r;
 }
 
+/*
+ * called by:
+ *   - vhost_net_ubuf_put_wait_and_free()
+ *   - vhost_net_flush()
+ */
 static void vhost_net_ubuf_put_and_wait(struct vhost_net_ubuf_ref *ubufs)
 {
 	vhost_net_ubuf_put(ubufs);
 	wait_event(ubufs->wait, !atomic_read(&ubufs->refcount));
 }
 
+/* called at two locations in vhost_net_set_backend() */
 static void vhost_net_ubuf_put_wait_and_free(struct vhost_net_ubuf_ref *ubufs)
 {
 	vhost_net_ubuf_put_and_wait(ubufs);
@@ -262,6 +315,7 @@ static void vhost_net_clear_ubuf_info(struct vhost_net *n)
 	}
 }
 
+/* called only by vhost_net_set_owner() */
 static int vhost_net_set_ubuf_info(struct vhost_net *n)
 {
 	bool zcopy;
@@ -323,6 +377,7 @@ static bool vhost_net_tx_select_zcopy(struct vhost_net *net)
 		net->tx_packets / 64 >= net->tx_zcopy_err;
 }
 
+/* called only by vhost_net_set_backend() */
 static bool vhost_sock_zcopy(struct socket *sock)
 {
 	return unlikely(experimental_zcopytx) &&
@@ -334,6 +389,12 @@ static bool vhost_sock_zcopy(struct socket *sock)
  * of used idx. Once lower device DMA done contiguously, we will signal KVM
  * guest used idx.
  */
+/* 分别是done_idx和upend_idx */
+/*
+ * called by:
+ *   - handle_tx()调用了两次
+ *   - vhost_net_set_backend()
+ */
 static void vhost_zerocopy_signal_used(struct vhost_net *net,
 				       struct vhost_virtqueue *vq)
 {
@@ -348,7 +409,7 @@ static void vhost_zerocopy_signal_used(struct vhost_net *net,
 		if (VHOST_DMA_IS_DONE(vq->heads[i].len)) {
 			vq->heads[i].len = VHOST_DMA_CLEAR_LEN;
 			++j;
-		} else
+		} else // 只能回收连续的 不连续就break
 			break;
 	}
 	while (j) {
@@ -391,6 +452,11 @@ static inline unsigned long busy_clock(void)
 	return local_clock() >> 10;
 }
 
+/*
+ * called by:
+ *   - vhost_net_tx_get_vq_desc()
+ *   - vhost_net_rx_peek_head_len()
+ */
 static bool vhost_can_busy_poll(struct vhost_dev *dev,
 				unsigned long endtime)
 {
@@ -400,6 +466,7 @@ static bool vhost_can_busy_poll(struct vhost_dev *dev,
 	       !vhost_has_work(dev);
 }
 
+/* 把vhost_net的poll在fd的poll上移除 */
 static void vhost_net_disable_vq(struct vhost_net *n,
 				 struct vhost_virtqueue *vq)
 {
@@ -411,6 +478,12 @@ static void vhost_net_disable_vq(struct vhost_net *n,
 	vhost_poll_stop(poll);
 }
 
+/*
+ * called by:
+ *   - handle_tx()
+ *   - handle_rx()
+ *   - VHOST_NET_SET_BACKEND:vhost_net_set_backend()
+ */
 static int vhost_net_enable_vq(struct vhost_net *n,
 				struct vhost_virtqueue *vq)
 {
@@ -423,6 +496,7 @@ static int vhost_net_enable_vq(struct vhost_net *n,
 	if (!sock)
 		return 0;
 
+	/* 这里的poll是n->poll */
 	return vhost_poll_start(poll, sock->file);
 }
 
@@ -432,6 +506,7 @@ static int vhost_net_tx_get_vq_desc(struct vhost_net *net,
 				    unsigned int *out_num, unsigned int *in_num)
 {
 	unsigned long uninitialized_var(endtime);
+	/* 把desc中的信息拷贝到iov (地址会转换成qemu userspace的地址) */
 	int r = vhost_get_vq_desc(vq, vq->iov, ARRAY_SIZE(vq->iov),
 				  out_num, in_num, NULL, NULL);
 
@@ -489,9 +564,12 @@ static void handle_tx(struct vhost_net *net)
 	if (!vq_iotlb_prefetch(vq))
 		goto out;
 
+	/* 如果不支持VIRTIO_RING_F_EVENT_IDX 在vq->used->flags中通知guest VRING_USED_F_NO_NOTIFY */
 	vhost_disable_notify(&net->dev, vq);
+	/* 把vhost_net的poll在fd的poll上移除 */
 	vhost_net_disable_vq(net, vq);
 
+	/* nvq->vhost_hlen在vhost_net_set_features()中设置 */
 	hdr_size = nvq->vhost_hlen;
 	zcopy = nvq->ubufs;
 
@@ -501,6 +579,7 @@ static void handle_tx(struct vhost_net *net)
 			vhost_zerocopy_signal_used(net, vq);
 
 
+		/* 把desc中的信息拷贝到iov (地址会转换成qemu userspace的地址) */
 		head = vhost_net_tx_get_vq_desc(net, vq, vq->iov,
 						ARRAY_SIZE(vq->iov),
 						&out, &in);
@@ -510,6 +589,7 @@ static void handle_tx(struct vhost_net *net)
 		/* Nothing new?  Wait for eventfd to tell us they refilled. */
 		if (head == vq->num) {
 			if (unlikely(vhost_enable_notify(&net->dev, vq))) {
+				/* 如果不支持VIRTIO_RING_F_EVENT_IDX 在vq->used->flags中通知guest VRING_USED_F_NO_NOTIFY */
 				vhost_disable_notify(&net->dev, vq);
 				continue;
 			}
@@ -568,6 +648,7 @@ static void handle_tx(struct vhost_net *net)
 		}
 
 		/* TODO: Check specific error and bomb out unless ENOBUFS? */
+		/* 实际是 tap_sendmsg() */
 		err = sock->ops->sendmsg(sock, &msg, len);
 		if (unlikely(err < 0)) {
 			if (zcopy_used) {
@@ -589,6 +670,7 @@ static void handle_tx(struct vhost_net *net)
 		vhost_net_tx_packet(net);
 		if (unlikely(total_len >= VHOST_NET_WEIGHT) ||
 		    unlikely(++sent_pkts >= VHOST_NET_PKT_WEIGHT(vq))) {
+			/* 把poll->work (vhost_work)挂到poll->dev (vhost_dev)上然后唤醒vhost_dev的内核线程 */
 			vhost_poll_queue(&vq->poll);
 			break;
 		}
@@ -597,12 +679,14 @@ static void handle_tx(struct vhost_net *net)
 	mutex_unlock(&vq->mutex);
 }
 
+/* 似乎就是skb->len吧 最后间接来自__skb_array_len_with_tag()*/
 static int peek_head_len(struct vhost_net_virtqueue *rvq, struct sock *sk)
 {
 	struct sk_buff *head;
 	int len = 0;
 	unsigned long flags;
 
+	/* 用不用rx_ring是tun/tap说了算的 */
 	if (rvq->rx_ring)
 		return vhost_net_buf_peek(rvq);
 
@@ -622,6 +706,7 @@ static int sk_has_rx_data(struct sock *sk)
 {
 	struct socket *sock = sk->sk_socket;
 
+	/* tap_peek_len() */
 	if (sock->ops->peek_len)
 		return sock->ops->peek_len(sock);
 
@@ -636,16 +721,26 @@ static void vhost_rx_signal_used(struct vhost_net_virtqueue *nvq)
 	if (!nvq->done_idx)
 		return;
 
+	/*
+	 * vq->heads是vring_used_elem类型
+	 *
+	 * nvq->done_idx作为count来用
+	 */
 	vhost_add_used_and_signal_n(dev, vq, vq->heads, nvq->done_idx);
 	nvq->done_idx = 0;
 }
 
+/*
+ * called only by handle_rx()
+ */
+/* 似乎就是skb->len吧 最后间接来自__skb_array_len_with_tag()*/
 static int vhost_net_rx_peek_head_len(struct vhost_net *net, struct sock *sk)
 {
 	struct vhost_net_virtqueue *rvq = &net->vqs[VHOST_NET_VQ_RX];
 	struct vhost_net_virtqueue *nvq = &net->vqs[VHOST_NET_VQ_TX];
 	struct vhost_virtqueue *vq = &nvq->vq;
 	unsigned long uninitialized_var(endtime);
+	/* 似乎就是skb->len吧 最后间接来自__skb_array_len_with_tag()*/
 	int len = peek_head_len(rvq, sk);
 
 	if (!len && vq->busyloop_timeout) {
@@ -690,6 +785,9 @@ static int vhost_net_rx_peek_head_len(struct vhost_net *net, struct sock *sk)
  * @quota       - headcount quota, 1 for big buffer
  *	returns number of buffer heads allocated, negative on error
  */
+/*
+ * called only by handle_rx()!
+ */
 static int get_rx_bufs(struct vhost_virtqueue *vq,
 		       struct vring_used_elem *heads,
 		       int datalen,
@@ -759,6 +857,11 @@ static int get_rx_bufs(struct vhost_virtqueue *vq,
 
 /* Expects to be always run from workqueue - which acts as
  * read-size critical section for our kind of RCU. */
+/*
+ * called by:
+ *   - drivers/vhost/net.c|1006| <<handle_rx_kick>> handle_rx(net);
+ *   - drivers/vhost/net.c|1020| <<handle_rx_net>> handle_rx(net);
+ */
 static void handle_rx(struct vhost_net *net)
 {
 	struct vhost_net_virtqueue *nvq = &net->vqs[VHOST_NET_VQ_RX];
@@ -793,16 +896,21 @@ static void handle_rx(struct vhost_net *net)
 	if (!vq_iotlb_prefetch(vq))
 		goto out;
 
+	/* 如果不支持VIRTIO_RING_F_EVENT_IDX 在vq->used->flags中通知guest VRING_USED_F_NO_NOTIFY */
 	vhost_disable_notify(&net->dev, vq);
+	/* 把vhost_net的poll在fd的poll上移除 */
 	vhost_net_disable_vq(net, vq);
 
+	/* 在vhost_net_set_features()中设置 */
 	vhost_hlen = nvq->vhost_hlen;
+	/* 在vhost_net_set_features()中设置 */
 	sock_hlen = nvq->sock_hlen;
 
 	vq_log = unlikely(vhost_has_feature(vq, VHOST_F_LOG_ALL)) ?
 		vq->log : NULL;
 	mergeable = vhost_has_feature(vq, VIRTIO_NET_F_MRG_RXBUF);
 
+	/* 似乎就是skb->len吧 最后间接来自__skb_array_len_with_tag()*/
 	while ((sock_len = vhost_net_rx_peek_head_len(net, sock->sk))) {
 		sock_len += sock_hlen;
 		vhost_len = sock_len + vhost_hlen;
@@ -843,6 +951,9 @@ static void handle_rx(struct vhost_net *net)
 			 */
 			iov_iter_advance(&msg.msg_iter, vhost_hlen);
 		}
+		/*
+		 * 对于macvlan/macvtap是tap_recvmsg
+		 */
 		err = sock->ops->recvmsg(sock, &msg,
 					 sock_len, MSG_DONTWAIT | MSG_TRUNC);
 		/* Userspace might have consumed the packet meanwhile:
@@ -920,6 +1031,10 @@ static void handle_tx_net(struct vhost_work *work)
 	handle_tx(net);
 }
 
+/*
+ * 在以下使用handle_rx_net():
+ *   - drivers/vhost/net.c|1161| <<vhost_net_open>> vhost_poll_init(n->poll + VHOST_NET_VQ_RX, handle_rx_net, EPOLLIN, dev);
+ */
 static void handle_rx_net(struct vhost_work *work)
 {
 	struct vhost_net *net = container_of(work, struct vhost_net,
@@ -927,6 +1042,50 @@ static void handle_rx_net(struct vhost_work *work)
 	handle_rx(net);
 }
 
+/*
+ * struct vhost_net {
+ *	struct vhost_dev dev {
+ *
+ *	}
+ *
+ *	struct vhost_net_virtqueue vqs[VHOST_NET_VQ_MAX] {
+ *		struct vhost_virtqueue vq {
+ *			struct eventfd_ctx *call_ctx;
+ *
+ *			struct vhost_poll poll {
+ *				poll_table table; (_qproc) --> vhost_poll_func()
+ *				wait_queue_head_t *wqh;
+ *				wait_queue_entry_t wait; (func) --> vhost_poll_wakeup()
+ *				struct vhost_work work; (fn) --> vq->handle_kick()
+ *				__poll_t mask;
+ *				struct vhost_dev *dev;
+ *			}
+ *
+ *			vhost_work_fn_t handle_kick; (handle_tx_kick() or handle_rx_kick())
+ *		}
+ *	}
+ *
+ *	struct vhost_poll poll[VHOST_NET_VQ_MAX] {
+ *		poll_table table; (_qproc) --> vhost_poll_func()
+ *		wait_queue_head_t *wqh;
+ *		wait_queue_entry_t wait; (func) --> vhost_poll_wakeup()
+ *		struct vhost_work work; (fn) --> handle_rx_net() or handle_tx_net()
+ *		__poll_t mask;
+ *		struct vhost_dev *dev;
+ *	}
+ * }
+ */
+
+/*
+ * 如果是4个queue就调用4次
+ *
+ * # /usr/share/bcc/tools/trace -t -C 'vhost_net_open'
+ * TIME     CPU PID     TID     COMM            FUNC
+ * 2.705153 23  25983   25983   qemu-system-x86 vhost_net_open
+ * 2.705519 23  25983   25983   qemu-system-x86 vhost_net_open
+ * 2.705715 23  25983   25983   qemu-system-x86 vhost_net_open
+ * 2.705892 23  25983   25983   qemu-system-x86 vhost_net_open
+ */
 static int vhost_net_open(struct inode *inode, struct file *f)
 {
 	struct vhost_net *n;
@@ -935,15 +1094,18 @@ static int vhost_net_open(struct inode *inode, struct file *f)
 	void **queue;
 	int i;
 
+	/* 分配vhost_net */
 	n = kvmalloc(sizeof *n, GFP_KERNEL | __GFP_RETRY_MAYFAIL);
 	if (!n)
 		return -ENOMEM;
+	/* 分配2个vhost_virtqueue指针 */
 	vqs = kmalloc(VHOST_NET_VQ_MAX * sizeof(*vqs), GFP_KERNEL);
 	if (!vqs) {
 		kvfree(n);
 		return -ENOMEM;
 	}
 
+	/* 分配64个指针 */
 	queue = kmalloc_array(VHOST_RX_BATCH, sizeof(void *),
 			      GFP_KERNEL);
 	if (!queue) {
@@ -951,9 +1113,17 @@ static int vhost_net_open(struct inode *inode, struct file *f)
 		kvfree(n);
 		return -ENOMEM;
 	}
+	/*
+	 * rxq是vhost_net_buf
+	 * queue是一个void指针数组 指针内容应该在vhost_net_virtqueue.rx_ring (似乎是sk_buff)
+	 */
 	n->vqs[VHOST_NET_VQ_RX].rxq.queue = queue;
 
 	dev = &n->dev;
+	/*
+	 * 上面分配的vqs包含2个vhost_virtqueue指针
+	 * 这里不分配不行 因为两个vhost_virtqueue不是连续的
+	 */
 	vqs[VHOST_NET_VQ_TX] = &n->vqs[VHOST_NET_VQ_TX].vq;
 	vqs[VHOST_NET_VQ_RX] = &n->vqs[VHOST_NET_VQ_RX].vq;
 	n->vqs[VHOST_NET_VQ_TX].vq.handle_kick = handle_tx_kick;
@@ -968,6 +1138,27 @@ static int vhost_net_open(struct inode *inode, struct file *f)
 		n->vqs[i].rx_ring = NULL;
 		vhost_net_buf_init(&n->vqs[i].rxq);
 	}
+	/*
+	 * 把参数vhost_dev dev的field vqs(二维指针)设置为vqs
+	 */
+
+	/*
+	 * vhost_dev_init()-->vhost_poll_init(&vq->poll, vq->handle_kick, EPOLLIN, dev)
+	 * 1. 把n->vqs[i].vq.poll的wait->func设置为vhost_poll_wakeup()
+	 * 2. 把n->vqs[i].vq.poll的table->_qproc设置为vhost_poll_func()
+	 * 3. 把n->vqs[i].vq.poll的work->fn设置为n->vqs[i].vq.handle_kick (也就是handle_tx_kick()或者handle_rx_kick()) ---> 都是EPOLLIN
+	 *
+	 * vhost_poll_init(n->poll + VHOST_NET_VQ_TX, handle_tx_net, EPOLLOUT, dev);
+	 * 1. 把n->poll[1]的wait->func设置为vhost_poll_wakeup()
+	 * 2. 把n->poll[1]的table->_qproc设置为vhost_poll_func()
+	 * 3. 把n->poll[1]的work->fn设置为handle_tx_net ---> EPOLLOUT
+	 *
+	 * vhost_poll_init(n->poll + VHOST_NET_VQ_RX, handle_rx_net, EPOLLIN, dev);
+	 * 1. 把n->poll[0]的wait->func设置为vhost_poll_wakeup()
+	 * 2. 把n->poll[0]的table->_qproc设置为vhost_poll_func()
+	 * 3. 把n->poll[0]的work->fn设置为handle_rx_net ---> EPOLLIN
+	 */
+
 	vhost_dev_init(dev, vqs, VHOST_NET_VQ_MAX);
 
 	vhost_poll_init(n->poll + VHOST_NET_VQ_TX, handle_tx_net, EPOLLOUT, dev);
@@ -987,6 +1178,7 @@ static struct socket *vhost_net_stop_vq(struct vhost_net *n,
 
 	mutex_lock(&vq->mutex);
 	sock = vq->private_data;
+	/* 把vhost_net的poll在fd的poll上移除 */
 	vhost_net_disable_vq(n, vq);
 	vq->private_data = NULL;
 	vhost_net_buf_unproduce(nvq);
@@ -1002,12 +1194,24 @@ static void vhost_net_stop(struct vhost_net *n, struct socket **tx_sock,
 	*rx_sock = vhost_net_stop_vq(n, &n->vqs[VHOST_NET_VQ_RX].vq);
 }
 
+/*
+ * called by:
+ *   - vhost_net_flush_vq()调用了两次
+ *   - vhost_net_flush_vq()
+ */
 static void vhost_net_flush_vq(struct vhost_net *n, int index)
 {
 	vhost_poll_flush(n->poll + index);
 	vhost_poll_flush(&n->vqs[index].vq.poll);
 }
 
+/*
+ * called by:
+ *   - vhost_net_release()调用了两次
+ *   - vhost_net_reset_owner()
+ *   - vhost_net_set_owner()
+ *   - vhost_net_ioctl()
+ */
 static void vhost_net_flush(struct vhost_net *n)
 {
 	vhost_net_flush_vq(n, VHOST_NET_VQ_TX);
@@ -1083,6 +1287,9 @@ static struct socket *get_raw_socket(int fd)
 	return ERR_PTR(r);
 }
 
+/*
+ * called only by VHOST_NET_SET_BACKEND:vhost_net_set_backend()
+ */
 static struct ptr_ring *get_tap_ptr_ring(int fd)
 {
 	struct ptr_ring *ring;
@@ -1134,6 +1341,11 @@ static struct socket *get_socket(int fd)
 	return ERR_PTR(-ENOTSOCK);
 }
 
+/*
+ * VHOST_NET_SET_BACKEND
+ *
+ * Attach virtio net ring to a raw socket, or tap device
+ */
 static long vhost_net_set_backend(struct vhost_net *n, unsigned index, int fd)
 {
 	struct socket *sock, *oldsock;
@@ -1176,6 +1388,7 @@ static long vhost_net_set_backend(struct vhost_net *n, unsigned index, int fd)
 			goto err_ubufs;
 		}
 
+		/* 把vhost_net的poll在fd的poll上移除 */
 		vhost_net_disable_vq(n, vq);
 		vq->private_data = sock;
 		vhost_net_buf_unproduce(nvq);
@@ -1228,6 +1441,7 @@ static long vhost_net_set_backend(struct vhost_net *n, unsigned index, int fd)
 	return r;
 }
 
+/* VHOST_RESET_OWNER */
 static long vhost_net_reset_owner(struct vhost_net *n)
 {
 	struct socket *tx_sock = NULL;
@@ -1258,6 +1472,7 @@ static long vhost_net_reset_owner(struct vhost_net *n)
 	return err;
 }
 
+/* VHOST_SET_FEATURES */
 static int vhost_net_set_features(struct vhost_net *n, u64 features)
 {
 	size_t vhost_hlen, sock_hlen, hdr_len;
@@ -1267,6 +1482,7 @@ static int vhost_net_set_features(struct vhost_net *n, u64 features)
 			       (1ULL << VIRTIO_F_VERSION_1))) ?
 			sizeof(struct virtio_net_hdr_mrg_rxbuf) :
 			sizeof(struct virtio_net_hdr);
+	/* vhost-net should add virtio_net_hdr for RX, and strip for TX packets. */
 	if (features & (1 << VHOST_NET_F_VIRTIO_NET_HDR)) {
 		/* vhost provides vnet_hdr */
 		vhost_hlen = hdr_len;
@@ -1301,6 +1517,7 @@ static int vhost_net_set_features(struct vhost_net *n, u64 features)
 	return -EFAULT;
 }
 
+/* VHOST_SET_OWNER */
 static long vhost_net_set_owner(struct vhost_net *n)
 {
 	int r;
@@ -1313,6 +1530,9 @@ static long vhost_net_set_owner(struct vhost_net *n)
 	r = vhost_net_set_ubuf_info(n);
 	if (r)
 		goto out;
+	/*
+	 * 这里会创建kthread
+	 */
 	r = vhost_dev_set_owner(&n->dev);
 	if (r)
 		vhost_net_clear_ubuf_info(n);
@@ -1333,7 +1553,7 @@ static long vhost_net_ioctl(struct file *f, unsigned int ioctl,
 	int r;
 
 	switch (ioctl) {
-	case VHOST_NET_SET_BACKEND:
+	case VHOST_NET_SET_BACKEND:  // Attach virtio net ring to a raw socket, or tap device.
 		if (copy_from_user(&backend, argp, sizeof backend))
 			return -EFAULT;
 		return vhost_net_set_backend(n, backend.index, backend.fd);
@@ -1372,6 +1592,7 @@ static long vhost_net_compat_ioctl(struct file *f, unsigned int ioctl,
 }
 #endif
 
+/* qemu通过这个接口读取VHOST_IOTLB_MISS信息 */
 static ssize_t vhost_net_chr_read_iter(struct kiocb *iocb, struct iov_iter *to)
 {
 	struct file *file = iocb->ki_filp;
@@ -1379,9 +1600,11 @@ static ssize_t vhost_net_chr_read_iter(struct kiocb *iocb, struct iov_iter *to)
 	struct vhost_dev *dev = &n->dev;
 	int noblock = file->f_flags & O_NONBLOCK;
 
+	/* qemu通过这个接口读取VHOST_IOTLB_MISS信息 */
 	return vhost_chr_read_iter(dev, to, noblock);
 }
 
+/* qemu通过这个接口发送VHOST_IOTLB_MISS的回复给vhost */
 static ssize_t vhost_net_chr_write_iter(struct kiocb *iocb,
 					struct iov_iter *from)
 {
@@ -1389,6 +1612,7 @@ static ssize_t vhost_net_chr_write_iter(struct kiocb *iocb,
 	struct vhost_net *n = file->private_data;
 	struct vhost_dev *dev = &n->dev;
 
+	/* qemu通过这个接口发送VHOST_IOTLB_MISS的回复给vhost */
 	return vhost_chr_write_iter(dev, from);
 }
 
@@ -1403,8 +1627,8 @@ static __poll_t vhost_net_chr_poll(struct file *file, poll_table *wait)
 static const struct file_operations vhost_net_fops = {
 	.owner          = THIS_MODULE,
 	.release        = vhost_net_release,
-	.read_iter      = vhost_net_chr_read_iter,
-	.write_iter     = vhost_net_chr_write_iter,
+	.read_iter      = vhost_net_chr_read_iter,   // qemu通过这个接口读取VHOST_IOTLB_MISS信息
+	.write_iter     = vhost_net_chr_write_iter,  // qemu通过这个接口发送VHOST_IOTLB_MISS的回复给vhost
 	.poll           = vhost_net_chr_poll,
 	.unlocked_ioctl = vhost_net_ioctl,
 #ifdef CONFIG_COMPAT
diff --git a/drivers/vhost/scsi.c b/drivers/vhost/scsi.c
index 7ad57094..737ddbee 100644
--- a/drivers/vhost/scsi.c
+++ b/drivers/vhost/scsi.c
@@ -67,6 +67,11 @@ struct vhost_scsi_inflight {
 
 struct vhost_scsi_cmd {
 	/* Descriptor from vhost_get_vq_desc() for virt_queue segment */
+	/*
+	 * 在以下使用vhost_scsi_cmd->tvc_vq_desc:
+	 *   - drivers/vhost/scsi.c|731| <<vhost_scsi_complete_cmd_work>> vhost_add_used(cmd->tvc_vq, cmd->tvc_vq_desc, 0);
+	 *   - drivers/vhost/scsi.c|1261| <<vhost_scsi_handle_vq>> cmd->tvc_vq_desc = head;
+	 */
 	int tvc_vq_desc;
 	/* virtio-scsi initiator task attribute */
 	int tvc_task_attr;
@@ -111,6 +116,18 @@ struct vhost_scsi_cmd {
 
 struct vhost_scsi_nexus {
 	/* Pointer to TCM session for I_T Nexus */
+	/*
+	 * 在以下使用vhost_scsi_nexus->tvn_se_sess:
+	 *   - drivers/vhost/scsi.c|460| <<vhost_scsi_release_cmd>> struct se_session *se_sess = tv_cmd->tvc_nexus->tvn_se_sess;
+	 *   - drivers/vhost/scsi.c|854| <<vhost_scsi_get_tag>> se_sess = tv_nexus->tvn_se_sess;
+	 *   - drivers/vhost/scsi.c|1104| <<vhost_scsi_submission_work>> rc = target_submit_cmd_map_sgls(se_cmd, tv_nexus->tvn_se_sess,
+	 *   - drivers/vhost/scsi.c|2320| <<vhost_scsi_make_nexus>> tv_nexus->tvn_se_sess = target_alloc_session(&tpg->se_tpg,
+	 *   - drivers/vhost/scsi.c|2326| <<vhost_scsi_make_nexus>> if (IS_ERR(tv_nexus->tvn_se_sess)) {
+	 *   - drivers/vhost/scsi.c|2354| <<vhost_scsi_drop_nexus>> se_sess = tv_nexus->tvn_se_sess;
+	 *   - drivers/vhost/scsi.c|2378| <<vhost_scsi_drop_nexus>> tv_nexus->tvn_se_sess->se_node_acl->initiatorname);
+	 *   - drivers/vhost/scsi.c|2384| <<vhost_scsi_drop_nexus>> transport_deregister_session(tv_nexus->tvn_se_sess);
+	 *   - drivers/vhost/scsi.c|2411| <<vhost_scsi_tpg_nexus_show>> tv_nexus->tvn_se_sess->se_node_acl->initiatorname);
+	 */
 	struct se_session *tvn_se_sess;
 };
 
@@ -120,6 +137,14 @@ struct vhost_scsi_tpg {
 	/* Used to track number of TPG Port/Lun Links wrt to explict I_T Nexus shutdown */
 	int tv_tpg_port_count;
 	/* Used for vhost_scsi device reference to tpg_nexus, protected by tv_tpg_mutex */
+	/*
+	 * 在以下使用和修改vhost_scsi_tpg->tv_tpg_vhost_count:
+	 *   - drivers/vhost/scsi.c|1447| <<vhost_scsi_set_endpoint>> tpg->tv_tpg_vhost_count++;
+	 *   - drivers/vhost/scsi.c|1533| <<vhost_scsi_clear_endpoint>> tpg->tv_tpg_vhost_count--;
+	 *   - drivers/vhost/scsi.c|1420| <<vhost_scsi_set_endpoint>> if (tpg->tv_tpg_vhost_count != 0) {
+	 *   - drivers/vhost/scsi.c|2056| <<vhost_scsi_drop_nexus>> if (tpg->tv_tpg_vhost_count != 0) {
+	 *   - drivers/vhost/scsi.c|2060| <<vhost_scsi_drop_nexus>> tpg->tv_tpg_vhost_count);
+	 */
 	int tv_tpg_vhost_count;
 	/* Used for enabling T10-PI with legacy devices */
 	int tv_fabric_prot_type;
@@ -156,8 +181,17 @@ struct vhost_scsi_evt {
 };
 
 enum {
+	/*
+	 * 在以下使用VHOST_SCSI_VQ_CTL:
+	 *   - drivers/vhost/scsi.c|1627| <<vhost_scsi_open>> vqs[VHOST_SCSI_VQ_CTL] = &vs->vqs[VHOST_SCSI_VQ_CTL].vq;
+	 *   - drivers/vhost/scsi.c|1646| <<vhost_scsi_open>> vs->vqs[VHOST_SCSI_VQ_CTL].vq.handle_kick = vhost_scsi_ctl_handle_kick;
+	 */
 	VHOST_SCSI_VQ_CTL = 0,
 	VHOST_SCSI_VQ_EVT = 1,
+	/*
+	 * 在以下使用VHOST_SCSI_VQ_IO:
+	 *   - drivers/vhost/scsi.c|1428| <<vhost_scsi_open>> for (i = VHOST_SCSI_VQ_IO; i < VHOST_SCSI_MAX_VQ; i++) {
+	 */
 	VHOST_SCSI_VQ_IO = 2,
 };
 
@@ -167,8 +201,18 @@ enum {
 					       (1ULL << VIRTIO_SCSI_F_T10_PI)
 };
 
+/*
+ * 在以下使用VHOST_SCSI_MAX_TARGET:
+ *   - drivers/vhost/scsi.c|1303| <<vhost_scsi_set_endpoint>> len = sizeof(vs_tpg[0]) * VHOST_SCSI_MAX_TARGET;
+ *   - drivers/vhost/scsi.c|1410| <<vhost_scsi_clear_endpoint>> for (i = 0; i < VHOST_SCSI_MAX_TARGET; i++) {
+ *   - drivers/vhost/scsi.c|2087| <<vhost_scsi_make_tpg>> if (kstrtou16(name + 5, 10, &tpgt) || tpgt >= VHOST_SCSI_MAX_TARGET)
+ */
 #define VHOST_SCSI_MAX_TARGET	256
 #define VHOST_SCSI_MAX_VQ	128
+/*
+ * 在以下使用VHOST_SCSI_MAX_EVENT:
+ *   - drivers/vhost/scsi.c|624| <<vhost_scsi_allocate_evt>> if (vs->vs_events_nr > VHOST_SCSI_MAX_EVENT) {
+ */
 #define VHOST_SCSI_MAX_EVENT	128
 
 struct vhost_scsi_virtqueue {
@@ -183,33 +227,110 @@ struct vhost_scsi_virtqueue {
 	 * Indicate current inflight in use, protected by vq->mutex.
 	 * Writers must also take dev mutex and flush under it.
 	 */
+	/*
+	 * 在以下使用vhost_scsi_virtqueue->inflight_idx:
+	 *   - drivers/vhost/scsi.c|279| <<vhost_scsi_init_inflight>> idx = vs->vqs[i].inflight_idx;
+	 *   - drivers/vhost/scsi.c|284| <<vhost_scsi_init_inflight>> vs->vqs[i].inflight_idx = idx ^ 1;
+	 *   - drivers/vhost/scsi.c|304| <<vhost_scsi_get_inflight>> inflight = &svq->inflights[svq->inflight_idx];
+	 */
 	int inflight_idx;
 };
 
 struct vhost_scsi {
 	/* Protected by vhost_scsi->dev.mutex */
 	struct vhost_scsi_tpg **vs_tpg;
+	/*
+	 * 在以下使用vhost_scsi->vs_vhost_wwpn[TRANSPORT_IQN_LEN]:
+	 *   - drivers/vhost/scsi.c|1705| <<vhost_scsi_set_endpoint>> memcpy(vs->vs_vhost_wwpn, t->vhost_wwpn,
+	 *   - drivers/vhost/scsi.c|1706| <<vhost_scsi_set_endpoint>> sizeof(vs->vs_vhost_wwpn));
+	 *   - drivers/vhost/scsi.c|1944| <<vhost_scsi_release>> memcpy(t.vhost_wwpn, vs->vs_vhost_wwpn, sizeof(t.vhost_wwpn));
+	 */
 	char vs_vhost_wwpn[TRANSPORT_IQN_LEN];
 
 	struct vhost_dev dev;
 	struct vhost_scsi_virtqueue vqs[VHOST_SCSI_MAX_VQ];
 
+	/*
+	 * 在以下使用vhost_scsi->vs_completion_work:
+	 *   - drivers/vhost/scsi.c|469| <<vhost_scsi_complete_cmd>> vhost_work_queue(&vs->dev, &vs->vs_completion_work);
+	 *   - drivers/vhost/scsi.c|638| <<vhost_scsi_complete_cmd_work>> vs_completion_work);
+	 *   - drivers/vhost/scsi.c|1296| <<vhost_scsi_flush>> vhost_work_flush(&vs->dev, &vs->vs_completion_work);
+	 *   - drivers/vhost/scsi.c|1551| <<vhost_scsi_open>> vhost_work_init(&vs->vs_completion_work, vhost_scsi_complete_cmd_work);
+	 */
 	struct vhost_work vs_completion_work; /* cmd completion work item */
+	/*
+	 * 在以下使用vhost_scsi->vs_completion_list:
+	 *   - drivers/vhost/scsi.c|467| <<vhost_scsi_complete_cmd>> llist_add(&cmd->tvc_completion_list, &vs->vs_completion_list);
+	 *   - drivers/vhost/scsi.c|648| <<vhost_scsi_complete_cmd_work>> llnode = llist_del_all(&vs->vs_completion_list);
+	 */
 	struct llist_head vs_completion_list; /* cmd completion queue */
 
+	/*
+	 * 在以下使用vhost_scsi->vs_event_work:
+	 *   - drivers/vhost/scsi.c|701| <<vhost_scsi_evt_work>> vs_event_work);
+	 *   - drivers/vhost/scsi.c|1444| <<vhost_scsi_send_evt>> vhost_work_queue(&vs->dev, &vs->vs_event_work);
+	 *   - drivers/vhost/scsi.c|1528| <<vhost_scsi_flush>> vhost_work_flush(&vs->dev, &vs->vs_event_work);
+	 *   - drivers/vhost/scsi.c|1823| <<vhost_scsi_open>> vhost_work_init(&vs->vs_event_work, vhost_scsi_evt_work);
+	 */
 	struct vhost_work vs_event_work; /* evt injection work item */
+	/*
+	 * 在以下使用vhost_scsi->vs_event_list:
+	 *   - drivers/vhost/scsi.c|707| <<vhost_scsi_evt_work>> llnode = llist_del_all(&vs->vs_event_list);
+	 *   - drivers/vhost/scsi.c|1443| <<vhost_scsi_send_evt>> llist_add(&evt->list, &vs->vs_event_list);
+	 */
 	struct llist_head vs_event_list; /* evt injection queue */
 
+	/*
+	 * 在以下使用vhost_scsi->vs_events_missed:
+	 *   - drivers/vhost/scsi.c|572| <<vhost_scsi_allocate_evt>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|579| <<vhost_scsi_allocate_evt>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|617| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|627| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|633| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|640| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|644| <<vhost_scsi_do_evt_work>> if (vs->vs_events_missed) {
+	 *   - drivers/vhost/scsi.c|646| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = false;
+	 *   - drivers/vhost/scsi.c|1320| <<vhost_scsi_evt_handle_kick>> if (vs->vs_events_missed)
+	 *   - drivers/vhost/scsi.c|1625| <<vhost_scsi_open>> vs->vs_events_missed = false;
+	 *   - drivers/vhost/scsi.c|1727| <<vhost_scsi_ioctl>> vs->vs_events_missed = events_missed;
+	 *   - drivers/vhost/scsi.c|1732| <<vhost_scsi_ioctl>> events_missed = vs->vs_events_missed;
+	 */
 	bool vs_events_missed; /* any missed events, protected by vq->mutex */
+	/*
+	 * 在以下使用vhost_scsi->vs_events_nr:
+	 *   - drivers/vhost/scsi.c|556| <<vhost_scsi_free_evt>> vs->vs_events_nr--;
+	 *   - drivers/vhost/scsi.c|571| <<vhost_scsi_allocate_evt>> if (vs->vs_events_nr > VHOST_SCSI_MAX_EVENT) {
+	 *   - drivers/vhost/scsi.c|585| <<vhost_scsi_allocate_evt>> vs->vs_events_nr++;
+	 *   - drivers/vhost/scsi.c|1560| <<vhost_scsi_clear_endpoint>> WARN_ON(vs->vs_events_nr);
+	 *   - drivers/vhost/scsi.c|1624| <<vhost_scsi_open>> vs->vs_events_nr = 0;
+	 */
 	int vs_events_nr; /* num of pending events, protected by vq->mutex */
 };
 
+/*
+ * 在以下使用vhost_scsi_workqueue:
+ *   - drivers/vhost/scsi.c|1045| <<vhost_scsi_handle_vq>> queue_work(vhost_scsi_workqueue, &cmd->work);
+ *   - drivers/vhost/scsi.c|2108| <<vhost_scsi_init>> vhost_scsi_workqueue = alloc_workqueue("vhost_scsi", 0, 0);
+ *   - drivers/vhost/scsi.c|2109| <<vhost_scsi_init>> if (!vhost_scsi_workqueue)
+ *   - drivers/vhost/scsi.c|2125| <<vhost_scsi_init>> destroy_workqueue(vhost_scsi_workqueue);
+ *   - drivers/vhost/scsi.c|2134| <<vhost_scsi_exit>> destroy_workqueue(vhost_scsi_workqueue);
+ */
 static struct workqueue_struct *vhost_scsi_workqueue;
 
 /* Global spinlock to protect vhost_scsi TPG list for vhost IOCTL access */
 static DEFINE_MUTEX(vhost_scsi_mutex);
+/*
+ * 在以下使用vhost_scsi_list:
+ *   - drivers/vhost/scsi.c|1184| <<vhost_scsi_set_endpoint>> list_for_each_entry(tpg, &vhost_scsi_list, tv_tpg_list) {
+ *   - drivers/vhost/scsi.c|1944| <<vhost_scsi_make_tpg>> list_add_tail(&tpg->tv_tpg_list, &vhost_scsi_list);
+ */
 static LIST_HEAD(vhost_scsi_list);
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|280| <<vhost_scsi_put_inflight>> kref_put(&inflight->kref, vhost_scsi_done_inflight);
+ *   - drivers/vhost/scsi.c|1259| <<vhost_scsi_flush>> kref_put(&old_inflight[i]->kref, vhost_scsi_done_inflight);
+ */
 static void vhost_scsi_done_inflight(struct kref *kref)
 {
 	struct vhost_scsi_inflight *inflight;
@@ -218,6 +339,11 @@ static void vhost_scsi_done_inflight(struct kref *kref)
 	complete(&inflight->comp);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1251| <<vhost_scsi_flush>> vhost_scsi_init_inflight(vs, old_inflight);
+ *   - drivers/vhost/scsi.c|1535| <<vhost_scsi_open>> vhost_scsi_init_inflight(vs, NULL);
+ */
 static void vhost_scsi_init_inflight(struct vhost_scsi *vs,
 				    struct vhost_scsi_inflight *old_inflight[])
 {
@@ -236,6 +362,14 @@ static void vhost_scsi_init_inflight(struct vhost_scsi *vs,
 			old_inflight[i] = &vs->vqs[i].inflights[idx];
 
 		/* setup new infight */
+		/*
+		 * struct vhost_scsi *vs:
+		 *  -> struct vhost_dev dev;
+		 *  -> struct vhost_scsi_virtqueue vqs[VHOST_SCSI_MAX_VQ];
+		 *       -> struct vhost_virtqueue vq;
+		 *       -> struct vhost_scsi_inflight inflights[2];
+		 *       -> int inflight_idx;
+		 */
 		vs->vqs[i].inflight_idx = idx ^ 1;
 		new_inflight = &vs->vqs[i].inflights[idx ^ 1];
 		kref_init(&new_inflight->kref);
@@ -245,6 +379,10 @@ static void vhost_scsi_init_inflight(struct vhost_scsi *vs,
 	}
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|701| <<vhost_scsi_get_tag>> cmd->inflight = vhost_scsi_get_inflight(vq);
+ */
 static struct vhost_scsi_inflight *
 vhost_scsi_get_inflight(struct vhost_virtqueue *vq)
 {
@@ -258,26 +396,44 @@ vhost_scsi_get_inflight(struct vhost_virtqueue *vq)
 	return inflight;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|369| <<vhost_scsi_release_cmd>> vhost_scsi_put_inflight(tv_cmd->inflight);
+ */
 static void vhost_scsi_put_inflight(struct vhost_scsi_inflight *inflight)
 {
 	kref_put(&inflight->kref, vhost_scsi_done_inflight);
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.tpg_check_demo_mode = vhost_scsi_check_true()
+ * struct target_core_fabric_ops vhost_scsi_ops.tpg_check_demo_mode_cache = vhost_scsi_check_true()
+ */
 static int vhost_scsi_check_true(struct se_portal_group *se_tpg)
 {
 	return 1;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.tpg_check_demo_mode_write_protect = vhost_scsi_check_false()
+ * struct target_core_fabric_ops vhost_scsi_ops.tpg_check_prod_mode_write_protect = vhost_scsi_check_false()
+ */
 static int vhost_scsi_check_false(struct se_portal_group *se_tpg)
 {
 	return 0;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.get_fabric_name = vhost_scsi_get_fabric_name()
+ */
 static char *vhost_scsi_get_fabric_name(void)
 {
 	return "vhost";
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.tpg_get_wwn = vhost_scsi_get_fabric_wwn()
+ */
 static char *vhost_scsi_get_fabric_wwn(struct se_portal_group *se_tpg)
 {
 	struct vhost_scsi_tpg *tpg = container_of(se_tpg,
@@ -287,6 +443,9 @@ static char *vhost_scsi_get_fabric_wwn(struct se_portal_group *se_tpg)
 	return &tport->tport_name[0];
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.tpg_get_tag = vhost_scsi_get_tpgt()
+ */
 static u16 vhost_scsi_get_tpgt(struct se_portal_group *se_tpg)
 {
 	struct vhost_scsi_tpg *tpg = container_of(se_tpg,
@@ -294,6 +453,9 @@ static u16 vhost_scsi_get_tpgt(struct se_portal_group *se_tpg)
 	return tpg->tport_tpgt;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.tpg_check_prot_fabric_only = vhost_scsi_check_prot_fabric_only()
+ */
 static int vhost_scsi_check_prot_fabric_only(struct se_portal_group *se_tpg)
 {
 	struct vhost_scsi_tpg *tpg = container_of(se_tpg,
@@ -302,11 +464,17 @@ static int vhost_scsi_check_prot_fabric_only(struct se_portal_group *se_tpg)
 	return tpg->tv_fabric_prot_type;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.tpg_get_inst_index = vhost_scsi_tpg_get_inst_index()
+ */
 static u32 vhost_scsi_tpg_get_inst_index(struct se_portal_group *se_tpg)
 {
 	return 1;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.release_cmd = vhost_scsi_release_cmd()
+ */
 static void vhost_scsi_release_cmd(struct se_cmd *se_cmd)
 {
 	struct vhost_scsi_cmd *tv_cmd = container_of(se_cmd,
@@ -327,50 +495,113 @@ static void vhost_scsi_release_cmd(struct se_cmd *se_cmd)
 	percpu_ida_free(&se_sess->sess_tag_pool, se_cmd->map_tag);
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.sess_get_index = vhost_scsi_sess_get_index()
+ */
 static u32 vhost_scsi_sess_get_index(struct se_session *se_sess)
 {
 	return 0;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.write_pending = vhost_scsi_write_pending()
+ */
 static int vhost_scsi_write_pending(struct se_cmd *se_cmd)
 {
 	/* Go ahead and process the write immediately */
+	/*
+	 * called by:
+	 *   - drivers/infiniband/ulp/isert/ib_isert.c|1743| <<isert_rdma_read_done>> target_execute_cmd(se_cmd);
+	 *   - drivers/infiniband/ulp/srpt/ib_srpt.c|1304| <<srpt_rdma_read_done>> target_execute_cmd(&ioctx->cmd);
+	 *   - drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c|3795| <<ibmvscsis_write_pending>> target_execute_cmd(se_cmd);
+	 *   - drivers/scsi/qla2xxx/tcm_qla2xxx.c|549| <<tcm_qla2xxx_handle_data_work>> return target_execute_cmd(&cmd->se_cmd);
+	 *   - drivers/target/iscsi/iscsi_target.c|1668| <<iscsit_check_dataout_payload>> target_execute_cmd(&cmd->se_cmd);
+	 *   - drivers/target/iscsi/iscsi_target_erl1.c|970| <<iscsit_execute_cmd>> target_execute_cmd(&cmd->se_cmd);
+	 *   - drivers/target/iscsi/iscsi_target_tmr.c|264| <<iscsit_task_reassign_complete_write>> target_execute_cmd(se_cmd);
+	 *   - drivers/target/loopback/tcm_loop.c|567| <<tcm_loop_write_pending>> target_execute_cmd(se_cmd);
+	 *   - drivers/target/sbp/sbp_target.c|1753| <<sbp_write_pending>> target_execute_cmd(se_cmd);
+	 *   - drivers/target/target_core_transport.c|2509| <<transport_generic_new_cmd>> target_execute_cmd(cmd);
+	 *   - drivers/target/target_core_xcopy.c|659| <<target_xcopy_issue_pt_cmd>> target_execute_cmd(se_cmd);
+	 *   - drivers/target/tcm_fc/tfc_io.c|203| <<ft_execute_work>> target_execute_cmd(&cmd->se_cmd);
+	 *   - drivers/usb/gadget/function/f_tcm.c|283| <<bot_send_write_request>> target_execute_cmd(se_cmd);
+	 *   - drivers/usb/gadget/function/f_tcm.c|712| <<uasp_send_write_request>> target_execute_cmd(se_cmd);
+	 *   - drivers/vhost/scsi.c|351| <<vhost_scsi_write_pending>> target_execute_cmd(se_cmd);
+	 *   - drivers/xen/xen-scsiback.c|1393| <<scsiback_write_pending>> target_execute_cmd(se_cmd);
+	 */
 	target_execute_cmd(se_cmd);
 	return 0;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.write_pending_status = vhost_scsi_write_pending_status()
+ */
 static int vhost_scsi_write_pending_status(struct se_cmd *se_cmd)
 {
 	return 0;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.set_default_node_attributes = vhost_scsi_set_default_node_attrs()
+ */
 static void vhost_scsi_set_default_node_attrs(struct se_node_acl *nacl)
 {
 	return;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.get_cmd_state = vhost_scsi_get_cmd_state()
+ */
 static int vhost_scsi_get_cmd_state(struct se_cmd *se_cmd)
 {
 	return 0;
 }
 
+/*
+ * [0] vhost_scsi_complete_cmd
+ * [0] target_complete_ok_work
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * called by:
+ *   - drivers/vhost/scsi.c|383| <<vhost_scsi_queue_data_in>> vhost_scsi_complete_cmd(cmd);
+ *   - drivers/vhost/scsi.c|391| <<vhost_scsi_queue_status>> vhost_scsi_complete_cmd(cmd);
+ */
 static void vhost_scsi_complete_cmd(struct vhost_scsi_cmd *cmd)
 {
 	struct vhost_scsi *vs = cmd->tvc_vhost;
 
 	llist_add(&cmd->tvc_completion_list, &vs->vs_completion_list);
 
+	/*
+	 * 在以下使用vhost_scsi->vs_completion_work:
+	 *   - drivers/vhost/scsi.c|469| <<vhost_scsi_complete_cmd>> vhost_work_queue(&vs->dev, &vs->vs_completion_work);
+	 *   - drivers/vhost/scsi.c|638| <<vhost_scsi_complete_cmd_work>> vs_completion_work);
+	 *   - drivers/vhost/scsi.c|1296| <<vhost_scsi_flush>> vhost_work_flush(&vs->dev, &vs->vs_completion_work);
+	 *   - drivers/vhost/scsi.c|1551| <<vhost_scsi_open>> vhost_work_init(&vs->vs_completion_work, vhost_scsi_complete_cmd_work);
+	 */
 	vhost_work_queue(&vs->dev, &vs->vs_completion_work);
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.queue_data_in = vhost_scsi_queue_data_in()
+ */
 static int vhost_scsi_queue_data_in(struct se_cmd *se_cmd)
 {
+	/*
+	 * struct vhost_scsi_cmd:
+	 *  -> struct se_cmd tvc_se_cmd;
+	 */
 	struct vhost_scsi_cmd *cmd = container_of(se_cmd,
 				struct vhost_scsi_cmd, tvc_se_cmd);
 	vhost_scsi_complete_cmd(cmd);
 	return 0;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.queue_status = vhost_scsi_queue_status()
+ */
 static int vhost_scsi_queue_status(struct se_cmd *se_cmd)
 {
 	struct vhost_scsi_cmd *cmd = container_of(se_cmd,
@@ -379,11 +610,17 @@ static int vhost_scsi_queue_status(struct se_cmd *se_cmd)
 	return 0;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.queue_tm_rsp = vhost_scsi_queue_tm_rsp()
+ */
 static void vhost_scsi_queue_tm_rsp(struct se_cmd *se_cmd)
 {
 	return;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.aborted_task = vhost_scsi_aborted_task()
+ */
 static void vhost_scsi_aborted_task(struct se_cmd *se_cmd)
 {
 	return;
@@ -395,6 +632,10 @@ static void vhost_scsi_free_evt(struct vhost_scsi *vs, struct vhost_scsi_evt *ev
 	kfree(evt);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1187| <<vhost_scsi_send_evt>> evt = vhost_scsi_allocate_evt(vs, event, reason);
+ */
 static struct vhost_scsi_evt *
 vhost_scsi_allocate_evt(struct vhost_scsi *vs,
 		       u32 event, u32 reason)
@@ -430,11 +671,18 @@ static void vhost_scsi_free_cmd(struct vhost_scsi_cmd *cmd)
 
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.check_stop_free = vhost_scsi_check_stop_free()
+ */
 static int vhost_scsi_check_stop_free(struct se_cmd *se_cmd)
 {
 	return target_put_sess_cmd(se_cmd);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|743| <<vhost_scsi_evt_work>> vhost_scsi_do_evt_work(vs, evt);
+ */
 static void
 vhost_scsi_do_evt_work(struct vhost_scsi *vs, struct vhost_scsi_evt *evt)
 {
@@ -485,6 +733,13 @@ vhost_scsi_do_evt_work(struct vhost_scsi *vs, struct vhost_scsi_evt *evt)
 		vq_err(vq, "Faulted on vhost_scsi_send_event\n");
 }
 
+/*
+ * 在以下使用vhost_scsi->vs_event_work:
+ *   - drivers/vhost/scsi.c|701| <<vhost_scsi_evt_work>> vs_event_work);
+ *   - drivers/vhost/scsi.c|1444| <<vhost_scsi_send_evt>> vhost_work_queue(&vs->dev, &vs->vs_event_work);
+ *   - drivers/vhost/scsi.c|1528| <<vhost_scsi_flush>> vhost_work_flush(&vs->dev, &vs->vs_event_work);
+ *   - drivers/vhost/scsi.c|1823| <<vhost_scsi_open>> vhost_work_init(&vs->vs_event_work, vhost_scsi_evt_work);
+ */
 static void vhost_scsi_evt_work(struct vhost_work *work)
 {
 	struct vhost_scsi *vs = container_of(work, struct vhost_scsi,
@@ -507,8 +762,34 @@ static void vhost_scsi_evt_work(struct vhost_work *work)
  * This is scheduled in the vhost work queue so we are called with the owner
  * process mm and can access the vring.
  */
+/*
+ * 调用的例子:
+ * [0] target_complete_cmd
+ * [0] fd_execute_rw
+ * [0] sbc_execute_rw
+ * [0] __target_execute_cmd
+ * [0] target_execute_cmd
+ * [0] transport_generic_new_cmd
+ * [0] transport_handle_cdb_direct
+ * [0] target_submit_cmd_map_sgls
+ * [0] vhost_scsi_submission_work
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * 在以下使用vhost_scsi->vs_completion_work:
+ *   - drivers/vhost/scsi.c|469| <<vhost_scsi_complete_cmd>> vhost_work_queue(&vs->dev, &vs->vs_completion_work);
+ *   - drivers/vhost/scsi.c|638| <<vhost_scsi_complete_cmd_work>> vs_completion_work);
+ *   - drivers/vhost/scsi.c|1296| <<vhost_scsi_flush>> vhost_work_flush(&vs->dev, &vs->vs_completion_work);
+ *   - drivers/vhost/scsi.c|1551| <<vhost_scsi_open>> vhost_work_init(&vs->vs_completion_work, vhost_scsi_complete_cmd_work);
+ */
 static void vhost_scsi_complete_cmd_work(struct vhost_work *work)
 {
+	/*
+	 * struct vhost_scsi:
+	 *  -> struct vhost_work vs_completion_work;
+	 */
 	struct vhost_scsi *vs = container_of(work, struct vhost_scsi,
 					vs_completion_work);
 	DECLARE_BITMAP(signal, VHOST_SCSI_MAX_VQ);
@@ -519,14 +800,30 @@ static void vhost_scsi_complete_cmd_work(struct vhost_work *work)
 	struct iov_iter iov_iter;
 	int ret, vq;
 
+	/* 上面声明的DECLARE_BITMAP(signal, VHOST_SCSI_MAX_VQ); */
 	bitmap_zero(signal, VHOST_SCSI_MAX_VQ);
+	/*
+	 * If list is empty, return NULL, otherwise, delete all entries and
+	 * return the pointer to the first entry.  The order of entries
+	 * deleted is from the newest to the oldest added one.
+	 *
+	 * 在以下使用vhost_scsi->vs_completion_list:
+	 *   - drivers/vhost/scsi.c|467| <<vhost_scsi_complete_cmd>> llist_add(&cmd->tvc_completion_list, &vs->vs_completion_list);
+	 *   - drivers/vhost/scsi.c|648| <<vhost_scsi_complete_cmd_work>> llnode = llist_del_all(&vs->vs_completion_list);
+	 */
 	llnode = llist_del_all(&vs->vs_completion_list);
+	/*
+	 * struct vhost_scsi_cmd *cmd;
+	 */
 	llist_for_each_entry_safe(cmd, t, llnode, tvc_completion_list) {
 		se_cmd = &cmd->tvc_se_cmd;
 
 		pr_debug("%s tv_cmd %p resid %u status %#02x\n", __func__,
 			cmd, se_cmd->residual_count, se_cmd->scsi_status);
 
+		/*
+		 * struct virtio_scsi_cmd_resp v_rsp;
+		 */
 		memset(&v_rsp, 0, sizeof(v_rsp));
 		v_rsp.resid = cpu_to_vhost32(cmd->tvc_vq, se_cmd->residual_count);
 		/* TODO is status_qualifier field needed? */
@@ -541,6 +838,11 @@ static void vhost_scsi_complete_cmd_work(struct vhost_work *work)
 		ret = copy_to_iter(&v_rsp, sizeof(v_rsp), &iov_iter);
 		if (likely(ret == sizeof(v_rsp))) {
 			struct vhost_scsi_virtqueue *q;
+			/*
+			 * 在以下使用vhost_scsi_cmd->tvc_vq_desc:
+			 *   - drivers/vhost/scsi.c|731| <<vhost_scsi_complete_cmd_work>> vhost_add_used(cmd->tvc_vq, cmd->tvc_vq_desc, 0);
+			 *   - drivers/vhost/scsi.c|1261| <<vhost_scsi_handle_vq>> cmd->tvc_vq_desc = head;
+			 */
 			vhost_add_used(cmd->tvc_vq, cmd->tvc_vq_desc, 0);
 			q = container_of(cmd->tvc_vq, struct vhost_scsi_virtqueue, vq);
 			vq = q - vs->vqs;
@@ -552,16 +854,26 @@ static void vhost_scsi_complete_cmd_work(struct vhost_work *work)
 	}
 
 	vq = -1;
+	/*
+	 * 根据情况用eventfd_signal()通知call_ctx
+	 */
 	while ((vq = find_next_bit(signal, VHOST_SCSI_MAX_VQ, vq + 1))
 		< VHOST_SCSI_MAX_VQ)
 		vhost_signal(&vs->dev, &vs->vqs[vq].vq);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1002| <<vhost_scsi_handle_vq>> cmd = vhost_scsi_get_tag(vq, tpg, cdb, tag, lun, task_attr,
+ */
 static struct vhost_scsi_cmd *
 vhost_scsi_get_tag(struct vhost_virtqueue *vq, struct vhost_scsi_tpg *tpg,
 		   unsigned char *cdb, u64 scsi_tag, u16 lun, u8 task_attr,
 		   u32 exp_data_len, int data_direction)
 {
+	/*
+	 * 包含一个 struct se_cmd tvc_se_cmd;
+	 */
 	struct vhost_scsi_cmd *cmd;
 	struct vhost_scsi_nexus *tv_nexus;
 	struct se_session *se_sess;
@@ -609,6 +921,10 @@ vhost_scsi_get_tag(struct vhost_virtqueue *vq, struct vhost_scsi_tpg *tpg,
  *
  * Returns the number of scatterlist entries used or -errno on error.
  */
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|771| <<vhost_scsi_iov_to_sgl>> ret = vhost_scsi_map_to_sgl(cmd, iter, sg, write);
+ */
 static int
 vhost_scsi_map_to_sgl(struct vhost_scsi_cmd *cmd,
 		      struct iov_iter *iter,
@@ -638,6 +954,11 @@ vhost_scsi_map_to_sgl(struct vhost_scsi_cmd *cmd,
 	return npages;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1005| <<vhost_scsi_mapal>> sgl_count = vhost_scsi_calc_sgls(prot_iter, prot_bytes,
+ *   - drivers/vhost/scsi.c|1023| <<vhost_scsi_mapal>> sgl_count = vhost_scsi_calc_sgls(data_iter, data_bytes,
+ */
 static int
 vhost_scsi_calc_sgls(struct iov_iter *iter, size_t bytes, int max_sgls)
 {
@@ -658,6 +979,11 @@ vhost_scsi_calc_sgls(struct iov_iter *iter, size_t bytes, int max_sgls)
 	return sgl_count;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|976| <<vhost_scsi_mapal>> ret = vhost_scsi_iov_to_sgl(cmd, write, prot_iter,
+ *   - drivers/vhost/scsi.c|994| <<vhost_scsi_mapal>> ret = vhost_scsi_iov_to_sgl(cmd, write, data_iter,
+ */
 static int
 vhost_scsi_iov_to_sgl(struct vhost_scsi_cmd *cmd, bool write,
 		      struct iov_iter *iter,
@@ -681,6 +1007,10 @@ vhost_scsi_iov_to_sgl(struct vhost_scsi_cmd *cmd, bool write,
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1228| <<vhost_scsi_handle_vq>> ret = vhost_scsi_mapal(cmd,
+ */
 static int
 vhost_scsi_mapal(struct vhost_scsi_cmd *cmd,
 		 size_t prot_bytes, struct iov_iter *prot_iter,
@@ -727,6 +1057,10 @@ vhost_scsi_mapal(struct vhost_scsi_cmd *cmd,
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1086| <<vhost_scsi_submission_work>> vhost_scsi_to_tcm_attr(cmd->tvc_task_attr),
+ */
 static int vhost_scsi_to_tcm_attr(int attr)
 {
 	switch (attr) {
@@ -744,6 +1078,38 @@ static int vhost_scsi_to_tcm_attr(int attr)
 	return TCM_SIMPLE_TAG;
 }
 
+/*
+ * 两个callstack的例子 (第一个次数少,第二个次数多):
+ * 都是基于file的例子
+ *
+ * [0] fd_execute_rw
+ * [0] __target_execute_cmd
+ * [0] target_execute_cmd
+ * [0] vhost_scsi_write_pending
+ * [0] transport_generic_new_cmd
+ * [0] transport_handle_cdb_direct
+ * [0] target_submit_cmd_map_sgls
+ * [0] vhost_scsi_submission_work
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] fd_execute_rw
+ * [0] __target_execute_cmd
+ * [0] target_execute_cmd
+ * [0] transport_generic_new_cmd
+ * [0] transport_handle_cdb_direct
+ * [0] target_submit_cmd_map_sgls
+ * [0] vhost_scsi_submission_work
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * 在以下使用vhost_scsi_submission_work():
+ *   - drivers/vhost/scsi.c|1044| <<vhost_scsi_handle_vq>> INIT_WORK(&cmd->work, vhost_scsi_submission_work);
+ */
 static void vhost_scsi_submission_work(struct work_struct *work)
 {
 	struct vhost_scsi_cmd *cmd =
@@ -767,6 +1133,14 @@ static void vhost_scsi_submission_work(struct work_struct *work)
 	tv_nexus = cmd->tvc_nexus;
 
 	se_cmd->tag = 0;
+	/*
+	 * called by:
+	 *   - drivers/infiniband/ulp/srpt/ib_srpt.c|1468| <<srpt_handle_cmd>> rc = target_submit_cmd_map_sgls(cmd, ch->sess, srp_cmd->cdb,
+	 *   - drivers/target/loopback/tcm_loop.c|153| <<tcm_loop_submission_work>> rc = target_submit_cmd_map_sgls(se_cmd, tl_nexus->se_sess, sc->cmnd,
+	 *   - drivers/target/target_core_transport.c|1609| <<target_submit_cmd>> return target_submit_cmd_map_sgls(se_cmd, se_sess, cdb, sense,
+	 *   - drivers/vhost/scsi.c|770| <<vhost_scsi_submission_work>> rc = target_submit_cmd_map_sgls(se_cmd, tv_nexus->tvn_se_sess,
+	 *   - drivers/xen/xen-scsiback.c|404| <<scsiback_cmd_exec>> rc = target_submit_cmd_map_sgls(se_cmd, sess, pending_req->cmnd,
+	 */
 	rc = target_submit_cmd_map_sgls(se_cmd, tv_nexus->tvn_se_sess,
 			cmd->tvc_cdb, &cmd->tvc_sense_buf[0],
 			cmd->tvc_lun, cmd->tvc_exp_data_len,
@@ -781,6 +1155,17 @@ static void vhost_scsi_submission_work(struct work_struct *work)
 	}
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1179| <<vhost_scsi_handle_vq>> vhost_scsi_send_bad_target(vs, vq, head, out);
+ *   - drivers/vhost/scsi.c|1185| <<vhost_scsi_handle_vq>> vhost_scsi_send_bad_target(vs, vq, head, out);
+ *   - drivers/vhost/scsi.c|1192| <<vhost_scsi_handle_vq>> vhost_scsi_send_bad_target(vs, vq, head, out);
+ *   - drivers/vhost/scsi.c|1238| <<vhost_scsi_handle_vq>> vhost_scsi_send_bad_target(vs, vq, head, out);
+ *   - drivers/vhost/scsi.c|1246| <<vhost_scsi_handle_vq>> vhost_scsi_send_bad_target(vs, vq, head, out);
+ *   - drivers/vhost/scsi.c|1284| <<vhost_scsi_handle_vq>> vhost_scsi_send_bad_target(vs, vq, head, out);
+ *   - drivers/vhost/scsi.c|1293| <<vhost_scsi_handle_vq>> vhost_scsi_send_bad_target(vs, vq, head, out);
+ *   - drivers/vhost/scsi.c|1313| <<vhost_scsi_handle_vq>> vhost_scsi_send_bad_target(vs, vq, head, out);
+ */
 static void
 vhost_scsi_send_bad_target(struct vhost_scsi *vs,
 			   struct vhost_virtqueue *vq,
@@ -800,6 +1185,15 @@ vhost_scsi_send_bad_target(struct vhost_scsi *vs,
 		pr_err("Faulted on virtio_scsi_cmd_resp\n");
 }
 
+/*
+ * [0] vhost_scsi_handle_vq
+ * [0] vhost_worker
+ * [0] kthread
+ * [0] ret_from_for
+ *
+ * called by:
+ *   - drivers/vhost/scsi.c|1108| <<vhost_scsi_handle_kick>> vhost_scsi_handle_vq(vs, vq);
+ */
 static void
 vhost_scsi_handle_vq(struct vhost_scsi *vs, struct vhost_virtqueue *vq)
 {
@@ -824,13 +1218,26 @@ vhost_scsi_handle_vq(struct vhost_scsi *vs, struct vhost_virtqueue *vq)
 	 * We can handle the vq only after the endpoint is setup by calling the
 	 * VHOST_SCSI_SET_ENDPOINT ioctl.
 	 */
+	/*
+	 * struct vhost_scsi_tpg **vs_tpg.
+	 * 之前用VHOST_SCSI_SET_ENDPOINT设置的
+	 */
 	vs_tpg = vq->private_data;
 	if (!vs_tpg)
 		goto out;
 
+	/* 如果不支持VIRTIO_RING_F_EVENT_IDX 在vq->used->flags中通知guest VRING_USED_F_NO_NOTIFY */
 	vhost_disable_notify(&vs->dev, vq);
 
 	for (;;) {
+		/*
+		 * struct vhost_virtqueue *vq:
+		 *  -> struct iovec iov[UIO_MAXIOV];
+		 *       -> void __user *iov_base;  // BSD uses caddr_t (1003.1g requires void *)
+		 *       -> __kernel_size_t iov_len; // Must be size_t (1003.1g)
+		 *
+		 * 把desc中的信息拷贝到iov (地址会转换成qemu userspace的地址)
+		 */
 		head = vhost_get_vq_desc(vq, vq->iov,
 					 ARRAY_SIZE(vq->iov), &out, &in,
 					 NULL, NULL);
@@ -861,19 +1268,42 @@ vhost_scsi_handle_vq(struct vhost_scsi *vs, struct vhost_virtqueue *vq)
 		 * request header if T10_PI is enabled in KVM guest.
 		 */
 		if (t10_pi) {
+			/*
+			 * struct virtio_scsi_cmd_req v_req;
+			 * struct virtio_scsi_cmd_req_pi v_req_pi;
+			 */
 			req = &v_req_pi;
 			req_size = sizeof(v_req_pi);
 			lunp = &v_req_pi.lun[0];
 			target = &v_req_pi.lun[1];
 		} else {
+			/*
+			 * struct virtio_scsi_cmd_req v_req;
+			 *   -> __u8 lun[8];            // Logical Unit Number
+			 *   -> __virtio64 tag;         // Command identifier
+			 *   -> __u8 task_attr;         // Task attribute
+			 *   -> __u8 prio;              // SAM command priority field
+			 *   -> __u8 crn;
+			 *   -> __u8 cdb[VIRTIO_SCSI_CDB_SIZE];
+			 * struct virtio_scsi_cmd_req_pi v_req_pi;
+			 *
+			 * void *req;
+			 */
 			req = &v_req;
 			req_size = sizeof(v_req);
+			/*
+			 * u8 *target, *lunp;
+			 */
 			lunp = &v_req.lun[0];
 			target = &v_req.lun[1];
 		}
 		/*
 		 * FIXME: Not correct for BIDI operation
 		 */
+		/*
+		 * iov_length():
+		 * Total number of bytes covered by an iovec.
+		 */
 		out_size = iov_length(vq->iov, out);
 		in_size = iov_length(&vq->iov[out], in);
 
@@ -889,6 +1319,14 @@ vhost_scsi_handle_vq(struct vhost_scsi *vs, struct vhost_virtqueue *vq)
 		 */
 		iov_iter_init(&out_iter, WRITE, vq->iov, out, out_size);
 
+		/*
+		 * 假设没有integrity的情况下
+		 * 这里req实际是指向"struct virtio_scsi_cmd_req v_req;"的指针
+		 * req_size就是sizeof(struct virtio_scsi_cmd_req v_req)
+		 *
+		 * !!!!这里的copy_from_iter_full()相当于把out_iter的头上的virtio_scsi_cmd_req部分
+		 * 拷贝到了 req
+		 */
 		if (unlikely(!copy_from_iter_full(req, req_size, &out_iter))) {
 			vq_err(vq, "Faulted on copy_from_iter\n");
 			vhost_scsi_send_bad_target(vs, vq, head, out);
@@ -901,6 +1339,7 @@ vhost_scsi_handle_vq(struct vhost_scsi *vs, struct vhost_virtqueue *vq)
 			continue;
 		}
 
+		/* struct vhost_scsi_tpg **vs_tpg, *tpg; */
 		tpg = READ_ONCE(vs_tpg[*target]);
 		if (unlikely(!tpg)) {
 			/* Target does not exist, fail the request */
@@ -929,6 +1368,9 @@ vhost_scsi_handle_vq(struct vhost_scsi *vs, struct vhost_virtqueue *vq)
 			exp_data_len = out_size - req_size;
 			data_iter = out_iter;
 		} else if (in_size > rsp_size) {
+			/*
+			 * size_t rsp_size = sizeof(struct virtio_scsi_cmd_resp);
+			 */
 			data_direction = DMA_FROM_DEVICE;
 			exp_data_len = in_size - rsp_size;
 
@@ -999,6 +1441,9 @@ vhost_scsi_handle_vq(struct vhost_scsi *vs, struct vhost_virtqueue *vq)
 			vhost_scsi_send_bad_target(vs, vq, head, out);
 			continue;
 		}
+		/*
+		 * struct vhost_scsi_cmd *cmd;
+		 */
 		cmd = vhost_scsi_get_tag(vq, tpg, cdb, tag, lun, task_attr,
 					 exp_data_len + prot_bytes,
 					 data_direction);
@@ -1034,6 +1479,11 @@ vhost_scsi_handle_vq(struct vhost_scsi *vs, struct vhost_virtqueue *vq)
 		 * complete the virtio-scsi request in TCM callback context via
 		 * vhost_scsi_queue_data_in() and vhost_scsi_queue_status()
 		 */
+		/*
+		 * 在以下使用vhost_scsi_cmd->tvc_vq_desc:
+		 *   - drivers/vhost/scsi.c|731| <<vhost_scsi_complete_cmd_work>> vhost_add_used(cmd->tvc_vq, cmd->tvc_vq_desc, 0);
+		 *   - drivers/vhost/scsi.c|1261| <<vhost_scsi_handle_vq>> cmd->tvc_vq_desc = head;
+		 */
 		cmd->tvc_vq_desc = head;
 		/*
 		 * Dispatch cmd descriptor for cmwq execution in process
@@ -1048,11 +1498,20 @@ vhost_scsi_handle_vq(struct vhost_scsi *vs, struct vhost_virtqueue *vq)
 	mutex_unlock(&vq->mutex);
 }
 
+/*
+ * 在以下使用vhost_scsi_ctl_handle_kick():
+ *   - drivers/vhost/scsi.c|1854| <<vhost_scsi_open>> vs->vqs[VHOST_SCSI_VQ_CTL].vq.handle_kick = vhost_scsi_ctl_handle_kick;
+ */
 static void vhost_scsi_ctl_handle_kick(struct vhost_work *work)
 {
 	pr_debug("%s: The handling func for control queue.\n", __func__);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1458| <<vhost_scsi_evt_handle_kick>> vhost_scsi_send_evt(vs, NULL, NULL, VIRTIO_SCSI_T_NO_EVENT, 0);
+ *   - drivers/vhost/scsi.c|2063| <<vhost_scsi_do_plug>> vhost_scsi_send_evt(vs, tpg, lun,
+ */
 static void
 vhost_scsi_send_evt(struct vhost_scsi *vs,
 		   struct vhost_scsi_tpg *tpg,
@@ -1079,10 +1538,26 @@ vhost_scsi_send_evt(struct vhost_scsi *vs,
 		evt->event.lun[3] = lun->unpacked_lun & 0xFF;
 	}
 
+	/*
+	 * 在以下使用vhost_scsi->vs_event_list:
+	 *   - drivers/vhost/scsi.c|707| <<vhost_scsi_evt_work>> llnode = llist_del_all(&vs->vs_event_list);
+	 *   - drivers/vhost/scsi.c|1443| <<vhost_scsi_send_evt>> llist_add(&evt->list, &vs->vs_event_list);
+	 */
 	llist_add(&evt->list, &vs->vs_event_list);
+	/*
+	 * 在以下使用vhost_scsi->vs_event_work:
+	 *   - drivers/vhost/scsi.c|701| <<vhost_scsi_evt_work>> vs_event_work);
+	 *   - drivers/vhost/scsi.c|1444| <<vhost_scsi_send_evt>> vhost_work_queue(&vs->dev, &vs->vs_event_work);
+	 *   - drivers/vhost/scsi.c|1528| <<vhost_scsi_flush>> vhost_work_flush(&vs->dev, &vs->vs_event_work);
+	 *   - drivers/vhost/scsi.c|1823| <<vhost_scsi_open>> vhost_work_init(&vs->vs_event_work, vhost_scsi_evt_work);
+	 */
 	vhost_work_queue(&vs->dev, &vs->vs_event_work);
 }
 
+/*
+ * 在以下使用vhost_scsi_evt_handle_kick():
+ *   - drivers/vhost/scsi.c|1855| <<vhost_scsi_open>> vs->vqs[VHOST_SCSI_VQ_EVT].vq.handle_kick = vhost_scsi_evt_handle_kick;
+ */
 static void vhost_scsi_evt_handle_kick(struct vhost_work *work)
 {
 	struct vhost_virtqueue *vq = container_of(work, struct vhost_virtqueue,
@@ -1099,21 +1574,61 @@ static void vhost_scsi_evt_handle_kick(struct vhost_work *work)
 	mutex_unlock(&vq->mutex);
 }
 
+/*
+ * 在以下设置vhost_virtqueue->handle_kick:
+ *   - drivers/vhost/net.c|1129| <<vhost_net_open>> n->vqs[VHOST_NET_VQ_TX].vq.handle_kick = handle_tx_kick;
+ *   - drivers/vhost/net.c|1130| <<vhost_net_open>> n->vqs[VHOST_NET_VQ_RX].vq.handle_kick = handle_rx_kick;
+ *   - drivers/vhost/scsi.c|1611| <<vhost_scsi_open>> vs->vqs[VHOST_SCSI_VQ_CTL].vq.handle_kick = vhost_scsi_ctl_handle_kick;
+ *   - drivers/vhost/scsi.c|1612| <<vhost_scsi_open>> vs->vqs[VHOST_SCSI_VQ_EVT].vq.handle_kick = vhost_scsi_evt_handle_kick;
+ *   - drivers/vhost/scsi.c|1615| <<vhost_scsi_open>> vs->vqs[i].vq.handle_kick = vhost_scsi_handle_kick;
+ *   - drivers/vhost/test.c|118| <<vhost_test_open>> n->vqs[VHOST_TEST_VQ].handle_kick = handle_vq_kick;
+ *   - drivers/vhost/vsock.c|527| <<vhost_vsock_dev_open>> vsock->vqs[VSOCK_VQ_TX].handle_kick = vhost_vsock_handle_tx_kick;
+ *   - drivers/vhost/vsock.c|528| <<vhost_vsock_dev_open>> vsock->vqs[VSOCK_VQ_RX].handle_kick = vhost_vsock_handle_rx_kick;
+ *
+ * 在以下一处会调用相关:
+ *   - drivers/vhost/vhost.c|580| <<vhost_dev_init>> vhost_poll_init(&vq->poll, vq->handle_kick,
+ *     579                 if (vq->handle_kick)
+ *     580                         vhost_poll_init(&vq->poll, vq->handle_kick,
+ *     581                                         EPOLLIN, dev);
+ *
+ * [0] vhost_scsi_handle_kick
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * 在以下使用vhost_scsi_handle_kick():
+ *   - drivers/vhost/scsi.c|1650| <<vhost_scsi_open>> vs->vqs[i].vq.handle_kick = vhost_scsi_handle_kick;
+ */
 static void vhost_scsi_handle_kick(struct vhost_work *work)
 {
 	struct vhost_virtqueue *vq = container_of(work, struct vhost_virtqueue,
 						poll.work);
 	struct vhost_scsi *vs = container_of(vq->dev, struct vhost_scsi, dev);
 
+	/*
+	 * [0] vhost_scsi_handle_vq
+	 * [0] vhost_worker
+	 * [0] kthread
+	 * [0] ret_from_for
+	 */
 	vhost_scsi_handle_vq(vs, vq);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1526| <<vhost_scsi_flush>> vhost_scsi_flush_vq(vs, i);
+ */
 static void vhost_scsi_flush_vq(struct vhost_scsi *vs, int index)
 {
 	vhost_poll_flush(&vs->vqs[index].vq.poll);
 }
 
 /* Callers must hold dev mutex */
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1667| <<vhost_scsi_set_endpoint>> vhost_scsi_flush(vs);
+ *   - drivers/vhost/scsi.c|1749| <<vhost_scsi_clear_endpoint>> vhost_scsi_flush(vs);
+ *   - drivers/vhost/scsi.c|1894| <<vhost_scsi_release>> vhost_scsi_flush(vs);
+ */
 static void vhost_scsi_flush(struct vhost_scsi *vs)
 {
 	struct vhost_scsi_inflight *old_inflight[VHOST_SCSI_MAX_VQ];
@@ -1148,6 +1663,14 @@ static void vhost_scsi_flush(struct vhost_scsi *vs)
  *  The lock nesting rule is:
  *    vhost_scsi_mutex -> vs->dev.mutex -> tpg->tv_tpg_mutex -> vq->mutex
  */
+/*
+ * 第二个参数从userspace传入的.
+ * struct vhost_scsi_target backend:
+ *   -> int abi_version;
+ *   -> char vhost_wwpn[224];
+ *   -> unsigned short vhost_tpgt;
+ *   -> unsigned short reserved;
+ */
 static int
 vhost_scsi_set_endpoint(struct vhost_scsi *vs,
 			struct vhost_scsi_target *t)
@@ -1181,18 +1704,41 @@ vhost_scsi_set_endpoint(struct vhost_scsi *vs,
 	if (vs->vs_tpg)
 		memcpy(vs_tpg, vs->vs_tpg, len);
 
+	/*
+	 * 在以下使用vhost_scsi_list:
+	 *   - drivers/vhost/scsi.c|1184| <<vhost_scsi_set_endpoint>> list_for_each_entry(tpg, &vhost_scsi_list, tv_tpg_list) {
+	 *   - drivers/vhost/scsi.c|1944| <<vhost_scsi_make_tpg>> list_add_tail(&tpg->tv_tpg_list, &vhost_scsi_list);
+	 *
+	 * struct vhost_scsi_tpg *tpg:
+	 */
 	list_for_each_entry(tpg, &vhost_scsi_list, tv_tpg_list) {
 		mutex_lock(&tpg->tv_tpg_mutex);
 		if (!tpg->tpg_nexus) {
 			mutex_unlock(&tpg->tv_tpg_mutex);
 			continue;
 		}
+		/*
+		 * 在以下使用和修改vhost_scsi_tpg->tv_tpg_vhost_count:
+		 *   - drivers/vhost/scsi.c|1447| <<vhost_scsi_set_endpoint>> tpg->tv_tpg_vhost_count++;
+		 *   - drivers/vhost/scsi.c|1533| <<vhost_scsi_clear_endpoint>> tpg->tv_tpg_vhost_count--;
+		 *   - drivers/vhost/scsi.c|1420| <<vhost_scsi_set_endpoint>> if (tpg->tv_tpg_vhost_count != 0) {
+		 *   - drivers/vhost/scsi.c|2056| <<vhost_scsi_drop_nexus>> if (tpg->tv_tpg_vhost_count != 0) {
+		 *   - drivers/vhost/scsi.c|2060| <<vhost_scsi_drop_nexus>> tpg->tv_tpg_vhost_count);
+		 */
 		if (tpg->tv_tpg_vhost_count != 0) {
 			mutex_unlock(&tpg->tv_tpg_mutex);
 			continue;
 		}
+		/*
+		 * struct vhost_scsi_tpg *tpg:
+		 *  -> struct vhost_scsi_tport *tport;
+		 *      -> char tport_name[VHOST_SCSI_NAMELEN];
+		 */
 		tv_tport = tpg->tport;
 
+		/*
+		 * t是传进来的参数
+		 */
 		if (!strcmp(tv_tport->tport_name, t->vhost_wwpn)) {
 			if (vs->vs_tpg && vs->vs_tpg[tpg->tport_tpgt]) {
 				kfree(vs_tpg);
@@ -1340,6 +1886,10 @@ vhost_scsi_clear_endpoint(struct vhost_scsi *vs,
 	return ret;
 }
 
+/*
+ * called by VHOST_SET_FEATURES:
+ *   - drivers/vhost/scsi.c|1962| <<vhost_scsi_ioctl>> return vhost_scsi_set_features(vs, features);
+ */
 static int vhost_scsi_set_features(struct vhost_scsi *vs, u64 features)
 {
 	struct vhost_virtqueue *vq;
@@ -1365,6 +1915,9 @@ static int vhost_scsi_set_features(struct vhost_scsi *vs, u64 features)
 	return 0;
 }
 
+/*
+ * struct file_operations vhost_scsi_fops.open = vhost_scsi_open()
+ */
 static int vhost_scsi_open(struct inode *inode, struct file *f)
 {
 	struct vhost_scsi *vs;
@@ -1378,24 +1931,69 @@ static int vhost_scsi_open(struct inode *inode, struct file *f)
 			goto err_vs;
 	}
 
+	/*
+	 * VHOST_SCSI_MAX_VQ是128
+	 */
 	vqs = kmalloc(VHOST_SCSI_MAX_VQ * sizeof(*vqs), GFP_KERNEL);
 	if (!vqs)
 		goto err_vqs;
 
+	/*
+	 * 核心是:
+	 *  - clear_bit(VHOST_WORK_QUEUED, &vhost_work->flags);
+	 *  - vhost_work->fn = fn;
+	 */
 	vhost_work_init(&vs->vs_completion_work, vhost_scsi_complete_cmd_work);
+	/*
+	 * 在以下使用vhost_scsi->vs_event_work:
+	 *   - drivers/vhost/scsi.c|701| <<vhost_scsi_evt_work>> vs_event_work);
+	 *   - drivers/vhost/scsi.c|1444| <<vhost_scsi_send_evt>> vhost_work_queue(&vs->dev, &vs->vs_event_work);
+	 *   - drivers/vhost/scsi.c|1528| <<vhost_scsi_flush>> vhost_work_flush(&vs->dev, &vs->vs_event_work);
+	 *   - drivers/vhost/scsi.c|1823| <<vhost_scsi_open>> vhost_work_init(&vs->vs_event_work, vhost_scsi_evt_work);
+	 */
 	vhost_work_init(&vs->vs_event_work, vhost_scsi_evt_work);
 
 	vs->vs_events_nr = 0;
 	vs->vs_events_missed = false;
 
+	/*
+	 * struct vhost_scsi *vs:
+	 *   -> struct vhost_dev dev;
+	 *   -> struct vhost_scsi_virtqueue vqs[VHOST_SCSI_MAX_VQ];
+	 *       -> struct vhost_virtqueue vq;
+	 *           -> vhost_work_fn_t handle_kick;
+	 */
 	vqs[VHOST_SCSI_VQ_CTL] = &vs->vqs[VHOST_SCSI_VQ_CTL].vq;
 	vqs[VHOST_SCSI_VQ_EVT] = &vs->vqs[VHOST_SCSI_VQ_EVT].vq;
+	/*
+	 * 在以下设置vhost_virtqueue->handle_kick:
+	 *   - drivers/vhost/net.c|1129| <<vhost_net_open>> n->vqs[VHOST_NET_VQ_TX].vq.handle_kick = handle_tx_kick;
+	 *   - drivers/vhost/net.c|1130| <<vhost_net_open>> n->vqs[VHOST_NET_VQ_RX].vq.handle_kick = handle_rx_kick;
+	 *   - drivers/vhost/scsi.c|1611| <<vhost_scsi_open>> vs->vqs[VHOST_SCSI_VQ_CTL].vq.handle_kick = vhost_scsi_ctl_handle_kick;
+	 *   - drivers/vhost/scsi.c|1612| <<vhost_scsi_open>> vs->vqs[VHOST_SCSI_VQ_EVT].vq.handle_kick = vhost_scsi_evt_handle_kick;
+	 *   - drivers/vhost/scsi.c|1615| <<vhost_scsi_open>> vs->vqs[i].vq.handle_kick = vhost_scsi_handle_kick;
+	 *   - drivers/vhost/test.c|118| <<vhost_test_open>> n->vqs[VHOST_TEST_VQ].handle_kick = handle_vq_kick;
+	 *   - drivers/vhost/vsock.c|527| <<vhost_vsock_dev_open>> vsock->vqs[VSOCK_VQ_TX].handle_kick = vhost_vsock_handle_tx_kick;
+	 *   - drivers/vhost/vsock.c|528| <<vhost_vsock_dev_open>> vsock->vqs[VSOCK_VQ_RX].handle_kick = vhost_vsock_handle_rx_kick;
+	 *
+	 * 在以下一处会调用相关:
+	 *   - drivers/vhost/vhost.c|580| <<vhost_dev_init>> vhost_poll_init(&vq->poll, vq->handle_kick,
+	 *     579                 if (vq->handle_kick)
+	 *     580                         vhost_poll_init(&vq->poll, vq->handle_kick,
+	 *     581                                         EPOLLIN, dev);
+	 */
 	vs->vqs[VHOST_SCSI_VQ_CTL].vq.handle_kick = vhost_scsi_ctl_handle_kick;
 	vs->vqs[VHOST_SCSI_VQ_EVT].vq.handle_kick = vhost_scsi_evt_handle_kick;
+	/*
+	 * for不包括VHOST_SCSI_VQ_CTL和VHOST_SCSI_VQ_EVT
+	 */
 	for (i = VHOST_SCSI_VQ_IO; i < VHOST_SCSI_MAX_VQ; i++) {
 		vqs[i] = &vs->vqs[i].vq;
 		vs->vqs[i].vq.handle_kick = vhost_scsi_handle_kick;
 	}
+	/*
+	 * 这里相当于初始化poll为handle_kick --> EPOLLIN
+	 */
 	vhost_dev_init(&vs->dev, vqs, VHOST_SCSI_MAX_VQ);
 
 	vhost_scsi_init_inflight(vs, NULL);
@@ -1409,6 +2007,9 @@ static int vhost_scsi_open(struct inode *inode, struct file *f)
 	return r;
 }
 
+/*
+ * struct file_operations vhost_scsi_fops.release = vhost_scsi_release()
+ */
 static int vhost_scsi_release(struct inode *inode, struct file *f)
 {
 	struct vhost_scsi *vs = f->private_data;
@@ -1427,6 +2028,9 @@ static int vhost_scsi_release(struct inode *inode, struct file *f)
 	return 0;
 }
 
+/*
+ * struct file_operations vhost_scsi_fops.unlocked_ioctl = vhost_scsi_ioctl()
+ */
 static long
 vhost_scsi_ioctl(struct file *f,
 		 unsigned int ioctl,
@@ -1444,6 +2048,13 @@ vhost_scsi_ioctl(struct file *f,
 
 	switch (ioctl) {
 	case VHOST_SCSI_SET_ENDPOINT:
+		/*
+		 * struct vhost_scsi_target backend:
+		 *   -> int abi_version;
+		 *   -> char vhost_wwpn[224];
+		 *   -> unsigned short vhost_tpgt;
+		 *   -> unsigned short reserved;
+		 */
 		if (copy_from_user(&backend, argp, sizeof backend))
 			return -EFAULT;
 		if (backend.reserved != 0)
@@ -1496,6 +2107,9 @@ vhost_scsi_ioctl(struct file *f,
 }
 
 #ifdef CONFIG_COMPAT
+/*
+ * struct file_operations vhost_scsi_fops.compat_ioctl = vhost_scsi_compat_ioctl()
+ */
 static long vhost_scsi_compat_ioctl(struct file *f, unsigned int ioctl,
 				unsigned long arg)
 {
@@ -1520,6 +2134,10 @@ static struct miscdevice vhost_scsi_misc = {
 	&vhost_scsi_fops,
 };
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|2145| <<vhost_scsi_init>> ret = vhost_scsi_register();
+ */
 static int __init vhost_scsi_register(void)
 {
 	return misc_register(&vhost_scsi_misc);
@@ -1546,6 +2164,11 @@ static char *vhost_scsi_dump_proto_id(struct vhost_scsi_tport *tport)
 	return "Unknown";
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|2062| <<vhost_scsi_hotplug>> vhost_scsi_do_plug(tpg, lun, true);
+ *   - drivers/vhost/scsi.c|2067| <<vhost_scsi_hotunplug>> vhost_scsi_do_plug(tpg, lun, false);
+ */
 static void
 vhost_scsi_do_plug(struct vhost_scsi_tpg *tpg,
 		  struct se_lun *lun, bool plug)
@@ -1574,16 +2197,27 @@ vhost_scsi_do_plug(struct vhost_scsi_tpg *tpg,
 	mutex_unlock(&vs->dev.mutex);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|2085| <<vhost_scsi_port_link>> vhost_scsi_hotplug(tpg, lun);
+ */
 static void vhost_scsi_hotplug(struct vhost_scsi_tpg *tpg, struct se_lun *lun)
 {
 	vhost_scsi_do_plug(tpg, lun, true);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|2107| <<vhost_scsi_port_unlink>> vhost_scsi_hotunplug(tpg, lun);
+ */
 static void vhost_scsi_hotunplug(struct vhost_scsi_tpg *tpg, struct se_lun *lun)
 {
 	vhost_scsi_do_plug(tpg, lun, false);
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.fabric_post_link = vhost_scsi_port_link()
+ */
 static int vhost_scsi_port_link(struct se_portal_group *se_tpg,
 			       struct se_lun *lun)
 {
@@ -1603,6 +2237,9 @@ static int vhost_scsi_port_link(struct se_portal_group *se_tpg,
 	return 0;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.fabric_pre_unlink = vhost_scsi_port_unlink()
+ */
 static void vhost_scsi_port_unlink(struct se_portal_group *se_tpg,
 				  struct se_lun *lun)
 {
@@ -1620,6 +2257,11 @@ static void vhost_scsi_port_unlink(struct se_portal_group *se_tpg,
 	mutex_unlock(&vhost_scsi_mutex);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|2203| <<vhost_scsi_nexus_cb>> vhost_scsi_free_cmd_map_res(se_sess);
+ *   - drivers/vhost/scsi.c|2285| <<vhost_scsi_drop_nexus>> vhost_scsi_free_cmd_map_res(se_sess);
+ */
 static void vhost_scsi_free_cmd_map_res(struct se_session *se_sess)
 {
 	struct vhost_scsi_cmd *tv_cmd;
@@ -1659,6 +2301,10 @@ static ssize_t vhost_scsi_tpg_attrib_fabric_prot_type_store(
 	return count;
 }
 
+/*
+ * # cat /sys/kernel/config/target/vhost/naa.50014056616d4144/tpgt_1/attrib/fabric_prot_type 
+ * 0
+ */
 static ssize_t vhost_scsi_tpg_attrib_fabric_prot_type_show(
 		struct config_item *item, char *page)
 {
@@ -1671,11 +2317,18 @@ static ssize_t vhost_scsi_tpg_attrib_fabric_prot_type_show(
 
 CONFIGFS_ATTR(vhost_scsi_tpg_attrib_, fabric_prot_type);
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.tfc_tpg_attrib_attrs = vhost_scsi_tpg_attrib_attrs
+ */
 static struct configfs_attribute *vhost_scsi_tpg_attrib_attrs[] = {
 	&vhost_scsi_tpg_attrib_attr_fabric_prot_type,
 	NULL,
 };
 
+/*
+ * 在以下使用vhost_scsi_nexus_cb():
+ *   - drivers/vhost/scsi.c|2235| <<vhost_scsi_make_nexus>> vhost_scsi_nexus_cb);
+ */
 static int vhost_scsi_nexus_cb(struct se_portal_group *se_tpg,
 			       struct se_session *se_sess, void *p)
 {
@@ -1712,6 +2365,10 @@ static int vhost_scsi_nexus_cb(struct se_portal_group *se_tpg,
 	return -ENOMEM;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|2389| <<vhost_scsi_tpg_nexus_store>> ret = vhost_scsi_make_nexus(tpg, port_ptr);
+ */
 static int vhost_scsi_make_nexus(struct vhost_scsi_tpg *tpg,
 				const char *name)
 {
@@ -1752,6 +2409,11 @@ static int vhost_scsi_make_nexus(struct vhost_scsi_tpg *tpg,
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|2331| <<vhost_scsi_tpg_nexus_store>> ret = vhost_scsi_drop_nexus(tpg);
+ *   - drivers/vhost/scsi.c|2467| <<vhost_scsi_drop_tpg>> vhost_scsi_drop_nexus(tpg);
+ */
 static int vhost_scsi_drop_nexus(struct vhost_scsi_tpg *tpg)
 {
 	struct se_session *se_sess;
@@ -1802,6 +2464,10 @@ static int vhost_scsi_drop_nexus(struct vhost_scsi_tpg *tpg)
 	return 0;
 }
 
+/*
+ * # cat /sys/kernel/config/target/vhost/naa.50014056616d4144/tpgt_1/nexus
+ * naa.500140565eb533bc
+ */
 static ssize_t vhost_scsi_tpg_nexus_show(struct config_item *item, char *page)
 {
 	struct se_portal_group *se_tpg = to_tpg(item);
@@ -1903,11 +2569,17 @@ static ssize_t vhost_scsi_tpg_nexus_store(struct config_item *item,
 
 CONFIGFS_ATTR(vhost_scsi_tpg_, nexus);
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.tfc_tpg_base_attrs = vhost_scsi_tpg_attrs
+ */
 static struct configfs_attribute *vhost_scsi_tpg_attrs[] = {
 	&vhost_scsi_tpg_attr_nexus,
 	NULL,
 };
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.fabric_make_tpg = vhost_scsi_make_tpg()
+ */
 static struct se_portal_group *
 vhost_scsi_make_tpg(struct se_wwn *wwn,
 		   struct config_group *group,
@@ -1941,12 +2613,20 @@ vhost_scsi_make_tpg(struct se_wwn *wwn,
 		return NULL;
 	}
 	mutex_lock(&vhost_scsi_mutex);
+	/*
+	 * 在以下使用vhost_scsi_list:
+	 *   - drivers/vhost/scsi.c|1184| <<vhost_scsi_set_endpoint>> list_for_each_entry(tpg, &vhost_scsi_list, tv_tpg_list) {
+	 *   - drivers/vhost/scsi.c|1944| <<vhost_scsi_make_tpg>> list_add_tail(&tpg->tv_tpg_list, &vhost_scsi_list);
+	 */
 	list_add_tail(&tpg->tv_tpg_list, &vhost_scsi_list);
 	mutex_unlock(&vhost_scsi_mutex);
 
 	return &tpg->se_tpg;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.fabric_drop_tpg = vhost_scsi_drop_tpg()
+ */
 static void vhost_scsi_drop_tpg(struct se_portal_group *se_tpg)
 {
 	struct vhost_scsi_tpg *tpg = container_of(se_tpg,
@@ -1966,6 +2646,9 @@ static void vhost_scsi_drop_tpg(struct se_portal_group *se_tpg)
 	kfree(tpg);
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.fabric_make_wwn = vhost_scsi_make_tport()
+ */
 static struct se_wwn *
 vhost_scsi_make_tport(struct target_fabric_configfs *tf,
 		     struct config_group *group,
@@ -2027,6 +2710,9 @@ vhost_scsi_make_tport(struct target_fabric_configfs *tf,
 	return &tport->tport_wwn;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.fabric_drop_wwn = vhost_scsi_drop_tport()
+ */
 static void vhost_scsi_drop_tport(struct se_wwn *wwn)
 {
 	struct vhost_scsi_tport *tport = container_of(wwn,
@@ -2039,6 +2725,10 @@ static void vhost_scsi_drop_tport(struct se_wwn *wwn)
 	kfree(tport);
 }
 
+/*
+ * # cat /sys/kernel/config/target/vhost/version
+ * TCM_VHOST fabric module v0.1 on Linux/x86_64on 4.14.35-1902.300.11.el7uek.x86_64
+ */
 static ssize_t
 vhost_scsi_wwn_version_show(struct config_item *item, char *page)
 {
@@ -2049,6 +2739,9 @@ vhost_scsi_wwn_version_show(struct config_item *item, char *page)
 
 CONFIGFS_ATTR_RO(vhost_scsi_wwn_, version);
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.tfc_wwn_attrs = vhost_scsi_wwn_attrs
+ */
 static struct configfs_attribute *vhost_scsi_wwn_attrs[] = {
 	&vhost_scsi_wwn_attr_version,
 	NULL,
@@ -2105,6 +2798,14 @@ static int __init vhost_scsi_init(void)
 	 * Use our own dedicated workqueue for submitting I/O into
 	 * target core to avoid contention within system_wq.
 	 */
+	/*
+	 * 在以下使用vhost_scsi_workqueue:
+	 *   - drivers/vhost/scsi.c|1045| <<vhost_scsi_handle_vq>> queue_work(vhost_scsi_workqueue, &cmd->work);
+	 *   - drivers/vhost/scsi.c|2108| <<vhost_scsi_init>> vhost_scsi_workqueue = alloc_workqueue("vhost_scsi", 0, 0);
+	 *   - drivers/vhost/scsi.c|2109| <<vhost_scsi_init>> if (!vhost_scsi_workqueue)
+	 *   - drivers/vhost/scsi.c|2125| <<vhost_scsi_init>> destroy_workqueue(vhost_scsi_workqueue);
+	 *   - drivers/vhost/scsi.c|2134| <<vhost_scsi_exit>> destroy_workqueue(vhost_scsi_workqueue);
+	 */
 	vhost_scsi_workqueue = alloc_workqueue("vhost_scsi", 0, 0);
 	if (!vhost_scsi_workqueue)
 		goto out;
@@ -2113,6 +2814,20 @@ static int __init vhost_scsi_init(void)
 	if (ret < 0)
 		goto out_destroy_workqueue;
 
+	/*
+	 * called by:
+	 *   - drivers/infiniband/ulp/srpt/ib_srpt.c|3735| <<srpt_init_module>> ret = target_register_template(&srpt_template);
+	 *   - drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c|4146| <<ibmvscsis_init>> rc = target_register_template(&ibmvscsis_ops);
+	 *   - drivers/scsi/qla2xxx/tcm_qla2xxx.c|1964| <<tcm_qla2xxx_register_configfs>> ret = target_register_template(&tcm_qla2xxx_ops);
+	 *   - drivers/scsi/qla2xxx/tcm_qla2xxx.c|1968| <<tcm_qla2xxx_register_configfs>> ret = target_register_template(&tcm_qla2xxx_npiv_ops);
+	 *   - drivers/target/iscsi/iscsi_target.c|707| <<iscsi_target_init_module>> ret = target_register_template(&iscsi_ops);
+	 *   - drivers/target/loopback/tcm_loop.c|1212| <<tcm_loop_fabric_init>> ret = target_register_template(&loop_ops);
+	 *   - drivers/target/sbp/sbp_target.c|2366| <<sbp_init>> return target_register_template(&sbp_ops);
+	 *   - drivers/target/tcm_fc/tfc_conf.c|478| <<ft_init>> ret = target_register_template(&ft_fabric_ops);
+	 *   - drivers/usb/gadget/function/f_tcm.c|2338| <<tcm_init>> ret = target_register_template(&usbg_ops);
+	 *   - drivers/vhost/scsi.c|2149| <<vhost_scsi_init>> ret = target_register_template(&vhost_scsi_ops);
+	 *   - drivers/xen/xen-scsiback.c|1868| <<scsiback_init>> ret = target_register_template(&scsiback_ops);
+	 */
 	ret = target_register_template(&vhost_scsi_ops);
 	if (ret < 0)
 		goto out_vhost_scsi_deregister;
diff --git a/drivers/vhost/vhost.c b/drivers/vhost/vhost.c
index 9beefa6e..6a751ec8 100644
--- a/drivers/vhost/vhost.c
+++ b/drivers/vhost/vhost.c
@@ -33,10 +33,28 @@
 
 #include "vhost.h"
 
+/*
+ * poll的函数是: vhost_poll_func()
+ * poll完了wakeup的时候是: vhost_poll_wakeup()
+ */
+
+/* 用在umem */
+/*
+ * 在以下使用max_mem_regions:
+ *   - drivers/vhost/vhost.c|1653| <<vhost_set_memory>> if (mem.nregions > max_mem_regions)
+ *
+ * 在VHOST_SET_MEM_TABLE:vhost_set_memory()使用
+ */
 static ushort max_mem_regions = 64;
 module_param(max_mem_regions, ushort, 0444);
 MODULE_PARM_DESC(max_mem_regions,
 	"Maximum number of memory regions in memory map. (default: 64)");
+/*
+ * 在以下使用max_iotlb_entries:
+ *   - drivers/vhost/vhost.c|1162| <<vhost_new_umem_range>> if (umem->numem == max_iotlb_entries) {
+ *
+ * 用在iotlb
+ */
 static int max_iotlb_entries = 2048;
 module_param(max_iotlb_entries, int, 0444);
 MODULE_PARM_DESC(max_iotlb_entries,
@@ -46,7 +64,18 @@ enum {
 	VHOST_MEMORY_F_LOG = 0x1,
 };
 
+/* avail和used都是用VHOST_SET_VRING_ADDR配置的 */
+
+/*
+ * last_avail_idx表示前端处理到avail ring的哪个元素了
+ * ++之后表示下次待处理的avail ring的哪个元素
+ * 并将这个信息放入了used ring的最后一个元素
+ * 前端驱动通过读取used ring的最后一个元素就知道后端处理到哪里了
+ */
+
+/* 返回avail的最后一个元素 */
 #define vhost_used_event(vq) ((__virtio16 __user *)&vq->avail->ring[vq->num])
+/* 返回used的最后一个元素 */
 #define vhost_avail_event(vq) ((__virtio16 __user *)&vq->used->ring[vq->num])
 
 INTERVAL_TREE_DEFINE(struct vhost_umem_node,
@@ -69,6 +98,7 @@ static void vhost_enable_cross_endian_little(struct vhost_virtqueue *vq)
 	vq->user_be = false;
 }
 
+/* VHOST_SET_VRING_ENDIAN */
 static long vhost_set_vring_endian(struct vhost_virtqueue *vq, int __user *argp)
 {
 	struct vhost_vring_state s;
@@ -147,6 +177,11 @@ struct vhost_flush_struct {
 	struct completion wait_event;
 };
 
+/* only used (not called) by vhost_work_flush() */
+/*
+ * 在以下使用vhost_flush_work():
+ *   - drivers/vhost/vhost.c|330| <<vhost_work_flush>> vhost_work_init(&flush.work, vhost_flush_work);
+ */
 static void vhost_flush_work(struct vhost_work *work)
 {
 	struct vhost_flush_struct *s;
@@ -155,6 +190,15 @@ static void vhost_flush_work(struct vhost_work *work)
 	complete(&s->wait_event);
 }
 
+/* 
+ * 这个函数被配置给了poll_table->_qproc
+ * socket和eventfd的poll会调用poll_wait()-->调用poll_table->_qproc=vhost_poll_func()
+ *
+ * 把&poll->wait加入到wqh
+ *
+ * 对于socket: 把n->poll->wait加入到socket的wqh
+ * 对于eventfd, 把vhost_virtqueue->poll->wait加入到socket的wqh
+ */
 static void vhost_poll_func(struct file *file, wait_queue_head_t *wqh,
 			    poll_table *pt)
 {
@@ -162,9 +206,21 @@ static void vhost_poll_func(struct file *file, wait_queue_head_t *wqh,
 
 	poll = container_of(pt, struct vhost_poll, table);
 	poll->wqh = wqh;
+	/* 把&poll->wait加入到wqh */
 	add_wait_queue(wqh, &poll->wait);
 }
 
+/*
+ * 对于socket: 把n->poll->wait加入到socket的wqh, wait的func是vhost_poll_wakeup()
+ * 对于eventfd, 把vhost_virtqueue->poll->wait加入到eventfd的wqh, wait的func是vhost_poll_wakeup()
+ *
+ * 所以对于socket和eventfd, 唤醒的waitqueue的func都是vhost_poll_wakeup()
+ *
+ * 把poll->work (vhost_work)挂到poll->dev (vhost_dev)上然后唤醒vhost_dev的内核线程
+ *
+ * socket的入口: tun_net_xmit()-->sock_def_readable()
+ * eventfd的入口: handle_ept_misconfig()-->kvm_io_bus_write()-->eventfd_signal()
+ */
 static int vhost_poll_wakeup(wait_queue_entry_t *wait, unsigned mode, int sync,
 			     void *key)
 {
@@ -173,10 +229,24 @@ static int vhost_poll_wakeup(wait_queue_entry_t *wait, unsigned mode, int sync,
 	if (!(key_to_poll(key) & poll->mask))
 		return 0;
 
+	/* 把poll->work (vhost_work)挂到poll->dev (vhost_dev)上然后唤醒vhost_dev的内核线程 */
 	vhost_poll_queue(poll);
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1603| <<vhost_scsi_open>> vhost_work_init(&vs->vs_completion_work, vhost_scsi_complete_cmd_work);
+ *   - drivers/vhost/scsi.c|1604| <<vhost_scsi_open>> vhost_work_init(&vs->vs_event_work, vhost_scsi_evt_work);
+ *   - drivers/vhost/vhost.c|246| <<vhost_poll_init>> vhost_work_init(&poll->work, fn);
+ *   - drivers/vhost/vhost.c|312| <<vhost_work_flush>> vhost_work_init(&flush.work, vhost_flush_work);
+ *   - drivers/vhost/vhost.c|592| <<vhost_attach_cgroups>> vhost_work_init(&attach.work, vhost_attach_cgroups_work);
+ *   - drivers/vhost/vsock.c|535| <<vhost_vsock_dev_open>> vhost_work_init(&vsock->send_pkt_work, vhost_transport_send_pkt_work);
+ *
+ * 核心是:
+ *  - clear_bit(VHOST_WORK_QUEUED, &vhost_work->flags);
+ *  - vhost_work->fn = fn;
+ */
 void vhost_work_init(struct vhost_work *work, vhost_work_fn_t fn)
 {
 	clear_bit(VHOST_WORK_QUEUED, &work->flags);
@@ -185,6 +255,17 @@ void vhost_work_init(struct vhost_work *work, vhost_work_fn_t fn)
 EXPORT_SYMBOL_GPL(vhost_work_init);
 
 /* Init poll structure */
+/*
+ * called by:
+ *   - vhost_net_open(), 初始化n->poll
+ *   - vhost_net_open(), 初始化n->poll
+ *   - vhost_dev_init(), 初始化vhost_virtqueue->poll
+ *
+ * called by:
+ *   - drivers/vhost/net.c|1164| <<vhost_net_open>> vhost_poll_init(n->poll + VHOST_NET_VQ_TX, handle_tx_net, EPOLLOUT, dev);
+ *   - drivers/vhost/net.c|1165| <<vhost_net_open>> vhost_poll_init(n->poll + VHOST_NET_VQ_RX, handle_rx_net, EPOLLIN, dev);
+ *   - drivers/vhost/vhost.c|559| <<vhost_dev_init>> vhost_poll_init(&vq->poll, vq->handle_kick,
+ */
 void vhost_poll_init(struct vhost_poll *poll, vhost_work_fn_t fn,
 		     __poll_t mask, struct vhost_dev *dev)
 {
@@ -200,6 +281,15 @@ EXPORT_SYMBOL_GPL(vhost_poll_init);
 
 /* Start polling a file. We add ourselves to file's wait queue. The caller must
  * keep a reference to a file until after vhost_poll_stop is called. */
+/*
+ * called by:
+ *   - vhost_net_enable_vq()  ---> poll在sock->file
+ *     这里poll是n->poll, 是handle_rx_net()
+ *
+ *
+ *   - vhost_vring_ioctl():VHOST_SET_VRING_KICK  --->设置host notifier, poll在eventfd
+ *     这里poll是vhost_virtqueue->poll, 是handle_tx_kick()
+ */
 int vhost_poll_start(struct vhost_poll *poll, struct file *file)
 {
 	__poll_t mask;
@@ -208,6 +298,19 @@ int vhost_poll_start(struct vhost_poll *poll, struct file *file)
 	if (poll->wqh)
 		return 0;
 
+	/*
+	 * socket : tun_chr_poll()
+	 * eventfd: eventfd_poll()
+	 *
+	 * poll_wait()就是调用poll_table->_qproc=vhost_poll_func()
+	 *
+	 * vhost_poll_func()把&poll->wait加入到fd的wqh
+	 *
+	 * 对于socket: 把n->poll->wait加入到socket的wqh, wait的func是vhost_poll_wakeup()
+	 * 对于eventfd, 把vhost_virtqueue->poll->wait加入到eventfd的wqh, wait的func是vhost_poll_wakeup()
+	 *
+	 * 所以到时候waitqueue唤醒的时候都是调用vhost_poll_wakeup()
+	 */
 	mask = file->f_op->poll(file, &poll->table);
 	if (mask)
 		vhost_poll_wakeup(&poll->wait, 0, 0, poll_to_key(mask));
@@ -224,6 +327,7 @@ EXPORT_SYMBOL_GPL(vhost_poll_start);
  * file reference. You must also flush afterwards. */
 void vhost_poll_stop(struct vhost_poll *poll)
 {
+	/* poll->wqh是socket或eventd的wait_queue_head_t */
 	if (poll->wqh) {
 		remove_wait_queue(poll->wqh, &poll->wait);
 		poll->wqh = NULL;
@@ -239,6 +343,7 @@ void vhost_work_flush(struct vhost_dev *dev, struct vhost_work *work)
 		init_completion(&flush.wait_event);
 		vhost_work_init(&flush.work, vhost_flush_work);
 
+		/* 把vhost_work挂到vhost_dev上然后唤醒内核线程 */
 		vhost_work_queue(dev, &flush.work);
 		wait_for_completion(&flush.wait_event);
 	}
@@ -253,6 +358,7 @@ void vhost_poll_flush(struct vhost_poll *poll)
 }
 EXPORT_SYMBOL_GPL(vhost_poll_flush);
 
+/* 把vhost_work挂到vhost_dev上然后唤醒内核线程 */
 void vhost_work_queue(struct vhost_dev *dev, struct vhost_work *work)
 {
 	if (!dev->worker)
@@ -276,20 +382,46 @@ bool vhost_has_work(struct vhost_dev *dev)
 }
 EXPORT_SYMBOL_GPL(vhost_has_work);
 
+/* 
+ * 很多地方都调用这里了 这里是唤醒vhost_dev内核线程的地方
+ *
+ * 把poll->work (vhost_work)挂到poll->dev (vhost_dev)上然后唤醒vhost_dev的内核线程
+ */
 void vhost_poll_queue(struct vhost_poll *poll)
 {
+	/* 把poll->work (vhost_work)挂到poll->dev (vhost_dev)上然后唤醒vhost_dev的内核线程 */
 	vhost_work_queue(poll->dev, &poll->work);
 }
 EXPORT_SYMBOL_GPL(vhost_poll_queue);
 
+/*
+ * called by:
+ *   - vhost_vq_meta_reset()
+ *   - vhost_vq_reset()
+ *
+ * enum vhost_uaddr_type {
+ *	VHOST_ADDR_DESC = 0,
+ *	VHOST_ADDR_AVAIL = 1,
+ *	VHOST_ADDR_USED = 2,
+ *	VHOST_NUM_ADDRS = 3,
+ * };
+ *
+ * 把vhost_virtqueue的VHOST_NUM_ADDRS个vq->meta_iotlb设成NULL
+ */
 static void __vhost_vq_meta_reset(struct vhost_virtqueue *vq)
 {
 	int j;
 
+	/*
+	 * meta_iotlb就在vhost_vq_meta_fetch()和vhost_vq_meta_update()用到过
+	 *
+	 * meta_iotlb is configured by iotlb_access_ok()-->vhost_vq_meta_update()
+	 */
 	for (j = 0; j < VHOST_NUM_ADDRS; j++)
-		vq->meta_iotlb[j] = NULL;
+		vq->meta_iotlb[j] = NULL;  // vhost_umem_node类型
 }
 
+/* 把vhost_dev的所有的vhost_virtqueue的VHOST_NUM_ADDRS个vq->meta_iotlb设成NULL */
 static void vhost_vq_meta_reset(struct vhost_dev *d)
 {
 	int i;
@@ -298,6 +430,11 @@ static void vhost_vq_meta_reset(struct vhost_dev *d)
 		__vhost_vq_meta_reset(d->vqs[i]);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|582| <<vhost_dev_init>> vhost_vq_reset(dev, vq);
+ *   - drivers/vhost/vhost.c|777| <<vhost_dev_cleanup>> vhost_vq_reset(dev, dev->vqs[i]);
+ */
 static void vhost_vq_reset(struct vhost_dev *dev,
 			   struct vhost_virtqueue *vq)
 {
@@ -367,6 +504,12 @@ static int vhost_worker(void *data)
 	return 0;
 }
 
+/*
+ * 清空free:
+ *   - vq->indirect
+ *   - vq->log
+ *   - vq->heads
+ */
 static void vhost_vq_free_iovecs(struct vhost_virtqueue *vq)
 {
 	kfree(vq->indirect);
@@ -378,6 +521,12 @@ static void vhost_vq_free_iovecs(struct vhost_virtqueue *vq)
 }
 
 /* Helper to allocate iovec buffers for all vqs. */
+/*
+ * 分配:
+ *   vq->indirect[]
+ *   vq->log
+ *   vq->heads
+ */
 static long vhost_dev_alloc_iovecs(struct vhost_dev *dev)
 {
 	struct vhost_virtqueue *vq;
@@ -404,10 +553,23 @@ static void vhost_dev_free_iovecs(struct vhost_dev *dev)
 {
 	int i;
 
+	/*
+	 * 清空free:
+	 *   - vq->indirect
+	 *   - vq->log
+	 *   - vq->heads
+	 */
 	for (i = 0; i < dev->nvqs; ++i)
 		vhost_vq_free_iovecs(dev->vqs[i]);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|1162| <<vhost_net_open>> vhost_dev_init(dev, vqs, VHOST_NET_VQ_MAX);
+ *   - drivers/vhost/scsi.c|1617| <<vhost_scsi_open>> vhost_dev_init(&vs->dev, vqs, VHOST_SCSI_MAX_VQ);
+ *   - drivers/vhost/test.c|119| <<vhost_test_open>> vhost_dev_init(dev, vqs, VHOST_TEST_VQ_MAX);
+ *   - drivers/vhost/vsock.c|530| <<vhost_vsock_dev_open>> vhost_dev_init(&vsock->dev, vqs, ARRAY_SIZE(vsock->vqs));
+ */
 void vhost_dev_init(struct vhost_dev *dev,
 		    struct vhost_virtqueue **vqs, int nvqs)
 {
@@ -485,6 +647,7 @@ bool vhost_dev_has_owner(struct vhost_dev *dev)
 EXPORT_SYMBOL_GPL(vhost_dev_has_owner);
 
 /* Caller should have device mutex */
+/* VHOST_SET_OWNER */
 long vhost_dev_set_owner(struct vhost_dev *dev)
 {
 	struct task_struct *worker;
@@ -511,6 +674,12 @@ long vhost_dev_set_owner(struct vhost_dev *dev)
 	if (err)
 		goto err_cgroup;
 
+	/*
+	 * 为所有vq分配:
+	 *   vq->indirect[]
+	 *   vq->log
+	 *   vq->heads
+	 */
 	err = vhost_dev_alloc_iovecs(dev);
 	if (err)
 		goto err_cgroup;
@@ -528,6 +697,7 @@ long vhost_dev_set_owner(struct vhost_dev *dev)
 }
 EXPORT_SYMBOL_GPL(vhost_dev_set_owner);
 
+/* called only by vhost_net_reset_owner() */
 struct vhost_umem *vhost_dev_reset_owner_prepare(void)
 {
 	return kvzalloc(sizeof(struct vhost_umem), GFP_KERNEL);
@@ -535,6 +705,9 @@ struct vhost_umem *vhost_dev_reset_owner_prepare(void)
 EXPORT_SYMBOL_GPL(vhost_dev_reset_owner_prepare);
 
 /* Caller should have device mutex */
+/*
+ * dev->umem和dev->vqs[i]->umem指向相同得vhost_umem
+ */
 void vhost_dev_reset_owner(struct vhost_dev *dev, struct vhost_umem *umem)
 {
 	int i;
@@ -565,6 +738,7 @@ void vhost_dev_stop(struct vhost_dev *dev)
 }
 EXPORT_SYMBOL_GPL(vhost_dev_stop);
 
+/* 把node从umem->umem_tree和umem->umem_list去掉 */
 static void vhost_umem_free(struct vhost_umem *umem,
 			    struct vhost_umem_node *node)
 {
@@ -574,6 +748,7 @@ static void vhost_umem_free(struct vhost_umem *umem,
 	umem->numem--;
 }
 
+/* 把vhost_umem下所有的vhost_umem_node从umem->umem_tree和umem->umem_list去掉 */
 static void vhost_umem_clean(struct vhost_umem *umem)
 {
 	struct vhost_umem_node *node, *tmp;
@@ -582,11 +757,12 @@ static void vhost_umem_clean(struct vhost_umem *umem)
 		return;
 
 	list_for_each_entry_safe(node, tmp, &umem->umem_list, link)
-		vhost_umem_free(umem, node);
+		vhost_umem_free(umem, node);  /* 把node从umem->umem_tree和umem->umem_list去掉 */
 
 	kvfree(umem);
 }
 
+/* called only by vhost_dev_cleanup() */
 static void vhost_clear_msg(struct vhost_dev *dev)
 {
 	struct vhost_msg_node *node, *n;
@@ -654,6 +830,7 @@ static bool log_access_ok(void __user *log_base, u64 addr, unsigned long sz)
 			 (sz + VHOST_PAGE_SIZE * 8 - 1) / VHOST_PAGE_SIZE / 8);
 }
 
+/* uaddr和size不能超出u64 */
 static bool vhost_overflow(u64 uaddr, u64 size)
 {
 	/* Make sure 64 bit math will not overflow. */
@@ -661,6 +838,12 @@ static bool vhost_overflow(u64 uaddr, u64 size)
 }
 
 /* Caller should have vq mutex and device mutex. */
+/* 遍历vhost_umem的vhost_umem_node,确认所有得userspace_addr是否都在vhost内核有访问权限 */
+/*
+ * called by:
+ *   - memory_access_ok()
+ *   - vq_log_access_ok()
+ */
 static bool vq_memory_access_ok(void __user *log_base, struct vhost_umem *umem,
 				int log_all)
 {
@@ -687,10 +870,21 @@ static bool vq_memory_access_ok(void __user *log_base, struct vhost_umem *umem,
 	return true;
 }
 
+/* 把guest的物理地址转换成qemu userspace的地址 */
+/*
+ * called by:
+ *   - vhost_copy_to_user()
+ *   - vhost_copy_from_user()
+ *   - __vhost_get_user()
+ *   - iotlb_access_ok()
+ */
 static inline void __user *vhost_vq_meta_fetch(struct vhost_virtqueue *vq,
 					       u64 addr, unsigned int size,
 					       int type)
 {
+	/*
+	 * meta_iotalb[]有三个元素: VHOST_ADDR_DESC, VHOST_ADDR_AVAIL, VHOST_ADDR_USED
+	 */
 	const struct vhost_umem_node *node = vq->meta_iotlb[type];
 
 	if (!node)
@@ -701,6 +895,7 @@ static inline void __user *vhost_vq_meta_fetch(struct vhost_virtqueue *vq,
 
 /* Can we switch to this memory table? */
 /* Caller should have device mutex but not vq mutex */
+/* 遍历vhost_umem的vhost_umem_node,确认所有得userspace_addr是否都在vhost内核有访问权限 */
 static bool memory_access_ok(struct vhost_dev *d, struct vhost_umem *umem,
 			     int log_all)
 {
@@ -713,6 +908,7 @@ static bool memory_access_ok(struct vhost_dev *d, struct vhost_umem *umem,
 		mutex_lock(&d->vqs[i]->mutex);
 		log = log_all || vhost_has_feature(d->vqs[i], VHOST_F_LOG_ALL);
 		/* If ring is inactive, will check when it's enabled. */
+		/* 遍历vhost_umem的vhost_umem_node,确认所有得userspace_addr是否都在vhost内核有访问权限 */
 		if (d->vqs[i]->private_data)
 			ok = vq_memory_access_ok(d->vqs[i]->log_base,
 						 umem, log);
@@ -725,9 +921,17 @@ static bool memory_access_ok(struct vhost_dev *d, struct vhost_umem *umem,
 	return true;
 }
 
+/*
+ * 把desc中的地址转换成qemu userspace的地址存放在iov中
+ *
+ * iov_size是从iov开始剩下可用的iov
+ */
 static int translate_desc(struct vhost_virtqueue *vq, u64 addr, u32 len,
 			  struct iovec iov[], int iov_size, int access);
 
+/*
+ * called only by __vhost_add_used_n()
+ */
 static int vhost_copy_to_user(struct vhost_virtqueue *vq, void __user *to,
 			      const void *from, unsigned size)
 {
@@ -742,6 +946,7 @@ static int vhost_copy_to_user(struct vhost_virtqueue *vq, void __user *to,
 		 * not happen in this case.
 		 */
 		struct iov_iter t;
+		/* 把guest的物理地址转换成qemu userspace的地址 */
 		void __user *uaddr = vhost_vq_meta_fetch(vq,
 				     (u64)(uintptr_t)to, size,
 				     VHOST_ADDR_USED);
@@ -749,6 +954,7 @@ static int vhost_copy_to_user(struct vhost_virtqueue *vq, void __user *to,
 		if (uaddr)
 			return __copy_to_user(uaddr, from, size);
 
+		/* 把desc中的地址转换成qemu userspace的地址存放在iov中 */
 		ret = translate_desc(vq, (u64)(uintptr_t)to, size, vq->iotlb_iov,
 				     ARRAY_SIZE(vq->iotlb_iov),
 				     VHOST_ACCESS_WO);
@@ -776,6 +982,7 @@ static int vhost_copy_from_user(struct vhost_virtqueue *vq, void *to,
 		 * could be access through iotlb. So -EAGAIN should
 		 * not happen in this case.
 		 */
+		/* 把guest的物理地址转换成qemu userspace的地址 */
 		void __user *uaddr = vhost_vq_meta_fetch(vq,
 				     (u64)(uintptr_t)from, size,
 				     VHOST_ADDR_DESC);
@@ -784,6 +991,7 @@ static int vhost_copy_from_user(struct vhost_virtqueue *vq, void *to,
 		if (uaddr)
 			return __copy_from_user(to, uaddr, size);
 
+		/* 把desc中的地址转换成qemu userspace的地址存放在iov中 */
 		ret = translate_desc(vq, (u64)(uintptr_t)from, size, vq->iotlb_iov,
 				     ARRAY_SIZE(vq->iotlb_iov),
 				     VHOST_ACCESS_RO);
@@ -803,12 +1011,15 @@ static int vhost_copy_from_user(struct vhost_virtqueue *vq, void *to,
 	return ret;
 }
 
+/* 把desc中的地址转换成qemu userspace的地址存放在iov中 然后返回iotlb_iov[0].iov_base */
+/* called only by __vhost_get_user() */
 static void __user *__vhost_get_user_slow(struct vhost_virtqueue *vq,
 					  void __user *addr, unsigned int size,
 					  int type)
 {
 	int ret;
 
+	/* 把desc中的地址转换成qemu userspace的地址存放在iov中 */
 	ret = translate_desc(vq, (u64)(uintptr_t)addr, size, vq->iotlb_iov,
 			     ARRAY_SIZE(vq->iotlb_iov),
 			     VHOST_ACCESS_RO);
@@ -834,18 +1045,36 @@ static void __user *__vhost_get_user_slow(struct vhost_virtqueue *vq,
  * could be access through iotlb. So -EAGAIN should
  * not happen in this case.
  */
+/* 把guest的物理地址转换成qemu userspace的地址 */
+/*
+ * called by (都是在不支持iotlb的情况下):
+ *   - vhost_put_user()
+ *   - vhost_get_user()
+ */
 static inline void __user *__vhost_get_user(struct vhost_virtqueue *vq,
 					    void *addr, unsigned int size,
 					    int type)
 {
+	/* 把guest的物理地址转换成qemu userspace的地址 */
 	void __user *uaddr = vhost_vq_meta_fetch(vq,
 			     (u64)(uintptr_t)addr, size, type);
 	if (uaddr)
 		return uaddr;
 
+	/* 把desc中的地址转换成qemu userspace的地址存放在iov中 然后返回iotlb_iov[0].iov_base */
 	return __vhost_get_user_slow(vq, addr, size, type);
 }
 
+/*
+ * 把x拷贝到ptr, 在需要的时候先把ptr转换成qemu的userspace地址
+ *
+ * called by:
+ *   - vhost_update_used_flags()
+ *   - vhost_update_avail_event()
+ *   - __vhost_add_used_n()
+ *   - __vhost_add_used_n()
+ *   - vhost_add_used_n()
+ */
 #define vhost_put_user(vq, x, ptr)		\
 ({ \
 	int ret = -EFAULT; \
@@ -863,6 +1092,15 @@ static inline void __user *__vhost_get_user(struct vhost_virtqueue *vq,
 	ret; \
 })
 
+/*
+ * 从ptr拷贝到x, 在需要的时候先把ptr转换成qemu的userspace地址
+ *
+ * called by:
+ *   - vhost_get_avail()
+ *   - vhost_get_used()
+ *
+ * type可以是VHOST_ADDR_AVAIL或者VHOST_ADDR_USED
+ */
 #define vhost_get_user(vq, x, ptr, type)		\
 ({ \
 	int ret; \
@@ -881,9 +1119,26 @@ static inline void __user *__vhost_get_user(struct vhost_virtqueue *vq,
 	ret; \
 })
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2398| <<vhost_get_vq_desc>> if (unlikely(vhost_get_avail(vq, avail_idx, &vq->avail->idx))) {
+ *   - drivers/vhost/vhost.c|2427| <<vhost_get_vq_desc>> if (unlikely(vhost_get_avail(vq, ring_head,
+ *   - drivers/vhost/vhost.c|2657| <<vhost_notify>> if (vhost_get_avail(vq, flags, &vq->avail->flags)) {
+ *   - drivers/vhost/vhost.c|2671| <<vhost_notify>> if (vhost_get_avail(vq, event, vhost_used_event(vq))) {
+ *   - drivers/vhost/vhost.c|2724| <<vhost_vq_avail_empty>> r = vhost_get_avail(vq, avail_idx, &vq->avail->idx);
+ *   - drivers/vhost/vhost.c|2768| <<vhost_enable_notify>> r = vhost_get_avail(vq, avail_idx, &vq->avail->idx);
+ *
+ * 从ptr拷贝到x, 在需要的时候先把ptr转换成qemu的userspace地址
+ */
 #define vhost_get_avail(vq, x, ptr) \
 	vhost_get_user(vq, x, ptr, VHOST_ADDR_AVAIL)
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2184| <<vhost_vq_init_access>> r = vhost_get_used(vq, last_used_idx, &vq->used->idx);
+ *
+ * 从ptr拷贝到x, 在需要的时候先把ptr转换成qemu的userspace地址
+ */
 #define vhost_get_used(vq, x, ptr) \
 	vhost_get_user(vq, x, ptr, VHOST_ADDR_USED)
 
@@ -901,6 +1156,13 @@ static void vhost_dev_unlock_vqs(struct vhost_dev *d)
 		mutex_unlock(&d->vqs[i]->mutex);
 }
 
+/*
+ * 把地址们做成一个vhost_umem_node, 放入vhost_umem
+ *
+ * called by:
+ *   - vhost_process_iotlb_msg()
+ *   - vhost_set_memory()  ---> 这是iotlb的
+ */
 static int vhost_new_umem_range(struct vhost_umem *umem,
 				u64 start, u64 size, u64 end,
 				u64 userspace_addr, int perm)
@@ -910,8 +1172,10 @@ static int vhost_new_umem_range(struct vhost_umem *umem,
 	if (!node)
 		return -ENOMEM;
 
+	/* 如果满了就要释放一个 */
 	if (umem->numem == max_iotlb_entries) {
 		tmp = list_first_entry(&umem->umem_list, typeof(*tmp), link);
+		/* 把node从umem->umem_tree和umem->umem_list去掉 */
 		vhost_umem_free(umem, tmp);
 	}
 
@@ -928,6 +1192,9 @@ static int vhost_new_umem_range(struct vhost_umem *umem,
 	return 0;
 }
 
+/*
+ * called only by vhost_process_iotlb_msg()
+ */
 static void vhost_del_umem_range(struct vhost_umem *umem,
 				 u64 start, u64 end)
 {
@@ -935,9 +1202,14 @@ static void vhost_del_umem_range(struct vhost_umem *umem,
 
 	while ((node = vhost_umem_interval_tree_iter_first(&umem->umem_tree,
 							   start, end)))
-		vhost_umem_free(umem, node);
+		vhost_umem_free(umem, node); /* 把node从umem->umem_tree和umem->umem_list去掉 */
 }
 
+/*
+ * called only by vhost_process_iotlb_msg()
+ *
+ * 回复唤醒vhost_chr_read_iter()插入的pending_list中的元素
+ */
 static void vhost_iotlb_notify_vq(struct vhost_dev *d,
 				  struct vhost_iotlb_msg *msg)
 {
@@ -945,6 +1217,7 @@ static void vhost_iotlb_notify_vq(struct vhost_dev *d,
 
 	spin_lock(&d->iotlb_lock);
 
+	/* pending_list是由vhost_chr_read_iter()插入的 */
 	list_for_each_entry_safe(node, n, &d->pending_list, node) {
 		struct vhost_iotlb_msg *vq_msg = &node->msg.iotlb;
 		if (msg->iova <= vq_msg->iova &&
@@ -959,11 +1232,14 @@ static void vhost_iotlb_notify_vq(struct vhost_dev *d,
 	spin_unlock(&d->iotlb_lock);
 }
 
+/* uaddr在内核是否可以访问 */
+/* called only by vhost_process_iotlb_msg() */
 static bool umem_access_ok(u64 uaddr, u64 size, int access)
 {
 	unsigned long a = uaddr;
 
 	/* Make sure 64 bit math will not overflow. */
+	/* uaddr和size不能超出u64 */
 	if (vhost_overflow(uaddr, size))
 		return false;
 
@@ -976,6 +1252,9 @@ static bool umem_access_ok(u64 uaddr, u64 size, int access)
 	return true;
 }
 
+/*
+ * called only by vhost_chr_write_iter()
+ */
 static int vhost_process_iotlb_msg(struct vhost_dev *dev,
 				   struct vhost_iotlb_msg *msg)
 {
@@ -993,7 +1272,16 @@ static int vhost_process_iotlb_msg(struct vhost_dev *dev,
 			ret = -EFAULT;
 			break;
 		}
+		/* 把vhost_dev的所有的vhost_virtqueue的VHOST_NUM_ADDRS个vq->meta_iotlb设成NULL */
+		/*
+		 * enum vhost_uaddr_type {
+		 *	VHOST_ADDR_DESC = 0,
+		 *	VHOST_ADDR_AVAIL = 1,
+		 *	VHOST_ADDR_USED = 2,
+		 *	VHOST_NUM_ADDRS = 3,
+		 */
 		vhost_vq_meta_reset(dev);
+		/* 把地址们做成一个vhost_umem_node, 放入dev->iotlb (vhost_umem类型) */
 		if (vhost_new_umem_range(dev->iotlb, msg->iova, msg->size,
 					 msg->iova + msg->size - 1,
 					 msg->uaddr, msg->perm)) {
@@ -1007,6 +1295,7 @@ static int vhost_process_iotlb_msg(struct vhost_dev *dev,
 			ret = -EFAULT;
 			break;
 		}
+		/* 把vhost_dev的所有的vhost_virtqueue的VHOST_NUM_ADDRS个vq->meta_iotlb设成NULL */
 		vhost_vq_meta_reset(dev);
 		vhost_del_umem_range(dev->iotlb, msg->iova,
 				     msg->iova + msg->size - 1);
@@ -1021,6 +1310,7 @@ static int vhost_process_iotlb_msg(struct vhost_dev *dev,
 
 	return ret;
 }
+/* qemu通过这个接口发送VHOST_IOTLB_MISS的回复给vhost */
 ssize_t vhost_chr_write_iter(struct vhost_dev *dev,
 			     struct iov_iter *from)
 {
@@ -1058,6 +1348,7 @@ __poll_t vhost_chr_poll(struct file *file, struct vhost_dev *dev,
 
 	poll_wait(file, &dev->wait, wait);
 
+	/* 由vhost_iotlb_miss()插入 */
 	if (!list_empty(&dev->read_list))
 		mask |= EPOLLIN | EPOLLRDNORM;
 
@@ -1065,6 +1356,7 @@ __poll_t vhost_chr_poll(struct file *file, struct vhost_dev *dev,
 }
 EXPORT_SYMBOL(vhost_chr_poll);
 
+/* qemu通过这个接口读取VHOST_IOTLB_MISS信息 */
 ssize_t vhost_chr_read_iter(struct vhost_dev *dev, struct iov_iter *to,
 			    int noblock)
 {
@@ -1081,6 +1373,7 @@ ssize_t vhost_chr_read_iter(struct vhost_dev *dev, struct iov_iter *to,
 			prepare_to_wait(&dev->wait, &wait,
 					TASK_INTERRUPTIBLE);
 
+		/* 从dev->read_list中取出vhost_msg_node (由vhost_iotlb_miss()插入) */
 		node = vhost_dequeue_msg(dev, &dev->read_list);
 		if (node)
 			break;
@@ -1088,6 +1381,7 @@ ssize_t vhost_chr_read_iter(struct vhost_dev *dev, struct iov_iter *to,
 			ret = -EAGAIN;
 			break;
 		}
+		/* 判断p,TIF_SIGPENDING */
 		if (signal_pending(current)) {
 			ret = -ERESTARTSYS;
 			break;
@@ -1118,12 +1412,45 @@ ssize_t vhost_chr_read_iter(struct vhost_dev *dev, struct iov_iter *to,
 }
 EXPORT_SYMBOL_GPL(vhost_chr_read_iter);
 
+/*
+ *    This patch tries to implement an device IOTLB for vhost. This could be
+ *    used with userspace(qemu) implementation of DMA remapping
+ *    to emulate an IOMMU for the guest.
+ *
+ *    The idea is simple, cache the translation in a software device IOTLB
+ *    (which is implemented as an interval tree) in vhost and use vhost_net
+ *    file descriptor for reporting IOTLB miss and IOTLB
+ *    update/invalidation. When vhost meets an IOTLB miss, the fault
+ *    address, size and access can be read from the file. After userspace
+ *    finishes the translation, it writes the translated address to the
+ *    vhost_net file to update the device IOTLB.
+ *
+ *    When device IOTLB is enabled by setting VIRTIO_F_IOMMU_PLATFORM all vq
+ *    addresses set by ioctl are treated as iova instead of virtual address and
+ *    the accessing can only be done through IOTLB instead of direct userspace
+ *    memory access. Before each round or vq processing, all vq metadata is
+ *    prefetched in device IOTLB to make sure no translation fault happens
+ *    during vq processing.
+ *
+ *    In most cases, virtqueues are contiguous even in virtual address space.
+ *    The IOTLB translation for virtqueue itself may make it a little
+ *    slower. We might add fast path cache on top of this patch.
+ */
+
+/*
+ * called by:
+ *   - iotlb_access_ok()
+ *   - translate_desc()
+ *
+ * 生成一个iotlb请求 插入read_list
+ */
 static int vhost_iotlb_miss(struct vhost_virtqueue *vq, u64 iova, int access)
 {
 	struct vhost_dev *dev = vq->dev;
 	struct vhost_msg_node *node;
 	struct vhost_iotlb_msg *msg;
 
+	/* 分配一个struct vhost_msg_node */
 	node = vhost_new_msg(vq, VHOST_IOTLB_MISS);
 	if (!node)
 		return -ENOMEM;
@@ -1138,6 +1465,12 @@ static int vhost_iotlb_miss(struct vhost_virtqueue *vq, u64 iova, int access)
 	return 0;
 }
 
+/* num是vq->num */
+/*
+ * called by:
+ *   - vhost_vq_access_ok()
+ *   - vhost_vring_ioctl()
+ */
 static bool vq_access_ok(struct vhost_virtqueue *vq, unsigned int num,
 			 struct vring_desc __user *desc,
 			 struct vring_avail __user *avail,
@@ -1153,6 +1486,8 @@ static bool vq_access_ok(struct vhost_virtqueue *vq, unsigned int num,
 			sizeof *used + num * sizeof *used->ring + s);
 }
 
+/* called only by iotlb_access_ok() */
+/* 更新meta_iotlb的地方!!! */
 static void vhost_vq_meta_update(struct vhost_virtqueue *vq,
 				 const struct vhost_umem_node *node,
 				 int type)
@@ -1164,6 +1499,7 @@ static void vhost_vq_meta_update(struct vhost_virtqueue *vq,
 		vq->meta_iotlb[type] = node;
 }
 
+/* called only by vq_iotlb_prefetch() */
 static bool iotlb_access_ok(struct vhost_virtqueue *vq,
 			    int access, u64 addr, u64 len, int type)
 {
@@ -1171,14 +1507,17 @@ static bool iotlb_access_ok(struct vhost_virtqueue *vq,
 	struct vhost_umem *umem = vq->iotlb;
 	u64 s = 0, size, orig_addr = addr, last = addr + len - 1;
 
+	/* 把guest的物理地址转换成qemu userspace的地址 */
 	if (vhost_vq_meta_fetch(vq, addr, len, type))
 		return true;
 
 	while (len > s) {
+		/* umem在上面来自vq->iotlb */
 		node = vhost_umem_interval_tree_iter_first(&umem->umem_tree,
 							   addr,
 							   last);
 		if (node == NULL || node->start > addr) {
+			/* 生成一个iotlb请求 插入read_list */
 			vhost_iotlb_miss(vq, addr, access);
 			return false;
 		} else if (!(node->perm & access)) {
@@ -1202,12 +1541,22 @@ static bool iotlb_access_ok(struct vhost_virtqueue *vq,
 
 int vq_iotlb_prefetch(struct vhost_virtqueue *vq)
 {
+	/* The Guest publishes the used index for which it expects an interrupt
+	 * at the end of the avail ring. Host should ignore the avail->flags field. */
+	/* The Host publishes the avail index for which it expects a kick
+	 * at the end of the used ring. Guest should ignore the used->flags field. */
 	size_t s = vhost_has_feature(vq, VIRTIO_RING_F_EVENT_IDX) ? 2 : 0;
 	unsigned int num = vq->num;
 
+	/*
+	 * 在VIRTIO_F_IOMMU_PLATFORM支持时才使用
+	 *
+	 * 似乎在qemu中默认是不支持的 (需要iommu_platform=true参数)
+	 */
 	if (!vq->iotlb)
 		return 1;
 
+	/* 不行的话在iotlb_access_ok()会生成iotlb miss! */
 	return iotlb_access_ok(vq, VHOST_ACCESS_RO, (u64)(uintptr_t)vq->desc,
 			       num * sizeof(*vq->desc), VHOST_ADDR_DESC) &&
 	       iotlb_access_ok(vq, VHOST_ACCESS_RO, (u64)(uintptr_t)vq->avail,
@@ -1236,6 +1585,7 @@ static bool vq_log_access_ok(struct vhost_virtqueue *vq,
 {
 	size_t s = vhost_has_feature(vq, VIRTIO_RING_F_EVENT_IDX) ? 2 : 0;
 
+	/* 遍历vhost_umem的vhost_umem_node,确认所有得userspace_addr是否都在vhost内核有访问权限 */
 	return vq_memory_access_ok(log_base, vq->umem,
 				   vhost_has_feature(vq, VHOST_F_LOG_ALL)) &&
 		(!vq->log_used || log_access_ok(log_base, vq->log_addr,
@@ -1272,6 +1622,36 @@ static struct vhost_umem *vhost_umem_alloc(void)
 	return umem;
 }
 
+/*
+ * VHOST_SET_MEM_TABLE
+ *
+ * 这个函数设置的vhost_umem, 和iotlb无关
+ *
+ * 似乎vhost_dev和vhost_virtqueue指向的相同的umem
+ */
+
+/*
+ * guest内存3000M的一个例子:
+ *    addr=0xfffc0000, size=0x40000, uaddr=0x7f14eca00000
+ *    addr=0x0, size=0xa0000, uaddr=0x7f1424600000
+ *    addr=0xc0000, size=0xbb740000, uaddr=0x7f14246c0000
+ *    addr=0xfffc0000, size=0x40000, uaddr=0x7f14eca00000
+ *    addr=0x0, size=0xa0000, uaddr=0x7f1424600000
+ *    addr=0xc0000, size=0xbb740000, uaddr=0x7f14246c0000
+ */
+
+/*
+ * guest内存8000M的一个例子:
+ *    addr=0x100000000, size=0x134000000, uaddr=0x7efae3e00000
+ *    addr=0xfffc0000, size=0x40000, uaddr=0x7efc26c00000
+ *    addr=0x0, size=0xa0000, uaddr=0x7efa23e00000
+ *    addr=0xc0000, size=0xbff40000, uaddr=0x7efa23ec0000
+ *    addr=0x100000000, size=0x134000000, uaddr=0x7efae3e00000
+ *    addr=0xfffc0000, size=0x40000, uaddr=0x7efc26c00000
+ *    addr=0x0, size=0xa0000, uaddr=0x7efa23e00000
+ *    addr=0xc0000, size=0xbff40000, uaddr=0x7efa23ec0000
+ */
+
 static long vhost_set_memory(struct vhost_dev *d, struct vhost_memory __user *m)
 {
 	struct vhost_memory mem, *newmem;
@@ -1286,26 +1666,58 @@ static long vhost_set_memory(struct vhost_dev *d, struct vhost_memory __user *m)
 		return -EOPNOTSUPP;
 	if (mem.nregions > max_mem_regions)
 		return -E2BIG;
+	/* 分配的时候把vhost_memory尾部的也分配 */
+	/* 该函数最后会kvfree()掉 */
 	newmem = kvzalloc(size + mem.nregions * sizeof(*m->regions), GFP_KERNEL);
 	if (!newmem)
 		return -ENOMEM;
 
+	/* 这里把参数的m拷贝到了newmem */
 	memcpy(newmem, &mem, size);
+	/* 这里真正把m尾部的成员拷贝到了newmem */
 	if (copy_from_user(newmem->regions, m->regions,
 			   mem.nregions * sizeof *m->regions)) {
 		kvfree(newmem);
 		return -EFAULT;
 	}
 
+	/*
+	 * newmem  是 vhost_memory 该函数最后会kvfree()掉
+	 * newumem 是 vhost_umem
+	 */
 	newumem = vhost_umem_alloc();
 	if (!newumem) {
 		kvfree(newmem);
 		return -ENOMEM;
 	}
 
+	/*
+	 * guest内存3000M的一个例子:
+	 *    addr=0xfffc0000, size=0x40000, uaddr=0x7f14eca00000
+	 *    addr=0x0, size=0xa0000, uaddr=0x7f1424600000
+	 *    addr=0xc0000, size=0xbb740000, uaddr=0x7f14246c0000
+	 *    addr=0xfffc0000, size=0x40000, uaddr=0x7f14eca00000
+	 *    addr=0x0, size=0xa0000, uaddr=0x7f1424600000
+	 *    addr=0xc0000, size=0xbb740000, uaddr=0x7f14246c0000
+	 */
+
+	/*
+	 * guest内存8000M的一个例子:
+	 *    addr=0x100000000, size=0x134000000, uaddr=0x7efae3e00000
+	 *    addr=0xfffc0000, size=0x40000, uaddr=0x7efc26c00000
+	 *    addr=0x0, size=0xa0000, uaddr=0x7efa23e00000
+	 *    addr=0xc0000, size=0xbff40000, uaddr=0x7efa23ec0000
+	 *    addr=0x100000000, size=0x134000000, uaddr=0x7efae3e00000
+	 *    addr=0xfffc0000, size=0x40000, uaddr=0x7efc26c00000
+	 *    addr=0x0, size=0xa0000, uaddr=0x7efa23e00000
+	 *    addr=0xc0000, size=0xbff40000, uaddr=0x7efa23ec0000
+	 */
+
+	/* newmem是从参数m拷贝过来的 */
 	for (region = newmem->regions;
 	     region < newmem->regions + mem.nregions;
 	     region++) {
+		/* 把地址们做成一个vhost_umem_node, 放入vhost_umem */
 		if (vhost_new_umem_range(newumem,
 					 region->guest_phys_addr,
 					 region->memory_size,
@@ -1316,15 +1728,18 @@ static long vhost_set_memory(struct vhost_dev *d, struct vhost_memory __user *m)
 			goto err;
 	}
 
+	/* 遍历vhost_umem的vhost_umem_node,确认所有得userspace_addr是否都在vhost内核有访问权限 */
 	if (!memory_access_ok(d, newumem, 0))
 		goto err;
 
 	oldumem = d->umem;
+	/* 似乎vhost_dev和vhost_virtqueue指向的相同的umem */
 	d->umem = newumem;
 
 	/* All memory accesses are done under some VQ mutex. */
 	for (i = 0; i < d->nvqs; ++i) {
 		mutex_lock(&d->vqs[i]->mutex);
+		/* 似乎vhost_dev和vhost_virtqueue指向的相同的umem */
 		d->vqs[i]->umem = newumem;
 		mutex_unlock(&d->vqs[i]->mutex);
 	}
@@ -1363,7 +1778,7 @@ long vhost_vring_ioctl(struct vhost_dev *d, unsigned int ioctl, void __user *arg
 	mutex_lock(&vq->mutex);
 
 	switch (ioctl) {
-	case VHOST_SET_VRING_NUM:
+	case VHOST_SET_VRING_NUM:  // 设置vq->num
 		/* Resizing ring with an active backend?
 		 * You don't want to do that. */
 		if (vq->private_data) {
@@ -1380,7 +1795,7 @@ long vhost_vring_ioctl(struct vhost_dev *d, unsigned int ioctl, void __user *arg
 		}
 		vq->num = s.num;
 		break;
-	case VHOST_SET_VRING_BASE:
+	case VHOST_SET_VRING_BASE:  // 同时更新vq->last_avail_idx和vq->avail_idx
 		/* Moving base with an active backend?
 		 * You don't want to do that. */
 		if (vq->private_data) {
@@ -1395,6 +1810,7 @@ long vhost_vring_ioctl(struct vhost_dev *d, unsigned int ioctl, void __user *arg
 			r = -EINVAL;
 			break;
 		}
+		/* 同时更新vq->last_avail_idx和vq->avail_idx */
 		vq->last_avail_idx = s.num;
 		/* Forget the cached index value. */
 		vq->avail_idx = vq->last_avail_idx;
@@ -1406,6 +1822,7 @@ long vhost_vring_ioctl(struct vhost_dev *d, unsigned int ioctl, void __user *arg
 			r = -EFAULT;
 		break;
 	case VHOST_SET_VRING_ADDR:
+		/* a 是 struct vhost_vring_addr */
 		if (copy_from_user(&a, argp, sizeof a)) {
 			r = -EFAULT;
 			break;
@@ -1414,6 +1831,7 @@ long vhost_vring_ioctl(struct vhost_dev *d, unsigned int ioctl, void __user *arg
 			r = -EOPNOTSUPP;
 			break;
 		}
+		/* 下面的a是内核空间的 */
 		/* For 32bit, verify that the top 32bits of the user
 		   data are set to zero. */
 		if ((u64)(unsigned long)a.desc_user_addr != a.desc_user_addr ||
@@ -1455,13 +1873,14 @@ long vhost_vring_ioctl(struct vhost_dev *d, unsigned int ioctl, void __user *arg
 			}
 		}
 
+		/* 就是一个赋值 和iotlb无关 */
 		vq->log_used = !!(a.flags & (0x1 << VHOST_VRING_F_LOG));
 		vq->desc = (void __user *)(unsigned long)a.desc_user_addr;
 		vq->avail = (void __user *)(unsigned long)a.avail_user_addr;
 		vq->log_addr = a.log_guest_addr;
 		vq->used = (void __user *)(unsigned long)a.used_user_addr;
 		break;
-	case VHOST_SET_VRING_KICK:
+	case VHOST_SET_VRING_KICK: // 设置host notifier
 		if (copy_from_user(&f, argp, sizeof f)) {
 			r = -EFAULT;
 			break;
@@ -1477,7 +1896,7 @@ long vhost_vring_ioctl(struct vhost_dev *d, unsigned int ioctl, void __user *arg
 		} else
 			filep = eventfp;
 		break;
-	case VHOST_SET_VRING_CALL:
+	case VHOST_SET_VRING_CALL: // 设置guest notifier
 		if (copy_from_user(&f, argp, sizeof f)) {
 			r = -EFAULT;
 			break;
@@ -1532,6 +1951,7 @@ long vhost_vring_ioctl(struct vhost_dev *d, unsigned int ioctl, void __user *arg
 	if (filep)
 		fput(filep);
 
+	/* 这里的poll是vq->poll */
 	if (pollstart && vq->handle_kick)
 		r = vhost_poll_start(&vq->poll, vq->kick);
 
@@ -1543,6 +1963,13 @@ long vhost_vring_ioctl(struct vhost_dev *d, unsigned int ioctl, void __user *arg
 }
 EXPORT_SYMBOL_GPL(vhost_vring_ioctl);
 
+/*
+ * called only by vhost_net_set_features()
+ *
+ * 在VIRTIO_F_IOMMU_PLATFORM支持时才使用
+ *
+ * 似乎在qemu中默认是不支持的 (需要iommu_platform=true参数)
+ */
 int vhost_init_device_iotlb(struct vhost_dev *d, bool enabled)
 {
 	struct vhost_umem *niotlb, *oiotlb;
@@ -1663,6 +2090,14 @@ static int set_bit_to_user(int nr, void __user *addr)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - vhost_log_write()
+ *   - vhost_update_used_flags()
+ *   - vhost_update_avail_event()
+ *   - __vhost_add_used_n()
+ *   - vhost_add_used_n()
+ */
 static int log_write(void __user *log_base,
 		     u64 write_address, u64 write_length)
 {
@@ -1689,6 +2124,10 @@ static int log_write(void __user *log_base,
 	return r;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|996| <<handle_rx>> vhost_log_write(vq, vq_log, log, vhost_len);
+ */
 int vhost_log_write(struct vhost_virtqueue *vq, struct vhost_log *log,
 		    unsigned int log_num, u64 len)
 {
@@ -1714,9 +2153,18 @@ int vhost_log_write(struct vhost_virtqueue *vq, struct vhost_log *log,
 }
 EXPORT_SYMBOL_GPL(vhost_log_write);
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2197| <<vhost_vq_init_access>> r = vhost_update_used_flags(vq);
+ *   - drivers/vhost/vhost.c|2864| <<vhost_enable_notify>> r = vhost_update_used_flags(vq);
+ *   - drivers/vhost/vhost.c|2907| <<vhost_disable_notify>> r = vhost_update_used_flags(vq);
+ *
+ * 把vq->used_flags写入vq->used->flags
+ */
 static int vhost_update_used_flags(struct vhost_virtqueue *vq)
 {
 	void __user *used;
+	/* 把x拷贝到ptr, 在需要的时候先把ptr转换成qemu的userspace地址 */
 	if (vhost_put_user(vq, cpu_to_vhost16(vq, vq->used_flags),
 			   &vq->used->flags) < 0)
 		return -EFAULT;
@@ -1734,8 +2182,15 @@ static int vhost_update_used_flags(struct vhost_virtqueue *vq)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2871| <<vhost_enable_notify>> r = vhost_update_avail_event(vq, vq->avail_idx);
+ *
+ * 把vq->avail_idx放入vq->used->ring[vq->num]
+ */
 static int vhost_update_avail_event(struct vhost_virtqueue *vq, u16 avail_event)
 {
+	/* 把vq->avail_idx放入vq->used->ring[vq->num] */
 	if (vhost_put_user(vq, cpu_to_vhost16(vq, vq->avail_idx),
 			   vhost_avail_event(vq)))
 		return -EFAULT;
@@ -1765,6 +2220,7 @@ int vhost_vq_init_access(struct vhost_virtqueue *vq)
 
 	vhost_init_is_le(vq);
 
+	/* 把vq->used_flags写入vq->used->flags */
 	r = vhost_update_used_flags(vq);
 	if (r)
 		goto err;
@@ -1789,18 +2245,31 @@ int vhost_vq_init_access(struct vhost_virtqueue *vq)
 }
 EXPORT_SYMBOL_GPL(vhost_vq_init_access);
 
+/*
+ * 把desc中的地址转换成qemu userspace的地址存放在iov中
+ *
+ * iov_size是从iov开始剩下可用的iov
+ */
 static int translate_desc(struct vhost_virtqueue *vq, u64 addr, u32 len,
 			  struct iovec iov[], int iov_size, int access)
 {
 	const struct vhost_umem_node *node;
 	struct vhost_dev *dev = vq->dev;
 	struct vhost_umem *umem = dev->iotlb ? dev->iotlb : dev->umem;
+	/*
+	 * struct iovec
+	 * {
+	 *     void __user *iov_base;  // BSD uses caddr_t (1003.1g requires void *)
+	 *     __kernel_size_t iov_len; // Must be size_t (1003.1g)
+	 * };
+	 */
 	struct iovec *_iov;
 	u64 s = 0;
 	int ret = 0;
 
 	while ((u64)len > s) {
 		u64 size;
+		/* iov_size是从iov开始剩下可用的iov */
 		if (unlikely(ret >= iov_size)) {
 			ret = -ENOBUFS;
 			break;
@@ -1820,7 +2289,9 @@ static int translate_desc(struct vhost_virtqueue *vq, u64 addr, u32 len,
 			break;
 		}
 
+		/* _iov是本地临时变量 指向iov+ret*/
 		_iov = iov + ret;
+		/* addr是desc的addr */
 		size = node->size - addr + node->start;
 		_iov->iov_len = min((u64)len - s, size);
 		_iov->iov_base = (void __user *)(unsigned long)
@@ -1851,6 +2322,10 @@ static unsigned next_desc(struct vhost_virtqueue *vq, struct vring_desc *desc)
 	return next;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2477| <<vhost_get_vq_desc>> ret = get_indirect(vq, iov, iov_size,
+ */
 static int get_indirect(struct vhost_virtqueue *vq,
 			struct iovec iov[], unsigned int iov_size,
 			unsigned int *out_num, unsigned int *in_num,
@@ -1957,6 +2432,11 @@ static int get_indirect(struct vhost_virtqueue *vq,
  * This function returns the descriptor number found, or vq->num (which is
  * never a valid descriptor number) if none was found.  A negative code is
  * returned on error. */
+/*
+ * 把desc中的信息拷贝到iov (地址会转换成qemu userspace的地址)
+ *
+ * iov_size的一种可能是ARRAY_SIZE(vq->iov)
+ */
 int vhost_get_vq_desc(struct vhost_virtqueue *vq,
 		      struct iovec iov[], unsigned int iov_size,
 		      unsigned int *out_num, unsigned int *in_num,
@@ -1970,14 +2450,40 @@ int vhost_get_vq_desc(struct vhost_virtqueue *vq,
 	int ret, access;
 
 	/* Check it isn't doing very strange things with descriptor numbers. */
+	/*
+	 * 在以下修改vhost_virtqueue->last_avail_idx:
+	 *   - drivers/vhost/vhost.c|426| <<vhost_vq_reset>> vq->last_avail_idx = 0;
+	 *   - drivers/vhost/vhost.c|1795| <<vhost_vring_ioctl>> vq->last_avail_idx = s.num;
+	 *   - drivers/vhost/vhost.c|2579| <<vhost_get_vq_desc>> vq->last_avail_idx++;
+	 *   - drivers/vhost/vhost.c|2591| <<vhost_discard_vq_desc>> vq->last_avail_idx -= n;
+	 * 在以下使用vhost_virtqueue->last_avail_idx:
+	 *   - drivers/vhost/vhost.c|1797| <<vhost_vring_ioctl>> vq->avail_idx = vq->last_avail_idx;
+	 *   - drivers/vhost/vhost.c|1801| <<vhost_vring_ioctl>> s.num = vq->last_avail_idx;
+	 *   - drivers/vhost/vhost.c|2421| <<vhost_get_vq_desc>> last_avail_idx = vq->last_avail_idx;
+	 *   - drivers/vhost/vhost.c|2424| <<vhost_get_vq_desc>> if (vq->avail_idx == vq->last_avail_idx) {
+	 *   - drivers/vhost/vhost.c|2712| <<vhost_notify>> unlikely(vq->avail_idx == vq->last_avail_idx))
+	 *   - drivers/vhost/vhost.c|2791| <<vhost_vq_avail_empty>> if (vq->avail_idx != vq->last_avail_idx)
+	 *   - drivers/vhost/vhost.c|2800| <<vhost_vq_avail_empty>> return vq->avail_idx == vq->last_avail_idx;
+	 */
 	last_avail_idx = vq->last_avail_idx;
 
+	/* 其实一般来说vq->avail_idx应该比vq->last_avail_idx更新的 */
 	if (vq->avail_idx == vq->last_avail_idx) {
+		/*
+		 * struct vhost_virtqueue *vq:
+		 *  -> struct vring_avail __user *avail;
+		 *      -> __virtio16 flags;
+		 *      -> __virtio16 idx;
+		 *      -> __virtio16 ring[];
+		 *
+		 * 把&vq->avail->idx的值放入avail_idx
+		 */
 		if (unlikely(vhost_get_avail(vq, avail_idx, &vq->avail->idx))) {
 			vq_err(vq, "Failed to access avail idx at %p\n",
 				&vq->avail->idx);
 			return -EFAULT;
 		}
+		/* ------------>>>>>>>>>>> 更新vq->avail_idx */
 		vq->avail_idx = vhost16_to_cpu(vq, avail_idx);
 
 		if (unlikely((u16)(vq->avail_idx - last_avail_idx) > vq->num)) {
@@ -2000,6 +2506,15 @@ int vhost_get_vq_desc(struct vhost_virtqueue *vq,
 
 	/* Grab the next descriptor number they're advertising, and increment
 	 * the index we've seen. */
+	/*
+	 * struct vhost_virtqueue *vq:
+	 *  -> struct vring_avail __user *avail;
+	 *      -> __virtio16 flags;
+	 *      -> __virtio16 idx;
+	 *      -> __virtio16 ring[];
+	 *
+	 * 在vq->avail->ring中获取desc head
+	 */
 	if (unlikely(vhost_get_avail(vq, ring_head,
 		     &vq->avail->ring[last_avail_idx & (vq->num - 1)]))) {
 		vq_err(vq, "Failed to read head: idx %d address %p\n",
@@ -2008,6 +2523,7 @@ int vhost_get_vq_desc(struct vhost_virtqueue *vq,
 		return -EFAULT;
 	}
 
+	/* ring_head来自上面的vq->avail->ring中 */
 	head = vhost16_to_cpu(vq, ring_head);
 
 	/* If their number is silly, that's an error. */
@@ -2024,18 +2540,23 @@ int vhost_get_vq_desc(struct vhost_virtqueue *vq,
 
 	i = head;
 	do {
+		/* 第一次进入的时候iov_count, in_num, out_num都是 0 */
 		unsigned iov_count = *in_num + *out_num;
 		if (unlikely(i >= vq->num)) {
 			vq_err(vq, "Desc index is %u > %u, head = %u",
 			       i, vq->num, head);
 			return -EINVAL;
 		}
+		/* 第一次进入的时候found也是 0 */
 		if (unlikely(++found > vq->num)) {
 			vq_err(vq, "Loop detected: last one at %u "
 			       "vq size %u head %u\n",
 			       i, vq->num, head);
 			return -EINVAL;
 		}
+		/*
+		 * desc是在本地申请的变量
+		 */
 		ret = vhost_copy_from_user(vq, &desc, vq->desc + i,
 					   sizeof desc);
 		if (unlikely(ret)) {
@@ -2056,10 +2577,21 @@ int vhost_get_vq_desc(struct vhost_virtqueue *vq,
 			continue;
 		}
 
+		/* This marks a buffer as write-only (otherwise read-only). */
 		if (desc.flags & cpu_to_vhost16(vq, VRING_DESC_F_WRITE))
 			access = VHOST_ACCESS_WO;
 		else
 			access = VHOST_ACCESS_RO;
+		/* 第一次进入的时候iov_count是0 */
+		/*
+		 * struct iovec
+		 * {
+		 *     void __user *iov_base;  // BSD uses caddr_t (1003.1g requires void *)
+		 *     __kernel_size_t iov_len; // Must be size_t (1003.1g)
+		 * };
+		 *
+		 * 把desc中的地址转换成qemu userspace的地址存放在iov中
+		 */
 		ret = translate_desc(vq, vhost64_to_cpu(vq, desc.addr),
 				     vhost32_to_cpu(vq, desc.len), iov + iov_count,
 				     iov_size - iov_count, access);
@@ -2088,9 +2620,24 @@ int vhost_get_vq_desc(struct vhost_virtqueue *vq,
 			}
 			*out_num += ret;
 		}
-	} while ((i = next_desc(vq, &desc)) != -1);
+	} while ((i = next_desc(vq, &desc)) != -1); // ----> VRING_DESC_F_NEXT
 
 	/* On success, increment avail index. */
+	/*
+	 * 在以下修改vhost_virtqueue->last_avail_idx:
+	 *   - drivers/vhost/vhost.c|426| <<vhost_vq_reset>> vq->last_avail_idx = 0;
+	 *   - drivers/vhost/vhost.c|1795| <<vhost_vring_ioctl>> vq->last_avail_idx = s.num;
+	 *   - drivers/vhost/vhost.c|2579| <<vhost_get_vq_desc>> vq->last_avail_idx++;
+	 *   - drivers/vhost/vhost.c|2591| <<vhost_discard_vq_desc>> vq->last_avail_idx -= n;
+	 * 在以下使用vhost_virtqueue->last_avail_idx:
+	 *   - drivers/vhost/vhost.c|1797| <<vhost_vring_ioctl>> vq->avail_idx = vq->last_avail_idx;
+	 *   - drivers/vhost/vhost.c|1801| <<vhost_vring_ioctl>> s.num = vq->last_avail_idx;
+	 *   - drivers/vhost/vhost.c|2421| <<vhost_get_vq_desc>> last_avail_idx = vq->last_avail_idx;
+	 *   - drivers/vhost/vhost.c|2424| <<vhost_get_vq_desc>> if (vq->avail_idx == vq->last_avail_idx) {
+	 *   - drivers/vhost/vhost.c|2712| <<vhost_notify>> unlikely(vq->avail_idx == vq->last_avail_idx))
+	 *   - drivers/vhost/vhost.c|2791| <<vhost_vq_avail_empty>> if (vq->avail_idx != vq->last_avail_idx)
+	 *   - drivers/vhost/vhost.c|2800| <<vhost_vq_avail_empty>> return vq->avail_idx == vq->last_avail_idx;
+	 */
 	vq->last_avail_idx++;
 
 	/* Assume notifications from guest are disabled at this point,
@@ -2101,6 +2648,13 @@ int vhost_get_vq_desc(struct vhost_virtqueue *vq,
 EXPORT_SYMBOL_GPL(vhost_get_vq_desc);
 
 /* Reverse the effect of vhost_get_vq_desc. Useful for error handling. */
+/*
+ * called by:
+ *   - drivers/vhost/net.c|659| <<handle_tx>> vhost_discard_vq_desc(vq, 1);
+ *   - drivers/vhost/net.c|854| <<get_rx_bufs>> vhost_discard_vq_desc(vq, headcount);
+ *   - drivers/vhost/net.c|965| <<handle_rx>> vhost_discard_vq_desc(vq, headcount);
+ *   - drivers/vhost/net.c|989| <<handle_rx>> vhost_discard_vq_desc(vq, headcount);
+ */
 void vhost_discard_vq_desc(struct vhost_virtqueue *vq, int n)
 {
 	vq->last_avail_idx -= n;
@@ -2109,6 +2663,13 @@ EXPORT_SYMBOL_GPL(vhost_discard_vq_desc);
 
 /* After we've used one of their buffers, we tell them about it.  We'll then
  * want to notify the guest, using eventfd. */
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|844| <<vhost_scsi_complete_cmd_work>> vhost_add_used(cmd->tvc_vq, cmd->tvc_vq_desc, 0);
+ *   - drivers/vhost/vhost.c|2745| <<vhost_add_used_and_signal>> vhost_add_used(vq, head, len);
+ *   - drivers/vhost/vsock.c|166| <<vhost_transport_do_send_pkt>> vhost_add_used(vq, head, sizeof(pkt->hdr) + pkt->len);
+ *   - drivers/vhost/vsock.c|400| <<vhost_vsock_handle_tx_kick>> vhost_add_used(vq, head, sizeof(pkt->hdr) + len);
+ */
 int vhost_add_used(struct vhost_virtqueue *vq, unsigned int head, int len)
 {
 	struct vring_used_elem heads = {
@@ -2165,6 +2726,11 @@ static int __vhost_add_used_n(struct vhost_virtqueue *vq,
 
 /* After we've used one of their buffers, we tell them about it.  We'll then
  * want to notify the guest, using eventfd. */
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2611| <<vhost_add_used>> return vhost_add_used_n(vq, &heads, 1);
+ *   - drivers/vhost/vhost.c|2762| <<vhost_add_used_and_signal_n>> vhost_add_used_n(vq, heads, count);
+ */
 int vhost_add_used_n(struct vhost_virtqueue *vq, struct vring_used_elem *heads,
 		     unsigned count)
 {
@@ -2172,6 +2738,7 @@ int vhost_add_used_n(struct vhost_virtqueue *vq, struct vring_used_elem *heads,
 
 	start = vq->last_used_idx & (vq->num - 1);
 	n = vq->num - start;
+	/* n是从当前last_used_idx到一处前的数目 */
 	if (n < count) {
 		r = __vhost_add_used_n(vq, heads, n);
 		if (r < 0)
@@ -2214,6 +2781,10 @@ static bool vhost_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 	    unlikely(vq->avail_idx == vq->last_avail_idx))
 		return true;
 
+	/* The Guest publishes the used index for which it expects an interrupt
+	 * at the end of the avail ring. Host should ignore the avail->flags field. */
+	/* The Host publishes the avail index for which it expects a kick
+	 * at the end of the used ring. Guest should ignore the used->flags field. */
 	if (!vhost_has_feature(vq, VIRTIO_RING_F_EVENT_IDX)) {
 		__virtio16 flags;
 		if (vhost_get_avail(vq, flags, &vq->avail->flags)) {
@@ -2238,6 +2809,7 @@ static bool vhost_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 }
 
 /* This actually signals the guest, using eventfd. */
+/* 根据情况用eventfd_signal()通知call_ctx */
 void vhost_signal(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 {
 	/* Signal the Guest tell them we used something up. */
@@ -2247,6 +2819,13 @@ void vhost_signal(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 EXPORT_SYMBOL_GPL(vhost_signal);
 
 /* And here's the combo meal deal.  Supersize me! */
+/*
+ * called by:
+ *   - drivers/vhost/net.c|667| <<handle_tx>> vhost_add_used_and_signal(&net->dev, vq, head, 0);
+ *   - drivers/vhost/scsi.c|731| <<vhost_scsi_do_evt_work>> vhost_add_used_and_signal(&vs->dev, vq, head, 0);
+ *   - drivers/vhost/scsi.c|1181| <<vhost_scsi_send_bad_target>> vhost_add_used_and_signal(&vs->dev, vq, head, 0);
+ *   - drivers/vhost/test.c|82| <<handle_vq>> vhost_add_used_and_signal(&n->dev, vq, head, 0);
+ */
 void vhost_add_used_and_signal(struct vhost_dev *dev,
 			       struct vhost_virtqueue *vq,
 			       unsigned int head, int len)
@@ -2262,11 +2841,17 @@ void vhost_add_used_and_signal_n(struct vhost_dev *dev,
 				 struct vring_used_elem *heads, unsigned count)
 {
 	vhost_add_used_n(vq, heads, count);
+	/* 根据情况用eventfd_signal()通知call_ctx */
 	vhost_signal(dev, vq);
 }
 EXPORT_SYMBOL_GPL(vhost_add_used_and_signal_n);
 
 /* return true if we're sure that avaiable ring is empty */
+/*
+ * 判断vq->avail_idx是否等于vq->last_avail_idx
+ *   - vq->avail_idx是刚刚从ring buffer获得的index
+ *   - vq->last_avail_idx是上次使用到的index
+ */
 bool vhost_vq_avail_empty(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 {
 	__virtio16 avail_idx;
@@ -2275,6 +2860,7 @@ bool vhost_vq_avail_empty(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 	if (vq->avail_idx != vq->last_avail_idx)
 		return false;
 
+	/* 从&vq->avail->idx拷贝到avail_idx, 在需要的时候先把ptr转换成qemu的userspace地址 */
 	r = vhost_get_avail(vq, avail_idx, &vq->avail->idx);
 	if (unlikely(r))
 		return false;
@@ -2285,15 +2871,23 @@ bool vhost_vq_avail_empty(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 EXPORT_SYMBOL_GPL(vhost_vq_avail_empty);
 
 /* OK, now we need to know about added descriptors. */
+/*
+ * 根据情况 去掉VRING_USED_F_NO_NOTIFY
+ * 如果不支持VIRTIO_RING_F_EVENT_IDX 把vq->used_flags写入vq->used->flags
+ */
 bool vhost_enable_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 {
 	__virtio16 avail_idx;
 	int r;
 
+	/* 如果没有设置VRING_USED_F_NO_NOTIFY 返回false 就不用enable了*/
 	if (!(vq->used_flags & VRING_USED_F_NO_NOTIFY))
 		return false;
+	/* 否则得话去掉VRING_USED_F_NO_NOTIFY */
 	vq->used_flags &= ~VRING_USED_F_NO_NOTIFY;
+	/* 如果不支持VIRTIO_RING_F_EVENT_IDX 把vq->used_flags写入vq->used->flags */
 	if (!vhost_has_feature(vq, VIRTIO_RING_F_EVENT_IDX)) {
+		/* 把vq->used_flags写入vq->used->flags */
 		r = vhost_update_used_flags(vq);
 		if (r) {
 			vq_err(vq, "Failed to enable notification at %p: %d\n",
@@ -2323,6 +2917,26 @@ bool vhost_enable_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 EXPORT_SYMBOL_GPL(vhost_enable_notify);
 
 /* We don't need to be notified again. */
+/*
+ * called by:
+ *   - drivers/vhost/net.c|568| <<handle_tx>> vhost_disable_notify(&net->dev, vq);
+ *   - drivers/vhost/net.c|593| <<handle_tx>> vhost_disable_notify(&net->dev, vq);
+ *   - drivers/vhost/net.c|751| <<vhost_net_rx_peek_head_len>> vhost_disable_notify(&net->dev, vq);
+ *   - drivers/vhost/net.c|766| <<vhost_net_rx_peek_head_len>> vhost_disable_notify(&net->dev, vq);
+ *   - drivers/vhost/net.c|900| <<handle_rx>> vhost_disable_notify(&net->dev, vq);
+ *   - drivers/vhost/net.c|928| <<handle_rx>> vhost_disable_notify(&net->dev, vq);
+ *   - drivers/vhost/scsi.c|701| <<vhost_scsi_do_evt_work>> vhost_disable_notify(&vs->dev, vq);
+ *   - drivers/vhost/scsi.c|1230| <<vhost_scsi_handle_vq>> vhost_disable_notify(&vs->dev, vq);
+ *   - drivers/vhost/scsi.c|1252| <<vhost_scsi_handle_vq>> vhost_disable_notify(&vs->dev, vq);
+ *   - drivers/vhost/test.c|53| <<handle_vq>> vhost_disable_notify(&n->dev, vq);
+ *   - drivers/vhost/test.c|66| <<handle_vq>> vhost_disable_notify(&n->dev, vq);
+ *   - drivers/vhost/vsock.c|97| <<vhost_transport_do_send_pkt>> vhost_disable_notify(&vsock->dev, vq);
+ *   - drivers/vhost/vsock.c|137| <<vhost_transport_do_send_pkt>> vhost_disable_notify(&vsock->dev, vq);
+ *   - drivers/vhost/vsock.c|358| <<vhost_vsock_handle_tx_kick>> vhost_disable_notify(&vsock->dev, vq);
+ *   - drivers/vhost/vsock.c|377| <<vhost_vsock_handle_tx_kick>> vhost_disable_notify(&vsock->dev, vq);
+ *
+ * 如果不支持VIRTIO_RING_F_EVENT_IDX 在vq->used->flags中通知guest VRING_USED_F_NO_NOTIFY
+ */
 void vhost_disable_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 {
 	int r;
@@ -2330,7 +2944,12 @@ void vhost_disable_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 	if (vq->used_flags & VRING_USED_F_NO_NOTIFY)
 		return;
 	vq->used_flags |= VRING_USED_F_NO_NOTIFY;
+	/* The Guest publishes the used index for which it expects an interrupt
+	 * at the end of the avail ring. Host should ignore the avail->flags field. */
+	/* The Host publishes the avail index for which it expects a kick
+	 * at the end of the used ring. Guest should ignore the used->flags field. */
 	if (!vhost_has_feature(vq, VIRTIO_RING_F_EVENT_IDX)) {
+		/* 把vq->used_flags写入vq->used->flags */
 		r = vhost_update_used_flags(vq);
 		if (r)
 			vq_err(vq, "Failed to enable notification at %p: %d\n",
@@ -2340,6 +2959,10 @@ void vhost_disable_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 EXPORT_SYMBOL_GPL(vhost_disable_notify);
 
 /* Create a new message. */
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|1440| <<vhost_iotlb_miss>> node = vhost_new_msg(vq, VHOST_IOTLB_MISS);
+ */
 struct vhost_msg_node *vhost_new_msg(struct vhost_virtqueue *vq, int type)
 {
 	struct vhost_msg_node *node = kmalloc(sizeof *node, GFP_KERNEL);
@@ -2354,6 +2977,11 @@ struct vhost_msg_node *vhost_new_msg(struct vhost_virtqueue *vq, int type)
 }
 EXPORT_SYMBOL_GPL(vhost_new_msg);
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|1394| <<vhost_chr_read_iter>> vhost_enqueue_msg(dev, &dev->pending_list, node);
+ *   - drivers/vhost/vhost.c|1449| <<vhost_iotlb_miss>> vhost_enqueue_msg(dev, &dev->read_list, node);
+ */
 void vhost_enqueue_msg(struct vhost_dev *dev, struct list_head *head,
 		       struct vhost_msg_node *node)
 {
@@ -2365,6 +2993,12 @@ void vhost_enqueue_msg(struct vhost_dev *dev, struct list_head *head,
 }
 EXPORT_SYMBOL_GPL(vhost_enqueue_msg);
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|1363| <<vhost_chr_read_iter>> node = vhost_dequeue_msg(dev, &dev->read_list);
+ *
+ * 从head中取出vhost_msg_node
+ */
 struct vhost_msg_node *vhost_dequeue_msg(struct vhost_dev *dev,
 					 struct list_head *head)
 {
diff --git a/drivers/vhost/vhost.h b/drivers/vhost/vhost.h
index 6c844b90..653730ff 100644
--- a/drivers/vhost/vhost.h
+++ b/drivers/vhost/vhost.h
@@ -58,10 +58,10 @@ struct vhost_log {
 struct vhost_umem_node {
 	struct rb_node rb;
 	struct list_head link;
-	__u64 start;
+	__u64 start;            // 似乎是guest中的物理地址
 	__u64 last;
 	__u64 size;
-	__u64 userspace_addr;
+	__u64 userspace_addr;   // 似乎是guest在qemu userspace的地址
 	__u32 perm;
 	__u32 flags_padding;
 	__u64 __subtree_last;
@@ -69,7 +69,7 @@ struct vhost_umem_node {
 
 struct vhost_umem {
 	struct rb_root_cached umem_tree;
-	struct list_head umem_list;
+	struct list_head umem_list;  // 链接上面的struct vhost_umem_node
 	int numem;
 };
 
@@ -90,7 +90,7 @@ struct vhost_virtqueue {
 	struct vring_desc __user *desc;
 	struct vring_avail __user *avail;
 	struct vring_used __user *used;
-	const struct vhost_umem_node *meta_iotlb[VHOST_NUM_ADDRS];
+	const struct vhost_umem_node *meta_iotlb[VHOST_NUM_ADDRS]; // VHOST_NUM_ADDRS定义在上面
 	struct file *kick;
 	struct eventfd_ctx *call_ctx;
 	struct eventfd_ctx *error_ctx;
@@ -99,9 +99,41 @@ struct vhost_virtqueue {
 	struct vhost_poll poll;
 
 	/* The routine to call when the Guest pings us, or timeout. */
+	/*
+	 * 在以下设置vhost_virtqueue->handle_kick:
+	 *   - drivers/vhost/net.c|1129| <<vhost_net_open>> n->vqs[VHOST_NET_VQ_TX].vq.handle_kick = handle_tx_kick;
+	 *   - drivers/vhost/net.c|1130| <<vhost_net_open>> n->vqs[VHOST_NET_VQ_RX].vq.handle_kick = handle_rx_kick;
+	 *   - drivers/vhost/scsi.c|1611| <<vhost_scsi_open>> vs->vqs[VHOST_SCSI_VQ_CTL].vq.handle_kick = vhost_scsi_ctl_handle_kick;
+	 *   - drivers/vhost/scsi.c|1612| <<vhost_scsi_open>> vs->vqs[VHOST_SCSI_VQ_EVT].vq.handle_kick = vhost_scsi_evt_handle_kick;
+	 *   - drivers/vhost/scsi.c|1615| <<vhost_scsi_open>> vs->vqs[i].vq.handle_kick = vhost_scsi_handle_kick;
+	 *   - drivers/vhost/test.c|118| <<vhost_test_open>> n->vqs[VHOST_TEST_VQ].handle_kick = handle_vq_kick;
+	 *   - drivers/vhost/vsock.c|527| <<vhost_vsock_dev_open>> vsock->vqs[VSOCK_VQ_TX].handle_kick = vhost_vsock_handle_tx_kick;
+	 *   - drivers/vhost/vsock.c|528| <<vhost_vsock_dev_open>> vsock->vqs[VSOCK_VQ_RX].handle_kick = vhost_vsock_handle_rx_kick;
+	 *
+	 * 在以下一处会调用相关:
+	 *   - drivers/vhost/vhost.c|580| <<vhost_dev_init>> vhost_poll_init(&vq->poll, vq->handle_kick,
+	 *     579                 if (vq->handle_kick)
+	 *     580                         vhost_poll_init(&vq->poll, vq->handle_kick,
+	 *     581                                         EPOLLIN, dev);
+	 */
 	vhost_work_fn_t handle_kick;
 
 	/* Last available index we saw. */
+	/*
+	 * 在以下修改vhost_virtqueue->last_avail_idx:
+	 *   - drivers/vhost/vhost.c|426| <<vhost_vq_reset>> vq->last_avail_idx = 0;
+	 *   - drivers/vhost/vhost.c|1795| <<vhost_vring_ioctl>> vq->last_avail_idx = s.num;
+	 *   - drivers/vhost/vhost.c|2579| <<vhost_get_vq_desc>> vq->last_avail_idx++;
+	 *   - drivers/vhost/vhost.c|2591| <<vhost_discard_vq_desc>> vq->last_avail_idx -= n;
+	 * 在以下使用vhost_virtqueue->last_avail_idx:
+	 *   - drivers/vhost/vhost.c|1797| <<vhost_vring_ioctl>> vq->avail_idx = vq->last_avail_idx;
+	 *   - drivers/vhost/vhost.c|1801| <<vhost_vring_ioctl>> s.num = vq->last_avail_idx;
+	 *   - drivers/vhost/vhost.c|2421| <<vhost_get_vq_desc>> last_avail_idx = vq->last_avail_idx;
+	 *   - drivers/vhost/vhost.c|2424| <<vhost_get_vq_desc>> if (vq->avail_idx == vq->last_avail_idx) {
+	 *   - drivers/vhost/vhost.c|2712| <<vhost_notify>> unlikely(vq->avail_idx == vq->last_avail_idx))
+	 *   - drivers/vhost/vhost.c|2791| <<vhost_vq_avail_empty>> if (vq->avail_idx != vq->last_avail_idx)
+	 *   - drivers/vhost/vhost.c|2800| <<vhost_vq_avail_empty>> return vq->avail_idx == vq->last_avail_idx;
+	 */
 	u16 last_avail_idx;
 
 	/* Caches available index value from user. */
@@ -128,9 +160,9 @@ struct vhost_virtqueue {
 	struct iovec *indirect;
 	struct vring_used_elem *heads;
 	/* Protected by virtqueue mutex. */
-	struct vhost_umem *umem;
+	struct vhost_umem *umem;  // 似乎vhost_dev和vhost_virtqueue指向的相同的umem
 	struct vhost_umem *iotlb;
-	void *private_data;
+	void *private_data; // 存着tap的struct socket
 	u64 acked_features;
 	/* Log write descriptors */
 	void __user *log_base;
@@ -143,7 +175,7 @@ struct vhost_virtqueue {
 	/* Ring endianness requested by userspace for cross-endian support. */
 	bool user_be;
 #endif
-	u32 busyloop_timeout;
+	u32 busyloop_timeout; /* 通过VHOST_SET_VRING_BUSYLOOP_TIMEOUT设置 */
 };
 
 struct vhost_msg_node {
@@ -158,13 +190,18 @@ struct vhost_dev {
 	struct vhost_virtqueue **vqs;
 	int nvqs;
 	struct eventfd_ctx *log_ctx;
-	struct llist_head work_list;
+	struct llist_head work_list;  // work_list的work被下面的worker处理
 	struct task_struct *worker;
-	struct vhost_umem *umem;
-	struct vhost_umem *iotlb;
+	struct vhost_umem *umem;  // iotlb和umem好像优先使用iotlb 似乎vhost_dev和vhost_virtqueue指向的相同的umem
+	/*
+	 * 在VIRTIO_F_IOMMU_PLATFORM支持时才使用
+	 *
+	 * 似乎在qemu中默认是不支持的 (需要iommu_platform=true参数)
+	 */
+	struct vhost_umem *iotlb; // iotlb和umem好像优先使用iotlb
 	spinlock_t iotlb_lock;
-	struct list_head read_list;
-	struct list_head pending_list;
+	struct list_head read_list;  // 由vhost_iotlb_miss()插入
+	struct list_head pending_list;  // 存放的vhost_msg_node 由vhost_chr_read_iter插入
 	wait_queue_head_t wait;
 };
 
diff --git a/drivers/vhost/vringh.c b/drivers/vhost/vringh.c
index bb8971f2..cbb450bd 100644
--- a/drivers/vhost/vringh.c
+++ b/drivers/vhost/vringh.c
@@ -14,6 +14,29 @@
 #include <linux/export.h>
 #include <uapi/linux/virtio_config.h>
 
+/*
+ * called by:
+ *   - drivers/vhost/vringh.c|44| <<__vringh_get_head>> vringh_bad("Failed to access avail idx at %p",
+ *   - drivers/vhost/vringh.c|59| <<__vringh_get_head>> vringh_bad("Failed to read head: idx %d address %p",
+ *   - drivers/vhost/vringh.c|65| <<__vringh_get_head>> vringh_bad("Guest says index %u > %u is available",
+ *   - drivers/vhost/vringh.c|131| <<range_check>> vringh_bad("Wrapping descriptor %zu@0x%llx",
+ *   - drivers/vhost/vringh.c|167| <<move_to_indirect>> vringh_bad("Multilevel indirect %u->%u", *up_next, *i);
+ *   - drivers/vhost/vringh.c|173| <<move_to_indirect>> vringh_bad("Strange indirect len %u", desc->len);
+ *   - drivers/vhost/vringh.c|348| <<__vringh_iov>> vringh_bad("Descriptor loop in %p", descs);
+ *   - drivers/vhost/vringh.c|358| <<__vringh_iov>> vringh_bad("Readable desc %p after writable",
+ *   - drivers/vhost/vringh.c|366| <<__vringh_iov>> vringh_bad("Unexpected %s desc"
+ *   - drivers/vhost/vringh.c|414| <<__vringh_iov>> vringh_bad("Chained index %u > %u", i, desc_max);
+ *   - drivers/vhost/vringh.c|455| <<__vringh_complete>> vringh_bad("Failed to write %u used entries %u at %p",
+ *   - drivers/vhost/vringh.c|465| <<__vringh_complete>> vringh_bad("Failed to update used index at %p",
+ *   - drivers/vhost/vringh.c|494| <<__vringh_need_notify>> vringh_bad("Failed to get flags at %p",
+ *   - drivers/vhost/vringh.c|505| <<__vringh_need_notify>> vringh_bad("Failed to get used event idx at %p",
+ *   - drivers/vhost/vringh.c|534| <<__vringh_notify_enable>> vringh_bad("Clearing used flags %p",
+ *   - drivers/vhost/vringh.c|541| <<__vringh_notify_enable>> vringh_bad("Updating avail event index %p",
+ *   - drivers/vhost/vringh.c|552| <<__vringh_notify_enable>> vringh_bad("Failed to check avail idx at %p",
+ *   - drivers/vhost/vringh.c|571| <<__vringh_notify_disable>> vringh_bad("Setting used flags %p",
+ *   - drivers/vhost/vringh.c|644| <<vringh_init_user>> vringh_bad("Bad ring size %u", num);
+ *   - drivers/vhost/vringh.c|984| <<vringh_init_kern>> vringh_bad("Bad ring size %u", num);
+ */
 static __printf(1,2) __cold void vringh_bad(const char *fmt, ...)
 {
 	static DEFINE_RATELIMIT_STATE(vringh_rs,
@@ -29,6 +52,13 @@ static __printf(1,2) __cold void vringh_bad(const char *fmt, ...)
 }
 
 /* Returns vring->num if empty, -ve on error. */
+/*
+ * called by:
+ *   - drivers/vhost/vringh.c|722| <<vringh_getdesc_user>> err = __vringh_get_head(vrh, getu16_user, &vrh->last_avail_idx);
+ *   - drivers/vhost/vringh.c|1055| <<vringh_getdesc_kern>> err = __vringh_get_head(vrh, getu16_kern, &vrh->last_avail_idx);
+ *
+ * 把vrh->vring.avail->ring中的下一个desc的index放入*last_avail_idx
+ */
 static inline int __vringh_get_head(const struct vringh *vrh,
 				    int (*getu16)(const struct vringh *vrh,
 						  u16 *val, const __virtio16 *p),
@@ -37,6 +67,7 @@ static inline int __vringh_get_head(const struct vringh *vrh,
 	u16 avail_idx, i, head;
 	int err;
 
+	/* getu16的定义把*p拷入val */
 	err = getu16(vrh, &avail_idx, &vrh->vring.avail->idx);
 	if (err) {
 		vringh_bad("Failed to access avail idx at %p",
@@ -70,6 +101,13 @@ static inline int __vringh_get_head(const struct vringh *vrh,
 }
 
 /* Copy some bytes to/from the iovec.  Returns num copied. */
+/*
+ * called by:
+ *   - drivers/vhost/vringh.c|779| <<vringh_iov_pull_user>> return vringh_iov_xfer((struct vringh_kiov *)riov,
+ *   - drivers/vhost/vringh.c|801| <<vringh_iov_push_user>> return vringh_iov_xfer((struct vringh_kiov *)wiov,
+ *   - drivers/vhost/vringh.c|1086| <<vringh_iov_pull_kern>> return vringh_iov_xfer(riov, dst, len, xfer_kern);
+ *   - drivers/vhost/vringh.c|1104| <<vringh_iov_push_kern>> return vringh_iov_xfer(wiov, (void *)src, len, xfer_kern);
+ */
 static inline ssize_t vringh_iov_xfer(struct vringh_kiov *iov,
 				      void *ptr, size_t len,
 				      int (*xfer)(void *addr, void *ptr,
@@ -77,6 +115,8 @@ static inline ssize_t vringh_iov_xfer(struct vringh_kiov *iov,
 {
 	int err, done = 0;
 
+	/* 一个xfer的例子是xfer_kern() 就是把ptr拷贝到addr */
+
 	while (len && iov->i < iov->used) {
 		size_t partlen;
 
@@ -104,6 +144,10 @@ static inline ssize_t vringh_iov_xfer(struct vringh_kiov *iov,
 }
 
 /* May reduce *len if range is shorter. */
+/*
+ * called by:
+ *   - drivers/vhost/vringh.c|766| <<vringh_getdesc_user>> range_check, getrange, GFP_KERNEL, copydesc_user);
+ */
 static inline bool range_check(struct vringh *vrh, u64 addr, size_t *len,
 			       struct vringh_range *range,
 			       bool (*getrange)(struct vringh *,
@@ -138,6 +182,10 @@ static inline bool range_check(struct vringh *vrh, u64 addr, size_t *len,
 	return true;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vringh.c|1081| <<vringh_getdesc_kern>> err = __vringh_iov(vrh, *head, riov, wiov, no_range_check, NULL,
+ */
 static inline bool no_range_check(struct vringh *vrh, u64 addr, size_t *len,
 				  struct vringh_range *range,
 				  bool (*getrange)(struct vringh *,
@@ -147,6 +195,10 @@ static inline bool no_range_check(struct vringh *vrh, u64 addr, size_t *len,
 }
 
 /* No reason for this code to be inline. */
+/*
+ * called by __vringh_iov():
+ *   - drivers/vhost/vringh.c|324| <<__vringh_iov>> err = move_to_indirect(vrh, &up_next, &i, addr, &desc,
+ */
 static int move_to_indirect(const struct vringh *vrh,
 			    int *up_next, u16 *i, void *addr,
 			    const struct vring_desc *desc,
@@ -179,6 +231,10 @@ static int move_to_indirect(const struct vringh *vrh,
 	return 0;
 }
 
+/*
+ * called by __vringh_iov():
+ *   - drivers/vhost/vringh.c|368| <<__vringh_iov>> err = resize_iovec(iov, gfp);
+ */
 static int resize_iovec(struct vringh_kiov *iov, gfp_t gfp)
 {
 	struct kvec *new;
@@ -205,6 +261,10 @@ static int resize_iovec(struct vringh_kiov *iov, gfp_t gfp)
 	return 0;
 }
 
+/*
+ * called by __vringh_iov():
+ *   - drivers/vhost/vringh.c|390| <<__vringh_iov>> i = return_from_indirect(vrh, &up_next,
+ */
 static u16 __cold return_from_indirect(const struct vringh *vrh, int *up_next,
 				       struct vring_desc **descs, int *desc_max)
 {
@@ -216,6 +276,10 @@ static u16 __cold return_from_indirect(const struct vringh *vrh, int *up_next,
 	return i;
 }
 
+/*
+ * called by __vringh_iov():
+ *   - drivers/vhost/vringh.c|299| <<__vringh_iov>> err = slow_copy(vrh, &desc, &descs[i], rcheck, getrange,
+ */
 static int slow_copy(struct vringh *vrh, void *dst, const void *src,
 		     bool (*rcheck)(struct vringh *vrh, u64 addr, size_t *len,
 				    struct vringh_range *range,
@@ -251,6 +315,11 @@ static int slow_copy(struct vringh *vrh, void *dst, const void *src,
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vringh.c|693| <<vringh_getdesc_user>> err = __vringh_iov(vrh, *head, (struct vringh_kiov *)riov,
+ *   - drivers/vhost/vringh.c|992| <<vringh_getdesc_kern>> err = __vringh_iov(vrh, *head, riov, wiov, no_range_check, NULL,
+ */
 static inline int
 __vringh_iov(struct vringh *vrh, u16 i,
 	     struct vringh_kiov *riov,
@@ -398,6 +467,12 @@ __vringh_iov(struct vringh *vrh, u16 i,
 	return err;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vringh.c|862| <<vringh_complete_user>> return __vringh_complete(vrh, &used, 1, putu16_user, putused_user);
+ *   - drivers/vhost/vringh.c|884| <<vringh_complete_multi_user>> return __vringh_complete(vrh, used, num_used,
+ *   - drivers/vhost/vringh.c|1165| <<vringh_complete_kern>> return __vringh_complete(vrh, &used, 1, putu16_kern, putused_kern);
+ */
 static inline int __vringh_complete(struct vringh *vrh,
 				    const struct vring_used_elem *used,
 				    unsigned int num_used,
@@ -447,6 +522,11 @@ static inline int __vringh_complete(struct vringh *vrh,
 }
 
 
+/*
+ * called by:
+ *   - drivers/vhost/vringh.c|971| <<vringh_need_notify_user>> return __vringh_need_notify(vrh, getu16_user);
+ *   - drivers/vhost/vringh.c|1254| <<vringh_need_notify_kern>> return __vringh_need_notify(vrh, getu16_kern);
+ */
 static inline int __vringh_need_notify(struct vringh *vrh,
 				       int (*getu16)(const struct vringh *vrh,
 						     u16 *val,
@@ -470,6 +550,7 @@ static inline int __vringh_need_notify(struct vringh *vrh,
 				   &vrh->vring.avail->flags);
 			return err;
 		}
+		/* 如果配置了VRING_AVAIL_F_NO_INTERRUPT就不用通知guest */
 		return (!(flags & VRING_AVAIL_F_NO_INTERRUPT));
 	}
 
@@ -494,6 +575,11 @@ static inline int __vringh_need_notify(struct vringh *vrh,
 	return notify;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vringh.c|936| <<vringh_notify_enable_user>> return __vringh_notify_enable(vrh, getu16_user, putu16_user);
+ *   - drivers/vhost/vringh.c|1217| <<vringh_notify_enable_kern>> return __vringh_notify_enable(vrh, getu16_kern, putu16_kern);
+ */
 static inline bool __vringh_notify_enable(struct vringh *vrh,
 					  int (*getu16)(const struct vringh *vrh,
 							u16 *val, const __virtio16 *p),
@@ -534,6 +620,11 @@ static inline bool __vringh_notify_enable(struct vringh *vrh,
 	return avail == vrh->last_avail_idx;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vringh.c|953| <<vringh_notify_disable_user>> __vringh_notify_disable(vrh, putu16_user);
+ *   - drivers/vhost/vringh.c|1237| <<vringh_notify_disable_kern>> __vringh_notify_disable(vrh, putu16_kern);
+ */
 static inline void __vringh_notify_disable(struct vringh *vrh,
 					   int (*putu16)(const struct vringh *vrh,
 							 __virtio16 *p, u16 val))
@@ -557,18 +648,34 @@ static inline int getu16_user(const struct vringh *vrh, u16 *val, const __virtio
 	return rc;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vringh.c|872| <<vringh_complete_user>> return __vringh_complete(vrh, &used, 1, putu16_user, putused_user);
+ *   - drivers/vhost/vringh.c|895| <<vringh_complete_multi_user>> putu16_user, putused_user);
+ *   - drivers/vhost/vringh.c|912| <<vringh_notify_enable_user>> return __vringh_notify_enable(vrh, getu16_user, putu16_user);
+ *   - drivers/vhost/vringh.c|929| <<vringh_notify_disable_user>> __vringh_notify_disable(vrh, putu16_user);
+ */
 static inline int putu16_user(const struct vringh *vrh, __virtio16 *p, u16 val)
 {
 	__virtio16 v = cpu_to_vringh16(vrh, val);
 	return put_user(v, (__force __virtio16 __user *)p);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vringh.c|780| <<vringh_getdesc_user>> range_check, getrange, GFP_KERNEL, copydesc_user);
+ */
 static inline int copydesc_user(void *dst, const void *src, size_t len)
 {
 	return copy_from_user(dst, (__force void __user *)src, len) ?
 		-EFAULT : 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vringh.c|872| <<vringh_complete_user>> return __vringh_complete(vrh, &used, 1, putu16_user, putused_user);
+ *   - drivers/vhost/vringh.c|895| <<vringh_complete_multi_user>> putu16_user, putused_user);
+ */
 static inline int putused_user(struct vring_used_elem *dst,
 			       const struct vring_used_elem *src,
 			       unsigned int num)
@@ -577,12 +684,20 @@ static inline int putused_user(struct vring_used_elem *dst,
 			    sizeof(*dst) * num) ? -EFAULT : 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vringh.c|807| <<vringh_iov_pull_user>> dst, len, xfer_from_user);
+ */
 static inline int xfer_from_user(void *src, void *dst, size_t len)
 {
 	return copy_from_user(dst, (__force void __user *)src, len) ?
 		-EFAULT : 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vringh.c|829| <<vringh_iov_push_user>> (void *)src, len, xfer_to_user);
+ */
 static inline int xfer_to_user(void *dst, void *src, size_t len)
 {
 	return copy_to_user((__force void __user *)dst, src, len) ?
@@ -602,6 +717,11 @@ static inline int xfer_to_user(void *dst, void *src, size_t len)
  * Returns an error if num is invalid: you should check pointers
  * yourself!
  */
+/*
+ * called by:
+ *   - tools/virtio/vringh_test.c|189| <<bool>> vringh_init_user(&vrh, features, RINGSIZE, true,
+ *   - tools/virtio/vringh_test.c|491| <<main>> vringh_init_user(&vrh, vdev.features, RINGSIZE, true,
+ */
 int vringh_init_user(struct vringh *vrh, u64 features,
 		     unsigned int num, bool weak_barriers,
 		     struct vring_desc __user *desc,
@@ -646,6 +766,15 @@ EXPORT_SYMBOL(vringh_init_user);
  *
  * Note that you may need to clean up riov and wiov, even on error!
  */
+/*
+ * called by:
+ *   - tools/virtio/vringh_test.c|226| <<bool>> err = vringh_getdesc_user(&vrh, &riov, &wiov,
+ *   - tools/virtio/vringh_test.c|495| <<main>> err = vringh_getdesc_user(&vrh, &riov, &wiov, getrange, &head);
+ *   - tools/virtio/vringh_test.c|519| <<main>> err = vringh_getdesc_user(&vrh, &riov, &wiov, getrange, &head);
+ *   - tools/virtio/vringh_test.c|588| <<main>> err = vringh_getdesc_user(&vrh, &riov, &wiov, getrange, &head);
+ *   - tools/virtio/vringh_test.c|641| <<main>> err = vringh_getdesc_user(&vrh, &riov, &wiov, getrange, &head);
+ *   - tools/virtio/vringh_test.c|725| <<main>> err = vringh_getdesc_user(&vrh, &riov, &wiov, getrange, &head);
+ */
 int vringh_getdesc_user(struct vringh *vrh,
 			struct vringh_iov *riov,
 			struct vringh_iov *wiov,
@@ -703,6 +832,14 @@ EXPORT_SYMBOL(vringh_getdesc_user);
  *
  * Returns the bytes copied <= len or a negative errno.
  */
+/*
+ * called by:
+ *   - tools/virtio/vringh_test.c|255| <<bool>> rlen = vringh_iov_pull_user(&riov, rbuf,
+ *   - tools/virtio/vringh_test.c|538| <<main>> err = vringh_iov_pull_user(&riov, buf, 5);
+ *   - tools/virtio/vringh_test.c|543| <<main>> assert(vringh_iov_pull_user(&riov, buf, 5) == 0);
+ *   - tools/virtio/vringh_test.c|604| <<main>> err = vringh_iov_pull_user(&riov, buf, 3);
+ *   - tools/virtio/vringh_test.c|737| <<main>> err = vringh_iov_pull_user(&riov, buf, 29);
+ */
 ssize_t vringh_iov_pull_user(struct vringh_iov *riov, void *dst, size_t len)
 {
 	return vringh_iov_xfer((struct vringh_kiov *)riov,
@@ -718,6 +855,12 @@ EXPORT_SYMBOL(vringh_iov_pull_user);
  *
  * Returns the bytes copied <= len or a negative errno.
  */
+/*
+ * called by:
+ *   - tools/virtio/vringh_test.c|263| <<bool>> err = vringh_iov_push_user(&wiov, rbuf, rlen);
+ *   - tools/virtio/vringh_test.c|546| <<main>> err = vringh_iov_push_user(&wiov, buf, 5);
+ *   - tools/virtio/vringh_test.c|551| <<main>> assert(vringh_iov_push_user(&wiov, buf, 5) == 0);
+ */
 ssize_t vringh_iov_push_user(struct vringh_iov *wiov,
 			     const void *src, size_t len)
 {
@@ -734,6 +877,9 @@ EXPORT_SYMBOL(vringh_iov_push_user);
  *
  * The next vringh_get_user() will return the old descriptor(s) again.
  */
+/*
+ * 没人调用
+ */
 void vringh_abandon_user(struct vringh *vrh, unsigned int num)
 {
 	/* We only update vring_avail_event(vr) when we want to be notified,
@@ -751,6 +897,11 @@ EXPORT_SYMBOL(vringh_abandon_user);
  * You should check vringh_need_notify_user() after one or more calls
  * to this function.
  */
+/*
+ * called by:
+ *   - tools/virtio/vringh_test.c|273| <<bool>> err = vringh_complete_user(&vrh, head, written);
+ *   - tools/virtio/vringh_test.c|554| <<main>> err = vringh_complete_user(&vrh, head, err);
+ */
 int vringh_complete_user(struct vringh *vrh, u16 head, u32 len)
 {
 	struct vring_used_elem used;
@@ -770,6 +921,11 @@ EXPORT_SYMBOL(vringh_complete_user);
  * You should check vringh_need_notify_user() after one or more calls
  * to this function.
  */
+/*
+ * called by:
+ *   - tools/virtio/vringh_test.c|618| <<main>> err = vringh_complete_multi_user(&vrh, used, 1);
+ *   - tools/virtio/vringh_test.c|649| <<main>> err = vringh_complete_multi_user(&vrh, used, RINGSIZE);
+ */
 int vringh_complete_multi_user(struct vringh *vrh,
 			       const struct vring_used_elem used[],
 			       unsigned num_used)
@@ -786,6 +942,10 @@ EXPORT_SYMBOL(vringh_complete_multi_user);
  * This always enables notifications, but returns false if there are
  * now more buffers available in the vring.
  */
+/*
+ * called by:
+ *   - tools/virtio/vringh_test.c|239| <<bool>> if (!vringh_notify_enable_user(&vrh))
+ */
 bool vringh_notify_enable_user(struct vringh *vrh)
 {
 	return __vringh_notify_enable(vrh, getu16_user, putu16_user);
@@ -799,6 +959,10 @@ EXPORT_SYMBOL(vringh_notify_enable_user);
  * This is our normal running state: we disable and then only enable when
  * we're going to sleep.
  */
+/*
+ * called by:
+ *   - tools/virtio/vringh_test.c|246| <<bool>> vringh_notify_disable_user(&vrh);
+ */
 void vringh_notify_disable_user(struct vringh *vrh)
 {
 	__vringh_notify_disable(vrh, putu16_user);
@@ -811,6 +975,12 @@ EXPORT_SYMBOL(vringh_notify_disable_user);
  *
  * Returns -errno or 0 if we don't need to tell the other side, 1 if we do.
  */
+/*
+ * called by:
+ *   - tools/virtio/vringh_test.c|205| <<bool>> err = vringh_need_notify_user(&vrh);
+ *   - tools/virtio/vringh_test.c|230| <<bool>> err = vringh_need_notify_user(&vrh);
+ *   - tools/virtio/vringh_test.c|278| <<bool>> err = vringh_need_notify_user(&vrh);
+ */
 int vringh_need_notify_user(struct vringh *vrh)
 {
 	return __vringh_need_notify(vrh, getu16_user);
@@ -818,6 +988,12 @@ int vringh_need_notify_user(struct vringh *vrh)
 EXPORT_SYMBOL(vringh_need_notify_user);
 
 /* Kernelspace access helpers. */
+/*
+ * called by:
+ *   - drivers/vhost/vringh.c|940| <<vringh_getdesc_kern>> err = __vringh_get_head(vrh, getu16_kern, &vrh->last_avail_idx);
+ *   - drivers/vhost/vringh.c|1051| <<vringh_notify_enable_kern>> return __vringh_notify_enable(vrh, getu16_kern, putu16_kern);
+ *   - drivers/vhost/vringh.c|1088| <<vringh_need_notify_kern>> return __vringh_need_notify(vrh, getu16_kern);
+ */
 static inline int getu16_kern(const struct vringh *vrh,
 			      u16 *val, const __virtio16 *p)
 {
@@ -825,18 +1001,32 @@ static inline int getu16_kern(const struct vringh *vrh,
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vringh.c|1033| <<vringh_complete_kern>> return __vringh_complete(vrh, &used, 1, putu16_kern, putused_kern);
+ *   - drivers/vhost/vringh.c|1051| <<vringh_notify_enable_kern>> return __vringh_notify_enable(vrh, getu16_kern, putu16_kern);
+ *   - drivers/vhost/vringh.c|1071| <<vringh_notify_disable_kern>> __vringh_notify_disable(vrh, putu16_kern);
+ */
 static inline int putu16_kern(const struct vringh *vrh, __virtio16 *p, u16 val)
 {
 	WRITE_ONCE(*p, cpu_to_vringh16(vrh, val));
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vringh.c|950| <<vringh_getdesc_kern>> gfp, copydesc_kern);
+ */
 static inline int copydesc_kern(void *dst, const void *src, size_t len)
 {
 	memcpy(dst, src, len);
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vringh.c|1015| <<vringh_complete_kern>> return __vringh_complete(vrh, &used, 1, putu16_kern, putused_kern);
+ */
 static inline int putused_kern(struct vring_used_elem *dst,
 			       const struct vring_used_elem *src,
 			       unsigned int num)
@@ -845,6 +1035,11 @@ static inline int putused_kern(struct vring_used_elem *dst,
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vringh.c|953| <<vringh_iov_pull_kern>> return vringh_iov_xfer(riov, dst, len, xfer_kern);
+ *   - drivers/vhost/vringh.c|971| <<vringh_iov_push_kern>> return vringh_iov_xfer(wiov, (void *)src, len, xfer_kern);
+ */
 static inline int xfer_kern(void *src, void *dst, size_t len)
 {
 	memcpy(dst, src, len);
@@ -863,6 +1058,10 @@ static inline int xfer_kern(void *src, void *dst, size_t len)
  *
  * Returns an error if num is invalid.
  */
+/*
+ * called by:
+ *   - drivers/misc/mic/vop/vop_vringh.c|337| <<vop_virtio_add_device>> ret = vringh_init_kern(&vvr->vrh,
+ */
 int vringh_init_kern(struct vringh *vrh, u64 features,
 		     unsigned int num, bool weak_barriers,
 		     struct vring_desc *desc,
@@ -906,6 +1105,11 @@ EXPORT_SYMBOL(vringh_init_kern);
  *
  * Note that you may need to clean up riov and wiov, even on error!
  */
+/*
+ * called by:
+ *   - drivers/misc/mic/vop/vop_vringh.c|765| <<_vop_virtio_copy>> ret = vringh_getdesc_kern(vrh, riov, wiov,
+ *   - drivers/net/caif/caif_virtio.c|274| <<cfv_rx_poll>> err = vringh_getdesc_kern(
+ */
 int vringh_getdesc_kern(struct vringh *vrh,
 			struct vringh_kiov *riov,
 			struct vringh_kiov *wiov,
@@ -940,6 +1144,9 @@ EXPORT_SYMBOL(vringh_getdesc_kern);
  *
  * Returns the bytes copied <= len or a negative errno.
  */
+/*
+ * 没人调用
+ */
 ssize_t vringh_iov_pull_kern(struct vringh_kiov *riov, void *dst, size_t len)
 {
 	return vringh_iov_xfer(riov, dst, len, xfer_kern);
@@ -954,6 +1161,9 @@ EXPORT_SYMBOL(vringh_iov_pull_kern);
  *
  * Returns the bytes copied <= len or a negative errno.
  */
+/*
+ * 没人调用
+ */
 ssize_t vringh_iov_push_kern(struct vringh_kiov *wiov,
 			     const void *src, size_t len)
 {
@@ -969,6 +1179,9 @@ EXPORT_SYMBOL(vringh_iov_push_kern);
  *
  * The next vringh_get_kern() will return the old descriptor(s) again.
  */
+/*
+ * 没人调用
+ */
 void vringh_abandon_kern(struct vringh *vrh, unsigned int num)
 {
 	/* We only update vring_avail_event(vr) when we want to be notified,
@@ -986,6 +1199,11 @@ EXPORT_SYMBOL(vringh_abandon_kern);
  * You should check vringh_need_notify_kern() after one or more calls
  * to this function.
  */
+/*
+ * called by:
+ *   - drivers/misc/mic/vop/vop_vringh.c|825| <<_vop_virtio_copy>> vringh_complete_kern(vrh, *head, total);
+ *   - drivers/net/caif/caif_virtio.c|268| <<cfv_rx_poll>> vringh_complete_kern(cfv->vr_rx,
+ */
 int vringh_complete_kern(struct vringh *vrh, u16 head, u32 len)
 {
 	struct vring_used_elem used;
@@ -1004,6 +1222,11 @@ EXPORT_SYMBOL(vringh_complete_kern);
  * This always enables notifications, but returns false if there are
  * now more buffers available in the vring.
  */
+/*
+ * called by:
+ *   - drivers/net/caif/caif_virtio.c|320| <<cfv_rx_poll>> if (unlikely(!vringh_notify_enable_kern(cfv->vr_rx)) &&
+ *   - drivers/net/caif/caif_virtio.c|332| <<cfv_rx_poll>> vringh_notify_enable_kern(cfv->vr_rx);
+ */
 bool vringh_notify_enable_kern(struct vringh *vrh)
 {
 	return __vringh_notify_enable(vrh, getu16_kern, putu16_kern);
@@ -1017,6 +1240,13 @@ EXPORT_SYMBOL(vringh_notify_enable_kern);
  * This is our normal running state: we disable and then only enable when
  * we're going to sleep.
  */
+/*
+ * called by:
+ *   - drivers/net/caif/caif_virtio.c|322| <<cfv_rx_poll>> vringh_notify_disable_kern(cfv->vr_rx);
+ *   - drivers/net/caif/caif_virtio.c|340| <<cfv_rx_poll>> vringh_notify_disable_kern(cfv->vr_rx);
+ *   - drivers/net/caif/caif_virtio.c|355| <<cfv_recv>> vringh_notify_disable_kern(cfv->vr_rx);
+ *   - drivers/net/caif/caif_virtio.c|463| <<cfv_netdev_close>> vringh_notify_disable_kern(cfv->vr_rx);
+ */
 void vringh_notify_disable_kern(struct vringh *vrh)
 {
 	__vringh_notify_disable(vrh, putu16_kern);
@@ -1029,6 +1259,11 @@ EXPORT_SYMBOL(vringh_notify_disable_kern);
  *
  * Returns -errno or 0 if we don't need to tell the other side, 1 if we do.
  */
+/*
+ * called by:
+ *   - drivers/misc/mic/vop/vop_vringh.c|827| <<_vop_virtio_copy>> if (vringh_need_notify_kern(vrh) > 0)
+ *   - drivers/net/caif/caif_virtio.c|345| <<cfv_rx_poll>> if (rxcnt && vringh_need_notify_kern(cfv->vr_rx) > 0)
+ */
 int vringh_need_notify_kern(struct vringh *vrh)
 {
 	return __vringh_need_notify(vrh, getu16_kern);
diff --git a/include/linux/ptr_ring.h b/include/linux/ptr_ring.h
index 6894976b..bf627c54 100644
--- a/include/linux/ptr_ring.h
+++ b/include/linux/ptr_ring.h
@@ -125,6 +125,15 @@ static inline int __ptr_ring_produce(struct ptr_ring *r, void *ptr)
  * consume in interrupt or BH context, you must disable interrupts/BH when
  * calling this.
  */
+/*
+ * called by:
+ *   - drivers/net/tap.c|406| <<tap_handle_frame>> if (ptr_ring_produce(&q->ring, skb))
+ *   - drivers/net/tap.c|416| <<tap_handle_frame>> if (ptr_ring_produce(&q->ring, segs)) {
+ *   - drivers/net/tap.c|433| <<tap_handle_frame>> if (ptr_ring_produce(&q->ring, skb))
+ *   - drivers/net/tun.c|1114| <<tun_net_xmit>> if (ptr_ring_produce(&tfile->tx_ring, skb))
+ *   - drivers/net/tun.c|1315| <<tun_xdp_xmit>> if (ptr_ring_produce(&tfile->tx_ring, tun_xdp_to_ptr(buff))) {
+ *   - include/linux/skb_array.h|48| <<skb_array_produce>> return ptr_ring_produce(&a->ring, skb);
+ */
 static inline int ptr_ring_produce(struct ptr_ring *r, void *ptr)
 {
 	int ret;
@@ -328,6 +337,15 @@ static inline int __ptr_ring_consume_batched(struct ptr_ring *r,
  * call this in interrupt or BH context, you must disable interrupts/BH when
  * producing.
  */
+/*
+ * called by:
+ *   - drivers/net/tap.c|865| <<tap_do_read>> skb = ptr_ring_consume(&q->ring);
+ *   - drivers/net/tun.c|677| <<tun_queue_purge>> while ((ptr = ptr_ring_consume(&tfile->tx_ring)) != NULL)
+ *   - drivers/net/tun.c|2140| <<tun_ring_recv>> ptr = ptr_ring_consume(&tfile->tx_ring);
+ *   - drivers/net/tun.c|2152| <<tun_ring_recv>> ptr = ptr_ring_consume(&tfile->tx_ring);
+ *   - include/linux/ptr_ring.h|671| <<ptr_ring_cleanup>> while ((ptr = ptr_ring_consume(r)))
+ *   - include/linux/skb_array.h|102| <<skb_array_consume>> return ptr_ring_consume(&a->ring);
+ */
 static inline void *ptr_ring_consume(struct ptr_ring *r)
 {
 	void *ptr;
diff --git a/include/uapi/linux/vhost.h b/include/uapi/linux/vhost.h
index c51f8e5c..e13a590c 100644
--- a/include/uapi/linux/vhost.h
+++ b/include/uapi/linux/vhost.h
@@ -114,6 +114,7 @@ struct vhost_memory {
 /* Memory writes can optionally be logged by setting bit at an offset
  * (calculated from the physical address) from specified log base.
  * The bit is set using an atomic 32 bit operation. */
+/* 用于guest在线迁移????? */
 /* Set base address for logging. */
 #define VHOST_SET_LOG_BASE _IOW(VHOST_VIRTIO, 0x04, __u64)
 /* Specify an eventfd file descriptor to signal on log write. */
@@ -148,8 +149,10 @@ struct vhost_memory {
  * for events. */
 
 /* Set eventfd to poll for added buffers */
+/* 设置host notifier */
 #define VHOST_SET_VRING_KICK _IOW(VHOST_VIRTIO, 0x20, struct vhost_vring_file)
 /* Set eventfd to signal when buffers have beed used */
+/* 设置guest notifier */
 #define VHOST_SET_VRING_CALL _IOW(VHOST_VIRTIO, 0x21, struct vhost_vring_file)
 /* Set eventfd to signal an error */
 #define VHOST_SET_VRING_ERR _IOW(VHOST_VIRTIO, 0x22, struct vhost_vring_file)
diff --git a/include/uapi/linux/virtio_config.h b/include/uapi/linux/virtio_config.h
index 308e2096..846cd32a 100644
--- a/include/uapi/linux/virtio_config.h
+++ b/include/uapi/linux/virtio_config.h
@@ -70,5 +70,6 @@
  * Note the reverse polarity (compared to most other features),
  * this is for compatibility with legacy systems.
  */
+/* 似乎用在iotlb */
 #define VIRTIO_F_IOMMU_PLATFORM		33
 #endif /* _UAPI_LINUX_VIRTIO_CONFIG_H */
diff --git a/net/core/dev.c b/net/core/dev.c
index 1ccc2a2a..c625c7d3 100644
--- a/net/core/dev.c
+++ b/net/core/dev.c
@@ -4379,6 +4379,52 @@ EXPORT_SYMBOL_GPL(netdev_is_rx_handler_busy);
  *
  *	For a general description of rx_handler, see enum rx_handler_result.
  */
+/*
+ * 使用macvtap会连续调用两次: ip link add link enp0s3 name macvtap0 type macvtap
+ *
+ * 第一次进来dev是macvtap0
+ * [0] netdev_rx_handler_register
+ * [0] macvtap_newlink
+ * [0] rtnl_newlink
+ * [0] rtnetlink_rcv_msg
+ * [0] netlink_rcv_skb
+ * [0] netlink_unicast
+ * [0] netlink_sendmsg
+ * [0] sock_sendmsg
+ * [0] ___sys_sendmsg
+ * [0] __sys_sendmsg
+ * [0] do_syscall_64
+ * [0] entry_SYSCALL_64_after_hwframe
+ *
+ * 第二次进来dev是enp0s3
+ * netdev_rx_handler_register
+ * [0] macvlan_common_newlink
+ * [0] macvtap_newlink
+ * [0] rtnl_newlink
+ * [0] rtnetlink_rcv_msg
+ * [0] netlink_rcv_skb
+ * [0] netlink_unicast
+ * [0] netlink_sendmsg
+ * [0] sock_sendmsg
+ * [0] ___sys_sendmsg
+ * [0] __sys_sendmsg
+ * [0] do_syscall_64
+ * [0] entry_SYSCALL_64_after_hwframe
+ *
+ * called by:
+ *   - drivers/net/bonding/bond_main.c|1675| <<bond_enslave>> res = netdev_rx_handler_register(slave_dev, bond_handle_frame,
+ *   - drivers/net/ethernet/qualcomm/rmnet/rmnet_config.c|95| <<rmnet_register_real_device>> rc = netdev_rx_handler_register(real_dev, rmnet_rx_handler, port);
+ *   - drivers/net/hyperv/netvsc_drv.c|1840| <<netvsc_vf_join>> ret = netdev_rx_handler_register(vf_netdev,
+ *   - drivers/net/ipvlan/ipvlan_main.c|128| <<ipvlan_port_create>> err = netdev_rx_handler_register(dev, ipvlan_handle_frame, port);
+ *   - drivers/net/ipvlan/ipvtap.c|93| <<ipvtap_newlink>> err = netdev_rx_handler_register(dev, tap_handle_frame, &vlantap->tap);
+ *   - drivers/net/macsec.c|3170| <<register_macsec_dev>> err = netdev_rx_handler_register(real_dev, macsec_handle_frame,
+ *   - drivers/net/macvlan.c|1178| <<macvlan_port_create>> err = netdev_rx_handler_register(dev, macvlan_handle_frame, port);
+ *   - drivers/net/macvtap.c|138| <<macvtap_newlink>> err = netdev_rx_handler_register(dev, tap_handle_frame, &vlantap->tap);
+ *   - drivers/net/team/team.c|1240| <<team_port_add>> err = netdev_rx_handler_register(port_dev, team_handle_frame,
+ *   - net/bridge/br_if.c|555| <<br_add_if>> err = netdev_rx_handler_register(dev, br_handle_frame, p);
+ *   - net/hsr/hsr_slave.c|118| <<hsr_portdev_setup>> res = netdev_rx_handler_register(dev, hsr_handle_frame, port);
+ *   - net/openvswitch/vport-netdev.c|116| <<ovs_netdev_link>> err = netdev_rx_handler_register(vport->dev, netdev_frame_hook,
+ */
 int netdev_rx_handler_register(struct net_device *dev,
 			       rx_handler_func_t *rx_handler,
 			       void *rx_handler_data)
-- 
2.17.1

