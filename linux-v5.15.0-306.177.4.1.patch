From c66cd6babacfad5d15e59c485cf64fe972f4282f Mon Sep 17 00:00:00 2001
From: Dongli Zhang <dongli.zhang0129@gmail.com>
Date: Mon, 21 Jul 2025 15:17:50 -0700
Subject: [PATCH 1/1] linux v5.15.0-306.177.4.1

Signed-off-by: Dongli Zhang <dongli.zhang0129@gmail.com>
---
 arch/x86/include/asm/apicdef.h               |   23 +
 arch/x86/include/asm/kvm_host.h              |  227 +++
 arch/x86/kernel/apic/io_apic.c               |    5 +
 arch/x86/kernel/cpu/intel.c                  |  470 +++++
 arch/x86/kvm/hyperv.c                        |   13 +
 arch/x86/kvm/i8254.c                         |    8 +
 arch/x86/kvm/ioapic.c                        |  314 ++++
 arch/x86/kvm/ioapic.h                        |   14 +
 arch/x86/kvm/irq.c                           |   93 +
 arch/x86/kvm/irq.h                           |   13 +
 arch/x86/kvm/irq_comm.c                      |  154 ++
 arch/x86/kvm/lapic.c                         | 1625 ++++++++++++++++++
 arch/x86/kvm/lapic.h                         |  249 +++
 arch/x86/kvm/mmu.h                           |    5 +
 arch/x86/kvm/svm/avic.c                      |   43 +
 arch/x86/kvm/svm/svm.c                       |   81 +
 arch/x86/kvm/vmx/nested.c                    |   25 +
 arch/x86/kvm/vmx/vmx.c                       |  628 +++++++
 arch/x86/kvm/vmx/vmx.h                       |   66 +
 arch/x86/kvm/x86.c                           | 1229 +++++++++++++
 arch/x86/kvm/x86.h                           |   33 +
 drivers/acpi/acpica/dbexec.c                 |   40 +
 drivers/acpi/acpica/dbxface.c                |   20 +
 drivers/acpi/acpica/dswexec.c                |   50 +
 drivers/acpi/acpica/evgpe.c                  |  330 ++++
 drivers/acpi/acpica/evmisc.c                 |  215 +++
 drivers/acpi/acpica/evsci.c                  |   58 +
 drivers/acpi/acpica/exoparg2.c               |   61 +
 drivers/acpi/acpica/nseval.c                 |  138 ++
 drivers/acpi/acpica/nsnames.c                |    3 +
 drivers/acpi/acpica/nsxfeval.c               |   10 +
 drivers/acpi/acpica/nsxfname.c               |    3 +
 drivers/acpi/acpica/psloop.c                 |   41 +
 drivers/acpi/acpica/psparse.c                |   40 +
 drivers/acpi/acpica/psxface.c                |   44 +
 drivers/acpi/acpica/utstate.c                |   12 +
 drivers/acpi/bus.c                           |   44 +
 drivers/acpi/osl.c                           |  122 ++
 drivers/acpi/scan.c                          |  203 +++
 drivers/net/ethernet/mellanox/mlx5/core/eq.c |    6 +
 drivers/pci/hotplug/acpiphp_glue.c           |   94 +
 drivers/pci/pci-acpi.c                       |    4 +
 include/linux/kvm_host.h                     |   32 +
 include/linux/sched.h                        |    6 +
 virt/kvm/eventfd.c                           |   34 +
 virt/kvm/irqchip.c                           |   52 +
 virt/kvm/kvm_main.c                          |   39 +
 47 files changed, 7019 insertions(+)

diff --git a/arch/x86/include/asm/apicdef.h b/arch/x86/include/asm/apicdef.h
index 863c2cad5872..7f4752325b2b 100644
--- a/arch/x86/include/asm/apicdef.h
+++ b/arch/x86/include/asm/apicdef.h
@@ -18,6 +18,29 @@
  */
 #define IO_APIC_SLOT_SIZE		1024
 
+/*
+ * 在以下使用APIC_ID:
+ *   - arch/x86/kvm/svm/svm.c|119| <<global>> { .index = X2APIC_MSR(APIC_ID), .always = false },
+ *   - arch/x86/include/asm/apic.h|204| <<native_apic_msr_write>> if (reg == APIC_DFR || reg == APIC_ID || reg == APIC_LDR ||
+ *   - arch/x86/include/asm/apic.h|487| <<read_apic_id>> unsigned int reg = apic_read(APIC_ID);
+ *   - arch/x86/kernel/apic/apic.c|1797| <<setup_nox2apic>> int apicid = native_apic_msr_read(APIC_ID);
+ *   - arch/x86/kernel/apic/apic.c|2586| <<apic_bsp_up_setup>> apic_write(APIC_ID, apic->set_apic_id(boot_cpu_physical_apicid));
+ *   - arch/x86/kernel/apic/apic.c|2668| <<lapic_suspend>> apic_pm_state.apic_id = apic_read(APIC_ID);
+ *   - arch/x86/kernel/apic/apic.c|2745| <<lapic_resume>> apic_write(APIC_ID, apic_pm_state.apic_id);
+ *   - arch/x86/kernel/apic/apic_flat_64.c|91| <<read_xapic_id>> return flat_get_apic_id(apic_read(APIC_ID));
+ *   - arch/x86/kernel/apic/vector.c|1157| <<print_local_APIC>> v = apic_read(APIC_ID);
+ *   - arch/x86/kernel/apic/x2apic_uv_x.c|811| <<uv_read_apic_id>> return x2apic_get_apic_id(apic_read(APIC_ID));
+ *   - arch/x86/kernel/smpboot.c|689| <<__inquire_remote_apic>> unsigned i, regs[] = { APIC_ID >> 4, APIC_LVR >> 4, APIC_SPIV >> 4 };
+ *   - arch/x86/kvm/lapic.c|381| <<kvm_apic_set_xapic_id>> kvm_lapic_set_reg(apic, APIC_ID, id << 24);
+ *   - arch/x86/kvm/lapic.c|408| <<kvm_apic_set_x2apic_id>> kvm_lapic_set_reg(apic, APIC_ID, id);
+ *   - arch/x86/kvm/lapic.c|1762| <<kvm_lapic_reg_read>> APIC_REG_MASK(APIC_ID) |
+ *   - arch/x86/kvm/lapic.c|2393| <<kvm_lapic_reg_write>> case APIC_ID:
+ *   - arch/x86/kvm/lapic.c|3094| <<kvm_apic_state_fixup>> u32 *id = (u32 *)(s->regs + APIC_ID);
+ *   - arch/x86/kvm/lapic.h|305| <<kvm_xapic_id>> return kvm_lapic_get_reg(apic, APIC_ID) >> 24;
+ *   - arch/x86/kvm/svm/avic.c|675| <<is_avic_unaccelerated_access_trap>> case APIC_ID:
+ *   - arch/x86/xen/apic.c|63| <<xen_apic_read>> if (reg != APIC_ID)
+ *   - tools/testing/selftests/kvm/x86_64/xapic_ipi_test.c|100| <<halter_guest_code>> data->halter_apic_id = GET_APIC_ID_FIELD(xapic_read_reg(APIC_ID));
+ */
 #define	APIC_ID		0x20
 
 #define	APIC_LVR	0x30
diff --git a/arch/x86/include/asm/kvm_host.h b/arch/x86/include/asm/kvm_host.h
index 8a710af8003c..a78717dc3338 100644
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@ -632,17 +632,94 @@ struct kvm_vcpu_arch {
 	u32 pkru;
 	u32 hflags;
 	u64 efer;
+	/*
+	 * 在以下设置kvm_vcpu_arch->apic_base (看似修改的地方):
+	 *   - arch/x86/kvm/lapic.c|2926| <<kvm_lapic_set_base>> vcpu->arch.apic_base = value;
+	 *   - arch/x86/kvm/lapic.c|3256| <<kvm_create_lapic>> vcpu->arch.apic_base = MSR_IA32_APICBASE_ENABLE;
+	 * 在以下使用kvm_vcpu_arch->apic_base:
+	 *   - arch/x86/kvm/cpuid.c|222| <<__kvm_update_cpuid_runtime>> cpuid_entry_change(best, X86_FEATURE_APIC, vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE);
+	 *   - arch/x86/kvm/lapic.c|2862| <<kvm_free_lapic>> if (!(vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE))
+	 *   - arch/x86/kvm/lapic.c|2923| <<kvm_lapic_set_base>> u64 old_value = vcpu->arch.apic_base;
+	 *   - arch/x86/kvm/lapic.c|2974| <<kvm_lapic_set_base>> apic->base_address = apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_BASE;
+	 *   - arch/x86/kvm/lapic.c|3454| <<kvm_apic_set_state>> kvm_lapic_set_base(vcpu, vcpu->arch.apic_base);
+	 *   - arch/x86/kvm/lapic.h|231| <<kvm_apic_hw_enabled>> return apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE;
+	 *   - arch/x86/kvm/lapic.h|256| <<apic_x2apic_mode>> return apic->vcpu->arch.apic_base & X2APIC_ENABLE;
+	 *   - arch/x86/kvm/lapic.h|300| <<kvm_apic_mode>> return apic_base & (MSR_IA32_APICBASE_ENABLE | X2APIC_ENABLE);
+	 *   - arch/x86/kvm/vmx/nested.c|878| <<nested_vmx_msr_check_common>> if (CC(vcpu->arch.apic_base & X2APIC_ENABLE && e->index >> 8 == 0x8))
+	 *   - arch/x86/kvm/x86.c|466| <<kvm_get_apic_base>> return vcpu->arch.apic_base;
+	 *   - arch/x86/kvm/x86.c|12215| <<kvm_vcpu_is_bsp>> return (vcpu->arch.apic_base & MSR_IA32_APICBASE_BSP) != 0;
+	 */
 	u64 apic_base;
 	struct kvm_lapic *apic;    /* kernel irqchip context */
+	/*
+	 * 在以下设置kvm_vcpu_arch->apicv_active:
+	 *   - arch/x86/kvm/x86.c|9800| <<kvm_vcpu_update_apicv>> vcpu->arch.apicv_active = activate;
+	 *   - arch/x86/kvm/x86.c|11393| <<kvm_arch_vcpu_create>> vcpu->arch.apicv_active = true;
+	 * 在以下使用kvm_vcpu_arch->apicv_active:
+	 *   - arch/x86/kvm/lapic.c|553| <<kvm_apic_update_irr>> if (unlikely(!vcpu->arch.apicv_active && irr_updated))
+	 *   - arch/x86/kvm/lapic.c|602| <<apic_clear_irr>> if (unlikely(vcpu->arch.apicv_active)) {
+	 *   - arch/x86/kvm/lapic.c|654| <<apic_set_isr>> if (unlikely(vcpu->arch.apicv_active))
+	 *   - arch/x86/kvm/lapic.c|714| <<apic_clear_isr>> if (unlikely(vcpu->arch.apicv_active))
+	 *   - arch/x86/kvm/lapic.c|1827| <<lapic_timer_int_injected>> if (vcpu->arch.apicv_active)
+	 *   - arch/x86/kvm/lapic.c|1944| <<apic_timer_expired>> if (!from_timer_fn && vcpu->arch.apicv_active) {
+	 *   - arch/x86/kvm/lapic.c|2613| <<kvm_apic_update_apicv>> if (vcpu->arch.apicv_active) {
+	 *   - arch/x86/kvm/lapic.c|2703| <<kvm_lapic_reset>> if (vcpu->arch.apicv_active) {
+	 *   - arch/x86/kvm/lapic.c|3003| <<kvm_apic_set_state>> if (vcpu->arch.apicv_active) {
+	 *   - arch/x86/kvm/lapic.h|241| <<kvm_vcpu_apicv_active>> return vcpu->arch.apic && vcpu->arch.apicv_active;
+	 *   - arch/x86/kvm/svm/svm.c|3661| <<svm_complete_interrupt_delivery>> if (!READ_ONCE(vcpu->arch.apicv_active)) {
+	 *   - arch/x86/kvm/vmx/vmx.c|4114| <<vmx_deliver_posted_interrupt>> if (!vcpu->arch.apicv_active)
+	 *   - arch/x86/kvm/x86.c|9241| <<update_cr8_intercept>> if (vcpu->arch.apicv_active)
+	 *   - arch/x86/kvm/x86.c|9797| <<kvm_vcpu_update_apicv>> if (vcpu->arch.apicv_active == activate)
+	 *   - arch/x86/kvm/x86.c|9810| <<kvm_vcpu_update_apicv>> if (!vcpu->arch.apicv_active)
+	 *   - arch/x86/kvm/x86.c|12441| <<kvm_arch_dy_has_pending_interrupt>> if (vcpu->arch.apicv_active &&
+	 *          static_call(kvm_x86_dy_apicv_has_pending_interrupt)(vcpu))
+	 */
 	bool apicv_active;
+	/*
+	 * 在以下使用kvm_vcpu_arch->load_eoi_exitmap_pending:
+	 *   - arch/x86/kvm/kvm_cache_regs.h|184| <<leave_guest_mode>> if (vcpu->arch.load_eoi_exitmap_pending) {
+	 *   - arch/x86/kvm/kvm_cache_regs.h|185| <<leave_guest_mode>> vcpu->arch.load_eoi_exitmap_pending = false;
+	 *   - arch/x86/kvm/x86.c|9850| <<vcpu_scan_ioapic>> vcpu->arch.load_eoi_exitmap_pending = true;
+	 */
 	bool load_eoi_exitmap_pending;
+	/*
+	 * 在以下使用kvm_vcpu_arch->ioapic_handled_vectors:
+	 *   - arch/x86/kvm/lapic.c|1273| <<kvm_ioapic_handles_vector>> return test_bit(vector, apic->vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|9840| <<vcpu_scan_ioapic>> bitmap_zero(vcpu->arch.ioapic_handled_vectors, 256);
+	 *   - arch/x86/kvm/x86.c|9845| <<vcpu_scan_ioapic>> kvm_scan_ioapic_routes(vcpu, vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|9847| <<vcpu_scan_ioapic>> kvm_ioapic_scan_entry(vcpu, vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|9864| <<vcpu_load_eoi_exitmap>> bitmap_or((ulong *)eoi_exit_bitmap, vcpu->arch.ioapic_handled_vectors,
+	 *              to_hv_synic(vcpu)->vec_bitmap, 256);
+	 *   - arch/x86/kvm/x86.c|9871| <<vcpu_load_eoi_exitmap>> static_call(kvm_x86_load_eoi_exitmap)(vcpu, (u64 *)vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|10004| <<vcpu_enter_guest>> if (test_bit(vcpu->arch.pending_ioapic_eoi, vcpu->arch.ioapic_handled_vectors)) {
+	 */
 	DECLARE_BITMAP(ioapic_handled_vectors, 256);
+	/*
+	 * 在以下使用kvm_vcpu_arch->apic_attention:
+	 *   - arch/x86/kvm/lapic.c|1283| <<pv_eoi_set_pending>> __set_bit(KVM_APIC_PV_EOI_PENDING, &vcpu->arch.apic_attention);
+	 *   - arch/x86/kvm/lapic.c|1291| <<pv_eoi_clr_pending>> __clear_bit(KVM_APIC_PV_EOI_PENDING, &vcpu->arch.apic_attention);
+	 *   - arch/x86/kvm/lapic.c|3541| <<kvm_lapic_reset>> vcpu->arch.apic_attention = 0;
+	 *   - arch/x86/kvm/lapic.c|4066| <<kvm_lapic_sync_from_vapic>> if (test_bit(KVM_APIC_PV_EOI_PENDING, &vcpu->arch.apic_attention))
+	 *   - arch/x86/kvm/lapic.c|4069| <<kvm_lapic_sync_from_vapic>> if (!test_bit(KVM_APIC_CHECK_VAPIC, &vcpu->arch.apic_attention))
+	 *   - arch/x86/kvm/lapic.c|4128| <<kvm_lapic_sync_to_vapic>> if (!test_bit(KVM_APIC_CHECK_VAPIC, &vcpu->arch.apic_attention))
+	 *   - arch/x86/kvm/lapic.c|4151| <<kvm_lapic_set_vapic_addr>> __set_bit(KVM_APIC_CHECK_VAPIC, &vcpu->arch.apic_attention);
+	 *   - arch/x86/kvm/lapic.c|4153| <<kvm_lapic_set_vapic_addr>> __clear_bit(KVM_APIC_CHECK_VAPIC, &vcpu->arch.apic_attention);
+	 *   - arch/x86/kvm/x86.c|10895| <<vcpu_enter_guest>> if (vcpu->arch.apic_attention)
+	 *   - arch/x86/kvm/x86.c|10926| <<vcpu_enter_guest>> if (unlikely(vcpu->arch.apic_attention))
+	 */
 	unsigned long apic_attention;
 	int32_t apic_arb_prio;
 	int mp_state;
 	u64 ia32_misc_enable_msr;
 	u64 smbase;
 	u64 smi_count;
+	/*
+	 * 在以下使用kvm_vcpu_arch->at_instruction_boundary:
+	 *   - arch/x86/kvm/svm/svm.c|4585| <<svm_handle_exit_irqoff>> vcpu->arch.at_instruction_boundary = true;
+	 *   - arch/x86/kvm/vmx/vmx.c|6979| <<handle_external_interrupt_irqoff>> vcpu->arch.at_instruction_boundary = true;
+	 *   - arch/x86/kvm/x86.c|4744| <<kvm_steal_time_set_preempted>> if (!vcpu->arch.at_instruction_boundary) {
+	 *   - arch/x86/kvm/x86.c|11223| <<vcpu_run>> vcpu->arch.at_instruction_boundary = false;
+	 */
 	bool at_instruction_boundary;
 	bool tpr_access_reporting;
 	bool xsaves_enabled;
@@ -778,6 +855,13 @@ struct kvm_vcpu_arch {
 	u64 l1_tsc_scaling_ratio;
 	u64 tsc_scaling_ratio; /* current scaling ratio */
 
+	/*
+	 * 在以下使用kvm_vcpu_arch->nmi_queued:
+	 *   - arch/x86/kvm/x86.c|874| <<kvm_inject_nmi>> atomic_inc(&vcpu->arch.nmi_queued);
+	 *   - arch/x86/kvm/x86.c|5158| <<kvm_vcpu_ioctl_x86_set_vcpu_events>> atomic_set(&vcpu->arch.nmi_queued, events->nmi.pending);
+	 *   - arch/x86/kvm/x86.c|9855| <<process_nmi>> vcpu->arch.nmi_pending += atomic_xchg(&vcpu->arch.nmi_queued, 0);
+	 *   - arch/x86/kvm/x86.c|12376| <<kvm_vcpu_reset>> atomic_set(&vcpu->arch.nmi_queued, 0);
+	 */
 	atomic_t nmi_queued;  /* unprocessed asynchronous NMIs */
 	/* Number of NMIs pending injection, not including hardware vNMIs. */
 	unsigned int nmi_pending;
@@ -875,7 +959,23 @@ struct kvm_vcpu_arch {
 		bool pv_unhalted;
 	} pv;
 
+	/*
+	 * 在以下使用kvm_vcpu_arch->pending_ioapic_eoi:
+	 *   - arch/x86/kvm/lapic.c|1286| <<kvm_ioapic_send_eoi>> apic->vcpu->arch.pending_ioapic_eoi = vector;
+	 *   - arch/x86/kvm/x86.c|10008| <<vcpu_enter_guest(KVM_REQ_IOAPIC_EOI_EXIT)>> BUG_ON(vcpu->arch.pending_ioapic_eoi > 255);
+	 *   - arch/x86/kvm/x86.c|10009| <<vcpu_enter_guest(KVM_REQ_IOAPIC_EOI_EXIT)>> if (test_bit(vcpu->arch.pending_ioapic_eoi,
+	 *   - arch/x86/kvm/x86.c|10013| <<vcpu_enter_guest(KVM_REQ_IOAPIC_EOI_EXIT)>> vcpu->arch.pending_ioapic_eoi;
+	 */
 	int pending_ioapic_eoi;
+	/*
+	 * 在以下使用kvm_vcpu_arch->pending_external_vector:
+	 *   - arch/x86/kvm/irq.c|37| <<pending_userspace_extint>> return v->arch.pending_external_vector != -1;
+	 *   - arch/x86/kvm/irq.c|121| <<kvm_cpu_get_extint>> int vector = v->arch.pending_external_vector;
+	 *   - arch/x86/kvm/irq.c|123| <<kvm_cpu_get_extint>> v->arch.pending_external_vector = -1;
+	 *   - arch/x86/kvm/x86.c|4691| <<kvm_vcpu_ioctl_interrupt>> if (vcpu->arch.pending_external_vector != -1)
+	 *   - arch/x86/kvm/x86.c|4694| <<kvm_vcpu_ioctl_interrupt>> vcpu->arch.pending_external_vector = irq->irq;
+	 *   - arch/x86/kvm/x86.c|11281| <<kvm_arch_vcpu_create>> vcpu->arch.pending_external_vector = -1;
+	 */
 	int pending_external_vector;
 
 	/* be preempted when it's in kernel-mode(cpl=0) */
@@ -884,6 +984,25 @@ struct kvm_vcpu_arch {
 	/* Flush the L1 Data cache for L1TF mitigation on VMENTER */
 	bool l1tf_flush_l1d;
 
+	/*
+	 * 在以下使用kvm_vcpu_arch->last_vmentry_cpu:
+	 *   - arch/x86/kvm/cpuid.c|349| <<kvm_set_cpuid>> if (vcpu->arch.last_vmentry_cpu != -1)
+	 *   - arch/x86/kvm/mmu/mmu.c|5018| <<kvm_mmu_after_set_cpuid>> if (vcpu->arch.last_vmentry_cpu != -1) {
+	 *   - arch/x86/kvm/svm/sev.c|2607| <<pre_sev_run>> if (sd->sev_vmcbs[asid] == svm->vmcb && svm->vcpu.arch.last_vmentry_cpu == cpu)
+	 *   - arch/x86/kvm/svm/svm.c|3341| <<dump_vmcb>> pr_err("VMCB %p, last attempted VMRUN on CPU %d\n",
+	 *                                    svm->current_vmcb->ptr, vcpu->arch.last_vmentry_cpu);
+	 *   - arch/x86/kvm/svm/svm.c|3465| <<svm_handle_invalid_exit>> vcpu->run->internal.data[1] = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/svm/svm.c|3540| <<handle_exit>> kvm_run->fail_entry.cpu = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/vmx/vmx.c|4996| <<handle_exception_nmi>> vcpu->run->internal.data[3] = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/vmx/vmx.c|5971| <<dump_vmcs>> pr_err("VMCS %p, last attempted VM-entry on CPU %d\n",
+	 *                                    vmx->loaded_vmcs->vmcs, vcpu->arch.last_vmentry_cpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|6195| <<__vmx_handle_exit>> vcpu->run->fail_entry.cpu = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/vmx/vmx.c|6204| <<__vmx_handle_exit>> vcpu->run->fail_entry.cpu = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/vmx/vmx.c|6232| <<__vmx_handle_exit>> vcpu->run->internal.data[ndata++] = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/vmx/vmx.c|6292| <<__vmx_handle_exit>> vcpu->run->internal.data[1] = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/x86.c|10741| <<vcpu_enter_guest>> vcpu->arch.last_vmentry_cpu = vcpu->cpu;
+	 *   - arch/x86/kvm/x86.c|11799| <<kvm_arch_vcpu_create>> vcpu->arch.last_vmentry_cpu = -1;
+	 */
 	/* Host CPU on which VM-entry was most recently attempted */
 	int last_vmentry_cpu;
 
@@ -1139,14 +1258,56 @@ struct kvm_arch {
 	struct kvm_ioapic *vioapic;
 	struct kvm_pit *vpit;
 	atomic_t vapics_in_nmi_mode;
+	/*
+	 * 在以下使用kvm_arch->apic_map_lock:
+	 *   - arch/x86/kvm/lapic.c|375| <<kvm_recalculate_apic_map>> mutex_lock(&kvm->arch.apic_map_lock);
+	 *   - arch/x86/kvm/lapic.c|383| <<kvm_recalculate_apic_map>> mutex_unlock(&kvm->arch.apic_map_lock);
+	 *   - arch/x86/kvm/lapic.c|506| <<kvm_recalculate_apic_map>> old = rcu_dereference_protected(kvm->arch.apic_map,
+	 *                                     lockdep_is_held(&kvm->arch.apic_map_lock));
+	 *   - arch/x86/kvm/lapic.c|514| <<kvm_recalculate_apic_map>> mutex_unlock(&kvm->arch.apic_map_lock);
+	 *   - arch/x86/kvm/x86.c|12397| <<kvm_arch_init_vm>> mutex_init(&kvm->arch.apic_map_lock);
+	 */
 	struct mutex apic_map_lock;
+	/*
+	 * 在以下使用kvm_arch->apic_map:
+	 *   - arch/x86/kvm/lapic.c|581| <<kvm_recalculate_apic_map>> old = rcu_dereference_protected(kvm->arch.apic_map,
+	 *   - arch/x86/kvm/lapic.c|583| <<kvm_recalculate_apic_map>> rcu_assign_pointer(kvm->arch.apic_map, new);
+	 *   - arch/x86/kvm/lapic.c|1305| <<kvm_pv_send_ipi>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1772| <<kvm_irq_delivery_to_apic_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1825| <<kvm_intr_is_single_vcpu_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|2023| <<kvm_bitmap_or_dest_vcpus>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|9391| <<kvm_sched_yield>> map = rcu_dereference(vcpu->kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|13061| <<kvm_arch_destroy_vm>> kvfree(rcu_dereference_check(kvm->arch.apic_map, 1));
+	 */
 	struct kvm_apic_map __rcu *apic_map;
+	/*
+	 * 在以下使用kvm_arch->apic_map_dirty:
+	 *   - arch/x86/kvm/lapic.c|279| <<kvm_recalculate_apic_map>> if (atomic_read_acquire(&kvm->arch.apic_map_dirty) == CLEAN)
+	 *   - arch/x86/kvm/lapic.c|290| <<kvm_recalculate_apic_map>> if (atomic_cmpxchg_acquire(&kvm->arch.apic_map_dirty,
+	 *   - arch/x86/kvm/lapic.c|378| <<kvm_recalculate_apic_map>> atomic_cmpxchg_release(&kvm->arch.apic_map_dirty,
+	 *   - arch/x86/kvm/lapic.c|401| <<apic_set_spiv>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|441| <<kvm_apic_set_xapic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|447| <<kvm_apic_set_ldr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|453| <<kvm_apic_set_dfr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|496| <<kvm_apic_set_x2apic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|2862| <<kvm_lapic_set_base>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|3370| <<kvm_apic_set_state>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 */
 	atomic_t apic_map_dirty;
 
 	/* Protects apic_access_memslot_enabled and apicv_inhibit_reasons */
 	struct rw_semaphore apicv_update_lock;
 
 	bool apic_access_memslot_enabled;
+	/*
+	 * 在以下使用kvm_arch->apicv_inhibit_reasons:
+	 *   - arch/x86/kvm/x86.c|9007| <<kvm_apicv_activated>> return (READ_ONCE(kvm->arch.apicv_inhibit_reasons) == 0);
+	 *   - arch/x86/kvm/x86.c|9013| <<kvm_vcpu_apicv_activated>> ulong vm_reasons = READ_ONCE(vcpu->kvm->arch.apicv_inhibit_reasons);
+	 *   - arch/x86/kvm/x86.c|9033| <<kvm_apicv_init>> unsigned long *inhibits = &kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|9830| <<__kvm_set_or_clear_apicv_inhibit>> old = new = kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|9848| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 *   - arch/x86/kvm/x86.c|9857| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 */
 	unsigned long apicv_inhibit_reasons;
 
 	gpa_t wall_clock;
@@ -1156,6 +1317,13 @@ struct kvm_arch {
 	bool pause_in_guest;
 	bool cstate_in_guest;
 
+	/*
+	 * 在以下使用kvm_arch->irq_sources_bitmap:
+	 *   - arch/x86/kvm/irq_comm.c|187| <<kvm_request_irq_source_id>> unsigned long *bitmap = &kvm->arch.irq_sources_bitmap;
+	 *   - arch/x86/kvm/irq_comm.c|219| <<kvm_free_irq_source_id>> clear_bit(irq_source_id, &kvm->arch.irq_sources_bitmap);
+	 *   - arch/x86/kvm/x86.c|11732| <<kvm_arch_init_vm>> set_bit(KVM_USERSPACE_IRQ_SOURCE_ID, &kvm->arch.irq_sources_bitmap);
+	 *   - arch/x86/kvm/x86.c|11735| <<kvm_arch_init_vm>> set_bit(KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID, &kvm->arch.irq_sources_bitmap);
+	 */
 	unsigned long irq_sources_bitmap;
 	s64 kvmclock_offset;
 	raw_spinlock_t tsc_write_lock;
@@ -1177,6 +1345,12 @@ struct kvm_arch {
 
 	struct kvm_xen_hvm_config xen_hvm_config;
 
+	/*
+	 * 在以下使用kvm_arch->mask_notifier_list:
+	 *   - arch/x86/kvm/irq_comm.c|234| <<kvm_register_irq_mask_notifier>> hlist_add_head_rcu(&kimn->link, &kvm->arch.mask_notifier_list);
+	 *   - arch/x86/kvm/irq_comm.c|256| <<kvm_fire_mask_notifiers>> hlist_for_each_entry_rcu(kimn, &kvm->arch.mask_notifier_list, link)
+	 *   - arch/x86/kvm/x86.c|11763| <<kvm_arch_init_vm>> INIT_HLIST_HEAD(&kvm->arch.mask_notifier_list);
+	 */
 	/* reads protected by irq_srcu, writes by irq_lock */
 	struct hlist_head mask_notifier_list;
 
@@ -1195,11 +1369,38 @@ struct kvm_arch {
 	int cpu_dirty_logging_count;
 
 	enum kvm_irqchip_mode irqchip_mode;
+	/*
+	 * 在以下使用kvm_arch->nr_reserved_ioapic_pins:
+	 *   - arch/x86/kvm/irq_comm.c|405| <<kvm_scan_ioapic_routes>> nr_ioapic_pins =
+	 *               min_t(u32, table->nr_rt_entries, kvm->arch.nr_reserved_ioapic_pins);
+	 *   - arch/x86/kvm/x86.c|5796| <<kvm_vm_ioctl_enable_cap>>
+	 *               kvm->arch.nr_reserved_ioapic_pins = cap->args[0];
+	 */
 	u8 nr_reserved_ioapic_pins;
 
 	bool disabled_lapic_found;
 
+	/*
+	 * 在以下使用kvm_arch->x2apic_format:
+	 *   - arch/x86/kvm/irq_comm.c|137| <<kvm_set_msi_irq>> trace_kvm_msi_set_irq(msg.address_lo | (kvm->arch.x2apic_format ?
+	 *   - arch/x86/kvm/irq_comm.c|140| <<kvm_set_msi_irq>> irq->dest_id = x86_msi_msg_get_destid(&msg, kvm->arch.x2apic_format);
+	 *   - arch/x86/kvm/irq_comm.c|154| <<kvm_msi_route_invalid>> return kvm->arch.x2apic_format && (e->msi.address_hi & 0xff);
+	 *   - arch/x86/kvm/lapic.c|3673| <<kvm_apic_state_fixup>> if (vcpu->kvm->arch.x2apic_format) {
+	 *   - arch/x86/kvm/x86.c|5933| <<kvm_vm_ioctl_enable_cap>> kvm->arch.x2apic_format = true;
+	 *
+	 *     x2apic_format = false,
+	 *     x2apic_broadcast_quirk_disabled = false,
+	 */
 	bool x2apic_format;
+	/*
+	 * 在以下使用kvm_arch->x2apic_broadcast_quirk_disabled:
+	 *   - arch/x86/kvm/lapic.c|1356| <<kvm_apic_mda>> if (!vcpu->kvm->arch.x2apic_broadcast_quirk_disabled &&
+	 *   - arch/x86/kvm/lapic.c|1435| <<kvm_apic_is_broadcast_dest>> if (kvm->arch.x2apic_broadcast_quirk_disabled) {
+	 *   - arch/x86/kvm/x86.c|5935| <<kvm_vm_ioctl_enable_cap>> kvm->arch.x2apic_broadcast_quirk_disabled = true;
+	 *
+	 *     x2apic_format = false,
+	 *     x2apic_broadcast_quirk_disabled = false,
+	 */
 	bool x2apic_broadcast_quirk_disabled;
 
 	bool guest_can_read_msr_platform_info;
@@ -1872,15 +2073,41 @@ void __kvm_set_or_clear_apicv_inhibit(struct kvm *kvm,
 void kvm_set_or_clear_apicv_inhibit(struct kvm *kvm,
 				    enum kvm_apicv_inhibit reason, bool set);
 
+/*
+ * 在以下使用kvm_set_apicv_inhibit():
+ *   - arch/x86/kvm/i8254.c|308| <<kvm_pit_set_reinject>> kvm_set_apicv_inhibit(kvm, APICV_INHIBIT_REASON_PIT_REINJ);
+ *   - arch/x86/kvm/lapic.c|337| <<kvm_recalculate_apic_map>> kvm_set_apicv_inhibit(kvm, APICV_INHIBIT_REASON_APIC_ID_MODIFIED);
+ *   - arch/x86/kvm/lapic.c|2715| <<kvm_lapic_set_base>> kvm_set_apicv_inhibit(apic->vcpu->kvm, APICV_INHIBIT_REASON_APIC_BASE_MODIFIED);
+ *   - arch/x86/kvm/svm/sev.c|263| <<sev_guest_init>> kvm_set_apicv_inhibit(kvm, APICV_INHIBIT_REASON_SEV);
+ *   - arch/x86/kvm/svm/svm.c|3855| <<svm_enable_irq_window>> kvm_set_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+ */
 static inline void kvm_set_apicv_inhibit(struct kvm *kvm,
 					 enum kvm_apicv_inhibit reason)
 {
+	/*
+	 * 在以下调用kvm_set_or_clear_apicv_inhibit():
+	 *   - arch/x86/include/asm/kvm_host.h|2021| <<kvm_set_apicv_inhibit>> kvm_set_or_clear_apicv_inhibit(kvm, reason, true);
+	 *   - arch/x86/include/asm/kvm_host.h|2027| <<kvm_clear_apicv_inhibit>> kvm_set_or_clear_apicv_inhibit(kvm, reason, false);
+	 */
 	kvm_set_or_clear_apicv_inhibit(kvm, reason, true);
 }
 
+/*
+ * 在以下使用kvm_clear_apicv_inhibit():
+ *   - arch/x86/kvm/i8254.c|314| <<kvm_pit_set_reinject>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_PIT_REINJ);
+ *   - arch/x86/kvm/lapic.c|579| <<kvm_recalculate_apic_map>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_APIC_ID_MODIFIED);
+ *   - arch/x86/kvm/svm/svm.c|3235| <<interrupt_window_interception>> kvm_clear_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+ *   - arch/x86/kvm/x86.c|6050| <<kvm_vm_ioctl_enable_cap(KVM_CAP_SPLIT_IRQCHIP)>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
+ *   - arch/x86/kvm/x86.c|6465| <<kvm_arch_vm_ioctl(KVM_CREATE_IRQCHIP)>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
+ */
 static inline void kvm_clear_apicv_inhibit(struct kvm *kvm,
 					   enum kvm_apicv_inhibit reason)
 {
+	/*
+	 * 在以下调用kvm_set_or_clear_apicv_inhibit():
+	 *   - arch/x86/include/asm/kvm_host.h|2021| <<kvm_set_apicv_inhibit>> kvm_set_or_clear_apicv_inhibit(kvm, reason, true);
+	 *   - arch/x86/include/asm/kvm_host.h|2027| <<kvm_clear_apicv_inhibit>> kvm_set_or_clear_apicv_inhibit(kvm, reason, false);
+	 */
 	kvm_set_or_clear_apicv_inhibit(kvm, reason, false);
 }
 
diff --git a/arch/x86/kernel/apic/io_apic.c b/arch/x86/kernel/apic/io_apic.c
index 586ea838a5a1..22f9c3bc4c2a 100644
--- a/arch/x86/kernel/apic/io_apic.c
+++ b/arch/x86/kernel/apic/io_apic.c
@@ -1896,6 +1896,11 @@ static void ioapic_setup_msg_from_msi(struct irq_data *irq_data,
 	entry->ir_index_0_14		= msg.arch_addr_lo.dmar_index_0_14;
 }
 
+/*
+ * 在以下使用ioapic_configure_entry():
+ *   - arch/x86/kernel/apic/io_apic.c|1920| <<ioapic_set_affinity>> ioapic_configure_entry(irq_data);
+ *   - arch/x86/kernel/apic/io_apic.c|3078| <<mp_irqdomain_activate>> ioapic_configure_entry(irq_data);
+ */
 static void ioapic_configure_entry(struct irq_data *irqd)
 {
 	struct mp_chip_data *mpd = irqd->chip_data;
diff --git a/arch/x86/kernel/cpu/intel.c b/arch/x86/kernel/cpu/intel.c
index 0ad97eea771e..b271e25c5642 100644
--- a/arch/x86/kernel/cpu/intel.c
+++ b/arch/x86/kernel/cpu/intel.c
@@ -53,7 +53,28 @@ enum split_lock_detect_state {
  * sld_state_setup() will switch this to sld_warn on systems that support
  * split lock/bus lock detect, unless there is a command line override.
  */
+/*
+ * 在以下使用sld_state:
+ *   - arch/x86/kernel/cpu/intel.c|60| <<global>> static enum split_lock_detect_state sld_state __ro_after_init = sld_off;
+ *   - arch/x86/kernel/cpu/intel.c|1100| <<sld_state_setup>> sld_state = state;
+ *   - arch/x86/kernel/cpu/intel.c|1144| <<split_lock_init>> if (sld_state == sld_ratelimit) {
+ *   - arch/x86/kernel/cpu/intel.c|1150| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+ *   - arch/x86/kernel/cpu/intel.c|1222| <<handle_guest_split_lock>> if (sld_state == sld_warn) {
+ *   - arch/x86/kernel/cpu/intel.c|1229| <<handle_guest_split_lock>> sld_state == sld_fatal ? "fatal" : "bogus", ip);
+ *   - arch/x86/kernel/cpu/intel.c|1248| <<bus_lock_init>> (sld_state == sld_warn || sld_state == sld_fatal)) ||
+ *   - arch/x86/kernel/cpu/intel.c|1249| <<bus_lock_init>> sld_state == sld_off) {
+ *   - arch/x86/kernel/cpu/intel.c|1264| <<handle_user_split_lock>> if ((regs->flags & X86_EFLAGS_AC) || sld_state == sld_fatal)
+ *   - arch/x86/kernel/cpu/intel.c|1272| <<handle_bus_lock>> switch (sld_state) {
+ *   - arch/x86/kernel/cpu/intel.c|1355| <<sld_state_show>> switch (sld_state) {
+ */
 static enum split_lock_detect_state sld_state __ro_after_init = sld_off;
+/*
+ * 在以下使用msr_test_ctrl_cache:
+ *   - arch/x86/kernel/cpu/intel.c|71| <<global>> static u64 msr_test_ctrl_cache __ro_after_init;
+ *   - arch/x86/kernel/cpu/intel.c|1173| <<__split_lock_setup>> rdmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
+ *   - arch/x86/kernel/cpu/intel.c|1188| <<__split_lock_setup>> wrmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
+ *   - arch/x86/kernel/cpu/intel.c|1200| <<sld_update_msr>> u64 test_ctrl_val = msr_test_ctrl_cache;
+ */
 static u64 msr_test_ctrl_cache __ro_after_init;
 
 /*
@@ -61,6 +82,12 @@ static u64 msr_test_ctrl_cache __ro_after_init;
  * MSR_TEST_CTL unless the CPU is one of the whitelisted models.  Writing it
  * on CPUs that do not support SLD can cause fireworks, even when writing '0'.
  */
+/*
+ * 在以下使用cpu_model_supports_sld:
+ *   - arch/x86/kernel/cpu/intel.c|64| <<global>> static bool cpu_model_supports_sld __ro_after_init;
+ *   - arch/x86/kernel/cpu/intel.c|1145| <<split_lock_init>> if (cpu_model_supports_sld)
+ *   - arch/x86/kernel/cpu/intel.c|1341| <<split_lock_setup>> cpu_model_supports_sld = true;
+ */
 static bool cpu_model_supports_sld __ro_after_init;
 
 /*
@@ -998,6 +1025,14 @@ cpu_dev_register(intel_cpu_dev);
 #undef pr_fmt
 #define pr_fmt(fmt) "x86/split lock detection: " fmt
 
+/*
+ * enum split_lock_detect_state {
+ *     sld_off = 0,
+ *     sld_warn,
+ *     sld_fatal,
+ *     sld_ratelimit,
+ * };
+ */
 static const struct {
 	const char			*option;
 	enum split_lock_detect_state	state;
@@ -1008,9 +1043,29 @@ static const struct {
 	{ "ratelimit:", sld_ratelimit },
 };
 
+/*
+ * 在以下使用bld_ratelimit:
+ *   - arch/x86/kernel/cpu/intel.c|1052| <<match_option>> ratelimit_state_init(&bld_ratelimit, HZ, ratelimit);
+ *   - arch/x86/kernel/cpu/intel.c|1053| <<match_option>> ratelimit_set_flags(&bld_ratelimit, RATELIMIT_MSG_ON_RELEASE);
+ *   - arch/x86/kernel/cpu/intel.c|1273| <<handle_bus_lock>> while (!__ratelimit(&bld_ratelimit))
+ *   - arch/x86/kernel/cpu/intel.c|1376| <<sld_state_show>> pr_info("#DB: setting system wide bus lock rate limit to %u/sec\n",
+ *                                             bld_ratelimit.burst);
+ */
 static struct ratelimit_state bld_ratelimit;
 
+/*
+ * 在以下使用sysctl_sld_mitigate:
+ *   - arch/x86/kernel/cpu/intel.c|1013| <<global>> static unsigned int sysctl_sld_mitigate = 1;
+ *   - arch/x86/kernel/cpu/intel.c|1020| <<global>> .data = &sysctl_sld_mitigate,
+ *   - arch/x86/kernel/cpu/intel.c|1190| <<split_lock_warn>> if (sysctl_sld_mitigate) {
+ */
 static unsigned int sysctl_sld_mitigate = 1;
+/*
+ * 在以下使用buslock_sem:
+ *   - arch/x86/kernel/cpu/intel.c|1063| <<global>> static DEFINE_SEMAPHORE(buslock_sem);
+ *   - arch/x86/kernel/cpu/intel.c|1313| <<__split_lock_reenable_unlock>> up(&buslock_sem);
+ *   - arch/x86/kernel/cpu/intel.c|1389| <<split_lock_warn>> if (down_interruptible(&buslock_sem) == -EINTR)
+ */
 static DEFINE_SEMAPHORE(buslock_sem);
 
 #ifdef CONFIG_PROC_SYSCTL
@@ -1029,6 +1084,9 @@ static struct ctl_table sld_sysctls[] = {
 
 static int __init sld_mitigate_sysctl_init(void)
 {
+	/*
+	 * sysctl_sld_mitigate
+	 */
 	register_sysctl_init("kernel", sld_sysctls);
 	return 0;
 }
@@ -1057,12 +1115,34 @@ static inline bool match_option(const char *arg, int arglen, const char *opt)
 	return len == arglen;
 }
 
+/*
+ * 在以下调用split_lock_verify_msr():
+ *   - arch/x86/kernel/cpu/intel.c|1101| <<__split_lock_setup>> if (!split_lock_verify_msr(false)) {
+ *   - arch/x86/kernel/cpu/intel.c|1108| <<__split_lock_setup>> if (!split_lock_verify_msr(true)) {
+ *   - arch/x86/kernel/cpu/intel.c|1141| <<split_lock_init>> split_lock_verify_msr(false);
+ *   - arch/x86/kernel/cpu/intel.c|1146| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+ */
 static bool split_lock_verify_msr(bool on)
 {
 	u64 ctrl, tmp;
 
+	/*
+	 * 在以下使用MSR_TEST_CTRL:
+	 *   - arch/x86/kernel/cpu/intel.c|1129| <<split_lock_verify_msr>> if (rdmsrl_safe(MSR_TEST_CTRL, &ctrl))
+	 *   - arch/x86/kernel/cpu/intel.c|1141| <<split_lock_verify_msr>> if (wrmsrl_safe(MSR_TEST_CTRL, ctrl))
+	 *   - arch/x86/kernel/cpu/intel.c|1143| <<split_lock_verify_msr>> rdmsrl(MSR_TEST_CTRL, tmp);
+	 *   - arch/x86/kernel/cpu/intel.c|1223| <<__split_lock_setup>> rdmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
+	 *   - arch/x86/kernel/cpu/intel.c|1238| <<__split_lock_setup>> wrmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
+	 *   - arch/x86/kernel/cpu/intel.c|1293| <<sld_update_msr>> wrmsrl(MSR_TEST_CTRL, test_ctrl_val);
+	 */
 	if (rdmsrl_safe(MSR_TEST_CTRL, &ctrl))
 		return false;
+	/*
+	 * 在以下使用MSR_TEST_CTRL_SPLIT_LOCK_DETECT:
+	 *   - arch/x86/kernel/cpu/intel.c|1132| <<split_lock_verify_msr>> ctrl |= MSR_TEST_CTRL_SPLIT_LOCK_DETECT;
+	 *   - arch/x86/kernel/cpu/intel.c|1134| <<split_lock_verify_msr>> ctrl &= ~MSR_TEST_CTRL_SPLIT_LOCK_DETECT;
+	 *   - arch/x86/kernel/cpu/intel.c|1275| <<sld_update_msr>> test_ctrl_val |= MSR_TEST_CTRL_SPLIT_LOCK_DETECT;
+	 */
 	if (on)
 		ctrl |= MSR_TEST_CTRL_SPLIT_LOCK_DETECT;
 	else
@@ -1073,8 +1153,22 @@ static bool split_lock_verify_msr(bool on)
 	return ctrl == tmp;
 }
 
+/*
+ * 在以下调用sld_state_setup():
+ *   - arch/x86/kernel/cpu/intel.c|1675| <<sld_setup>> sld_state_setup();
+ */
 static void __init sld_state_setup(void)
 {
+	/*
+	 * enum split_lock_detect_state {
+	 *     sld_off = 0,
+	 *     sld_warn,
+	 *     sld_fatal,
+	 *     sld_ratelimit,
+	 * };
+	 *
+	 * 默认是sld_warn.
+	 */
 	enum split_lock_detect_state state = sld_warn;
 	char arg[20];
 	int i, ret;
@@ -1093,18 +1187,65 @@ static void __init sld_state_setup(void)
 			}
 		}
 	}
+	/*
+	 * 在以下使用sld_state:
+	 *   - arch/x86/kernel/cpu/intel.c|60| <<global>> static enum split_lock_detect_state sld_state __ro_after_init = sld_off;
+	 *   - arch/x86/kernel/cpu/intel.c|1100| <<sld_state_setup>> sld_state = state;
+	 *   - arch/x86/kernel/cpu/intel.c|1144| <<split_lock_init>> if (sld_state == sld_ratelimit) {
+	 *   - arch/x86/kernel/cpu/intel.c|1150| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+	 *   - arch/x86/kernel/cpu/intel.c|1222| <<handle_guest_split_lock>> if (sld_state == sld_warn) {
+	 *   - arch/x86/kernel/cpu/intel.c|1229| <<handle_guest_split_lock>> sld_state == sld_fatal ? "fatal" : "bogus", ip);
+	 *   - arch/x86/kernel/cpu/intel.c|1248| <<bus_lock_init>> (sld_state == sld_warn || sld_state == sld_fatal)) ||
+	 *   - arch/x86/kernel/cpu/intel.c|1249| <<bus_lock_init>> sld_state == sld_off) {
+	 *   - arch/x86/kernel/cpu/intel.c|1264| <<handle_user_split_lock>> if ((regs->flags & X86_EFLAGS_AC) || sld_state == sld_fatal)
+	 *   - arch/x86/kernel/cpu/intel.c|1272| <<handle_bus_lock>> switch (sld_state) {
+	 *   - arch/x86/kernel/cpu/intel.c|1355| <<sld_state_show>> switch (sld_state) {
+	 */
 	sld_state = state;
 }
 
+/*
+ * 在以下使用__split_lock_setup():
+ *   - arch/x86/kernel/cpu/intel.c|1715| <<split_lock_setup>> __split_lock_setup();
+ */
 static void __init __split_lock_setup(void)
 {
+	/*
+	 * 在以下调用split_lock_verify_msr():
+	 *   - arch/x86/kernel/cpu/intel.c|1101| <<__split_lock_setup>> if (!split_lock_verify_msr(false)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1108| <<__split_lock_setup>> if (!split_lock_verify_msr(true)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1141| <<split_lock_init>> split_lock_verify_msr(false);
+	 *   - arch/x86/kernel/cpu/intel.c|1146| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+	 */
 	if (!split_lock_verify_msr(false)) {
 		pr_info("MSR access failed: Disabled\n");
 		return;
 	}
 
+	/*
+	 * 在以下使用MSR_TEST_CTRL:
+	 *   - arch/x86/kernel/cpu/intel.c|1129| <<split_lock_verify_msr>> if (rdmsrl_safe(MSR_TEST_CTRL, &ctrl))
+	 *   - arch/x86/kernel/cpu/intel.c|1141| <<split_lock_verify_msr>> if (wrmsrl_safe(MSR_TEST_CTRL, ctrl))
+	 *   - arch/x86/kernel/cpu/intel.c|1143| <<split_lock_verify_msr>> rdmsrl(MSR_TEST_CTRL, tmp);
+	 *   - arch/x86/kernel/cpu/intel.c|1223| <<__split_lock_setup>> rdmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
+	 *   - arch/x86/kernel/cpu/intel.c|1238| <<__split_lock_setup>> wrmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
+	 *   - arch/x86/kernel/cpu/intel.c|1293| <<sld_update_msr>> wrmsrl(MSR_TEST_CTRL, test_ctrl_val);
+	 *
+	 * 在以下使用msr_test_ctrl_cache:
+	 *   - arch/x86/kernel/cpu/intel.c|71| <<global>> static u64 msr_test_ctrl_cache __ro_after_init;
+	 *   - arch/x86/kernel/cpu/intel.c|1173| <<__split_lock_setup>> rdmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
+	 *   - arch/x86/kernel/cpu/intel.c|1188| <<__split_lock_setup>> wrmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
+	 *   - arch/x86/kernel/cpu/intel.c|1200| <<sld_update_msr>> u64 test_ctrl_val = msr_test_ctrl_cache;
+	 */
 	rdmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
 
+	/*
+	 * 在以下调用split_lock_verify_msr():
+	 *   - arch/x86/kernel/cpu/intel.c|1101| <<__split_lock_setup>> if (!split_lock_verify_msr(false)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1108| <<__split_lock_setup>> if (!split_lock_verify_msr(true)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1141| <<split_lock_init>> split_lock_verify_msr(false);
+	 *   - arch/x86/kernel/cpu/intel.c|1146| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+	 */
 	if (!split_lock_verify_msr(true)) {
 		pr_info("MSR access failed: Disabled\n");
 		return;
@@ -1113,6 +1254,20 @@ static void __init __split_lock_setup(void)
 	/* Restore the MSR to its cached value. */
 	wrmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
 
+	/*
+	 * 在以下使用X86_FEATURE_SPLIT_LOCK_DETECT:
+	 *   - arch/x86/kernel/cpu/intel.c|1149| <<sld_state_setup>> if (!boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) &&
+	 *   - arch/x86/kernel/cpu/intel.c|1221| <<__split_lock_setup>> setup_force_cpu_cap(X86_FEATURE_SPLIT_LOCK_DETECT);
+	 *   - arch/x86/kernel/cpu/intel.c|1475| <<bus_lock_init>> if ((boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) &&
+	 *   - arch/x86/kernel/cpu/intel.c|1621| <<sld_state_show>> !boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 *   - arch/x86/kernel/cpu/intel.c|1643| <<sld_state_show>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1653| <<sld_state_show>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1657| <<sld_state_show>> boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) ?
+	 *   - arch/x86/kvm/vmx/vmx.c|4917| <<vmx_guest_inject_ac>> if (!boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 *   - arch/x86/kvm/x86.c|7297| <<emulator_cmpxchg_emulated>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 *
+	 * 只在此处设置X86_FEATURE_SPLIT_LOCK_DETECT
+	 */
 	setup_force_cpu_cap(X86_FEATURE_SPLIT_LOCK_DETECT);
 }
 
@@ -1121,18 +1276,66 @@ static void __init __split_lock_setup(void)
  * is not implemented as one thread could undo the setting of the other
  * thread immediately after dropping the lock anyway.
  */
+/*
+ * 在以下使用sld_update_msr():
+ *   - arch/x86/kernel/cpu/intel.c|1239| <<__split_lock_reenable_unlock>> sld_update_msr(true);
+ *   - arch/x86/kernel/cpu/intel.c|1247| <<__split_lock_reenable>> sld_update_msr(true);
+ *   - arch/x86/kernel/cpu/intel.c|1263| <<splitlock_cpu_offline>> sld_update_msr(true);
+ *   - arch/x86/kernel/cpu/intel.c|1305| <<split_lock_warn>> sld_update_msr(false);
+ *
+ * MSR_TEST_CTRL is per core, but we treat it like a per CPU MSR. Locking
+ * is not implemented as one thread could undo the setting of the other
+ * thread immediately after dropping the lock anyway.
+ */
 static void sld_update_msr(bool on)
 {
+	/*
+	 * 在以下使用msr_test_ctrl_cache:
+	 *   - arch/x86/kernel/cpu/intel.c|71| <<global>> static u64 msr_test_ctrl_cache __ro_after_init;
+	 *   - arch/x86/kernel/cpu/intel.c|1173| <<__split_lock_setup>> rdmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
+	 *   - arch/x86/kernel/cpu/intel.c|1188| <<__split_lock_setup>> wrmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
+	 *   - arch/x86/kernel/cpu/intel.c|1200| <<sld_update_msr>> u64 test_ctrl_val = msr_test_ctrl_cache;0
+	 */
 	u64 test_ctrl_val = msr_test_ctrl_cache;
 
+	/*
+	 * 在以下使用MSR_TEST_CTRL_SPLIT_LOCK_DETECT:
+	 *   - arch/x86/kernel/cpu/intel.c|1132| <<split_lock_verify_msr>> ctrl |= MSR_TEST_CTRL_SPLIT_LOCK_DETECT;
+	 *   - arch/x86/kernel/cpu/intel.c|1134| <<split_lock_verify_msr>> ctrl &= ~MSR_TEST_CTRL_SPLIT_LOCK_DETECT;
+	 *   - arch/x86/kernel/cpu/intel.c|1275| <<sld_update_msr>> test_ctrl_val |= MSR_TEST_CTRL_SPLIT_LOCK_DETECT;
+	 */
 	if (on)
 		test_ctrl_val |= MSR_TEST_CTRL_SPLIT_LOCK_DETECT;
 
 	wrmsrl(MSR_TEST_CTRL, test_ctrl_val);
 }
 
+/*
+ * 在以下调用split_lock_init():
+ *   - arch/x86/kernel/cpu/intel.c|758| <<init_intel>> split_lock_init();
+ */
 static void split_lock_init(void)
 {
+	/*
+	 * 在以下使用sld_state:
+	 *   - arch/x86/kernel/cpu/intel.c|60| <<global>> static enum split_lock_detect_state sld_state __ro_after_init = sld_off;
+	 *   - arch/x86/kernel/cpu/intel.c|1100| <<sld_state_setup>> sld_state = state;
+	 *   - arch/x86/kernel/cpu/intel.c|1144| <<split_lock_init>> if (sld_state == sld_ratelimit) {
+	 *   - arch/x86/kernel/cpu/intel.c|1150| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+	 *   - arch/x86/kernel/cpu/intel.c|1222| <<handle_guest_split_lock>> if (sld_state == sld_warn) {
+	 *   - arch/x86/kernel/cpu/intel.c|1229| <<handle_guest_split_lock>> sld_state == sld_fatal ? "fatal" : "bogus", ip);
+	 *   - arch/x86/kernel/cpu/intel.c|1248| <<bus_lock_init>> (sld_state == sld_warn || sld_state == sld_fatal)) ||
+	 *   - arch/x86/kernel/cpu/intel.c|1249| <<bus_lock_init>> sld_state == sld_off) {
+	 *   - arch/x86/kernel/cpu/intel.c|1264| <<handle_user_split_lock>> if ((regs->flags & X86_EFLAGS_AC) || sld_state == sld_fatal)
+	 *   - arch/x86/kernel/cpu/intel.c|1272| <<handle_bus_lock>> switch (sld_state) {
+	 *   - arch/x86/kernel/cpu/intel.c|1355| <<sld_state_show>> switch (sld_state) {
+	 *
+	 * 在以下调用split_lock_verify_msr():
+	 *   - arch/x86/kernel/cpu/intel.c|1101| <<__split_lock_setup>> if (!split_lock_verify_msr(false)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1108| <<__split_lock_setup>> if (!split_lock_verify_msr(true)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1141| <<split_lock_init>> split_lock_verify_msr(false);
+	 *   - arch/x86/kernel/cpu/intel.c|1146| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+	 */
 	/*
 	 * #DB for bus lock handles ratelimit and #AC for split lock is
 	 * disabled.
@@ -1142,22 +1345,80 @@ static void split_lock_init(void)
 		return;
 	}
 
+	/*
+	 * enum split_lock_detect_state {
+	 *     sld_off = 0,
+	 *     sld_warn,
+	 *     sld_fatal,
+	 *     sld_ratelimit,
+	 * };
+	 *
+	 * 在以下调用split_lock_verify_msr():
+	 *   - arch/x86/kernel/cpu/intel.c|1101| <<__split_lock_setup>> if (!split_lock_verify_msr(false)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1108| <<__split_lock_setup>> if (!split_lock_verify_msr(true)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1141| <<split_lock_init>> split_lock_verify_msr(false);
+	 *   - arch/x86/kernel/cpu/intel.c|1146| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+	 */
 	if (cpu_model_supports_sld)
 		split_lock_verify_msr(sld_state != sld_off);
 }
 
+/*
+ * 在以下使用__split_lock_reenable_unlock():
+ *   - arch/x86/kernel/cpu/intel.c|1320| <<global>> static DECLARE_DELAYED_WORK(sl_reenable_unlock, __split_lock_reenable_unlock);
+ */
 static void __split_lock_reenable_unlock(struct work_struct *work)
 {
+	/*
+	 * 在以下使用sld_update_msr():
+	 *   - arch/x86/kernel/cpu/intel.c|1239| <<__split_lock_reenable_unlock>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1247| <<__split_lock_reenable>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1263| <<splitlock_cpu_offline>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1305| <<split_lock_warn>> sld_update_msr(false);
+	 *
+	 * MSR_TEST_CTRL is per core, but we treat it like a per CPU MSR. Locking
+	 * is not implemented as one thread could undo the setting of the other
+	 * thread immediately after dropping the lock anyway.
+	 */
 	sld_update_msr(true);
+	/*
+	 * 在以下使用buslock_sem:
+	 *   - arch/x86/kernel/cpu/intel.c|1063| <<global>> static DEFINE_SEMAPHORE(buslock_sem);
+	 *   - arch/x86/kernel/cpu/intel.c|1313| <<__split_lock_reenable_unlock>> up(&buslock_sem);
+	 *   - arch/x86/kernel/cpu/intel.c|1389| <<split_lock_warn>> if (down_interruptible(&buslock_sem) == -EINTR)
+	 */
 	up(&buslock_sem);
 }
 
+/*
+ * 在以下调用sl_reenable_unlock:
+ *   - arch/x86/kernel/cpu/intel.c|1391| <<split_lock_warn>> work = &sl_reenable_unlock;
+ */
 static DECLARE_DELAYED_WORK(sl_reenable_unlock, __split_lock_reenable_unlock);
 
+/*
+ * 在以下使用__split_lock_reenable():
+ *   - arch/x86/kernel/cpu/intel.c|1333| <<global>> static DECLARE_DELAYED_WORK(sl_reenable, __split_lock_reenable);
+ */
 static void __split_lock_reenable(struct work_struct *work)
 {
+	/*
+	 * 在以下使用sld_update_msr():
+	 *   - arch/x86/kernel/cpu/intel.c|1239| <<__split_lock_reenable_unlock>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1247| <<__split_lock_reenable>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1263| <<splitlock_cpu_offline>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1305| <<split_lock_warn>> sld_update_msr(false);
+	 *
+	 * MSR_TEST_CTRL is per core, but we treat it like a per CPU MSR. Locking
+	 * is not implemented as one thread could undo the setting of the other
+	 * thread immediately after dropping the lock anyway.
+	 */
 	sld_update_msr(true);
 }
+/*
+ * 在以下调用sl_reenable:
+ *   - arch/x86/kernel/cpu/intel.c|1393| <<split_lock_warn>> work = &sl_reenable;
+ */
 static DECLARE_DELAYED_WORK(sl_reenable, __split_lock_reenable);
 
 /*
@@ -1172,21 +1433,49 @@ static DECLARE_DELAYED_WORK(sl_reenable, __split_lock_reenable);
  */
 static int splitlock_cpu_offline(unsigned int cpu)
 {
+	/*
+	 * 在以下使用sld_update_msr():
+	 *   - arch/x86/kernel/cpu/intel.c|1239| <<__split_lock_reenable_unlock>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1247| <<__split_lock_reenable>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1263| <<splitlock_cpu_offline>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1305| <<split_lock_warn>> sld_update_msr(false);
+	 *
+	 * MSR_TEST_CTRL is per core, but we treat it like a per CPU MSR. Locking
+	 * is not implemented as one thread could undo the setting of the other
+	 * thread immediately after dropping the lock anyway.
+	 */
 	sld_update_msr(true);
 
 	return 0;
 }
 
+/*
+ * 在以下使用split_lock_warn():
+ *   - arch/x86/kernel/cpu/intel.c|1219| <<handle_guest_split_lock>> split_lock_warn(ip);
+ *   - arch/x86/kernel/cpu/intel.c|1262| <<handle_user_split_lock>> split_lock_warn(regs->ip);
+ */
 static void split_lock_warn(unsigned long ip)
 {
 	struct delayed_work *work;
 	int cpu;
 
+	/*
+	 * 在以下使用task_struct->reported_split_lock:
+	 *   - arch/x86/kernel/cpu/intel.c|1373| <<split_lock_warn>> if (!current->reported_split_lock)
+	 *   - arch/x86/kernel/cpu/intel.c|1376| <<split_lock_warn>> current->reported_split_lock = 1;
+	 *   - kernel/fork.c|989| <<dup_task_struct>> tsk->reported_split_lock = 0;
+	 */
 	if (!current->reported_split_lock)
 		pr_warn_ratelimited("#AC: %s/%d took a split_lock trap at address: 0x%lx\n",
 				    current->comm, current->pid, ip);
 	current->reported_split_lock = 1;
 
+	/*
+	 * 在以下使用sysctl_sld_mitigate:
+	 *   - arch/x86/kernel/cpu/intel.c|1013| <<global>> static unsigned int sysctl_sld_mitigate = 1;
+	 *   - arch/x86/kernel/cpu/intel.c|1020| <<global>> .data = &sysctl_sld_mitigate,
+	 *   - arch/x86/kernel/cpu/intel.c|1190| <<split_lock_warn>> if (sysctl_sld_mitigate) {
+	 */
 	if (sysctl_sld_mitigate) {
 		/*
 		 * misery factor #1:
@@ -1194,28 +1483,81 @@ static void split_lock_warn(unsigned long ip)
 		 */
 		if (msleep_interruptible(10) > 0)
 			return;
+		/*
+		 * 在以下使用buslock_sem:
+		 *   - arch/x86/kernel/cpu/intel.c|1063| <<global>> static DEFINE_SEMAPHORE(buslock_sem);
+		 *   - arch/x86/kernel/cpu/intel.c|1313| <<__split_lock_reenable_unlock>> up(&buslock_sem);
+		 *   - arch/x86/kernel/cpu/intel.c|1389| <<split_lock_warn>> if (down_interruptible(&buslock_sem) == -EINTR)
+		 */
 		/*
 		 * Misery factor #2:
 		 * only allow one buslocked disabled core at a time.
 		 */
 		if (down_interruptible(&buslock_sem) == -EINTR)
 			return;
+		/*
+		 * static DECLARE_DELAYED_WORK(sl_reenable_unlock, __split_lock_reenable_unlock);
+		 */
 		work = &sl_reenable_unlock;
 	} else {
+		/*
+		 * static DECLARE_DELAYED_WORK(sl_reenable, __split_lock_reenable);
+		 */
 		work = &sl_reenable;
 	}
 
 	cpu = get_cpu();
 	schedule_delayed_work_on(cpu, work, 2);
 
+	/*
+	 * 在以下使用sld_update_msr():
+	 *   - arch/x86/kernel/cpu/intel.c|1239| <<__split_lock_reenable_unlock>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1247| <<__split_lock_reenable>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1263| <<splitlock_cpu_offline>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1305| <<split_lock_warn>> sld_update_msr(false);
+	 *
+	 * MSR_TEST_CTRL is per core, but we treat it like a per CPU MSR. Locking
+	 * is not implemented as one thread could undo the setting of the other
+	 * thread immediately after dropping the lock anyway.
+	 */
 	/* Disable split lock detection on this CPU to make progress */
 	sld_update_msr(false);
 	put_cpu();
 }
 
+/*
+ * 在以下使用handle_guest_split_lock():
+ *   - arch/x86/kvm/vmx/vmx.c|5069| <<handle_exception_nmi(AC_VECTOR)>> if (handle_guest_split_lock(kvm_rip_read(vcpu)))
+ */
 bool handle_guest_split_lock(unsigned long ip)
 {
+	/*
+	 * 在以下使用sld_state:
+	 *   - arch/x86/kernel/cpu/intel.c|60| <<global>> static enum split_lock_detect_state sld_state __ro_after_init = sld_off;
+	 *   - arch/x86/kernel/cpu/intel.c|1100| <<sld_state_setup>> sld_state = state;
+	 *   - arch/x86/kernel/cpu/intel.c|1144| <<split_lock_init>> if (sld_state == sld_ratelimit) {
+	 *   - arch/x86/kernel/cpu/intel.c|1150| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+	 *   - arch/x86/kernel/cpu/intel.c|1222| <<handle_guest_split_lock>> if (sld_state == sld_warn) {
+	 *   - arch/x86/kernel/cpu/intel.c|1229| <<handle_guest_split_lock>> sld_state == sld_fatal ? "fatal" : "bogus", ip);
+	 *   - arch/x86/kernel/cpu/intel.c|1248| <<bus_lock_init>> (sld_state == sld_warn || sld_state == sld_fatal)) ||
+	 *   - arch/x86/kernel/cpu/intel.c|1249| <<bus_lock_init>> sld_state == sld_off) {
+	 *   - arch/x86/kernel/cpu/intel.c|1264| <<handle_user_split_lock>> if ((regs->flags & X86_EFLAGS_AC) || sld_state == sld_fatal)
+	 *   - arch/x86/kernel/cpu/intel.c|1272| <<handle_bus_lock>> switch (sld_state) {
+	 *   - arch/x86/kernel/cpu/intel.c|1355| <<sld_state_show>> switch (sld_state) {
+	 *
+	 * enum split_lock_detect_state {
+	 *     sld_off = 0,
+	 *     sld_warn,
+	 *     sld_fatal,
+	 *     sld_ratelimit,
+	 * };
+	 */
 	if (sld_state == sld_warn) {
+		/*
+		 * 在以下使用split_lock_warn():
+		 *   - arch/x86/kernel/cpu/intel.c|1219| <<handle_guest_split_lock>> split_lock_warn(ip);
+		 *   - arch/x86/kernel/cpu/intel.c|1262| <<handle_user_split_lock>> split_lock_warn(regs->ip);
+		 */
 		split_lock_warn(ip);
 		return true;
 	}
@@ -1240,6 +1582,32 @@ static void bus_lock_init(void)
 
 	rdmsrl(MSR_IA32_DEBUGCTLMSR, val);
 
+	/*
+	 * 在以下使用X86_FEATURE_SPLIT_LOCK_DETECT:
+	 *   - arch/x86/kernel/cpu/intel.c|1149| <<sld_state_setup>> if (!boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) &&
+	 *   - arch/x86/kernel/cpu/intel.c|1221| <<__split_lock_setup>> setup_force_cpu_cap(X86_FEATURE_SPLIT_LOCK_DETECT);
+	 *   - arch/x86/kernel/cpu/intel.c|1475| <<bus_lock_init>> if ((boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) &&
+	 *   - arch/x86/kernel/cpu/intel.c|1621| <<sld_state_show>> !boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 *   - arch/x86/kernel/cpu/intel.c|1643| <<sld_state_show>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1653| <<sld_state_show>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1657| <<sld_state_show>> boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) ?
+	 *   - arch/x86/kvm/vmx/vmx.c|4917| <<vmx_guest_inject_ac>> if (!boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 *   - arch/x86/kvm/x86.c|7297| <<emulator_cmpxchg_emulated>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 *
+	 *
+	 * 在以下使用sld_state:
+	 *   - arch/x86/kernel/cpu/intel.c|60| <<global>> static enum split_lock_detect_state sld_state __ro_after_init = sld_off;
+	 *   - arch/x86/kernel/cpu/intel.c|1100| <<sld_state_setup>> sld_state = state;
+	 *   - arch/x86/kernel/cpu/intel.c|1144| <<split_lock_init>> if (sld_state == sld_ratelimit) {
+	 *   - arch/x86/kernel/cpu/intel.c|1150| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+	 *   - arch/x86/kernel/cpu/intel.c|1222| <<handle_guest_split_lock>> if (sld_state == sld_warn) {
+	 *   - arch/x86/kernel/cpu/intel.c|1229| <<handle_guest_split_lock>> sld_state == sld_fatal ? "fatal" : "bogus", ip);
+	 *   - arch/x86/kernel/cpu/intel.c|1248| <<bus_lock_init>> (sld_state == sld_warn || sld_state == sld_fatal)) ||
+	 *   - arch/x86/kernel/cpu/intel.c|1249| <<bus_lock_init>> sld_state == sld_off) {
+	 *   - arch/x86/kernel/cpu/intel.c|1264| <<handle_user_split_lock>> if ((regs->flags & X86_EFLAGS_AC) || sld_state == sld_fatal)
+	 *   - arch/x86/kernel/cpu/intel.c|1272| <<handle_bus_lock>> switch (sld_state) {
+	 *   - arch/x86/kernel/cpu/intel.c|1355| <<sld_state_show>> switch (sld_state) {
+	 */
 	if ((boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) &&
 	    (sld_state == sld_warn || sld_state == sld_fatal)) ||
 	    sld_state == sld_off) {
@@ -1255,20 +1623,69 @@ static void bus_lock_init(void)
 	wrmsrl(MSR_IA32_DEBUGCTLMSR, val);
 }
 
+/*
+ * 在以下使用handle_user_split_lock():
+ *   - arch/x86/kernel/traps.c|305| <<DEFINE_IDTENTRY_ERRORCODE(exc_alignment_check)>> if (handle_user_split_lock(regs, error_code))
+ */
 bool handle_user_split_lock(struct pt_regs *regs, long error_code)
 {
+	/*
+	 * 在以下使用sld_state:
+	 *   - arch/x86/kernel/cpu/intel.c|60| <<global>> static enum split_lock_detect_state sld_state __ro_after_init = sld_off;
+	 *   - arch/x86/kernel/cpu/intel.c|1100| <<sld_state_setup>> sld_state = state;
+	 *   - arch/x86/kernel/cpu/intel.c|1144| <<split_lock_init>> if (sld_state == sld_ratelimit) {
+	 *   - arch/x86/kernel/cpu/intel.c|1150| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+	 *   - arch/x86/kernel/cpu/intel.c|1222| <<handle_guest_split_lock>> if (sld_state == sld_warn) {
+	 *   - arch/x86/kernel/cpu/intel.c|1229| <<handle_guest_split_lock>> sld_state == sld_fatal ? "fatal" : "bogus", ip);
+	 *   - arch/x86/kernel/cpu/intel.c|1248| <<bus_lock_init>> (sld_state == sld_warn || sld_state == sld_fatal)) ||
+	 *   - arch/x86/kernel/cpu/intel.c|1249| <<bus_lock_init>> sld_state == sld_off) {
+	 *   - arch/x86/kernel/cpu/intel.c|1264| <<handle_user_split_lock>> if ((regs->flags & X86_EFLAGS_AC) || sld_state == sld_fatal)
+	 *   - arch/x86/kernel/cpu/intel.c|1272| <<handle_bus_lock>> switch (sld_state) {
+	 *   - arch/x86/kernel/cpu/intel.c|1355| <<sld_state_show>> switch (sld_state) {
+	 */
 	if ((regs->flags & X86_EFLAGS_AC) || sld_state == sld_fatal)
 		return false;
+	/*
+	 * 在以下使用split_lock_warn():
+	 *   - arch/x86/kernel/cpu/intel.c|1219| <<handle_guest_split_lock>> split_lock_warn(ip);
+	 *   - arch/x86/kernel/cpu/intel.c|1262| <<handle_user_split_lock>> split_lock_warn(regs->ip);
+	 */
 	split_lock_warn(regs->ip);
 	return true;
 }
 
+/*
+ * 在以下调用handle_bus_lock():
+ *   - arch/x86/kernel/traps.c|1011| <<exc_debug_user>> handle_bus_lock(regs);
+ */
 void handle_bus_lock(struct pt_regs *regs)
 {
+	/*
+	 * 在以下使用sld_state:
+	 *   - arch/x86/kernel/cpu/intel.c|60| <<global>> static enum split_lock_detect_state sld_state __ro_after_init = sld_off;
+	 *   - arch/x86/kernel/cpu/intel.c|1100| <<sld_state_setup>> sld_state = state;
+	 *   - arch/x86/kernel/cpu/intel.c|1144| <<split_lock_init>> if (sld_state == sld_ratelimit) {
+	 *   - arch/x86/kernel/cpu/intel.c|1150| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+	 *   - arch/x86/kernel/cpu/intel.c|1222| <<handle_guest_split_lock>> if (sld_state == sld_warn) {
+	 *   - arch/x86/kernel/cpu/intel.c|1229| <<handle_guest_split_lock>> sld_state == sld_fatal ? "fatal" : "bogus", ip);
+	 *   - arch/x86/kernel/cpu/intel.c|1248| <<bus_lock_init>> (sld_state == sld_warn || sld_state == sld_fatal)) ||
+	 *   - arch/x86/kernel/cpu/intel.c|1249| <<bus_lock_init>> sld_state == sld_off) {
+	 *   - arch/x86/kernel/cpu/intel.c|1264| <<handle_user_split_lock>> if ((regs->flags & X86_EFLAGS_AC) || sld_state == sld_fatal)
+	 *   - arch/x86/kernel/cpu/intel.c|1272| <<handle_bus_lock>> switch (sld_state) {
+	 *   - arch/x86/kernel/cpu/intel.c|1355| <<sld_state_show>> switch (sld_state) {
+	 */
 	switch (sld_state) {
 	case sld_off:
 		break;
 	case sld_ratelimit:
+		/*
+		 * 在以下使用bld_ratelimit:
+		 *   - arch/x86/kernel/cpu/intel.c|1052| <<match_option>> ratelimit_state_init(&bld_ratelimit, HZ, ratelimit);
+		 *   - arch/x86/kernel/cpu/intel.c|1053| <<match_option>> ratelimit_set_flags(&bld_ratelimit, RATELIMIT_MSG_ON_RELEASE);
+		 *   - arch/x86/kernel/cpu/intel.c|1273| <<handle_bus_lock>> while (!__ratelimit(&bld_ratelimit))
+		 *   - arch/x86/kernel/cpu/intel.c|1376| <<sld_state_show>> pr_info("#DB: setting system wide bus lock rate limit to %u/sec\n",
+		 *                                             bld_ratelimit.burst);
+		 */
 		/* Enforce no more than bld_ratelimit bus locks/sec. */
 		while (!__ratelimit(&bld_ratelimit))
 			msleep(20);
@@ -1312,6 +1729,10 @@ static const struct x86_cpu_id split_lock_cpu_ids[] __initconst = {
 	{}
 };
 
+/*
+ * called by:
+ *   - arch/x86/kernel/cpu/intel.c|1774| <<sld_setup>> split_lock_setup(c);
+ */
 static void __init split_lock_setup(struct cpuinfo_x86 *c)
 {
 	const struct x86_cpu_id *m;
@@ -1338,16 +1759,49 @@ static void __init split_lock_setup(struct cpuinfo_x86 *c)
 		return;
 	}
 
+	/*
+	 * 在以下使用cpu_model_supports_sld:
+	 *   - arch/x86/kernel/cpu/intel.c|64| <<global>> static bool cpu_model_supports_sld __ro_after_init;
+	 *   - arch/x86/kernel/cpu/intel.c|1145| <<split_lock_init>> if (cpu_model_supports_sld)
+	 *   - arch/x86/kernel/cpu/intel.c|1341| <<split_lock_setup>> cpu_model_supports_sld = true;
+	 */
 	cpu_model_supports_sld = true;
 	__split_lock_setup();
 }
 
+/*
+ * called by:
+ *   - arch/x86/kernel/cpu/intel.c|1776| <<sld_setup>> sld_state_show();
+ *
+ * early_identify_cpu()
+ * -> sld_setup()
+ *    -> split_lock_setup() --> 检测支持吗: cpu_model_supports_sld
+ *    -> sld_state_setup()
+ *    -> sld_state_show()
+ */
 static void sld_state_show(void)
 {
 	if (!boot_cpu_has(X86_FEATURE_BUS_LOCK_DETECT) &&
 	    !boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
 		return;
 
+	/*
+	 * 在以下使用sld_state:
+	 *   - arch/x86/kernel/cpu/intel.c|60| <<global>> static enum split_lock_detect_state sld_state __ro_after_init = sld_off;
+	 *   - arch/x86/kernel/cpu/intel.c|1100| <<sld_state_setup>> sld_state = state;
+	 *   - arch/x86/kernel/cpu/intel.c|1144| <<split_lock_init>> if (sld_state == sld_ratelimit) {
+	 *   - arch/x86/kernel/cpu/intel.c|1150| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+	 *   - arch/x86/kernel/cpu/intel.c|1222| <<handle_guest_split_lock>> if (sld_state == sld_warn) {
+	 *   - arch/x86/kernel/cpu/intel.c|1229| <<handle_guest_split_lock>> sld_state == sld_fatal ? "fatal" : "bogus", ip);
+	 *   - arch/x86/kernel/cpu/intel.c|1248| <<bus_lock_init>> (sld_state == sld_warn || sld_state == sld_fatal)) ||
+	 *   - arch/x86/kernel/cpu/intel.c|1249| <<bus_lock_init>> sld_state == sld_off) {
+	 *   - arch/x86/kernel/cpu/intel.c|1264| <<handle_user_split_lock>> if ((regs->flags & X86_EFLAGS_AC) || sld_state == sld_fatal)
+	 *   - arch/x86/kernel/cpu/intel.c|1272| <<handle_bus_lock>> switch (sld_state) {
+	 *   - arch/x86/kernel/cpu/intel.c|1355| <<sld_state_show>> switch (sld_state) {
+	 *
+	 * 1025 #undef pr_fmt   
+	 * 1026 #define pr_fmt(fmt) "x86/split lock detection: " fmt
+	 */
 	switch (sld_state) {
 	case sld_off:
 		pr_info("disabled\n");
@@ -1372,12 +1826,28 @@ static void sld_state_show(void)
 		}
 		break;
 	case sld_ratelimit:
+		/*
+		 * // Intel-defined CPU features, CPUID level 0x00000007:0 (ECX), word 16
+		 * #define X86_FEATURE_BUS_LOCK_DETECT     (16*32+24) // Bus Lock detect
+		 *
+		 *
+		 * 在以下使用bld_ratelimit:
+		 *   - arch/x86/kernel/cpu/intel.c|1052| <<match_option>> ratelimit_state_init(&bld_ratelimit, HZ, ratelimit);
+		 *   - arch/x86/kernel/cpu/intel.c|1053| <<match_option>> ratelimit_set_flags(&bld_ratelimit, RATELIMIT_MSG_ON_RELEASE);
+		 *   - arch/x86/kernel/cpu/intel.c|1273| <<handle_bus_lock>> while (!__ratelimit(&bld_ratelimit))
+		 *   - arch/x86/kernel/cpu/intel.c|1376| <<sld_state_show>> pr_info("#DB: setting system wide bus lock rate limit to %u/sec\n",
+		 *                                             bld_ratelimit.burst);
+		 */
 		if (boot_cpu_has(X86_FEATURE_BUS_LOCK_DETECT))
 			pr_info("#DB: setting system wide bus lock rate limit to %u/sec\n", bld_ratelimit.burst);
 		break;
 	}
 }
 
+/*
+ * 在以下调用sld_setup():
+ *   - arch/x86/kernel/cpu/common.c|1604| <<early_identify_cpu>> sld_setup(c);
+ */
 void __init sld_setup(struct cpuinfo_x86 *c)
 {
 	split_lock_setup(c);
diff --git a/arch/x86/kvm/hyperv.c b/arch/x86/kvm/hyperv.c
index 1baaf481680d..c452903e20f9 100644
--- a/arch/x86/kvm/hyperv.c
+++ b/arch/x86/kvm/hyperv.c
@@ -88,6 +88,11 @@ static bool synic_has_vector_auto_eoi(struct kvm_vcpu_hv_synic *synic,
 	return false;
 }
 
+/*
+ * 在以下使用synic_update_vector():
+ *   - arch/x86/kvm/hyperv.c|166| <<synic_set_sint>> synic_update_vector(synic, old_vector);
+ *   - arch/x86/kvm/hyperv.c|168| <<synic_set_sint>> synic_update_vector(synic, vector);
+ */
 static void synic_update_vector(struct kvm_vcpu_hv_synic *synic,
 				int vector)
 {
@@ -125,6 +130,14 @@ static void synic_update_vector(struct kvm_vcpu_hv_synic *synic,
 	else
 		hv->synic_auto_eoi_used--;
 
+	/*
+	 * 在以下调用__kvm_set_or_clear_apicv_inhibit():
+	 *   - arch/x86/kvm/hyperv.c|132| <<synic_update_vector>> __kvm_set_or_clear_apicv_inhibit(vcpu->kvm,
+	 *          APICV_INHIBIT_REASON_HYPERV, !!hv->synic_auto_eoi_used);
+	 *   - arch/x86/kvm/x86.c|10434| <<kvm_set_or_clear_apicv_inhibit>> __kvm_set_or_clear_apicv_inhibit(kvm, reason, set);
+	 *   - arch/x86/kvm/x86.c|12032| <<kvm_arch_vcpu_guestdbg_update_apicv_inhibit>> __kvm_set_or_clear_apicv_inhibit(kvm,
+	 *          APICV_INHIBIT_REASON_BLOCKIRQ, set);
+	 */
 	/*
 	 * Inhibit APICv if any vCPU is using SynIC's AutoEOI, which relies on
 	 * the hypervisor to manually inject IRQs.
diff --git a/arch/x86/kvm/i8254.c b/arch/x86/kvm/i8254.c
index 043dd4af1848..de33901a68a8 100644
--- a/arch/x86/kvm/i8254.c
+++ b/arch/x86/kvm/i8254.c
@@ -311,6 +311,14 @@ void kvm_pit_set_reinject(struct kvm_pit *pit, bool reinject)
 		kvm_register_irq_ack_notifier(kvm, &ps->irq_ack_notifier);
 		kvm_register_irq_mask_notifier(kvm, 0, &pit->mask_notifier);
 	} else {
+		/*
+		 * 在以下使用kvm_clear_apicv_inhibit():
+		 *   - arch/x86/kvm/i8254.c|314| <<kvm_pit_set_reinject>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_PIT_REINJ);
+		 *   - arch/x86/kvm/lapic.c|579| <<kvm_recalculate_apic_map>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_APIC_ID_MODIFIED);
+		 *   - arch/x86/kvm/svm/svm.c|3235| <<interrupt_window_interception>> kvm_clear_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+		 *   - arch/x86/kvm/x86.c|6050| <<kvm_vm_ioctl_enable_cap(KVM_CAP_SPLIT_IRQCHIP)>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
+		 *   - arch/x86/kvm/x86.c|6465| <<kvm_arch_vm_ioctl(KVM_CREATE_IRQCHIP)>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
+		 */
 		kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_PIT_REINJ);
 		kvm_unregister_irq_ack_notifier(kvm, &ps->irq_ack_notifier);
 		kvm_unregister_irq_mask_notifier(kvm, 0, &pit->mask_notifier);
diff --git a/arch/x86/kvm/ioapic.c b/arch/x86/kvm/ioapic.c
index 4e0f52660842..4fde81e988cb 100644
--- a/arch/x86/kvm/ioapic.c
+++ b/arch/x86/kvm/ioapic.c
@@ -80,6 +80,20 @@ static unsigned long ioapic_read_indirect(struct kvm_ioapic *ioapic,
 				u32 index = array_index_nospec(
 					redir_index, IOAPIC_NUM_PINS);
 
+				/*
+				 * 在以下使用kvm_ioapic->redirtbl[IOAPIC_NUM_PINS]:
+				 *   - arch/x86/kvm/ioapic.c|83| <<ioapic_read_indirect>> redir_content = ioapic->redirtbl[index].bits;
+				 *   - arch/x86/kvm/ioapic.c|117| <<__rtc_irq_eoi_tracking_restore_one>> e = &ioapic->redirtbl[RTC_GSI];
+				 *   - arch/x86/kvm/ioapic.c|189| <<ioapic_lazy_update_eoi>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+				 *   - arch/x86/kvm/ioapic.c|215| <<ioapic_set_irq>> entry = ioapic->redirtbl[irq];
+				 *   - arch/x86/kvm/ioapic.c|294| <<kvm_ioapic_scan_entry>> e = &ioapic->redirtbl[index];
+				 *   - arch/x86/kvm/ioapic.c|343| <<ioapic_write_indirect>> e = &ioapic->redirtbl[index];
+				 *   - arch/x86/kvm/ioapic.c|415| <<ioapic_service>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+				 *   - arch/x86/kvm/ioapic.c|490| <<kvm_ioapic_eoi_inject_work>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+				 *   - arch/x86/kvm/ioapic.c|508| <<kvm_ioapic_update_eoi_one>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
+				 *   - arch/x86/kvm/ioapic.c|558| <<kvm_ioapic_update_eoi>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+				 *   - arch/x86/kvm/ioapic.c|670| <<kvm_ioapic_reset>> ioapic->redirtbl[i].fields.mask = 1;
+				 */
 				redir_content = ioapic->redirtbl[index].bits;
 			}
 
@@ -114,7 +128,40 @@ static void __rtc_irq_eoi_tracking_restore_one(struct kvm_vcpu *vcpu)
 	struct dest_map *dest_map = &ioapic->rtc_status.dest_map;
 	union kvm_ioapic_redirect_entry *e;
 
+	/*
+	 * 在以下使用kvm_ioapic->redirtbl[IOAPIC_NUM_PINS]:
+	 *   - arch/x86/kvm/ioapic.c|83| <<ioapic_read_indirect>> redir_content = ioapic->redirtbl[index].bits;
+	 *   - arch/x86/kvm/ioapic.c|117| <<__rtc_irq_eoi_tracking_restore_one>> e = &ioapic->redirtbl[RTC_GSI];
+	 *   - arch/x86/kvm/ioapic.c|189| <<ioapic_lazy_update_eoi>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|215| <<ioapic_set_irq>> entry = ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|294| <<kvm_ioapic_scan_entry>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|343| <<ioapic_write_indirect>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|415| <<ioapic_service>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|490| <<kvm_ioapic_eoi_inject_work>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|508| <<kvm_ioapic_update_eoi_one>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
+	 *   - arch/x86/kvm/ioapic.c|558| <<kvm_ioapic_update_eoi>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|670| <<kvm_ioapic_reset>> ioapic->redirtbl[i].fields.mask = 1;
+	 */
 	e = &ioapic->redirtbl[RTC_GSI];
+	/*
+	 * 在以下调用kvm_apic_match_dest():
+	 *   - arch/x86/kvm/ioapic.c|146| <<__rtc_irq_eoi_tracking_restore_one>> if (!kvm_apic_match_dest(vcpu, NULL,
+	 *          APIC_DEST_NOSHORT, e->fields.dest_id, kvm_lapic_irq_dest_mode(!!e->fields.dest_mode)))
+	 *   - arch/x86/kvm/ioapic.c|234| <<ioapic_lazy_update_eoi>> if (!kvm_apic_match_dest(vcpu, NULL,
+	 *          APIC_DEST_NOSHORT, entry->fields.dest_id, entry->fields.dest_mode) ||
+	 *   - arch/x86/kvm/ioapic.c|414| <<kvm_ioapic_scan_entry>> if (kvm_apic_match_dest(vcpu, NULL,
+	 *          APIC_DEST_NOSHORT, e->fields.dest_id, dm) ||
+	 *   - arch/x86/kvm/irq_comm.c|68| <<kvm_irq_delivery_to_apic>> if (!kvm_apic_match_dest(vcpu, src,
+	 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+	 *   - arch/x86/kvm/irq_comm.c|359| <<kvm_intr_is_single_vcpu>> if (!kvm_apic_match_dest(vcpu, NULL,
+	 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+	 *   - arch/x86/kvm/irq_comm.c|442| <<kvm_scan_ioapic_routes>> if (irq.trig_mode && (kvm_apic_match_dest(vcpu, NULL,
+	 *          APIC_DEST_NOSHORT, irq.dest_id, irq.dest_mode) ||
+	 *   - arch/x86/kvm/lapic.c|1262| <<kvm_bitmap_or_dest_vcpus>> if (!kvm_apic_match_dest(vcpu, NULL,
+	 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+	 *   - arch/x86/kvm/svm/avic.c|461| <<avic_kick_target_vcpus>> if (kvm_apic_match_dest(vcpu, source,
+	 *          icrl & APIC_SHORT_MASK, dest, icrl & APIC_DEST_MASK)) {
+	 */
 	if (!kvm_apic_match_dest(vcpu, NULL, APIC_DEST_NOSHORT,
 				 e->fields.dest_id,
 				 kvm_lapic_irq_dest_mode(!!e->fields.dest_mode)))
@@ -186,9 +233,42 @@ static void ioapic_lazy_update_eoi(struct kvm_ioapic *ioapic, int irq)
 {
 	int i;
 	struct kvm_vcpu *vcpu;
+	/*
+	 * 在以下使用kvm_ioapic->redirtbl[IOAPIC_NUM_PINS]:
+	 *   - arch/x86/kvm/ioapic.c|83| <<ioapic_read_indirect>> redir_content = ioapic->redirtbl[index].bits;
+	 *   - arch/x86/kvm/ioapic.c|117| <<__rtc_irq_eoi_tracking_restore_one>> e = &ioapic->redirtbl[RTC_GSI];
+	 *   - arch/x86/kvm/ioapic.c|189| <<ioapic_lazy_update_eoi>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|215| <<ioapic_set_irq>> entry = ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|294| <<kvm_ioapic_scan_entry>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|343| <<ioapic_write_indirect>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|415| <<ioapic_service>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|490| <<kvm_ioapic_eoi_inject_work>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|508| <<kvm_ioapic_update_eoi_one>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
+	 *   - arch/x86/kvm/ioapic.c|558| <<kvm_ioapic_update_eoi>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|670| <<kvm_ioapic_reset>> ioapic->redirtbl[i].fields.mask = 1;
+	 */
 	union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
 
 	kvm_for_each_vcpu(i, vcpu, ioapic->kvm) {
+		/*
+		 * 在以下调用kvm_apic_match_dest():
+		 *   - arch/x86/kvm/ioapic.c|146| <<__rtc_irq_eoi_tracking_restore_one>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, e->fields.dest_id, kvm_lapic_irq_dest_mode(!!e->fields.dest_mode)))
+		 *   - arch/x86/kvm/ioapic.c|234| <<ioapic_lazy_update_eoi>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, entry->fields.dest_id, entry->fields.dest_mode) ||
+		 *   - arch/x86/kvm/ioapic.c|414| <<kvm_ioapic_scan_entry>> if (kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, e->fields.dest_id, dm) ||
+		 *   - arch/x86/kvm/irq_comm.c|68| <<kvm_irq_delivery_to_apic>> if (!kvm_apic_match_dest(vcpu, src,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/irq_comm.c|359| <<kvm_intr_is_single_vcpu>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/irq_comm.c|442| <<kvm_scan_ioapic_routes>> if (irq.trig_mode && (kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, irq.dest_id, irq.dest_mode) ||
+		 *   - arch/x86/kvm/lapic.c|1262| <<kvm_bitmap_or_dest_vcpus>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/svm/avic.c|461| <<avic_kick_target_vcpus>> if (kvm_apic_match_dest(vcpu, source,
+		 *          icrl & APIC_SHORT_MASK, dest, icrl & APIC_DEST_MASK)) {
+		 */
 		if (!kvm_apic_match_dest(vcpu, NULL, APIC_DEST_NOSHORT,
 					 entry->fields.dest_id,
 					 entry->fields.dest_mode) ||
@@ -212,6 +292,20 @@ static int ioapic_set_irq(struct kvm_ioapic *ioapic, unsigned int irq,
 	u32 old_irr;
 	int edge, ret;
 
+	/*
+	 * 在以下使用kvm_ioapic->redirtbl[IOAPIC_NUM_PINS]:
+	 *   - arch/x86/kvm/ioapic.c|83| <<ioapic_read_indirect>> redir_content = ioapic->redirtbl[index].bits;
+	 *   - arch/x86/kvm/ioapic.c|117| <<__rtc_irq_eoi_tracking_restore_one>> e = &ioapic->redirtbl[RTC_GSI];
+	 *   - arch/x86/kvm/ioapic.c|189| <<ioapic_lazy_update_eoi>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|215| <<ioapic_set_irq>> entry = ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|294| <<kvm_ioapic_scan_entry>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|343| <<ioapic_write_indirect>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|415| <<ioapic_service>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|490| <<kvm_ioapic_eoi_inject_work>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|508| <<kvm_ioapic_update_eoi_one>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
+	 *   - arch/x86/kvm/ioapic.c|558| <<kvm_ioapic_update_eoi>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|670| <<kvm_ioapic_reset>> ioapic->redirtbl[i].fields.mask = 1;
+	 */
 	entry = ioapic->redirtbl[irq];
 	edge = (entry.fields.trig_mode == IOAPIC_EDGE_TRIG);
 
@@ -276,6 +370,10 @@ static void kvm_ioapic_inject_all(struct kvm_ioapic *ioapic, unsigned long irr)
 }
 
 
+/*
+ * 在以下使用kvm_ioapic_scan_entry():
+ *   - arch/x86/kvm/x86.c|9917| <<vcpu_scan_ioapic>> kvm_ioapic_scan_entry(vcpu, vcpu->arch.ioapic_handled_vectors);
+ */
 void kvm_ioapic_scan_entry(struct kvm_vcpu *vcpu, ulong *ioapic_handled_vectors)
 {
 	struct kvm_ioapic *ioapic = vcpu->kvm->arch.vioapic;
@@ -285,18 +383,97 @@ void kvm_ioapic_scan_entry(struct kvm_vcpu *vcpu, ulong *ioapic_handled_vectors)
 
 	spin_lock(&ioapic->lock);
 
+	/*
+	 * struct dest_map {
+	 * map = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
+	 * 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
+	 * 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},
+	 *
+	 * 第一次设置的地方
+	 * 看着似乎rtc_statu的bit都是空
+	 */
 	/* Make sure we see any missing RTC EOI */
 	if (test_bit(vcpu->vcpu_id, dest_map->map))
 		__set_bit(dest_map->vectors[vcpu->vcpu_id],
 			  ioapic_handled_vectors);
 
+	/*
+	 * union kvm_ioapic_redirect_entry {
+	 *     bits = 144115188075888682,
+	 *     fields = {
+	 *       vector = 42 '*',
+	 *       delivery_mode = 0 '\000',
+	 *       dest_mode = 0 '\000',
+	 *       delivery_status = 0 '\000',
+	 *       polarity = 0 '\000',
+	 *       remote_irr = 0 '\000',
+	 *       trig_mode = 1 '\001',
+	 *       mask = 0 '\000',
+	 *       reserve = 0 '\000',
+	 *       reserved = "\000\000\000",
+	 *       dest_id = 2 '\002'
+	 *     }
+	 *  }
+	 *
+	 * 57 union kvm_ioapic_redirect_entry {
+	 * 58         u64 bits;
+	 * 59         struct {
+	 * 60                 u8 vector;
+	 * 61                 u8 delivery_mode:3;
+	 * 62                 u8 dest_mode:1;
+	 * 63                 u8 delivery_status:1;
+	 * 64                 u8 polarity:1;
+	 * 65                 u8 remote_irr:1;
+	 * 66                 u8 trig_mode:1;
+	 * 67                 u8 mask:1;
+	 * 68                 u8 reserve:7;
+	 * 69                 u8 reserved[4];
+	 * 70                 u8 dest_id;
+	 * 71         } fields;
+	 * 72 };
+	 */
 	for (index = 0; index < IOAPIC_NUM_PINS; index++) {
+		/*
+		 * 在以下使用kvm_ioapic->redirtbl[IOAPIC_NUM_PINS]:
+		 *   - arch/x86/kvm/ioapic.c|83| <<ioapic_read_indirect>> redir_content = ioapic->redirtbl[index].bits;
+		 *   - arch/x86/kvm/ioapic.c|117| <<__rtc_irq_eoi_tracking_restore_one>> e = &ioapic->redirtbl[RTC_GSI];
+		 *   - arch/x86/kvm/ioapic.c|189| <<ioapic_lazy_update_eoi>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+		 *   - arch/x86/kvm/ioapic.c|215| <<ioapic_set_irq>> entry = ioapic->redirtbl[irq];
+		 *   - arch/x86/kvm/ioapic.c|294| <<kvm_ioapic_scan_entry>> e = &ioapic->redirtbl[index];
+		 *   - arch/x86/kvm/ioapic.c|343| <<ioapic_write_indirect>> e = &ioapic->redirtbl[index];
+		 *   - arch/x86/kvm/ioapic.c|415| <<ioapic_service>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+		 *   - arch/x86/kvm/ioapic.c|490| <<kvm_ioapic_eoi_inject_work>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+		 *   - arch/x86/kvm/ioapic.c|508| <<kvm_ioapic_update_eoi_one>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
+		 *   - arch/x86/kvm/ioapic.c|558| <<kvm_ioapic_update_eoi>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+		 *   - arch/x86/kvm/ioapic.c|670| <<kvm_ioapic_reset>> ioapic->redirtbl[i].fields.mask = 1;
+		 *
+		 * 只在这里一个地方使用kvm_irq_has_notifier(), 返回false的概率大
+		 */
 		e = &ioapic->redirtbl[index];
 		if (e->fields.trig_mode == IOAPIC_LEVEL_TRIG ||
 		    kvm_irq_has_notifier(ioapic->kvm, KVM_IRQCHIP_IOAPIC, index) ||
 		    index == RTC_GSI) {
 			u16 dm = kvm_lapic_irq_dest_mode(!!e->fields.dest_mode);
 
+			/*
+			 * 在以下调用kvm_apic_match_dest():
+			 *   - arch/x86/kvm/ioapic.c|146| <<__rtc_irq_eoi_tracking_restore_one>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, e->fields.dest_id, kvm_lapic_irq_dest_mode(!!e->fields.dest_mode)))
+			 *   - arch/x86/kvm/ioapic.c|234| <<ioapic_lazy_update_eoi>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, entry->fields.dest_id, entry->fields.dest_mode) ||
+			 *   - arch/x86/kvm/ioapic.c|414| <<kvm_ioapic_scan_entry>> if (kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, e->fields.dest_id, dm) ||
+			 *   - arch/x86/kvm/irq_comm.c|68| <<kvm_irq_delivery_to_apic>> if (!kvm_apic_match_dest(vcpu, src,
+			 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+			 *   - arch/x86/kvm/irq_comm.c|359| <<kvm_intr_is_single_vcpu>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+			 *   - arch/x86/kvm/irq_comm.c|442| <<kvm_scan_ioapic_routes>> if (irq.trig_mode && (kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, irq.dest_id, irq.dest_mode) ||
+			 *   - arch/x86/kvm/lapic.c|1262| <<kvm_bitmap_or_dest_vcpus>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+			 *   - arch/x86/kvm/svm/avic.c|461| <<avic_kick_target_vcpus>> if (kvm_apic_match_dest(vcpu, source,
+			 *          icrl & APIC_SHORT_MASK, dest, icrl & APIC_DEST_MASK)) {
+			 */
 			if (kvm_apic_match_dest(vcpu, NULL, APIC_DEST_NOSHORT,
 						e->fields.dest_id, dm) ||
 			    kvm_apic_pending_eoi(vcpu, e->fields.vector))
@@ -314,6 +491,10 @@ void kvm_arch_post_irq_ack_notifier_list_update(struct kvm *kvm)
 	kvm_make_scan_ioapic_request(kvm);
 }
 
+/*
+ * 在以下使用ioapic_write_indirect():
+ *   - arch/x86/kvm/ioapic.c|907| <<ioapic_mmio_write>> ioapic_write_indirect(ioapic, data);
+ */
 static void ioapic_write_indirect(struct kvm_ioapic *ioapic, u32 val)
 {
 	unsigned index;
@@ -340,6 +521,24 @@ static void ioapic_write_indirect(struct kvm_ioapic *ioapic, u32 val)
 		if (index >= IOAPIC_NUM_PINS)
 			return;
 		index = array_index_nospec(index, IOAPIC_NUM_PINS);
+		/*
+		 * union kvm_ioapic_redirect_entry {
+		 *     u64 bits;
+		 *     struct {
+		 *         u8 vector;
+		 *         u8 delivery_mode:3;
+		 *         u8 dest_mode:1;
+		 *         u8 delivery_status:1;
+		 *         u8 polarity:1;
+		 *         u8 remote_irr:1;
+		 *         u8 trig_mode:1;
+		 *         u8 mask:1;
+		 *         u8 reserve:7;
+		 *         u8 reserved[4];
+		 *         u8 dest_id;
+		 *      } fields;
+		 * };
+		 */
 		e = &ioapic->redirtbl[index];
 		mask_before = e->fields.mask;
 		/* Preserve read-only fields */
@@ -347,6 +546,9 @@ static void ioapic_write_indirect(struct kvm_ioapic *ioapic, u32 val)
 		old_delivery_status = e->fields.delivery_status;
 		old_dest_id = e->fields.dest_id;
 		old_dest_mode = e->fields.dest_mode;
+		/*
+		 * 主要在这里修改!
+		 */
 		if (ioapic->ioregsel & 1) {
 			e->bits &= 0xffffffff;
 			e->bits |= (u64) val << 32;
@@ -410,8 +612,35 @@ static void ioapic_write_indirect(struct kvm_ioapic *ioapic, u32 val)
 	}
 }
 
+/*
+ * hot-add和hot-del都调用
+ *
+ * ioapic_service
+ * ioapic_set_irq
+ * kvm_ioapic_set_irq
+ * kvm_set_irq
+ * kvm_vm_ioctl_irq_line
+ * kvm_vm_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ */
 static int ioapic_service(struct kvm_ioapic *ioapic, int irq, bool line_status)
 {
+	/*
+	 * 在以下使用kvm_ioapic->redirtbl[IOAPIC_NUM_PINS]:
+	 *   - arch/x86/kvm/ioapic.c|83| <<ioapic_read_indirect>> redir_content = ioapic->redirtbl[index].bits;
+	 *   - arch/x86/kvm/ioapic.c|117| <<__rtc_irq_eoi_tracking_restore_one>> e = &ioapic->redirtbl[RTC_GSI];
+	 *   - arch/x86/kvm/ioapic.c|189| <<ioapic_lazy_update_eoi>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|215| <<ioapic_set_irq>> entry = ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|294| <<kvm_ioapic_scan_entry>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|343| <<ioapic_write_indirect>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|415| <<ioapic_service>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|490| <<kvm_ioapic_eoi_inject_work>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|508| <<kvm_ioapic_update_eoi_one>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
+	 *   - arch/x86/kvm/ioapic.c|558| <<kvm_ioapic_update_eoi>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|670| <<kvm_ioapic_reset>> ioapic->redirtbl[i].fields.mask = 1;
+	 */
 	union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
 	struct kvm_lapic_irq irqe;
 	int ret;
@@ -487,6 +716,20 @@ static void kvm_ioapic_eoi_inject_work(struct work_struct *work)
 						 eoi_inject.work);
 	spin_lock(&ioapic->lock);
 	for (i = 0; i < IOAPIC_NUM_PINS; i++) {
+		/*
+		 * 在以下使用kvm_ioapic->redirtbl[IOAPIC_NUM_PINS]:
+		 *   - arch/x86/kvm/ioapic.c|83| <<ioapic_read_indirect>> redir_content = ioapic->redirtbl[index].bits;
+		 *   - arch/x86/kvm/ioapic.c|117| <<__rtc_irq_eoi_tracking_restore_one>> e = &ioapic->redirtbl[RTC_GSI];
+		 *   - arch/x86/kvm/ioapic.c|189| <<ioapic_lazy_update_eoi>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+		 *   - arch/x86/kvm/ioapic.c|215| <<ioapic_set_irq>> entry = ioapic->redirtbl[irq];
+		 *   - arch/x86/kvm/ioapic.c|294| <<kvm_ioapic_scan_entry>> e = &ioapic->redirtbl[index];
+		 *   - arch/x86/kvm/ioapic.c|343| <<ioapic_write_indirect>> e = &ioapic->redirtbl[index];
+		 *   - arch/x86/kvm/ioapic.c|415| <<ioapic_service>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+		 *   - arch/x86/kvm/ioapic.c|490| <<kvm_ioapic_eoi_inject_work>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+		 *   - arch/x86/kvm/ioapic.c|508| <<kvm_ioapic_update_eoi_one>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
+		 *   - arch/x86/kvm/ioapic.c|558| <<kvm_ioapic_update_eoi>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+		 *   - arch/x86/kvm/ioapic.c|670| <<kvm_ioapic_reset>> ioapic->redirtbl[i].fields.mask = 1;
+		 */
 		union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
 
 		if (ent->fields.trig_mode != IOAPIC_LEVEL_TRIG)
@@ -499,12 +742,39 @@ static void kvm_ioapic_eoi_inject_work(struct work_struct *work)
 }
 
 #define IOAPIC_SUCCESSIVE_IRQ_MAX_COUNT 10000
+/*
+ * kvm_ioapic_update_eoi
+ * kvm_apic_set_eoi_accelerated
+ * handle_apic_eoi_induced
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ */
 static void kvm_ioapic_update_eoi_one(struct kvm_vcpu *vcpu,
 				      struct kvm_ioapic *ioapic,
 				      int trigger_mode,
 				      int pin)
 {
 	struct kvm_lapic *apic = vcpu->arch.apic;
+	/*
+	 * 在以下使用kvm_ioapic->redirtbl[IOAPIC_NUM_PINS]:
+	 *   - arch/x86/kvm/ioapic.c|83| <<ioapic_read_indirect>> redir_content = ioapic->redirtbl[index].bits;
+	 *   - arch/x86/kvm/ioapic.c|117| <<__rtc_irq_eoi_tracking_restore_one>> e = &ioapic->redirtbl[RTC_GSI];
+	 *   - arch/x86/kvm/ioapic.c|189| <<ioapic_lazy_update_eoi>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|215| <<ioapic_set_irq>> entry = ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|294| <<kvm_ioapic_scan_entry>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|343| <<ioapic_write_indirect>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|415| <<ioapic_service>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|490| <<kvm_ioapic_eoi_inject_work>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|508| <<kvm_ioapic_update_eoi_one>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
+	 *   - arch/x86/kvm/ioapic.c|558| <<kvm_ioapic_update_eoi>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|670| <<kvm_ioapic_reset>> ioapic->redirtbl[i].fields.mask = 1;
+	 */
 	union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
 
 	/*
@@ -547,6 +817,22 @@ static void kvm_ioapic_update_eoi_one(struct kvm_vcpu *vcpu,
 	}
 }
 
+/*
+ * kvm_ioapic_update_eoi
+ * kvm_apic_set_eoi_accelerated
+ * handle_apic_eoi_induced
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * 在以下使用kvm_ioapic_update_eoi():
+ *   - arch/x86/kvm/lapic.c|2113| <<kvm_ioapic_send_eoi>> kvm_ioapic_update_eoi(apic->vcpu, vector, trigger_mode);
+ */
 void kvm_ioapic_update_eoi(struct kvm_vcpu *vcpu, int vector, int trigger_mode)
 {
 	int i;
@@ -555,6 +841,20 @@ void kvm_ioapic_update_eoi(struct kvm_vcpu *vcpu, int vector, int trigger_mode)
 	spin_lock(&ioapic->lock);
 	rtc_irq_eoi(ioapic, vcpu, vector);
 	for (i = 0; i < IOAPIC_NUM_PINS; i++) {
+		/*
+		 * 在以下使用kvm_ioapic->redirtbl[IOAPIC_NUM_PINS]:
+		 *   - arch/x86/kvm/ioapic.c|83| <<ioapic_read_indirect>> redir_content = ioapic->redirtbl[index].bits;
+		 *   - arch/x86/kvm/ioapic.c|117| <<__rtc_irq_eoi_tracking_restore_one>> e = &ioapic->redirtbl[RTC_GSI];
+		 *   - arch/x86/kvm/ioapic.c|189| <<ioapic_lazy_update_eoi>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+		 *   - arch/x86/kvm/ioapic.c|215| <<ioapic_set_irq>> entry = ioapic->redirtbl[irq];
+		 *   - arch/x86/kvm/ioapic.c|294| <<kvm_ioapic_scan_entry>> e = &ioapic->redirtbl[index];
+		 *   - arch/x86/kvm/ioapic.c|343| <<ioapic_write_indirect>> e = &ioapic->redirtbl[index];
+		 *   - arch/x86/kvm/ioapic.c|415| <<ioapic_service>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+		 *   - arch/x86/kvm/ioapic.c|490| <<kvm_ioapic_eoi_inject_work>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+		 *   - arch/x86/kvm/ioapic.c|508| <<kvm_ioapic_update_eoi_one>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
+		 *   - arch/x86/kvm/ioapic.c|558| <<kvm_ioapic_update_eoi>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+		 *   - arch/x86/kvm/ioapic.c|670| <<kvm_ioapic_reset>> ioapic->redirtbl[i].fields.mask = 1;
+		 */
 		union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
 
 		if (ent->fields.vector != vector)
@@ -666,6 +966,20 @@ static void kvm_ioapic_reset(struct kvm_ioapic *ioapic)
 	int i;
 
 	cancel_delayed_work_sync(&ioapic->eoi_inject);
+	/*
+	 * 在以下使用kvm_ioapic->redirtbl[IOAPIC_NUM_PINS]:
+	 *   - arch/x86/kvm/ioapic.c|83| <<ioapic_read_indirect>> redir_content = ioapic->redirtbl[index].bits;
+	 *   - arch/x86/kvm/ioapic.c|117| <<__rtc_irq_eoi_tracking_restore_one>> e = &ioapic->redirtbl[RTC_GSI];
+	 *   - arch/x86/kvm/ioapic.c|189| <<ioapic_lazy_update_eoi>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|215| <<ioapic_set_irq>> entry = ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|294| <<kvm_ioapic_scan_entry>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|343| <<ioapic_write_indirect>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|415| <<ioapic_service>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|490| <<kvm_ioapic_eoi_inject_work>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|508| <<kvm_ioapic_update_eoi_one>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
+	 *   - arch/x86/kvm/ioapic.c|558| <<kvm_ioapic_update_eoi>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|670| <<kvm_ioapic_reset>> ioapic->redirtbl[i].fields.mask = 1;
+	 */
 	for (i = 0; i < IOAPIC_NUM_PINS; i++)
 		ioapic->redirtbl[i].fields.mask = 1;
 	ioapic->base_address = IOAPIC_DEFAULT_BASE_ADDRESS;
diff --git a/arch/x86/kvm/ioapic.h b/arch/x86/kvm/ioapic.h
index f1b2b2a6ff4d..ac3cbdd17bcf 100644
--- a/arch/x86/kvm/ioapic.h
+++ b/arch/x86/kvm/ioapic.h
@@ -77,6 +77,20 @@ struct kvm_ioapic {
 	u32 id;
 	u32 irr;
 	u32 pad;
+	/*
+	 * 在以下使用kvm_ioapic->redirtbl[IOAPIC_NUM_PINS]:
+	 *   - arch/x86/kvm/ioapic.c|83| <<ioapic_read_indirect>> redir_content = ioapic->redirtbl[index].bits;
+	 *   - arch/x86/kvm/ioapic.c|117| <<__rtc_irq_eoi_tracking_restore_one>> e = &ioapic->redirtbl[RTC_GSI];
+	 *   - arch/x86/kvm/ioapic.c|189| <<ioapic_lazy_update_eoi>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|215| <<ioapic_set_irq>> entry = ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|294| <<kvm_ioapic_scan_entry>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|343| <<ioapic_write_indirect>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|415| <<ioapic_service>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|490| <<kvm_ioapic_eoi_inject_work>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|508| <<kvm_ioapic_update_eoi_one>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
+	 *   - arch/x86/kvm/ioapic.c|558| <<kvm_ioapic_update_eoi>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|670| <<kvm_ioapic_reset>> ioapic->redirtbl[i].fields.mask = 1;
+	 */
 	union kvm_ioapic_redirect_entry redirtbl[IOAPIC_NUM_PINS];
 	unsigned long irq_states[IOAPIC_NUM_PINS];
 	struct kvm_io_device dev;
diff --git a/arch/x86/kvm/irq.c b/arch/x86/kvm/irq.c
index 172b05343cfd..007aa9b96d5e 100644
--- a/arch/x86/kvm/irq.c
+++ b/arch/x86/kvm/irq.c
@@ -41,6 +41,16 @@ static int pending_userspace_extint(struct kvm_vcpu *v)
  * check if there is pending interrupt from
  * non-APIC source without intack.
  */
+/*
+ * 在以下调用kvm_cpu_has_extint():
+ *   - arch/x86/kvm/irq.c|86| <<kvm_cpu_has_injectable_intr>> if (kvm_cpu_has_extint(v))
+ *   - arch/x86/kvm/irq.c|115| <<kvm_cpu_has_interrupt>> if (kvm_cpu_has_extint(v))
+ *   - arch/x86/kvm/irq.c|135| <<kvm_cpu_get_extint>> if (!kvm_cpu_has_extint(v)) {
+ *   - arch/x86/kvm/x86.c|4850| <<kvm_cpu_accept_dm_intr>> if (kvm_cpu_has_extint(vcpu))
+ *
+ * check if there is pending interrupt from
+ * non-APIC source without intack.
+ */
 int kvm_cpu_has_extint(struct kvm_vcpu *v)
 {
 	/*
@@ -63,6 +73,11 @@ int kvm_cpu_has_extint(struct kvm_vcpu *v)
 	if (!kvm_apic_accept_pic_intr(v))
 		return 0;
 
+	/*
+	 * on: KVM模拟全部
+	 * split: QEMU模拟IOAPIC和PIC,KVM模拟LAPIC
+	 * off:QEMU 模拟全部
+	 */
 	if (irqchip_split(v->kvm))
 		return pending_userspace_extint(v);
 	else
@@ -75,14 +90,39 @@ int kvm_cpu_has_extint(struct kvm_vcpu *v)
  * interrupt from apic will handled by hardware,
  * we don't need to check it here.
  */
+/*
+ * 在以下使用kvm_cpu_has_injectable_intr():
+ *   - arch/x86/kvm/svm/svm.c|2448| <<svm_set_gif>> kvm_cpu_has_injectable_intr(&svm->vcpu))
+ *   - arch/x86/kvm/x86.c|9412| <<inject_pending_event>> if (kvm_cpu_has_injectable_intr(vcpu)) {
+ *   - arch/x86/kvm/x86.c|9425| <<inject_pending_event>> if (kvm_cpu_has_injectable_intr(vcpu))
+ */
 int kvm_cpu_has_injectable_intr(struct kvm_vcpu *v)
 {
+	/*
+	 * 在以下调用kvm_cpu_has_extint():
+	 *   - arch/x86/kvm/irq.c|86| <<kvm_cpu_has_injectable_intr>> if (kvm_cpu_has_extint(v))
+	 *   - arch/x86/kvm/irq.c|115| <<kvm_cpu_has_interrupt>> if (kvm_cpu_has_extint(v))
+	 *   - arch/x86/kvm/irq.c|135| <<kvm_cpu_get_extint>> if (!kvm_cpu_has_extint(v)) {
+	 *   - arch/x86/kvm/x86.c|4850| <<kvm_cpu_accept_dm_intr>> if (kvm_cpu_has_extint(vcpu))
+	 *
+	 * check if there is pending interrupt from
+	 * non-APIC source without intack.
+	 */
 	if (kvm_cpu_has_extint(v))
 		return 1;
 
 	if (!is_guest_mode(v) && kvm_vcpu_apicv_active(v))
 		return 0;
 
+	/*
+	 * 在以下使用kvm_apic_has_interrupt():
+	 *   - arch/x86/kvm/irq.c|86| <<kvm_cpu_has_injectable_intr>> return kvm_apic_has_interrupt(v) != -1;
+	 *   - arch/x86/kvm/irq.c|99| <<kvm_cpu_has_interrupt>> return kvm_apic_has_interrupt(v) != -1;
+	 *   - arch/x86/kvm/lapic.c|2841| <<kvm_get_apic_interrupt>> int vector = kvm_apic_has_interrupt(vcpu);
+	 *   - arch/x86/kvm/vmx/nested.c|3627| <<nested_vmx_run>> kvm_apic_has_interrupt(vcpu) == vmx->nested.posted_intr_nv) {
+	 *
+	 * 似乎选出最大的irr, 不选isr
+	 */
 	return kvm_apic_has_interrupt(v) != -1; /* LAPIC */
 }
 EXPORT_SYMBOL_GPL(kvm_cpu_has_injectable_intr);
@@ -91,11 +131,34 @@ EXPORT_SYMBOL_GPL(kvm_cpu_has_injectable_intr);
  * check if there is pending interrupt without
  * intack.
  */
+/*
+ * 在以下使用kvm_cpu_has_interrupt():
+ *   - arch/x86/kvm/svm/nested.c|1334| <<svm_check_nested_events>> if (kvm_cpu_has_interrupt(vcpu) && !svm_interrupt_blocked(vcpu)) {
+ *   - arch/x86/kvm/vmx/nested.c|4021| <<vmx_check_nested_events>> if (kvm_cpu_has_interrupt(vcpu) && !vmx_interrupt_blocked(vcpu)) {
+ *   - arch/x86/kvm/x86.c|12828| <<kvm_vcpu_has_events>> (kvm_cpu_has_interrupt(vcpu) ||
+ */
 int kvm_cpu_has_interrupt(struct kvm_vcpu *v)
 {
+	/*
+	 * 在以下调用kvm_cpu_has_extint():
+	 *   - arch/x86/kvm/irq.c|86| <<kvm_cpu_has_injectable_intr>> if (kvm_cpu_has_extint(v))
+	 *   - arch/x86/kvm/irq.c|115| <<kvm_cpu_has_interrupt>> if (kvm_cpu_has_extint(v))
+	 *   - arch/x86/kvm/irq.c|135| <<kvm_cpu_get_extint>> if (!kvm_cpu_has_extint(v)) {
+	 *   - arch/x86/kvm/x86.c|4850| <<kvm_cpu_accept_dm_intr>> if (kvm_cpu_has_extint(vcpu))
+	 *
+	 * check if there is pending interrupt from
+	 * non-APIC source without intack.
+	 */
 	if (kvm_cpu_has_extint(v))
 		return 1;
 
+	/*
+	 * 在以下使用kvm_apic_has_interrupt():
+	 *   - arch/x86/kvm/irq.c|86| <<kvm_cpu_has_injectable_intr>> return kvm_apic_has_interrupt(v) != -1;
+	 *   - arch/x86/kvm/irq.c|99| <<kvm_cpu_has_interrupt>> return kvm_apic_has_interrupt(v) != -1;
+	 *   - arch/x86/kvm/lapic.c|2841| <<kvm_get_apic_interrupt>> int vector = kvm_apic_has_interrupt(vcpu);
+	 *   - arch/x86/kvm/vmx/nested.c|3627| <<nested_vmx_run>> kvm_apic_has_interrupt(vcpu) == vmx->nested.posted_intr_nv) {
+	 */
 	return kvm_apic_has_interrupt(v) != -1;	/* LAPIC */
 }
 EXPORT_SYMBOL_GPL(kvm_cpu_has_interrupt);
@@ -106,6 +169,16 @@ EXPORT_SYMBOL_GPL(kvm_cpu_has_interrupt);
  */
 static int kvm_cpu_get_extint(struct kvm_vcpu *v)
 {
+	/*
+	 * 在以下调用kvm_cpu_has_extint():
+	 *   - arch/x86/kvm/irq.c|86| <<kvm_cpu_has_injectable_intr>> if (kvm_cpu_has_extint(v))
+	 *   - arch/x86/kvm/irq.c|115| <<kvm_cpu_has_interrupt>> if (kvm_cpu_has_extint(v))
+	 *   - arch/x86/kvm/irq.c|135| <<kvm_cpu_get_extint>> if (!kvm_cpu_has_extint(v)) {
+	 *   - arch/x86/kvm/x86.c|4850| <<kvm_cpu_accept_dm_intr>> if (kvm_cpu_has_extint(vcpu))
+	 *
+	 * check if there is pending interrupt from
+	 * non-APIC source without intack.
+	 */
 	if (!kvm_cpu_has_extint(v)) {
 		WARN_ON(!lapic_in_kernel(v));
 		return -1;
@@ -117,6 +190,11 @@ static int kvm_cpu_get_extint(struct kvm_vcpu *v)
 	if (kvm_xen_has_interrupt(v))
 		return v->kvm->arch.xen.upcall_vector;
 
+	/*
+	 * on: KVM模拟全部
+	 * split: QEMU模拟IOAPIC和PIC,KVM模拟LAPIC
+	 * off:QEMU 模拟全部
+	 */
 	if (irqchip_split(v->kvm)) {
 		int vector = v->arch.pending_external_vector;
 
@@ -129,12 +207,27 @@ static int kvm_cpu_get_extint(struct kvm_vcpu *v)
 /*
  * Read pending interrupt vector and intack.
  */
+/*
+ * 在以下调用kvm_cpu_get_interrupt():
+ *   - arch/x86/kvm/vmx/nested.c|4709| <<nested_vmx_vmexit>> int irq = kvm_cpu_get_interrupt(vcpu);
+ *   - arch/x86/kvm/x86.c|9417| <<inject_pending_event>> int irq = kvm_cpu_get_interrupt(vcpu);
+ *
+ * vcpu_enter_guest()
+ * -> inject_pending_event()
+ *    -> kvm_cpu_get_interrupt()
+ *       -> kvm_get_apic_interrupt()
+ *          -> apic_set_isr()
+ */
 int kvm_cpu_get_interrupt(struct kvm_vcpu *v)
 {
 	int vector = kvm_cpu_get_extint(v);
 	if (vector != -1)
 		return vector;			/* PIC */
 
+	/*
+	 * 只在此处调用
+	 * 这个函数会把IRR的bit移动到ISR.
+	 */
 	return kvm_get_apic_interrupt(v);	/* APIC */
 }
 EXPORT_SYMBOL_GPL(kvm_cpu_get_interrupt);
diff --git a/arch/x86/kvm/irq.h b/arch/x86/kvm/irq.h
index c2d7cfe82d00..1f0011c8606f 100644
--- a/arch/x86/kvm/irq.h
+++ b/arch/x86/kvm/irq.h
@@ -64,6 +64,19 @@ void kvm_pic_destroy(struct kvm *kvm);
 int kvm_pic_read_irq(struct kvm *kvm);
 void kvm_pic_update_irq(struct kvm_pic *s);
 
+/*
+ * 在以下使用irqchip_split():
+ *   - arch/x86/kvm/irq.c|76| <<kvm_cpu_has_extint>> if (irqchip_split(v->kvm))
+ *   - arch/x86/kvm/irq.c|188| <<kvm_cpu_get_extint>> if (irqchip_split(v->kvm)) {
+ *   - arch/x86/kvm/irq_comm.c|379| <<kvm_set_routing_entry>> if (irqchip_split(kvm))
+ *   - arch/x86/kvm/irq_comm.c|509| <<kvm_arch_post_irq_routing_update>> if (!irqchip_split(kvm))
+ *   - arch/x86/kvm/lapic.c|2102| <<kvm_ioapic_send_eoi>> if (irqchip_split(apic->vcpu->kvm)) {
+ *   - arch/x86/kvm/x86.c|10453| <<vcpu_scan_ioapic>> if (irqchip_split(vcpu->kvm))
+ *
+ * on: KVM模拟全部
+ * split: QEMU模拟IOAPIC和PIC,KVM模拟LAPIC
+ * off:QEMU 模拟全部
+ */
 static inline int irqchip_split(struct kvm *kvm)
 {
 	int mode = kvm->arch.irqchip_mode;
diff --git a/arch/x86/kvm/irq_comm.c b/arch/x86/kvm/irq_comm.c
index 025b65502fce..00ef5768faa0 100644
--- a/arch/x86/kvm/irq_comm.c
+++ b/arch/x86/kvm/irq_comm.c
@@ -65,6 +65,25 @@ int kvm_irq_delivery_to_apic(struct kvm *kvm, struct kvm_lapic *src,
 		if (!kvm_apic_present(vcpu))
 			continue;
 
+		/*
+		 * 在以下调用kvm_apic_match_dest():
+		 *   - arch/x86/kvm/ioapic.c|146| <<__rtc_irq_eoi_tracking_restore_one>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, e->fields.dest_id, kvm_lapic_irq_dest_mode(!!e->fields.dest_mode)))
+		 *   - arch/x86/kvm/ioapic.c|234| <<ioapic_lazy_update_eoi>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, entry->fields.dest_id, entry->fields.dest_mode) ||
+		 *   - arch/x86/kvm/ioapic.c|414| <<kvm_ioapic_scan_entry>> if (kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, e->fields.dest_id, dm) ||
+		 *   - arch/x86/kvm/irq_comm.c|68| <<kvm_irq_delivery_to_apic>> if (!kvm_apic_match_dest(vcpu, src,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/irq_comm.c|359| <<kvm_intr_is_single_vcpu>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/irq_comm.c|442| <<kvm_scan_ioapic_routes>> if (irq.trig_mode && (kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, irq.dest_id, irq.dest_mode) ||
+		 *   - arch/x86/kvm/lapic.c|1262| <<kvm_bitmap_or_dest_vcpus>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/svm/avic.c|461| <<avic_kick_target_vcpus>> if (kvm_apic_match_dest(vcpu, source,
+		 *          icrl & APIC_SHORT_MASK, dest, icrl & APIC_DEST_MASK)) {
+		 */
 		if (!kvm_apic_match_dest(vcpu, src, irq->shorthand,
 					irq->dest_id, irq->dest_mode))
 			continue;
@@ -72,8 +91,28 @@ int kvm_irq_delivery_to_apic(struct kvm *kvm, struct kvm_lapic *src,
 		if (!kvm_lowest_prio_delivery(irq)) {
 			if (r < 0)
 				r = 0;
+			/*
+			 * 在以下使用kvm_apic_set_irq():
+			 *   - arch/x86/kvm/hyperv.c|828| <<stimer_notify_direct>> return !kvm_apic_set_irq(vcpu, &irq, NULL);
+			 *   - arch/x86/kvm/hyperv.c|1899| <<kvm_send_ipi_to_many>> kvm_apic_set_irq(vcpu, &irq, NULL);
+			 *   - arch/x86/kvm/irq_comm.c|94| <<kvm_irq_delivery_to_apic>> r += kvm_apic_set_irq(vcpu, irq, dest_map);
+			 *   - arch/x86/kvm/irq_comm.c|125| <<kvm_irq_delivery_to_apic>> r = kvm_apic_set_irq(lowest, irq, dest_map);
+			 *   - arch/x86/kvm/lapic.c|1218| <<__pv_send_ipi>> count += kvm_apic_set_irq(vcpu, irq, NULL);
+			 *   - arch/x86/kvm/lapic.c|1699| <<kvm_irq_delivery_to_apic_fast>> *r = kvm_apic_set_irq(src->vcpu, irq, dest_map);
+			 *   - arch/x86/kvm/lapic.c|1712| <<kvm_irq_delivery_to_apic_fast>> *r += kvm_apic_set_irq(dst[i]->vcpu, irq, dest_map);
+			 *   - arch/x86/kvm/x86.c|13639| <<kvm_arch_async_page_present>> kvm_apic_set_irq(vcpu, &irq, NULL);
+			 */
 			r += kvm_apic_set_irq(vcpu, irq, dest_map);
 		} else if (kvm_apic_sw_enabled(vcpu->arch.apic)) {
+			/*
+			 * 在以下使用kvm_apic_sw_enabled():
+			 *   - arch/x86/kvm/irq_comm.c|95| <<kvm_irq_delivery_to_apic>> } else if (kvm_apic_sw_enabled(vcpu->arch.apic)) {
+			 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+			 *   - arch/x86/kvm/lapic.c|424| <<kvm_recalculate_apic_map>> if (!kvm_apic_sw_enabled(apic))
+			 *   - arch/x86/kvm/lapic.c|2720| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+			 *   - arch/x86/kvm/lapic.c|2731| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+			 *   - arch/x86/kvm/lapic.h|251| <<kvm_lapic_enabled>> return kvm_apic_present(vcpu) && kvm_apic_sw_enabled(vcpu->arch.apic);
+			 */
 			if (!kvm_vector_hashing_enabled()) {
 				if (!lowest)
 					lowest = vcpu;
@@ -93,6 +132,17 @@ int kvm_irq_delivery_to_apic(struct kvm *kvm, struct kvm_lapic *src,
 		lowest = kvm_get_vcpu(kvm, idx);
 	}
 
+	/*
+	 * 在以下使用kvm_apic_set_irq():
+1198  *   - arch/x86/kvm/hyperv.c|828| <<stimer_notify_direct>> return !kvm_apic_set_irq(vcpu, &irq, NULL);
+1199  *   - arch/x86/kvm/hyperv.c|1899| <<kvm_send_ipi_to_many>> kvm_apic_set_irq(vcpu, &irq, NULL);
+1200  *   - arch/x86/kvm/irq_comm.c|94| <<kvm_irq_delivery_to_apic>> r += kvm_apic_set_irq(vcpu, irq, dest_map);
+1201  *   - arch/x86/kvm/irq_comm.c|125| <<kvm_irq_delivery_to_apic>> r = kvm_apic_set_irq(lowest, irq, dest_map);
+1202  *   - arch/x86/kvm/lapic.c|1218| <<__pv_send_ipi>> count += kvm_apic_set_irq(vcpu, irq, NULL);
+1203  *   - arch/x86/kvm/lapic.c|1699| <<kvm_irq_delivery_to_apic_fast>> *r = kvm_apic_set_irq(src->vcpu, irq, dest_map);
+1204  *   - arch/x86/kvm/lapic.c|1712| <<kvm_irq_delivery_to_apic_fast>> *r += kvm_apic_set_irq(dst[i]->vcpu, irq, dest_map);
+1205  *   - arch/x86/kvm/x86.c|13639| <<kvm_arch_async_page_present>> kvm_apic_set_irq(vcpu, &irq, NULL);
+	 */
 	if (lowest)
 		r = kvm_apic_set_irq(lowest, irq, dest_map);
 
@@ -109,6 +159,17 @@ void kvm_set_msi_irq(struct kvm *kvm, struct kvm_kernel_irq_routing_entry *e,
 	trace_kvm_msi_set_irq(msg.address_lo | (kvm->arch.x2apic_format ?
 			      (u64)msg.address_hi << 32 : 0), msg.data);
 
+	/*
+	 * 在以下使用kvm_arch->x2apic_format:
+	 *   - arch/x86/kvm/irq_comm.c|137| <<kvm_set_msi_irq>> trace_kvm_msi_set_irq(msg.address_lo | (kvm->arch.x2apic_format ?
+	 *   - arch/x86/kvm/irq_comm.c|140| <<kvm_set_msi_irq>> irq->dest_id = x86_msi_msg_get_destid(&msg, kvm->arch.x2apic_format);
+	 *   - arch/x86/kvm/irq_comm.c|154| <<kvm_msi_route_invalid>> return kvm->arch.x2apic_format && (e->msi.address_hi & 0xff);
+	 *   - arch/x86/kvm/lapic.c|3673| <<kvm_apic_state_fixup>> if (vcpu->kvm->arch.x2apic_format) {
+	 *   - arch/x86/kvm/x86.c|5933| <<kvm_vm_ioctl_enable_cap>> kvm->arch.x2apic_format = true;
+	 *
+	 *     x2apic_format = false,
+	 *     x2apic_broadcast_quirk_disabled = false,
+	 */
 	irq->dest_id = x86_msi_msg_get_destid(&msg, kvm->arch.x2apic_format);
 	irq->vector = msg.arch_data.vector;
 	irq->dest_mode = kvm_lapic_irq_dest_mode(msg.arch_addr_lo.dest_mode_logical);
@@ -123,6 +184,17 @@ EXPORT_SYMBOL_GPL(kvm_set_msi_irq);
 static inline bool kvm_msi_route_invalid(struct kvm *kvm,
 		struct kvm_kernel_irq_routing_entry *e)
 {
+	/*
+	 * 在以下使用kvm_arch->x2apic_format:
+	 *   - arch/x86/kvm/irq_comm.c|137| <<kvm_set_msi_irq>> trace_kvm_msi_set_irq(msg.address_lo | (kvm->arch.x2apic_format ?
+	 *   - arch/x86/kvm/irq_comm.c|140| <<kvm_set_msi_irq>> irq->dest_id = x86_msi_msg_get_destid(&msg, kvm->arch.x2apic_format);
+	 *   - arch/x86/kvm/irq_comm.c|154| <<kvm_msi_route_invalid>> return kvm->arch.x2apic_format && (e->msi.address_hi & 0xff);
+	 *   - arch/x86/kvm/lapic.c|3673| <<kvm_apic_state_fixup>> if (vcpu->kvm->arch.x2apic_format) {
+	 *   - arch/x86/kvm/x86.c|5933| <<kvm_vm_ioctl_enable_cap>> kvm->arch.x2apic_format = true;
+	 *
+	 *     x2apic_format = false,
+	 *     x2apic_broadcast_quirk_disabled = false,
+	 */
 	return kvm->arch.x2apic_format && (e->msi.address_hi & 0xff);
 }
 
@@ -182,8 +254,19 @@ int kvm_arch_set_irq_inatomic(struct kvm_kernel_irq_routing_entry *e,
 	return -EWOULDBLOCK;
 }
 
+/*
+ * 在以下使用kvm_request_irq_source_id():
+ *   - arch/x86/kvm/i8254.c|670| <<kvm_create_pit>> pit->irq_source_id = kvm_request_irq_source_id(kvm);
+ */
 int kvm_request_irq_source_id(struct kvm *kvm)
 {
+	/*
+	 * 在以下使用kvm_arch->irq_sources_bitmap:
+	 *   - arch/x86/kvm/irq_comm.c|187| <<kvm_request_irq_source_id>> unsigned long *bitmap = &kvm->arch.irq_sources_bitmap;
+	 *   - arch/x86/kvm/irq_comm.c|219| <<kvm_free_irq_source_id>> clear_bit(irq_source_id, &kvm->arch.irq_sources_bitmap);
+	 *   - arch/x86/kvm/x86.c|11732| <<kvm_arch_init_vm>> set_bit(KVM_USERSPACE_IRQ_SOURCE_ID, &kvm->arch.irq_sources_bitmap);
+	 *   - arch/x86/kvm/x86.c|11735| <<kvm_arch_init_vm>> set_bit(KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID, &kvm->arch.irq_sources_bitmap);
+	 */
 	unsigned long *bitmap = &kvm->arch.irq_sources_bitmap;
 	int irq_source_id;
 
@@ -216,6 +299,13 @@ void kvm_free_irq_source_id(struct kvm *kvm, int irq_source_id)
 		printk(KERN_ERR "kvm: IRQ source ID out of range!\n");
 		goto unlock;
 	}
+	/*
+	 * 在以下使用kvm_arch->irq_sources_bitmap:
+	 *   - arch/x86/kvm/irq_comm.c|187| <<kvm_request_irq_source_id>> unsigned long *bitmap = &kvm->arch.irq_sources_bitmap;
+	 *   - arch/x86/kvm/irq_comm.c|219| <<kvm_free_irq_source_id>> clear_bit(irq_source_id, &kvm->arch.irq_sources_bitmap);
+	 *   - arch/x86/kvm/x86.c|11732| <<kvm_arch_init_vm>> set_bit(KVM_USERSPACE_IRQ_SOURCE_ID, &kvm->arch.irq_sources_bitmap);
+	 *   - arch/x86/kvm/x86.c|11735| <<kvm_arch_init_vm>> set_bit(KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID, &kvm->arch.irq_sources_bitmap);
+	 */
 	clear_bit(irq_source_id, &kvm->arch.irq_sources_bitmap);
 	if (!irqchip_kernel(kvm))
 		goto unlock;
@@ -231,6 +321,12 @@ void kvm_register_irq_mask_notifier(struct kvm *kvm, int irq,
 {
 	mutex_lock(&kvm->irq_lock);
 	kimn->irq = irq;
+	/*
+	 * 在以下使用kvm_arch->mask_notifier_list:
+	 *   - arch/x86/kvm/irq_comm.c|234| <<kvm_register_irq_mask_notifier>> hlist_add_head_rcu(&kimn->link, &kvm->arch.mask_notifier_list);
+	 *   - arch/x86/kvm/irq_comm.c|256| <<kvm_fire_mask_notifiers>> hlist_for_each_entry_rcu(kimn, &kvm->arch.mask_notifier_list, link)
+	 *   - arch/x86/kvm/x86.c|11763| <<kvm_arch_init_vm>> INIT_HLIST_HEAD(&kvm->arch.mask_notifier_list);
+	 */
 	hlist_add_head_rcu(&kimn->link, &kvm->arch.mask_notifier_list);
 	mutex_unlock(&kvm->irq_lock);
 }
@@ -252,6 +348,12 @@ void kvm_fire_mask_notifiers(struct kvm *kvm, unsigned irqchip, unsigned pin,
 
 	idx = srcu_read_lock(&kvm->irq_srcu);
 	gsi = kvm_irq_map_chip_pin(kvm, irqchip, pin);
+	/*
+	 * 在以下使用kvm_arch->mask_notifier_list:
+	 *   - arch/x86/kvm/irq_comm.c|234| <<kvm_register_irq_mask_notifier>> hlist_add_head_rcu(&kimn->link, &kvm->arch.mask_notifier_list);
+	 *   - arch/x86/kvm/irq_comm.c|256| <<kvm_fire_mask_notifiers>> hlist_for_each_entry_rcu(kimn, &kvm->arch.mask_notifier_list, link)
+	 *   - arch/x86/kvm/x86.c|11763| <<kvm_arch_init_vm>> INIT_HLIST_HEAD(&kvm->arch.mask_notifier_list);
+	 */
 	if (gsi != -1)
 		hlist_for_each_entry_rcu(kimn, &kvm->arch.mask_notifier_list, link)
 			if (kimn->irq == gsi)
@@ -274,6 +376,11 @@ int kvm_set_routing_entry(struct kvm *kvm,
 	 */
 	switch (ue->type) {
 	case KVM_IRQ_ROUTING_IRQCHIP:
+		/*
+		 * on: KVM模拟全部
+		 * split: QEMU模拟IOAPIC和PIC,KVM模拟LAPIC
+		 * off:QEMU 模拟全部
+		 */
 		if (irqchip_split(kvm))
 			return -EINVAL;
 		e->irqchip.pin = ue->u.irqchip.pin;
@@ -330,6 +437,25 @@ bool kvm_intr_is_single_vcpu(struct kvm *kvm, struct kvm_lapic_irq *irq,
 		if (!kvm_apic_present(vcpu))
 			continue;
 
+		/*
+		 * 在以下调用kvm_apic_match_dest():
+		 *   - arch/x86/kvm/ioapic.c|146| <<__rtc_irq_eoi_tracking_restore_one>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, e->fields.dest_id, kvm_lapic_irq_dest_mode(!!e->fields.dest_mode)))
+		 *   - arch/x86/kvm/ioapic.c|234| <<ioapic_lazy_update_eoi>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, entry->fields.dest_id, entry->fields.dest_mode) ||
+		 *   - arch/x86/kvm/ioapic.c|414| <<kvm_ioapic_scan_entry>> if (kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, e->fields.dest_id, dm) ||
+		 *   - arch/x86/kvm/irq_comm.c|68| <<kvm_irq_delivery_to_apic>> if (!kvm_apic_match_dest(vcpu, src,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/irq_comm.c|359| <<kvm_intr_is_single_vcpu>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/irq_comm.c|442| <<kvm_scan_ioapic_routes>> if (irq.trig_mode && (kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, irq.dest_id, irq.dest_mode) ||
+		 *   - arch/x86/kvm/lapic.c|1262| <<kvm_bitmap_or_dest_vcpus>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/svm/avic.c|461| <<avic_kick_target_vcpus>> if (kvm_apic_match_dest(vcpu, source,
+		 *          icrl & APIC_SHORT_MASK, dest, icrl & APIC_DEST_MASK)) {
+		 */
 		if (!kvm_apic_match_dest(vcpu, NULL, irq->shorthand,
 					irq->dest_id, irq->dest_mode))
 			continue;
@@ -385,11 +511,20 @@ int kvm_setup_empty_irq_routing(struct kvm *kvm)
 
 void kvm_arch_post_irq_routing_update(struct kvm *kvm)
 {
+	/*
+	 * on: KVM模拟全部
+	 * split: QEMU模拟IOAPIC和PIC,KVM模拟LAPIC
+	 * off:QEMU 模拟全部
+	 */
 	if (!irqchip_split(kvm))
 		return;
 	kvm_make_scan_ioapic_request(kvm);
 }
 
+/*
+ * 只在一个地方调用kvm_scan_ioapic_routes():
+ *   - arch/x86/kvm/x86.c|9856| <<vcpu_scan_ioapic>> kvm_scan_ioapic_routes(vcpu, vcpu->arch.ioapic_handled_vectors);
+ */
 void kvm_scan_ioapic_routes(struct kvm_vcpu *vcpu,
 			    ulong *ioapic_handled_vectors)
 {
@@ -412,6 +547,25 @@ void kvm_scan_ioapic_routes(struct kvm_vcpu *vcpu,
 
 			kvm_set_msi_irq(vcpu->kvm, entry, &irq);
 
+			/*
+			 * 在以下调用kvm_apic_match_dest():
+			 *   - arch/x86/kvm/ioapic.c|146| <<__rtc_irq_eoi_tracking_restore_one>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, e->fields.dest_id, kvm_lapic_irq_dest_mode(!!e->fields.dest_mode)))
+			 *   - arch/x86/kvm/ioapic.c|234| <<ioapic_lazy_update_eoi>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, entry->fields.dest_id, entry->fields.dest_mode) ||
+			 *   - arch/x86/kvm/ioapic.c|414| <<kvm_ioapic_scan_entry>> if (kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, e->fields.dest_id, dm) ||
+			 *   - arch/x86/kvm/irq_comm.c|68| <<kvm_irq_delivery_to_apic>> if (!kvm_apic_match_dest(vcpu, src,
+			 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+			 *   - arch/x86/kvm/irq_comm.c|359| <<kvm_intr_is_single_vcpu>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+			 *   - arch/x86/kvm/irq_comm.c|442| <<kvm_scan_ioapic_routes>> if (irq.trig_mode && (kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, irq.dest_id, irq.dest_mode) ||
+			 *   - arch/x86/kvm/lapic.c|1262| <<kvm_bitmap_or_dest_vcpus>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+			 *   - arch/x86/kvm/svm/avic.c|461| <<avic_kick_target_vcpus>> if (kvm_apic_match_dest(vcpu, source,
+			 *          icrl & APIC_SHORT_MASK, dest, icrl & APIC_DEST_MASK)) {
+			 */
 			if (irq.trig_mode &&
 			    (kvm_apic_match_dest(vcpu, NULL, APIC_DEST_NOSHORT,
 						 irq.dest_id, irq.dest_mode) ||
diff --git a/arch/x86/kvm/lapic.c b/arch/x86/kvm/lapic.c
index 43c2722ef25e..24902a9fde4b 100644
--- a/arch/x86/kvm/lapic.c
+++ b/arch/x86/kvm/lapic.c
@@ -43,6 +43,66 @@
 #include "cpuid.h"
 #include "hyperv.h"
 
+/*
+ * | 项目                 | MSR_IA32_APICBASE       | SPIV (0xF0)                |
+ * | ------------------ | ------------------------- | -------------------------- |
+ * | 控制粒度               | 硬件级,全局关闭                  | 软件级,关闭中断处理                 |
+ * | 生效范围               | 关闭整个 Local APIC           | 保留结构但不响应中断                 |
+ * | 通常使用时机             | BIOS,操作系统启动阶段             | 操作系统运行时                    |
+ * | 会影响 APIC MMIO 寄存器吗 | 是,APIC 基址无效后不能访问 APIC 寄存器 | 否,仍然可访问 APIC 寄存器           |
+ * | 对中断的影响             | 完全禁用中断(包括 INIT, STARTUP)  | 仅禁用普通中断,某些特殊中断(如 NMI)有效    |
+ * | 典型用途               | 内核初始化前设置,关闭 SMP 支持        | 操作系统禁用中断(如使用 IOAPIC 或 PIC) |
+ *
+ *
+ * 如果你只把SPIV 的使能位关掉(即SPIV[8]=0),CPU不会响应普通中断,但Local APIC结构还在,
+ * 依然可以接收INIT或IPI等特殊信号.
+ *
+ * 如果你把MSR_IA32_APICBASE[11]=0,则整个Local APIC被禁用,APIC MMIO区也不能访问,
+ * 连 INIT,STARTUP都可能无法正确使用.
+ */
+
+/*
+ * 下面两个函数很重要.
+ *
+ * vmx_inject_irq()
+ * vmx_hwapic_isr_update()
+ */
+
+/*
+ * 在以下使用apic的regs:
+ *   - arch/x86/kvm/lapic.c|88| <<kvm_lapic_set_reg>> __kvm_lapic_set_reg(apic->regs, reg_off, val);
+ *   - arch/x86/kvm/lapic.c|99| <<kvm_lapic_get_reg64>> return __kvm_lapic_get_reg64(apic->regs, reg);
+ *   - arch/x86/kvm/lapic.c|111| <<kvm_lapic_set_reg64>> __kvm_lapic_set_reg64(apic->regs, reg, val);
+ *   - arch/x86/kvm/lapic.c|123| <<kvm_apic_pending_eoi>> return apic_test_vector(vector, apic->regs + APIC_ISR) ||
+ *   - arch/x86/kvm/lapic.c|124| <<kvm_apic_pending_eoi>> apic_test_vector(vector, apic->regs + APIC_IRR);
+ *   - arch/x86/kvm/lapic.c|682| <<kvm_apic_update_irr>> bool irr_updated = __kvm_apic_update_irr(pir, apic->regs, max_irr);
+ *   - arch/x86/kvm/lapic.c|707| <<apic_search_irr>> return find_highest_vector(apic->regs + APIC_IRR);
+ *   - arch/x86/kvm/lapic.c|750| <<apic_clear_irr>> kvm_lapic_clear_vector(vec, apic->regs + APIC_IRR);
+ *   - arch/x86/kvm/lapic.c|770| <<apic_clear_irr>> kvm_lapic_clear_vector(vec, apic->regs + APIC_IRR);
+ *   - arch/x86/kvm/lapic.c|790| <<apic_set_isr>> if (__apic_test_and_set_vector(vec, apic->regs + APIC_ISR))
+ *   - arch/x86/kvm/lapic.c|878| <<apic_find_highest_isr>> result = find_highest_vector(apic->regs + APIC_ISR);
+ *   - arch/x86/kvm/lapic.c|891| <<apic_clear_isr>> if (!__apic_test_and_clear_vector(vec, apic->regs + APIC_ISR))
+ *   - arch/x86/kvm/lapic.c|1553| <<__apic_accept_irq>> if (apic_test_vector(vector, apic->regs + APIC_TMR) != !!trig_mode) {
+ *   - arch/x86/kvm/lapic.c|1556| <<__apic_accept_irq>> kvm_lapic_set_vector(vector, apic->regs + APIC_TMR);
+ *   - arch/x86/kvm/lapic.c|1559| <<__apic_accept_irq>> kvm_lapic_clear_vector(vector, apic->regs + APIC_TMR);
+ *   - arch/x86/kvm/lapic.c|1730| <<kvm_ioapic_send_eoi>> if (apic_test_vector(vector, apic->regs + APIC_TMR))
+ *   - arch/x86/kvm/lapic.c|2060| <<lapic_timer_int_injected>> void *bitmap = apic->regs + APIC_ISR;
+ *   - arch/x86/kvm/lapic.c|2063| <<lapic_timer_int_injected>> bitmap = apic->regs + APIC_IRR;
+ *   - arch/x86/kvm/lapic.c|2833| <<kvm_free_lapic>> if (apic->regs)
+ *   - arch/x86/kvm/lapic.c|2834| <<kvm_free_lapic>> free_page((unsigned long )apic->regs);
+ *   - arch/x86/kvm/lapic.c|2995| <<kvm_apic_update_apicv>> apic->isr_count = count_vectors(apic->regs + APIC_ISR);
+ *   - arch/x86/kvm/lapic.c|3198| <<kvm_create_lapic>> apic->regs = (void *)get_zeroed_page(GFP_KERNEL_ACCOUNT);
+ *   - arch/x86/kvm/lapic.c|3199| <<kvm_create_lapic>> if (!apic->regs) {
+ *   - arch/x86/kvm/lapic.c|3373| <<kvm_apic_get_state>> memcpy(s->regs, vcpu->arch.apic->regs, sizeof(*s));
+ *   - arch/x86/kvm/lapic.c|3413| <<kvm_apic_set_state>> apic_set_spiv(apic, *((u32 *)(s->regs + APIC_SPIV)));
+ *   - arch/x86/kvm/lapic.c|3433| <<kvm_apic_set_state>> memcpy(vcpu->arch.apic->regs, s->regs, sizeof(*s));
+ *   - arch/x86/kvm/lapic.h|184| <<kvm_lapic_set_irr>> kvm_lapic_set_vector(vec, apic->regs + APIC_IRR);
+ *   - arch/x86/kvm/lapic.h|214| <<kvm_lapic_get_reg>> return __kvm_lapic_get_reg(apic->regs, reg_off);
+ *   - arch/x86/kvm/svm/avic.c|294| <<avic_init_backing_page>> if (!vcpu->arch.apic->regs)
+ *   - arch/x86/kvm/svm/avic.c|305| <<avic_init_backing_page>> svm->avic_backing_page = virt_to_page(vcpu->arch.apic->regs);
+ *   - arch/x86/kvm/vmx/vmx.c|4590| <<init_vmcs>> ivmcs_write64(VIRTUAL_APIC_PAGE_ADDR, __pa(vmx->vcpu.arch.apic->regs));
+ */
+
 #ifndef CONFIG_X86_64
 #define mod_64(x, y) ((x) - (y) * div64_u64(x, y))
 #else
@@ -127,11 +187,56 @@ static inline int __apic_test_and_clear_vector(int vec, void *bitmap)
 	return __test_and_clear_bit(VEC_POS(vec), (bitmap) + REG_POS(vec));
 }
 
+/*
+ * 在以下使用apic_hw_disabled:
+ *   - arch/x86/kvm/lapic.c|190| <<global>> __read_mostly DEFINE_STATIC_KEY_DEFERRED_FALSE(apic_hw_disabled, HZ);
+ *   - arch/x86/kvm/lapic.c|3253| <<kvm_free_lapic>> static_branch_slow_dec_deferred(&apic_hw_disabled);
+ *   - arch/x86/kvm/lapic.c|3460| <<kvm_lapic_set_base>> static_branch_slow_dec_deferred(&apic_hw_disabled);
+ *   - arch/x86/kvm/lapic.c|3472| <<kvm_lapic_set_base>> static_branch_inc(&apic_hw_disabled.key);
+ *   - arch/x86/kvm/lapic.c|4580| <<kvm_lapic_exit>> static_key_deferred_flush(&apic_hw_disabled);
+ *   - arch/x86/kvm/lapic.c|4581| <<kvm_lapic_exit>> WARN_ON(static_branch_unlikely(&apic_hw_disabled.key));
+ *   - arch/x86/kvm/lapic.h|290| <<kvm_apic_hw_enabled>> if (static_branch_unlikely(&apic_hw_disabled.key))
+ */
 __read_mostly DEFINE_STATIC_KEY_DEFERRED_FALSE(apic_hw_disabled, HZ);
+/*
+ * 在以下使用apic_sw_disabled:
+ *   - arch/x86/kvm/lapic.c|191| <<global>> __read_mostly DEFINE_STATIC_KEY_DEFERRED_FALSE(apic_sw_disabled, HZ);
+ *   - arch/x86/kvm/lapic.c|599| <<apic_set_spiv>> static_branch_slow_dec_deferred(&apic_sw_disabled);
+ *   - arch/x86/kvm/lapic.c|601| <<apic_set_spiv>> static_branch_inc(&apic_sw_disabled.key);
+ *   - arch/x86/kvm/lapic.c|3263| <<kvm_free_lapic>> static_branch_slow_dec_deferred(&apic_sw_disabled);
+ *   - arch/x86/kvm/lapic.c|3840| <<kvm_create_lapic>> static_branch_inc(&apic_sw_disabled.key);
+ *   - arch/x86/kvm/lapic.c|4582| <<kvm_lapic_exit>> static_key_deferred_flush(&apic_sw_disabled);
+ *   - arch/x86/kvm/lapic.c|4583| <<kvm_lapic_exit>> WARN_ON(static_branch_unlikely(&apic_sw_disabled.key));
+ *   - arch/x86/kvm/lapic.h|315| <<kvm_apic_sw_enabled>> if (static_branch_unlikely(&apic_sw_disabled.key))
+ */
 __read_mostly DEFINE_STATIC_KEY_DEFERRED_FALSE(apic_sw_disabled, HZ);
 
+/*
+ * 在以下使用apic_enabled():
+ *   - arch/x86/kvm/lapic.c|1655| <<__apic_accept_irq>> if (unlikely(!apic_enabled(apic)))
+ *   - arch/x86/kvm/lapic.c|3388| <<apic_has_pending_timer>> if (apic_enabled(apic) && apic_lvt_enabled(apic, APIC_LVTT))
+ */
 static inline int apic_enabled(struct kvm_lapic *apic)
 {
+	/*
+	 * 在以下使用kvm_apic_sw_enabled():
+	 *   - arch/x86/kvm/irq_comm.c|95| <<kvm_irq_delivery_to_apic>> } else if (kvm_apic_sw_enabled(vcpu->arch.apic)) {
+	 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+	 *   - arch/x86/kvm/lapic.c|424| <<kvm_recalculate_apic_map>> if (!kvm_apic_sw_enabled(apic))
+	 *   - arch/x86/kvm/lapic.c|2720| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+	 *   - arch/x86/kvm/lapic.c|2731| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+	 *   - arch/x86/kvm/lapic.h|251| <<kvm_lapic_enabled>> return kvm_apic_present(vcpu) && kvm_apic_sw_enabled(vcpu->arch.apic);
+	 *
+	 * 在以下调用kvm_apic_hw_enabled():
+	 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+	 *   - arch/x86/kvm/lapic.c|2040| <<apic_mmio_read>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2125| <<lapic_timer_int_injected>> if (kvm_apic_hw_enabled(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2809| <<apic_mmio_write>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|3330| <<kvm_apic_local_deliver>> if (kvm_apic_hw_enabled(apic) && !(reg & APIC_LVT_MASKED)) {
+	 *   - arch/x86/kvm/lapic.c|3443| <<kvm_apic_accept_pic_intr>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 *   - arch/x86/kvm/lapic.h|246| <<kvm_apic_present>> return lapic_in_kernel(vcpu) && kvm_apic_hw_enabled(vcpu->arch.apic);
+	 *   - arch/x86/kvm/x86.c|10218| <<vcpu_load_eoi_exitmap>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 */
 	return kvm_apic_sw_enabled(apic) &&	kvm_apic_hw_enabled(apic);
 }
 
@@ -222,6 +327,82 @@ enum {
 	DIRTY
 };
 
+/*
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_vcpu_reset
+ * kvm_apic_accept_events
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_lapic_reg_write
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ *
+ * 根据测试online/offline不会调用
+ * hot-remove cpu不会调用
+ * hot-add cpu会调用3次.
+ *
+ * kvm_recalculate_apic_map+0x1'
+ * kvm_set_apic_base+0xbe'
+ * vmx_set_msr+0x5f4'
+ * __kvm_set_msr+0x9d'
+ * kvm_arch_vcpu_ioctl+0xa20'
+ * kvm_vcpu_ioctl+0x552'
+ * __x64_sys_ioctl+0x8f'
+ * do_syscall_64+0x35'
+ * entry_SYSCALL_64_after_hwframe+0x6e'
+ *
+ * kvm_recalculate_apic_map+0x1'
+ * kvm_set_apic_base+0xbe'
+ * __set_sregs_common.constprop.0+0x165'
+ * kvm_arch_vcpu_ioctl+0x908'
+ * kvm_vcpu_ioctl+0x552'
+ * __x64_sys_ioctl+0x8f'
+ * do_syscall_64+0x35'
+ * entry_SYSCALL_64_after_hwframe+0x6e'
+ *
+ * kvm_recalculate_apic_map+0x1'
+ * kvm_set_apic_base+0xbe'
+ * vmx_set_msr+0x5f4'
+ * __kvm_set_msr+0x9d'
+ * kvm_emulate_wrmsr+0x38'
+ * vmx_handle_exit+0xe'
+ * vcpu_enter_guest+0x86f'
+ * vcpu_run+0x4e'
+ * kvm_arch_vcpu_ioctl_run+0xc8'
+ * kvm_vcpu_ioctl+0x2a8'
+ * __x64_sys_ioctl+0x8f'
+ * do_syscall_64+0x35'
+ * entry_SYSCALL_64_after_hwframe+0x6e'
+ *
+ *
+ * 在以下调用kvm_recalculate_apic_map():
+ *   - arch/x86/kvm/lapic.c|2441| <<kvm_lapic_reg_write>> kvm_recalculate_apic_map(apic->vcpu->kvm);
+ *   - arch/x86/kvm/lapic.c|2718| <<kvm_lapic_reset>> kvm_recalculate_apic_map(vcpu->kvm);
+ *   - arch/x86/kvm/lapic.c|2995| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+ *   - arch/x86/kvm/lapic.c|3001| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+ *   - arch/x86/kvm/x86.c|493| <<kvm_set_apic_base>> kvm_recalculate_apic_map(vcpu->kvm);
+ */
 void kvm_recalculate_apic_map(struct kvm *kvm)
 {
 	struct kvm_apic_map *new, *old = NULL;
@@ -230,6 +411,21 @@ void kvm_recalculate_apic_map(struct kvm *kvm)
 	u32 max_id = 255; /* enough space for any xAPIC ID */
 	bool xapic_id_mismatch = false;
 
+	/*
+	 * 在以下使用kvm_arch->apic_map_dirty:
+	 *   - arch/x86/kvm/lapic.c|279| <<kvm_recalculate_apic_map>> if (atomic_read_acquire(&kvm->arch.apic_map_dirty) == CLEAN)
+	 *   - arch/x86/kvm/lapic.c|290| <<kvm_recalculate_apic_map>> if (atomic_cmpxchg_acquire(&kvm->arch.apic_map_dirty,
+	 *                                  DIRTY, UPDATE_IN_PROGRESS) == CLEAN) {
+	 *   - arch/x86/kvm/lapic.c|378| <<kvm_recalculate_apic_map>> atomic_cmpxchg_release(&kvm->arch.apic_map_dirty,
+	 *                                  UPDATE_IN_PROGRESS, CLEAN);
+	 *   - arch/x86/kvm/lapic.c|401| <<apic_set_spiv>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|441| <<kvm_apic_set_xapic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|447| <<kvm_apic_set_ldr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|453| <<kvm_apic_set_dfr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|496| <<kvm_apic_set_x2apic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|2862| <<kvm_lapic_set_base>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|3370| <<kvm_apic_set_state>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 */
 	/* Read kvm->arch.apic_map_dirty before kvm->arch.apic_map.  */
 	if (atomic_read_acquire(&kvm->arch.apic_map_dirty) == CLEAN)
 		return;
@@ -237,6 +433,15 @@ void kvm_recalculate_apic_map(struct kvm *kvm)
 	WARN_ONCE(!irqchip_in_kernel(kvm),
 		  "Dirty APIC map without an in-kernel local APIC");
 
+	/*
+	 * 在以下使用kvm_arch->apic_map_lock:
+	 *   - arch/x86/kvm/lapic.c|375| <<kvm_recalculate_apic_map>> mutex_lock(&kvm->arch.apic_map_lock);
+	 *   - arch/x86/kvm/lapic.c|383| <<kvm_recalculate_apic_map>> mutex_unlock(&kvm->arch.apic_map_lock);
+	 *   - arch/x86/kvm/lapic.c|506| <<kvm_recalculate_apic_map>> old = rcu_dereference_protected(kvm->arch.apic_map,
+	 *                                     lockdep_is_held(&kvm->arch.apic_map_lock));
+	 *   - arch/x86/kvm/lapic.c|514| <<kvm_recalculate_apic_map>> mutex_unlock(&kvm->arch.apic_map_lock);
+	 *   - arch/x86/kvm/x86.c|12397| <<kvm_arch_init_vm>> mutex_init(&kvm->arch.apic_map_lock);
+	 */
 	mutex_lock(&kvm->arch.apic_map_lock);
 	/*
 	 * Read kvm->arch.apic_map_dirty before kvm->arch.apic_map
@@ -249,6 +454,9 @@ void kvm_recalculate_apic_map(struct kvm *kvm)
 		return;
 	}
 
+	/*
+	 * apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE;
+	 */
 	kvm_for_each_vcpu(i, vcpu, kvm)
 		if (kvm_apic_present(vcpu))
 			max_id = max(max_id, kvm_x2apic_id(vcpu->arch.apic));
@@ -270,12 +478,47 @@ void kvm_recalculate_apic_map(struct kvm *kvm)
 		u8 xapic_id;
 		u32 x2apic_id;
 
+		/*
+		 * apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE;
+		 */
 		if (!kvm_apic_present(vcpu))
 			continue;
 
+		/*
+		 * 在以下使用kvm_apic_set_xapic_id():
+		 *   - arch/x86/kvm/lapic.c|2455| <<kvm_lapic_reg_write(APIC_ID)>> kvm_apic_set_xapic_id(apic, val >> 24);
+		 *   - arch/x86/kvm/lapic.c|2756| <<kvm_lapic_set_base>> kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
+		 *   - arch/x86/kvm/lapic.c|2871| <<kvm_lapic_reset>> kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
+		 *
+		 *
+		 * 返回: return kvm_lapic_get_reg(apic, APIC_ID) >> 24;
+		 */
 		xapic_id = kvm_xapic_id(apic);
+		/*
+		 * 返回: return apic->vcpu->vcpu_id;
+		 */
 		x2apic_id = kvm_x2apic_id(apic);
 
+		/*
+		 * 在以下设置kvm_vcpu_arch->apic_base (看似修改的地方):
+		 *   - arch/x86/kvm/lapic.c|2926| <<kvm_lapic_set_base>> vcpu->arch.apic_base = value;
+		 *   - arch/x86/kvm/lapic.c|3256| <<kvm_create_lapic>> vcpu->arch.apic_base = MSR_IA32_APICBASE_ENABLE;
+		 * 在以下使用kvm_vcpu_arch->apic_base:
+		 *   - arch/x86/kvm/cpuid.c|222| <<__kvm_update_cpuid_runtime>> cpuid_entry_change(best, X86_FEATURE_APIC, vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE);
+		 *   - arch/x86/kvm/lapic.c|2862| <<kvm_free_lapic>> if (!(vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE))
+		 *   - arch/x86/kvm/lapic.c|2923| <<kvm_lapic_set_base>> u64 old_value = vcpu->arch.apic_base;
+		 *   - arch/x86/kvm/lapic.c|2974| <<kvm_lapic_set_base>> apic->base_address = apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_BASE;
+		 *   - arch/x86/kvm/lapic.c|3454| <<kvm_apic_set_state>> kvm_lapic_set_base(vcpu, vcpu->arch.apic_base);
+		 *   - arch/x86/kvm/lapic.h|231| <<kvm_apic_hw_enabled>> return apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE;
+		 *   - arch/x86/kvm/lapic.h|256| <<apic_x2apic_mode>> return apic->vcpu->arch.apic_base & X2APIC_ENABLE;
+		 *   - arch/x86/kvm/lapic.h|300| <<kvm_apic_mode>> return apic_base & (MSR_IA32_APICBASE_ENABLE | X2APIC_ENABLE);
+		 *   - arch/x86/kvm/vmx/nested.c|878| <<nested_vmx_msr_check_common>> if (CC(vcpu->arch.apic_base & X2APIC_ENABLE && e->index >> 8 == 0x8))
+		 *   - arch/x86/kvm/x86.c|466| <<kvm_get_apic_base>> return vcpu->arch.apic_base;
+		 *   - arch/x86/kvm/x86.c|12215| <<kvm_vcpu_is_bsp>> return (vcpu->arch.apic_base & MSR_IA32_APICBASE_BSP) != 0;
+		 *
+		 * 返回:
+		 * return apic->vcpu->arch.apic_base & X2APIC_ENABLE;
+		 */
 		/*
 		 * Deliberately truncate the vCPU ID when detecting a mismatched
 		 * APIC ID to avoid false positives if the vCPU ID, i.e. x2APIC
@@ -296,6 +539,15 @@ void kvm_recalculate_apic_map(struct kvm *kvm)
 		if (!apic_x2apic_mode(apic) && !new->phys_map[xapic_id])
 			new->phys_map[xapic_id] = apic;
 
+		/*
+		 * 在以下使用kvm_apic_sw_enabled():
+		 *   - arch/x86/kvm/irq_comm.c|95| <<kvm_irq_delivery_to_apic>> } else if (kvm_apic_sw_enabled(vcpu->arch.apic)) {
+		 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+		 *   - arch/x86/kvm/lapic.c|424| <<kvm_recalculate_apic_map>> if (!kvm_apic_sw_enabled(apic))
+		 *   - arch/x86/kvm/lapic.c|2720| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+		 *   - arch/x86/kvm/lapic.c|2731| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+		 *   - arch/x86/kvm/lapic.h|251| <<kvm_lapic_enabled>> return kvm_apic_present(vcpu) && kvm_apic_sw_enabled(vcpu->arch.apic);
+		 */
 		if (!kvm_apic_sw_enabled(apic))
 			continue;
 
@@ -318,11 +570,25 @@ void kvm_recalculate_apic_map(struct kvm *kvm)
 			cluster[ffs(mask) - 1] = apic;
 	}
 out:
+	/*
+	 * 就在这一个地方修改APICV_INHIBIT_REASON_APIC_ID_MODIFIED
+	 */
 	if (xapic_id_mismatch)
 		kvm_set_apicv_inhibit(kvm, APICV_INHIBIT_REASON_APIC_ID_MODIFIED);
 	else
 		kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_APIC_ID_MODIFIED);
 
+	/*
+	 * 在以下使用kvm_arch->apic_map:
+	 *   - arch/x86/kvm/lapic.c|581| <<kvm_recalculate_apic_map>> old = rcu_dereference_protected(kvm->arch.apic_map,
+	 *   - arch/x86/kvm/lapic.c|583| <<kvm_recalculate_apic_map>> rcu_assign_pointer(kvm->arch.apic_map, new);
+	 *   - arch/x86/kvm/lapic.c|1305| <<kvm_pv_send_ipi>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1772| <<kvm_irq_delivery_to_apic_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1825| <<kvm_intr_is_single_vcpu_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|2023| <<kvm_bitmap_or_dest_vcpus>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|9391| <<kvm_sched_yield>> map = rcu_dereference(vcpu->kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|13061| <<kvm_arch_destroy_vm>> kvfree(rcu_dereference_check(kvm->arch.apic_map, 1));
+	 */
 	old = rcu_dereference_protected(kvm->arch.apic_map,
 			lockdep_is_held(&kvm->arch.apic_map_lock));
 	rcu_assign_pointer(kvm->arch.apic_map, new);
@@ -340,30 +606,119 @@ void kvm_recalculate_apic_map(struct kvm *kvm)
 	kvm_make_scan_ioapic_request(kvm);
 }
 
+/*
+ * 在以下调用apic_set_spiv():
+ *   - arch/x86/kvm/lapic.c|2786| <<kvm_lapic_reg_write(APIC_SPIV)>> apic_set_spiv(apic, val & mask);
+ *   - arch/x86/kvm/lapic.c|3389| <<kvm_lapic_reset>> apic_set_spiv(apic, 0xff);
+ *   - arch/x86/kvm/lapic.c|3817| <<kvm_apic_set_state>> apic_set_spiv(apic, *((u32 *)(s->regs + APIC_SPIV)));
+ */
 static inline void apic_set_spiv(struct kvm_lapic *apic, u32 val)
 {
 	bool enabled = val & APIC_SPIV_APIC_ENABLED;
 
 	kvm_lapic_set_reg(apic, APIC_SPIV, val);
 
+	/*
+	 * 在以下使用kvm_lapic->sw_enabled:
+	 *   - arch/x86/kvm/lapic.c|474| <<apic_set_spiv>> if (enabled != apic->sw_enabled) {
+	 *   - arch/x86/kvm/lapic.c|475| <<apic_set_spiv>> apic->sw_enabled = enabled;
+	 *   - arch/x86/kvm/lapic.c|2899| <<kvm_free_lapic>> if (!apic->sw_enabled)
+	 *   - arch/x86/kvm/lapic.h|260| <<kvm_apic_sw_enabled>> return apic->sw_enabled;
+	 */
 	if (enabled != apic->sw_enabled) {
 		apic->sw_enabled = enabled;
+		/*
+		 * 在以下使用apic_sw_disabled:
+		 *   - arch/x86/kvm/lapic.c|191| <<global>> __read_mostly DEFINE_STATIC_KEY_DEFERRED_FALSE(apic_sw_disabled, HZ);
+		 *   - arch/x86/kvm/lapic.c|599| <<apic_set_spiv>> static_branch_slow_dec_deferred(&apic_sw_disabled);
+		 *   - arch/x86/kvm/lapic.c|601| <<apic_set_spiv>> static_branch_inc(&apic_sw_disabled.key);
+		 *   - arch/x86/kvm/lapic.c|3263| <<kvm_free_lapic>> static_branch_slow_dec_deferred(&apic_sw_disabled);
+		 *   - arch/x86/kvm/lapic.c|3840| <<kvm_create_lapic>> static_branch_inc(&apic_sw_disabled.key);
+		 *   - arch/x86/kvm/lapic.c|4582| <<kvm_lapic_exit>> static_key_deferred_flush(&apic_sw_disabled);
+		 *   - arch/x86/kvm/lapic.c|4583| <<kvm_lapic_exit>> WARN_ON(static_branch_unlikely(&apic_sw_disabled.key));
+		 *   - arch/x86/kvm/lapic.h|315| <<kvm_apic_sw_enabled>> if (static_branch_unlikely(&apic_sw_disabled.key))
+		 */
 		if (enabled)
 			static_branch_slow_dec_deferred(&apic_sw_disabled);
 		else
 			static_branch_inc(&apic_sw_disabled.key);
 
+		/*
+		 * 在以下使用kvm_arch->apic_map_dirty:
+		 *   - arch/x86/kvm/lapic.c|279| <<kvm_recalculate_apic_map>> if (atomic_read_acquire(&kvm->arch.apic_map_dirty) == CLEAN)
+		 *   - arch/x86/kvm/lapic.c|290| <<kvm_recalculate_apic_map>> if (atomic_cmpxchg_acquire(&kvm->arch.apic_map_dirty,
+		 *   - arch/x86/kvm/lapic.c|378| <<kvm_recalculate_apic_map>> atomic_cmpxchg_release(&kvm->arch.apic_map_dirty,
+		 *   - arch/x86/kvm/lapic.c|401| <<apic_set_spiv>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+		 *   - arch/x86/kvm/lapic.c|441| <<kvm_apic_set_xapic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+		 *   - arch/x86/kvm/lapic.c|447| <<kvm_apic_set_ldr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+		 *   - arch/x86/kvm/lapic.c|453| <<kvm_apic_set_dfr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+		 *   - arch/x86/kvm/lapic.c|496| <<kvm_apic_set_x2apic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+		 *   - arch/x86/kvm/lapic.c|2862| <<kvm_lapic_set_base>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+		 *   - arch/x86/kvm/lapic.c|3370| <<kvm_apic_set_state>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+		 */
 		atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
 	}
 
+	/*
+	 * 在以下使用KVM_REQ_APF_READY:
+	 *   - arch/x86/kvm/lapic.c|621| <<apic_set_spiv>> kvm_make_request(KVM_REQ_APF_READY, apic->vcpu);
+	 *   - arch/x86/kvm/lapic.c|3303| <<kvm_lapic_set_base>> kvm_make_request(KVM_REQ_APF_READY, vcpu);
+	 *   - arch/x86/kvm/x86.c|13246| <<kvm_arch_async_page_present_queued>> kvm_make_request(KVM_REQ_APF_READY, vcpu);
+	 *
+	 * 处理的函数kvm_check_async_pf_completion()
+	 */
 	/* Check if there are APF page ready requests pending */
 	if (enabled)
 		kvm_make_request(KVM_REQ_APF_READY, apic->vcpu);
 }
 
+/*
+ * 在以下使用kvm_apic_set_xapic_id():
+ *   - arch/x86/kvm/lapic.c|2455| <<kvm_lapic_reg_write(APIC_ID)>> kvm_apic_set_xapic_id(apic, val >> 24);
+ *   - arch/x86/kvm/lapic.c|2756| <<kvm_lapic_set_base>> kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
+ *   - arch/x86/kvm/lapic.c|2871| <<kvm_lapic_reset>> kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
+ *
+ * 其实kvm_apic_set_state()也会修改APIC_ID
+ */
 static inline void kvm_apic_set_xapic_id(struct kvm_lapic *apic, u8 id)
 {
+	/*
+	 * 在以下使用APIC_ID:
+	 *   - arch/x86/kvm/svm/svm.c|119| <<global>> { .index = X2APIC_MSR(APIC_ID), .always = false },
+	 *   - arch/x86/include/asm/apic.h|204| <<native_apic_msr_write>> if (reg == APIC_DFR || reg == APIC_ID || reg == APIC_LDR ||
+	 *   - arch/x86/include/asm/apic.h|487| <<read_apic_id>> unsigned int reg = apic_read(APIC_ID);
+	 *   - arch/x86/kernel/apic/apic.c|1797| <<setup_nox2apic>> int apicid = native_apic_msr_read(APIC_ID);
+	 *   - arch/x86/kernel/apic/apic.c|2586| <<apic_bsp_up_setup>> apic_write(APIC_ID, apic->set_apic_id(boot_cpu_physical_apicid));
+	 *   - arch/x86/kernel/apic/apic.c|2668| <<lapic_suspend>> apic_pm_state.apic_id = apic_read(APIC_ID);
+	 *   - arch/x86/kernel/apic/apic.c|2745| <<lapic_resume>> apic_write(APIC_ID, apic_pm_state.apic_id);
+	 *   - arch/x86/kernel/apic/apic_flat_64.c|91| <<read_xapic_id>> return flat_get_apic_id(apic_read(APIC_ID));
+	 *   - arch/x86/kernel/apic/vector.c|1157| <<print_local_APIC>> v = apic_read(APIC_ID);
+	 *   - arch/x86/kernel/apic/x2apic_uv_x.c|811| <<uv_read_apic_id>> return x2apic_get_apic_id(apic_read(APIC_ID));
+	 *   - arch/x86/kernel/smpboot.c|689| <<__inquire_remote_apic>> unsigned i, regs[] = { APIC_ID >> 4, APIC_LVR >> 4, APIC_SPIV >> 4 };
+	 *   - arch/x86/kvm/lapic.c|381| <<kvm_apic_set_xapic_id>> kvm_lapic_set_reg(apic, APIC_ID, id << 24);
+	 *   - arch/x86/kvm/lapic.c|408| <<kvm_apic_set_x2apic_id>> kvm_lapic_set_reg(apic, APIC_ID, id);
+	 *   - arch/x86/kvm/lapic.c|1762| <<kvm_lapic_reg_read>> APIC_REG_MASK(APIC_ID) |
+	 *   - arch/x86/kvm/lapic.c|2393| <<kvm_lapic_reg_write>> case APIC_ID:
+	 *   - arch/x86/kvm/lapic.c|3094| <<kvm_apic_state_fixup>> u32 *id = (u32 *)(s->regs + APIC_ID);
+	 *   - arch/x86/kvm/lapic.h|305| <<kvm_xapic_id>> return kvm_lapic_get_reg(apic, APIC_ID) >> 24;
+	 *   - arch/x86/kvm/svm/avic.c|675| <<is_avic_unaccelerated_access_trap>> case APIC_ID:
+	 *   - arch/x86/xen/apic.c|63| <<xen_apic_read>> if (reg != APIC_ID)
+	 *   - tools/testing/selftests/kvm/x86_64/xapic_ipi_test.c|100| <<halter_guest_code>> data->halter_apic_id = GET_APIC_ID_FIELD(xapic_read_reg(APIC_ID));
+	 */
 	kvm_lapic_set_reg(apic, APIC_ID, id << 24);
+	/*
+	 * 在以下使用kvm_arch->apic_map_dirty:
+	 *   - arch/x86/kvm/lapic.c|279| <<kvm_recalculate_apic_map>> if (atomic_read_acquire(&kvm->arch.apic_map_dirty) == CLEAN)
+	 *   - arch/x86/kvm/lapic.c|290| <<kvm_recalculate_apic_map>> if (atomic_cmpxchg_acquire(&kvm->arch.apic_map_dirty,
+	 *   - arch/x86/kvm/lapic.c|378| <<kvm_recalculate_apic_map>> atomic_cmpxchg_release(&kvm->arch.apic_map_dirty,
+	 *   - arch/x86/kvm/lapic.c|401| <<apic_set_spiv>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|441| <<kvm_apic_set_xapic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|447| <<kvm_apic_set_ldr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|453| <<kvm_apic_set_dfr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|496| <<kvm_apic_set_x2apic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|2862| <<kvm_lapic_set_base>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|3370| <<kvm_apic_set_state>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 */
 	atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
 }
 
@@ -384,14 +739,54 @@ static inline u32 kvm_apic_calc_x2apic_ldr(u32 id)
 	return ((id >> 4) << 16) | (1 << (id & 0xf));
 }
 
+/*
+ * 只在此处使用kvm_apic_set_x2apic_id():
+ *   - arch/x86/kvm/lapic.c|2767| <<kvm_lapic_set_base>> kvm_apic_set_x2apic_id(apic, vcpu->vcpu_id);
+ */
 static inline void kvm_apic_set_x2apic_id(struct kvm_lapic *apic, u32 id)
 {
 	u32 ldr = kvm_apic_calc_x2apic_ldr(id);
 
 	WARN_ON_ONCE(id != apic->vcpu->vcpu_id);
 
+	/*
+	 * 在以下使用APIC_ID:
+	 *   - arch/x86/kvm/svm/svm.c|119| <<global>> { .index = X2APIC_MSR(APIC_ID), .always = false },
+	 *   - arch/x86/include/asm/apic.h|204| <<native_apic_msr_write>> if (reg == APIC_DFR || reg == APIC_ID || reg == APIC_LDR ||
+	 *   - arch/x86/include/asm/apic.h|487| <<read_apic_id>> unsigned int reg = apic_read(APIC_ID);
+	 *   - arch/x86/kernel/apic/apic.c|1797| <<setup_nox2apic>> int apicid = native_apic_msr_read(APIC_ID);
+	 *   - arch/x86/kernel/apic/apic.c|2586| <<apic_bsp_up_setup>> apic_write(APIC_ID, apic->set_apic_id(boot_cpu_physical_apicid));
+	 *   - arch/x86/kernel/apic/apic.c|2668| <<lapic_suspend>> apic_pm_state.apic_id = apic_read(APIC_ID);
+	 *   - arch/x86/kernel/apic/apic.c|2745| <<lapic_resume>> apic_write(APIC_ID, apic_pm_state.apic_id);
+	 *   - arch/x86/kernel/apic/apic_flat_64.c|91| <<read_xapic_id>> return flat_get_apic_id(apic_read(APIC_ID));
+	 *   - arch/x86/kernel/apic/vector.c|1157| <<print_local_APIC>> v = apic_read(APIC_ID);
+	 *   - arch/x86/kernel/apic/x2apic_uv_x.c|811| <<uv_read_apic_id>> return x2apic_get_apic_id(apic_read(APIC_ID));
+	 *   - arch/x86/kernel/smpboot.c|689| <<__inquire_remote_apic>> unsigned i, regs[] = { APIC_ID >> 4, APIC_LVR >> 4, APIC_SPIV >> 4 };
+	 *   - arch/x86/kvm/lapic.c|381| <<kvm_apic_set_xapic_id>> kvm_lapic_set_reg(apic, APIC_ID, id << 24);
+	 *   - arch/x86/kvm/lapic.c|408| <<kvm_apic_set_x2apic_id>> kvm_lapic_set_reg(apic, APIC_ID, id);
+	 *   - arch/x86/kvm/lapic.c|1762| <<kvm_lapic_reg_read>> APIC_REG_MASK(APIC_ID) |
+	 *   - arch/x86/kvm/lapic.c|2393| <<kvm_lapic_reg_write>> case APIC_ID:
+	 *   - arch/x86/kvm/lapic.c|3094| <<kvm_apic_state_fixup>> u32 *id = (u32 *)(s->regs + APIC_ID);
+	 *   - arch/x86/kvm/lapic.h|305| <<kvm_xapic_id>> return kvm_lapic_get_reg(apic, APIC_ID) >> 24;
+	 *   - arch/x86/kvm/svm/avic.c|675| <<is_avic_unaccelerated_access_trap>> case APIC_ID:
+	 *   - arch/x86/xen/apic.c|63| <<xen_apic_read>> if (reg != APIC_ID)
+	 *   - tools/testing/selftests/kvm/x86_64/xapic_ipi_test.c|100| <<halter_guest_code>> data->halter_apic_id = GET_APIC_ID_FIELD(xapic_read_reg(APIC_ID));
+	 */
 	kvm_lapic_set_reg(apic, APIC_ID, id);
 	kvm_lapic_set_reg(apic, APIC_LDR, ldr);
+	/*
+	 * 在以下使用kvm_arch->apic_map_dirty:
+	 *   - arch/x86/kvm/lapic.c|279| <<kvm_recalculate_apic_map>> if (atomic_read_acquire(&kvm->arch.apic_map_dirty) == CLEAN)
+	 *   - arch/x86/kvm/lapic.c|290| <<kvm_recalculate_apic_map>> if (atomic_cmpxchg_acquire(&kvm->arch.apic_map_dirty,
+	 *   - arch/x86/kvm/lapic.c|378| <<kvm_recalculate_apic_map>> atomic_cmpxchg_release(&kvm->arch.apic_map_dirty,
+	 *   - arch/x86/kvm/lapic.c|401| <<apic_set_spiv>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|441| <<kvm_apic_set_xapic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|447| <<kvm_apic_set_ldr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|453| <<kvm_apic_set_dfr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|496| <<kvm_apic_set_x2apic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|2862| <<kvm_lapic_set_base>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|3370| <<kvm_apic_set_state>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 */
 	atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
 }
 
@@ -478,6 +873,15 @@ static u8 count_vectors(void *bitmap)
 	return count;
 }
 
+/*
+ * 在以下使用__kvm_apic_update_irr():
+ *   - arch/x86/kvm/lapic.c|527| <<kvm_apic_update_irr>> bool irr_updated = __kvm_apic_update_irr(pir, apic->regs, max_irr);
+ *   - arch/x86/kvm/vmx/nested.c|3832| <<vmx_complete_nested_posted_interrupt>> __kvm_apic_update_irr(vmx->nested.pi_desc->pir,
+ *
+ * vmx_sync_pir_to_irr()
+ * -> kvm_apic_update_irr()
+ *    -> __kvm_apic_update_irr()
+ */
 bool __kvm_apic_update_irr(u32 *pir, void *regs, int *max_irr)
 {
 	u32 i, vec;
@@ -514,11 +918,34 @@ bool __kvm_apic_update_irr(u32 *pir, void *regs, int *max_irr)
 }
 EXPORT_SYMBOL_GPL(__kvm_apic_update_irr);
 
+/*
+ * 只在以下调用kvm_apic_update_irr():
+ *   - arch/x86/kvm/vmx/vmx.c|6490| <<vmx_sync_pir_to_irr>> kvm_apic_update_irr(vcpu, vmx->pi_desc.pir, &max_irr);
+ *
+ * vmx_sync_pir_to_irr()
+ * -> kvm_apic_update_irr()
+ *    -> __kvm_apic_update_irr()
+ */
 bool kvm_apic_update_irr(struct kvm_vcpu *vcpu, u32 *pir, int *max_irr)
 {
 	struct kvm_lapic *apic = vcpu->arch.apic;
 	bool irr_updated = __kvm_apic_update_irr(pir, apic->regs, max_irr);
 
+	/*
+	 * 在以下使用kvm_lapic->irr_pending:
+	 *   - arch/x86/kvm/lapic.c|530| <<kvm_apic_update_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|548| <<apic_find_highest_irr>> if (!apic->irr_pending)
+	 *   - arch/x86/kvm/lapic.c|569| <<apic_clear_irr>> apic->irr_pending = false;
+	 *   - arch/x86/kvm/lapic.c|572| <<apic_clear_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|2519| <<kvm_apic_update_apicv>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|2968| <<apic_sync_pv_eoi_to_guest>> apic->irr_pending ||
+	 *   - arch/x86/kvm/lapic.h|154| <<kvm_lapic_set_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/svm/avic.c|434| <<avic_kick_target_vcpus_fast>> target_vcpu->arch.apic->irr_pending = true;
+	 *   - arch/x86/kvm/svm/avic.c|482| <<avic_kick_target_vcpus>> vcpu->arch.apic->irr_pending = true;
+	 *
+	 * 理论上来说:
+	 * irr_pending is always true when apicv is activated.
+	 */
 	if (unlikely(!vcpu->arch.apicv_active && irr_updated))
 		apic->irr_pending = true;
 	return irr_updated;
@@ -534,6 +961,21 @@ static inline int apic_find_highest_irr(struct kvm_lapic *apic)
 {
 	int result;
 
+	/*
+	 * 在以下使用kvm_lapic->irr_pending:
+	 *   - arch/x86/kvm/lapic.c|530| <<kvm_apic_update_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|548| <<apic_find_highest_irr>> if (!apic->irr_pending)
+	 *   - arch/x86/kvm/lapic.c|569| <<apic_clear_irr>> apic->irr_pending = false;
+	 *   - arch/x86/kvm/lapic.c|572| <<apic_clear_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|2519| <<kvm_apic_update_apicv>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|2968| <<apic_sync_pv_eoi_to_guest>> apic->irr_pending ||
+	 *   - arch/x86/kvm/lapic.h|154| <<kvm_lapic_set_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/svm/avic.c|434| <<avic_kick_target_vcpus_fast>> target_vcpu->arch.apic->irr_pending = true;
+	 *   - arch/x86/kvm/svm/avic.c|482| <<avic_kick_target_vcpus>> vcpu->arch.apic->irr_pending = true;
+	 *
+	 * 理论上来说:
+	 * irr_pending is always true when apicv is activated.
+	 */
 	/*
 	 * Note that irr_pending is just a hint. It will be always
 	 * true with virtual interrupt delivery enabled.
@@ -559,6 +1001,21 @@ static inline void apic_clear_irr(int vec, struct kvm_lapic *apic)
 		static_call(kvm_x86_hwapic_irr_update)(vcpu,
 				apic_find_highest_irr(apic));
 	} else {
+		/*
+		 * 在以下使用kvm_lapic->irr_pending:
+		 *   - arch/x86/kvm/lapic.c|530| <<kvm_apic_update_irr>> apic->irr_pending = true;
+		 *   - arch/x86/kvm/lapic.c|548| <<apic_find_highest_irr>> if (!apic->irr_pending)
+		 *   - arch/x86/kvm/lapic.c|569| <<apic_clear_irr>> apic->irr_pending = false;
+		 *   - arch/x86/kvm/lapic.c|572| <<apic_clear_irr>> apic->irr_pending = true;
+		 *   - arch/x86/kvm/lapic.c|2519| <<kvm_apic_update_apicv>> apic->irr_pending = true;
+		 *   - arch/x86/kvm/lapic.c|2968| <<apic_sync_pv_eoi_to_guest>> apic->irr_pending ||
+		 *   - arch/x86/kvm/lapic.h|154| <<kvm_lapic_set_irr>> apic->irr_pending = true;
+		 *   - arch/x86/kvm/svm/avic.c|434| <<avic_kick_target_vcpus_fast>> target_vcpu->arch.apic->irr_pending = true;
+		 *   - arch/x86/kvm/svm/avic.c|482| <<avic_kick_target_vcpus>> vcpu->arch.apic->irr_pending = true;
+		 *
+		 * 理论上来说:
+		 * irr_pending is always true when apicv is activated.
+		 */
 		apic->irr_pending = false;
 		kvm_lapic_clear_vector(vec, apic->regs + APIC_IRR);
 		if (apic_search_irr(apic) != -1)
@@ -572,6 +1029,16 @@ void kvm_apic_clear_irr(struct kvm_vcpu *vcpu, int vec)
 }
 EXPORT_SYMBOL_GPL(kvm_apic_clear_irr);
 
+/*
+ * 只在以下调用apic_set_isr():
+ *   - arch/x86/kvm/lapic.c|2870| <<kvm_get_apic_interrupt>> apic_set_isr(vector, apic);
+ *
+ * vcpu_enter_guest()
+ * -> inject_pending_event()
+ *    -> kvm_cpu_get_interrupt()
+ *       -> kvm_get_apic_interrupt()
+ *          -> apic_set_isr()
+ */
 static inline void apic_set_isr(int vec, struct kvm_lapic *apic)
 {
 	struct kvm_vcpu *vcpu;
@@ -586,11 +1053,40 @@ static inline void apic_set_isr(int vec, struct kvm_lapic *apic)
 	 * because the processor can modify ISR under the hood.  Instead
 	 * just set SVI.
 	 */
+	/*
+	 * 在以下调用kvm_x86_hwapic_isr_update:
+	 *   - arch/x86/kvm/lapic.c|1003| <<apic_set_isr>> static_call(kvm_x86_hwapic_isr_update)(vcpu, vec);
+	 *   - arch/x86/kvm/lapic.c|1129| <<apic_clear_isr>> static_call(kvm_x86_hwapic_isr_update)(vcpu, apic_find_highest_isr(apic));
+	 *   - arch/x86/kvm/lapic.c|3622| <<kvm_lapic_reset>> static_call(kvm_x86_hwapic_isr_update)(vcpu, -1);
+	 *   - arch/x86/kvm/lapic.c|4127| <<kvm_apic_set_state>> static_call(kvm_x86_hwapic_isr_update)(vcpu, apic_find_highest_isr(apic));
+	 *
+	 * vmx_hwapic_isr_update()
+	 */
 	if (unlikely(vcpu->arch.apicv_active))
 		static_call(kvm_x86_hwapic_isr_update)(vcpu, vec);
 	else {
+		/*
+		 * 在以下使用kvm_lapic->isr_count:
+		 *   - arch/x86/kvm/lapic.c|657| <<apic_set_isr>> ++apic->isr_count;
+		 *   - arch/x86/kvm/lapic.c|658| <<apic_set_isr>> BUG_ON(apic->isr_count > MAX_APIC_VECTOR);
+		 *   - arch/x86/kvm/lapic.c|684| <<apic_find_highest_isr>> if (!apic->isr_count)
+		 *   - arch/x86/kvm/lapic.c|718| <<apic_clear_isr>> --apic->isr_count;
+		 *   - arch/x86/kvm/lapic.c|719| <<apic_clear_isr>> BUG_ON(apic->isr_count < 0);
+		 *   - arch/x86/kvm/lapic.c|2631| <<kvm_apic_update_apicv>> apic->isr_count = 1;
+		 *   - arch/x86/kvm/lapic.c|2639| <<kvm_apic_update_apicv>> apic->isr_count = count_vectors(apic->regs + APIC_ISR);
+		 */
 		++apic->isr_count;
 		BUG_ON(apic->isr_count > MAX_APIC_VECTOR);
+		/*
+		 * 在以下使用kvm_lapic->highest_isr_cache:
+		 *   - arch/x86/kvm/lapic.c|675| <<apic_set_isr>> apic->highest_isr_cache = vec;
+		 *   - arch/x86/kvm/lapic.c|697| <<apic_find_highest_isr>> if (likely(apic->highest_isr_cache != -1))
+		 *   - arch/x86/kvm/lapic.c|698| <<apic_find_highest_isr>> return apic->highest_isr_cache;
+		 *   - arch/x86/kvm/lapic.c|734| <<apic_clear_isr>> apic->highest_isr_cache = -1;
+		 *   - arch/x86/kvm/lapic.c|2669| <<kvm_apic_update_apicv>> apic->highest_isr_cache = -1;
+		 *   - arch/x86/kvm/lapic.c|3170| <<apic_sync_pv_eoi_to_guest>> apic->highest_isr_cache == -1 ||
+		 *   - arch/x86/kvm/lapic.c|3172| <<apic_sync_pv_eoi_to_guest>> kvm_ioapic_handles_vector(apic, apic->highest_isr_cache)) {
+		 */
 		/*
 		 * ISR (in service register) bit is set when injecting an interrupt.
 		 * The highest vector is injected. Thus the latest bit set matches
@@ -600,6 +1096,14 @@ static inline void apic_set_isr(int vec, struct kvm_lapic *apic)
 	}
 }
 
+/*
+ * 在以下调用apic_find_highest_isr():
+ *   - arch/x86/kvm/lapic.c|700| <<apic_clear_isr>> apic_find_highest_isr(apic));
+ *   - arch/x86/kvm/lapic.c|858| <<__apic_update_ppr>> isr = apic_find_highest_isr(apic);
+ *   - arch/x86/kvm/lapic.c|1486| <<apic_set_eoi>> int vector = apic_find_highest_isr(apic);
+ *   - arch/x86/kvm/lapic.c|2963| <<kvm_apic_set_state>> apic_find_highest_isr(apic));
+ *   - arch/x86/kvm/lapic.c|3097| <<kvm_lapic_sync_to_vapic>> max_isr = apic_find_highest_isr(apic);
+ */
 static inline int apic_find_highest_isr(struct kvm_lapic *apic)
 {
 	int result;
@@ -608,8 +1112,28 @@ static inline int apic_find_highest_isr(struct kvm_lapic *apic)
 	 * Note that isr_count is always 1, and highest_isr_cache
 	 * is always -1, with APIC virtualization enabled.
 	 */
+	/*
+	 * 在以下使用kvm_lapic->isr_count:
+	 *   - arch/x86/kvm/lapic.c|657| <<apic_set_isr>> ++apic->isr_count;
+	 *   - arch/x86/kvm/lapic.c|658| <<apic_set_isr>> BUG_ON(apic->isr_count > MAX_APIC_VECTOR);
+	 *   - arch/x86/kvm/lapic.c|684| <<apic_find_highest_isr>> if (!apic->isr_count)
+	 *   - arch/x86/kvm/lapic.c|718| <<apic_clear_isr>> --apic->isr_count;
+	 *   - arch/x86/kvm/lapic.c|719| <<apic_clear_isr>> BUG_ON(apic->isr_count < 0);
+	 *   - arch/x86/kvm/lapic.c|2631| <<kvm_apic_update_apicv>> apic->isr_count = 1;
+	 *   - arch/x86/kvm/lapic.c|2639| <<kvm_apic_update_apicv>> apic->isr_count = count_vectors(apic->regs + APIC_ISR);
+	 */
 	if (!apic->isr_count)
 		return -1;
+	/*
+	 * 在以下使用kvm_lapic->highest_isr_cache:
+	 *   - arch/x86/kvm/lapic.c|675| <<apic_set_isr>> apic->highest_isr_cache = vec;
+	 *   - arch/x86/kvm/lapic.c|697| <<apic_find_highest_isr>> if (likely(apic->highest_isr_cache != -1))
+	 *   - arch/x86/kvm/lapic.c|698| <<apic_find_highest_isr>> return apic->highest_isr_cache;
+	 *   - arch/x86/kvm/lapic.c|734| <<apic_clear_isr>> apic->highest_isr_cache = -1;
+	 *   - arch/x86/kvm/lapic.c|2669| <<kvm_apic_update_apicv>> apic->highest_isr_cache = -1;
+	 *   - arch/x86/kvm/lapic.c|3170| <<apic_sync_pv_eoi_to_guest>> apic->highest_isr_cache == -1 ||
+	 *   - arch/x86/kvm/lapic.c|3172| <<apic_sync_pv_eoi_to_guest>> kvm_ioapic_handles_vector(apic, apic->highest_isr_cache)) {
+	 */
 	if (likely(apic->highest_isr_cache != -1))
 		return apic->highest_isr_cache;
 
@@ -619,6 +1143,10 @@ static inline int apic_find_highest_isr(struct kvm_lapic *apic)
 	return result;
 }
 
+/*
+ * 在以下使用apic_clear_isr():
+ *   - arch/x86/kvm/lapic.c|1497| <<apic_set_eoi>> apic_clear_isr(vector, apic);
+ */
 static inline void apic_clear_isr(int vec, struct kvm_lapic *apic)
 {
 	struct kvm_vcpu *vcpu;
@@ -627,6 +1155,29 @@ static inline void apic_clear_isr(int vec, struct kvm_lapic *apic)
 
 	vcpu = apic->vcpu;
 
+	/*
+	 * 在以下设置kvm_vcpu_arch->apicv_active:
+	 *   - arch/x86/kvm/x86.c|9800| <<kvm_vcpu_update_apicv>> vcpu->arch.apicv_active = activate;
+	 *   - arch/x86/kvm/x86.c|11393| <<kvm_arch_vcpu_create>> vcpu->arch.apicv_active = true;
+	 * 在以下使用kvm_vcpu_arch->apicv_active:
+	 *   - arch/x86/kvm/lapic.c|553| <<kvm_apic_update_irr>> if (unlikely(!vcpu->arch.apicv_active && irr_updated))
+	 *   - arch/x86/kvm/lapic.c|602| <<apic_clear_irr>> if (unlikely(vcpu->arch.apicv_active)) {
+	 *   - arch/x86/kvm/lapic.c|654| <<apic_set_isr>> if (unlikely(vcpu->arch.apicv_active))
+	 *   - arch/x86/kvm/lapic.c|714| <<apic_clear_isr>> if (unlikely(vcpu->arch.apicv_active))
+	 *   - arch/x86/kvm/lapic.c|1827| <<lapic_timer_int_injected>> if (vcpu->arch.apicv_active)
+	 *   - arch/x86/kvm/lapic.c|1944| <<apic_timer_expired>> if (!from_timer_fn && vcpu->arch.apicv_active) {
+	 *   - arch/x86/kvm/lapic.c|2613| <<kvm_apic_update_apicv>> if (vcpu->arch.apicv_active) {
+	 *   - arch/x86/kvm/lapic.c|2703| <<kvm_lapic_reset>> if (vcpu->arch.apicv_active) {
+	 *   - arch/x86/kvm/lapic.c|3003| <<kvm_apic_set_state>> if (vcpu->arch.apicv_active) {
+	 *   - arch/x86/kvm/lapic.h|241| <<kvm_vcpu_apicv_active>> return vcpu->arch.apic && vcpu->arch.apicv_active;
+	 *   - arch/x86/kvm/svm/svm.c|3661| <<svm_complete_interrupt_delivery>> if (!READ_ONCE(vcpu->arch.apicv_active)) {
+	 *   - arch/x86/kvm/vmx/vmx.c|4114| <<vmx_deliver_posted_interrupt>> if (!vcpu->arch.apicv_active)
+	 *   - arch/x86/kvm/x86.c|9241| <<update_cr8_intercept>> if (vcpu->arch.apicv_active)
+	 *   - arch/x86/kvm/x86.c|9797| <<kvm_vcpu_update_apicv>> if (vcpu->arch.apicv_active == activate)
+	 *   - arch/x86/kvm/x86.c|9810| <<kvm_vcpu_update_apicv>> if (!vcpu->arch.apicv_active)
+	 *   - arch/x86/kvm/x86.c|12441| <<kvm_arch_dy_has_pending_interrupt>> if (vcpu->arch.apicv_active &&
+	 *          static_call(kvm_x86_dy_apicv_has_pending_interrupt)(vcpu))
+	 */
 	/*
 	 * We do get here for APIC virtualization enabled if the guest
 	 * uses the Hyper-V APIC enlightenment.  In this case we may need
@@ -634,16 +1185,50 @@ static inline void apic_clear_isr(int vec, struct kvm_lapic *apic)
 	 * on the other hand isr_count and highest_isr_cache are unused
 	 * and must be left alone.
 	 */
+	/*
+	 * 在以下调用kvm_x86_hwapic_isr_update:
+	 *   - arch/x86/kvm/lapic.c|1003| <<apic_set_isr>> static_call(kvm_x86_hwapic_isr_update)(vcpu, vec);
+	 *   - arch/x86/kvm/lapic.c|1129| <<apic_clear_isr>> static_call(kvm_x86_hwapic_isr_update)(vcpu, apic_find_highest_isr(apic));
+	 *   - arch/x86/kvm/lapic.c|3622| <<kvm_lapic_reset>> static_call(kvm_x86_hwapic_isr_update)(vcpu, -1);
+	 *   - arch/x86/kvm/lapic.c|4127| <<kvm_apic_set_state>> static_call(kvm_x86_hwapic_isr_update)(vcpu, apic_find_highest_isr(apic));
+	 *
+	 * vmx_hwapic_isr_update()
+	 */
 	if (unlikely(vcpu->arch.apicv_active))
 		static_call(kvm_x86_hwapic_isr_update)(vcpu,
 						apic_find_highest_isr(apic));
 	else {
+		/*
+		 * 在以下使用kvm_lapic->isr_count:
+		 *   - arch/x86/kvm/lapic.c|657| <<apic_set_isr>> ++apic->isr_count;
+		 *   - arch/x86/kvm/lapic.c|658| <<apic_set_isr>> BUG_ON(apic->isr_count > MAX_APIC_VECTOR);
+		 *   - arch/x86/kvm/lapic.c|684| <<apic_find_highest_isr>> if (!apic->isr_count)
+		 *   - arch/x86/kvm/lapic.c|718| <<apic_clear_isr>> --apic->isr_count;
+		 *   - arch/x86/kvm/lapic.c|719| <<apic_clear_isr>> BUG_ON(apic->isr_count < 0);
+		 *   - arch/x86/kvm/lapic.c|2631| <<kvm_apic_update_apicv>> apic->isr_count = 1;
+		 *   - arch/x86/kvm/lapic.c|2639| <<kvm_apic_update_apicv>> apic->isr_count = count_vectors(apic->regs + APIC_ISR);
+		 */
 		--apic->isr_count;
 		BUG_ON(apic->isr_count < 0);
+		/*
+		 * 在以下使用kvm_lapic->highest_isr_cache:
+		 *   - arch/x86/kvm/lapic.c|675| <<apic_set_isr>> apic->highest_isr_cache = vec;
+		 *   - arch/x86/kvm/lapic.c|697| <<apic_find_highest_isr>> if (likely(apic->highest_isr_cache != -1))
+		 *   - arch/x86/kvm/lapic.c|698| <<apic_find_highest_isr>> return apic->highest_isr_cache;
+		 *   - arch/x86/kvm/lapic.c|734| <<apic_clear_isr>> apic->highest_isr_cache = -1;
+		 *   - arch/x86/kvm/lapic.c|2669| <<kvm_apic_update_apicv>> apic->highest_isr_cache = -1;
+		 *   - arch/x86/kvm/lapic.c|3170| <<apic_sync_pv_eoi_to_guest>> apic->highest_isr_cache == -1 ||
+		 *   - arch/x86/kvm/lapic.c|3172| <<apic_sync_pv_eoi_to_guest>> kvm_ioapic_handles_vector(apic, apic->highest_isr_cache)) {
+		 */
 		apic->highest_isr_cache = -1;
 	}
 }
 
+/*
+ * 在以下使用kvm_lapic_find_highest_irr():
+ *   - arch/x86/kvm/vmx/vmx.c|6502| <<vmx_sync_pir_to_irr>> max_irr = kvm_lapic_find_highest_irr(vcpu);
+ *   - arch/x86/kvm/x86.c|9245| <<update_cr8_intercept>> max_irr = kvm_lapic_find_highest_irr(vcpu);
+ */
 int kvm_lapic_find_highest_irr(struct kvm_vcpu *vcpu)
 {
 	/* This may race with setting of irr in __apic_accept_irq() and
@@ -659,6 +1244,17 @@ static int __apic_accept_irq(struct kvm_lapic *apic, int delivery_mode,
 			     int vector, int level, int trig_mode,
 			     struct dest_map *dest_map);
 
+/*
+ * 在以下使用kvm_apic_set_irq():
+ *   - arch/x86/kvm/hyperv.c|828| <<stimer_notify_direct>> return !kvm_apic_set_irq(vcpu, &irq, NULL);
+ *   - arch/x86/kvm/hyperv.c|1899| <<kvm_send_ipi_to_many>> kvm_apic_set_irq(vcpu, &irq, NULL);
+ *   - arch/x86/kvm/irq_comm.c|94| <<kvm_irq_delivery_to_apic>> r += kvm_apic_set_irq(vcpu, irq, dest_map);
+ *   - arch/x86/kvm/irq_comm.c|125| <<kvm_irq_delivery_to_apic>> r = kvm_apic_set_irq(lowest, irq, dest_map);
+ *   - arch/x86/kvm/lapic.c|1218| <<__pv_send_ipi>> count += kvm_apic_set_irq(vcpu, irq, NULL);
+ *   - arch/x86/kvm/lapic.c|1699| <<kvm_irq_delivery_to_apic_fast>> *r = kvm_apic_set_irq(src->vcpu, irq, dest_map);
+ *   - arch/x86/kvm/lapic.c|1712| <<kvm_irq_delivery_to_apic_fast>> *r += kvm_apic_set_irq(dst[i]->vcpu, irq, dest_map);
+ *   - arch/x86/kvm/x86.c|13639| <<kvm_arch_async_page_present>> kvm_apic_set_irq(vcpu, &irq, NULL);
+ */
 int kvm_apic_set_irq(struct kvm_vcpu *vcpu, struct kvm_lapic_irq *irq,
 		     struct dest_map *dest_map)
 {
@@ -681,6 +1277,17 @@ static int __pv_send_ipi(unsigned long *ipi_bitmap, struct kvm_apic_map *map,
 		min((u32)BITS_PER_LONG, (map->max_apic_id - min + 1))) {
 		if (map->phys_map[min + i]) {
 			vcpu = map->phys_map[min + i]->vcpu;
+			/*
+			 * 在以下使用kvm_apic_set_irq():
+			 *   - arch/x86/kvm/hyperv.c|828| <<stimer_notify_direct>> return !kvm_apic_set_irq(vcpu, &irq, NULL);
+			 *   - arch/x86/kvm/hyperv.c|1899| <<kvm_send_ipi_to_many>> kvm_apic_set_irq(vcpu, &irq, NULL);
+			 *   - arch/x86/kvm/irq_comm.c|94| <<kvm_irq_delivery_to_apic>> r += kvm_apic_set_irq(vcpu, irq, dest_map);
+			 *   - arch/x86/kvm/irq_comm.c|125| <<kvm_irq_delivery_to_apic>> r = kvm_apic_set_irq(lowest, irq, dest_map);
+			 *   - arch/x86/kvm/lapic.c|1218| <<__pv_send_ipi>> count += kvm_apic_set_irq(vcpu, irq, NULL);
+			 *   - arch/x86/kvm/lapic.c|1699| <<kvm_irq_delivery_to_apic_fast>> *r = kvm_apic_set_irq(src->vcpu, irq, dest_map);
+			 *   - arch/x86/kvm/lapic.c|1712| <<kvm_irq_delivery_to_apic_fast>> *r += kvm_apic_set_irq(dst[i]->vcpu, irq, dest_map);
+			 *   - arch/x86/kvm/x86.c|13639| <<kvm_arch_async_page_present>> kvm_apic_set_irq(vcpu, &irq, NULL);
+			 */
 			count += kvm_apic_set_irq(vcpu, irq, NULL);
 		}
 	}
@@ -706,6 +1313,17 @@ int kvm_pv_send_ipi(struct kvm *kvm, unsigned long ipi_bitmap_low,
 	irq.trig_mode = icr & APIC_INT_LEVELTRIG;
 
 	rcu_read_lock();
+	/*
+	 * 在以下使用kvm_arch->apic_map:
+	 *   - arch/x86/kvm/lapic.c|581| <<kvm_recalculate_apic_map>> old = rcu_dereference_protected(kvm->arch.apic_map,
+	 *   - arch/x86/kvm/lapic.c|583| <<kvm_recalculate_apic_map>> rcu_assign_pointer(kvm->arch.apic_map, new);
+	 *   - arch/x86/kvm/lapic.c|1305| <<kvm_pv_send_ipi>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1772| <<kvm_irq_delivery_to_apic_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1825| <<kvm_intr_is_single_vcpu_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|2023| <<kvm_bitmap_or_dest_vcpus>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|9391| <<kvm_sched_yield>> map = rcu_dereference(vcpu->kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|13061| <<kvm_arch_destroy_vm>> kvfree(rcu_dereference_check(kvm->arch.apic_map, 1));
+	 */
 	map = rcu_dereference(kvm->arch.apic_map);
 
 	count = -EOPNOTSUPP;
@@ -735,6 +1353,18 @@ static int pv_eoi_get_user(struct kvm_vcpu *vcpu, u8 *val)
 
 static inline bool pv_eoi_enabled(struct kvm_vcpu *vcpu)
 {
+	/*
+	 *     pv_eoi = {
+	 *       msr_val = 0,
+	 *        data = {
+	 *          generation = 0,
+	 *          gpa = 0,
+	 *          hva = 0,
+	 *          len = 0,
+	 *          memslot = 0x0
+	 *        }
+	 *     },
+	 */
 	return vcpu->arch.pv_eoi.msr_val & KVM_MSR_ENABLED;
 }
 
@@ -763,9 +1393,17 @@ static void pv_eoi_clr_pending(struct kvm_vcpu *vcpu)
 	__clear_bit(KVM_APIC_PV_EOI_PENDING, &vcpu->arch.apic_attention);
 }
 
+/*
+ * 在以下使用apic_has_interrupt_for_ppr():
+ *   - arch/x86/kvm/lapic.c|1342| <<apic_update_ppr>> apic_has_interrupt_for_ppr(apic, ppr) != -1)
+ *   - arch/x86/kvm/lapic.c|3716| <<kvm_apic_has_interrupt>> return apic_has_interrupt_for_ppr(apic, ppr);
+ */
 static int apic_has_interrupt_for_ppr(struct kvm_lapic *apic, u32 ppr)
 {
 	int highest_irr;
+	/*
+	 * vmx_sync_pir_to_irr()
+	 */
 	if (kvm_x86_ops.sync_pir_to_irr)
 		highest_irr = static_call(kvm_x86_sync_pir_to_irr)(apic->vcpu);
 	else
@@ -775,6 +1413,12 @@ static int apic_has_interrupt_for_ppr(struct kvm_lapic *apic, u32 ppr)
 	return highest_irr;
 }
 
+/*
+ * 在以下使用__apic_update_ppr():
+ *   - arch/x86/kvm/lapic.c|1266| <<apic_update_ppr>> if (__apic_update_ppr(apic, &ppr) &&
+ *   - arch/x86/kvm/lapic.c|3587| <<kvm_apic_has_interrupt>> __apic_update_ppr(apic, &ppr);
+ *   - arch/x86/kvm/lapic.c|3672| <<kvm_get_apic_interrupt>> __apic_update_ppr(apic, &ppr);
+ */
 static bool __apic_update_ppr(struct kvm_lapic *apic, u32 *new_ppr)
 {
 	u32 tpr, isrv, ppr, old_ppr;
@@ -782,6 +1426,14 @@ static bool __apic_update_ppr(struct kvm_lapic *apic, u32 *new_ppr)
 
 	old_ppr = kvm_lapic_get_reg(apic, APIC_PROCPRI);
 	tpr = kvm_lapic_get_reg(apic, APIC_TASKPRI);
+	/*
+	 * 在以下调用apic_find_highest_isr():
+	 *   - arch/x86/kvm/lapic.c|700| <<apic_clear_isr>> apic_find_highest_isr(apic));
+	 *   - arch/x86/kvm/lapic.c|858| <<__apic_update_ppr>> isr = apic_find_highest_isr(apic);
+	 *   - arch/x86/kvm/lapic.c|1486| <<apic_set_eoi>> int vector = apic_find_highest_isr(apic);
+	 *   - arch/x86/kvm/lapic.c|2963| <<kvm_apic_set_state>> apic_find_highest_isr(apic));
+	 *   - arch/x86/kvm/lapic.c|3097| <<kvm_lapic_sync_to_vapic>> max_isr = apic_find_highest_isr(apic);
+	 */
 	isr = apic_find_highest_isr(apic);
 	isrv = (isr != -1) ? isr : 0;
 
@@ -797,10 +1449,25 @@ static bool __apic_update_ppr(struct kvm_lapic *apic, u32 *new_ppr)
 	return ppr < old_ppr;
 }
 
+/*
+ * 在以下使用apic_update_ppr():
+ *   - arch/x86/kvm/lapic.c|1361| <<kvm_apic_update_ppr>> apic_update_ppr(vcpu->arch.apic);
+ *   - arch/x86/kvm/lapic.c|1368| <<apic_set_tpr>> apic_update_ppr(apic);
+ *   - arch/x86/kvm/lapic.c|1996| <<apic_set_eoi>> apic_update_ppr(apic);
+ *   - arch/x86/kvm/lapic.c|2115| <<__apic_read>> apic_update_ppr(apic);
+ *   - arch/x86/kvm/lapic.c|3544| <<kvm_lapic_reset>> apic_update_ppr(apic);
+ *   - arch/x86/kvm/lapic.c|3816| <<kvm_get_apic_interrupt>> apic_update_ppr(apic);
+ *   - arch/x86/kvm/lapic.c|4014| <<kvm_apic_set_state>> apic_update_ppr(apic);
+ */
 static void apic_update_ppr(struct kvm_lapic *apic)
 {
 	u32 ppr;
 
+	/*
+	 * 在以下使用apic_has_interrupt_for_ppr():
+	 *   - arch/x86/kvm/lapic.c|1342| <<apic_update_ppr>> apic_has_interrupt_for_ppr(apic, ppr) != -1)
+	 *   - arch/x86/kvm/lapic.c|3716| <<kvm_apic_has_interrupt>> return apic_has_interrupt_for_ppr(apic, ppr);
+	 */
 	if (__apic_update_ppr(apic, &ppr) &&
 	    apic_has_interrupt_for_ppr(apic, ppr) != -1)
 		kvm_make_request(KVM_REQ_EVENT, apic->vcpu);
@@ -808,6 +1475,16 @@ static void apic_update_ppr(struct kvm_lapic *apic)
 
 void kvm_apic_update_ppr(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用apic_update_ppr():
+	 *   - arch/x86/kvm/lapic.c|1361| <<kvm_apic_update_ppr>> apic_update_ppr(vcpu->arch.apic);
+	 *   - arch/x86/kvm/lapic.c|1368| <<apic_set_tpr>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|1996| <<apic_set_eoi>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|2115| <<__apic_read>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|3544| <<kvm_lapic_reset>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|3816| <<kvm_get_apic_interrupt>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|4014| <<kvm_apic_set_state>> apic_update_ppr(apic);
+	 */
 	apic_update_ppr(vcpu->arch.apic);
 }
 EXPORT_SYMBOL_GPL(kvm_apic_update_ppr);
@@ -815,6 +1492,16 @@ EXPORT_SYMBOL_GPL(kvm_apic_update_ppr);
 static void apic_set_tpr(struct kvm_lapic *apic, u32 tpr)
 {
 	kvm_lapic_set_reg(apic, APIC_TASKPRI, tpr);
+	/*
+	 * 在以下使用apic_update_ppr():
+	 *   - arch/x86/kvm/lapic.c|1361| <<kvm_apic_update_ppr>> apic_update_ppr(vcpu->arch.apic);
+	 *   - arch/x86/kvm/lapic.c|1368| <<apic_set_tpr>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|1996| <<apic_set_eoi>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|2115| <<__apic_read>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|3544| <<kvm_lapic_reset>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|3816| <<kvm_get_apic_interrupt>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|4014| <<kvm_apic_set_state>> apic_update_ppr(apic);
+	 */
 	apic_update_ppr(apic);
 }
 
@@ -891,6 +1578,15 @@ static u32 kvm_apic_mda(struct kvm_vcpu *vcpu, unsigned int dest_id,
 {
 	bool ipi = source != NULL;
 
+	/*
+	 * 在以下使用kvm_arch->x2apic_broadcast_quirk_disabled:
+	 *   - arch/x86/kvm/lapic.c|1356| <<kvm_apic_mda>> if (!vcpu->kvm->arch.x2apic_broadcast_quirk_disabled &&
+	 *   - arch/x86/kvm/lapic.c|1435| <<kvm_apic_is_broadcast_dest>> if (kvm->arch.x2apic_broadcast_quirk_disabled) {
+	 *   - arch/x86/kvm/x86.c|5935| <<kvm_vm_ioctl_enable_cap>> kvm->arch.x2apic_broadcast_quirk_disabled = true;
+	 *
+	 *     x2apic_format = false,
+	 *     x2apic_broadcast_quirk_disabled = false,
+	 */
 	if (!vcpu->kvm->arch.x2apic_broadcast_quirk_disabled &&
 	    !ipi && dest_id == APIC_BROADCAST && apic_x2apic_mode(target))
 		return X2APIC_BROADCAST;
@@ -898,6 +1594,25 @@ static u32 kvm_apic_mda(struct kvm_vcpu *vcpu, unsigned int dest_id,
 	return dest_id;
 }
 
+/*
+ * 在以下调用kvm_apic_match_dest():
+ *   - arch/x86/kvm/ioapic.c|146| <<__rtc_irq_eoi_tracking_restore_one>> if (!kvm_apic_match_dest(vcpu, NULL,
+ *          APIC_DEST_NOSHORT, e->fields.dest_id, kvm_lapic_irq_dest_mode(!!e->fields.dest_mode)))
+ *   - arch/x86/kvm/ioapic.c|234| <<ioapic_lazy_update_eoi>> if (!kvm_apic_match_dest(vcpu, NULL,
+ *          APIC_DEST_NOSHORT, entry->fields.dest_id, entry->fields.dest_mode) ||
+ *   - arch/x86/kvm/ioapic.c|414| <<kvm_ioapic_scan_entry>> if (kvm_apic_match_dest(vcpu, NULL,
+ *          APIC_DEST_NOSHORT, e->fields.dest_id, dm) ||
+ *   - arch/x86/kvm/irq_comm.c|68| <<kvm_irq_delivery_to_apic>> if (!kvm_apic_match_dest(vcpu, src,
+ *          irq->shorthand, irq->dest_id, irq->dest_mode))
+ *   - arch/x86/kvm/irq_comm.c|359| <<kvm_intr_is_single_vcpu>> if (!kvm_apic_match_dest(vcpu, NULL,
+ *          irq->shorthand, irq->dest_id, irq->dest_mode))
+ *   - arch/x86/kvm/irq_comm.c|442| <<kvm_scan_ioapic_routes>> if (irq.trig_mode && (kvm_apic_match_dest(vcpu, NULL,
+ *          APIC_DEST_NOSHORT, irq.dest_id, irq.dest_mode) ||
+ *   - arch/x86/kvm/lapic.c|1262| <<kvm_bitmap_or_dest_vcpus>> if (!kvm_apic_match_dest(vcpu, NULL,
+ *          irq->shorthand, irq->dest_id, irq->dest_mode))
+ *   - arch/x86/kvm/svm/avic.c|461| <<avic_kick_target_vcpus>> if (kvm_apic_match_dest(vcpu, source,
+ *          icrl & APIC_SHORT_MASK, dest, icrl & APIC_DEST_MASK)) {
+ */
 bool kvm_apic_match_dest(struct kvm_vcpu *vcpu, struct kvm_lapic *source,
 			   int shorthand, unsigned int dest, int dest_mode)
 {
@@ -951,6 +1666,15 @@ static void kvm_apic_disabled_lapic_found(struct kvm *kvm)
 static bool kvm_apic_is_broadcast_dest(struct kvm *kvm, struct kvm_lapic **src,
 		struct kvm_lapic_irq *irq, struct kvm_apic_map *map)
 {
+	/*
+	 * 在以下使用kvm_arch->x2apic_broadcast_quirk_disabled:
+	 *   - arch/x86/kvm/lapic.c|1356| <<kvm_apic_mda>> if (!vcpu->kvm->arch.x2apic_broadcast_quirk_disabled &&
+	 *   - arch/x86/kvm/lapic.c|1435| <<kvm_apic_is_broadcast_dest>> if (kvm->arch.x2apic_broadcast_quirk_disabled) {
+	 *   - arch/x86/kvm/x86.c|5935| <<kvm_vm_ioctl_enable_cap>> kvm->arch.x2apic_broadcast_quirk_disabled = true;
+	 *
+	 *     x2apic_format = false,
+	 *     x2apic_broadcast_quirk_disabled = false,
+	 */
 	if (kvm->arch.x2apic_broadcast_quirk_disabled) {
 		if ((irq->dest_id == APIC_BROADCAST &&
 				map->mode != KVM_APIC_MODE_X2APIC))
@@ -974,6 +1698,12 @@ static bool kvm_apic_is_broadcast_dest(struct kvm *kvm, struct kvm_lapic **src,
  * means that the interrupt should be dropped.  In this case, *bitmap would be
  * zero and *dst undefined.
  */
+/*
+ * 在以下使用kvm_apic_map_get_dest_lapic():
+ *   - arch/x86/kvm/lapic.c|1768| <<kvm_irq_delivery_to_apic_fast>> ret = kvm_apic_map_get_dest_lapic(kvm, &src, irq, map, &dst, &bitmap);
+ *   - arch/x86/kvm/lapic.c|1821| <<kvm_intr_is_single_vcpu_fast>> if (kvm_apic_map_get_dest_lapic(kvm, NULL, irq, map, &dst, &bitmap) &&
+ *   - arch/x86/kvm/lapic.c|2019| <<kvm_bitmap_or_dest_vcpus>> ret = kvm_apic_map_get_dest_lapic(kvm, &src, irq, map, &dest_vcpu, &bitmap);
+ */
 static inline bool kvm_apic_map_get_dest_lapic(struct kvm *kvm,
 		struct kvm_lapic **src, struct kvm_lapic_irq *irq,
 		struct kvm_apic_map *map, struct kvm_lapic ***dst,
@@ -1061,6 +1791,17 @@ bool kvm_irq_delivery_to_apic_fast(struct kvm *kvm, struct kvm_lapic *src,
 	}
 
 	rcu_read_lock();
+	/*
+	 * 在以下使用kvm_arch->apic_map:
+	 *   - arch/x86/kvm/lapic.c|581| <<kvm_recalculate_apic_map>> old = rcu_dereference_protected(kvm->arch.apic_map,
+	 *   - arch/x86/kvm/lapic.c|583| <<kvm_recalculate_apic_map>> rcu_assign_pointer(kvm->arch.apic_map, new);
+	 *   - arch/x86/kvm/lapic.c|1305| <<kvm_pv_send_ipi>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1772| <<kvm_irq_delivery_to_apic_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1825| <<kvm_intr_is_single_vcpu_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|2023| <<kvm_bitmap_or_dest_vcpus>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|9391| <<kvm_sched_yield>> map = rcu_dereference(vcpu->kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|13061| <<kvm_arch_destroy_vm>> kvfree(rcu_dereference_check(kvm->arch.apic_map, 1));
+	 */
 	map = rcu_dereference(kvm->arch.apic_map);
 
 	ret = kvm_apic_map_get_dest_lapic(kvm, &src, irq, map, &dst, &bitmap);
@@ -1069,6 +1810,17 @@ bool kvm_irq_delivery_to_apic_fast(struct kvm *kvm, struct kvm_lapic *src,
 		for_each_set_bit(i, &bitmap, 16) {
 			if (!dst[i])
 				continue;
+			/*
+			 * 在以下使用kvm_apic_set_irq():
+			 *   - arch/x86/kvm/hyperv.c|828| <<stimer_notify_direct>> return !kvm_apic_set_irq(vcpu, &irq, NULL);
+			 *   - arch/x86/kvm/hyperv.c|1899| <<kvm_send_ipi_to_many>> kvm_apic_set_irq(vcpu, &irq, NULL);
+			 *   - arch/x86/kvm/irq_comm.c|94| <<kvm_irq_delivery_to_apic>> r += kvm_apic_set_irq(vcpu, irq, dest_map);
+			 *   - arch/x86/kvm/irq_comm.c|125| <<kvm_irq_delivery_to_apic>> r = kvm_apic_set_irq(lowest, irq, dest_map);
+			 *   - arch/x86/kvm/lapic.c|1218| <<__pv_send_ipi>> count += kvm_apic_set_irq(vcpu, irq, NULL);
+			 *   - arch/x86/kvm/lapic.c|1699| <<kvm_irq_delivery_to_apic_fast>> *r = kvm_apic_set_irq(src->vcpu, irq, dest_map);
+			 *   - arch/x86/kvm/lapic.c|1712| <<kvm_irq_delivery_to_apic_fast>> *r += kvm_apic_set_irq(dst[i]->vcpu, irq, dest_map);
+			 *   - arch/x86/kvm/x86.c|13639| <<kvm_arch_async_page_present>> kvm_apic_set_irq(vcpu, &irq, NULL);
+			 */
 			*r += kvm_apic_set_irq(dst[i]->vcpu, irq, dest_map);
 		}
 	}
@@ -1103,6 +1855,17 @@ bool kvm_intr_is_single_vcpu_fast(struct kvm *kvm, struct kvm_lapic_irq *irq,
 		return false;
 
 	rcu_read_lock();
+	/*
+	 * 在以下使用kvm_arch->apic_map:
+	 *   - arch/x86/kvm/lapic.c|581| <<kvm_recalculate_apic_map>> old = rcu_dereference_protected(kvm->arch.apic_map,
+	 *   - arch/x86/kvm/lapic.c|583| <<kvm_recalculate_apic_map>> rcu_assign_pointer(kvm->arch.apic_map, new);
+	 *   - arch/x86/kvm/lapic.c|1305| <<kvm_pv_send_ipi>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1772| <<kvm_irq_delivery_to_apic_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1825| <<kvm_intr_is_single_vcpu_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|2023| <<kvm_bitmap_or_dest_vcpus>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|9391| <<kvm_sched_yield>> map = rcu_dereference(vcpu->kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|13061| <<kvm_arch_destroy_vm>> kvfree(rcu_dereference_check(kvm->arch.apic_map, 1));
+	 */
 	map = rcu_dereference(kvm->arch.apic_map);
 
 	if (kvm_apic_map_get_dest_lapic(kvm, NULL, irq, map, &dst, &bitmap) &&
@@ -1119,6 +1882,54 @@ bool kvm_intr_is_single_vcpu_fast(struct kvm *kvm, struct kvm_lapic_irq *irq,
 	return ret;
 }
 
+/*
+ * 其他的:
+ * __apic_accept_irq
+ * __pv_send_ipi
+ * kvm_pv_send_ipi
+ * kvm_emulate_hypercall
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * __apic_accept_irq
+ * kvm_irq_delivery_to_apic
+ * kvm_apic_send_ipi
+ * kvm_x2apic_icr_write
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ */
+/*
+ * 关于RESCHEDULE_VECTOR (0xfd)
+ *
+ * __apic_accept_irq
+ * kvm_irq_delivery_to_apic_fast
+ * kvm_irq_delivery_to_apic
+ * kvm_apic_send_ipi
+ * kvm_x2apic_icr_write
+ * handle_fastpath_set_msr_irqoff
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ */
 /*
  * Add a pending IRQ into lapic.
  * Return 1 if successfully added and 0 if discarded.
@@ -1151,6 +1962,22 @@ static int __apic_accept_irq(struct kvm_lapic *apic, int delivery_mode,
 			dest_map->vectors[vcpu->vcpu_id] = vector;
 		}
 
+		/*
+		 * 在APIC中,TMR是Trigger Mode Register(触发方式寄存器),它的作用
+		 * 是记录每个中断向量是边沿触发还是电平触发.
+		 *
+		 * TMR[x] = 0 -> 中断向量x是边沿触发
+		 * TMR[x] = 1 -> 中断向量x是电平触发
+		 *
+		 * 对于边沿触发,中断发生后就结束,不再重复处理
+		 * 对于电平触发,需要在处理完成后确认信号已解除,
+		 * 否则中断会再次被触发(因为信号电平还在)
+		 *
+		 * 假设中断向量45是电平触发,那么:
+		 * TMR[45] = 1
+		 * 当中断控制器检测到45的信号为低电平时,会记录它在IRR(中断请求寄存器)中
+		 * 处理中断后,系统必须通知设备"我处理完了",否则设备保持信号为低电平,45 会一直被重复触发
+		 */
 		if (apic_test_vector(vector, apic->regs + APIC_TMR) != !!trig_mode) {
 			if (trig_mode)
 				kvm_lapic_set_vector(vector,
@@ -1237,6 +2064,17 @@ void kvm_bitmap_or_dest_vcpus(struct kvm *kvm, struct kvm_lapic_irq *irq,
 	bool ret;
 
 	rcu_read_lock();
+	/*
+	 * 在以下使用kvm_arch->apic_map:
+	 *   - arch/x86/kvm/lapic.c|581| <<kvm_recalculate_apic_map>> old = rcu_dereference_protected(kvm->arch.apic_map,
+	 *   - arch/x86/kvm/lapic.c|583| <<kvm_recalculate_apic_map>> rcu_assign_pointer(kvm->arch.apic_map, new);
+	 *   - arch/x86/kvm/lapic.c|1305| <<kvm_pv_send_ipi>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1772| <<kvm_irq_delivery_to_apic_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1825| <<kvm_intr_is_single_vcpu_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|2023| <<kvm_bitmap_or_dest_vcpus>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|9391| <<kvm_sched_yield>> map = rcu_dereference(vcpu->kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|13061| <<kvm_arch_destroy_vm>> kvfree(rcu_dereference_check(kvm->arch.apic_map, 1));
+	 */
 	map = rcu_dereference(kvm->arch.apic_map);
 
 	ret = kvm_apic_map_get_dest_lapic(kvm, &src, irq, map, &dest_vcpu,
@@ -1252,6 +2090,25 @@ void kvm_bitmap_or_dest_vcpus(struct kvm *kvm, struct kvm_lapic_irq *irq,
 		kvm_for_each_vcpu(i, vcpu, kvm) {
 			if (!kvm_apic_present(vcpu))
 				continue;
+			/*
+			 * 在以下调用kvm_apic_match_dest():
+			 *   - arch/x86/kvm/ioapic.c|146| <<__rtc_irq_eoi_tracking_restore_one>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, e->fields.dest_id, kvm_lapic_irq_dest_mode(!!e->fields.dest_mode)))
+			 *   - arch/x86/kvm/ioapic.c|234| <<ioapic_lazy_update_eoi>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, entry->fields.dest_id, entry->fields.dest_mode) ||
+			 *   - arch/x86/kvm/ioapic.c|414| <<kvm_ioapic_scan_entry>> if (kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, e->fields.dest_id, dm) ||
+			 *   - arch/x86/kvm/irq_comm.c|68| <<kvm_irq_delivery_to_apic>> if (!kvm_apic_match_dest(vcpu, src,
+			 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+			 *   - arch/x86/kvm/irq_comm.c|359| <<kvm_intr_is_single_vcpu>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+			 *   - arch/x86/kvm/irq_comm.c|442| <<kvm_scan_ioapic_routes>> if (irq.trig_mode && (kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, irq.dest_id, irq.dest_mode) ||
+			 *   - arch/x86/kvm/lapic.c|1262| <<kvm_bitmap_or_dest_vcpus>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+			 *   - arch/x86/kvm/svm/avic.c|461| <<avic_kick_target_vcpus>> if (kvm_apic_match_dest(vcpu, source,
+			 *          icrl & APIC_SHORT_MASK, dest, icrl & APIC_DEST_MASK)) {
+			 */
 			if (!kvm_apic_match_dest(vcpu, NULL,
 						 irq->shorthand,
 						 irq->dest_id,
@@ -1268,11 +2125,32 @@ int kvm_apic_compare_prio(struct kvm_vcpu *vcpu1, struct kvm_vcpu *vcpu2)
 	return vcpu1->arch.apic_arb_prio - vcpu2->arch.apic_arb_prio;
 }
 
+/*
+ * 在以下使用kvm_ioapic_handles_vector():
+ *   - arch/x86/kvm/lapic.c|1397| <<kvm_ioapic_send_eoi>> if (!kvm_ioapic_handles_vector(apic, vector))
+ *   - arch/x86/kvm/lapic.c|2972| <<apic_sync_pv_eoi_to_guest>> kvm_ioapic_handles_vector(apic, apic->highest_isr_cache)) {
+ */
 static bool kvm_ioapic_handles_vector(struct kvm_lapic *apic, int vector)
 {
+	/*
+	 * 在以下使用kvm_vcpu_arch->ioapic_handled_vectors:
+	 *   - arch/x86/kvm/lapic.c|1273| <<kvm_ioapic_handles_vector>> return test_bit(vector, apic->vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|9840| <<vcpu_scan_ioapic>> bitmap_zero(vcpu->arch.ioapic_handled_vectors, 256);
+	 *   - arch/x86/kvm/x86.c|9845| <<vcpu_scan_ioapic>> kvm_scan_ioapic_routes(vcpu, vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|9847| <<vcpu_scan_ioapic>> kvm_ioapic_scan_entry(vcpu, vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|9864| <<vcpu_load_eoi_exitmap>> bitmap_or((ulong *)eoi_exit_bitmap, vcpu->arch.ioapic_handled_vectors,
+	 *              to_hv_synic(vcpu)->vec_bitmap, 256);
+	 *   - arch/x86/kvm/x86.c|9871| <<vcpu_load_eoi_exitmap>> static_call(kvm_x86_load_eoi_exitmap)(vcpu, (u64 *)vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|10004| <<vcpu_enter_guest>> if (test_bit(vcpu->arch.pending_ioapic_eoi, vcpu->arch.ioapic_handled_vectors)) {
+	 */
 	return test_bit(vector, apic->vcpu->arch.ioapic_handled_vectors);
 }
 
+/*
+ * 在以下调用kvm_ioapic_send_eoi():
+ *   - arch/x86/kvm/lapic.c|1435| <<apic_set_eoi>> kvm_ioapic_send_eoi(apic, vector);
+ *   - arch/x86/kvm/lapic.c|1450| <<kvm_apic_set_eoi_accelerated>> kvm_ioapic_send_eoi(apic, vector);
+ */
 static void kvm_ioapic_send_eoi(struct kvm_lapic *apic, int vector)
 {
 	int trigger_mode;
@@ -1281,6 +2159,11 @@ static void kvm_ioapic_send_eoi(struct kvm_lapic *apic, int vector)
 	if (!kvm_ioapic_handles_vector(apic, vector))
 		return;
 
+	/*
+	 * on: KVM模拟全部
+	 * split: QEMU模拟IOAPIC和PIC,KVM模拟LAPIC
+	 * off:QEMU 模拟全部
+	 */
 	/* Request a KVM exit to inform the userspace IOAPIC. */
 	if (irqchip_split(apic->vcpu->kvm)) {
 		apic->vcpu->arch.pending_ioapic_eoi = vector;
@@ -1296,6 +2179,11 @@ static void kvm_ioapic_send_eoi(struct kvm_lapic *apic, int vector)
 	kvm_ioapic_update_eoi(apic->vcpu, vector, trigger_mode);
 }
 
+/*
+ * 在以下使用apic_set_eoi():
+ *   - arch/x86/kvm/lapic.c|2274| <<kvm_lapic_reg_write>> apic_set_eoi(apic);
+ *   - arch/x86/kvm/lapic.c|3015| <<apic_sync_pv_eoi_from_guest>> vector = apic_set_eoi(apic);
+ */
 static int apic_set_eoi(struct kvm_lapic *apic)
 {
 	int vector = apic_find_highest_isr(apic);
@@ -1309,7 +2197,20 @@ static int apic_set_eoi(struct kvm_lapic *apic)
 	if (vector == -1)
 		return vector;
 
+	/*
+	 * 只在此处调用apic_clear_isr()
+	 */
 	apic_clear_isr(vector, apic);
+	/*
+	 * 在以下使用apic_update_ppr():
+	 *   - arch/x86/kvm/lapic.c|1361| <<kvm_apic_update_ppr>> apic_update_ppr(vcpu->arch.apic);
+	 *   - arch/x86/kvm/lapic.c|1368| <<apic_set_tpr>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|1996| <<apic_set_eoi>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|2115| <<__apic_read>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|3544| <<kvm_lapic_reset>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|3816| <<kvm_get_apic_interrupt>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|4014| <<kvm_apic_set_state>> apic_update_ppr(apic);
+	 */
 	apic_update_ppr(apic);
 
 	if (to_hv_vcpu(apic->vcpu) &&
@@ -1386,6 +2287,10 @@ static u32 apic_get_tmcct(struct kvm_lapic *apic)
 	return tmcct;
 }
 
+/*
+ * 在以下使用__report_tpr_access():
+ *   - arch/x86/kvm/lapic.c|2064| <<report_tpr_access>> __report_tpr_access(apic, write);
+ */
 static void __report_tpr_access(struct kvm_lapic *apic, bool write)
 {
 	struct kvm_vcpu *vcpu = apic->vcpu;
@@ -1396,6 +2301,11 @@ static void __report_tpr_access(struct kvm_lapic *apic, bool write)
 	run->tpr_access.is_write = write;
 }
 
+/*
+ * 在以下使用report_tpr_access():
+ *   - arch/x86/kvm/lapic.c|2089| <<__apic_read(APIC_TASKPRI)>> report_tpr_access(apic, false);
+ *   - arch/x86/kvm/lapic.c|2821| <<kvm_lapic_reg_write(APIC_TASKPRI)>> report_tpr_access(apic, true);
+ */
 static inline void report_tpr_access(struct kvm_lapic *apic, bool write)
 {
 	if (apic->vcpu->arch.tpr_access_reporting)
@@ -1420,6 +2330,16 @@ static u32 __apic_read(struct kvm_lapic *apic, unsigned int offset)
 		val = apic_get_tmcct(apic);
 		break;
 	case APIC_PROCPRI:
+		/*
+		 * 在以下使用apic_update_ppr():
+		 *   - arch/x86/kvm/lapic.c|1361| <<kvm_apic_update_ppr>> apic_update_ppr(vcpu->arch.apic);
+		 *   - arch/x86/kvm/lapic.c|1368| <<apic_set_tpr>> apic_update_ppr(apic);
+		 *   - arch/x86/kvm/lapic.c|1996| <<apic_set_eoi>> apic_update_ppr(apic);
+		 *   - arch/x86/kvm/lapic.c|2115| <<__apic_read>> apic_update_ppr(apic);
+		 *   - arch/x86/kvm/lapic.c|3544| <<kvm_lapic_reset>> apic_update_ppr(apic);
+		 *   - arch/x86/kvm/lapic.c|3816| <<kvm_get_apic_interrupt>> apic_update_ppr(apic);
+		 *   - arch/x86/kvm/lapic.c|4014| <<kvm_apic_set_state>> apic_update_ppr(apic);
+		 */
 		apic_update_ppr(apic);
 		val = kvm_lapic_get_reg(apic, offset);
 		break;
@@ -1523,6 +2443,17 @@ static int apic_mmio_read(struct kvm_vcpu *vcpu, struct kvm_io_device *this,
 	if (!apic_mmio_in_range(apic, address))
 		return -EOPNOTSUPP;
 
+	/*
+	 * 在以下调用kvm_apic_hw_enabled():
+	 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+	 *   - arch/x86/kvm/lapic.c|2040| <<apic_mmio_read>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2125| <<lapic_timer_int_injected>> if (kvm_apic_hw_enabled(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2809| <<apic_mmio_write>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|3330| <<kvm_apic_local_deliver>> if (kvm_apic_hw_enabled(apic) && !(reg & APIC_LVT_MASKED)) {
+	 *   - arch/x86/kvm/lapic.c|3443| <<kvm_apic_accept_pic_intr>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 *   - arch/x86/kvm/lapic.h|246| <<kvm_apic_present>> return lapic_in_kernel(vcpu) && kvm_apic_hw_enabled(vcpu->arch.apic);
+	 *   - arch/x86/kvm/x86.c|10218| <<vcpu_load_eoi_exitmap>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 */
 	if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
 		if (!kvm_check_has_quirk(vcpu->kvm,
 					 KVM_X86_QUIRK_LAPIC_MMIO_HOLE))
@@ -1608,6 +2539,17 @@ static bool lapic_timer_int_injected(struct kvm_vcpu *vcpu)
 	struct kvm_lapic *apic = vcpu->arch.apic;
 	u32 reg = kvm_lapic_get_reg(apic, APIC_LVTT);
 
+	/*
+	 * 在以下调用kvm_apic_hw_enabled():
+	 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+	 *   - arch/x86/kvm/lapic.c|2040| <<apic_mmio_read>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2125| <<lapic_timer_int_injected>> if (kvm_apic_hw_enabled(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2809| <<apic_mmio_write>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|3330| <<kvm_apic_local_deliver>> if (kvm_apic_hw_enabled(apic) && !(reg & APIC_LVT_MASKED)) {
+	 *   - arch/x86/kvm/lapic.c|3443| <<kvm_apic_accept_pic_intr>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 *   - arch/x86/kvm/lapic.h|246| <<kvm_apic_present>> return lapic_in_kernel(vcpu) && kvm_apic_hw_enabled(vcpu->arch.apic);
+	 *   - arch/x86/kvm/x86.c|10218| <<vcpu_load_eoi_exitmap>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 */
 	if (kvm_apic_hw_enabled(apic)) {
 		int vec = reg & APIC_VECTOR_MASK;
 		void *bitmap = apic->regs + APIC_ISR;
@@ -1678,6 +2620,13 @@ static void __kvm_wait_lapic_expire(struct kvm_vcpu *vcpu)
 	tsc_deadline = apic->lapic_timer.expired_tscdeadline;
 	apic->lapic_timer.expired_tscdeadline = 0;
 	guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	/*
+	 * 在以下使用kvm_timer->advance_expire_delta:
+	 *   - arch/x86/kvm/lapic.c|2382| <<__kvm_wait_lapic_expire>> apic->lapic_timer.advance_expire_delta = guest_tsc - tsc_deadline;
+	 *   - arch/x86/kvm/lapic.c|2385| <<__kvm_wait_lapic_expire>> adjust_lapic_timer_advance(vcpu, apic->lapic_timer.advance_expire_delta);
+	 *   - arch/x86/kvm/x86.c|10872| <<vcpu_enter_guest>> s64 delta = vcpu->arch.apic->lapic_timer.advance_expire_delta;
+	 *   - arch/x86/kvm/x86.c|10875| <<vcpu_enter_guest>> vcpu->arch.apic->lapic_timer.advance_expire_delta = S64_MIN;
+	 */
 	apic->lapic_timer.advance_expire_delta = guest_tsc - tsc_deadline;
 
 	if (lapic_timer_advance_dynamic) {
@@ -2033,6 +2982,10 @@ void kvm_lapic_switch_to_sw_timer(struct kvm_vcpu *vcpu)
 }
 EXPORT_SYMBOL_GPL(kvm_lapic_switch_to_sw_timer);
 
+/*
+ * 在以下使用kvm_lapic_restart_hv_timer():
+ *   - arch/x86/kvm/x86.c|4546| <<kvm_arch_vcpu_load>> kvm_lapic_restart_hv_timer(vcpu);
+ */
 void kvm_lapic_restart_hv_timer(struct kvm_vcpu *vcpu)
 {
 	struct kvm_lapic *apic = vcpu->arch.apic;
@@ -2070,6 +3023,44 @@ static void apic_manage_nmi_watchdog(struct kvm_lapic *apic, u32 lvt0_val)
 	}
 }
 
+/*
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_vcpu_reset
+ * kvm_apic_accept_events
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_lapic_reg_write
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ *
+ * 在以下调用kvm_lapic_reg_write():
+ *   - arch/x86/kvm/lapic.c|2638| <<apic_mmio_write>> kvm_lapic_reg_write(apic, offset & 0xff0, val);
+ *   - arch/x86/kvm/lapic.c|2645| <<kvm_lapic_set_eoi>> kvm_lapic_reg_write(vcpu->arch.apic, APIC_EOI, 0);
+ *   - arch/x86/kvm/lapic.c|2667| <<kvm_apic_write_nodecode>> kvm_lapic_reg_write(apic, offset, (u32)val);
+ *   - arch/x86/kvm/lapic.c|3496| <<kvm_lapic_msr_write>> return kvm_lapic_reg_write(apic, reg, (u32)data);
+ *   - arch/x86/kvm/svm/avic.c|665| <<avic_unaccel_trap_write>> kvm_lapic_reg_write(apic, offset, kvm_lapic_get_reg(apic, offset));
+ */
 int kvm_lapic_reg_write(struct kvm_lapic *apic, u32 reg, u32 val)
 {
 	int ret = 0;
@@ -2079,6 +3070,12 @@ int kvm_lapic_reg_write(struct kvm_lapic *apic, u32 reg, u32 val)
 	switch (reg) {
 	case APIC_ID:		/* Local APIC ID */
 		if (!apic_x2apic_mode(apic)) {
+			/*
+			 * 在以下使用kvm_apic_set_xapic_id():
+			 *   - arch/x86/kvm/lapic.c|2455| <<kvm_lapic_reg_write(APIC_ID)>> kvm_apic_set_xapic_id(apic, val >> 24);
+			 *   - arch/x86/kvm/lapic.c|2756| <<kvm_lapic_set_base>> kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
+			 *   - arch/x86/kvm/lapic.c|2871| <<kvm_lapic_reset>> kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
+			 */
 			kvm_apic_set_xapic_id(apic, val >> 24);
 		} else {
 			ret = 1;
@@ -2155,6 +3152,15 @@ int kvm_lapic_reg_write(struct kvm_lapic *apic, u32 reg, u32 val)
 		size_t size;
 		u32 index;
 
+		/*
+		 * 在以下使用kvm_apic_sw_enabled():
+		 *   - arch/x86/kvm/irq_comm.c|95| <<kvm_irq_delivery_to_apic>> } else if (kvm_apic_sw_enabled(vcpu->arch.apic)) {
+		 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+		 *   - arch/x86/kvm/lapic.c|424| <<kvm_recalculate_apic_map>> if (!kvm_apic_sw_enabled(apic))
+		 *   - arch/x86/kvm/lapic.c|2720| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+		 *   - arch/x86/kvm/lapic.c|2731| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+		 *   - arch/x86/kvm/lapic.h|251| <<kvm_lapic_enabled>> return kvm_apic_present(vcpu) && kvm_apic_sw_enabled(vcpu->arch.apic);
+		 */
 		if (!kvm_apic_sw_enabled(apic))
 			val |= APIC_LVT_MASKED;
 		size = ARRAY_SIZE(apic_lvt_mask);
@@ -2166,6 +3172,15 @@ int kvm_lapic_reg_write(struct kvm_lapic *apic, u32 reg, u32 val)
 	}
 
 	case APIC_LVTT:
+		/*
+		 * 在以下使用kvm_apic_sw_enabled():
+		 *   - arch/x86/kvm/irq_comm.c|95| <<kvm_irq_delivery_to_apic>> } else if (kvm_apic_sw_enabled(vcpu->arch.apic)) {
+		 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+		 *   - arch/x86/kvm/lapic.c|424| <<kvm_recalculate_apic_map>> if (!kvm_apic_sw_enabled(apic))
+		 *   - arch/x86/kvm/lapic.c|2720| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+		 *   - arch/x86/kvm/lapic.c|2731| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+		 *   - arch/x86/kvm/lapic.h|251| <<kvm_lapic_enabled>> return kvm_apic_present(vcpu) && kvm_apic_sw_enabled(vcpu->arch.apic);
+		 */
 		if (!kvm_apic_sw_enabled(apic))
 			val |= APIC_LVT_MASKED;
 		val &= (apic_lvt_mask[0] | apic->lapic_timer.timer_mode_mask);
@@ -2220,6 +3235,14 @@ int kvm_lapic_reg_write(struct kvm_lapic *apic, u32 reg, u32 val)
 	 * was toggled, the APIC ID changed, etc...   The maps are marked dirty
 	 * on relevant changes, i.e. this is a nop for most writes.
 	 */
+	/*
+	 * 在以下调用kvm_recalculate_apic_map():
+	 *   - arch/x86/kvm/lapic.c|2441| <<kvm_lapic_reg_write>> kvm_recalculate_apic_map(apic->vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|2718| <<kvm_lapic_reset>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|2995| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|3001| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/x86.c|493| <<kvm_set_apic_base>> kvm_recalculate_apic_map(vcpu->kvm);
+	 */
 	kvm_recalculate_apic_map(apic->vcpu->kvm);
 
 	return ret;
@@ -2236,6 +3259,17 @@ static int apic_mmio_write(struct kvm_vcpu *vcpu, struct kvm_io_device *this,
 	if (!apic_mmio_in_range(apic, address))
 		return -EOPNOTSUPP;
 
+	/*
+	 * 在以下调用kvm_apic_hw_enabled():
+	 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+	 *   - arch/x86/kvm/lapic.c|2040| <<apic_mmio_read>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2125| <<lapic_timer_int_injected>> if (kvm_apic_hw_enabled(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2809| <<apic_mmio_write>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|3330| <<kvm_apic_local_deliver>> if (kvm_apic_hw_enabled(apic) && !(reg & APIC_LVT_MASKED)) {
+	 *   - arch/x86/kvm/lapic.c|3443| <<kvm_apic_accept_pic_intr>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 *   - arch/x86/kvm/lapic.h|246| <<kvm_apic_present>> return lapic_in_kernel(vcpu) && kvm_apic_hw_enabled(vcpu->arch.apic);
+	 *   - arch/x86/kvm/x86.c|10218| <<vcpu_load_eoi_exitmap>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 */
 	if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
 		if (!kvm_check_has_quirk(vcpu->kvm,
 					 KVM_X86_QUIRK_LAPIC_MMIO_HOLE))
@@ -2254,6 +3288,14 @@ static int apic_mmio_write(struct kvm_vcpu *vcpu, struct kvm_io_device *this,
 
 	val = *(u32*)data;
 
+	/*
+	 * 在以下调用kvm_lapic_reg_write():
+	 *   - arch/x86/kvm/lapic.c|2638| <<apic_mmio_write>> kvm_lapic_reg_write(apic, offset & 0xff0, val);
+	 *   - arch/x86/kvm/lapic.c|2645| <<kvm_lapic_set_eoi>> kvm_lapic_reg_write(vcpu->arch.apic, APIC_EOI, 0);
+	 *   - arch/x86/kvm/lapic.c|2667| <<kvm_apic_write_nodecode>> kvm_lapic_reg_write(apic, offset, (u32)val);
+	 *   - arch/x86/kvm/lapic.c|3496| <<kvm_lapic_msr_write>> return kvm_lapic_reg_write(apic, reg, (u32)data);
+	 *   - arch/x86/kvm/svm/avic.c|665| <<avic_unaccel_trap_write>> kvm_lapic_reg_write(apic, offset, kvm_lapic_get_reg(apic, offset));
+	 */
 	kvm_lapic_reg_write(apic, offset & 0xff0, val);
 
 	return 0;
@@ -2261,6 +3303,14 @@ static int apic_mmio_write(struct kvm_vcpu *vcpu, struct kvm_io_device *this,
 
 void kvm_lapic_set_eoi(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下调用kvm_lapic_reg_write():
+	 *   - arch/x86/kvm/lapic.c|2638| <<apic_mmio_write>> kvm_lapic_reg_write(apic, offset & 0xff0, val);
+	 *   - arch/x86/kvm/lapic.c|2645| <<kvm_lapic_set_eoi>> kvm_lapic_reg_write(vcpu->arch.apic, APIC_EOI, 0);
+	 *   - arch/x86/kvm/lapic.c|2667| <<kvm_apic_write_nodecode>> kvm_lapic_reg_write(apic, offset, (u32)val);
+	 *   - arch/x86/kvm/lapic.c|3496| <<kvm_lapic_msr_write>> return kvm_lapic_reg_write(apic, reg, (u32)data);
+	 *   - arch/x86/kvm/svm/avic.c|665| <<avic_unaccel_trap_write>> kvm_lapic_reg_write(apic, offset, kvm_lapic_get_reg(apic, offset));
+	 */
 	kvm_lapic_reg_write(vcpu->arch.apic, APIC_EOI, 0);
 }
 EXPORT_SYMBOL_GPL(kvm_lapic_set_eoi);
@@ -2283,6 +3333,14 @@ void kvm_apic_write_nodecode(struct kvm_vcpu *vcpu, u32 offset)
 	} else {
 		/* TODO: optimize to just emulate side effect w/o one more write */
 		val = kvm_lapic_get_reg(apic, offset);
+		/*
+		 * 在以下调用kvm_lapic_reg_write():
+		 *   - arch/x86/kvm/lapic.c|2638| <<apic_mmio_write>> kvm_lapic_reg_write(apic, offset & 0xff0, val);
+		 *   - arch/x86/kvm/lapic.c|2645| <<kvm_lapic_set_eoi>> kvm_lapic_reg_write(vcpu->arch.apic, APIC_EOI, 0);
+		 *   - arch/x86/kvm/lapic.c|2667| <<kvm_apic_write_nodecode>> kvm_lapic_reg_write(apic, offset, (u32)val);
+		 *   - arch/x86/kvm/lapic.c|3496| <<kvm_lapic_msr_write>> return kvm_lapic_reg_write(apic, reg, (u32)data);
+		 *   - arch/x86/kvm/svm/avic.c|665| <<avic_unaccel_trap_write>> kvm_lapic_reg_write(apic, offset, kvm_lapic_get_reg(apic, offset));
+		 */
 		kvm_lapic_reg_write(apic, offset, (u32)val);
 	}
 }
@@ -2300,6 +3358,13 @@ void kvm_free_lapic(struct kvm_vcpu *vcpu)
 	if (!(vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE))
 		static_branch_slow_dec_deferred(&apic_hw_disabled);
 
+	/*
+	 * 在以下使用kvm_lapic->sw_enabled:
+	 *   - arch/x86/kvm/lapic.c|474| <<apic_set_spiv>> if (enabled != apic->sw_enabled) {
+	 *   - arch/x86/kvm/lapic.c|475| <<apic_set_spiv>> apic->sw_enabled = enabled;
+	 *   - arch/x86/kvm/lapic.c|2899| <<kvm_free_lapic>> if (!apic->sw_enabled)
+	 *   - arch/x86/kvm/lapic.h|260| <<kvm_apic_sw_enabled>> return apic->sw_enabled;
+	 */
 	if (!apic->sw_enabled)
 		static_branch_slow_dec_deferred(&apic_sw_disabled);
 
@@ -2350,13 +3415,135 @@ u64 kvm_lapic_get_cr8(struct kvm_vcpu *vcpu)
 	return (tpr & 0xf0) >> 4;
 }
 
+/*
+ * virsh hot-add的时候一共调用五次.
+ *
+ * 185171  185801  CPU 17/KVM      kvm_lapic_set_base
+ * 185171  185801  CPU 17/KVM      kvm_lapic_set_base
+ * 185171  185801  CPU 17/KVM      kvm_lapic_set_base
+ * 185171  185801  CPU 17/KVM      kvm_lapic_set_base
+ * 185171  185801  CPU 17/KVM      kvm_lapic_set_base
+ *
+ * kvm_lapic_set_base
+ * kvm_lapic_reset
+ * kvm_vcpu_reset
+ * kvm_arch_vcpu_create
+ * kvm_vm_ioctl_create_vcpu
+ * kvm_vm_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * kvm_lapic_set_base
+ * kvm_set_apic_base
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_arch_vcpu_ioctl
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * kvm_lapic_set_base
+ * kvm_set_apic_base
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * kvm_lapic_set_base
+ * kvm_set_apic_base
+ * __set_sregs_common.constprop.0
+ * kvm_arch_vcpu_ioctl
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * kvm_lapic_set_base
+ * kvm_apic_set_state
+ * kvm_arch_vcpu_ioctl
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ *
+ * 这是另外的一组.
+ *
+ * kvm_lapic_set_base
+ * kvm_set_apic_base
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_arch_vcpu_ioctl
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * kvm_lapic_set_base
+ * kvm_set_apic_base
+ * __set_sregs_common.constprop.0
+ * kvm_arch_vcpu_ioctl
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * kvm_lapic_set_base
+ * kvm_set_apic_base
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * kvm_lapic_set_base
+ * kvm_apic_set_state
+ * kvm_arch_vcpu_ioctl
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ *
+ * 在以下使用kvm_lapic_set_base():
+ *   - arch/x86/kvm/lapic.c|2661| <<kvm_lapic_reset>> kvm_lapic_set_base(vcpu, msr_val);
+ *   - arch/x86/kvm/lapic.c|2989| <<kvm_apic_set_state>> kvm_lapic_set_base(vcpu, vcpu->arch.apic_base);
+ *   - arch/x86/kvm/x86.c|492| <<kvm_set_apic_base>> kvm_lapic_set_base(vcpu, msr_info->data);
+ */
 void kvm_lapic_set_base(struct kvm_vcpu *vcpu, u64 value)
 {
 	u64 old_value = vcpu->arch.apic_base;
 	struct kvm_lapic *apic = vcpu->arch.apic;
 
+	/*
+	 * 在以下设置kvm_vcpu_arch->apic_base (看似修改的地方):
+	 *   - arch/x86/kvm/lapic.c|2926| <<kvm_lapic_set_base>> vcpu->arch.apic_base = value;
+	 *   - arch/x86/kvm/lapic.c|3256| <<kvm_create_lapic>> vcpu->arch.apic_base = MSR_IA32_APICBASE_ENABLE;
+	 *
+	 * struct kvm_vcpu:
+	 * -> struct kvm_vcpu_arch arch;
+	 *    -> u64 apic_base;
+	 */
 	vcpu->arch.apic_base = value;
 
+	/*
+	 * 如果新旧不同的bit里有MSR_IA32_APICBASE_ENABLE ...
+	 */
 	if ((old_value ^ value) & MSR_IA32_APICBASE_ENABLE)
 		kvm_update_cpuid_runtime(vcpu);
 
@@ -2365,13 +3552,53 @@ void kvm_lapic_set_base(struct kvm_vcpu *vcpu, u64 value)
 
 	/* update jump label if enable bit changes */
 	if ((old_value ^ value) & MSR_IA32_APICBASE_ENABLE) {
+		/*
+		 * 如果新的value是enable
+		 */
 		if (value & MSR_IA32_APICBASE_ENABLE) {
+			/*
+			 * 在以下使用kvm_apic_set_xapic_id():
+			 *   - arch/x86/kvm/lapic.c|2455| <<kvm_lapic_reg_write(APIC_ID)>> kvm_apic_set_xapic_id(apic, val >> 24);
+			 *   - arch/x86/kvm/lapic.c|2756| <<kvm_lapic_set_base>> kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
+			 *   - arch/x86/kvm/lapic.c|2871| <<kvm_lapic_reset>> kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
+			 */
 			kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
+			/*
+			 * 在以下使用apic_hw_disabled:
+			 *   - arch/x86/kvm/lapic.c|190| <<global>> __read_mostly DEFINE_STATIC_KEY_DEFERRED_FALSE(apic_hw_disabled, HZ);
+			 *   - arch/x86/kvm/lapic.c|3253| <<kvm_free_lapic>> static_branch_slow_dec_deferred(&apic_hw_disabled);
+			 *   - arch/x86/kvm/lapic.c|3460| <<kvm_lapic_set_base>> static_branch_slow_dec_deferred(&apic_hw_disabled);
+			 *   - arch/x86/kvm/lapic.c|3472| <<kvm_lapic_set_base>> static_branch_inc(&apic_hw_disabled.key);
+			 *   - arch/x86/kvm/lapic.c|4580| <<kvm_lapic_exit>> static_key_deferred_flush(&apic_hw_disabled);
+			 *   - arch/x86/kvm/lapic.c|4581| <<kvm_lapic_exit>> WARN_ON(static_branch_unlikely(&apic_hw_disabled.key));
+			 *   - arch/x86/kvm/lapic.h|290| <<kvm_apic_hw_enabled>> if (static_branch_unlikely(&apic_hw_disabled.key))
+			 */
 			static_branch_slow_dec_deferred(&apic_hw_disabled);
+			/*
+			 * 在以下使用KVM_REQ_APF_READY:
+			 *   - arch/x86/kvm/lapic.c|621| <<apic_set_spiv>> kvm_make_request(KVM_REQ_APF_READY, apic->vcpu);
+			 *   - arch/x86/kvm/lapic.c|3303| <<kvm_lapic_set_base>> kvm_make_request(KVM_REQ_APF_READY, vcpu);
+			 *   - arch/x86/kvm/x86.c|13246| <<kvm_arch_async_page_present_queued>> kvm_make_request(KVM_REQ_APF_READY, vcpu);
+			 *
+			 * 处理的函数kvm_check_async_pf_completion()
+			 */
 			/* Check if there are APF page ready requests pending */
 			kvm_make_request(KVM_REQ_APF_READY, vcpu);
 		} else {
 			static_branch_inc(&apic_hw_disabled.key);
+			/*
+			 * 在以下使用kvm_arch->apic_map_dirty:
+			 *   - arch/x86/kvm/lapic.c|279| <<kvm_recalculate_apic_map>> if (atomic_read_acquire(&kvm->arch.apic_map_dirty) == CLEAN)
+			 *   - arch/x86/kvm/lapic.c|290| <<kvm_recalculate_apic_map>> if (atomic_cmpxchg_acquire(&kvm->arch.apic_map_dirty,
+			 *   - arch/x86/kvm/lapic.c|378| <<kvm_recalculate_apic_map>> atomic_cmpxchg_release(&kvm->arch.apic_map_dirty,
+			 *   - arch/x86/kvm/lapic.c|401| <<apic_set_spiv>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+			 *   - arch/x86/kvm/lapic.c|441| <<kvm_apic_set_xapic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+			 *   - arch/x86/kvm/lapic.c|447| <<kvm_apic_set_ldr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+			 *   - arch/x86/kvm/lapic.c|453| <<kvm_apic_set_dfr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+			 *   - arch/x86/kvm/lapic.c|496| <<kvm_apic_set_x2apic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+			 *   - arch/x86/kvm/lapic.c|2862| <<kvm_lapic_set_base>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+			 *   - arch/x86/kvm/lapic.c|3370| <<kvm_apic_set_state>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+			 */
 			atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
 		}
 	}
@@ -2394,13 +3621,44 @@ void kvm_lapic_set_base(struct kvm_vcpu *vcpu, u64 value)
 	}
 }
 
+/*
+ * 在以下使用kvm_apic_update_apicv():
+ *   - arch/x86/kvm/lapic.c|2828| <<kvm_lapic_reset>> kvm_apic_update_apicv(vcpu);
+ *   - arch/x86/kvm/lapic.c|3192| <<kvm_apic_set_state>> kvm_apic_update_apicv(vcpu);
+ *   - arch/x86/kvm/x86.c|9877| <<kvm_vcpu_update_apicv>> kvm_apic_update_apicv(vcpu);
+ */
 void kvm_apic_update_apicv(struct kvm_vcpu *vcpu)
 {
 	struct kvm_lapic *apic = vcpu->arch.apic;
 
 	if (vcpu->arch.apicv_active) {
+		/*
+		 * 在以下使用kvm_lapic->irr_pending:
+		 *   - arch/x86/kvm/lapic.c|530| <<kvm_apic_update_irr>> apic->irr_pending = true;
+		 *   - arch/x86/kvm/lapic.c|548| <<apic_find_highest_irr>> if (!apic->irr_pending)
+		 *   - arch/x86/kvm/lapic.c|569| <<apic_clear_irr>> apic->irr_pending = false;
+		 *   - arch/x86/kvm/lapic.c|572| <<apic_clear_irr>> apic->irr_pending = true;
+		 *   - arch/x86/kvm/lapic.c|2519| <<kvm_apic_update_apicv>> apic->irr_pending = true;
+		 *   - arch/x86/kvm/lapic.c|2968| <<apic_sync_pv_eoi_to_guest>> apic->irr_pending ||
+		 *   - arch/x86/kvm/lapic.h|154| <<kvm_lapic_set_irr>> apic->irr_pending = true;
+		 *   - arch/x86/kvm/svm/avic.c|434| <<avic_kick_target_vcpus_fast>> target_vcpu->arch.apic->irr_pending = true;
+		 *   - arch/x86/kvm/svm/avic.c|482| <<avic_kick_target_vcpus>> vcpu->arch.apic->irr_pending = true;
+		 *
+		 * 理论上来说:
+		 * irr_pending is always true when apicv is activated.
+		 */
 		/* irr_pending is always true when apicv is activated. */
 		apic->irr_pending = true;
+		/*
+		 * 在以下使用kvm_lapic->isr_count:
+		 *   - arch/x86/kvm/lapic.c|657| <<apic_set_isr>> ++apic->isr_count;
+		 *   - arch/x86/kvm/lapic.c|658| <<apic_set_isr>> BUG_ON(apic->isr_count > MAX_APIC_VECTOR);
+		 *   - arch/x86/kvm/lapic.c|684| <<apic_find_highest_isr>> if (!apic->isr_count)
+		 *   - arch/x86/kvm/lapic.c|718| <<apic_clear_isr>> --apic->isr_count;
+		 *   - arch/x86/kvm/lapic.c|719| <<apic_clear_isr>> BUG_ON(apic->isr_count < 0);
+		 *   - arch/x86/kvm/lapic.c|2631| <<kvm_apic_update_apicv>> apic->isr_count = 1;
+		 *   - arch/x86/kvm/lapic.c|2639| <<kvm_apic_update_apicv>> apic->isr_count = count_vectors(apic->regs + APIC_ISR);
+		 */
 		apic->isr_count = 1;
 	} else {
 		/*
@@ -2411,16 +3669,53 @@ void kvm_apic_update_apicv(struct kvm_vcpu *vcpu)
 		 */
 		apic->isr_count = count_vectors(apic->regs + APIC_ISR);
 	}
+	/*
+	 * 在以下使用kvm_lapic->highest_isr_cache:
+	 *   - arch/x86/kvm/lapic.c|675| <<apic_set_isr>> apic->highest_isr_cache = vec;
+	 *   - arch/x86/kvm/lapic.c|697| <<apic_find_highest_isr>> if (likely(apic->highest_isr_cache != -1))
+	 *   - arch/x86/kvm/lapic.c|698| <<apic_find_highest_isr>> return apic->highest_isr_cache;
+	 *   - arch/x86/kvm/lapic.c|734| <<apic_clear_isr>> apic->highest_isr_cache = -1;
+	 *   - arch/x86/kvm/lapic.c|2669| <<kvm_apic_update_apicv>> apic->highest_isr_cache = -1;
+	 *   - arch/x86/kvm/lapic.c|3170| <<apic_sync_pv_eoi_to_guest>> apic->highest_isr_cache == -1 ||
+	 *   - arch/x86/kvm/lapic.c|3172| <<apic_sync_pv_eoi_to_guest>> kvm_ioapic_handles_vector(apic, apic->highest_isr_cache)) {
+	 */
 	apic->highest_isr_cache = -1;
 }
 EXPORT_SYMBOL_GPL(kvm_apic_update_apicv);
 
+/*
+ * init_event = 0
+ * [0] kvm_lapic_reset
+ * [0] kvm_vcpu_reset
+ * [0] kvm_arch_vcpu_create
+ * [0] kvm_vm_ioctl
+ * [0] __x64_sys_ioctl
+ * [0] do_syscall_64
+ * [0] entry_SYSCALL_64_after_hwframe
+ *
+ * init_event = 1
+ * [0] kvm_lapic_reset
+ * [0] kvm_vcpu_reset
+ * [0] kvm_apic_accept_events
+ * [0] kvm_arch_vcpu_ioctl_run
+ * [0] kvm_vcpu_ioctl
+ * [0] __x64_sys_ioctl
+ * [0] do_syscall_64
+ * [0] entry_SYSCALL_64_after_hwframe
+ *
+ *
+ * 在以下使用kvm_lapic_reset():
+ *  - arch/x86/kvm/x86.c|11672| <<kvm_vcpu_reset>> kvm_lapic_reset(vcpu, init_event);
+ */
 void kvm_lapic_reset(struct kvm_vcpu *vcpu, bool init_event)
 {
 	struct kvm_lapic *apic = vcpu->arch.apic;
 	u64 msr_val;
 	int i;
 
+	/*
+	 * 只有kvm_arch_vcpu_create()的时候init_event是false
+	 */
 	if (!init_event) {
 		msr_val = APIC_DEFAULT_PHYS_BASE | MSR_IA32_APICBASE_ENABLE;
 		if (kvm_vcpu_is_reset_bsp(vcpu))
@@ -2434,6 +3729,12 @@ void kvm_lapic_reset(struct kvm_vcpu *vcpu, bool init_event)
 	/* Stop the timer in case it's a reset to an active apic */
 	hrtimer_cancel(&apic->lapic_timer.timer);
 
+	/*
+	 * 在以下使用kvm_apic_set_xapic_id():
+	 *   - arch/x86/kvm/lapic.c|2455| <<kvm_lapic_reg_write(APIC_ID)>> kvm_apic_set_xapic_id(apic, val >> 24);
+	 *   - arch/x86/kvm/lapic.c|2756| <<kvm_lapic_set_base>> kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
+	 *   - arch/x86/kvm/lapic.c|2871| <<kvm_lapic_reset>> kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
+	 */
 	/* The xAPIC ID is set at RESET even if the APIC was already enabled. */
 	if (!init_event)
 		kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
@@ -2467,21 +3768,72 @@ void kvm_lapic_reset(struct kvm_vcpu *vcpu, bool init_event)
 		kvm_lapic_set_reg(apic, APIC_ISR + 0x10 * i, 0);
 		kvm_lapic_set_reg(apic, APIC_TMR + 0x10 * i, 0);
 	}
+	/*
+	 * 在以下使用kvm_apic_update_apicv():
+	 *   - arch/x86/kvm/lapic.c|2828| <<kvm_lapic_reset>> kvm_apic_update_apicv(vcpu);
+	 *   - arch/x86/kvm/lapic.c|3192| <<kvm_apic_set_state>> kvm_apic_update_apicv(vcpu);
+	 *   - arch/x86/kvm/x86.c|9877| <<kvm_vcpu_update_apicv>> kvm_apic_update_apicv(vcpu);
+	 */
 	kvm_apic_update_apicv(vcpu);
 	update_divide_count(apic);
 	atomic_set(&apic->lapic_timer.pending, 0);
 
 	vcpu->arch.pv_eoi.msr_val = 0;
+	/*
+	 * 在以下使用apic_update_ppr():
+	 *   - arch/x86/kvm/lapic.c|1361| <<kvm_apic_update_ppr>> apic_update_ppr(vcpu->arch.apic);
+	 *   - arch/x86/kvm/lapic.c|1368| <<apic_set_tpr>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|1996| <<apic_set_eoi>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|2115| <<__apic_read>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|3544| <<kvm_lapic_reset>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|3816| <<kvm_get_apic_interrupt>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|4014| <<kvm_apic_set_state>> apic_update_ppr(apic);
+	 */
 	apic_update_ppr(apic);
 	if (vcpu->arch.apicv_active) {
+		/*
+		 * vmx_apicv_post_state_restore()
+		 */
 		static_call(kvm_x86_apicv_post_state_restore)(vcpu);
+		/*
+		 * vmx_hwapic_irr_update()
+		 */
 		static_call(kvm_x86_hwapic_irr_update)(vcpu, -1);
+		/*
+		 * 在以下调用kvm_x86_hwapic_isr_update:
+		 *   - arch/x86/kvm/lapic.c|1003| <<apic_set_isr>> static_call(kvm_x86_hwapic_isr_update)(vcpu, vec);
+		 *   - arch/x86/kvm/lapic.c|1129| <<apic_clear_isr>> static_call(kvm_x86_hwapic_isr_update)(vcpu, apic_find_highest_isr(apic));
+		 *   - arch/x86/kvm/lapic.c|3622| <<kvm_lapic_reset>> static_call(kvm_x86_hwapic_isr_update)(vcpu, -1);
+		 *   - arch/x86/kvm/lapic.c|4127| <<kvm_apic_set_state>> static_call(kvm_x86_hwapic_isr_update)(vcpu, apic_find_highest_isr(apic));
+		 *
+		 * vmx_hwapic_isr_update()
+		 */
 		static_call(kvm_x86_hwapic_isr_update)(vcpu, -1);
 	}
 
 	vcpu->arch.apic_arb_prio = 0;
 	vcpu->arch.apic_attention = 0;
 
+	/*
+	 * __kvm_set_or_clear_apicv_inhibit
+	 * __kvm_set_or_clear_apicv_inhibit
+	 * kvm_set_or_clear_apicv_inhibit
+	 * kvm_recalculate_apic_map
+	 * kvm_vcpu_reset
+	 * kvm_apic_accept_events
+	 * kvm_arch_vcpu_ioctl_run
+	 * kvm_vcpu_ioctl
+	 * __x64_sys_ioctl
+	 * do_syscall_64
+	 * entry_SYSCALL_64_after_hwframe
+	 *
+	 * 在以下调用kvm_recalculate_apic_map():
+	 *   - arch/x86/kvm/lapic.c|2441| <<kvm_lapic_reg_write>> kvm_recalculate_apic_map(apic->vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|2718| <<kvm_lapic_reset>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|2995| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|3001| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/x86.c|493| <<kvm_set_apic_base>> kvm_recalculate_apic_map(vcpu->kvm);
+	 */
 	kvm_recalculate_apic_map(vcpu->kvm);
 }
 
@@ -2512,6 +3864,17 @@ int kvm_apic_local_deliver(struct kvm_lapic *apic, int lvt_type)
 	int vector, mode, trig_mode;
 	int r;
 
+	/*
+	 * 在以下调用kvm_apic_hw_enabled():
+	 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+	 *   - arch/x86/kvm/lapic.c|2040| <<apic_mmio_read>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2125| <<lapic_timer_int_injected>> if (kvm_apic_hw_enabled(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2809| <<apic_mmio_write>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|3330| <<kvm_apic_local_deliver>> if (kvm_apic_hw_enabled(apic) && !(reg & APIC_LVT_MASKED)) {
+	 *   - arch/x86/kvm/lapic.c|3443| <<kvm_apic_accept_pic_intr>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 *   - arch/x86/kvm/lapic.h|246| <<kvm_apic_present>> return lapic_in_kernel(vcpu) && kvm_apic_hw_enabled(vcpu->arch.apic);
+	 *   - arch/x86/kvm/x86.c|10218| <<vcpu_load_eoi_exitmap>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 */
 	if (kvm_apic_hw_enabled(apic) && !(reg & APIC_LVT_MASKED)) {
 		vector = reg & APIC_VECTOR_MASK;
 		mode = reg & APIC_MODE_MASK;
@@ -2590,6 +3953,17 @@ int kvm_create_lapic(struct kvm_vcpu *vcpu, int timer_advance_ns)
 	 * apic_hw_disabled; the full RESET value is set by kvm_lapic_reset().
 	 */
 	vcpu->arch.apic_base = MSR_IA32_APICBASE_ENABLE;
+	/*
+	 * 在以下使用apic_sw_disabled:
+	 *   - arch/x86/kvm/lapic.c|191| <<global>> __read_mostly DEFINE_STATIC_KEY_DEFERRED_FALSE(apic_sw_disabled, HZ);
+	 *   - arch/x86/kvm/lapic.c|599| <<apic_set_spiv>> static_branch_slow_dec_deferred(&apic_sw_disabled);
+	 *   - arch/x86/kvm/lapic.c|601| <<apic_set_spiv>> static_branch_inc(&apic_sw_disabled.key);
+	 *   - arch/x86/kvm/lapic.c|3263| <<kvm_free_lapic>> static_branch_slow_dec_deferred(&apic_sw_disabled);
+	 *   - arch/x86/kvm/lapic.c|3840| <<kvm_create_lapic>> static_branch_inc(&apic_sw_disabled.key);
+	 *   - arch/x86/kvm/lapic.c|4582| <<kvm_lapic_exit>> static_key_deferred_flush(&apic_sw_disabled);
+	 *   - arch/x86/kvm/lapic.c|4583| <<kvm_lapic_exit>> WARN_ON(static_branch_unlikely(&apic_sw_disabled.key));
+	 *   - arch/x86/kvm/lapic.h|315| <<kvm_apic_sw_enabled>> if (static_branch_unlikely(&apic_sw_disabled.key))
+	 */
 	static_branch_inc(&apic_sw_disabled.key); /* sw disabled at reset */
 	kvm_iodevice_init(&apic->dev, &apic_mmio_ops);
 
@@ -2601,6 +3975,13 @@ int kvm_create_lapic(struct kvm_vcpu *vcpu, int timer_advance_ns)
 	return -ENOMEM;
 }
 
+/*
+ * 在以下使用kvm_apic_has_interrupt():
+ *   - arch/x86/kvm/irq.c|86| <<kvm_cpu_has_injectable_intr>> return kvm_apic_has_interrupt(v) != -1;
+ *   - arch/x86/kvm/irq.c|99| <<kvm_cpu_has_interrupt>> return kvm_apic_has_interrupt(v) != -1;
+ *   - arch/x86/kvm/lapic.c|2841| <<kvm_get_apic_interrupt>> int vector = kvm_apic_has_interrupt(vcpu);
+ *   - arch/x86/kvm/vmx/nested.c|3627| <<nested_vmx_run>> kvm_apic_has_interrupt(vcpu) == vmx->nested.posted_intr_nv) {
+ */
 int kvm_apic_has_interrupt(struct kvm_vcpu *vcpu)
 {
 	struct kvm_lapic *apic = vcpu->arch.apic;
@@ -2609,7 +3990,22 @@ int kvm_apic_has_interrupt(struct kvm_vcpu *vcpu)
 	if (!kvm_apic_present(vcpu))
 		return -1;
 
+	/*
+	 * 在以下使用__apic_update_ppr():
+	 *   - arch/x86/kvm/lapic.c|1266| <<apic_update_ppr>> if (__apic_update_ppr(apic, &ppr) &&
+	 *   - arch/x86/kvm/lapic.c|3587| <<kvm_apic_has_interrupt>> __apic_update_ppr(apic, &ppr);
+	 *   - arch/x86/kvm/lapic.c|3672| <<kvm_get_apic_interrupt>> __apic_update_ppr(apic, &ppr);
+	 *
+	 * 什么也不修改
+	 */
 	__apic_update_ppr(apic, &ppr);
+	/*
+	 * 在以下使用apic_has_interrupt_for_ppr():
+	 *   - arch/x86/kvm/lapic.c|1342| <<apic_update_ppr>> apic_has_interrupt_for_ppr(apic, ppr) != -1)
+	 *   - arch/x86/kvm/lapic.c|3716| <<kvm_apic_has_interrupt>> return apic_has_interrupt_for_ppr(apic, ppr);
+	 *
+	 * 等同调用vmx_sync_pir_to_irr()
+	 */
 	return apic_has_interrupt_for_ppr(apic, ppr);
 }
 EXPORT_SYMBOL_GPL(kvm_apic_has_interrupt);
@@ -2618,6 +4014,17 @@ int kvm_apic_accept_pic_intr(struct kvm_vcpu *vcpu)
 {
 	u32 lvt0 = kvm_lapic_get_reg(vcpu->arch.apic, APIC_LVT0);
 
+	/*
+	 * 在以下调用kvm_apic_hw_enabled():
+	 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+	 *   - arch/x86/kvm/lapic.c|2040| <<apic_mmio_read>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2125| <<lapic_timer_int_injected>> if (kvm_apic_hw_enabled(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2809| <<apic_mmio_write>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|3330| <<kvm_apic_local_deliver>> if (kvm_apic_hw_enabled(apic) && !(reg & APIC_LVT_MASKED)) {
+	 *   - arch/x86/kvm/lapic.c|3443| <<kvm_apic_accept_pic_intr>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 *   - arch/x86/kvm/lapic.h|246| <<kvm_apic_present>> return lapic_in_kernel(vcpu) && kvm_apic_hw_enabled(vcpu->arch.apic);
+	 *   - arch/x86/kvm/x86.c|10218| <<vcpu_load_eoi_exitmap>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 */
 	if (!kvm_apic_hw_enabled(vcpu->arch.apic))
 		return 1;
 	if ((lvt0 & APIC_LVT_MASKED) == 0 &&
@@ -2636,8 +4043,27 @@ void kvm_inject_apic_timer_irqs(struct kvm_vcpu *vcpu)
 	}
 }
 
+/*
+ * 在以下调用kvm_get_apic_interrupt():
+ *   - arch/x86/kvm/irq.c|138| <<kvm_cpu_get_interrupt>> return kvm_get_apic_interrupt(v);
+ *
+ * vcpu_enter_guest()
+ * -> inject_pending_event()
+ *    -> kvm_cpu_get_interrupt()
+ *       -> kvm_get_apic_interrupt()
+ *          -> apic_set_isr()
+ *
+ * 这个函数会把IRR的bit移动到ISR.
+ */
 int kvm_get_apic_interrupt(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用kvm_apic_has_interrupt():
+	 *   - arch/x86/kvm/irq.c|86| <<kvm_cpu_has_injectable_intr>> return kvm_apic_has_interrupt(v) != -1;
+	 *   - arch/x86/kvm/irq.c|99| <<kvm_cpu_has_interrupt>> return kvm_apic_has_interrupt(v) != -1;
+	 *   - arch/x86/kvm/lapic.c|2841| <<kvm_get_apic_interrupt>> int vector = kvm_apic_has_interrupt(vcpu);
+	 *   - arch/x86/kvm/vmx/nested.c|3627| <<nested_vmx_run>> kvm_apic_has_interrupt(vcpu) == vmx->nested.posted_intr_nv) {
+	 */
 	int vector = kvm_apic_has_interrupt(vcpu);
 	struct kvm_lapic *apic = vcpu->arch.apic;
 	u32 ppr;
@@ -2652,6 +4078,9 @@ int kvm_get_apic_interrupt(struct kvm_vcpu *vcpu)
 	 * because the process would deliver it through the IDT.
 	 */
 
+	/*
+	 * 从irr上清空
+	 */
 	apic_clear_irr(vector, apic);
 	if (to_hv_vcpu(vcpu) && test_bit(vector, to_hv_synic(vcpu)->auto_eoi_bitmap)) {
 		/*
@@ -2659,6 +4088,16 @@ int kvm_get_apic_interrupt(struct kvm_vcpu *vcpu)
 		 * interrupt above PPR, so check whether to raise another
 		 * KVM_REQ_EVENT.
 		 */
+		/*
+		 * 在以下使用apic_update_ppr():
+		 *   - arch/x86/kvm/lapic.c|1361| <<kvm_apic_update_ppr>> apic_update_ppr(vcpu->arch.apic);
+		 *   - arch/x86/kvm/lapic.c|1368| <<apic_set_tpr>> apic_update_ppr(apic);
+		 *   - arch/x86/kvm/lapic.c|1996| <<apic_set_eoi>> apic_update_ppr(apic);
+		 *   - arch/x86/kvm/lapic.c|2115| <<__apic_read>> apic_update_ppr(apic);
+		 *   - arch/x86/kvm/lapic.c|3544| <<kvm_lapic_reset>> apic_update_ppr(apic);
+		 *   - arch/x86/kvm/lapic.c|3816| <<kvm_get_apic_interrupt>> apic_update_ppr(apic);
+		 *   - arch/x86/kvm/lapic.c|4014| <<kvm_apic_set_state>> apic_update_ppr(apic);
+		 */
 		apic_update_ppr(apic);
 	} else {
 		/*
@@ -2667,13 +4106,33 @@ int kvm_get_apic_interrupt(struct kvm_vcpu *vcpu)
 		 * a concurrent interrupt injection, but that would have
 		 * triggered KVM_REQ_EVENT already.
 		 */
+		/*
+		 * 这里set了ISR!
+		 * 只在这一个地方调用
+		 */
 		apic_set_isr(vector, apic);
+		/*
+		 * 在以下使用__apic_update_ppr():
+		 *   - arch/x86/kvm/lapic.c|1266| <<apic_update_ppr>> if (__apic_update_ppr(apic, &ppr) &&
+		 *   - arch/x86/kvm/lapic.c|3587| <<kvm_apic_has_interrupt>> __apic_update_ppr(apic, &ppr);
+		 *   - arch/x86/kvm/lapic.c|3672| <<kvm_get_apic_interrupt>> __apic_update_ppr(apic, &ppr);
+		 */
 		__apic_update_ppr(apic, &ppr);
 	}
 
 	return vector;
 }
 
+/*
+ * 在以下调用kvm_apic_state_fixup():
+ *   - arch/x86/kvm/lapic.c|3114| <<kvm_apic_get_state>> return kvm_apic_state_fixup(vcpu, s, false);
+ *   - arch/x86/kvm/lapic.c|3136| <<kvm_apic_set_state>> r = kvm_apic_state_fixup(vcpu, s, true);
+ *
+ * #define KVM_APIC_REG_SIZE 0x400
+ * struct kvm_lapic_state {
+ *     char regs[KVM_APIC_REG_SIZE];
+ * };
+ */
 static int kvm_apic_state_fixup(struct kvm_vcpu *vcpu,
 		struct kvm_lapic_state *s, bool set)
 {
@@ -2682,6 +4141,17 @@ static int kvm_apic_state_fixup(struct kvm_vcpu *vcpu,
 		u32 *ldr = (u32 *)(s->regs + APIC_LDR);
 		u64 icr;
 
+		/*
+		 * 在以下使用kvm_arch->x2apic_format:
+		 *   - arch/x86/kvm/irq_comm.c|137| <<kvm_set_msi_irq>> trace_kvm_msi_set_irq(msg.address_lo | (kvm->arch.x2apic_format ?
+		 *   - arch/x86/kvm/irq_comm.c|140| <<kvm_set_msi_irq>> irq->dest_id = x86_msi_msg_get_destid(&msg, kvm->arch.x2apic_format);
+		 *   - arch/x86/kvm/irq_comm.c|154| <<kvm_msi_route_invalid>> return kvm->arch.x2apic_format && (e->msi.address_hi & 0xff);
+		 *   - arch/x86/kvm/lapic.c|3673| <<kvm_apic_state_fixup>> if (vcpu->kvm->arch.x2apic_format) {
+		 *   - arch/x86/kvm/x86.c|5933| <<kvm_vm_ioctl_enable_cap>> kvm->arch.x2apic_format = true;
+		 *
+		 *     x2apic_format = false,
+		 *     x2apic_broadcast_quirk_disabled = false,
+		 */
 		if (vcpu->kvm->arch.x2apic_format) {
 			if (*id != vcpu->vcpu_id)
 				return -EINVAL;
@@ -2723,29 +4193,119 @@ int kvm_apic_get_state(struct kvm_vcpu *vcpu, struct kvm_lapic_state *s)
 	__kvm_lapic_set_reg(s->regs, APIC_TMCCT,
 			    __apic_read(vcpu->arch.apic, APIC_TMCCT));
 
+	/*
+	 * 在以下调用kvm_apic_state_fixup():
+	 *   - arch/x86/kvm/lapic.c|3114| <<kvm_apic_get_state>> return kvm_apic_state_fixup(vcpu, s, false);
+	 *   - arch/x86/kvm/lapic.c|3136| <<kvm_apic_set_state>> r = kvm_apic_state_fixup(vcpu, s, true);
+	 */
 	return kvm_apic_state_fixup(vcpu, s, false);
 }
 
+/*
+ * 在以下使用kvm_apic_set_state():
+ *   - arch/x86/kvm/x86.c|4654| <<kvm_vcpu_ioctl_set_lapic>> r = kvm_apic_set_state(vcpu, s);
+ *
+ * 根据测试, 只在add的时候调用:
+ * kvm_apic_set_state
+ * kvm_arch_vcpu_ioctl
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * kvm_arch_vcpu_ioctl(KVM_SET_LAPIC)
+ * -> kvm_vcpu_ioctl_set_lapic()
+ *    -> kvm_apic_set_state()
+ *       -> kvm_recalculate_apic_map() -> 只有kvm_apic_state_fixup() > 0的时候
+ *       -> kvm_recalculate_apic_map()
+ */
 int kvm_apic_set_state(struct kvm_vcpu *vcpu, struct kvm_lapic_state *s)
 {
 	struct kvm_lapic *apic = vcpu->arch.apic;
 	int r;
 
+	/*
+	 * 在以下设置kvm_vcpu_arch->apic_base (看似修改的地方):
+	 *   - arch/x86/kvm/lapic.c|2926| <<kvm_lapic_set_base>> vcpu->arch.apic_base = value;
+	 *   - arch/x86/kvm/lapic.c|3256| <<kvm_create_lapic>> vcpu->arch.apic_base = MSR_IA32_APICBASE_ENABLE;
+	 *
+	 *
+	 * 在以下使用kvm_lapic_set_base():
+	 *   - arch/x86/kvm/lapic.c|2661| <<kvm_lapic_reset>> kvm_lapic_set_base(vcpu, msr_val);
+	 *   - arch/x86/kvm/lapic.c|2989| <<kvm_apic_set_state>> kvm_lapic_set_base(vcpu, vcpu->arch.apic_base);
+	 *   - arch/x86/kvm/x86.c|492| <<kvm_set_apic_base>> kvm_lapic_set_base(vcpu, msr_info->data);
+	 *
+	 * 这一行在2024年被删掉了.
+	 * 8166d25579120590ad0ec4ece02afd00a3c54f6a
+	 * KVM: x86: Drop superfluous kvm_lapic_set_base() call when setting APIC state
+	 */
 	kvm_lapic_set_base(vcpu, vcpu->arch.apic_base);
+	/*
+	 * #define KVM_APIC_REG_SIZE 0x400
+	 * struct kvm_lapic_state {
+	 *     char regs[KVM_APIC_REG_SIZE];
+	 * };
+	 */
 	/* set SPIV separately to get count of SW disabled APICs right */
 	apic_set_spiv(apic, *((u32 *)(s->regs + APIC_SPIV)));
 
+	/*
+	 * 在以下调用kvm_apic_state_fixup():
+	 *   - arch/x86/kvm/lapic.c|3114| <<kvm_apic_get_state>> return kvm_apic_state_fixup(vcpu, s, false);
+	 *   - arch/x86/kvm/lapic.c|3136| <<kvm_apic_set_state>> r = kvm_apic_state_fixup(vcpu, s, true);
+	 *
+	 * 这里fix的是s里面的!
+	 */
 	r = kvm_apic_state_fixup(vcpu, s, true);
 	if (r) {
+		/*
+		 * 在以下调用kvm_recalculate_apic_map():
+		 *   - arch/x86/kvm/lapic.c|2441| <<kvm_lapic_reg_write>> kvm_recalculate_apic_map(apic->vcpu->kvm);
+		 *   - arch/x86/kvm/lapic.c|2718| <<kvm_lapic_reset>> kvm_recalculate_apic_map(vcpu->kvm);
+		 *   - arch/x86/kvm/lapic.c|2995| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+		 *   - arch/x86/kvm/lapic.c|3001| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+		 *   - arch/x86/kvm/x86.c|493| <<kvm_set_apic_base>> kvm_recalculate_apic_map(vcpu->kvm);
+		 */
 		kvm_recalculate_apic_map(vcpu->kvm);
 		return r;
 	}
 	memcpy(vcpu->arch.apic->regs, s->regs, sizeof(*s));
 
+	/*
+	 * 在以下使用kvm_arch->apic_map_dirty:
+	 *   - arch/x86/kvm/lapic.c|279| <<kvm_recalculate_apic_map>> if (atomic_read_acquire(&kvm->arch.apic_map_dirty) == CLEAN)
+	 *   - arch/x86/kvm/lapic.c|290| <<kvm_recalculate_apic_map>> if (atomic_cmpxchg_acquire(&kvm->arch.apic_map_dirty,
+	 *   - arch/x86/kvm/lapic.c|378| <<kvm_recalculate_apic_map>> atomic_cmpxchg_release(&kvm->arch.apic_map_dirty,
+	 *   - arch/x86/kvm/lapic.c|401| <<apic_set_spiv>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|441| <<kvm_apic_set_xapic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|447| <<kvm_apic_set_ldr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|453| <<kvm_apic_set_dfr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|496| <<kvm_apic_set_x2apic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|2862| <<kvm_lapic_set_base>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|3370| <<kvm_apic_set_state>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 */
 	atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	/*
+	 * 在以下调用kvm_recalculate_apic_map():
+	 *   - arch/x86/kvm/lapic.c|2441| <<kvm_lapic_reg_write>> kvm_recalculate_apic_map(apic->vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|2718| <<kvm_lapic_reset>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|2995| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|3001| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/x86.c|493| <<kvm_set_apic_base>> kvm_recalculate_apic_map(vcpu->kvm);
+	 */
 	kvm_recalculate_apic_map(vcpu->kvm);
 	kvm_apic_set_version(vcpu);
 
+	/*
+	 * 在以下使用apic_update_ppr():
+	 *   - arch/x86/kvm/lapic.c|1361| <<kvm_apic_update_ppr>> apic_update_ppr(vcpu->arch.apic);
+	 *   - arch/x86/kvm/lapic.c|1368| <<apic_set_tpr>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|1996| <<apic_set_eoi>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|2115| <<__apic_read>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|3544| <<kvm_lapic_reset>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|3816| <<kvm_get_apic_interrupt>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|4014| <<kvm_apic_set_state>> apic_update_ppr(apic);
+	 */
 	apic_update_ppr(apic);
 	cancel_apic_timer(apic);
 	apic->lapic_timer.expired_tscdeadline = 0;
@@ -2754,11 +4314,32 @@ int kvm_apic_set_state(struct kvm_vcpu *vcpu, struct kvm_lapic_state *s)
 	update_divide_count(apic);
 	__start_apic_timer(apic, APIC_TMCCT);
 	kvm_lapic_set_reg(apic, APIC_TMCCT, 0);
+	/*
+	 * 在以下使用kvm_apic_update_apicv():
+	 *   - arch/x86/kvm/lapic.c|2828| <<kvm_lapic_reset>> kvm_apic_update_apicv(vcpu);
+	 *   - arch/x86/kvm/lapic.c|3192| <<kvm_apic_set_state>> kvm_apic_update_apicv(vcpu);
+	 *   - arch/x86/kvm/x86.c|9877| <<kvm_vcpu_update_apicv>> kvm_apic_update_apicv(vcpu);
+	 */
 	kvm_apic_update_apicv(vcpu);
 	if (vcpu->arch.apicv_active) {
+		/*
+		 * vmx_apicv_post_state_restore()
+		 */
 		static_call(kvm_x86_apicv_post_state_restore)(vcpu);
+		/*
+		 * 在以下调用kvm_x86_hwapic_isr_update:
+		 *   - arch/x86/kvm/lapic.c|1003| <<apic_set_isr>> static_call(kvm_x86_hwapic_isr_update)(vcpu, vec);
+		 *   - arch/x86/kvm/lapic.c|1129| <<apic_clear_isr>> static_call(kvm_x86_hwapic_isr_update)(vcpu, apic_find_highest_isr(apic));
+		 *   - arch/x86/kvm/lapic.c|3622| <<kvm_lapic_reset>> static_call(kvm_x86_hwapic_isr_update)(vcpu, -1);
+		 *   - arch/x86/kvm/lapic.c|4127| <<kvm_apic_set_state>> static_call(kvm_x86_hwapic_isr_update)(vcpu, apic_find_highest_isr(apic));
+		 *
+		 * vmx_hwapic_irr_update()
+		 */
 		static_call(kvm_x86_hwapic_irr_update)(vcpu,
 				apic_find_highest_irr(apic));
+		/*
+		 * vmx_hwapic_isr_update()
+		 */
 		static_call(kvm_x86_hwapic_isr_update)(vcpu,
 				apic_find_highest_isr(apic));
 	}
@@ -2821,6 +4402,11 @@ static void apic_sync_pv_eoi_from_guest(struct kvm_vcpu *vcpu,
 	trace_kvm_pv_eoi(apic, vector);
 }
 
+/*
+ * 在以下调用kvm_lapic_sync_from_vapic():
+ *   - arch/x86/kvm/x86.c|10896| <<vcpu_enter_guest>> kvm_lapic_sync_from_vapic(vcpu);
+ *   - arch/x86/kvm/x86.c|10927| <<vcpu_enter_guest>> kvm_lapic_sync_from_vapic(vcpu);
+ */
 void kvm_lapic_sync_from_vapic(struct kvm_vcpu *vcpu)
 {
 	u32 data;
@@ -2847,6 +4433,21 @@ void kvm_lapic_sync_from_vapic(struct kvm_vcpu *vcpu)
 static void apic_sync_pv_eoi_to_guest(struct kvm_vcpu *vcpu,
 					struct kvm_lapic *apic)
 {
+	/*
+	 * 在以下使用kvm_lapic->irr_pending:
+	 *   - arch/x86/kvm/lapic.c|530| <<kvm_apic_update_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|548| <<apic_find_highest_irr>> if (!apic->irr_pending)
+	 *   - arch/x86/kvm/lapic.c|569| <<apic_clear_irr>> apic->irr_pending = false;
+	 *   - arch/x86/kvm/lapic.c|572| <<apic_clear_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|2519| <<kvm_apic_update_apicv>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|2968| <<apic_sync_pv_eoi_to_guest>> apic->irr_pending ||
+	 *   - arch/x86/kvm/lapic.h|154| <<kvm_lapic_set_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/svm/avic.c|434| <<avic_kick_target_vcpus_fast>> target_vcpu->arch.apic->irr_pending = true;
+	 *   - arch/x86/kvm/svm/avic.c|482| <<avic_kick_target_vcpus>> vcpu->arch.apic->irr_pending = true;
+	 *
+	 * 理论上来说:
+	 * irr_pending is always true when apicv is activated.
+	 */
 	if (!pv_eoi_enabled(vcpu) ||
 	    /* IRR set or many bits in ISR: could be nested. */
 	    apic->irr_pending ||
@@ -2945,6 +4546,14 @@ static int kvm_lapic_msr_write(struct kvm_lapic *apic, u32 reg, u64 data)
 	if (data >> 32)
 		return 1;
 
+	/*
+	 * 在以下调用kvm_lapic_reg_write():
+	 *   - arch/x86/kvm/lapic.c|2638| <<apic_mmio_write>> kvm_lapic_reg_write(apic, offset & 0xff0, val);
+	 *   - arch/x86/kvm/lapic.c|2645| <<kvm_lapic_set_eoi>> kvm_lapic_reg_write(vcpu->arch.apic, APIC_EOI, 0);
+	 *   - arch/x86/kvm/lapic.c|2667| <<kvm_apic_write_nodecode>> kvm_lapic_reg_write(apic, offset, (u32)val);
+	 *   - arch/x86/kvm/lapic.c|3496| <<kvm_lapic_msr_write>> return kvm_lapic_reg_write(apic, reg, (u32)data);
+	 *   - arch/x86/kvm/svm/avic.c|665| <<avic_unaccel_trap_write>> kvm_lapic_reg_write(apic, offset, kvm_lapic_get_reg(apic, offset));
+	 */
 	return kvm_lapic_reg_write(apic, reg, (u32)data);
 }
 
@@ -3010,6 +4619,13 @@ int kvm_lapic_enable_pv_eoi(struct kvm_vcpu *vcpu, u64 data, unsigned long len)
 	return kvm_gfn_to_hva_cache_init(vcpu->kvm, ghc, addr, new_len);
 }
 
+/*
+ * 在以下使用kvm_apic_accept_events():
+ *   - arch/x86/kvm/x86.c|10552| <<vcpu_enter_guest>> r = kvm_apic_accept_events(vcpu);
+ *   - arch/x86/kvm/x86.c|10877| <<vcpu_block>> if (kvm_apic_accept_events(vcpu) < 0)
+ *   - arch/x86/kvm/x86.c|11077| <<kvm_arch_vcpu_ioctl_run>> if (kvm_apic_accept_events(vcpu) < 0) {
+ *   - arch/x86/kvm/x86.c|11313| <<kvm_arch_vcpu_ioctl_get_mpstate>> r = kvm_apic_accept_events(vcpu);
+ */
 int kvm_apic_accept_events(struct kvm_vcpu *vcpu)
 {
 	struct kvm_lapic *apic = vcpu->arch.apic;
@@ -3058,6 +4674,15 @@ int kvm_apic_accept_events(struct kvm_vcpu *vcpu)
 
 	if (test_bit(KVM_APIC_INIT, &pe)) {
 		clear_bit(KVM_APIC_INIT, &apic->pending_events);
+		/*
+		 * 在以下使用:
+		 *   - arch/x86/kvm/lapic.c|3537| <<kvm_apic_accept_events>> kvm_vcpu_reset(vcpu, true);
+		 *   - arch/x86/kvm/svm/svm.c|2230| <<shutdown_interception>> kvm_vcpu_reset(vcpu, true);
+		 *   - arch/x86/kvm/x86.c|11655| <<kvm_arch_vcpu_create>> kvm_vcpu_reset(vcpu, false);
+		 *
+		 * 只在VM里面online/offline也会调用kvm_vcpu_reset()
+		 * online的时候调用
+		 */
 		kvm_vcpu_reset(vcpu, true);
 		if (kvm_vcpu_is_bsp(apic->vcpu))
 			vcpu->arch.mp_state = KVM_MP_STATE_RUNNABLE;
diff --git a/arch/x86/kvm/lapic.h b/arch/x86/kvm/lapic.h
index ee42eef92f32..b4f0409e362f 100644
--- a/arch/x86/kvm/lapic.h
+++ b/arch/x86/kvm/lapic.h
@@ -38,6 +38,13 @@ struct kvm_timer {
 	u64 tscdeadline;
 	u64 expired_tscdeadline;
 	u32 timer_advance_ns;
+	/*
+	 * 在以下使用kvm_timer->advance_expire_delta:
+	 *   - arch/x86/kvm/lapic.c|2382| <<__kvm_wait_lapic_expire>> apic->lapic_timer.advance_expire_delta = guest_tsc - tsc_deadline;
+	 *   - arch/x86/kvm/lapic.c|2385| <<__kvm_wait_lapic_expire>> adjust_lapic_timer_advance(vcpu, apic->lapic_timer.advance_expire_delta);
+	 *   - arch/x86/kvm/x86.c|10872| <<vcpu_enter_guest>> s64 delta = vcpu->arch.apic->lapic_timer.advance_expire_delta;
+	 *   - arch/x86/kvm/x86.c|10875| <<vcpu_enter_guest>> vcpu->arch.apic->lapic_timer.advance_expire_delta = S64_MIN;
+	 */
 	s64 advance_expire_delta;
 	atomic_t pending;			/* accumulated triggered timers */
 	bool hv_timer_in_use;
@@ -49,11 +56,53 @@ struct kvm_lapic {
 	struct kvm_timer lapic_timer;
 	u32 divide_count;
 	struct kvm_vcpu *vcpu;
+	/*
+	 * 在以下使用kvm_lapic->sw_enabled:
+	 *   - arch/x86/kvm/lapic.c|474| <<apic_set_spiv>> if (enabled != apic->sw_enabled) {
+	 *   - arch/x86/kvm/lapic.c|475| <<apic_set_spiv>> apic->sw_enabled = enabled;
+	 *   - arch/x86/kvm/lapic.c|2899| <<kvm_free_lapic>> if (!apic->sw_enabled)
+	 *   - arch/x86/kvm/lapic.h|260| <<kvm_apic_sw_enabled>> return apic->sw_enabled;
+	 */
 	bool sw_enabled;
+	/*
+	 * 在以下使用kvm_lapic->irr_pending:
+	 *   - arch/x86/kvm/lapic.c|530| <<kvm_apic_update_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|548| <<apic_find_highest_irr>> if (!apic->irr_pending)
+	 *   - arch/x86/kvm/lapic.c|569| <<apic_clear_irr>> apic->irr_pending = false;
+	 *   - arch/x86/kvm/lapic.c|572| <<apic_clear_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|2519| <<kvm_apic_update_apicv>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|2968| <<apic_sync_pv_eoi_to_guest>> apic->irr_pending ||
+	 *   - arch/x86/kvm/lapic.h|154| <<kvm_lapic_set_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/svm/avic.c|434| <<avic_kick_target_vcpus_fast>> target_vcpu->arch.apic->irr_pending = true;
+	 *   - arch/x86/kvm/svm/avic.c|482| <<avic_kick_target_vcpus>> vcpu->arch.apic->irr_pending = true;
+	 *
+	 * 理论上来说:
+	 * irr_pending is always true when apicv is activated.
+	 */
 	bool irr_pending;
 	bool lvt0_in_nmi_mode;
+	/*
+	 * 在以下使用kvm_lapic->isr_count:
+	 *   - arch/x86/kvm/lapic.c|657| <<apic_set_isr>> ++apic->isr_count;
+	 *   - arch/x86/kvm/lapic.c|658| <<apic_set_isr>> BUG_ON(apic->isr_count > MAX_APIC_VECTOR);
+	 *   - arch/x86/kvm/lapic.c|684| <<apic_find_highest_isr>> if (!apic->isr_count)
+	 *   - arch/x86/kvm/lapic.c|718| <<apic_clear_isr>> --apic->isr_count;
+	 *   - arch/x86/kvm/lapic.c|719| <<apic_clear_isr>> BUG_ON(apic->isr_count < 0);
+	 *   - arch/x86/kvm/lapic.c|2631| <<kvm_apic_update_apicv>> apic->isr_count = 1;
+	 *   - arch/x86/kvm/lapic.c|2639| <<kvm_apic_update_apicv>> apic->isr_count = count_vectors(apic->regs + APIC_ISR);
+	 */
 	/* Number of bits set in ISR. */
 	s16 isr_count;
+	/*
+	 * 在以下使用kvm_lapic->highest_isr_cache:
+	 *   - arch/x86/kvm/lapic.c|675| <<apic_set_isr>> apic->highest_isr_cache = vec;
+	 *   - arch/x86/kvm/lapic.c|697| <<apic_find_highest_isr>> if (likely(apic->highest_isr_cache != -1))
+	 *   - arch/x86/kvm/lapic.c|698| <<apic_find_highest_isr>> return apic->highest_isr_cache;
+	 *   - arch/x86/kvm/lapic.c|734| <<apic_clear_isr>> apic->highest_isr_cache = -1;
+	 *   - arch/x86/kvm/lapic.c|2669| <<kvm_apic_update_apicv>> apic->highest_isr_cache = -1;
+	 *   - arch/x86/kvm/lapic.c|3170| <<apic_sync_pv_eoi_to_guest>> apic->highest_isr_cache == -1 ||
+	 *   - arch/x86/kvm/lapic.c|3172| <<apic_sync_pv_eoi_to_guest>> kvm_ioapic_handles_vector(apic, apic->highest_isr_cache)) {
+	 */
 	/* The highest vector set in ISR; if -1 - invalid, must scan ISR. */
 	int highest_isr_cache;
 	/**
@@ -147,6 +196,21 @@ static inline void kvm_lapic_set_vector(int vec, void *bitmap)
 static inline void kvm_lapic_set_irr(int vec, struct kvm_lapic *apic)
 {
 	kvm_lapic_set_vector(vec, apic->regs + APIC_IRR);
+	/*
+	 * 在以下使用kvm_lapic->irr_pending:
+	 *   - arch/x86/kvm/lapic.c|530| <<kvm_apic_update_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|548| <<apic_find_highest_irr>> if (!apic->irr_pending)
+	 *   - arch/x86/kvm/lapic.c|569| <<apic_clear_irr>> apic->irr_pending = false;
+	 *   - arch/x86/kvm/lapic.c|572| <<apic_clear_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|2519| <<kvm_apic_update_apicv>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|2968| <<apic_sync_pv_eoi_to_guest>> apic->irr_pending ||
+	 *   - arch/x86/kvm/lapic.h|154| <<kvm_lapic_set_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/svm/avic.c|434| <<avic_kick_target_vcpus_fast>> target_vcpu->arch.apic->irr_pending = true;
+	 *   - arch/x86/kvm/svm/avic.c|482| <<avic_kick_target_vcpus>> vcpu->arch.apic->irr_pending = true;
+	 *
+	 * 理论上来说:
+	 * irr_pending is always true when apicv is activated.
+	 */
 	/*
 	 * irr_pending must be true if any interrupt is pending; set it after
 	 * APIC_IRR to avoid race with apic_clear_irr
@@ -173,10 +237,66 @@ static inline bool lapic_in_kernel(struct kvm_vcpu *vcpu)
 	return true;
 }
 
+/*
+ * | 项目                 | MSR_IA32_APICBASE       | SPIV (0xF0)                |
+ * | ------------------ | ------------------------- | -------------------------- |
+ * | 控制粒度               | 硬件级,全局关闭                  | 软件级,关闭中断处理                 |
+ * | 生效范围               | 关闭整个 Local APIC           | 保留结构但不响应中断                 |
+ * | 通常使用时机             | BIOS,操作系统启动阶段             | 操作系统运行时                    |
+ * | 会影响 APIC MMIO 寄存器吗 | 是,APIC 基址无效后不能访问 APIC 寄存器 | 否,仍然可访问 APIC 寄存器           |
+ * | 对中断的影响             | 完全禁用中断(包括 INIT, STARTUP)  | 仅禁用普通中断,某些特殊中断(如 NMI)有效    |
+ * | 典型用途               | 内核初始化前设置,关闭 SMP 支持        | 操作系统禁用中断(如使用 IOAPIC 或 PIC) |
+ *
+ *
+ * 如果你只把SPIV 的使能位关掉(即SPIV[8]=0),CPU不会响应普通中断,但Local APIC结构还在,
+ * 依然可以接收INIT或IPI等特殊信号.
+ *
+ * 如果你把MSR_IA32_APICBASE[11]=0,则整个Local APIC被禁用,APIC MMIO区也不能访问,
+ * 连 INIT,STARTUP都可能无法正确使用.
+ */
+
 extern struct static_key_false_deferred apic_hw_disabled;
 
+/*
+ * 在以下调用kvm_apic_hw_enabled():
+ *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+ *   - arch/x86/kvm/lapic.c|2040| <<apic_mmio_read>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+ *   - arch/x86/kvm/lapic.c|2125| <<lapic_timer_int_injected>> if (kvm_apic_hw_enabled(apic)) {
+ *   - arch/x86/kvm/lapic.c|2809| <<apic_mmio_write>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+ *   - arch/x86/kvm/lapic.c|3330| <<kvm_apic_local_deliver>> if (kvm_apic_hw_enabled(apic) && !(reg & APIC_LVT_MASKED)) {
+ *   - arch/x86/kvm/lapic.c|3443| <<kvm_apic_accept_pic_intr>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+ *   - arch/x86/kvm/lapic.h|246| <<kvm_apic_present>> return lapic_in_kernel(vcpu) && kvm_apic_hw_enabled(vcpu->arch.apic);
+ *   - arch/x86/kvm/x86.c|10218| <<vcpu_load_eoi_exitmap>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+ */
 static inline int kvm_apic_hw_enabled(struct kvm_lapic *apic)
 {
+	/*
+	 * 在以下使用apic_hw_disabled:
+	 *   - arch/x86/kvm/lapic.c|190| <<global>> __read_mostly DEFINE_STATIC_KEY_DEFERRED_FALSE(apic_hw_disabled, HZ);
+	 *   - arch/x86/kvm/lapic.c|3253| <<kvm_free_lapic>> static_branch_slow_dec_deferred(&apic_hw_disabled);
+	 *   - arch/x86/kvm/lapic.c|3460| <<kvm_lapic_set_base>> static_branch_slow_dec_deferred(&apic_hw_disabled);
+	 *   - arch/x86/kvm/lapic.c|3472| <<kvm_lapic_set_base>> static_branch_inc(&apic_hw_disabled.key);
+	 *   - arch/x86/kvm/lapic.c|4580| <<kvm_lapic_exit>> static_key_deferred_flush(&apic_hw_disabled);
+	 *   - arch/x86/kvm/lapic.c|4581| <<kvm_lapic_exit>> WARN_ON(static_branch_unlikely(&apic_hw_disabled.key));
+	 *   - arch/x86/kvm/lapic.h|290| <<kvm_apic_hw_enabled>> if (static_branch_unlikely(&apic_hw_disabled.key))
+	 *
+	 *
+	 * 在以下设置kvm_vcpu_arch->apic_base (看似修改的地方):
+	 *   - arch/x86/kvm/lapic.c|2926| <<kvm_lapic_set_base>> vcpu->arch.apic_base = value;
+	 *   - arch/x86/kvm/lapic.c|3256| <<kvm_create_lapic>> vcpu->arch.apic_base = MSR_IA32_APICBASE_ENABLE;
+	 * 在以下使用kvm_vcpu_arch->apic_base:
+	 *   - arch/x86/kvm/cpuid.c|222| <<__kvm_update_cpuid_runtime>> cpuid_entry_change(best, X86_FEATURE_APIC, vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE);
+	 *   - arch/x86/kvm/lapic.c|2862| <<kvm_free_lapic>> if (!(vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE))
+	 *   - arch/x86/kvm/lapic.c|2923| <<kvm_lapic_set_base>> u64 old_value = vcpu->arch.apic_base;
+	 *   - arch/x86/kvm/lapic.c|2974| <<kvm_lapic_set_base>> apic->base_address = apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_BASE;
+	 *   - arch/x86/kvm/lapic.c|3454| <<kvm_apic_set_state>> kvm_lapic_set_base(vcpu, vcpu->arch.apic_base);
+	 *   - arch/x86/kvm/lapic.h|231| <<kvm_apic_hw_enabled>> return apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE;
+	 *   - arch/x86/kvm/lapic.h|256| <<apic_x2apic_mode>> return apic->vcpu->arch.apic_base & X2APIC_ENABLE;
+	 *   - arch/x86/kvm/lapic.h|300| <<kvm_apic_mode>> return apic_base & (MSR_IA32_APICBASE_ENABLE | X2APIC_ENABLE);
+	 *   - arch/x86/kvm/vmx/nested.c|878| <<nested_vmx_msr_check_common>> if (CC(vcpu->arch.apic_base & X2APIC_ENABLE && e->index >> 8 == 0x8))
+	 *   - arch/x86/kvm/x86.c|466| <<kvm_get_apic_base>> return vcpu->arch.apic_base;
+	 *   - arch/x86/kvm/x86.c|12215| <<kvm_vcpu_is_bsp>> return (vcpu->arch.apic_base & MSR_IA32_APICBASE_BSP) != 0;
+	 */
 	if (static_branch_unlikely(&apic_hw_disabled.key))
 		return apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE;
 	return MSR_IA32_APICBASE_ENABLE;
@@ -184,33 +304,162 @@ static inline int kvm_apic_hw_enabled(struct kvm_lapic *apic)
 
 extern struct static_key_false_deferred apic_sw_disabled;
 
+/*
+ * 在以下使用kvm_apic_sw_enabled():
+ *   - arch/x86/kvm/irq_comm.c|95| <<kvm_irq_delivery_to_apic>> } else if (kvm_apic_sw_enabled(vcpu->arch.apic)) {
+ *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+ *   - arch/x86/kvm/lapic.c|424| <<kvm_recalculate_apic_map>> if (!kvm_apic_sw_enabled(apic))
+ *   - arch/x86/kvm/lapic.c|2720| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+ *   - arch/x86/kvm/lapic.c|2731| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+ *   - arch/x86/kvm/lapic.h|251| <<kvm_lapic_enabled>> return kvm_apic_present(vcpu) && kvm_apic_sw_enabled(vcpu->arch.apic);
+ */
 static inline bool kvm_apic_sw_enabled(struct kvm_lapic *apic)
 {
+	/*
+	 * 在以下使用apic_sw_disabled:
+	 *   - arch/x86/kvm/lapic.c|191| <<global>> __read_mostly DEFINE_STATIC_KEY_DEFERRED_FALSE(apic_sw_disabled, HZ);
+	 *   - arch/x86/kvm/lapic.c|599| <<apic_set_spiv>> static_branch_slow_dec_deferred(&apic_sw_disabled);
+	 *   - arch/x86/kvm/lapic.c|601| <<apic_set_spiv>> static_branch_inc(&apic_sw_disabled.key);
+	 *   - arch/x86/kvm/lapic.c|3263| <<kvm_free_lapic>> static_branch_slow_dec_deferred(&apic_sw_disabled);
+	 *   - arch/x86/kvm/lapic.c|3840| <<kvm_create_lapic>> static_branch_inc(&apic_sw_disabled.key);
+	 *   - arch/x86/kvm/lapic.c|4582| <<kvm_lapic_exit>> static_key_deferred_flush(&apic_sw_disabled);
+	 *   - arch/x86/kvm/lapic.c|4583| <<kvm_lapic_exit>> WARN_ON(static_branch_unlikely(&apic_sw_disabled.key));
+	 *   - arch/x86/kvm/lapic.h|315| <<kvm_apic_sw_enabled>> if (static_branch_unlikely(&apic_sw_disabled.key))
+	 *
+	 *
+	 * 在以下使用kvm_lapic->sw_enabled:
+	 *   - arch/x86/kvm/lapic.c|474| <<apic_set_spiv>> if (enabled != apic->sw_enabled) {
+	 *   - arch/x86/kvm/lapic.c|475| <<apic_set_spiv>> apic->sw_enabled = enabled;
+	 *   - arch/x86/kvm/lapic.c|2899| <<kvm_free_lapic>> if (!apic->sw_enabled)
+	 *   - arch/x86/kvm/lapic.h|260| <<kvm_apic_sw_enabled>> return apic->sw_enabled;
+	 */
 	if (static_branch_unlikely(&apic_sw_disabled.key))
 		return apic->sw_enabled;
 	return true;
 }
 
+/*
+ * | 项目                 | MSR_IA32_APICBASE       | SPIV (0xF0)                |
+ * | ------------------ | ------------------------- | -------------------------- |
+ * | 控制粒度               | 硬件级,全局关闭                  | 软件级,关闭中断处理                 |
+ * | 生效范围               | 关闭整个 Local APIC           | 保留结构但不响应中断                 |
+ * | 通常使用时机             | BIOS,操作系统启动阶段             | 操作系统运行时                    |
+ * | 会影响 APIC MMIO 寄存器吗 | 是,APIC 基址无效后不能访问 APIC 寄存器 | 否,仍然可访问 APIC 寄存器           |
+ * | 对中断的影响             | 完全禁用中断(包括 INIT, STARTUP)  | 仅禁用普通中断,某些特殊中断(如 NMI)有效    |
+ * | 典型用途               | 内核初始化前设置,关闭 SMP 支持        | 操作系统禁用中断(如使用 IOAPIC 或 PIC) |
+ *
+ *
+ * 如果你只把SPIV 的使能位关掉(即SPIV[8]=0),CPU不会响应普通中断,但Local APIC结构还在,
+ * 依然可以接收INIT或IPI等特殊信号.
+ *
+ * 如果你把MSR_IA32_APICBASE[11]=0,则整个Local APIC被禁用,APIC MMIO区也不能访问,
+ * 连 INIT,STARTUP都可能无法正确使用.
+ *
+ *
+ * 在以下调用kvm_apic_present():
+ *   - arch/x86/kvm/irq_comm.c|65| <<kvm_irq_delivery_to_apic>> if (!kvm_apic_present(vcpu))
+ *   - arch/x86/kvm/irq_comm.c|384| <<kvm_intr_is_single_vcpu>> if (!kvm_apic_present(vcpu))
+ *   - arch/x86/kvm/lapic.c|373| <<kvm_recalculate_apic_map>> if (kvm_apic_present(vcpu))
+ *   - arch/x86/kvm/lapic.c|393| <<kvm_recalculate_apic_map>> if (!kvm_apic_present(vcpu))
+ *   - arch/x86/kvm/lapic.c|1764| <<kvm_bitmap_or_dest_vcpus>> if (!kvm_apic_present(vcpu))
+ *   - arch/x86/kvm/lapic.c|2985| <<kvm_get_lapic_tscdeadline_msr>> if (!kvm_apic_present(vcpu) || !apic_lvtt_tscdeadline(apic))
+ *   - arch/x86/kvm/lapic.c|2995| <<kvm_set_lapic_tscdeadline_msr>> if (!kvm_apic_present(vcpu) || !apic_lvtt_tscdeadline(apic))
+ *   - arch/x86/kvm/lapic.c|3501| <<kvm_apic_has_interrupt>> if (!kvm_apic_present(vcpu))
+ *   - arch/x86/kvm/lapic.h|346| <<kvm_lapic_enabled>> return kvm_apic_present(vcpu) && kvm_apic_sw_enabled(vcpu->arch.apic);
+ *   - arch/x86/kvm/x86.c|10149| <<vcpu_scan_ioapic>> if (!kvm_apic_present(vcpu))
+ */
 static inline bool kvm_apic_present(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下调用kvm_apic_hw_enabled():
+	 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+	 *   - arch/x86/kvm/lapic.c|2040| <<apic_mmio_read>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2125| <<lapic_timer_int_injected>> if (kvm_apic_hw_enabled(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2809| <<apic_mmio_write>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|3330| <<kvm_apic_local_deliver>> if (kvm_apic_hw_enabled(apic) && !(reg & APIC_LVT_MASKED)) {
+	 *   - arch/x86/kvm/lapic.c|3443| <<kvm_apic_accept_pic_intr>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 *   - arch/x86/kvm/lapic.h|246| <<kvm_apic_present>> return lapic_in_kernel(vcpu) && kvm_apic_hw_enabled(vcpu->arch.apic);
+	 *   - arch/x86/kvm/x86.c|10218| <<vcpu_load_eoi_exitmap>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 */
 	return lapic_in_kernel(vcpu) && kvm_apic_hw_enabled(vcpu->arch.apic);
 }
 
+/*
+ * 在以下使用kvm_lapic_enabled():
+ *   - arch/x86/kvm/x86.c|10495| <<vcpu_enter_guest>> if (kvm_lapic_enabled(vcpu)) {
+ *   - arch/x86/kvm/x86.c|10555| <<vcpu_enter_guest>> if (kvm_lapic_enabled(vcpu))
+ *   - arch/x86/kvm/x86.c|10620| <<vcpu_enter_guest>> if (kvm_lapic_enabled(vcpu))
+ *   - arch/x86/kvm/x86.c|13109| <<kvm_arch_can_dequeue_async_page_present>> return kvm_lapic_enabled(vcpu) && apf_pageready_slot_free(vcpu);
+ */
 static inline int kvm_lapic_enabled(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用kvm_apic_sw_enabled():
+	 *   - arch/x86/kvm/irq_comm.c|95| <<kvm_irq_delivery_to_apic>> } else if (kvm_apic_sw_enabled(vcpu->arch.apic)) {
+	 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+	 *   - arch/x86/kvm/lapic.c|424| <<kvm_recalculate_apic_map>> if (!kvm_apic_sw_enabled(apic))
+	 *   - arch/x86/kvm/lapic.c|2720| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+	 *   - arch/x86/kvm/lapic.c|2731| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+	 *   - arch/x86/kvm/lapic.h|251| <<kvm_lapic_enabled>> return kvm_apic_present(vcpu) && kvm_apic_sw_enabled(vcpu->arch.apic);
+	 */
 	return kvm_apic_present(vcpu) && kvm_apic_sw_enabled(vcpu->arch.apic);
 }
 
 static inline int apic_x2apic_mode(struct kvm_lapic *apic)
 {
+	/*
+	 * 在以下设置kvm_vcpu_arch->apic_base (看似修改的地方):
+	 *   - arch/x86/kvm/lapic.c|2926| <<kvm_lapic_set_base>> vcpu->arch.apic_base = value;
+	 *   - arch/x86/kvm/lapic.c|3256| <<kvm_create_lapic>> vcpu->arch.apic_base = MSR_IA32_APICBASE_ENABLE;
+	 * 在以下使用kvm_vcpu_arch->apic_base:
+	 *   - arch/x86/kvm/cpuid.c|222| <<__kvm_update_cpuid_runtime>> cpuid_entry_change(best, X86_FEATURE_APIC, vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE);
+	 *   - arch/x86/kvm/lapic.c|2862| <<kvm_free_lapic>> if (!(vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE))
+	 *   - arch/x86/kvm/lapic.c|2923| <<kvm_lapic_set_base>> u64 old_value = vcpu->arch.apic_base;
+	 *   - arch/x86/kvm/lapic.c|2974| <<kvm_lapic_set_base>> apic->base_address = apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_BASE;
+	 *   - arch/x86/kvm/lapic.c|3454| <<kvm_apic_set_state>> kvm_lapic_set_base(vcpu, vcpu->arch.apic_base);
+	 *   - arch/x86/kvm/lapic.h|231| <<kvm_apic_hw_enabled>> return apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE;
+	 *   - arch/x86/kvm/lapic.h|256| <<apic_x2apic_mode>> return apic->vcpu->arch.apic_base & X2APIC_ENABLE;
+	 *   - arch/x86/kvm/lapic.h|300| <<kvm_apic_mode>> return apic_base & (MSR_IA32_APICBASE_ENABLE | X2APIC_ENABLE);
+	 *   - arch/x86/kvm/vmx/nested.c|878| <<nested_vmx_msr_check_common>> if (CC(vcpu->arch.apic_base & X2APIC_ENABLE && e->index >> 8 == 0x8))
+	 *   - arch/x86/kvm/x86.c|466| <<kvm_get_apic_base>> return vcpu->arch.apic_base;
+	 *   - arch/x86/kvm/x86.c|12215| <<kvm_vcpu_is_bsp>> return (vcpu->arch.apic_base & MSR_IA32_APICBASE_BSP) != 0;
+	 */
 	return apic->vcpu->arch.apic_base & X2APIC_ENABLE;
 }
 
+/*
+ * 在以下使用kvm_vcpu_apicv_active():
+ *   - arch/x86/kvm/irq.c|89| <<kvm_cpu_has_injectable_intr>> if (!is_guest_mode(v) && kvm_vcpu_apicv_active(v))
+ *   - arch/x86/kvm/lapic.c|221| <<kvm_can_post_timer_interrupt>> return pi_inject_timer && kvm_vcpu_apicv_active(vcpu) &&
+ *   - arch/x86/kvm/svm/avic.c|964| <<avic_pi_update_irte>> kvm_vcpu_apicv_active(&svm->vcpu)) {
+ *   - arch/x86/kvm/svm/avic.c|1183| <<avic_refresh_apicv_exec_ctrl>> bool activated = kvm_vcpu_apicv_active(vcpu);
+ *   - arch/x86/kvm/svm/avic.c|1213| <<avic_vcpu_blocking>> if (!kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/svm/avic.c|1234| <<avic_vcpu_unblocking>> if (!kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/svm/nested.c|728| <<enter_svm_guest_mode>> if (kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/svm/svm.c|1307| <<init_vmcb>> if (!kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/svm/svm.c|1422| <<init_vmcb>> if (kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/svm/svm.c|1618| <<svm_vcpu_load>> if (kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/svm/svm.c|1624| <<svm_vcpu_put>> if (kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/svm/svm.c|3946| <<sync_lapic_to_cr8>> kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/vmx/nested.c|3402| <<nested_vmx_enter_non_root_mode>> if (likely(!evaluate_pending_interrupts) && kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/vmx/vmx.c|3984| <<vmx_update_msr_bitmap_x2apic>> if (enable_apicv && kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/vmx/vmx.c|4256| <<vmx_pin_based_exec_ctrl>> if (!kvm_vcpu_apicv_active(&vmx->vcpu))
+ *   - arch/x86/kvm/vmx/vmx.c|4303| <<vmx_refresh_apicv_exec_ctrl>> if (kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/vmx/vmx.c|4418| <<vmx_secondary_exec_control>> if (!kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/vmx/vmx.c|4511| <<init_vmcs>> if (kvm_vcpu_apicv_active(&vmx->vcpu)) {
+ *   - arch/x86/kvm/vmx/vmx.c|6613| <<vmx_sync_pir_to_irr>> if (!is_guest_mode(vcpu) && kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/vmx/vmx.c|6630| <<vmx_load_eoi_exitmap>> if (!kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/x86.c|10602| <<vcpu_enter_guest>> WARN_ON_ONCE((kvm_vcpu_apicv_activated(vcpu) != kvm_vcpu_apicv_active(vcpu)) &&
+ */
 static inline bool kvm_vcpu_apicv_active(struct kvm_vcpu *vcpu)
 {
 	return vcpu->arch.apic && vcpu->arch.apicv_active;
 }
 
+/*
+ * 在以下使用kvm_apic_has_events():
+ *   - arch/x86/kvm/x86.c|12773| <<kvm_vcpu_has_events>> if (kvm_apic_has_events(vcpu))
+ */
 static inline bool kvm_apic_has_events(struct kvm_vcpu *vcpu)
 {
 	return lapic_in_kernel(vcpu) && vcpu->arch.apic->pending_events;
diff --git a/arch/x86/kvm/mmu.h b/arch/x86/kvm/mmu.h
index 8669044b1c27..1577233dc1b4 100644
--- a/arch/x86/kvm/mmu.h
+++ b/arch/x86/kvm/mmu.h
@@ -82,6 +82,11 @@ int kvm_mmu_load(struct kvm_vcpu *vcpu);
 void kvm_mmu_unload(struct kvm_vcpu *vcpu);
 void kvm_mmu_sync_roots(struct kvm_vcpu *vcpu);
 
+/*
+ * 在以下使用kvm_mmu_reload():
+ *   - arch/x86/kvm/x86.c|10576| <<vcpu_enter_guest>> r = kvm_mmu_reload(vcpu);
+ *   - arch/x86/kvm/x86.c|13052| <<kvm_arch_async_page_ready>> r = kvm_mmu_reload(vcpu);
+ */
 static inline int kvm_mmu_reload(struct kvm_vcpu *vcpu)
 {
 	if (likely(vcpu->arch.mmu->root_hpa != INVALID_PAGE))
diff --git a/arch/x86/kvm/svm/avic.c b/arch/x86/kvm/svm/avic.c
index df2d33395a48..b41c2476e819 100644
--- a/arch/x86/kvm/svm/avic.c
+++ b/arch/x86/kvm/svm/avic.c
@@ -432,6 +432,15 @@ static int avic_kick_target_vcpus_fast(struct kvm *kvm, struct kvm_lapic *source
 		return 0;
 
 	target_vcpu->arch.apic->irr_pending = true;
+	/*
+	 * 在以下使用svm_complete_interrupt_delivery():
+	 *   - arch/x86/kvm/svm/avic.c|435| <<avic_kick_target_vcpus_fast>> svm_complete_interrupt_delivery(target_vcpu,
+	 *              icrl & APIC_MODE_MASK, icrl & APIC_INT_LEVELTRIG, icrl & APIC_VECTOR_MASK);
+	 *   - arch/x86/kvm/svm/avic.c|483| <<avic_kick_target_vcpus>> svm_complete_interrupt_delivery(vcpu,
+	 *              icrl & APIC_MODE_MASK, icrl & APIC_INT_LEVELTRIG, icrl & APIC_VECTOR_MASK);
+	 *   - arch/x86/kvm/svm/svm.c|3698| <<svm_deliver_interrupt>> svm_complete_interrupt_delivery(apic->vcpu,
+	 *              delivery_mode, trig_mode, vector); 
+	 */
 	svm_complete_interrupt_delivery(target_vcpu,
 					icrl & APIC_MODE_MASK,
 					icrl & APIC_INT_LEVELTRIG,
@@ -458,9 +467,37 @@ static void avic_kick_target_vcpus(struct kvm *kvm, struct kvm_lapic *source,
 	 * since entered the guest will have processed pending IRQs at VMRUN.
 	 */
 	kvm_for_each_vcpu(i, vcpu, kvm) {
+		/*
+		 * 在以下调用kvm_apic_match_dest():
+		 *   - arch/x86/kvm/ioapic.c|146| <<__rtc_irq_eoi_tracking_restore_one>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, e->fields.dest_id, kvm_lapic_irq_dest_mode(!!e->fields.dest_mode)))
+		 *   - arch/x86/kvm/ioapic.c|234| <<ioapic_lazy_update_eoi>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, entry->fields.dest_id, entry->fields.dest_mode) ||
+		 *   - arch/x86/kvm/ioapic.c|414| <<kvm_ioapic_scan_entry>> if (kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, e->fields.dest_id, dm) ||
+		 *   - arch/x86/kvm/irq_comm.c|68| <<kvm_irq_delivery_to_apic>> if (!kvm_apic_match_dest(vcpu, src,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/irq_comm.c|359| <<kvm_intr_is_single_vcpu>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/irq_comm.c|442| <<kvm_scan_ioapic_routes>> if (irq.trig_mode && (kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, irq.dest_id, irq.dest_mode) ||
+		 *   - arch/x86/kvm/lapic.c|1262| <<kvm_bitmap_or_dest_vcpus>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/svm/avic.c|461| <<avic_kick_target_vcpus>> if (kvm_apic_match_dest(vcpu, source,
+		 *          icrl & APIC_SHORT_MASK, dest, icrl & APIC_DEST_MASK)) {
+		 */
 		if (kvm_apic_match_dest(vcpu, source, icrl & APIC_SHORT_MASK,
 					dest, icrl & APIC_DEST_MASK)) {
 			vcpu->arch.apic->irr_pending = true;
+			/*
+			 * 在以下使用svm_complete_interrupt_delivery():
+			 *   - arch/x86/kvm/svm/avic.c|435| <<avic_kick_target_vcpus_fast>> svm_complete_interrupt_delivery(target_vcpu,
+			 *              icrl & APIC_MODE_MASK, icrl & APIC_INT_LEVELTRIG, icrl & APIC_VECTOR_MASK);
+			 *   - arch/x86/kvm/svm/avic.c|483| <<avic_kick_target_vcpus>> svm_complete_interrupt_delivery(vcpu,
+			 *              icrl & APIC_MODE_MASK, icrl & APIC_INT_LEVELTRIG, icrl & APIC_VECTOR_MASK);
+			 *   - arch/x86/kvm/svm/svm.c|3698| <<svm_deliver_interrupt>> svm_complete_interrupt_delivery(apic->vcpu,
+			 *              delivery_mode, trig_mode, vector); 
+			 */
 			svm_complete_interrupt_delivery(vcpu,
 							icrl & APIC_MODE_MASK,
 							icrl & APIC_INT_LEVELTRIG,
@@ -1012,6 +1049,12 @@ int avic_pi_update_irte(struct kvm *kvm, unsigned int host_irq,
 
 bool avic_check_apicv_inhibit_reasons(enum kvm_apicv_inhibit reason)
 {
+	/*
+	 * 在以下使用APICV_INHIBIT_REASON_IRQWIN:
+	 *   - arch/x86/kvm/svm/avic.c|1056| <<avic_check_apicv_inhibit_reasons>> BIT(APICV_INHIBIT_REASON_IRQWIN) |
+	 *   - arch/x86/kvm/svm/svm.c|3203| <<interrupt_window_interception>> kvm_clear_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+	 *   - arch/x86/kvm/svm/svm.c|3873| <<svm_enable_irq_window>> kvm_set_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+	 */
 	ulong supported = BIT(APICV_INHIBIT_REASON_DISABLE) |
 			  BIT(APICV_INHIBIT_REASON_ABSENT) |
 			  BIT(APICV_INHIBIT_REASON_HYPERV) |
diff --git a/arch/x86/kvm/svm/svm.c b/arch/x86/kvm/svm/svm.c
index 96640c185c6e..a7ca5c1d827b 100644
--- a/arch/x86/kvm/svm/svm.c
+++ b/arch/x86/kvm/svm/svm.c
@@ -1678,6 +1678,10 @@ static void svm_cache_reg(struct kvm_vcpu *vcpu, enum kvm_reg reg)
 	}
 }
 
+/*
+ * 在以下使用svm_set_vintr():
+ *   - arch/x86/kvm/svm/svm.c|3875| <<svm_enable_irq_window>> svm_set_vintr(svm);
+ */
 static void svm_set_vintr(struct vcpu_svm *svm)
 {
 	struct vmcb_control_area *control;
@@ -1687,6 +1691,16 @@ static void svm_set_vintr(struct vcpu_svm *svm)
 	 */
 	WARN_ON(kvm_vcpu_apicv_activated(&svm->vcpu));
 
+	/*
+	 * SDM注释:
+	 * When virtualizing interrupt handling, a VMM typically needs only
+	 * gain control when new interrupts
+	 * for a guest arrive or are generated, and when the guest issues an EOI
+	 * (end-of-interrupt). In some circumstances, it may also be necessary
+	 * for the VMM to gain control at the moment interrupts become enabled in
+	 * the guest (i.e., just before the guest takes a virtual interrupt). The
+	 * VMM can do so by enabling the VINTR intercept.
+	 */
 	svm_set_intercept(svm, INTERCEPT_VINTR);
 
 	/*
@@ -1711,6 +1725,12 @@ static void svm_set_vintr(struct vcpu_svm *svm)
 	vmcb_mark_dirty(svm->vmcb, VMCB_INTR);
 }
 
+/*
+ * 在以下使用svm_clear_vintr():
+ *   - arch/x86/kvm/svm/svm.c|2443| <<svm_set_gif>> svm_clear_vintr(svm);
+ *   - arch/x86/kvm/svm/svm.c|2459| <<svm_set_gif>> svm_clear_vintr(svm);
+ *   - arch/x86/kvm/svm/svm.c|3189| <<interrupt_window_interception>> svm_clear_vintr(to_svm(vcpu));
+ */
 static void svm_clear_vintr(struct vcpu_svm *svm)
 {
 	svm_clr_intercept(svm, INTERCEPT_VINTR);
@@ -3186,6 +3206,12 @@ static int msr_interception(struct kvm_vcpu *vcpu)
 static int interrupt_window_interception(struct kvm_vcpu *vcpu)
 {
 	kvm_make_request(KVM_REQ_EVENT, vcpu);
+	/*
+	 * 在以下使用svm_clear_vintr():
+	 *   - arch/x86/kvm/svm/svm.c|2443| <<svm_set_gif>> svm_clear_vintr(svm);
+	 *   - arch/x86/kvm/svm/svm.c|2459| <<svm_set_gif>> svm_clear_vintr(svm);
+	 *   - arch/x86/kvm/svm/svm.c|3189| <<interrupt_window_interception>> svm_clear_vintr(to_svm(vcpu));
+	 */
 	svm_clear_vintr(to_svm(vcpu));
 
 	/*
@@ -3200,6 +3226,19 @@ static int interrupt_window_interception(struct kvm_vcpu *vcpu)
 	 * All vCPUs which run still run nested, will remain to have their
 	 * AVIC still inhibited due to per-cpu AVIC inhibition.
 	 */
+	/*
+	 * 在以下使用kvm_clear_apicv_inhibit():
+	 *   - arch/x86/kvm/i8254.c|314| <<kvm_pit_set_reinject>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_PIT_REINJ);
+	 *   - arch/x86/kvm/lapic.c|579| <<kvm_recalculate_apic_map>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_APIC_ID_MODIFIED);
+	 *   - arch/x86/kvm/svm/svm.c|3235| <<interrupt_window_interception>> kvm_clear_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+	 *   - arch/x86/kvm/x86.c|6050| <<kvm_vm_ioctl_enable_cap(KVM_CAP_SPLIT_IRQCHIP)>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
+	 *   - arch/x86/kvm/x86.c|6465| <<kvm_arch_vm_ioctl(KVM_CREATE_IRQCHIP)>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
+	 *
+	 * 在以下使用APICV_INHIBIT_REASON_IRQWIN:
+	 *   - arch/x86/kvm/svm/avic.c|1056| <<avic_check_apicv_inhibit_reasons>> BIT(APICV_INHIBIT_REASON_IRQWIN) |
+	 *   - arch/x86/kvm/svm/svm.c|3203| <<interrupt_window_interception>> kvm_clear_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+	 *   - arch/x86/kvm/svm/svm.c|3873| <<svm_enable_irq_window>> kvm_set_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+	 */
 	kvm_clear_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
 
 	++vcpu->stat.irq_window_exits;
@@ -3649,6 +3688,15 @@ static void svm_set_irq(struct kvm_vcpu *vcpu, bool reinjected)
 				       SVM_EVTINJ_VALID | type;
 }
 
+/*
+ * 在以下使用svm_complete_interrupt_delivery():
+ *   - arch/x86/kvm/svm/avic.c|435| <<avic_kick_target_vcpus_fast>> svm_complete_interrupt_delivery(target_vcpu,
+ *              icrl & APIC_MODE_MASK, icrl & APIC_INT_LEVELTRIG, icrl & APIC_VECTOR_MASK);
+ *   - arch/x86/kvm/svm/avic.c|483| <<avic_kick_target_vcpus>> svm_complete_interrupt_delivery(vcpu,
+ *              icrl & APIC_MODE_MASK, icrl & APIC_INT_LEVELTRIG, icrl & APIC_VECTOR_MASK);
+ *   - arch/x86/kvm/svm/svm.c|3698| <<svm_deliver_interrupt>> svm_complete_interrupt_delivery(apic->vcpu,
+ *              delivery_mode, trig_mode, vector); 
+ */
 void svm_complete_interrupt_delivery(struct kvm_vcpu *vcpu, int delivery_mode,
 				     int trig_mode, int vector)
 {
@@ -3695,6 +3743,15 @@ static void svm_deliver_interrupt(struct kvm_lapic *apic,  int delivery_mode,
 	 * will signal the doorbell if the CPU has already entered the guest.
 	 */
 	smp_mb__after_atomic();
+	/*
+	 * 在以下使用svm_complete_interrupt_delivery():
+	 *   - arch/x86/kvm/svm/avic.c|435| <<avic_kick_target_vcpus_fast>> svm_complete_interrupt_delivery(target_vcpu,
+	 *              icrl & APIC_MODE_MASK, icrl & APIC_INT_LEVELTRIG, icrl & APIC_VECTOR_MASK);
+	 *   - arch/x86/kvm/svm/avic.c|483| <<avic_kick_target_vcpus>> svm_complete_interrupt_delivery(vcpu,
+	 *              icrl & APIC_MODE_MASK, icrl & APIC_INT_LEVELTRIG, icrl & APIC_VECTOR_MASK);
+	 *   - arch/x86/kvm/svm/svm.c|3698| <<svm_deliver_interrupt>> svm_complete_interrupt_delivery(apic->vcpu,
+	 *              delivery_mode, trig_mode, vector); 
+	 */
 	svm_complete_interrupt_delivery(apic->vcpu, delivery_mode, trig_mode, vector);
 }
 
@@ -3828,6 +3885,11 @@ static int svm_interrupt_allowed(struct kvm_vcpu *vcpu, bool for_injection)
 	return 1;
 }
 
+/*
+ * 在以下调用:
+ *   - arch/x86/kvm/x86.c|9847| <<inject_pending_event>> static_call(kvm_x86_enable_irq_window)(vcpu);
+ *   - arch/x86/kvm/x86.c|10871| <<vcpu_enter_guest>> static_call(kvm_x86_enable_irq_window)(vcpu);
+ */
 static void svm_enable_irq_window(struct kvm_vcpu *vcpu)
 {
 	struct vcpu_svm *svm = to_svm(vcpu);
@@ -3851,6 +3913,12 @@ static void svm_enable_irq_window(struct kvm_vcpu *vcpu)
 		 * on this vCPU, therefore there is no need to request
 		 * the VM wide AVIC inhibition.
 		 */
+		/*
+		 * 在以下使用APICV_INHIBIT_REASON_IRQWIN:
+		 *   - arch/x86/kvm/svm/avic.c|1056| <<avic_check_apicv_inhibit_reasons>> BIT(APICV_INHIBIT_REASON_IRQWIN) |
+		 *   - arch/x86/kvm/svm/svm.c|3203| <<interrupt_window_interception>> kvm_clear_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+		 *   - arch/x86/kvm/svm/svm.c|3873| <<svm_enable_irq_window>> kvm_set_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+		 */
 		if (!is_guest_mode(vcpu))
 			kvm_set_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
 
@@ -4202,6 +4270,12 @@ static __no_kcsan fastpath_t svm_vcpu_run(struct kvm_vcpu *vcpu)
 		vcpu->arch.regs[VCPU_REGS_RIP] = svm->vmcb->save.rip;
 	}
 
+	/*
+	 * 在以下使用kvm_before_interrupt():
+	 *   - arch/x86/kvm/svm/svm.c|4206| <<svm_vcpu_run>> kvm_before_interrupt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|6920| <<handle_interrupt_nmi_irqoff>> kvm_before_interrupt(vcpu);
+	 *   - arch/x86/kvm/x86.c|11036| <<vcpu_enter_guest>> kvm_before_interrupt(vcpu);
+	 */
 	if (unlikely(svm->vmcb->control.exit_code == SVM_EXIT_NMI))
 		kvm_before_interrupt(vcpu);
 
@@ -4581,6 +4655,13 @@ static int svm_check_intercept(struct kvm_vcpu *vcpu,
 
 static void svm_handle_exit_irqoff(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用kvm_vcpu_arch->at_instruction_boundary:
+	 *   - arch/x86/kvm/svm/svm.c|4585| <<svm_handle_exit_irqoff>> vcpu->arch.at_instruction_boundary = true;
+	 *   - arch/x86/kvm/vmx/vmx.c|6979| <<handle_external_interrupt_irqoff>> vcpu->arch.at_instruction_boundary = true;
+	 *   - arch/x86/kvm/x86.c|4744| <<kvm_steal_time_set_preempted>> if (!vcpu->arch.at_instruction_boundary) {
+	 *   - arch/x86/kvm/x86.c|11223| <<vcpu_run>> vcpu->arch.at_instruction_boundary = false;
+	 */
 	if (to_svm(vcpu)->vmcb->control.exit_code == SVM_EXIT_INTR)
 		vcpu->arch.at_instruction_boundary = true;
 }
diff --git a/arch/x86/kvm/vmx/nested.c b/arch/x86/kvm/vmx/nested.c
index ab2a35fe97f8..d35db682b875 100644
--- a/arch/x86/kvm/vmx/nested.c
+++ b/arch/x86/kvm/vmx/nested.c
@@ -2363,6 +2363,22 @@ static void prepare_vmcs02_early(struct vcpu_vmx *vmx, struct loaded_vmcs *vmcs0
 	 * Interrupt/Exception Fields
 	 */
 	if (vmx->nested.nested_run_pending) {
+		/*
+		 * vmx代码中主要使用VM_ENTRY_INTR_INFO_FIELD的地方:
+		 *   - arch/x86/kvm/vmx/nested.c|2366| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+		 *   - arch/x86/kvm/vmx/nested.c|2377| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+		 *   - arch/x86/kvm/vmx/vmx.c|1732| <<vmx_inject_exception>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr_info);
+		 *   - arch/x86/kvm/vmx/vmx.c|4653| <<vmx_vcpu_reset>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+		 *   - arch/x86/kvm/vmx/vmx.c|4710| <<vmx_inject_irq>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr);
+		 *   - arch/x86/kvm/vmx/vmx.c|4740| <<vmx_inject_nmi>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+		 *   - arch/x86/kvm/vmx/vmx.c|6095| <<dump_vmcs>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+		 *   - arch/x86/kvm/vmx/vmx.c|6952| <<vmx_cancel_injection>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+		 *   - arch/x86/kvm/vmx/vmx.c|6956| <<vmx_cancel_injection>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+		 *
+		 * bit 0-7: Vector of interrupt or exception
+		 * bit 8-10: interrupt type: 0-7不同的数, 0是external interrupt
+		 * bit 31: valid (cleared on every vm exit)
+		 */
 		vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
 			     vmcs12->vm_entry_intr_info_field);
 		vmcs_write32(VM_ENTRY_EXCEPTION_ERROR_CODE,
@@ -4688,6 +4704,15 @@ void nested_vmx_vmexit(struct kvm_vcpu *vcpu, u32 vm_exit_reason,
 
 	if (vmx->nested.reload_vmcs01_apic_access_page) {
 		vmx->nested.reload_vmcs01_apic_access_page = false;
+		/*
+		 * 在以下使用KVM_REQ_APIC_PAGE_RELOAD:
+		 *   - arch/x86/kvm/vmx/nested.c|4691| <<nested_vmx_vmexit>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+		 *   - arch/x86/kvm/vmx/vmx.c|4645| <<vmx_vcpu_reset>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+		 *   - arch/x86/kvm/vmx/vmx.c|6462| <<vmx_set_virtual_apic_mode>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+		 *   - arch/x86/kvm/x86.c|10340| <<kvm_arch_mmu_notifier_invalidate_range>> kvm_make_all_cpus_request(kvm, KVM_REQ_APIC_PAGE_RELOAD);
+		 *
+		 * 处理的函数kvm_vcpu_reload_apic_access_page()
+		 */
 		kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
 	}
 
diff --git a/arch/x86/kvm/vmx/vmx.c b/arch/x86/kvm/vmx/vmx.c
index d0a0883599c5..df82cf555c80 100644
--- a/arch/x86/kvm/vmx/vmx.c
+++ b/arch/x86/kvm/vmx/vmx.c
@@ -515,6 +515,13 @@ static inline void vmx_segment_cache_clear(struct vcpu_vmx *vmx)
 	vmx->segment_cache.bitmask = 0;
 }
 
+/*
+ * 在以下使用host_idt_base:
+ *   - arch/x86/kvm/vmx/vmx.c|518| <<global>> static unsigned long host_idt_base;
+ *   - arch/x86/kvm/vmx/vmx.c|4304| <<vmx_set_constant_host_state>> vmcs_writel(HOST_IDTR_BASE, host_idt_base);
+ *   - arch/x86/kvm/vmx/vmx.c|6972| <<handle_external_interrupt_irqoff>> gate_desc *desc = (gate_desc *)host_idt_base + vector;
+ *   - arch/x86/kvm/vmx/vmx.c|8510| <<hardware_setup>> host_idt_base = dt.address;
+ */
 static unsigned long host_idt_base;
 
 #if IS_ENABLED(CONFIG_HYPERV)
@@ -1182,6 +1189,11 @@ void vmx_set_host_fs_gs(struct vmcs_host_state *host, u16 fs_sel, u16 gs_sel,
 	}
 }
 
+/*
+ * 在以下调用vmx_prepare_switch_to_guest():
+ *   - arch/x86/kvm/vmx/vmx.h|370| <<global>> void vmx_prepare_switch_to_guest(struct kvm_vcpu *vcpu);
+ *   - arch/x86/kvm/vmx/nested.c|3103| <<nested_vmx_check_vmentry_hw>> vmx_prepare_switch_to_guest(vcpu);
+ */
 void vmx_prepare_switch_to_guest(struct kvm_vcpu *vcpu)
 {
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
@@ -1215,6 +1227,16 @@ void vmx_prepare_switch_to_guest(struct kvm_vcpu *vcpu)
     	if (vmx->nested.need_vmcs12_to_shadow_sync)
 		nested_sync_vmcs12_to_shadow(vcpu);
 
+	/*
+	 * 在以下使用vcpu_vmx->guest_state_loaded:
+	 *   - arch/x86/kvm/vmx/nested.c|243| <<vmx_sync_vmcs_host_state>> if (unlikely(!vmx->guest_state_loaded))
+	 *   - arch/x86/kvm/vmx/vmx.c|1223| <<vmx_prepare_switch_to_guest>> if (vmx->guest_state_loaded)
+	 *   - arch/x86/kvm/vmx/vmx.c|1261| <<vmx_prepare_switch_to_guest>> vmx->guest_state_loaded = true;
+	 *   - arch/x86/kvm/vmx/vmx.c|1268| <<vmx_prepare_switch_to_host>> if (!vmx->guest_state_loaded)
+	 *   - arch/x86/kvm/vmx/vmx.c|1299| <<vmx_prepare_switch_to_host>> vmx->guest_state_loaded = false;
+	 *   - arch/x86/kvm/vmx/vmx.c|1307| <<vmx_read_guest_kernel_gs_base>> if (vmx->guest_state_loaded)
+	 *   - arch/x86/kvm/vmx/vmx.c|1316| <<vmx_write_guest_kernel_gs_base>> if (vmx->guest_state_loaded)
+	 */
 	if (vmx->guest_state_loaded)
 		return;
 
@@ -1291,6 +1313,16 @@ static void vmx_prepare_switch_to_host(struct vcpu_vmx *vmx)
 	wrmsrl(MSR_KERNEL_GS_BASE, vmx->msr_host_kernel_gs_base);
 #endif
 	load_fixmap_gdt(raw_smp_processor_id());
+	/*
+	 * 在以下使用vcpu_vmx->guest_state_loaded:
+	 *   - arch/x86/kvm/vmx/nested.c|243| <<vmx_sync_vmcs_host_state>> if (unlikely(!vmx->guest_state_loaded))
+	 *   - arch/x86/kvm/vmx/vmx.c|1223| <<vmx_prepare_switch_to_guest>> if (vmx->guest_state_loaded)
+	 *   - arch/x86/kvm/vmx/vmx.c|1261| <<vmx_prepare_switch_to_guest>> vmx->guest_state_loaded = true;
+	 *   - arch/x86/kvm/vmx/vmx.c|1268| <<vmx_prepare_switch_to_host>> if (!vmx->guest_state_loaded)
+	 *   - arch/x86/kvm/vmx/vmx.c|1299| <<vmx_prepare_switch_to_host>> vmx->guest_state_loaded = false;
+	 *   - arch/x86/kvm/vmx/vmx.c|1307| <<vmx_read_guest_kernel_gs_base>> if (vmx->guest_state_loaded)
+	 *   - arch/x86/kvm/vmx/vmx.c|1316| <<vmx_write_guest_kernel_gs_base>> if (vmx->guest_state_loaded)
+	 */
 	vmx->guest_state_loaded = false;
 	vmx->guest_uret_msrs_loaded = false;
 }
@@ -1674,6 +1706,13 @@ static int vmx_skip_emulated_instruction(struct kvm_vcpu *vcpu)
 	return skip_emulated_instruction(vcpu);
 }
 
+/*
+ * 在以下调用vmx_clear_hlt():
+ *   - arch/x86/kvm/vmx/vmx.c|1734| <<vmx_inject_exception>> vmx_clear_hlt(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|4712| <<vmx_inject_irq>> vmx_clear_hlt(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|4743| <<vmx_inject_nmi>> vmx_clear_hlt(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|7989| <<vmx_enter_smm>> vmx_clear_hlt(vcpu);
+ */
 static void vmx_clear_hlt(struct kvm_vcpu *vcpu)
 {
 	/*
@@ -1690,6 +1729,26 @@ static void vmx_clear_hlt(struct kvm_vcpu *vcpu)
 static void vmx_inject_exception(struct kvm_vcpu *vcpu)
 {
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
+	/*
+	 * struct kvm_vcpu *vcpu:
+	 * -> struct kvm_vcpu_arch arch;
+	 *        struct kvm_queued_exception {
+	 *            bool pending;
+	 *            bool injected;
+	 *            bool has_error_code;
+	 *            u8 nr;
+	 *            u32 error_code;
+	 *            unsigned long payload;
+	 *            bool has_payload;
+	 *            u8 nested_apf;
+	 *        } exception;
+	 *
+	 *        struct kvm_queued_interrupt {
+	 *            bool injected;
+	 *            bool soft;
+	 *            u8 nr;
+	 *        } interrupt;
+	 */
 	unsigned nr = vcpu->arch.exception.nr;
 	bool has_error_code = vcpu->arch.exception.has_error_code;
 	u32 error_code = vcpu->arch.exception.error_code;
@@ -1729,8 +1788,31 @@ static void vmx_inject_exception(struct kvm_vcpu *vcpu)
 	} else
 		intr_info |= INTR_TYPE_HARD_EXCEPTION;
 
+	/*
+	 * vmx代码中主要使用VM_ENTRY_INTR_INFO_FIELD的地方:
+	 *   - arch/x86/kvm/vmx/nested.c|2366| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+	 *   - arch/x86/kvm/vmx/nested.c|2377| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *   - arch/x86/kvm/vmx/vmx.c|1732| <<vmx_inject_exception>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr_info);
+	 *   - arch/x86/kvm/vmx/vmx.c|4653| <<vmx_vcpu_reset>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *   - arch/x86/kvm/vmx/vmx.c|4710| <<vmx_inject_irq>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr);
+	 *   - arch/x86/kvm/vmx/vmx.c|4740| <<vmx_inject_nmi>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+	 *   - arch/x86/kvm/vmx/vmx.c|6095| <<dump_vmcs>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *   - arch/x86/kvm/vmx/vmx.c|6952| <<vmx_cancel_injection>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *   - arch/x86/kvm/vmx/vmx.c|6956| <<vmx_cancel_injection>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *
+	 * bit 0-7: Vector of interrupt or exception
+	 * bit 8-10: interrupt type: 0-7不同的数, 0是external interrupt
+	 * bit 31: valid (cleared on every vm exit)
+	 */
 	vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr_info);
 
+	/*
+	 * 在以下调用vmx_clear_hlt():
+	 *   - arch/x86/kvm/vmx/vmx.c|1734| <<vmx_inject_exception>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|4712| <<vmx_inject_irq>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|4743| <<vmx_inject_nmi>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|7989| <<vmx_enter_smm>> vmx_clear_hlt(vcpu);
+	 */
 	vmx_clear_hlt(vcpu);
 }
 
@@ -2033,6 +2115,36 @@ static u64 vcpu_supported_debugctl(struct kvm_vcpu *vcpu)
 	return debugctl;
 }
 
+/*
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_vcpu_reset
+ * kvm_apic_accept_events
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_lapic_reg_write
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ */
 /*
  * Writes msr value into the appropriate "register".
  * Returns 0 on success, non-0 otherwise.
@@ -3939,6 +4051,11 @@ static void vmx_reset_x2apic_msrs(struct kvm_vcpu *vcpu, u8 mode)
 	}
 }
 
+/*
+ * 在以下使用vmx_update_msr_bitmap_x2apic():
+ *   - arch/x86/kvm/vmx/vmx.c|4313| <<vmx_refresh_apicv_exec_ctrl>> vmx_update_msr_bitmap_x2apic(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|6481| <<vmx_set_virtual_apic_mode>> vmx_update_msr_bitmap_x2apic(vcpu);
+ */
 static void vmx_update_msr_bitmap_x2apic(struct kvm_vcpu *vcpu)
 {
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
@@ -3947,6 +4064,10 @@ static void vmx_update_msr_bitmap_x2apic(struct kvm_vcpu *vcpu)
 	if (!cpu_has_vmx_msr_bitmap())
 		return;
 
+	/*
+	 * #define MSR_BITMAP_MODE_X2APIC          1
+	 * #define MSR_BITMAP_MODE_X2APIC_APICV    2
+	 */
 	if (cpu_has_secondary_exec_ctrls() &&
 	    (secondary_exec_controls_get(vmx) &
 	     SECONDARY_EXEC_VIRTUALIZE_X2APIC_MODE)) {
@@ -4187,6 +4308,13 @@ void vmx_set_constant_host_state(struct vcpu_vmx *vmx)
 	vmcs_write16(HOST_SS_SELECTOR, __KERNEL_DS);  /* 22.2.4 */
 	vmcs_write16(HOST_TR_SELECTOR, GDT_ENTRY_TSS*8);  /* 22.2.4 */
 
+	/*
+	 * 在以下使用host_idt_base:
+	 *   - arch/x86/kvm/vmx/vmx.c|518| <<global>> static unsigned long host_idt_base;
+	 *   - arch/x86/kvm/vmx/vmx.c|4304| <<vmx_set_constant_host_state>> vmcs_writel(HOST_IDTR_BASE, host_idt_base);
+	 *   - arch/x86/kvm/vmx/vmx.c|6972| <<handle_external_interrupt_irqoff>> gate_desc *desc = (gate_desc *)host_idt_base + vector;
+	 *   - arch/x86/kvm/vmx/vmx.c|8510| <<hardware_setup>> host_idt_base = dt.address;
+	 */
 	vmcs_writel(HOST_IDTR_BASE, host_idt_base);   /* 22.2.4 */
 
 	vmcs_writel(HOST_RIP, (unsigned long)vmx_vmexit); /* 22.2.5 */
@@ -4280,6 +4408,11 @@ static void vmx_refresh_apicv_exec_ctrl(struct kvm_vcpu *vcpu)
 					SECONDARY_EXEC_VIRTUAL_INTR_DELIVERY);
 	}
 
+	/*
+	 * 在以下使用vmx_update_msr_bitmap_x2apic():
+	 *   - arch/x86/kvm/vmx/vmx.c|4313| <<vmx_refresh_apicv_exec_ctrl>> vmx_update_msr_bitmap_x2apic(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|6481| <<vmx_set_virtual_apic_mode>> vmx_update_msr_bitmap_x2apic(vcpu);
+	 */
 	vmx_update_msr_bitmap_x2apic(vcpu);
 }
 
@@ -4610,8 +4743,33 @@ static void vmx_vcpu_reset(struct kvm_vcpu *vcpu, bool init_event)
 	if (kvm_mpx_supported())
 		vmcs_write64(GUEST_BNDCFGS, 0);
 
+	/*
+	 * vmx代码中主要使用VM_ENTRY_INTR_INFO_FIELD的地方:
+	 *   - arch/x86/kvm/vmx/nested.c|2366| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+	 *   - arch/x86/kvm/vmx/nested.c|2377| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *   - arch/x86/kvm/vmx/vmx.c|1732| <<vmx_inject_exception>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr_info);
+	 *   - arch/x86/kvm/vmx/vmx.c|4653| <<vmx_vcpu_reset>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *   - arch/x86/kvm/vmx/vmx.c|4710| <<vmx_inject_irq>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr);
+	 *   - arch/x86/kvm/vmx/vmx.c|4740| <<vmx_inject_nmi>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+	 *   - arch/x86/kvm/vmx/vmx.c|6095| <<dump_vmcs>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *   - arch/x86/kvm/vmx/vmx.c|6952| <<vmx_cancel_injection>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *   - arch/x86/kvm/vmx/vmx.c|6956| <<vmx_cancel_injection>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *
+	 * bit 0-7: Vector of interrupt or exception
+	 * bit 8-10: interrupt type: 0-7不同的数, 0是external interrupt
+	 * bit 31: valid (cleared on every vm exit)
+	 */
 	vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);  /* 22.2.1 */
 
+	/*
+	 * 在以下使用KVM_REQ_APIC_PAGE_RELOAD:
+	 *   - arch/x86/kvm/vmx/nested.c|4691| <<nested_vmx_vmexit>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|4645| <<vmx_vcpu_reset>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|6462| <<vmx_set_virtual_apic_mode>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+	 *   - arch/x86/kvm/x86.c|10340| <<kvm_arch_mmu_notifier_invalidate_range>> kvm_make_all_cpus_request(kvm, KVM_REQ_APIC_PAGE_RELOAD);
+	 *
+	 * 处理的函数kvm_vcpu_reload_apic_access_page()
+	 */
 	kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
 
 	vpid_sync_context(vmx->vpid);
@@ -4621,6 +4779,19 @@ static void vmx_vcpu_reset(struct kvm_vcpu *vcpu, bool init_event)
 
 static void vmx_enable_irq_window(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用CPU_BASED_INTR_WINDOW_EXITING:
+	 *   - arch/x86/kvm/vmx/nested.c|2243| <<prepare_vmcs02_early>> exec_control &= ~CPU_BASED_INTR_WINDOW_EXITING;
+	 *   - arch/x86/kvm/vmx/nested.c|3417| <<nested_vmx_enter_non_root_mode>> evaluate_pending_interrupts =
+	 *           exec_controls_get(vmx) & (CPU_BASED_INTR_WINDOW_EXITING | CPU_BASED_NMI_WINDOW_EXITING);
+	 *   - arch/x86/kvm/vmx/nested.c|3673| <<nested_vmx_run>> if (... !(nested_cpu_has(vmcs12, CPU_BASED_INTR_WINDOW_EXITING) &&
+	 *   - arch/x86/kvm/vmx/nested.c|6115| <<nested_vmx_l1_wants_exit>> return nested_cpu_has(vmcs12, CPU_BASED_INTR_WINDOW_EXITING);
+	 *   - arch/x86/kvm/vmx/nested.c|6713| <<nested_vmx_setup_ctls_msrs>> msrs->procbased_ctls_high &= CPU_BASED_INTR_WINDOW_EXITING |
+	 *   - arch/x86/kvm/vmx/vmx.c|4782| <<vmx_enable_irq_window>> exec_controls_setbit(to_vmx(vcpu), CPU_BASED_INTR_WINDOW_EXITING);
+	 *   - arch/x86/kvm/vmx/vmx.c|5562| <<handle_interrupt_window>> exec_controls_clearbit(to_vmx(vcpu), CPU_BASED_INTR_WINDOW_EXITING);
+	 *   - arch/x86/kvm/vmx/vmx.c|5790| <<handle_invalid_guest_state>> intr_window_requested =
+	 *           exec_controls_get(vmx) & CPU_BASED_INTR_WINDOW_EXITING;
+	 */
 	exec_controls_setbit(to_vmx(vcpu), CPU_BASED_INTR_WINDOW_EXITING);
 }
 
@@ -4635,10 +4806,35 @@ static void vmx_enable_nmi_window(struct kvm_vcpu *vcpu)
 	exec_controls_setbit(to_vmx(vcpu), CPU_BASED_NMI_WINDOW_EXITING);
 }
 
+/*
+ * 在以下调用vmx_inject_irq():
+ *   - arch/x86/kvm/x86.c|9518| <<inject_pending_event>> static_call(kvm_x86_inject_irq)(vcpu, true);
+ *   - arch/x86/kvm/x86.c|9637| <<inject_pending_event>> static_call(kvm_x86_inject_irq)(vcpu, false);
+ */
 static void vmx_inject_irq(struct kvm_vcpu *vcpu, bool reinjected)
 {
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
 	uint32_t intr;
+	/*
+	 * struct kvm_vcpu *vcpu:
+	 * -> struct kvm_vcpu_arch arch;
+	 *        struct kvm_queued_exception {
+	 *            bool pending;
+	 *            bool injected;
+	 *            bool has_error_code;
+	 *            u8 nr;
+	 *            u32 error_code;
+	 *            unsigned long payload;
+	 *            bool has_payload;
+	 *            u8 nested_apf;
+	 *        } exception;
+	 *
+	 *        struct kvm_queued_interrupt {
+	 *            bool injected;
+	 *            bool soft;
+	 *            u8 nr;
+	 *        } interrupt;
+	 */
 	int irq = vcpu->arch.interrupt.nr;
 
 	trace_kvm_inj_virq(irq, vcpu->arch.interrupt.soft, reinjected);
@@ -4658,8 +4854,31 @@ static void vmx_inject_irq(struct kvm_vcpu *vcpu, bool reinjected)
 			     vmx->vcpu.arch.event_exit_inst_len);
 	} else
 		intr |= INTR_TYPE_EXT_INTR;
+	/*
+	 * vmx代码中主要使用VM_ENTRY_INTR_INFO_FIELD的地方:
+	 *   - arch/x86/kvm/vmx/nested.c|2366| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+	 *   - arch/x86/kvm/vmx/nested.c|2377| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *   - arch/x86/kvm/vmx/vmx.c|1732| <<vmx_inject_exception>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr_info);
+	 *   - arch/x86/kvm/vmx/vmx.c|4653| <<vmx_vcpu_reset>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *   - arch/x86/kvm/vmx/vmx.c|4710| <<vmx_inject_irq>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr);
+	 *   - arch/x86/kvm/vmx/vmx.c|4740| <<vmx_inject_nmi>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+	 *   - arch/x86/kvm/vmx/vmx.c|6095| <<dump_vmcs>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *   - arch/x86/kvm/vmx/vmx.c|6952| <<vmx_cancel_injection>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *   - arch/x86/kvm/vmx/vmx.c|6956| <<vmx_cancel_injection>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *
+	 * bit 0-7: Vector of interrupt or exception
+	 * bit 8-10: interrupt type: 0-7不同的数, 0是external interrupt
+	 * bit 31: valid (cleared on every vm exit)
+	 */
 	vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr);
 
+	/*
+	 * 在以下调用vmx_clear_hlt():
+	 *   - arch/x86/kvm/vmx/vmx.c|1734| <<vmx_inject_exception>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|4712| <<vmx_inject_irq>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|4743| <<vmx_inject_nmi>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|7989| <<vmx_enter_smm>> vmx_clear_hlt(vcpu);
+	 */
 	vmx_clear_hlt(vcpu);
 }
 
@@ -4688,9 +4907,32 @@ static void vmx_inject_nmi(struct kvm_vcpu *vcpu)
 		return;
 	}
 
+	/*
+	 * vmx代码中主要使用VM_ENTRY_INTR_INFO_FIELD的地方:
+	 *   - arch/x86/kvm/vmx/nested.c|2366| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+	 *   - arch/x86/kvm/vmx/nested.c|2377| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *   - arch/x86/kvm/vmx/vmx.c|1732| <<vmx_inject_exception>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr_info);
+	 *   - arch/x86/kvm/vmx/vmx.c|4653| <<vmx_vcpu_reset>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *   - arch/x86/kvm/vmx/vmx.c|4710| <<vmx_inject_irq>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr);
+	 *   - arch/x86/kvm/vmx/vmx.c|4740| <<vmx_inject_nmi>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+	 *   - arch/x86/kvm/vmx/vmx.c|6095| <<dump_vmcs>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *   - arch/x86/kvm/vmx/vmx.c|6952| <<vmx_cancel_injection>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *   - arch/x86/kvm/vmx/vmx.c|6956| <<vmx_cancel_injection>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *
+	 * bit 0-7: Vector of interrupt or exception
+	 * bit 8-10: interrupt type: 0-7不同的数, 0是external interrupt
+	 * bit 31: valid (cleared on every vm exit)
+	 */
 	vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
 			INTR_TYPE_NMI_INTR | INTR_INFO_VALID_MASK | NMI_VECTOR);
 
+	/*
+	 * 在以下调用vmx_clear_hlt():
+	 *   - arch/x86/kvm/vmx/vmx.c|1734| <<vmx_inject_exception>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|4712| <<vmx_inject_irq>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|4743| <<vmx_inject_nmi>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|7989| <<vmx_enter_smm>> vmx_clear_hlt(vcpu);
+	 */
 	vmx_clear_hlt(vcpu);
 }
 
@@ -4728,6 +4970,11 @@ void vmx_set_nmi_mask(struct kvm_vcpu *vcpu, bool masked)
 	}
 }
 
+/*
+ * 在以下调用vmx_nmi_blocked():
+ *   - arch/x86/kvm/vmx/nested.c|4019| <<vmx_check_nested_events>> if (vcpu->arch.nmi_pending && !vmx_nmi_blocked(vcpu)) {
+ *   - arch/x86/kvm/vmx/vmx.c|4995| <<vmx_nmi_allowed>> return !vmx_nmi_blocked(vcpu);
+ */
 bool vmx_nmi_blocked(struct kvm_vcpu *vcpu)
 {
 	if (is_guest_mode(vcpu) && nested_exit_on_nmi(vcpu))
@@ -4741,6 +4988,12 @@ bool vmx_nmi_blocked(struct kvm_vcpu *vcpu)
 		 GUEST_INTR_STATE_NMI));
 }
 
+/*
+ * 在以下使用kvm_x86_nmi_allowed():
+ *   - arch/x86/kvm/x86.c|9727| <<inject_pending_event>> r = can_inject ? static_call(kvm_x86_nmi_allowed)(vcpu, true) : -EBUSY;
+ *   - arch/x86/kvm/x86.c|9735| <<inject_pending_event>> WARN_ON(static_call(kvm_x86_nmi_allowed)(vcpu, true) < 0);
+ *   - arch/x86/kvm/x86.c|13270| <<kvm_vcpu_has_events>> static_call(kvm_x86_nmi_allowed)(vcpu, false)))
+ */
 static int vmx_nmi_allowed(struct kvm_vcpu *vcpu, bool for_injection)
 {
 	if (to_vmx(vcpu)->nested.nested_run_pending)
@@ -4884,6 +5137,18 @@ static int handle_machine_check(struct kvm_vcpu *vcpu)
  */
 bool vmx_guest_inject_ac(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用X86_FEATURE_SPLIT_LOCK_DETECT:
+	 *   - arch/x86/kernel/cpu/intel.c|1149| <<sld_state_setup>> if (!boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) &&
+	 *   - arch/x86/kernel/cpu/intel.c|1221| <<__split_lock_setup>> setup_force_cpu_cap(X86_FEATURE_SPLIT_LOCK_DETECT);
+	 *   - arch/x86/kernel/cpu/intel.c|1475| <<bus_lock_init>> if ((boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) &&
+	 *   - arch/x86/kernel/cpu/intel.c|1621| <<sld_state_show>> !boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 *   - arch/x86/kernel/cpu/intel.c|1643| <<sld_state_show>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1653| <<sld_state_show>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1657| <<sld_state_show>> boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) ?
+	 *   - arch/x86/kvm/vmx/vmx.c|4917| <<vmx_guest_inject_ac>> if (!boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 *   - arch/x86/kvm/x86.c|7297| <<emulator_cmpxchg_emulated>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 */
 	if (!boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
 		return true;
 
@@ -5318,6 +5583,19 @@ static int handle_tpr_below_threshold(struct kvm_vcpu *vcpu)
 
 static int handle_interrupt_window(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用CPU_BASED_INTR_WINDOW_EXITING:
+	 *   - arch/x86/kvm/vmx/nested.c|2243| <<prepare_vmcs02_early>> exec_control &= ~CPU_BASED_INTR_WINDOW_EXITING;
+	 *   - arch/x86/kvm/vmx/nested.c|3417| <<nested_vmx_enter_non_root_mode>> evaluate_pending_interrupts =
+	 *           exec_controls_get(vmx) & (CPU_BASED_INTR_WINDOW_EXITING | CPU_BASED_NMI_WINDOW_EXITING);
+	 *   - arch/x86/kvm/vmx/nested.c|3673| <<nested_vmx_run>> if (... !(nested_cpu_has(vmcs12, CPU_BASED_INTR_WINDOW_EXITING) &&
+	 *   - arch/x86/kvm/vmx/nested.c|6115| <<nested_vmx_l1_wants_exit>> return nested_cpu_has(vmcs12, CPU_BASED_INTR_WINDOW_EXITING);
+	 *   - arch/x86/kvm/vmx/nested.c|6713| <<nested_vmx_setup_ctls_msrs>> msrs->procbased_ctls_high &= CPU_BASED_INTR_WINDOW_EXITING |
+	 *   - arch/x86/kvm/vmx/vmx.c|4782| <<vmx_enable_irq_window>> exec_controls_setbit(to_vmx(vcpu), CPU_BASED_INTR_WINDOW_EXITING);
+	 *   - arch/x86/kvm/vmx/vmx.c|5562| <<handle_interrupt_window>> exec_controls_clearbit(to_vmx(vcpu), CPU_BASED_INTR_WINDOW_EXITING);
+	 *   - arch/x86/kvm/vmx/vmx.c|5790| <<handle_invalid_guest_state>> intr_window_requested =
+	 *           exec_controls_get(vmx) & CPU_BASED_INTR_WINDOW_EXITING;
+	 */
 	exec_controls_clearbit(to_vmx(vcpu), CPU_BASED_INTR_WINDOW_EXITING);
 
 	kvm_make_request(KVM_REQ_EVENT, vcpu);
@@ -5407,6 +5685,16 @@ static int handle_task_switch(struct kvm_vcpu *vcpu)
 			break;
 		case INTR_TYPE_EXT_INTR:
 		case INTR_TYPE_SOFT_INTR:
+			/*
+			 * 在以下调用kvm_clear_interrupt_queue():
+			 *   - arch/x86/kvm/svm/nested.c|1017| <<nested_svm_vmexit>> kvm_clear_interrupt_queue(vcpu);
+			 *   - arch/x86/kvm/svm/svm.c|2556| <<task_switch_interception>> kvm_clear_interrupt_queue(vcpu);
+			 *   - arch/x86/kvm/svm/svm.c|4012| <<svm_complete_interrupts>> kvm_clear_interrupt_queue(vcpu);
+			 *   - arch/x86/kvm/vmx/nested.c|4645| <<nested_vmx_vmexit>> kvm_clear_interrupt_queue(vcpu);
+			 *   - arch/x86/kvm/vmx/vmx.c|5440| <<handle_task_switch>> kvm_clear_interrupt_queue(vcpu);
+			 *   - arch/x86/kvm/vmx/vmx.c|6799| <<__vmx_complete_interrupts>> kvm_clear_interrupt_queue(vcpu);
+			 *   - arch/x86/kvm/x86.c|11947| <<kvm_vcpu_reset>> kvm_clear_interrupt_queue(vcpu);
+			 */
 			kvm_clear_interrupt_queue(vcpu);
 			break;
 		case INTR_TYPE_HARD_EXCEPTION:
@@ -5517,6 +5805,9 @@ static int handle_ept_misconfig(struct kvm_vcpu *vcpu)
 	return kvm_mmu_page_fault(vcpu, gpa, PFERR_RSVD_MASK, NULL, 0);
 }
 
+/*
+ * EXIT_REASON_NMI_WINDOW
+ */
 static int handle_nmi_window(struct kvm_vcpu *vcpu)
 {
 	if (KVM_BUG_ON(!enable_vnmi, vcpu->kvm))
@@ -5686,10 +5977,22 @@ static int handle_pml_full(struct kvm_vcpu *vcpu)
 	return 1;
 }
 
+/*
+ * 在以下调用handle_fastpath_preemption_timer():
+ *   - arch/x86/kvm/vmx/vmx.c|5704| <<handle_preemption_timer>> handle_fastpath_preemption_timer(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|6875| <<vmx_exit_handlers_fastpath>> return handle_fastpath_preemption_timer(vcpu);
+ */
 static fastpath_t handle_fastpath_preemption_timer(struct kvm_vcpu *vcpu)
 {
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
 
+	/*
+	 * 在以下使用vcpu_vmx->req_immediate_exit:
+	 *   - arch/x86/kvm/vmx/vmx.c|1196| <<vmx_prepare_switch_to_guest>> vmx->req_immediate_exit = false;
+	 *   - arch/x86/kvm/vmx/vmx.c|5906| <<handle_fastpath_preemption_timer>> if (!vmx->req_immediate_exit &&
+	 *   - arch/x86/kvm/vmx/vmx.c|7146| <<vmx_update_hv_timer>> if (vmx->req_immediate_exit) {
+	 *   - arch/x86/kvm/vmx/vmx.c|7907| <<vmx_request_immediate_exit>> to_vmx(vcpu)->req_immediate_exit = true;
+	 */
 	if (!vmx->req_immediate_exit &&
 	    !unlikely(vmx->loaded_vmcs->hv_timer_soft_disabled)) {
 		kvm_lapic_expired_hv_timer(vcpu);
@@ -5810,6 +6113,22 @@ static void vmx_get_exit_info(struct kvm_vcpu *vcpu, u32 *reason,
 	*reason = vmx->exit_reason.full;
 	*info1 = vmx_get_exit_qual(vcpu);
 	if (!(vmx->exit_reason.failed_vmentry)) {
+		/*
+		 * 在以下使用vcpu_vmx->idt_vectoring_info:
+		 *   - arch/x86/kvm/vmx/vmx.c|5129| <<handle_exception_nmi>> vect_info = vmx->idt_vectoring_info;
+		 *   - arch/x86/kvm/vmx/vmx.c|5622| <<handle_task_switch>> idt_v = (vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK);
+		 *   - arch/x86/kvm/vmx/vmx.c|5623| <<handle_task_switch>> idt_index = (vmx->idt_vectoring_info & VECTORING_INFO_VECTOR_MASK);
+		 *   - arch/x86/kvm/vmx/vmx.c|5624| <<handle_task_switch>> type = (vmx->idt_vectoring_info & VECTORING_INFO_TYPE_MASK);
+		 *   - arch/x86/kvm/vmx/vmx.c|5650| <<handle_task_switch>> if (vmx->idt_vectoring_info &
+		 *   - arch/x86/kvm/vmx/vmx.c|5694| <<handle_ept_violation>> if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&
+		 *   - arch/x86/kvm/vmx/vmx.c|5913| <<handle_pml_full>> if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&
+		 *   - arch/x86/kvm/vmx/vmx.c|6062| <<vmx_get_exit_info>> *info2 = vmx->idt_vectoring_info;
+		 *   - arch/x86/kvm/vmx/vmx.c|6314| <<__vmx_handle_exit>> u32 vectoring_info = vmx->idt_vectoring_info;
+		 *   - arch/x86/kvm/vmx/vmx.c|6989| <<vmx_recover_nmi_blocking>> idtv_info_valid = vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK;
+		 *   - arch/x86/kvm/vmx/vmx.c|7125| <<vmx_complete_interrupts>> __vmx_complete_interrupts(&vmx->vcpu, vmx->idt_vectoring_info,
+		 *   - arch/x86/kvm/vmx/vmx.c|7427| <<vmx_vcpu_run>> vmx->idt_vectoring_info = 0;
+		 *   - arch/x86/kvm/vmx/vmx.c|7439| <<vmx_vcpu_run>> vmx->idt_vectoring_info = vmcs_read32(IDT_VECTORING_INFO_FIELD);
+		 */
 		*info2 = vmx->idt_vectoring_info;
 		*intr_info = vmx_get_intr_info(vcpu);
 		if (is_exception_with_error_code(*intr_info))
@@ -6062,6 +6381,22 @@ static int __vmx_handle_exit(struct kvm_vcpu *vcpu, fastpath_t exit_fastpath)
 {
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
 	union vmx_exit_reason exit_reason = vmx->exit_reason;
+	/*
+	 * 在以下使用vcpu_vmx->idt_vectoring_info:
+	 *   - arch/x86/kvm/vmx/vmx.c|5129| <<handle_exception_nmi>> vect_info = vmx->idt_vectoring_info;
+	 *   - arch/x86/kvm/vmx/vmx.c|5622| <<handle_task_switch>> idt_v = (vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK);
+	 *   - arch/x86/kvm/vmx/vmx.c|5623| <<handle_task_switch>> idt_index = (vmx->idt_vectoring_info & VECTORING_INFO_VECTOR_MASK);
+	 *   - arch/x86/kvm/vmx/vmx.c|5624| <<handle_task_switch>> type = (vmx->idt_vectoring_info & VECTORING_INFO_TYPE_MASK);
+	 *   - arch/x86/kvm/vmx/vmx.c|5650| <<handle_task_switch>> if (vmx->idt_vectoring_info &
+	 *   - arch/x86/kvm/vmx/vmx.c|5694| <<handle_ept_violation>> if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&
+	 *   - arch/x86/kvm/vmx/vmx.c|5913| <<handle_pml_full>> if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&
+	 *   - arch/x86/kvm/vmx/vmx.c|6062| <<vmx_get_exit_info>> *info2 = vmx->idt_vectoring_info;
+	 *   - arch/x86/kvm/vmx/vmx.c|6314| <<__vmx_handle_exit>> u32 vectoring_info = vmx->idt_vectoring_info;
+	 *   - arch/x86/kvm/vmx/vmx.c|6989| <<vmx_recover_nmi_blocking>> idtv_info_valid = vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK;
+	 *   - arch/x86/kvm/vmx/vmx.c|7125| <<vmx_complete_interrupts>> __vmx_complete_interrupts(&vmx->vcpu, vmx->idt_vectoring_info,
+	 *   - arch/x86/kvm/vmx/vmx.c|7427| <<vmx_vcpu_run>> vmx->idt_vectoring_info = 0;
+	 *   - arch/x86/kvm/vmx/vmx.c|7439| <<vmx_vcpu_run>> vmx->idt_vectoring_info = vmcs_read32(IDT_VECTORING_INFO_FIELD);
+	 */
 	u32 vectoring_info = vmx->idt_vectoring_info;
 	u16 exit_handler_index;
 
@@ -6236,6 +6571,36 @@ static int __vmx_handle_exit(struct kvm_vcpu *vcpu, fastpath_t exit_fastpath)
 	return 0;
 }
 
+/*
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_vcpu_reset
+ * kvm_apic_accept_events
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_lapic_reg_write
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ */
 static int vmx_handle_exit(struct kvm_vcpu *vcpu, fastpath_t exit_fastpath)
 {
 	int ret = __vmx_handle_exit(vcpu, exit_fastpath);
@@ -6372,6 +6737,15 @@ void vmx_set_virtual_apic_mode(struct kvm_vcpu *vcpu)
 		if (flexpriority_enabled) {
 			sec_exec_control |=
 				SECONDARY_EXEC_VIRTUALIZE_APIC_ACCESSES;
+			/*
+			 * 在以下使用KVM_REQ_APIC_PAGE_RELOAD:
+			 *   - arch/x86/kvm/vmx/nested.c|4691| <<nested_vmx_vmexit>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+			 *   - arch/x86/kvm/vmx/vmx.c|4645| <<vmx_vcpu_reset>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+			 *   - arch/x86/kvm/vmx/vmx.c|6462| <<vmx_set_virtual_apic_mode>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+			 *   - arch/x86/kvm/x86.c|10340| <<kvm_arch_mmu_notifier_invalidate_range>> kvm_make_all_cpus_request(kvm, KVM_REQ_APIC_PAGE_RELOAD);
+			 *
+			 * 处理的函数kvm_vcpu_reload_apic_access_page()
+			 */
 			kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
 
 			/*
@@ -6391,6 +6765,11 @@ void vmx_set_virtual_apic_mode(struct kvm_vcpu *vcpu)
 	}
 	secondary_exec_controls_set(vmx, sec_exec_control);
 
+	/*
+	 * 在以下使用vmx_update_msr_bitmap_x2apic():
+	 *   - arch/x86/kvm/vmx/vmx.c|4313| <<vmx_refresh_apicv_exec_ctrl>> vmx_update_msr_bitmap_x2apic(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|6481| <<vmx_set_virtual_apic_mode>> vmx_update_msr_bitmap_x2apic(vcpu);
+	 */
 	vmx_update_msr_bitmap_x2apic(vcpu);
 }
 
@@ -6422,6 +6801,33 @@ static void vmx_set_apic_access_page_addr(struct kvm_vcpu *vcpu)
 	put_page(page);
 }
 
+/*
+ * vmx_hwapic_isr_update
+ * kvm_lapic_reset
+ * kvm_vcpu_reset
+ * kvm_apic_accept_events
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * vmx_hwapic_isr_update
+ * kvm_apic_set_state
+ * kvm_arch_vcpu_ioctl
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * 在以下调用kvm_x86_hwapic_isr_update:
+ *   - arch/x86/kvm/lapic.c|1003| <<apic_set_isr>> static_call(kvm_x86_hwapic_isr_update)(vcpu, vec);
+ *   - arch/x86/kvm/lapic.c|1129| <<apic_clear_isr>> static_call(kvm_x86_hwapic_isr_update)(vcpu, apic_find_highest_isr(apic));
+ *   - arch/x86/kvm/lapic.c|3622| <<kvm_lapic_reset>> static_call(kvm_x86_hwapic_isr_update)(vcpu, -1);
+ *   - arch/x86/kvm/lapic.c|4127| <<kvm_apic_set_state>> static_call(kvm_x86_hwapic_isr_update)(vcpu, apic_find_highest_isr(apic));
+ *
+ * struct kvm_x86_ops vmx_x86_ops.hwapic_isr_update = vmx_hwapic_isr_update()
+ */
 static void vmx_hwapic_isr_update(struct kvm_vcpu *vcpu, int max_isr)
 {
 	u16 status;
@@ -6447,6 +6853,11 @@ static void vmx_set_rvi(int vector)
 	if (vector == -1)
 		vector = 0;
 
+	/*
+	 * GUEST_INTR_STATUS一共16位
+	 * 低16位是RVI
+	 * 高16位是SVI
+	 */
 	status = vmcs_read16(GUEST_INTR_STATUS);
 	old = (u8)status & 0xff;
 	if ((u8)vector != old) {
@@ -6456,6 +6867,9 @@ static void vmx_set_rvi(int vector)
 	}
 }
 
+/*
+ * struct kvm_x86_ops vmx_x86_opshwapic_irr_update = vmx_hwapic_irr_update()
+ */
 static void vmx_hwapic_irr_update(struct kvm_vcpu *vcpu, int max_irr)
 {
 	/*
@@ -6470,6 +6884,16 @@ static void vmx_hwapic_irr_update(struct kvm_vcpu *vcpu, int max_irr)
 		vmx_set_rvi(max_irr);
 }
 
+/*
+ * 在以下调用kvm_x86_sync_pir_to_irr()
+ *   - arch/x86/kvm/lapic.c|789| <<apic_has_interrupt_for_ppr>> highest_irr = static_call(kvm_x86_sync_pir_to_irr)(apic->vcpu);
+ *   - arch/x86/kvm/x86.c|4623| <<kvm_vcpu_ioctl_get_lapic>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+ *   - arch/x86/kvm/x86.c|9842| <<vcpu_scan_ioapic>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+ *   - arch/x86/kvm/x86.c|10171| <<vcpu_enter_guest>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+ *   - arch/x86/kvm/x86.c|10220| <<vcpu_enter_guest>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+ *
+ * struct kvm_x86_ops vmx_x86_ops.sync_pir_to_irr = vmx_sync_pir_to_irr()
+ */
 static int vmx_sync_pir_to_irr(struct kvm_vcpu *vcpu)
 {
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
@@ -6516,6 +6940,13 @@ static int vmx_sync_pir_to_irr(struct kvm_vcpu *vcpu)
 	return max_irr;
 }
 
+/*
+ * 在以下调用kvm_x86_load_eoi_exitmap():
+ *   - arch/x86/kvm/x86.c|9921| <<vcpu_load_eoi_exitmap>> static_call(kvm_x86_load_eoi_exitmap)(vcpu, eoi_exit_bitmap);
+ *   - arch/x86/kvm/x86.c|9928| <<vcpu_load_eoi_exitmap>> static_call(kvm_x86_load_eoi_exitmap)(
+ *
+ * 在以下使用struct kvm_x86_ops vmx_x86_ops.load_eoi_exitmap = vmx_load_eoi_exitmap()
+ */
 static void vmx_load_eoi_exitmap(struct kvm_vcpu *vcpu, u64 *eoi_exit_bitmap)
 {
 	if (!kvm_vcpu_apicv_active(vcpu))
@@ -6537,9 +6968,20 @@ static void vmx_apicv_post_state_restore(struct kvm_vcpu *vcpu)
 
 void vmx_do_interrupt_nmi_irqoff(unsigned long entry);
 
+/*
+ * 在以下调用handle_interrupt_nmi_irqoff():
+ *   - arch/x86/kvm/vmx/vmx.c|6961| <<handle_exception_nmi_irqoff>> handle_interrupt_nmi_irqoff(&vmx->vcpu, nmi_entry);
+ *   - arch/x86/kvm/vmx/vmx.c|6978| <<handle_external_interrupt_irqoff>> handle_interrupt_nmi_irqoff(vcpu, gate_offset(desc));
+ */
 static void handle_interrupt_nmi_irqoff(struct kvm_vcpu *vcpu,
 					unsigned long entry)
 {
+	/*
+	 * 在以下使用kvm_before_interrupt():
+	 *   - arch/x86/kvm/svm/svm.c|4206| <<svm_vcpu_run>> kvm_before_interrupt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|6920| <<handle_interrupt_nmi_irqoff>> kvm_before_interrupt(vcpu);
+	 *   - arch/x86/kvm/x86.c|11036| <<vcpu_enter_guest>> kvm_before_interrupt(vcpu);
+	 */
 	kvm_before_interrupt(vcpu);
 	vmx_do_interrupt_nmi_irqoff(entry);
 	kvm_after_interrupt(vcpu);
@@ -6565,9 +7007,16 @@ static void handle_nm_fault_irqoff(struct kvm_vcpu *vcpu)
 		rdmsrl(MSR_IA32_XFD_ERR, vcpu->arch.guest_fpu.xfd_err);
 }
 
+/*
+ * 处理EXIT_REASON_EXCEPTION_NMI:
+ *   - arch/x86/kvm/vmx/vmx.c|6992| <<vmx_handle_exit_irqoff>> handle_exception_nmi_irqoff(vmx);
+ */
 static void handle_exception_nmi_irqoff(struct vcpu_vmx *vmx)
 {
 	const unsigned long nmi_entry = (unsigned long)asm_exc_nmi_noist;
+	/*
+	 * 告诉VMM(Hypervisor)此次VM-exit是由于某个中断,异常或NMI等原因引起的
+	 */
 	u32 intr_info = vmx_get_intr_info(&vmx->vcpu);
 
 	/* if exit due to PF check for async PF */
@@ -6582,19 +7031,51 @@ static void handle_exception_nmi_irqoff(struct vcpu_vmx *vmx)
 	/* We need to handle NMIs before interrupts are enabled */
 	else if (is_nmi(intr_info))
 		handle_interrupt_nmi_irqoff(&vmx->vcpu, nmi_entry);
+
+	/*
+	 * 在以下调用handle_interrupt_nmi_irqoff():
+	 *   - arch/x86/kvm/vmx/vmx.c|6961| <<handle_exception_nmi_irqoff>> handle_interrupt_nmi_irqoff(&vmx->vcpu, nmi_entry);
+	 *   - arch/x86/kvm/vmx/vmx.c|6978| <<handle_external_interrupt_irqoff>> handle_interrupt_nmi_irqoff(vcpu, gate_offset(desc));
+	 */
 }
 
+/*
+ * 处理EXIT_REASON_EXTERNAL_INTERRUPT:
+ *   - arch/x86/kvm/vmx/vmx.c|6986| <<vmx_handle_exit_irqoff>> handle_external_interrupt_irqoff(vcpu);
+ */
 static void handle_external_interrupt_irqoff(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 告诉VMM(Hypervisor)此次VM-exit是由于某个中断,异常或NMI等原因引起的
+	 */
 	u32 intr_info = vmx_get_intr_info(vcpu);
 	unsigned int vector = intr_info & INTR_INFO_VECTOR_MASK;
+	/*
+	 * 在以下使用host_idt_base:
+	 *   - arch/x86/kvm/vmx/vmx.c|518| <<global>> static unsigned long host_idt_base;
+	 *   - arch/x86/kvm/vmx/vmx.c|4304| <<vmx_set_constant_host_state>> vmcs_writel(HOST_IDTR_BASE, host_idt_base);
+	 *   - arch/x86/kvm/vmx/vmx.c|6972| <<handle_external_interrupt_irqoff>> gate_desc *desc = (gate_desc *)host_idt_base + vector;
+	 *   - arch/x86/kvm/vmx/vmx.c|8510| <<hardware_setup>> host_idt_base = dt.address;
+	 */
 	gate_desc *desc = (gate_desc *)host_idt_base + vector;
 
 	if (KVM_BUG(!is_external_intr(intr_info), vcpu->kvm,
 	    "KVM: unexpected VM-Exit interrupt info: 0x%x", intr_info))
 		return;
 
+	/*
+	 * 在以下调用handle_interrupt_nmi_irqoff():
+	 *   - arch/x86/kvm/vmx/vmx.c|6961| <<handle_exception_nmi_irqoff>> handle_interrupt_nmi_irqoff(&vmx->vcpu, nmi_entry);
+	 *   - arch/x86/kvm/vmx/vmx.c|6978| <<handle_external_interrupt_irqoff>> handle_interrupt_nmi_irqoff(vcpu, gate_offset(desc));
+	 */
 	handle_interrupt_nmi_irqoff(vcpu, gate_offset(desc));
+	/*
+	 * 在以下使用kvm_vcpu_arch->at_instruction_boundary:
+	 *   - arch/x86/kvm/svm/svm.c|4585| <<svm_handle_exit_irqoff>> vcpu->arch.at_instruction_boundary = true;
+	 *   - arch/x86/kvm/vmx/vmx.c|6979| <<handle_external_interrupt_irqoff>> vcpu->arch.at_instruction_boundary = true;
+	 *   - arch/x86/kvm/x86.c|4744| <<kvm_steal_time_set_preempted>> if (!vcpu->arch.at_instruction_boundary) {
+	 *   - arch/x86/kvm/x86.c|11223| <<vcpu_run>> vcpu->arch.at_instruction_boundary = false;
+	 */
 	vcpu->arch.at_instruction_boundary = true;
 }
 
@@ -6674,6 +7155,29 @@ static void vmx_recover_nmi_blocking(struct vcpu_vmx *vmx)
 					      vmx->loaded_vmcs->entry_time));
 }
 
+/*
+ * 在以下使用vcpu_vmx->idt_vectoring_info:
+ *   - arch/x86/kvm/vmx/vmx.c|5129| <<handle_exception_nmi>> vect_info = vmx->idt_vectoring_info;
+ *   - arch/x86/kvm/vmx/vmx.c|5622| <<handle_task_switch>> idt_v = (vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK);
+ *   - arch/x86/kvm/vmx/vmx.c|5623| <<handle_task_switch>> idt_index = (vmx->idt_vectoring_info & VECTORING_INFO_VECTOR_MASK);
+ *   - arch/x86/kvm/vmx/vmx.c|5624| <<handle_task_switch>> type = (vmx->idt_vectoring_info & VECTORING_INFO_TYPE_MASK);
+ *   - arch/x86/kvm/vmx/vmx.c|5650| <<handle_task_switch>> if (vmx->idt_vectoring_info &
+ *   - arch/x86/kvm/vmx/vmx.c|5694| <<handle_ept_violation>> if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&
+ *   - arch/x86/kvm/vmx/vmx.c|5913| <<handle_pml_full>> if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&
+ *   - arch/x86/kvm/vmx/vmx.c|6062| <<vmx_get_exit_info>> *info2 = vmx->idt_vectoring_info;
+ *   - arch/x86/kvm/vmx/vmx.c|6314| <<__vmx_handle_exit>> u32 vectoring_info = vmx->idt_vectoring_info;
+ *   - arch/x86/kvm/vmx/vmx.c|6989| <<vmx_recover_nmi_blocking>> idtv_info_valid = vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK;
+ *   - arch/x86/kvm/vmx/vmx.c|7125| <<vmx_complete_interrupts>> __vmx_complete_interrupts(&vmx->vcpu, vmx->idt_vectoring_info,
+ *   - arch/x86/kvm/vmx/vmx.c|7427| <<vmx_vcpu_run>> vmx->idt_vectoring_info = 0;
+ *   - arch/x86/kvm/vmx/vmx.c|7439| <<vmx_vcpu_run>> vmx->idt_vectoring_info = vmcs_read32(IDT_VECTORING_INFO_FIELD);
+ *
+ *
+ * 在以下使用__vmx_complete_interrupts():
+ *   - arch/x86/kvm/vmx/vmx.c|6842| <<vmx_complete_interrupts>> __vmx_complete_interrupts(&vmx->vcpu, vmx->idt_vectoring_info,
+ *                                        VM_EXIT_INSTRUCTION_LEN, IDT_VECTORING_ERROR_CODE);
+ *   - arch/x86/kvm/vmx/vmx.c|6849| <<vmx_cancel_injection>> __vmx_complete_interrupts(vcpu, vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+ *                                        VM_ENTRY_INSTRUCTION_LEN, VM_ENTRY_EXCEPTION_ERROR_CODE);
+ */
 static void __vmx_complete_interrupts(struct kvm_vcpu *vcpu,
 				      u32 idt_vectoring_info,
 				      int instr_len_field,
@@ -6683,15 +7187,39 @@ static void __vmx_complete_interrupts(struct kvm_vcpu *vcpu,
 	int type;
 	bool idtv_info_valid;
 
+	/*
+	 * 描述原本准备注入给 guest 的中断,但由于 VM-exit 等原因被中断了.
+	 */
+
 	idtv_info_valid = idt_vectoring_info & VECTORING_INFO_VALID_MASK;
 
 	vcpu->arch.nmi_injected = false;
+	/*
+	 * 在以下调用kvm_clear_interrupt_queue():
+	 *   - arch/x86/kvm/svm/nested.c|1017| <<nested_svm_vmexit>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/svm/svm.c|2556| <<task_switch_interception>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/svm/svm.c|4012| <<svm_complete_interrupts>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/vmx/nested.c|4645| <<nested_vmx_vmexit>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|5440| <<handle_task_switch>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|6799| <<__vmx_complete_interrupts>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/x86.c|11947| <<kvm_vcpu_reset>> kvm_clear_interrupt_queue(vcpu);
+	 *
+	 * vcpu->arch.exception.pending = false;
+	 * vcpu->arch.exception.injected = false;
+	 */
 	kvm_clear_exception_queue(vcpu);
+	/*
+	 * vcpu->arch.interrupt.injected = false;
+	 */
 	kvm_clear_interrupt_queue(vcpu);
 
 	if (!idtv_info_valid)
 		return;
 
+	/*
+	 * 这里很重要
+	 * 会触发inject_pending_event()
+	 */
 	kvm_make_request(KVM_REQ_EVENT, vcpu);
 
 	vector = idt_vectoring_info & VECTORING_INFO_VECTOR_MASK;
@@ -6721,6 +7249,19 @@ static void __vmx_complete_interrupts(struct kvm_vcpu *vcpu,
 		vcpu->arch.event_exit_inst_len = vmcs_read32(instr_len_field);
 		fallthrough;
 	case INTR_TYPE_EXT_INTR:
+		/*
+		 * 在以下使用kvm_queue_interrupt():
+		 *   - arch/x86/kvm/svm/svm.c|4045| <<svm_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, false);
+		 *   - arch/x86/kvm/svm/svm.c|4048| <<svm_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, true);
+		 *   - arch/x86/kvm/vmx/vmx.c|6768| <<__vmx_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, type == INTR_TYPE_SOFT_INTR);
+		 *   - arch/x86/kvm/x86.c|4713| <<kvm_vcpu_ioctl_interrupt>> kvm_queue_interrupt(vcpu, irq->irq, false);
+		 *   - arch/x86/kvm/x86.c|9490| <<inject_pending_event>> kvm_queue_interrupt(vcpu, irq, false);
+		 *   - arch/x86/kvm/x86.c|11223| <<__set_sregs>> kvm_queue_interrupt(vcpu, pending_vec, false);
+		 *
+		 * vcpu->arch.interrupt.injected = true;
+		 * vcpu->arch.interrupt.soft = soft;
+		 * vcpu->arch.interrupt.nr = vector;
+		 */
 		kvm_queue_interrupt(vcpu, vector, type == INTR_TYPE_SOFT_INTR);
 		break;
 	default:
@@ -6728,20 +7269,72 @@ static void __vmx_complete_interrupts(struct kvm_vcpu *vcpu,
 	}
 }
 
+/*
+ * 在以下使用vmx_complete_interrupts():
+ *   - arch/x86/kvm/vmx/vmx.c|7133| <<vmx_vcpu_run>> vmx_complete_interrupts(vmx);
+ */
 static void vmx_complete_interrupts(struct vcpu_vmx *vmx)
 {
+	/*
+	 * 在以下使用vcpu_vmx->idt_vectoring_info:
+	 *   - arch/x86/kvm/vmx/vmx.c|5129| <<handle_exception_nmi>> vect_info = vmx->idt_vectoring_info;
+	 *   - arch/x86/kvm/vmx/vmx.c|5622| <<handle_task_switch>> idt_v = (vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK);
+	 *   - arch/x86/kvm/vmx/vmx.c|5623| <<handle_task_switch>> idt_index = (vmx->idt_vectoring_info & VECTORING_INFO_VECTOR_MASK);
+	 *   - arch/x86/kvm/vmx/vmx.c|5624| <<handle_task_switch>> type = (vmx->idt_vectoring_info & VECTORING_INFO_TYPE_MASK);
+	 *   - arch/x86/kvm/vmx/vmx.c|5650| <<handle_task_switch>> if (vmx->idt_vectoring_info &
+	 *   - arch/x86/kvm/vmx/vmx.c|5694| <<handle_ept_violation>> if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&
+	 *   - arch/x86/kvm/vmx/vmx.c|5913| <<handle_pml_full>> if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&
+	 *   - arch/x86/kvm/vmx/vmx.c|6062| <<vmx_get_exit_info>> *info2 = vmx->idt_vectoring_info;
+	 *   - arch/x86/kvm/vmx/vmx.c|6314| <<__vmx_handle_exit>> u32 vectoring_info = vmx->idt_vectoring_info;
+	 *   - arch/x86/kvm/vmx/vmx.c|6989| <<vmx_recover_nmi_blocking>> idtv_info_valid = vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK;
+	 *   - arch/x86/kvm/vmx/vmx.c|7125| <<vmx_complete_interrupts>> __vmx_complete_interrupts(&vmx->vcpu, vmx->idt_vectoring_info,
+	 *   - arch/x86/kvm/vmx/vmx.c|7427| <<vmx_vcpu_run>> vmx->idt_vectoring_info = 0;
+	 *   - arch/x86/kvm/vmx/vmx.c|7439| <<vmx_vcpu_run>> vmx->idt_vectoring_info = vmcs_read32(IDT_VECTORING_INFO_FIELD);
+	 *
+	 * 在以下使用__vmx_complete_interrupts():
+	 *   - arch/x86/kvm/vmx/vmx.c|6842| <<vmx_complete_interrupts>> __vmx_complete_interrupts(&vmx->vcpu, vmx->idt_vectoring_info,
+	 *                                        VM_EXIT_INSTRUCTION_LEN, IDT_VECTORING_ERROR_CODE);
+	 *   - arch/x86/kvm/vmx/vmx.c|6849| <<vmx_cancel_injection>> __vmx_complete_interrupts(vcpu, vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *                                        VM_ENTRY_INSTRUCTION_LEN, VM_ENTRY_EXCEPTION_ERROR_CODE);
+	 */
 	__vmx_complete_interrupts(&vmx->vcpu, vmx->idt_vectoring_info,
 				  VM_EXIT_INSTRUCTION_LEN,
 				  IDT_VECTORING_ERROR_CODE);
 }
 
+/*
+ * struct kvm_x86_ops vmx_x86_ops.cancel_injection = vmx_cancel_injection()
+ */
 static void vmx_cancel_injection(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用__vmx_complete_interrupts():
+	 *   - arch/x86/kvm/vmx/vmx.c|6842| <<vmx_complete_interrupts>> __vmx_complete_interrupts(&vmx->vcpu, vmx->idt_vectoring_info,
+	 *                                        VM_EXIT_INSTRUCTION_LEN, IDT_VECTORING_ERROR_CODE);
+	 *   - arch/x86/kvm/vmx/vmx.c|6849| <<vmx_cancel_injection>> __vmx_complete_interrupts(vcpu, vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *                                        VM_ENTRY_INSTRUCTION_LEN, VM_ENTRY_EXCEPTION_ERROR_CODE);
+	 */
 	__vmx_complete_interrupts(vcpu,
 				  vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
 				  VM_ENTRY_INSTRUCTION_LEN,
 				  VM_ENTRY_EXCEPTION_ERROR_CODE);
 
+	/*
+	 * vmx代码中主要使用VM_ENTRY_INTR_INFO_FIELD的地方:
+	 *   - arch/x86/kvm/vmx/nested.c|2366| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+	 *   - arch/x86/kvm/vmx/nested.c|2377| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *   - arch/x86/kvm/vmx/vmx.c|1732| <<vmx_inject_exception>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr_info);
+	 *   - arch/x86/kvm/vmx/vmx.c|4653| <<vmx_vcpu_reset>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *   - arch/x86/kvm/vmx/vmx.c|4710| <<vmx_inject_irq>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr);
+	 *   - arch/x86/kvm/vmx/vmx.c|4740| <<vmx_inject_nmi>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+	 *   - arch/x86/kvm/vmx/vmx.c|6095| <<dump_vmcs>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *   - arch/x86/kvm/vmx/vmx.c|6952| <<vmx_cancel_injection>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *   - arch/x86/kvm/vmx/vmx.c|6956| <<vmx_cancel_injection>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *
+	 * bit 0-7: Vector of interrupt or exception
+	 * bit 8-10: interrupt type: 0-7不同的数, 0是external interrupt
+	 * bit 31: valid (cleared on every vm exit)
+	 */
 	vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
 }
 
@@ -6769,6 +7362,13 @@ static void vmx_update_hv_timer(struct kvm_vcpu *vcpu)
 	u64 tscl;
 	u32 delta_tsc;
 
+	/*
+	 * 在以下使用vcpu_vmx->req_immediate_exit:
+	 *   - arch/x86/kvm/vmx/vmx.c|1196| <<vmx_prepare_switch_to_guest>> vmx->req_immediate_exit = false;
+	 *   - arch/x86/kvm/vmx/vmx.c|5906| <<handle_fastpath_preemption_timer>> if (!vmx->req_immediate_exit &&
+	 *   - arch/x86/kvm/vmx/vmx.c|7146| <<vmx_update_hv_timer>> if (vmx->req_immediate_exit) {
+	 *   - arch/x86/kvm/vmx/vmx.c|7907| <<vmx_request_immediate_exit>> to_vmx(vcpu)->req_immediate_exit = true;
+	 */
 	if (vmx->req_immediate_exit) {
 		vmcs_write32(VMX_PREEMPTION_TIMER_VALUE, 0);
 		vmx->loaded_vmcs->hv_timer_soft_disabled = false;
@@ -6822,6 +7422,10 @@ void noinstr vmx_spec_ctrl_restore_host(struct vcpu_vmx *vmx,
 	barrier_nospec();
 }
 
+/*
+ * 在以下调用vmx_exit_handlers_fastpath():
+ *   - arch/x86/kvm/vmx/vmx.c|7069| <<vmx_vcpu_run>> return vmx_exit_handlers_fastpath(vcpu);
+ */
 static fastpath_t vmx_exit_handlers_fastpath(struct kvm_vcpu *vcpu)
 {
 	switch (to_vmx(vcpu)->exit_reason.basic) {
@@ -7017,6 +7621,9 @@ static fastpath_t vmx_vcpu_run(struct kvm_vcpu *vcpu)
 	vmx->loaded_vmcs->launched = 1;
 
 	vmx_recover_nmi_blocking(vmx);
+	/*
+	 * 只在这里使用
+	 */
 	vmx_complete_interrupts(vmx);
 
 	if (is_guest_mode(vcpu))
@@ -7526,6 +8133,13 @@ static __init void vmx_set_cpu_caps(void)
 
 static void vmx_request_immediate_exit(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用vcpu_vmx->req_immediate_exit:
+	 *   - arch/x86/kvm/vmx/vmx.c|1196| <<vmx_prepare_switch_to_guest>> vmx->req_immediate_exit = false;
+	 *   - arch/x86/kvm/vmx/vmx.c|5906| <<handle_fastpath_preemption_timer>> if (!vmx->req_immediate_exit &&
+	 *   - arch/x86/kvm/vmx/vmx.c|7146| <<vmx_update_hv_timer>> if (vmx->req_immediate_exit) {
+	 *   - arch/x86/kvm/vmx/vmx.c|7907| <<vmx_request_immediate_exit>> to_vmx(vcpu)->req_immediate_exit = true;
+	 */
 	to_vmx(vcpu)->req_immediate_exit = true;
 }
 
@@ -7759,6 +8373,13 @@ static int vmx_enter_smm(struct kvm_vcpu *vcpu, char *smstate)
 
 	vmx->nested.smm.vmxon = vmx->nested.vmxon;
 	vmx->nested.vmxon = false;
+	/*
+	 * 在以下调用vmx_clear_hlt():
+	 *   - arch/x86/kvm/vmx/vmx.c|1734| <<vmx_inject_exception>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|4712| <<vmx_inject_irq>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|4743| <<vmx_inject_nmi>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|7989| <<vmx_enter_smm>> vmx_clear_hlt(vcpu);
+	 */
 	vmx_clear_hlt(vcpu);
 	return 0;
 }
@@ -7997,6 +8618,13 @@ static __init int hardware_setup(void)
 	int r, ept_lpage_level;
 
 	store_idt(&dt);
+	/*
+	 * 在以下使用host_idt_base:
+	 *   - arch/x86/kvm/vmx/vmx.c|518| <<global>> static unsigned long host_idt_base;
+	 *   - arch/x86/kvm/vmx/vmx.c|4304| <<vmx_set_constant_host_state>> vmcs_writel(HOST_IDTR_BASE, host_idt_base);
+	 *   - arch/x86/kvm/vmx/vmx.c|6972| <<handle_external_interrupt_irqoff>> gate_desc *desc = (gate_desc *)host_idt_base + vector;
+	 *   - arch/x86/kvm/vmx/vmx.c|8510| <<hardware_setup>> host_idt_base = dt.address;
+	 */
 	host_idt_base = dt.address;
 
 	vmx_setup_user_return_msrs();
diff --git a/arch/x86/kvm/vmx/vmx.h b/arch/x86/kvm/vmx/vmx.h
index 8a2ab6cff744..56bff8408743 100644
--- a/arch/x86/kvm/vmx/vmx.h
+++ b/arch/x86/kvm/vmx/vmx.h
@@ -241,6 +241,11 @@ struct nested_vmx {
 struct vcpu_vmx {
 	struct kvm_vcpu       vcpu;
 	u8                    fail;
+	/*
+	 * 在以下使用vcpu_vmx->x2apic_msr_bitmap_mode:
+	 *   - arch/x86/kvm/vmx/vmx.c|4050| <<vmx_update_msr_bitmap_x2apic>> if (mode == vmx->x2apic_msr_bitmap_mode)
+	 *   - arch/x86/kvm/vmx/vmx.c|4053| <<vmx_update_msr_bitmap_x2apic>> vmx->x2apic_msr_bitmap_mode = mode;
+	 */
 	u8		      x2apic_msr_bitmap_mode;
 
 	/*
@@ -250,10 +255,46 @@ struct vcpu_vmx {
 	 * values.  If false, host state is loaded in the CPU registers
 	 * and vmx->loaded_vmcs->host_state is invalid.
 	 */
+	/*
+	 * 在以下使用vcpu_vmx->guest_state_loaded:
+	 *   - arch/x86/kvm/vmx/nested.c|243| <<vmx_sync_vmcs_host_state>> if (unlikely(!vmx->guest_state_loaded))
+	 *   - arch/x86/kvm/vmx/vmx.c|1223| <<vmx_prepare_switch_to_guest>> if (vmx->guest_state_loaded)
+	 *   - arch/x86/kvm/vmx/vmx.c|1261| <<vmx_prepare_switch_to_guest>> vmx->guest_state_loaded = true;
+	 *   - arch/x86/kvm/vmx/vmx.c|1268| <<vmx_prepare_switch_to_host>> if (!vmx->guest_state_loaded)
+	 *   - arch/x86/kvm/vmx/vmx.c|1299| <<vmx_prepare_switch_to_host>> vmx->guest_state_loaded = false;
+	 *   - arch/x86/kvm/vmx/vmx.c|1307| <<vmx_read_guest_kernel_gs_base>> if (vmx->guest_state_loaded)
+	 *   - arch/x86/kvm/vmx/vmx.c|1316| <<vmx_write_guest_kernel_gs_base>> if (vmx->guest_state_loaded)
+	 */
 	bool		      guest_state_loaded;
 
 	unsigned long         exit_qualification;
+	/*
+	 * 在以下使用vcpu_vmx->exit_intr_info:
+	 *   - arch/x86/kvm/vmx/vmx.c|7322| <<vmx_vcpu_run>> vmx->exit_intr_info = 0;
+	 *   - arch/x86/kvm/vmx/vmx.h|584| <<vmx_get_intr_info>> vmx->exit_intr_info = vmcs_read32(VM_EXIT_INTR_INFO);
+	 *   - arch/x86/kvm/vmx/vmx.h|586| <<vmx_get_intr_info>> return vmx->exit_intr_info;
+	 *
+	 * 告诉VMM(Hypervisor)此次VM-exit是由于某个中断,异常或NMI等原因引起的
+	 */
 	u32                   exit_intr_info;
+	/*
+	 * 在以下使用vcpu_vmx->idt_vectoring_info:
+	 *   - arch/x86/kvm/vmx/vmx.c|5129| <<handle_exception_nmi>> vect_info = vmx->idt_vectoring_info;
+	 *   - arch/x86/kvm/vmx/vmx.c|5622| <<handle_task_switch>> idt_v = (vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK);
+	 *   - arch/x86/kvm/vmx/vmx.c|5623| <<handle_task_switch>> idt_index = (vmx->idt_vectoring_info & VECTORING_INFO_VECTOR_MASK);
+	 *   - arch/x86/kvm/vmx/vmx.c|5624| <<handle_task_switch>> type = (vmx->idt_vectoring_info & VECTORING_INFO_TYPE_MASK);
+	 *   - arch/x86/kvm/vmx/vmx.c|5650| <<handle_task_switch>> if (vmx->idt_vectoring_info &
+	 *   - arch/x86/kvm/vmx/vmx.c|5694| <<handle_ept_violation>> if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&
+	 *   - arch/x86/kvm/vmx/vmx.c|5913| <<handle_pml_full>> if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&
+	 *   - arch/x86/kvm/vmx/vmx.c|6062| <<vmx_get_exit_info>> *info2 = vmx->idt_vectoring_info;
+	 *   - arch/x86/kvm/vmx/vmx.c|6314| <<__vmx_handle_exit>> u32 vectoring_info = vmx->idt_vectoring_info;
+	 *   - arch/x86/kvm/vmx/vmx.c|6989| <<vmx_recover_nmi_blocking>> idtv_info_valid = vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK;
+	 *   - arch/x86/kvm/vmx/vmx.c|7125| <<vmx_complete_interrupts>> __vmx_complete_interrupts(&vmx->vcpu, vmx->idt_vectoring_info,
+	 *   - arch/x86/kvm/vmx/vmx.c|7427| <<vmx_vcpu_run>> vmx->idt_vectoring_info = 0;
+	 *   - arch/x86/kvm/vmx/vmx.c|7439| <<vmx_vcpu_run>> vmx->idt_vectoring_info = vmcs_read32(IDT_VECTORING_INFO_FIELD);
+	 *
+	 * 描述原本准备注入给 guest 的中断,但由于 VM-exit 等原因被中断了.
+	 */
 	u32                   idt_vectoring_info;
 	ulong                 rflags;
 
@@ -319,6 +360,13 @@ struct vcpu_vmx {
 	unsigned int ple_window;
 	bool ple_window_dirty;
 
+	/*
+	 * 在以下使用vcpu_vmx->req_immediate_exit:
+	 *   - arch/x86/kvm/vmx/vmx.c|1196| <<vmx_prepare_switch_to_guest>> vmx->req_immediate_exit = false;
+	 *   - arch/x86/kvm/vmx/vmx.c|5906| <<handle_fastpath_preemption_timer>> if (!vmx->req_immediate_exit &&
+	 *   - arch/x86/kvm/vmx/vmx.c|7146| <<vmx_update_hv_timer>> if (vmx->req_immediate_exit) {
+	 *   - arch/x86/kvm/vmx/vmx.c|7907| <<vmx_request_immediate_exit>> to_vmx(vcpu)->req_immediate_exit = true;
+	 */
 	bool req_immediate_exit;
 
 	/* Support for PML */
@@ -553,12 +601,30 @@ static inline unsigned long vmx_get_exit_qual(struct kvm_vcpu *vcpu)
 	return vmx->exit_qualification;
 }
 
+/*
+ * 在以下使用vmx_get_intr_info():
+ *   - arch/x86/kvm/vmx/nested.c|5790| <<handle_vmfunc>> vmx_get_intr_info(vcpu),
+ *   - arch/x86/kvm/vmx/nested.c|6031| <<nested_vmx_l0_wants_exit>> intr_info = vmx_get_intr_info(vcpu);
+ *   - arch/x86/kvm/vmx/nested.c|6103| <<nested_vmx_l1_wants_exit>> intr_info = vmx_get_intr_info(vcpu);
+ *   - arch/x86/kvm/vmx/nested.c|6257| <<nested_vmx_reflect_vmexit>> exit_intr_info = vmx_get_intr_info(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|5130| <<handle_exception_nmi>> intr_info = vmx_get_intr_info(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|6079| <<vmx_get_exit_info>> *intr_info = vmx_get_intr_info(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|6948| <<handle_exception_nmi_irqoff>> u32 intr_info = vmx_get_intr_info(&vmx->vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|6966| <<handle_external_interrupt_irqoff>> u32 intr_info = vmx_get_intr_info(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|7027| <<vmx_recover_nmi_blocking>> exit_intr_info = vmx_get_intr_info(&vmx->vcpu);
+ */
 static inline u32 vmx_get_intr_info(struct kvm_vcpu *vcpu)
 {
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
 
 	if (!kvm_register_is_available(vcpu, VCPU_EXREG_EXIT_INFO_2)) {
 		kvm_register_mark_available(vcpu, VCPU_EXREG_EXIT_INFO_2);
+		/*
+		 * 在以下使用vcpu_vmx->exit_intr_info:
+		 *   - arch/x86/kvm/vmx/vmx.c|7322| <<vmx_vcpu_run>> vmx->exit_intr_info = 0;
+		 *   - arch/x86/kvm/vmx/vmx.h|584| <<vmx_get_intr_info>> vmx->exit_intr_info = vmcs_read32(VM_EXIT_INTR_INFO);
+		 *   - arch/x86/kvm/vmx/vmx.h|586| <<vmx_get_intr_info>> return vmx->exit_intr_info;
+		 */
 		vmx->exit_intr_info = vmcs_read32(VM_EXIT_INTR_INFO);
 	}
 	return vmx->exit_intr_info;
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index 321af8f0e7ab..6b6b1a4a4cdd 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -473,6 +473,11 @@ enum lapic_mode kvm_get_apic_mode(struct kvm_vcpu *vcpu)
 }
 EXPORT_SYMBOL_GPL(kvm_get_apic_mode);
 
+/*
+ * 在以下使用kvm_set_apic_base():
+ *   - arch/x86/kvm/x86.c|3471| <<kvm_set_msr_common(MSR_IA32_APICBASE)>> return kvm_set_apic_base(vcpu, msr_info);
+ *   - arch/x86/kvm/x86.c|11103| <<__set_sregs_common>> if (kvm_set_apic_base(vcpu, &apic_base_msr))
+ */
 int kvm_set_apic_base(struct kvm_vcpu *vcpu, struct msr_data *msr_info)
 {
 	enum lapic_mode old_mode = kvm_get_apic_mode(vcpu);
@@ -490,6 +495,14 @@ int kvm_set_apic_base(struct kvm_vcpu *vcpu, struct msr_data *msr_info)
 	}
 
 	kvm_lapic_set_base(vcpu, msr_info->data);
+	/*
+	 * 在以下调用kvm_recalculate_apic_map():
+	 *   - arch/x86/kvm/lapic.c|2441| <<kvm_lapic_reg_write>> kvm_recalculate_apic_map(apic->vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|2718| <<kvm_lapic_reset>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|2995| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|3001| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/x86.c|493| <<kvm_set_apic_base>> kvm_recalculate_apic_map(vcpu->kvm);
+	 */
 	kvm_recalculate_apic_map(vcpu->kvm);
 	return 0;
 }
@@ -564,6 +577,26 @@ static int exception_type(int vector)
 
 void kvm_deliver_exception_payload(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * struct kvm_vcpu *vcpu:
+	 * -> struct kvm_vcpu_arch arch;
+	 *        struct kvm_queued_exception {
+	 *            bool pending;
+	 *            bool injected;
+	 *            bool has_error_code;
+	 *            u8 nr;
+	 *            u32 error_code;
+	 *            unsigned long payload;
+	 *            bool has_payload;
+	 *            u8 nested_apf;
+	 *        } exception;
+	 *
+	 *        struct kvm_queued_interrupt {
+	 *            bool injected;
+	 *            bool soft;
+	 *            u8 nr;
+	 *        } interrupt;
+	 */
 	unsigned nr = vcpu->arch.exception.nr;
 	bool has_payload = vcpu->arch.exception.has_payload;
 	unsigned long payload = vcpu->arch.exception.payload;
@@ -623,6 +656,15 @@ static void kvm_leave_nested(struct kvm_vcpu *vcpu)
 	kvm_x86_ops.nested_ops->leave_nested(vcpu);
 }
 
+/*
+ * 在以下调用kvm_multiple_exception():
+ *   - arch/x86/kvm/x86.c|735| <<kvm_queue_exception>> kvm_multiple_exception(vcpu, nr, false, 0, false, 0, false);
+ *   - arch/x86/kvm/x86.c|741| <<kvm_requeue_exception>> kvm_multiple_exception(vcpu, nr, false, 0, false, 0, true);
+ *   - arch/x86/kvm/x86.c|748| <<kvm_queue_exception_p>> kvm_multiple_exception(vcpu, nr, false, 0, true, payload, false);
+ *   - arch/x86/kvm/x86.c|755| <<kvm_queue_exception_e_p>> kvm_multiple_exception(vcpu, nr, true, error_code,
+ *   - arch/x86/kvm/x86.c|817| <<kvm_queue_exception_e>> kvm_multiple_exception(vcpu, nr, true, error_code, false, 0, false);
+ *   - arch/x86/kvm/x86.c|823| <<kvm_requeue_exception_e>> kvm_multiple_exception(vcpu, nr, true, error_code, false, 0, true);
+ */
 static void kvm_multiple_exception(struct kvm_vcpu *vcpu,
 		unsigned nr, bool has_error, u32 error_code,
 	        bool has_payload, unsigned long payload, bool reinject)
@@ -697,18 +739,68 @@ static void kvm_multiple_exception(struct kvm_vcpu *vcpu,
 		goto queue;
 }
 
+/*
+ * 在以下使用kvm_queue_exception():
+ *   - arch/x86/kvm/hyperv.c|2220| <<kvm_hv_hypercall>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/hyperv.c|2258| <<kvm_hv_hypercall>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/svm/nested.c|748| <<nested_svm_vmrun>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/svm/nested.c|1026| <<nested_svm_vmexit>> kvm_queue_exception(&(svm->vcpu), DB_VECTOR);
+ *   - arch/x86/kvm/svm/nested.c|1226| <<nested_svm_check_permissions>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/svm/svm.c|2508| <<skinit_interception>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/svm/svm.c|2691| <<cr_interception>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/svm/svm.c|2713| <<cr_interception>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/svm/svm.c|2750| <<cr_trap>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/svm/svm.c|3234| <<invpcid_interception>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/svm/svm.c|4795| <<svm_can_emulate_instruction>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/nested.c|3360| <<nested_vmx_check_permission>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/nested.c|3575| <<nested_vmx_run>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/nested.c|4809| <<get_vmx_mem_address>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/nested.c|5050| <<handle_vmon>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/nested.c|5553| <<handle_invept>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/nested.c|5633| <<handle_invvpid>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/nested.c|5755| <<handle_vmfunc>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/nested.c|5766| <<handle_vmfunc>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/sgx.c|378| <<handle_encls>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/vmx.c|1574| <<vmx_can_emulate_instruction>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/vmx.c|5050| <<handle_rmode_exception>> kvm_queue_exception(vcpu, vec);
+ *   - arch/x86/kvm/vmx/vmx.c|5113| <<handle_exception_nmi>> kvm_queue_exception(vcpu, NM_VECTOR);
+ *   - arch/x86/kvm/vmx/vmx.c|5849| <<handle_invpcid>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/vmx.c|5927| <<handle_vmx_instruction>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/vmx.c|5939| <<handle_encls>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/x86.c|845| <<kvm_require_dr>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/x86.c|2111| <<kvm_handle_invalid_op>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/x86.c|4933| <<kvm_vcpu_ioctl_x86_set_mce>> kvm_queue_exception(vcpu, MC_VECTOR);
+ *   - arch/x86/kvm/x86.c|7934| <<inject_emulated_exception>> kvm_queue_exception(vcpu, ctxt->exception.vector);
+ *   - arch/x86/kvm/x86.c|8097| <<handle_emulation_failure>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/x86.c|8441| <<x86_emulate_instruction>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/x86.c|11805| <<kvm_arch_vcpu_ioctl_set_guest_debug>> kvm_queue_exception(vcpu, DB_VECTOR);
+ *   - arch/x86/kvm/x86.c|11807| <<kvm_arch_vcpu_ioctl_set_guest_debug>> kvm_queue_exception(vcpu, BP_VECTOR);
+ */
 void kvm_queue_exception(struct kvm_vcpu *vcpu, unsigned nr)
 {
 	kvm_multiple_exception(vcpu, nr, false, 0, false, 0, false);
 }
 EXPORT_SYMBOL_GPL(kvm_queue_exception);
 
+/*
+ * 在以下使用kvm_requeue_exception():
+ *   - arch/x86/kvm/svm/svm.c|4042| <<svm_complete_interrupts>> kvm_requeue_exception(vcpu, vector);
+ *   - arch/x86/kvm/vmx/vmx.c|7042| <<__vmx_complete_interrupts>> kvm_requeue_exception(vcpu, vector);
+ */
 void kvm_requeue_exception(struct kvm_vcpu *vcpu, unsigned nr)
 {
 	kvm_multiple_exception(vcpu, nr, false, 0, false, 0, true);
 }
 EXPORT_SYMBOL_GPL(kvm_requeue_exception);
 
+/*
+ * 在以下使用kvm_queue_exception_p():
+ *   - arch/x86/kvm/svm/svm.c|2098| <<db_interception>> kvm_queue_exception_p(vcpu, DB_VECTOR, payload);
+ *   - arch/x86/kvm/vmx/vmx.c|5208| <<handle_exception_nmi>> kvm_queue_exception_p(vcpu, DB_VECTOR, dr6);
+ *   - arch/x86/kvm/vmx/vmx.c|5455| <<handle_dr>> kvm_queue_exception_p(vcpu, DB_VECTOR, DR6_BD);
+ *   - arch/x86/kvm/x86.c|8282| <<kvm_vcpu_do_singlestep>> kvm_queue_exception_p(vcpu, DB_VECTOR, DR6_BS);
+ *   - arch/x86/kvm/x86.c|8337| <<kvm_vcpu_check_code_breakpoint>> kvm_queue_exception_p(vcpu, DB_VECTOR, dr6);
+ */
 void kvm_queue_exception_p(struct kvm_vcpu *vcpu, unsigned nr,
 			   unsigned long payload)
 {
@@ -716,6 +808,11 @@ void kvm_queue_exception_p(struct kvm_vcpu *vcpu, unsigned nr,
 }
 EXPORT_SYMBOL_GPL(kvm_queue_exception_p);
 
+/*
+ * 在以下使用kvm_queue_exception_e_p():
+ *   - arch/x86/kvm/x86.c|779| <<kvm_inject_page_fault>> kvm_queue_exception_e_p(vcpu, PF_VECTOR,
+ *             fault->error_code, fault->address);
+ */
 static void kvm_queue_exception_e_p(struct kvm_vcpu *vcpu, unsigned nr,
 				    u32 error_code, unsigned long payload)
 {
@@ -774,6 +871,13 @@ EXPORT_SYMBOL_GPL(kvm_inject_emulated_page_fault);
 
 void kvm_inject_nmi(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用kvm_vcpu_arch->nmi_queued:
+	 *   - arch/x86/kvm/x86.c|874| <<kvm_inject_nmi>> atomic_inc(&vcpu->arch.nmi_queued);
+	 *   - arch/x86/kvm/x86.c|5158| <<kvm_vcpu_ioctl_x86_set_vcpu_events>> atomic_set(&vcpu->arch.nmi_queued, events->nmi.pending);
+	 *   - arch/x86/kvm/x86.c|9855| <<process_nmi>> vcpu->arch.nmi_pending += atomic_xchg(&vcpu->arch.nmi_queued, 0);
+	 *   - arch/x86/kvm/x86.c|12376| <<kvm_vcpu_reset>> atomic_set(&vcpu->arch.nmi_queued, 0);
+	 */
 	atomic_inc(&vcpu->arch.nmi_queued);
 	kvm_make_request(KVM_REQ_NMI, vcpu);
 }
@@ -1732,6 +1836,36 @@ bool kvm_msr_allowed(struct kvm_vcpu *vcpu, u32 index, u32 type)
 }
 EXPORT_SYMBOL_GPL(kvm_msr_allowed);
 
+/*
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_vcpu_reset
+ * kvm_apic_accept_events
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_lapic_reg_write
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ */
 /*
  * Write @data into the MSR specified by @index.  Select MSR specific fault
  * checks are bypassed if @host_initiated is %true.
@@ -1967,6 +2101,36 @@ int kvm_emulate_rdmsr(struct kvm_vcpu *vcpu)
 }
 EXPORT_SYMBOL_GPL(kvm_emulate_rdmsr);
 
+/*
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_vcpu_reset
+ * kvm_apic_accept_events
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_lapic_reg_write
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ */
 int kvm_emulate_wrmsr(struct kvm_vcpu *vcpu)
 {
 	u32 ecx = kvm_rcx_read(vcpu);
@@ -2020,6 +2184,11 @@ int kvm_handle_invalid_op(struct kvm_vcpu *vcpu)
 }
 EXPORT_SYMBOL_GPL(kvm_handle_invalid_op);
 
+/*
+ * 在以下使用kvm_emulate_monitor():
+ *   - arch/x86/kvm/svm/svm.c|3312| <<global>> [SVM_EXIT_MONITOR] = kvm_emulate_monitor,
+ *   - arch/x86/kvm/vmx/vmx.c|5788| <<global>> [EXIT_REASON_MONITOR_INSTRUCTION] = kvm_emulate_monitor,
+ */
 int kvm_emulate_monitor(struct kvm_vcpu *vcpu)
 {
 	pr_warn_once("kvm: MONITOR instruction emulated as NOP!\n");
@@ -2027,6 +2196,11 @@ int kvm_emulate_monitor(struct kvm_vcpu *vcpu)
 }
 EXPORT_SYMBOL_GPL(kvm_emulate_monitor);
 
+/*
+ * 在以下调用kvm_vcpu_exit_request():
+ *   - arch/x86/kvm/x86.c|10386| <<vcpu_enter_guest(关于cancel_injection)>> if (kvm_vcpu_exit_request(vcpu)) {
+ *   - arch/x86/kvm/x86.c|10443| <<vcpu_enter_guest(关于EXIT_FASTPATH_EXIT_HANDLED)>> if (unlikely(kvm_vcpu_exit_request(vcpu))) {
+ */
 static inline bool kvm_vcpu_exit_request(struct kvm_vcpu *vcpu)
 {
 	xfer_to_guest_mode_prepare();
@@ -2041,6 +2215,10 @@ static inline bool kvm_vcpu_exit_request(struct kvm_vcpu *vcpu)
  * from guest to host, e.g. reacquiring KVM's SRCU lock. In contrast to the
  * other cases which must be called after interrupts are enabled on the host.
  */
+/*
+ * 在以下调用handle_fastpath_set_x2apic_icr_irqoff():
+ *   - arch/x86/kvm/x86.c|2089| <<handle_fastpath_set_msr_irqoff>> if (!handle_fastpath_set_x2apic_icr_irqoff(vcpu, data)) {
+ */
 static int handle_fastpath_set_x2apic_icr_irqoff(struct kvm_vcpu *vcpu, u64 data)
 {
 	if (!lapic_in_kernel(vcpu) || !apic_x2apic_mode(vcpu->arch.apic))
@@ -2055,6 +2233,10 @@ static int handle_fastpath_set_x2apic_icr_irqoff(struct kvm_vcpu *vcpu, u64 data
 	return 1;
 }
 
+/*
+ * 在以下使用handle_fastpath_set_tscdeadline():
+ *   - arch/x86/kvm/x86.c|2096| <<handle_fastpath_set_msr_irqoff>> if (!handle_fastpath_set_tscdeadline(vcpu, data)) {
+ */
 static int handle_fastpath_set_tscdeadline(struct kvm_vcpu *vcpu, u64 data)
 {
 	if (!kvm_can_use_hv_timer(vcpu))
@@ -2064,6 +2246,11 @@ static int handle_fastpath_set_tscdeadline(struct kvm_vcpu *vcpu, u64 data)
 	return 0;
 }
 
+/*
+ * 在以下调用handle_fastpath_set_msr_irqoff():
+ *   - arch/x86/kvm/svm/svm.c|4077| <<svm_exit_handlers_fastpath>> return handle_fastpath_set_msr_irqoff(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|6873| <<vmx_exit_handlers_fastpath>> return handle_fastpath_set_msr_irqoff(vcpu);
+ */
 fastpath_t handle_fastpath_set_msr_irqoff(struct kvm_vcpu *vcpu)
 {
 	u32 msr = kvm_rcx_read(vcpu);
@@ -4561,6 +4748,13 @@ static void kvm_steal_time_set_preempted(struct kvm_vcpu *vcpu)
 	 * when this is true, for example allowing the vCPU to be marked
 	 * preempted if and only if the VM-Exit was due to a host interrupt.
 	 */
+	/*
+	 * 在以下使用kvm_vcpu_arch->at_instruction_boundary:
+	 *   - arch/x86/kvm/svm/svm.c|4585| <<svm_handle_exit_irqoff>> vcpu->arch.at_instruction_boundary = true;
+	 *   - arch/x86/kvm/vmx/vmx.c|6979| <<handle_external_interrupt_irqoff>> vcpu->arch.at_instruction_boundary = true;
+	 *   - arch/x86/kvm/x86.c|4744| <<kvm_steal_time_set_preempted>> if (!vcpu->arch.at_instruction_boundary) {
+	 *   - arch/x86/kvm/x86.c|11223| <<vcpu_run>> vcpu->arch.at_instruction_boundary = false;
+	 */
 	if (!vcpu->arch.at_instruction_boundary) {
 		vcpu->stat.preemption_other++;
 		return;
@@ -4620,16 +4814,37 @@ void kvm_arch_vcpu_put(struct kvm_vcpu *vcpu)
 static int kvm_vcpu_ioctl_get_lapic(struct kvm_vcpu *vcpu,
 				    struct kvm_lapic_state *s)
 {
+	/*
+	 * 在以下调用kvm_x86_sync_pir_to_irr()
+	 *   - arch/x86/kvm/lapic.c|789| <<apic_has_interrupt_for_ppr>> highest_irr = static_call(kvm_x86_sync_pir_to_irr)(apic->vcpu);
+	 *   - arch/x86/kvm/x86.c|4623| <<kvm_vcpu_ioctl_get_lapic>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 *   - arch/x86/kvm/x86.c|9842| <<vcpu_scan_ioapic>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 *   - arch/x86/kvm/x86.c|10171| <<vcpu_enter_guest>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 *   - arch/x86/kvm/x86.c|10220| <<vcpu_enter_guest>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 */
 	static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
 
 	return kvm_apic_get_state(vcpu, s);
 }
 
+/*
+ * 在以下使用KVM_SET_LAPIC:
+ *   - arch/x86/kvm/x86.c|5200| <<kvm_arch_vcpu_ioctl(KVM_SET_LAPIC)>> r = kvm_vcpu_ioctl_set_lapic(vcpu, u.lapic);
+ *
+ * kvm_arch_vcpu_ioctl(KVM_SET_LAPIC)
+ * -> kvm_vcpu_ioctl_set_lapic()
+ *    -> kvm_apic_set_state()
+ *       -> kvm_recalculate_apic_map() -> 只有kvm_apic_state_fixup() > 0的时候
+ *       -> kvm_recalculate_apic_map()
+ */
 static int kvm_vcpu_ioctl_set_lapic(struct kvm_vcpu *vcpu,
 				    struct kvm_lapic_state *s)
 {
 	int r;
 
+	/*
+	 * 只在此处调用
+	 */
 	r = kvm_apic_set_state(vcpu, s);
 	if (r)
 		return r;
@@ -4640,6 +4855,16 @@ static int kvm_vcpu_ioctl_set_lapic(struct kvm_vcpu *vcpu,
 
 static int kvm_cpu_accept_dm_intr(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下调用kvm_cpu_has_extint():
+	 *   - arch/x86/kvm/irq.c|86| <<kvm_cpu_has_injectable_intr>> if (kvm_cpu_has_extint(v))
+	 *   - arch/x86/kvm/irq.c|115| <<kvm_cpu_has_interrupt>> if (kvm_cpu_has_extint(v))
+	 *   - arch/x86/kvm/irq.c|135| <<kvm_cpu_get_extint>> if (!kvm_cpu_has_extint(v)) {
+	 *   - arch/x86/kvm/x86.c|4850| <<kvm_cpu_accept_dm_intr>> if (kvm_cpu_has_extint(vcpu))
+	 *
+	 * check if there is pending interrupt from
+	 * non-APIC source without intack.
+	 */
 	/*
 	 * We can accept userspace's request for interrupt injection
 	 * as long as we have a place to store the interrupt number.
@@ -4654,6 +4879,11 @@ static int kvm_cpu_accept_dm_intr(struct kvm_vcpu *vcpu)
 		kvm_apic_accept_pic_intr(vcpu));
 }
 
+/*
+ * 在以下使用kvm_vcpu_ready_for_interrupt_injection():
+ *   - arch/x86/kvm/x86.c|9418| <<post_kvm_run_save>> kvm_vcpu_ready_for_interrupt_injection(vcpu);
+ *   - arch/x86/kvm/x86.c|11078| <<vcpu_run>> kvm_vcpu_ready_for_interrupt_injection(vcpu)) {
+ */
 static int kvm_vcpu_ready_for_interrupt_injection(struct kvm_vcpu *vcpu)
 {
 	/*
@@ -4676,6 +4906,15 @@ static int kvm_vcpu_ioctl_interrupt(struct kvm_vcpu *vcpu,
 		return -EINVAL;
 
 	if (!irqchip_in_kernel(vcpu->kvm)) {
+		/*
+		 * 在以下使用kvm_queue_interrupt():
+		 *   - arch/x86/kvm/svm/svm.c|4045| <<svm_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, false);
+		 *   - arch/x86/kvm/svm/svm.c|4048| <<svm_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, true);
+		 *   - arch/x86/kvm/vmx/vmx.c|6768| <<__vmx_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, type == INTR_TYPE_SOFT_INTR);
+		 *   - arch/x86/kvm/x86.c|4713| <<kvm_vcpu_ioctl_interrupt>> kvm_queue_interrupt(vcpu, irq->irq, false);
+		 *   - arch/x86/kvm/x86.c|9490| <<inject_pending_event>> kvm_queue_interrupt(vcpu, irq, false);
+		 *   - arch/x86/kvm/x86.c|11223| <<__set_sregs>> kvm_queue_interrupt(vcpu, pending_vec, false);
+		 */
 		kvm_queue_interrupt(vcpu, irq->irq, false);
 		kvm_make_request(KVM_REQ_EVENT, vcpu);
 		return 0;
@@ -4923,6 +5162,13 @@ static int kvm_vcpu_ioctl_x86_set_vcpu_events(struct kvm_vcpu *vcpu,
 	vcpu->arch.nmi_injected = events->nmi.injected;
 	if (events->flags & KVM_VCPUEVENT_VALID_NMI_PENDING) {
 		vcpu->arch.nmi_pending = 0;
+		/*
+		 * 在以下使用kvm_vcpu_arch->nmi_queued:
+		 *   - arch/x86/kvm/x86.c|874| <<kvm_inject_nmi>> atomic_inc(&vcpu->arch.nmi_queued);
+		 *   - arch/x86/kvm/x86.c|5158| <<kvm_vcpu_ioctl_x86_set_vcpu_events>> atomic_set(&vcpu->arch.nmi_queued, events->nmi.pending);
+		 *   - arch/x86/kvm/x86.c|9855| <<process_nmi>> vcpu->arch.nmi_pending += atomic_xchg(&vcpu->arch.nmi_queued, 0);
+		 *   - arch/x86/kvm/x86.c|12376| <<kvm_vcpu_reset>> atomic_set(&vcpu->arch.nmi_queued, 0);
+		 */
 		atomic_set(&vcpu->arch.nmi_queued, events->nmi.pending);
 		kvm_make_request(KVM_REQ_NMI, vcpu);
 	}
@@ -5176,6 +5422,13 @@ long kvm_arch_vcpu_ioctl(struct file *filp,
 			goto out_nofree;
 		}
 
+		/*
+		 * kvm_arch_vcpu_ioctl(KVM_SET_LAPIC)
+		 * -> kvm_vcpu_ioctl_set_lapic()
+		 *    -> kvm_apic_set_state()
+		 *       -> kvm_recalculate_apic_map() -> 只有kvm_apic_state_fixup() > 0的时候
+		 *       -> kvm_recalculate_apic_map()
+		 */
 		r = kvm_vcpu_ioctl_set_lapic(vcpu, u.lapic);
 		break;
 	}
@@ -5794,6 +6047,14 @@ int kvm_vm_ioctl_enable_cap(struct kvm *kvm,
 		smp_wmb();
 		kvm->arch.irqchip_mode = KVM_IRQCHIP_SPLIT;
 		kvm->arch.nr_reserved_ioapic_pins = cap->args[0];
+		/*
+		 * 在以下使用kvm_clear_apicv_inhibit():
+		 *   - arch/x86/kvm/i8254.c|314| <<kvm_pit_set_reinject>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_PIT_REINJ);
+		 *   - arch/x86/kvm/lapic.c|579| <<kvm_recalculate_apic_map>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_APIC_ID_MODIFIED);
+		 *   - arch/x86/kvm/svm/svm.c|3235| <<interrupt_window_interception>> kvm_clear_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+		 *   - arch/x86/kvm/x86.c|6050| <<kvm_vm_ioctl_enable_cap(KVM_CAP_SPLIT_IRQCHIP)>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
+		 *   - arch/x86/kvm/x86.c|6465| <<kvm_arch_vm_ioctl(KVM_CREATE_IRQCHIP)>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
+		 */
 		kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
 		r = 0;
 split_irqchip_unlock:
@@ -5805,8 +6066,28 @@ int kvm_vm_ioctl_enable_cap(struct kvm *kvm,
 		if (cap->args[0] & ~KVM_X2APIC_API_VALID_FLAGS)
 			break;
 
+		/*
+		 * 在以下使用kvm_arch->x2apic_format:
+		 *   - arch/x86/kvm/irq_comm.c|137| <<kvm_set_msi_irq>> trace_kvm_msi_set_irq(msg.address_lo | (kvm->arch.x2apic_format ?
+		 *   - arch/x86/kvm/irq_comm.c|140| <<kvm_set_msi_irq>> irq->dest_id = x86_msi_msg_get_destid(&msg, kvm->arch.x2apic_format);
+		 *   - arch/x86/kvm/irq_comm.c|154| <<kvm_msi_route_invalid>> return kvm->arch.x2apic_format && (e->msi.address_hi & 0xff);
+		 *   - arch/x86/kvm/lapic.c|3673| <<kvm_apic_state_fixup>> if (vcpu->kvm->arch.x2apic_format) {
+		 *   - arch/x86/kvm/x86.c|5933| <<kvm_vm_ioctl_enable_cap>> kvm->arch.x2apic_format = true;
+		 *
+		 *     x2apic_format = false,
+		 *     x2apic_broadcast_quirk_disabled = false,
+		 */
 		if (cap->args[0] & KVM_X2APIC_API_USE_32BIT_IDS)
 			kvm->arch.x2apic_format = true;
+		/*
+		 * 在以下使用kvm_arch->x2apic_broadcast_quirk_disabled:
+		 *   - arch/x86/kvm/lapic.c|1356| <<kvm_apic_mda>> if (!vcpu->kvm->arch.x2apic_broadcast_quirk_disabled &&
+		 *   - arch/x86/kvm/lapic.c|1435| <<kvm_apic_is_broadcast_dest>> if (kvm->arch.x2apic_broadcast_quirk_disabled) {
+		 *   - arch/x86/kvm/x86.c|5935| <<kvm_vm_ioctl_enable_cap>> kvm->arch.x2apic_broadcast_quirk_disabled = true;
+		 *
+		 *     x2apic_format = false,
+		 *     x2apic_broadcast_quirk_disabled = false,
+		 */
 		if (cap->args[0] & KVM_X2APIC_API_DISABLE_BROADCAST_QUIRK)
 			kvm->arch.x2apic_broadcast_quirk_disabled = true;
 
@@ -6189,6 +6470,14 @@ long kvm_arch_vm_ioctl(struct file *filp,
 		/* Write kvm->irq_routing before enabling irqchip_in_kernel. */
 		smp_wmb();
 		kvm->arch.irqchip_mode = KVM_IRQCHIP_KERNEL;
+		/*
+		 * 在以下使用kvm_clear_apicv_inhibit():
+		 *   - arch/x86/kvm/i8254.c|314| <<kvm_pit_set_reinject>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_PIT_REINJ);
+		 *   - arch/x86/kvm/lapic.c|579| <<kvm_recalculate_apic_map>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_APIC_ID_MODIFIED);
+		 *   - arch/x86/kvm/svm/svm.c|3235| <<interrupt_window_interception>> kvm_clear_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+		 *   - arch/x86/kvm/x86.c|6050| <<kvm_vm_ioctl_enable_cap(KVM_CAP_SPLIT_IRQCHIP)>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
+		 *   - arch/x86/kvm/x86.c|6465| <<kvm_arch_vm_ioctl(KVM_CREATE_IRQCHIP)>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
+		 */
 		kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
 	create_irqchip_unlock:
 		mutex_unlock(&kvm->lock);
@@ -7137,6 +7426,18 @@ static int emulator_cmpxchg_emulated(struct x86_emulate_ctxt *ctxt,
 	    (gpa & PAGE_MASK) == APIC_DEFAULT_PHYS_BASE)
 		goto emul_write;
 
+	/*
+	 * 在以下使用X86_FEATURE_SPLIT_LOCK_DETECT:
+	 *   - arch/x86/kernel/cpu/intel.c|1149| <<sld_state_setup>> if (!boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) &&
+	 *   - arch/x86/kernel/cpu/intel.c|1221| <<__split_lock_setup>> setup_force_cpu_cap(X86_FEATURE_SPLIT_LOCK_DETECT);
+	 *   - arch/x86/kernel/cpu/intel.c|1475| <<bus_lock_init>> if ((boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) &&
+	 *   - arch/x86/kernel/cpu/intel.c|1621| <<sld_state_show>> !boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 *   - arch/x86/kernel/cpu/intel.c|1643| <<sld_state_show>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1653| <<sld_state_show>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1657| <<sld_state_show>> boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) ?
+	 *   - arch/x86/kvm/vmx/vmx.c|4917| <<vmx_guest_inject_ac>> if (!boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 *   - arch/x86/kvm/x86.c|7297| <<emulator_cmpxchg_emulated>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 */
 	/*
 	 * Emulate the atomic as a straight write to avoid #AC if SLD is
 	 * enabled in the host and the access splits a cache line.
@@ -8996,19 +9297,53 @@ static void kvm_pv_kick_cpu_op(struct kvm *kvm, unsigned long flags, int apicid)
 
 bool kvm_apicv_activated(struct kvm *kvm)
 {
+	/*
+	 * 在以下使用kvm_arch->apicv_inhibit_reasons:
+	 *   - arch/x86/kvm/x86.c|9007| <<kvm_apicv_activated>> return (READ_ONCE(kvm->arch.apicv_inhibit_reasons) == 0);
+	 *   - arch/x86/kvm/x86.c|9013| <<kvm_vcpu_apicv_activated>> ulong vm_reasons = READ_ONCE(vcpu->kvm->arch.apicv_inhibit_reasons);
+	 *   - arch/x86/kvm/x86.c|9033| <<kvm_apicv_init>> unsigned long *inhibits = &kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|9830| <<__kvm_set_or_clear_apicv_inhibit>> old = new = kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|9848| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 *   - arch/x86/kvm/x86.c|9857| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 */
 	return (READ_ONCE(kvm->arch.apicv_inhibit_reasons) == 0);
 }
 EXPORT_SYMBOL_GPL(kvm_apicv_activated);
 
+/*
+ * 在以下调用kvm_vcpu_apicv_activated():
+ *   - arch/x86/kvm/svm/svm.c|1688| <<svm_set_vintr>> WARN_ON(kvm_vcpu_apicv_activated(&svm->vcpu));
+ *   - arch/x86/kvm/x86.c|9794| <<kvm_vcpu_update_apicv>> activate = kvm_vcpu_apicv_activated(vcpu) &&
+ *   - arch/x86/kvm/x86.c|10318| <<vcpu_enter_guest>> WARN_ON_ONCE((kvm_vcpu_apicv_activated(vcpu) != kvm_vcpu_apicv_active(vcpu)) &&
+ */
 bool kvm_vcpu_apicv_activated(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用kvm_arch->apicv_inhibit_reasons:
+	 *   - arch/x86/kvm/x86.c|9007| <<kvm_apicv_activated>> return (READ_ONCE(kvm->arch.apicv_inhibit_reasons) == 0);
+	 *   - arch/x86/kvm/x86.c|9013| <<kvm_vcpu_apicv_activated>> ulong vm_reasons = READ_ONCE(vcpu->kvm->arch.apicv_inhibit_reasons);
+	 *   - arch/x86/kvm/x86.c|9033| <<kvm_apicv_init>> unsigned long *inhibits = &kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|9830| <<__kvm_set_or_clear_apicv_inhibit>> old = new = kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|9848| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 *   - arch/x86/kvm/x86.c|9857| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 */
 	ulong vm_reasons = READ_ONCE(vcpu->kvm->arch.apicv_inhibit_reasons);
+	/*
+	 * 只在这里调用
+	 * 只有amd有: avic_vcpu_get_apicv_inhibit_reasons()
+	 */
 	ulong vcpu_reasons = static_call(kvm_x86_vcpu_get_apicv_inhibit_reasons)(vcpu);
 
 	return (vm_reasons | vcpu_reasons) == 0;
 }
 EXPORT_SYMBOL_GPL(kvm_vcpu_apicv_activated);
 
+/*
+ * 在以下使用set_or_clear_apicv_inhibit():
+ *   - arch/x86/kvm/x86.c|9367| <<kvm_apicv_init>> set_or_clear_apicv_inhibit(inhibits, APICV_INHIBIT_REASON_ABSENT, true);
+ *   - arch/x86/kvm/x86.c|9370| <<kvm_apicv_init>> set_or_clear_apicv_inhibit(inhibits, APICV_INHIBIT_REASON_DISABLE, true);
+ *   - arch/x86/kvm/x86.c|10360| <<__kvm_set_or_clear_apicv_inhibit>> set_or_clear_apicv_inhibit(&new, reason, set);
+ */
 static void set_or_clear_apicv_inhibit(unsigned long *inhibits,
 				       enum kvm_apicv_inhibit reason, bool set)
 {
@@ -9020,12 +9355,31 @@ static void set_or_clear_apicv_inhibit(unsigned long *inhibits,
 	trace_kvm_apicv_inhibit_changed(reason, set, *inhibits);
 }
 
+/*
+ * 在以下使用kvm_apicv_init():
+ *    - arch/x86/kvm/x86.c|12910| <<kvm_arch_init_vm>> kvm_apicv_init(kvm);
+ */
 static void kvm_apicv_init(struct kvm *kvm)
 {
+	/*
+	 * 在以下使用kvm_arch->apicv_inhibit_reasons:
+	 *   - arch/x86/kvm/x86.c|9007| <<kvm_apicv_activated>> return (READ_ONCE(kvm->arch.apicv_inhibit_reasons) == 0);
+	 *   - arch/x86/kvm/x86.c|9013| <<kvm_vcpu_apicv_activated>> ulong vm_reasons = READ_ONCE(vcpu->kvm->arch.apicv_inhibit_reasons);
+	 *   - arch/x86/kvm/x86.c|9033| <<kvm_apicv_init>> unsigned long *inhibits = &kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|9830| <<__kvm_set_or_clear_apicv_inhibit>> old = new = kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|9848| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 *   - arch/x86/kvm/x86.c|9857| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 */
 	unsigned long *inhibits = &kvm->arch.apicv_inhibit_reasons;
 
 	init_rwsem(&kvm->arch.apicv_update_lock);
 
+	/*
+	 * 在以下使用set_or_clear_apicv_inhibit():
+	 *   - arch/x86/kvm/x86.c|9367| <<kvm_apicv_init>> set_or_clear_apicv_inhibit(inhibits, APICV_INHIBIT_REASON_ABSENT, true);
+	 *   - arch/x86/kvm/x86.c|9370| <<kvm_apicv_init>> set_or_clear_apicv_inhibit(inhibits, APICV_INHIBIT_REASON_DISABLE, true);
+	 *   - arch/x86/kvm/x86.c|10360| <<__kvm_set_or_clear_apicv_inhibit>> set_or_clear_apicv_inhibit(&new, reason, set);
+	 */
 	set_or_clear_apicv_inhibit(inhibits, APICV_INHIBIT_REASON_ABSENT, true);
 
 	if (!enable_apicv)
@@ -9044,6 +9398,17 @@ static void kvm_sched_yield(struct kvm_vcpu *vcpu, unsigned long dest_id)
 		goto no_yield;
 
 	rcu_read_lock();
+	/*
+	 * 在以下使用kvm_arch->apic_map:
+	 *   - arch/x86/kvm/lapic.c|581| <<kvm_recalculate_apic_map>> old = rcu_dereference_protected(kvm->arch.apic_map,
+	 *   - arch/x86/kvm/lapic.c|583| <<kvm_recalculate_apic_map>> rcu_assign_pointer(kvm->arch.apic_map, new);
+	 *   - arch/x86/kvm/lapic.c|1305| <<kvm_pv_send_ipi>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1772| <<kvm_irq_delivery_to_apic_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1825| <<kvm_intr_is_single_vcpu_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|2023| <<kvm_bitmap_or_dest_vcpus>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|9391| <<kvm_sched_yield>> map = rcu_dereference(vcpu->kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|13061| <<kvm_arch_destroy_vm>> kvfree(rcu_dereference_check(kvm->arch.apic_map, 1));
+	 */
 	map = rcu_dereference(vcpu->kvm->arch.apic_map);
 
 	if (likely(map) && dest_id <= map->max_apic_id && map->phys_map[dest_id])
@@ -9257,6 +9622,11 @@ int kvm_check_nested_events(struct kvm_vcpu *vcpu)
 	return kvm_x86_ops.nested_ops->check_events(vcpu);
 }
 
+/*
+ * 在以下调用kvm_inject_exception():
+ *   - arch/x86/kvm/x86.c|9582| <<inject_pending_event>> kvm_inject_exception(vcpu);
+ *   - arch/x86/kvm/x86.c|9651| <<inject_pending_event>> kvm_inject_exception(vcpu);
+ */
 static void kvm_inject_exception(struct kvm_vcpu *vcpu)
 {
 	/*
@@ -9276,6 +9646,16 @@ static void kvm_inject_exception(struct kvm_vcpu *vcpu)
 	static_call(kvm_x86_inject_exception)(vcpu);
 }
 
+/*
+ * 在以下调用inject_pending_event():
+ *   - arch/x86/kvm/x86.c|10320| <<vcpu_enter_guest>> r = inject_pending_event(vcpu, &req_immediate_exit);
+ *
+ * vcpu_enter_guest()
+ * -> inject_pending_event()
+ *    -> kvm_cpu_get_interrupt()
+ *       -> kvm_get_apic_interrupt()
+ *          -> apic_set_isr()
+ */
 static int inject_pending_event(struct kvm_vcpu *vcpu, bool *req_immediate_exit)
 {
 	int r;
@@ -9284,6 +9664,11 @@ static int inject_pending_event(struct kvm_vcpu *vcpu, bool *req_immediate_exit)
 	/* try to reinject previous events if any */
 
 	if (vcpu->arch.exception.injected) {
+		/*
+		 * 在以下调用kvm_inject_exception():
+		 *   - arch/x86/kvm/x86.c|9582| <<inject_pending_event>> kvm_inject_exception(vcpu);
+		 *   - arch/x86/kvm/x86.c|9651| <<inject_pending_event>> kvm_inject_exception(vcpu);
+		 */
 		kvm_inject_exception(vcpu);
 		can_inject = false;
 	}
@@ -9303,9 +9688,16 @@ static int inject_pending_event(struct kvm_vcpu *vcpu, bool *req_immediate_exit)
 	 */
 	else if (!vcpu->arch.exception.pending) {
 		if (vcpu->arch.nmi_injected) {
+			/*
+			 * vmx_inject_nmi
+			 */
 			static_call(kvm_x86_inject_nmi)(vcpu);
 			can_inject = false;
 		} else if (vcpu->arch.interrupt.injected) {
+			/*
+			 * vmx_inject_irq()
+			 * svm_set_irq()
+			 */
 			static_call(kvm_x86_inject_irq)(vcpu, true);
 			can_inject = false;
 		}
@@ -9350,6 +9742,11 @@ static int inject_pending_event(struct kvm_vcpu *vcpu, bool *req_immediate_exit)
 			}
 		}
 
+		/*
+		 * 在以下调用kvm_inject_exception():
+		 *   - arch/x86/kvm/x86.c|9582| <<inject_pending_event>> kvm_inject_exception(vcpu);
+		 *   - arch/x86/kvm/x86.c|9651| <<inject_pending_event>> kvm_inject_exception(vcpu);
+		 */
 		kvm_inject_exception(vcpu);
 
 		vcpu->arch.exception.pending = false;
@@ -9387,33 +9784,118 @@ static int inject_pending_event(struct kvm_vcpu *vcpu, bool *req_immediate_exit)
 	}
 
 	if (vcpu->arch.nmi_pending) {
+		/*
+		 * 在以下使用kvm_x86_nmi_allowed():
+		 *   - arch/x86/kvm/x86.c|9727| <<inject_pending_event>> r = can_inject ? static_call(kvm_x86_nmi_allowed)(vcpu, true) : -EBUSY;
+		 *   - arch/x86/kvm/x86.c|9735| <<inject_pending_event>> WARN_ON(static_call(kvm_x86_nmi_allowed)(vcpu, true) < 0);
+		 *   - arch/x86/kvm/x86.c|13270| <<kvm_vcpu_has_events>> static_call(kvm_x86_nmi_allowed)(vcpu, false)))
+		 *
+		 * vmx_nmi_allowed
+		 */
 		r = can_inject ? static_call(kvm_x86_nmi_allowed)(vcpu, true) : -EBUSY;
 		if (r < 0)
 			goto out;
 		if (r) {
 			--vcpu->arch.nmi_pending;
 			vcpu->arch.nmi_injected = true;
+			/*
+			 * vmx_inject_nmi
+			 */
 			static_call(kvm_x86_inject_nmi)(vcpu);
 			can_inject = false;
+			/*
+			 * 在以下使用kvm_x86_nmi_allowed():
+			 *   - arch/x86/kvm/x86.c|9727| <<inject_pending_event>> r = can_inject ? static_call(kvm_x86_nmi_allowed)(vcpu, true) : -EBUSY;
+			 *   - arch/x86/kvm/x86.c|9735| <<inject_pending_event>> WARN_ON(static_call(kvm_x86_nmi_allowed)(vcpu, true) < 0);
+			 *   - arch/x86/kvm/x86.c|13270| <<kvm_vcpu_has_events>> static_call(kvm_x86_nmi_allowed)(vcpu, false)))
+			 */
 			WARN_ON(static_call(kvm_x86_nmi_allowed)(vcpu, true) < 0);
 		}
+		/*
+		 * vmx_enable_nmi_window
+		 */
 		if (vcpu->arch.nmi_pending)
 			static_call(kvm_x86_enable_nmi_window)(vcpu);
 	}
 
+	/*
+	 * 在以下使用kvm_cpu_has_injectable_intr():
+	 *   - arch/x86/kvm/svm/svm.c|2448| <<svm_set_gif>> kvm_cpu_has_injectable_intr(&svm->vcpu))
+	 *   - arch/x86/kvm/x86.c|9412| <<inject_pending_event>> if (kvm_cpu_has_injectable_intr(vcpu)) {
+	 *   - arch/x86/kvm/x86.c|9425| <<inject_pending_event>> if (kvm_cpu_has_injectable_intr(vcpu))
+	 *
+	 * 第一个地方
+	 */
 	if (kvm_cpu_has_injectable_intr(vcpu)) {
+		/*
+		 * 在以下调用kvm_x86_interrupt_allowed():
+		 *   - arch/x86/kvm/x86.c|9719| <<inject_pending_event>> r = can_inject ? static_call(kvm_x86_interrupt_allowed)(vcpu, true) : -EBUSY;
+		 *   - arch/x86/kvm/x86.c|9749| <<inject_pending_event>> WARN_ON(static_call(kvm_x86_interrupt_allowed)(vcpu, true) < 0);
+		 *   - arch/x86/kvm/x86.c|13272| <<kvm_arch_interrupt_allowed>> return static_call(kvm_x86_interrupt_allowed)(vcpu, false);
+		 *
+		 * vmx_interrupt_allowed()
+		 * svm_interrupt_allowed()
+		 */
 		r = can_inject ? static_call(kvm_x86_interrupt_allowed)(vcpu, true) : -EBUSY;
 		if (r < 0)
 			goto out;
 		if (r) {
+			/*
+			 * 在以下调用kvm_cpu_get_interrupt():
+			 *   - arch/x86/kvm/vmx/nested.c|4709| <<nested_vmx_vmexit>> int irq = kvm_cpu_get_interrupt(vcpu);
+			 *   - arch/x86/kvm/x86.c|9417| <<inject_pending_event>> int irq = kvm_cpu_get_interrupt(vcpu);
+			 *
+			 * vcpu_enter_guest()
+			 * -> inject_pending_event()
+			 *    -> kvm_cpu_get_interrupt()
+			 *       -> kvm_get_apic_interrupt()
+			 *          -> apic_set_isr()
+			 *
+			 * 这里很重要!
+			 * 这个函数有可能会把IRR的bit移动到ISR.
+			 */
 			int irq = kvm_cpu_get_interrupt(vcpu);
 
 			if (!WARN_ON_ONCE(irq == -1)) {
+				/*
+				 * 在以下使用kvm_queue_interrupt():
+				 *   - arch/x86/kvm/svm/svm.c|4045| <<svm_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, false);
+				 *   - arch/x86/kvm/svm/svm.c|4048| <<svm_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, true);
+				 *   - arch/x86/kvm/vmx/vmx.c|6768| <<__vmx_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, type == INTR_TYPE_SOFT_INTR);
+				 *   - arch/x86/kvm/x86.c|4713| <<kvm_vcpu_ioctl_interrupt>> kvm_queue_interrupt(vcpu, irq->irq, false);
+				 *   - arch/x86/kvm/x86.c|9490| <<inject_pending_event>> kvm_queue_interrupt(vcpu, irq, false);
+				 *   - arch/x86/kvm/x86.c|11223| <<__set_sregs>> kvm_queue_interrupt(vcpu, pending_vec, false);
+				 *
+				 * vcpu->arch.interrupt.injected = true;
+				 * vcpu->arch.interrupt.soft = soft;
+				 * vcpu->arch.interrupt.nr = vector;
+				 */
 				kvm_queue_interrupt(vcpu, irq, false);
+				/*
+				 * vmx_inject_irq()
+				 * svm_set_irq()
+				 */
 				static_call(kvm_x86_inject_irq)(vcpu, false);
+				/*
+				 * 在以下调用kvm_x86_interrupt_allowed():
+				 *   - arch/x86/kvm/x86.c|9719| <<inject_pending_event>> r = can_inject ? static_call(kvm_x86_interrupt_allowed)(vcpu, true) : -EBUSY;
+				 *   - arch/x86/kvm/x86.c|9749| <<inject_pending_event>> WARN_ON(static_call(kvm_x86_interrupt_allowed)(vcpu, true) < 0);
+				 *   - arch/x86/kvm/x86.c|13272| <<kvm_arch_interrupt_allowed>> return static_call(kvm_x86_interrupt_allowed)(vcpu, false);
+				 */
 				WARN_ON(static_call(kvm_x86_interrupt_allowed)(vcpu, true) < 0);
 			}
 		}
+		/*
+		 * 在以下调用:
+		 *   - arch/x86/kvm/x86.c|9847| <<inject_pending_event>> static_call(kvm_x86_enable_irq_window)(vcpu);
+		 *   - arch/x86/kvm/x86.c|10871| <<vcpu_enter_guest>> static_call(kvm_x86_enable_irq_window)(vcpu);
+		 *
+		 * vmx_enable_irq_window()
+		 * "VM-Exit if INTRs are unblocked in guest"
+		 * svm_enable_irq_window()
+		 *
+		 * 第二个地方
+		 */
 		if (kvm_cpu_has_injectable_intr(vcpu))
 			static_call(kvm_x86_enable_irq_window)(vcpu);
 	}
@@ -9460,6 +9942,13 @@ static void process_nmi(struct kvm_vcpu *vcpu)
 	if (static_call(kvm_x86_is_vnmi_pending)(vcpu))
 		limit--;
 
+	/*
+	 * 在以下使用kvm_vcpu_arch->nmi_queued:
+	 *   - arch/x86/kvm/x86.c|874| <<kvm_inject_nmi>> atomic_inc(&vcpu->arch.nmi_queued);
+	 *   - arch/x86/kvm/x86.c|5158| <<kvm_vcpu_ioctl_x86_set_vcpu_events>> atomic_set(&vcpu->arch.nmi_queued, events->nmi.pending);
+	 *   - arch/x86/kvm/x86.c|9855| <<process_nmi>> vcpu->arch.nmi_pending += atomic_xchg(&vcpu->arch.nmi_queued, 0);
+	 *   - arch/x86/kvm/x86.c|12376| <<kvm_vcpu_reset>> atomic_set(&vcpu->arch.nmi_queued, 0);
+	 */
 	vcpu->arch.nmi_pending += atomic_xchg(&vcpu->arch.nmi_queued, 0);
 	vcpu->arch.nmi_pending = min(vcpu->arch.nmi_pending, limit);
 
@@ -9724,6 +10213,10 @@ static void process_smi(struct kvm_vcpu *vcpu)
 	kvm_make_request(KVM_REQ_EVENT, vcpu);
 }
 
+/*
+ * 在以下使用kvm_make_scan_ioapic_request_mask():
+ *   - arch/x86/kvm/ioapic.c|575| <<ioapic_write_indirect>> kvm_make_scan_ioapic_request_mask(ioapic->kvm, vcpu_bitmap);
+ */
 void kvm_make_scan_ioapic_request_mask(struct kvm *kvm,
 				       unsigned long *vcpu_bitmap)
 {
@@ -9731,17 +10224,60 @@ void kvm_make_scan_ioapic_request_mask(struct kvm *kvm,
 
 	zalloc_cpumask_var(&cpus, GFP_ATOMIC);
 
+	/*
+	 * 在以下使用KVM_REQ_SCAN_IOAPIC:
+	 *   - arch/x86/kvm/hyperv.c|171| <<synic_set_sint>> kvm_make_request(KVM_REQ_SCAN_IOAPIC, hv_synic_to_vcpu(synic));
+	 *   - arch/x86/kvm/x86.c|9742| <<kvm_make_scan_ioapic_request_mask>> kvm_make_vcpus_request_mask(kvm, KVM_REQ_SCAN_IOAPIC,
+	 *   - arch/x86/kvm/x86.c|9750| <<kvm_make_scan_ioapic_request>> kvm_make_all_cpus_request(kvm, KVM_REQ_SCAN_IOAPIC);
+	 *   - arch/x86/kvm/x86.c|10087| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_SCAN_IOAPIC, vcpu))
+	 *
+	 * 处理的函数vcpu_scan_ioapic()
+	 */
 	kvm_make_vcpus_request_mask(kvm, KVM_REQ_SCAN_IOAPIC,
 				    NULL, vcpu_bitmap, cpus);
 
 	free_cpumask_var(cpus);
 }
 
+/*
+ * 在以下使用kvm_make_scan_ioapic_request():
+ *   - arch/x86/kvm/ioapic.c|485| <<kvm_arch_post_irq_ack_notifier_list_update>> kvm_make_scan_ioapic_request(kvm);
+ *   - arch/x86/kvm/ioapic.c|578| <<ioapic_write_indirect>> kvm_make_scan_ioapic_request(ioapic->kvm);
+ *   - arch/x86/kvm/ioapic.c|1011| <<kvm_set_ioapic>> kvm_make_scan_ioapic_request(kvm);
+ *   - arch/x86/kvm/irq_comm.c|454| <<kvm_arch_post_irq_routing_update>> kvm_make_scan_ioapic_request(kvm);
+ *   - arch/x86/kvm/lapic.c|347| <<kvm_recalculate_apic_map>> kvm_make_scan_ioapic_request(kvm);
+ */
 void kvm_make_scan_ioapic_request(struct kvm *kvm)
 {
+	/*
+	 * 在以下使用KVM_REQ_SCAN_IOAPIC:
+	 *   - arch/x86/kvm/hyperv.c|171| <<synic_set_sint>> kvm_make_request(KVM_REQ_SCAN_IOAPIC, hv_synic_to_vcpu(synic));
+	 *   - arch/x86/kvm/x86.c|9742| <<kvm_make_scan_ioapic_request_mask>> kvm_make_vcpus_request_mask(kvm, KVM_REQ_SCAN_IOAPIC,
+	 *   - arch/x86/kvm/x86.c|9750| <<kvm_make_scan_ioapic_request>> kvm_make_all_cpus_request(kvm, KVM_REQ_SCAN_IOAPIC);
+	 *   - arch/x86/kvm/x86.c|10087| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_SCAN_IOAPIC, vcpu))
+	 *
+	 * 处理的函数vcpu_scan_ioapic()
+	 */
 	kvm_make_all_cpus_request(kvm, KVM_REQ_SCAN_IOAPIC);
 }
 
+/*
+ * 在以下使用KVM_REQ_APICV_UPDATE:
+ *   - arch/x86/kvm/svm/nested.c|729| <<enter_svm_guest_mode>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+ *   - arch/x86/kvm/svm/nested.c|1111| <<svm_leave_nested>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+ *   - arch/x86/kvm/vmx/nested.c|4696| <<nested_vmx_vmexit>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|10189| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_APICV_UPDATE, vcpu))
+ *   - arch/x86/kvm/x86.c|11394| <<kvm_arch_vcpu_create>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+ *
+ * 处理的函数:
+ * kvm_vcpu_update_apicv(vcpu);
+ *
+ *
+ * 在以下使用kvm_vcpu_update_apicv():
+ *   - arch/x86/kvm/lapic.c|2595| <<kvm_lapic_set_base>> kvm_vcpu_update_apicv(vcpu);
+ *   - arch/x86/kvm/svm/nested.c|1033| <<nested_svm_vmexit>> kvm_vcpu_update_apicv(vcpu);
+ *   - arch/x86/kvm/x86.c|10190| <<vcpu_enter_guest(KVM_REQ_APICV_UPDATE)>> kvm_vcpu_update_apicv(vcpu);
+ */
 void kvm_vcpu_update_apicv(struct kvm_vcpu *vcpu)
 {
 	bool activate;
@@ -9760,7 +10296,17 @@ void kvm_vcpu_update_apicv(struct kvm_vcpu *vcpu)
 		goto out;
 
 	vcpu->arch.apicv_active = activate;
+	/*
+	 * 在以下使用kvm_apic_update_apicv():
+	 *   - arch/x86/kvm/lapic.c|2828| <<kvm_lapic_reset>> kvm_apic_update_apicv(vcpu);
+	 *   - arch/x86/kvm/lapic.c|3192| <<kvm_apic_set_state>> kvm_apic_update_apicv(vcpu);
+	 *   - arch/x86/kvm/x86.c|9877| <<kvm_vcpu_update_apicv>> kvm_apic_update_apicv(vcpu);
+	 */
 	kvm_apic_update_apicv(vcpu);
+	/*
+	 * vmx_refresh_apicv_exec_ctrl()
+	 * avic_refresh_apicv_exec_ctrl()
+	 */
 	static_call(kvm_x86_refresh_apicv_exec_ctrl)(vcpu);
 
 	/*
@@ -9778,6 +10324,44 @@ void kvm_vcpu_update_apicv(struct kvm_vcpu *vcpu)
 }
 EXPORT_SYMBOL_GPL(kvm_vcpu_update_apicv);
 
+/*
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_vcpu_reset
+ * kvm_apic_accept_events
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_lapic_reg_write
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ *
+ * 在以下调用__kvm_set_or_clear_apicv_inhibit():
+ *   - arch/x86/kvm/hyperv.c|132| <<synic_update_vector>> __kvm_set_or_clear_apicv_inhibit(vcpu->kvm,
+ *          APICV_INHIBIT_REASON_HYPERV, !!hv->synic_auto_eoi_used);
+ *   - arch/x86/kvm/x86.c|10434| <<kvm_set_or_clear_apicv_inhibit>> __kvm_set_or_clear_apicv_inhibit(kvm, reason, set);
+ *   - arch/x86/kvm/x86.c|12032| <<kvm_arch_vcpu_guestdbg_update_apicv_inhibit>> __kvm_set_or_clear_apicv_inhibit(kvm,
+ *          APICV_INHIBIT_REASON_BLOCKIRQ, set);
+ */
 void __kvm_set_or_clear_apicv_inhibit(struct kvm *kvm,
 				      enum kvm_apicv_inhibit reason, bool set)
 {
@@ -9785,10 +10369,23 @@ void __kvm_set_or_clear_apicv_inhibit(struct kvm *kvm,
 
 	lockdep_assert_held_write(&kvm->arch.apicv_update_lock);
 
+	/*
+	 * vmx_check_apicv_inhibit_reasons()
+	 * avic_check_apicv_inhibit_reasons()
+	 */
 	if (!kvm_x86_ops.check_apicv_inhibit_reasons ||
 	    !static_call(kvm_x86_check_apicv_inhibit_reasons)(reason))
 		return;
 
+	/*
+	 * 在以下使用kvm_arch->apicv_inhibit_reasons:
+	 *   - arch/x86/kvm/x86.c|9007| <<kvm_apicv_activated>> return (READ_ONCE(kvm->arch.apicv_inhibit_reasons) == 0);
+	 *   - arch/x86/kvm/x86.c|9013| <<kvm_vcpu_apicv_activated>> ulong vm_reasons = READ_ONCE(vcpu->kvm->arch.apicv_inhibit_reasons);
+	 *   - arch/x86/kvm/x86.c|9033| <<kvm_apicv_init>> unsigned long *inhibits = &kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|9830| <<__kvm_set_or_clear_apicv_inhibit>> old = new = kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|9848| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 *   - arch/x86/kvm/x86.c|9857| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 */
 	old = new = kvm->arch.apicv_inhibit_reasons;
 
 	set_or_clear_apicv_inhibit(&new, reason, set);
@@ -9806,6 +10403,17 @@ void __kvm_set_or_clear_apicv_inhibit(struct kvm *kvm,
 		 * side (handling the request) also prevents other vCPUs from
 		 * servicing the request with a stale apicv_inhibit_reasons.
 		 */
+		/*
+		 * 在以下使用KVM_REQ_APICV_UPDATE:
+		 *   - arch/x86/kvm/svm/nested.c|729| <<enter_svm_guest_mode>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+		 *   - arch/x86/kvm/svm/nested.c|1111| <<svm_leave_nested>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+		 *   - arch/x86/kvm/vmx/nested.c|4696| <<nested_vmx_vmexit>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+		 *   - arch/x86/kvm/x86.c|10189| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_APICV_UPDATE, vcpu))
+		 *   - arch/x86/kvm/x86.c|11394| <<kvm_arch_vcpu_create>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+		 *
+		 * 处理的函数:
+		 * kvm_vcpu_update_apicv(vcpu);
+		 */
 		kvm_make_all_cpus_request(kvm, KVM_REQ_APICV_UPDATE);
 		kvm->arch.apicv_inhibit_reasons = new;
 		if (new) {
@@ -9820,6 +10428,41 @@ void __kvm_set_or_clear_apicv_inhibit(struct kvm *kvm,
 	}
 }
 
+/*
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_vcpu_reset
+ * kvm_apic_accept_events
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_lapic_reg_write
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ *
+ * 在以下调用kvm_set_or_clear_apicv_inhibit():
+ *   - arch/x86/include/asm/kvm_host.h|2021| <<kvm_set_apicv_inhibit>> kvm_set_or_clear_apicv_inhibit(kvm, reason, true);
+ *   - arch/x86/include/asm/kvm_host.h|2027| <<kvm_clear_apicv_inhibit>> kvm_set_or_clear_apicv_inhibit(kvm, reason, false);
+ */
 void kvm_set_or_clear_apicv_inhibit(struct kvm *kvm,
 				    enum kvm_apicv_inhibit reason, bool set)
 {
@@ -9827,11 +10470,30 @@ void kvm_set_or_clear_apicv_inhibit(struct kvm *kvm,
 		return;
 
 	down_write(&kvm->arch.apicv_update_lock);
+	/*
+	 * 在以下调用__kvm_set_or_clear_apicv_inhibit():
+	 *   - arch/x86/kvm/hyperv.c|132| <<synic_update_vector>> __kvm_set_or_clear_apicv_inhibit(vcpu->kvm,
+	 *          APICV_INHIBIT_REASON_HYPERV, !!hv->synic_auto_eoi_used);
+	 *   - arch/x86/kvm/x86.c|10434| <<kvm_set_or_clear_apicv_inhibit>> __kvm_set_or_clear_apicv_inhibit(kvm, reason, set);
+	 *   - arch/x86/kvm/x86.c|12032| <<kvm_arch_vcpu_guestdbg_update_apicv_inhibit>> __kvm_set_or_clear_apicv_inhibit(kvm,
+	 *          APICV_INHIBIT_REASON_BLOCKIRQ, set);
+	 */
 	__kvm_set_or_clear_apicv_inhibit(kvm, reason, set);
 	up_write(&kvm->arch.apicv_update_lock);
 }
 EXPORT_SYMBOL_GPL(kvm_set_or_clear_apicv_inhibit);
 
+/*
+ * 在以下使用KVM_REQ_SCAN_IOAPIC:
+ *   - arch/x86/kvm/hyperv.c|171| <<synic_set_sint>> kvm_make_request(KVM_REQ_SCAN_IOAPIC, hv_synic_to_vcpu(synic));
+ *   - arch/x86/kvm/x86.c|9742| <<kvm_make_scan_ioapic_request_mask>> kvm_make_vcpus_request_mask(kvm, KVM_REQ_SCAN_IOAPIC,
+ *   - arch/x86/kvm/x86.c|9750| <<kvm_make_scan_ioapic_request>> kvm_make_all_cpus_request(kvm, KVM_REQ_SCAN_IOAPIC);
+ *   - arch/x86/kvm/x86.c|10087| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_SCAN_IOAPIC, vcpu)) 
+ *
+ *
+ * 处理KVM_REQ_SCAN_IOAPIC:
+ *   - arch/x86/kvm/x86.c|10058| <<vcpu_enter_guest>> vcpu_scan_ioapic(vcpu);
+ */
 static void vcpu_scan_ioapic(struct kvm_vcpu *vcpu)
 {
 	if (!kvm_apic_present(vcpu))
@@ -9839,34 +10501,118 @@ static void vcpu_scan_ioapic(struct kvm_vcpu *vcpu)
 
 	bitmap_zero(vcpu->arch.ioapic_handled_vectors, 256);
 
+	/*
+	 * 在以下调用kvm_x86_sync_pir_to_irr()
+	 *   - arch/x86/kvm/lapic.c|789| <<apic_has_interrupt_for_ppr>> highest_irr = static_call(kvm_x86_sync_pir_to_irr)(apic->vcpu);
+	 *   - arch/x86/kvm/x86.c|4623| <<kvm_vcpu_ioctl_get_lapic>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 *   - arch/x86/kvm/x86.c|9842| <<vcpu_scan_ioapic>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 *   - arch/x86/kvm/x86.c|10171| <<vcpu_enter_guest>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 *   - arch/x86/kvm/x86.c|10220| <<vcpu_enter_guest>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 *
+	 * vmx_sync_pir_to_irr()
+	 */
 	static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
 
+	/*
+	 * 在以下使用kvm_vcpu_arch->ioapic_handled_vectors:
+	 *   - arch/x86/kvm/lapic.c|1273| <<kvm_ioapic_handles_vector>> return test_bit(vector, apic->vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|9840| <<vcpu_scan_ioapic>> bitmap_zero(vcpu->arch.ioapic_handled_vectors, 256);
+	 *   - arch/x86/kvm/x86.c|9845| <<vcpu_scan_ioapic>> kvm_scan_ioapic_routes(vcpu, vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|9847| <<vcpu_scan_ioapic>> kvm_ioapic_scan_entry(vcpu, vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|9864| <<vcpu_load_eoi_exitmap>> bitmap_or((ulong *)eoi_exit_bitmap, vcpu->arch.ioapic_handled_vectors,
+	 *              to_hv_synic(vcpu)->vec_bitmap, 256);
+	 *   - arch/x86/kvm/x86.c|9871| <<vcpu_load_eoi_exitmap>> static_call(kvm_x86_load_eoi_exitmap)(vcpu, (u64 *)vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|10004| <<vcpu_enter_guest>> if (test_bit(vcpu->arch.pending_ioapic_eoi, vcpu->arch.ioapic_handled_vectors)) {
+	 *
+	 *
+	 * on: KVM模拟全部
+	 * split: QEMU模拟IOAPIC和PIC,KVM模拟LAPIC
+	 * off:QEMU 模拟全部
+	 */
 	if (irqchip_split(vcpu->kvm))
 		kvm_scan_ioapic_routes(vcpu, vcpu->arch.ioapic_handled_vectors);
 	else if (ioapic_in_kernel(vcpu->kvm))
 		kvm_ioapic_scan_entry(vcpu, vcpu->arch.ioapic_handled_vectors);
 
+	/*
+	 * 在以下使用kvm_vcpu_arch->load_eoi_exitmap_pending:
+	 *   - arch/x86/kvm/kvm_cache_regs.h|184| <<leave_guest_mode>> if (vcpu->arch.load_eoi_exitmap_pending) {
+	 *   - arch/x86/kvm/kvm_cache_regs.h|185| <<leave_guest_mode>> vcpu->arch.load_eoi_exitmap_pending = false;
+	 *   - arch/x86/kvm/x86.c|9850| <<vcpu_scan_ioapic>> vcpu->arch.load_eoi_exitmap_pending = true;
+	 */
 	if (is_guest_mode(vcpu))
 		vcpu->arch.load_eoi_exitmap_pending = true;
 	else
 		kvm_make_request(KVM_REQ_LOAD_EOI_EXITMAP, vcpu);
+	/*
+	 * 在以下使用KVM_REQ_LOAD_EOI_EXITMAP:
+	 *   - arch/x86/kvm/kvm_cache_regs.h|186| <<leave_guest_mode>> kvm_make_request(KVM_REQ_LOAD_EOI_EXITMAP, vcpu);
+	 *   - arch/x86/kvm/x86.c|9889| <<vcpu_scan_ioapic>> kvm_make_request(KVM_REQ_LOAD_EOI_EXITMAP, vcpu);
+	 *   - arch/x86/kvm/x86.c|10089| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_LOAD_EOI_EXITMAP, vcpu))
+	 *
+	 * 处理的函数vcpu_load_eoi_exitmap()
+	 */
 }
 
+/*
+ * 在以下使用KVM_REQ_LOAD_EOI_EXITMAP:
+ *   - arch/x86/kvm/kvm_cache_regs.h|186| <<leave_guest_mode>> kvm_make_request(KVM_REQ_LOAD_EOI_EXITMAP, vcpu);
+ *   - arch/x86/kvm/x86.c|9889| <<vcpu_scan_ioapic>> kvm_make_request(KVM_REQ_LOAD_EOI_EXITMAP, vcpu);
+ *   - arch/x86/kvm/x86.c|10089| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_LOAD_EOI_EXITMAP, vcpu))
+ *
+ * 处理的函数vcpu_load_eoi_exitmap()
+ *
+ *
+ * 处理KVM_REQ_IOAPIC_EOI_EXIT:
+ *   - arch/x86/kvm/x86.c|10060| <<vcpu_enter_guest>> vcpu_load_eoi_exitmap(vcpu);
+ */
 static void vcpu_load_eoi_exitmap(struct kvm_vcpu *vcpu)
 {
 	u64 eoi_exit_bitmap[4];
 
+	/*
+	 * 在以下调用kvm_apic_hw_enabled():
+	 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+	 *   - arch/x86/kvm/lapic.c|2040| <<apic_mmio_read>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2125| <<lapic_timer_int_injected>> if (kvm_apic_hw_enabled(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2809| <<apic_mmio_write>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|3330| <<kvm_apic_local_deliver>> if (kvm_apic_hw_enabled(apic) && !(reg & APIC_LVT_MASKED)) {
+	 *   - arch/x86/kvm/lapic.c|3443| <<kvm_apic_accept_pic_intr>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 *   - arch/x86/kvm/lapic.h|246| <<kvm_apic_present>> return lapic_in_kernel(vcpu) && kvm_apic_hw_enabled(vcpu->arch.apic);
+	 *   - arch/x86/kvm/x86.c|10218| <<vcpu_load_eoi_exitmap>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 */
 	if (!kvm_apic_hw_enabled(vcpu->arch.apic))
 		return;
 
 	if (to_hv_vcpu(vcpu)) {
+		/*
+		 * 在以下使用kvm_vcpu_arch->ioapic_handled_vectors:
+		 *   - arch/x86/kvm/lapic.c|1273| <<kvm_ioapic_handles_vector>> return test_bit(vector, apic->vcpu->arch.ioapic_handled_vectors);
+		 *   - arch/x86/kvm/x86.c|9840| <<vcpu_scan_ioapic>> bitmap_zero(vcpu->arch.ioapic_handled_vectors, 256);
+		 *   - arch/x86/kvm/x86.c|9845| <<vcpu_scan_ioapic>> kvm_scan_ioapic_routes(vcpu, vcpu->arch.ioapic_handled_vectors);
+		 *   - arch/x86/kvm/x86.c|9847| <<vcpu_scan_ioapic>> kvm_ioapic_scan_entry(vcpu, vcpu->arch.ioapic_handled_vectors);
+		 *   - arch/x86/kvm/x86.c|9864| <<vcpu_load_eoi_exitmap>> bitmap_or((ulong *)eoi_exit_bitmap, vcpu->arch.ioapic_handled_vectors,
+		 *              to_hv_synic(vcpu)->vec_bitmap, 256);
+		 *   - arch/x86/kvm/x86.c|9871| <<vcpu_load_eoi_exitmap>> static_call(kvm_x86_load_eoi_exitmap)(vcpu, (u64 *)vcpu->arch.ioapic_handled_vectors);
+		 *   - arch/x86/kvm/x86.c|10004| <<vcpu_enter_guest>> if (test_bit(vcpu->arch.pending_ioapic_eoi, vcpu->arch.ioapic_handled_vectors)) {
+		 */
 		bitmap_or((ulong *)eoi_exit_bitmap,
 			  vcpu->arch.ioapic_handled_vectors,
 			  to_hv_synic(vcpu)->vec_bitmap, 256);
+		/*
+		 * vmx_load_eoi_exitmap()
+		 */
 		static_call(kvm_x86_load_eoi_exitmap)(vcpu, eoi_exit_bitmap);
 		return;
 	}
 
+	/*
+	 * 在以下调用kvm_x86_load_eoi_exitmap():
+	 *   - arch/x86/kvm/x86.c|9921| <<vcpu_load_eoi_exitmap>> static_call(kvm_x86_load_eoi_exitmap)(vcpu, eoi_exit_bitmap);
+	 *   - arch/x86/kvm/x86.c|9928| <<vcpu_load_eoi_exitmap>> static_call(kvm_x86_load_eoi_exitmap)(
+	 *
+	 * vmx_load_eoi_exitmap()
+	 */
 	static_call(kvm_x86_load_eoi_exitmap)(
 		vcpu, (u64 *)vcpu->arch.ioapic_handled_vectors);
 }
@@ -9881,6 +10627,15 @@ void kvm_arch_mmu_notifier_invalidate_range(struct kvm *kvm,
 	 * Update it when it becomes invalid.
 	 */
 	apic_address = gfn_to_hva(kvm, APIC_DEFAULT_PHYS_BASE >> PAGE_SHIFT);
+	/*
+	 * 在以下使用KVM_REQ_APIC_PAGE_RELOAD:
+	 *   - arch/x86/kvm/vmx/nested.c|4691| <<nested_vmx_vmexit>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|4645| <<vmx_vcpu_reset>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|6462| <<vmx_set_virtual_apic_mode>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+	 *   - arch/x86/kvm/x86.c|10340| <<kvm_arch_mmu_notifier_invalidate_range>> kvm_make_all_cpus_request(kvm, KVM_REQ_APIC_PAGE_RELOAD);
+	 *
+	 * 处理的函数kvm_vcpu_reload_apic_access_page()
+	 */
 	if (start <= apic_address && apic_address < end)
 		kvm_make_all_cpus_request(kvm, KVM_REQ_APIC_PAGE_RELOAD);
 }
@@ -9890,6 +10645,15 @@ void kvm_arch_guest_memory_reclaimed(struct kvm *kvm)
 	static_call_cond(kvm_x86_guest_memory_reclaimed)(kvm);
 }
 
+/*
+ * 在以下使用KVM_REQ_APIC_PAGE_RELOAD:
+ *   - arch/x86/kvm/vmx/nested.c|4691| <<nested_vmx_vmexit>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|4645| <<vmx_vcpu_reset>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|6462| <<vmx_set_virtual_apic_mode>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+ *   - arch/x86/kvm/x86.c|10340| <<kvm_arch_mmu_notifier_invalidate_range>> kvm_make_all_cpus_request(kvm, KVM_REQ_APIC_PAGE_RELOAD);
+ *
+ * 处理的函数kvm_vcpu_reload_apic_access_page()
+ */
 void kvm_vcpu_reload_apic_access_page(struct kvm_vcpu *vcpu)
 {
 	if (!lapic_in_kernel(vcpu))
@@ -9912,6 +10676,10 @@ EXPORT_SYMBOL_GPL(__kvm_request_immediate_exit);
  * exiting to the userspace.  Otherwise, the value will be returned to the
  * userspace.
  */
+/*
+ * 在以下调用vcpu_enter_guest():
+ *   - arch/x86/kvm/x86.c|11174| <<vcpu_run>> r = vcpu_enter_guest(vcpu);
+ */
 static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 {
 	int r;
@@ -9922,6 +10690,23 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 
 	bool req_immediate_exit = false;
 
+	/*
+	 * 在以下使用kvm->dirty_ring_size:
+	 *   - arch/x86/kvm/x86.c|10381| <<vcpu_enter_guest>> if (unlikely(vcpu->kvm->dirty_ring_size &&
+	 *   - virt/kvm/kvm_main.c|1563| <<kvm_prepare_memory_region>> else if (!kvm->dirty_ring_size) {
+	 *   - virt/kvm/kvm_main.c|2007| <<kvm_get_dirty_log>> if (kvm->dirty_ring_size)
+	 *   - virt/kvm/kvm_main.c|2072| <<kvm_get_dirty_log_protect>> if (kvm->dirty_ring_size)
+	 *   - virt/kvm/kvm_main.c|2184| <<kvm_clear_dirty_log_protect>> if (kvm->dirty_ring_size)
+	 *   - virt/kvm/kvm_main.c|3302| <<mark_page_dirty_in_slot>> if (kvm->dirty_ring_size)
+	 *   - virt/kvm/kvm_main.c|3706| <<kvm_page_in_dirty_ring>> return (pgoff >= KVM_DIRTY_LOG_PAGE_OFFSET)
+	 *           && (pgoff < KVM_DIRTY_LOG_PAGE_OFFSET + kvm->dirty_ring_size / PAGE_SIZE);
+	 *   - virt/kvm/kvm_main.c|3849| <<kvm_vm_ioctl_create_vcpu>> if (kvm->dirty_ring_size) {
+	 *   - virt/kvm/kvm_main.c|3851| <<kvm_vm_ioctl_create_vcpu>> r = kvm_dirty_ring_alloc(&vcpu->dirty_ring,
+	 *           id, kvm->dirty_ring_size);
+	 *   - virt/kvm/kvm_main.c|4459| <<kvm_vm_ioctl_enable_dirty_log_ring>> if (kvm->dirty_ring_size)
+	 *   - virt/kvm/kvm_main.c|4468| <<kvm_vm_ioctl_enable_dirty_log_ring>> kvm->dirty_ring_size = size;
+	 *   - virt/kvm/kvm_main.c|4482| <<kvm_vm_ioctl_reset_dirty_pages>> if (!kvm->dirty_ring_size)
+	 */
 	/* Forbid vmenter if vcpu dirty ring is soft-full */
 	if (unlikely(vcpu->kvm->dirty_ring_size &&
 		     kvm_dirty_ring_soft_full(&vcpu->dirty_ring))) {
@@ -9931,7 +10716,15 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 		goto out;
 	}
 
+	/*
+	 * 一直到kvm_mmu_reload()之前
+	 */
 	if (kvm_request_pending(vcpu)) {
+		/*
+		 * 在以下使用KVM_REQ_VM_DEAD:
+		 *   - arch/x86/kvm/x86.c|10390| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_VM_DEAD, vcpu)) {
+		 *   - include/linux/kvm_host.h|795| <<kvm_vm_dead>> kvm_make_all_cpus_request(kvm, KVM_REQ_VM_DEAD);
+		 */
 		if (kvm_check_request(KVM_REQ_VM_DEAD, vcpu)) {
 			r = -EIO;
 			goto out;
@@ -9942,6 +10735,12 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 				goto out;
 			}
 		}
+		/*
+		 * x86在以下使用KVM_REQ_MMU_RELOAD:
+		 *   - arch/x86/kvm/mmu/mmu.c|3940| <<is_page_fault_stale>> if (!sp && kvm_test_request(KVM_REQ_MMU_RELOAD, vcpu))
+		 *   - arch/x86/kvm/x86.c|10400| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_MMU_RELOAD, vcpu))
+		 *   - virt/kvm/kvm_main.c|377| <<kvm_reload_remote_mmus>> kvm_make_all_cpus_request(kvm, KVM_REQ_MMU_RELOAD);
+		 */
 		if (kvm_check_request(KVM_REQ_MMU_RELOAD, vcpu))
 			kvm_mmu_unload(vcpu);
 		if (kvm_check_request(KVM_REQ_MIGRATE_TIMER, vcpu))
@@ -9967,6 +10766,11 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 		}
 		kvm_service_local_tlb_flush_requests(vcpu);
 
+		/*
+		 * 在以下使用KVM_REQ_REPORT_TPR_ACCESS:
+		 *   - arch/x86/kvm/lapic.c|2056| <<__report_tpr_access>> kvm_make_request(KVM_REQ_REPORT_TPR_ACCESS, vcpu);
+		 *   - arch/x86/kvm/x86.c|10425| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_REPORT_TPR_ACCESS, vcpu)) {
+		 */
 		if (kvm_check_request(KVM_REQ_REPORT_TPR_ACCESS, vcpu)) {
 			vcpu->run->exit_reason = KVM_EXIT_TPR_ACCESS;
 			r = 0;
@@ -10000,6 +10804,23 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 			kvm_pmu_deliver_pmi(vcpu);
 		if (kvm_check_request(KVM_REQ_IOAPIC_EOI_EXIT, vcpu)) {
 			BUG_ON(vcpu->arch.pending_ioapic_eoi > 255);
+			/*
+			 * 在以下使用kvm_vcpu_arch->pending_ioapic_eoi:
+			 *   - arch/x86/kvm/lapic.c|1286| <<kvm_ioapic_send_eoi>> apic->vcpu->arch.pending_ioapic_eoi = vector;
+			 *   - arch/x86/kvm/x86.c|10008| <<vcpu_enter_guest(KVM_REQ_IOAPIC_EOI_EXIT)>> BUG_ON(vcpu->arch.pending_ioapic_eoi > 255);
+			 *   - arch/x86/kvm/x86.c|10009| <<vcpu_enter_guest(KVM_REQ_IOAPIC_EOI_EXIT)>> if (test_bit(vcpu->arch.pending_ioapic_eoi,
+			 *   - arch/x86/kvm/x86.c|10013| <<vcpu_enter_guest(KVM_REQ_IOAPIC_EOI_EXIT)>> vcpu->arch.pending_ioapic_eoi;
+			 *
+			 * 在以下使用kvm_vcpu_arch->ioapic_handled_vectors:
+			 *   - arch/x86/kvm/lapic.c|1273| <<kvm_ioapic_handles_vector>> return test_bit(vector, apic->vcpu->arch.ioapic_handled_vectors);
+			 *   - arch/x86/kvm/x86.c|9840| <<vcpu_scan_ioapic>> bitmap_zero(vcpu->arch.ioapic_handled_vectors, 256);
+			 *   - arch/x86/kvm/x86.c|9845| <<vcpu_scan_ioapic>> kvm_scan_ioapic_routes(vcpu, vcpu->arch.ioapic_handled_vectors);
+			 *   - arch/x86/kvm/x86.c|9847| <<vcpu_scan_ioapic>> kvm_ioapic_scan_entry(vcpu, vcpu->arch.ioapic_handled_vectors);
+			 *   - arch/x86/kvm/x86.c|9864| <<vcpu_load_eoi_exitmap>> bitmap_or((ulong *)eoi_exit_bitmap, vcpu->arch.ioapic_handled_vectors,
+			 *              to_hv_synic(vcpu)->vec_bitmap, 256);
+			 *   - arch/x86/kvm/x86.c|9871| <<vcpu_load_eoi_exitmap>> static_call(kvm_x86_load_eoi_exitmap)(vcpu, (u64 *)vcpu->arch.ioapic_handled_vectors);
+			 *   - arch/x86/kvm/x86.c|10004| <<vcpu_enter_guest>> if (test_bit(vcpu->arch.pending_ioapic_eoi, vcpu->arch.ioapic_handled_vectors)) {
+			 */
 			if (test_bit(vcpu->arch.pending_ioapic_eoi,
 				     vcpu->arch.ioapic_handled_vectors)) {
 				vcpu->run->exit_reason = KVM_EXIT_IOAPIC_EOI;
@@ -10009,10 +10830,28 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 				goto out;
 			}
 		}
+		/*
+		 * 在以下使用KVM_REQ_SCAN_IOAPIC:
+		 *   - arch/x86/kvm/hyperv.c|171| <<synic_set_sint>> kvm_make_request(KVM_REQ_SCAN_IOAPIC, hv_synic_to_vcpu(synic));
+		 *   - arch/x86/kvm/x86.c|9742| <<kvm_make_scan_ioapic_request_mask>> kvm_make_vcpus_request_mask(kvm, KVM_REQ_SCAN_IOAPIC,
+		 *   - arch/x86/kvm/x86.c|9750| <<kvm_make_scan_ioapic_request>> kvm_make_all_cpus_request(kvm, KVM_REQ_SCAN_IOAPIC);
+		 *   - arch/x86/kvm/x86.c|10087| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_SCAN_IOAPIC, vcpu)) 
+		 *
+		 * 处理的函数vcpu_scan_ioapic()
+		 */
 		if (kvm_check_request(KVM_REQ_SCAN_IOAPIC, vcpu))
 			vcpu_scan_ioapic(vcpu);
 		if (kvm_check_request(KVM_REQ_LOAD_EOI_EXITMAP, vcpu))
 			vcpu_load_eoi_exitmap(vcpu);
+		/*
+		 * 在以下使用KVM_REQ_APIC_PAGE_RELOAD:
+		 *   - arch/x86/kvm/vmx/nested.c|4691| <<nested_vmx_vmexit>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+		 *   - arch/x86/kvm/vmx/vmx.c|4645| <<vmx_vcpu_reset>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+		 *   - arch/x86/kvm/vmx/vmx.c|6462| <<vmx_set_virtual_apic_mode>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+		 *   - arch/x86/kvm/x86.c|10340| <<kvm_arch_mmu_notifier_invalidate_range>> kvm_make_all_cpus_request(kvm, KVM_REQ_APIC_PAGE_RELOAD);
+		 *
+		 * 处理的函数kvm_vcpu_reload_apic_access_page()
+		 */
 		if (kvm_check_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu))
 			kvm_vcpu_reload_apic_access_page(vcpu);
 		if (kvm_check_request(KVM_REQ_HV_CRASH, vcpu)) {
@@ -10043,8 +10882,27 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 		 */
 		if (kvm_check_request(KVM_REQ_HV_STIMER, vcpu))
 			kvm_hv_process_stimers(vcpu);
+		/*
+		 * 在以下使用KVM_REQ_APICV_UPDATE:
+		 *   - arch/x86/kvm/svm/nested.c|729| <<enter_svm_guest_mode>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+		 *   - arch/x86/kvm/svm/nested.c|1111| <<svm_leave_nested>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+		 *   - arch/x86/kvm/vmx/nested.c|4696| <<nested_vmx_vmexit>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+		 *   - arch/x86/kvm/x86.c|10189| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_APICV_UPDATE, vcpu))
+		 *   - arch/x86/kvm/x86.c|11394| <<kvm_arch_vcpu_create>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+		 *
+		 * 处理的函数:
+		 * kvm_vcpu_update_apicv(vcpu);
+		 */
 		if (kvm_check_request(KVM_REQ_APICV_UPDATE, vcpu))
 			kvm_vcpu_update_apicv(vcpu);
+		/*
+		 * 在以下使用KVM_REQ_APF_READY:
+		 *   - arch/x86/kvm/lapic.c|621| <<apic_set_spiv>> kvm_make_request(KVM_REQ_APF_READY, apic->vcpu);
+		 *   - arch/x86/kvm/lapic.c|3303| <<kvm_lapic_set_base>> kvm_make_request(KVM_REQ_APF_READY, vcpu);
+		 *   - arch/x86/kvm/x86.c|13246| <<kvm_arch_async_page_present_queued>> kvm_make_request(KVM_REQ_APF_READY, vcpu);
+		 *
+		 * 处理的函数kvm_check_async_pf_completion()
+		 */
 		if (kvm_check_request(KVM_REQ_APF_READY, vcpu))
 			kvm_check_async_pf_completion(vcpu);
 		if (kvm_check_request(KVM_REQ_MSR_FILTER_CHANGED, vcpu))
@@ -10057,6 +10915,13 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 	if (kvm_check_request(KVM_REQ_EVENT, vcpu) || req_int_win ||
 	    kvm_xen_has_interrupt(vcpu)) {
 		++vcpu->stat.req_event;
+		/*
+		 * 在以下使用kvm_apic_accept_events():
+		 *   - arch/x86/kvm/x86.c|10552| <<vcpu_enter_guest>> r = kvm_apic_accept_events(vcpu);
+		 *   - arch/x86/kvm/x86.c|10877| <<vcpu_block>> if (kvm_apic_accept_events(vcpu) < 0)
+		 *   - arch/x86/kvm/x86.c|11077| <<kvm_arch_vcpu_ioctl_run>> if (kvm_apic_accept_events(vcpu) < 0) {
+		 *   - arch/x86/kvm/x86.c|11313| <<kvm_arch_vcpu_ioctl_get_mpstate>> r = kvm_apic_accept_events(vcpu);
+		 */
 		r = kvm_apic_accept_events(vcpu);
 		if (r < 0) {
 			r = 0;
@@ -10067,11 +10932,22 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 			goto out;
 		}
 
+		/*
+		 * 只在此处调用
+		 */
 		r = inject_pending_event(vcpu, &req_immediate_exit);
 		if (r < 0) {
 			r = 0;
 			goto out;
 		}
+		/*
+		 * 在以下调用:
+		 *   - arch/x86/kvm/x86.c|9847| <<inject_pending_event>> static_call(kvm_x86_enable_irq_window)(vcpu);
+		 *   - arch/x86/kvm/x86.c|10871| <<vcpu_enter_guest>> static_call(kvm_x86_enable_irq_window)(vcpu);
+		 *
+		 * vmx_enable_irq_window()
+		 * svm_enable_irq_window()
+		 */
 		if (req_int_win)
 			static_call(kvm_x86_enable_irq_window)(vcpu);
 
@@ -10081,6 +10957,11 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 		}
 	}
 
+	/*
+	 * 在以下使用kvm_mmu_reload():
+	 *   - arch/x86/kvm/x86.c|10576| <<vcpu_enter_guest>> r = kvm_mmu_reload(vcpu);
+	 *   - arch/x86/kvm/x86.c|13052| <<kvm_arch_async_page_ready>> r = kvm_mmu_reload(vcpu);
+	 */
 	r = kvm_mmu_reload(vcpu);
 	if (unlikely(r)) {
 		goto cancel_injection;
@@ -10088,6 +10969,11 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 
 	preempt_disable();
 
+	/*
+	 * 只在此处调用kvm_x86_prepare_switch_to_guest
+	 *
+	 * vmx_prepare_switch_to_guest()
+	 */
 	static_call(kvm_x86_prepare_switch_to_guest)(vcpu);
 
 	/*
@@ -10122,9 +11008,24 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 	 * use the POSTED_INTR_VECTOR even if APICv is disabled,
 	 * so do it even if APICv is disabled on this vCPU.
 	 */
+	/*
+	 * 在以下调用kvm_x86_sync_pir_to_irr()
+	 *   - arch/x86/kvm/lapic.c|789| <<apic_has_interrupt_for_ppr>> highest_irr = static_call(kvm_x86_sync_pir_to_irr)(apic->vcpu);
+	 *   - arch/x86/kvm/x86.c|4623| <<kvm_vcpu_ioctl_get_lapic>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 *   - arch/x86/kvm/x86.c|9842| <<vcpu_scan_ioapic>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 *   - arch/x86/kvm/x86.c|10171| <<vcpu_enter_guest>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 *   - arch/x86/kvm/x86.c|10220| <<vcpu_enter_guest>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 *
+	 * vmx_sync_pir_to_irr()
+	 */
 	if (kvm_lapic_enabled(vcpu))
 		static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
 
+	/*
+	 * 在以下调用kvm_vcpu_exit_request():
+	 *   - arch/x86/kvm/x86.c|10386| <<vcpu_enter_guest(关于cancel_injection)>> if (kvm_vcpu_exit_request(vcpu)) {
+	 *   - arch/x86/kvm/x86.c|10443| <<vcpu_enter_guest(关于EXIT_FASTPATH_EXIT_HANDLED)>> if (unlikely(kvm_vcpu_exit_request(vcpu))) {
+	 */
 	if (kvm_vcpu_exit_request(vcpu)) {
 		vcpu->mode = OUTSIDE_GUEST_MODE;
 		smp_wmb();
@@ -10137,6 +11038,9 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 
 	if (req_immediate_exit) {
 		kvm_make_request(KVM_REQ_EVENT, vcpu);
+		/*
+		 * vmx_request_immediate_exit()
+		 */
 		static_call(kvm_x86_request_immediate_exit)(vcpu);
 	}
 
@@ -10167,13 +11071,36 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 		WARN_ON_ONCE((kvm_vcpu_apicv_activated(vcpu) != kvm_vcpu_apicv_active(vcpu)) &&
 			     (kvm_get_apic_mode(vcpu) != LAPIC_MODE_DISABLED));
 
+		/*
+		 * vmx_vcpu_run()
+		 * svm_vcpu_run()
+		 */
 		exit_fastpath = static_call(kvm_x86_vcpu_run)(vcpu);
+		/*
+		 * 很可能是EXIT_FASTPATH_NONE
+		 * 除非ICR或者HW timer
+		 */
 		if (likely(exit_fastpath != EXIT_FASTPATH_REENTER_GUEST))
 			break;
 
+		/*
+		 * 在以下调用kvm_x86_sync_pir_to_irr()
+		 *   - arch/x86/kvm/lapic.c|789| <<apic_has_interrupt_for_ppr>> highest_irr = static_call(kvm_x86_sync_pir_to_irr)(apic->vcpu);
+		 *   - arch/x86/kvm/x86.c|4623| <<kvm_vcpu_ioctl_get_lapic>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+		 *   - arch/x86/kvm/x86.c|9842| <<vcpu_scan_ioapic>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+		 *   - arch/x86/kvm/x86.c|10171| <<vcpu_enter_guest>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+		 *   - arch/x86/kvm/x86.c|10220| <<vcpu_enter_guest>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+		 *
+		 * vmx_sync_pir_to_irr();
+		 */
 		if (kvm_lapic_enabled(vcpu))
 			static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
 
+		/*
+		 * 在以下调用kvm_vcpu_exit_request():
+		 *   - arch/x86/kvm/x86.c|10386| <<vcpu_enter_guest(关于cancel_injection)>> if (kvm_vcpu_exit_request(vcpu)) {
+		 *   - arch/x86/kvm/x86.c|10443| <<vcpu_enter_guest(关于EXIT_FASTPATH_EXIT_HANDLED)>> if (unlikely(kvm_vcpu_exit_request(vcpu))) {
+		 */
 		if (unlikely(kvm_vcpu_exit_request(vcpu))) {
 			exit_fastpath = EXIT_FASTPATH_EXIT_HANDLED;
 			break;
@@ -10206,6 +11133,25 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 	if (hw_breakpoint_active())
 		hw_breakpoint_restore();
 
+	/*
+	 * 在以下使用kvm_vcpu_arch->last_vmentry_cpu:
+	 *   - arch/x86/kvm/cpuid.c|349| <<kvm_set_cpuid>> if (vcpu->arch.last_vmentry_cpu != -1)
+	 *   - arch/x86/kvm/mmu/mmu.c|5018| <<kvm_mmu_after_set_cpuid>> if (vcpu->arch.last_vmentry_cpu != -1) {
+	 *   - arch/x86/kvm/svm/sev.c|2607| <<pre_sev_run>> if (sd->sev_vmcbs[asid] == svm->vmcb && svm->vcpu.arch.last_vmentry_cpu == cpu)
+	 *   - arch/x86/kvm/svm/svm.c|3341| <<dump_vmcb>> pr_err("VMCB %p, last attempted VMRUN on CPU %d\n",
+	 *                                    svm->current_vmcb->ptr, vcpu->arch.last_vmentry_cpu);
+	 *   - arch/x86/kvm/svm/svm.c|3465| <<svm_handle_invalid_exit>> vcpu->run->internal.data[1] = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/svm/svm.c|3540| <<handle_exit>> kvm_run->fail_entry.cpu = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/vmx/vmx.c|4996| <<handle_exception_nmi>> vcpu->run->internal.data[3] = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/vmx/vmx.c|5971| <<dump_vmcs>> pr_err("VMCS %p, last attempted VM-entry on CPU %d\n",
+	 *                                    vmx->loaded_vmcs->vmcs, vcpu->arch.last_vmentry_cpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|6195| <<__vmx_handle_exit>> vcpu->run->fail_entry.cpu = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/vmx/vmx.c|6204| <<__vmx_handle_exit>> vcpu->run->fail_entry.cpu = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/vmx/vmx.c|6232| <<__vmx_handle_exit>> vcpu->run->internal.data[ndata++] = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/vmx/vmx.c|6292| <<__vmx_handle_exit>> vcpu->run->internal.data[1] = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/x86.c|10741| <<vcpu_enter_guest>> vcpu->arch.last_vmentry_cpu = vcpu->cpu;
+	 *   - arch/x86/kvm/x86.c|11799| <<kvm_arch_vcpu_create>> vcpu->arch.last_vmentry_cpu = -1;
+	 */
 	vcpu->arch.last_vmentry_cpu = vcpu->cpu;
 	vcpu->arch.last_guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
 
@@ -10220,6 +11166,10 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 	if (vcpu->arch.xfd_no_write_intercept)
 		fpu_sync_guest_vmexit_xfd_state();
 
+	/*
+	 * vmx_handle_exit_irqoff
+	 * svm_handle_exit_irqoff
+	 */
 	static_call(kvm_x86_handle_exit_irqoff)(vcpu);
 
 	if (vcpu->arch.guest_fpu.xfd_err)
@@ -10232,6 +11182,12 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 	 * interrupts on processors that implement an interrupt shadow, the
 	 * stat.exits increment will do nicely.
 	 */
+	/*
+	 * 在以下使用kvm_before_interrupt():
+	 *   - arch/x86/kvm/svm/svm.c|4206| <<svm_vcpu_run>> kvm_before_interrupt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|6920| <<handle_interrupt_nmi_irqoff>> kvm_before_interrupt(vcpu);
+	 *   - arch/x86/kvm/x86.c|11036| <<vcpu_enter_guest>> kvm_before_interrupt(vcpu);
+	 */
 	kvm_before_interrupt(vcpu);
 	local_irq_enable();
 	++vcpu->stat.exits;
@@ -10248,6 +11204,13 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 	vtime_account_guest_exit();
 
 	if (lapic_in_kernel(vcpu)) {
+		/*
+		 * 在以下使用kvm_timer->advance_expire_delta:
+		 *   - arch/x86/kvm/lapic.c|2382| <<__kvm_wait_lapic_expire>> apic->lapic_timer.advance_expire_delta = guest_tsc - tsc_deadline;
+		 *   - arch/x86/kvm/lapic.c|2385| <<__kvm_wait_lapic_expire>> adjust_lapic_timer_advance(vcpu, apic->lapic_timer.advance_expire_delta);
+		 *   - arch/x86/kvm/x86.c|10872| <<vcpu_enter_guest>> s64 delta = vcpu->arch.apic->lapic_timer.advance_expire_delta;
+		 *   - arch/x86/kvm/x86.c|10875| <<vcpu_enter_guest>> vcpu->arch.apic->lapic_timer.advance_expire_delta = S64_MIN;
+		 */
 		s64 delta = vcpu->arch.apic->lapic_timer.advance_expire_delta;
 		if (delta != S64_MIN) {
 			trace_kvm_wait_lapic_expire(vcpu->vcpu_id, delta);
@@ -10271,16 +11234,59 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 	if (unlikely(vcpu->arch.tsc_always_catchup))
 		kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
 
+	/*
+	 * 在以下使用kvm_vcpu_arch->apic_attention:
+	 *   - arch/x86/kvm/lapic.c|1283| <<pv_eoi_set_pending>> __set_bit(KVM_APIC_PV_EOI_PENDING, &vcpu->arch.apic_attention);
+	 *   - arch/x86/kvm/lapic.c|1291| <<pv_eoi_clr_pending>> __clear_bit(KVM_APIC_PV_EOI_PENDING, &vcpu->arch.apic_attention);
+	 *   - arch/x86/kvm/lapic.c|3541| <<kvm_lapic_reset>> vcpu->arch.apic_attention = 0;
+	 *   - arch/x86/kvm/lapic.c|4066| <<kvm_lapic_sync_from_vapic>> if (test_bit(KVM_APIC_PV_EOI_PENDING, &vcpu->arch.apic_attention))
+	 *   - arch/x86/kvm/lapic.c|4069| <<kvm_lapic_sync_from_vapic>> if (!test_bit(KVM_APIC_CHECK_VAPIC, &vcpu->arch.apic_attention))
+	 *   - arch/x86/kvm/lapic.c|4128| <<kvm_lapic_sync_to_vapic>> if (!test_bit(KVM_APIC_CHECK_VAPIC, &vcpu->arch.apic_attention))
+	 *   - arch/x86/kvm/lapic.c|4151| <<kvm_lapic_set_vapic_addr>> __set_bit(KVM_APIC_CHECK_VAPIC, &vcpu->arch.apic_attention);
+	 *   - arch/x86/kvm/lapic.c|4153| <<kvm_lapic_set_vapic_addr>> __clear_bit(KVM_APIC_CHECK_VAPIC, &vcpu->arch.apic_attention);
+	 *   - arch/x86/kvm/x86.c|10895| <<vcpu_enter_guest>> if (vcpu->arch.apic_attention)
+	 *   - arch/x86/kvm/x86.c|10926| <<vcpu_enter_guest>> if (unlikely(vcpu->arch.apic_attention))
+	 *
+	 * 在以下调用kvm_lapic_sync_from_vapic():
+	 *   - arch/x86/kvm/x86.c|10896| <<vcpu_enter_guest>> kvm_lapic_sync_from_vapic(vcpu);
+	 *   - arch/x86/kvm/x86.c|10927| <<vcpu_enter_guest>> kvm_lapic_sync_from_vapic(vcpu);
+	 */
 	if (vcpu->arch.apic_attention)
 		kvm_lapic_sync_from_vapic(vcpu);
 
+	/*
+	 * apic_set_eoi
+	 * kvm_lapic_reg_write
+	 * vmx_set_msr
+	 * __kvm_set_msr
+	 * kvm_emulate_wrmsr
+	 * vmx_handle_exit
+	 * vcpu_enter_guest
+	 * vcpu_run
+	 * kvm_arch_vcpu_ioctl_run
+	 * kvm_vcpu_ioctl
+	 * __x64_sys_ioctl
+	 * do_syscall_64
+	 * entry_SYSCALL_64_after_hwframe
+	 *
+	 * vmx_handle_exit
+	 */
 	r = static_call(kvm_x86_handle_exit)(vcpu, exit_fastpath);
 	return r;
 
 cancel_injection:
 	if (req_immediate_exit)
 		kvm_make_request(KVM_REQ_EVENT, vcpu);
+	/*
+	 * vmx_cancel_injection
+	 * svm_cancel_injection
+	 */
 	static_call(kvm_x86_cancel_injection)(vcpu);
+	/*
+	 * 在以下调用kvm_lapic_sync_from_vapic():
+	 *   - arch/x86/kvm/x86.c|10896| <<vcpu_enter_guest>> kvm_lapic_sync_from_vapic(vcpu);
+	 *   - arch/x86/kvm/x86.c|10927| <<vcpu_enter_guest>> kvm_lapic_sync_from_vapic(vcpu);
+	 */
 	if (unlikely(vcpu->arch.apic_attention))
 		kvm_lapic_sync_from_vapic(vcpu);
 out:
@@ -10318,6 +11324,13 @@ static inline int vcpu_block(struct kvm *kvm, struct kvm_vcpu *vcpu)
 			return 1;
 	}
 
+	/*
+	 * 在以下使用kvm_apic_accept_events():
+	 *   - arch/x86/kvm/x86.c|10552| <<vcpu_enter_guest>> r = kvm_apic_accept_events(vcpu);
+	 *   - arch/x86/kvm/x86.c|10877| <<vcpu_block>> if (kvm_apic_accept_events(vcpu) < 0)
+	 *   - arch/x86/kvm/x86.c|11077| <<kvm_arch_vcpu_ioctl_run>> if (kvm_apic_accept_events(vcpu) < 0) {
+	 *   - arch/x86/kvm/x86.c|11313| <<kvm_arch_vcpu_ioctl_get_mpstate>> r = kvm_apic_accept_events(vcpu);
+	 */
 	if (kvm_apic_accept_events(vcpu) < 0)
 		return 0;
 	switch(vcpu->arch.mp_state) {
@@ -10518,6 +11531,13 @@ int kvm_arch_vcpu_ioctl_run(struct kvm_vcpu *vcpu)
 		 */
 		WARN_ON_ONCE(kvm_lapic_hv_timer_in_use(vcpu));
 		kvm_vcpu_block(vcpu);
+		/*
+		 * 在以下使用kvm_apic_accept_events():
+		 *   - arch/x86/kvm/x86.c|10552| <<vcpu_enter_guest>> r = kvm_apic_accept_events(vcpu);
+		 *   - arch/x86/kvm/x86.c|10877| <<vcpu_block>> if (kvm_apic_accept_events(vcpu) < 0)
+		 *   - arch/x86/kvm/x86.c|11077| <<kvm_arch_vcpu_ioctl_run>> if (kvm_apic_accept_events(vcpu) < 0) {
+		 *   - arch/x86/kvm/x86.c|11313| <<kvm_arch_vcpu_ioctl_get_mpstate>> r = kvm_apic_accept_events(vcpu);
+		 */
 		if (kvm_apic_accept_events(vcpu) < 0) {
 			r = 0;
 			goto out;
@@ -10754,6 +11774,13 @@ int kvm_arch_vcpu_ioctl_get_mpstate(struct kvm_vcpu *vcpu,
 	if (kvm_mpx_supported())
 		kvm_load_guest_fpu(vcpu);
 
+	/*
+	 * 在以下使用kvm_apic_accept_events():
+	 *   - arch/x86/kvm/x86.c|10552| <<vcpu_enter_guest>> r = kvm_apic_accept_events(vcpu);
+	 *   - arch/x86/kvm/x86.c|10877| <<vcpu_block>> if (kvm_apic_accept_events(vcpu) < 0)
+	 *   - arch/x86/kvm/x86.c|11077| <<kvm_arch_vcpu_ioctl_run>> if (kvm_apic_accept_events(vcpu) < 0) {
+	 *   - arch/x86/kvm/x86.c|11313| <<kvm_arch_vcpu_ioctl_get_mpstate>> r = kvm_apic_accept_events(vcpu);
+	 */
 	r = kvm_apic_accept_events(vcpu);
 	if (r < 0)
 		goto out;
@@ -10807,6 +11834,13 @@ int kvm_arch_vcpu_ioctl_set_mpstate(struct kvm_vcpu *vcpu,
 	return ret;
 }
 
+/*
+ * 在以下使用kvm_task_switch():
+ *   - arch/x86/kvm/svm/svm.c|2574| <<task_switch_interception>> return kvm_task_switch(vcpu,
+ *                  tss_selector, int_vec, reason, has_error_code, error_code);
+ *   - arch/x86/kvm/vmx/vmx.c|5468| <<handle_task_switch>> return kvm_task_switch(vcpu,
+ *                  tss_selector, type == INTR_TYPE_SOFT_INTR ? idt_index : -1, reason, has_error_code, error_code);
+ */
 int kvm_task_switch(struct kvm_vcpu *vcpu, u16 tss_selector, int idt_index,
 		    int reason, bool has_error_code, u32 error_code)
 {
@@ -10855,6 +11889,11 @@ static bool kvm_is_valid_sregs(struct kvm_vcpu *vcpu, struct kvm_sregs *sregs)
 	       kvm_is_valid_cr0(vcpu, sregs->cr0);
 }
 
+/*
+ * 在以下调用__set_sregs_common():
+ *   - arch/x86/kvm/x86.c|11200| <<__set_sregs>> int ret = __set_sregs_common(vcpu, sregs, &mmu_reset_needed, true);
+ *   - arch/x86/kvm/x86.c|11234| <<__set_sregs2>> ret = __set_sregs_common(vcpu, (struct kvm_sregs *)sregs2,
+ */
 static int __set_sregs_common(struct kvm_vcpu *vcpu, struct kvm_sregs *sregs,
 		int *mmu_reset_needed, bool update_pdptrs)
 {
@@ -10927,6 +11966,11 @@ static int __set_sregs_common(struct kvm_vcpu *vcpu, struct kvm_sregs *sregs,
 	return 0;
 }
 
+/*
+ * 在以下调用__set_sregs():
+ *   - arch/x86/kvm/x86.c|11258| <<kvm_arch_vcpu_ioctl_set_sregs>> ret = __set_sregs(vcpu, sregs);
+ *   - arch/x86/kvm/x86.c|11438| <<sync_regs>> if (__set_sregs(vcpu, &vcpu->run->s.regs.sregs))
+ */
 static int __set_sregs(struct kvm_vcpu *vcpu, struct kvm_sregs *sregs)
 {
 	int pending_vec, max_bits;
@@ -10944,6 +11988,15 @@ static int __set_sregs(struct kvm_vcpu *vcpu, struct kvm_sregs *sregs)
 		(const unsigned long *)sregs->interrupt_bitmap, max_bits);
 
 	if (pending_vec < max_bits) {
+		/*
+		 * 在以下使用kvm_queue_interrupt():
+		 *   - arch/x86/kvm/svm/svm.c|4045| <<svm_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, false);
+		 *   - arch/x86/kvm/svm/svm.c|4048| <<svm_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, true);
+		 *   - arch/x86/kvm/vmx/vmx.c|6768| <<__vmx_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, type == INTR_TYPE_SOFT_INTR);
+		 *   - arch/x86/kvm/x86.c|4713| <<kvm_vcpu_ioctl_interrupt>> kvm_queue_interrupt(vcpu, irq->irq, false);
+		 *   - arch/x86/kvm/x86.c|9490| <<inject_pending_event>> kvm_queue_interrupt(vcpu, irq, false);
+		 *   - arch/x86/kvm/x86.c|11223| <<__set_sregs>> kvm_queue_interrupt(vcpu, pending_vec, false);
+		 */
 		kvm_queue_interrupt(vcpu, pending_vec, false);
 		pr_debug("Set back pending irq %d\n", pending_vec);
 		kvm_make_request(KVM_REQ_EVENT, vcpu);
@@ -10951,6 +12004,10 @@ static int __set_sregs(struct kvm_vcpu *vcpu, struct kvm_sregs *sregs)
 	return 0;
 }
 
+/*
+ * 在以下调用__set_sregs2():
+ *   - arch/x86/kvm/x86.c|5597| <<kvm_arch_vcpu_ioctl(KVM_SET_SREGS2)>> r = __set_sregs2(vcpu, u.sregs2);
+ */
 static int __set_sregs2(struct kvm_vcpu *vcpu, struct kvm_sregs2 *sregs2)
 {
 	int mmu_reset_needed = 0;
@@ -10983,6 +12040,10 @@ static int __set_sregs2(struct kvm_vcpu *vcpu, struct kvm_sregs2 *sregs2)
 	return 0;
 }
 
+/*
+ * 处理KVM_SET_SREGS:
+ *   - virt/kvm/kvm_main.c|4062| <<kvm_vcpu_ioctl(KVM_SET_SREGS)>> r = kvm_arch_vcpu_ioctl_set_sregs(vcpu, kvm_sregs);
+ */
 int kvm_arch_vcpu_ioctl_set_sregs(struct kvm_vcpu *vcpu,
 				  struct kvm_sregs *sregs)
 {
@@ -10994,6 +12055,10 @@ int kvm_arch_vcpu_ioctl_set_sregs(struct kvm_vcpu *vcpu,
 	return ret;
 }
 
+/*
+ * 在以下使用kvm_arch_vcpu_guestdbg_update_apicv_inhibit():
+ *   - arch/x86/kvm/x86.c|12068| <<kvm_arch_vcpu_ioctl_set_guest_debug>> kvm_arch_vcpu_guestdbg_update_apicv_inhibit(vcpu->kvm);
+ */
 static void kvm_arch_vcpu_guestdbg_update_apicv_inhibit(struct kvm *kvm)
 {
 	bool set = false;
@@ -11011,10 +12076,22 @@ static void kvm_arch_vcpu_guestdbg_update_apicv_inhibit(struct kvm *kvm)
 			break;
 		}
 	}
+	/*
+	 * 在以下调用__kvm_set_or_clear_apicv_inhibit():
+	 *   - arch/x86/kvm/hyperv.c|132| <<synic_update_vector>> __kvm_set_or_clear_apicv_inhibit(vcpu->kvm,
+	 *          APICV_INHIBIT_REASON_HYPERV, !!hv->synic_auto_eoi_used);
+	 *   - arch/x86/kvm/x86.c|10434| <<kvm_set_or_clear_apicv_inhibit>> __kvm_set_or_clear_apicv_inhibit(kvm, reason, set);
+	 *   - arch/x86/kvm/x86.c|12032| <<kvm_arch_vcpu_guestdbg_update_apicv_inhibit>> __kvm_set_or_clear_apicv_inhibit(kvm,
+	 *          APICV_INHIBIT_REASON_BLOCKIRQ, set);
+	 */
 	__kvm_set_or_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_BLOCKIRQ, set);
 	up_write(&kvm->arch.apicv_update_lock);
 }
 
+/*
+ * 在以下使用kvm_arch_vcpu_ioctl_set_guest_debug():
+ *   - virt/kvm/kvm_main.c|4122| <<kvm_vcpu_ioctl(KVM_SET_GUEST_DEBUG)>> r = kvm_arch_vcpu_ioctl_set_guest_debug(vcpu, &dbg);
+ */
 int kvm_arch_vcpu_ioctl_set_guest_debug(struct kvm_vcpu *vcpu,
 					struct kvm_guest_debug *dbg)
 {
@@ -11162,6 +12239,10 @@ static void store_regs(struct kvm_vcpu *vcpu)
 				vcpu, &vcpu->run->s.regs.events);
 }
 
+/*
+ * 在以下调用sync_regs():
+ *   - arch/x86/kvm/x86.c|10808| <<kvm_arch_vcpu_ioctl_run>> r = sync_regs(vcpu); 
+ */
 static int sync_regs(struct kvm_vcpu *vcpu)
 {
 	if (vcpu->run->kvm_dirty_regs & KVM_SYNC_X86_REGS) {
@@ -11232,6 +12313,17 @@ int kvm_arch_vcpu_create(struct kvm_vcpu *vcpu)
 		 */
 		if (enable_apicv) {
 			vcpu->arch.apicv_active = true;
+			/*
+			 * 在以下使用KVM_REQ_APICV_UPDATE:
+			 *   - arch/x86/kvm/svm/nested.c|729| <<enter_svm_guest_mode>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+			 *   - arch/x86/kvm/svm/nested.c|1111| <<svm_leave_nested>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+			 *   - arch/x86/kvm/vmx/nested.c|4696| <<nested_vmx_vmexit>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+			 *   - arch/x86/kvm/x86.c|10189| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_APICV_UPDATE, vcpu))
+			 *   - arch/x86/kvm/x86.c|11394| <<kvm_arch_vcpu_create>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+			 *
+			 * 处理的函数:
+			 * kvm_vcpu_update_apicv(vcpu);
+			 */
 			kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
 		}
 	} else
@@ -11355,6 +12447,45 @@ void kvm_arch_vcpu_destroy(struct kvm_vcpu *vcpu)
 		static_branch_dec(&kvm_has_noapic_vcpu);
 }
 
+/*
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_vcpu_reset
+ * kvm_apic_accept_events
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_lapic_reg_write
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ *
+ * 在以下使用:
+ *   - arch/x86/kvm/lapic.c|3537| <<kvm_apic_accept_events>> kvm_vcpu_reset(vcpu, true);
+ *   - arch/x86/kvm/svm/svm.c|2230| <<shutdown_interception>> kvm_vcpu_reset(vcpu, true);
+ *   - arch/x86/kvm/x86.c|11655| <<kvm_arch_vcpu_create>> kvm_vcpu_reset(vcpu, false);
+ *
+ * 只在VM里面online/offline也会调用kvm_vcpu_reset()
+ * online的时候调用
+ */
 void kvm_vcpu_reset(struct kvm_vcpu *vcpu, bool init_event)
 {
 	unsigned long old_cr0 = kvm_read_cr0(vcpu);
@@ -11370,6 +12501,19 @@ void kvm_vcpu_reset(struct kvm_vcpu *vcpu, bool init_event)
 	if (is_guest_mode(vcpu))
 		kvm_leave_nested(vcpu);
 
+	/*
+	 * __kvm_set_or_clear_apicv_inhibit
+	 * __kvm_set_or_clear_apicv_inhibit
+	 * kvm_set_or_clear_apicv_inhibit
+	 * kvm_recalculate_apic_map
+	 * kvm_vcpu_reset
+	 * kvm_apic_accept_events
+	 * kvm_arch_vcpu_ioctl_run
+	 * kvm_vcpu_ioctl
+	 * __x64_sys_ioctl
+	 * do_syscall_64
+	 * entry_SYSCALL_64_after_hwframe
+	 */
 	kvm_lapic_reset(vcpu, init_event);
 
 	WARN_ON_ONCE(is_guest_mode(vcpu) || is_smm(vcpu));
@@ -11377,9 +12521,26 @@ void kvm_vcpu_reset(struct kvm_vcpu *vcpu, bool init_event)
 
 	vcpu->arch.smi_pending = 0;
 	vcpu->arch.smi_count = 0;
+	/*
+	 * 在以下使用kvm_vcpu_arch->nmi_queued:
+	 *   - arch/x86/kvm/x86.c|874| <<kvm_inject_nmi>> atomic_inc(&vcpu->arch.nmi_queued);
+	 *   - arch/x86/kvm/x86.c|5158| <<kvm_vcpu_ioctl_x86_set_vcpu_events>> atomic_set(&vcpu->arch.nmi_queued, events->nmi.pending);
+	 *   - arch/x86/kvm/x86.c|9855| <<process_nmi>> vcpu->arch.nmi_pending += atomic_xchg(&vcpu->arch.nmi_queued, 0);
+	 *   - arch/x86/kvm/x86.c|12376| <<kvm_vcpu_reset>> atomic_set(&vcpu->arch.nmi_queued, 0);
+	 */
 	atomic_set(&vcpu->arch.nmi_queued, 0);
 	vcpu->arch.nmi_pending = 0;
 	vcpu->arch.nmi_injected = false;
+	/*
+	 * 在以下调用kvm_clear_interrupt_queue():
+	 *   - arch/x86/kvm/svm/nested.c|1017| <<nested_svm_vmexit>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/svm/svm.c|2556| <<task_switch_interception>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/svm/svm.c|4012| <<svm_complete_interrupts>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/vmx/nested.c|4645| <<nested_vmx_vmexit>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|5440| <<handle_task_switch>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|6799| <<__vmx_complete_interrupts>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/x86.c|11947| <<kvm_vcpu_reset>> kvm_clear_interrupt_queue(vcpu);
+	 */
 	kvm_clear_interrupt_queue(vcpu);
 	kvm_clear_exception_queue(vcpu);
 
@@ -11715,6 +12876,12 @@ int kvm_arch_init_vm(struct kvm *kvm, unsigned long type)
 	if (ret)
 		return ret;
 
+	/*
+	 * 在以下使用kvm_arch->mask_notifier_list:
+	 *   - arch/x86/kvm/irq_comm.c|234| <<kvm_register_irq_mask_notifier>> hlist_add_head_rcu(&kimn->link, &kvm->arch.mask_notifier_list);
+	 *   - arch/x86/kvm/irq_comm.c|256| <<kvm_fire_mask_notifiers>> hlist_for_each_entry_rcu(kimn, &kvm->arch.mask_notifier_list, link)
+	 *   - arch/x86/kvm/x86.c|11763| <<kvm_arch_init_vm>> INIT_HLIST_HEAD(&kvm->arch.mask_notifier_list);
+	 */
 	INIT_HLIST_HEAD(&kvm->arch.mask_notifier_list);
 	INIT_LIST_HEAD(&kvm->arch.active_mmu_pages);
 	INIT_LIST_HEAD(&kvm->arch.zapped_obsolete_pages);
@@ -11722,6 +12889,13 @@ int kvm_arch_init_vm(struct kvm *kvm, unsigned long type)
 	INIT_LIST_HEAD(&kvm->arch.assigned_dev_head);
 	atomic_set(&kvm->arch.noncoherent_dma_count, 0);
 
+	/*
+	 * 在以下使用kvm_arch->irq_sources_bitmap:
+	 *   - arch/x86/kvm/irq_comm.c|187| <<kvm_request_irq_source_id>> unsigned long *bitmap = &kvm->arch.irq_sources_bitmap;
+	 *   - arch/x86/kvm/irq_comm.c|219| <<kvm_free_irq_source_id>> clear_bit(irq_source_id, &kvm->arch.irq_sources_bitmap);
+	 *   - arch/x86/kvm/x86.c|11732| <<kvm_arch_init_vm>> set_bit(KVM_USERSPACE_IRQ_SOURCE_ID, &kvm->arch.irq_sources_bitmap);
+	 *   - arch/x86/kvm/x86.c|11735| <<kvm_arch_init_vm>> set_bit(KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID, &kvm->arch.irq_sources_bitmap);
+	 */
 	/* Reserve bit 0 of irq_sources_bitmap for userspace irq source */
 	set_bit(KVM_USERSPACE_IRQ_SOURCE_ID, &kvm->arch.irq_sources_bitmap);
 	/* Reserve bit 1 of irq_sources_bitmap for irqfd-resampler */
@@ -11729,6 +12903,15 @@ int kvm_arch_init_vm(struct kvm *kvm, unsigned long type)
 		&kvm->arch.irq_sources_bitmap);
 
 	raw_spin_lock_init(&kvm->arch.tsc_write_lock);
+	/*
+	 * 在以下使用kvm_arch->apic_map_lock:
+	 *   - arch/x86/kvm/lapic.c|375| <<kvm_recalculate_apic_map>> mutex_lock(&kvm->arch.apic_map_lock);
+	 *   - arch/x86/kvm/lapic.c|383| <<kvm_recalculate_apic_map>> mutex_unlock(&kvm->arch.apic_map_lock);
+	 *   - arch/x86/kvm/lapic.c|506| <<kvm_recalculate_apic_map>> old = rcu_dereference_protected(kvm->arch.apic_map,
+	 *                                     lockdep_is_held(&kvm->arch.apic_map_lock));
+	 *   - arch/x86/kvm/lapic.c|514| <<kvm_recalculate_apic_map>> mutex_unlock(&kvm->arch.apic_map_lock);
+	 *   - arch/x86/kvm/x86.c|12397| <<kvm_arch_init_vm>> mutex_init(&kvm->arch.apic_map_lock);
+	 */
 	mutex_init(&kvm->arch.apic_map_lock);
 	raw_spin_lock_init(&kvm->arch.pvclock_gtod_sync_lock);
 
@@ -11896,6 +13079,17 @@ void kvm_arch_destroy_vm(struct kvm *kvm)
 	kvm_pic_destroy(kvm);
 	kvm_ioapic_destroy(kvm);
 	kvm_free_vcpus(kvm);
+	/*
+	 * 在以下使用kvm_arch->apic_map:
+	 *   - arch/x86/kvm/lapic.c|581| <<kvm_recalculate_apic_map>> old = rcu_dereference_protected(kvm->arch.apic_map,
+	 *   - arch/x86/kvm/lapic.c|583| <<kvm_recalculate_apic_map>> rcu_assign_pointer(kvm->arch.apic_map, new);
+	 *   - arch/x86/kvm/lapic.c|1305| <<kvm_pv_send_ipi>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1772| <<kvm_irq_delivery_to_apic_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1825| <<kvm_intr_is_single_vcpu_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|2023| <<kvm_bitmap_or_dest_vcpus>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|9391| <<kvm_sched_yield>> map = rcu_dereference(vcpu->kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|13061| <<kvm_arch_destroy_vm>> kvfree(rcu_dereference_check(kvm->arch.apic_map, 1));
+	 */
 	kvfree(rcu_dereference_check(kvm->arch.apic_map, 1));
 	kfree(srcu_dereference_check(kvm->arch.pmu_event_filter, &kvm->srcu, 1));
 	kvm_mmu_uninit_vm(kvm);
@@ -12219,6 +13413,10 @@ static inline bool kvm_guest_apic_has_interrupt(struct kvm_vcpu *vcpu)
 		static_call(kvm_x86_guest_apic_has_interrupt)(vcpu));
 }
 
+/*
+ * 在以下使用kvm_vcpu_has_events():
+ *   - arch/x86/kvm/x86.c|12810| <<kvm_arch_vcpu_runnable>> return kvm_vcpu_running(vcpu) || kvm_vcpu_has_events(vcpu);
+ */
 static inline bool kvm_vcpu_has_events(struct kvm_vcpu *vcpu)
 {
 	if (!list_empty_careful(&vcpu->async_pf.done))
@@ -12233,6 +13431,12 @@ static inline bool kvm_vcpu_has_events(struct kvm_vcpu *vcpu)
 	if (vcpu->arch.exception.pending)
 		return true;
 
+	/*
+	 * 在以下使用kvm_x86_nmi_allowed():
+	 *   - arch/x86/kvm/x86.c|9727| <<inject_pending_event>> r = can_inject ? static_call(kvm_x86_nmi_allowed)(vcpu, true) : -EBUSY;
+	 *   - arch/x86/kvm/x86.c|9735| <<inject_pending_event>> WARN_ON(static_call(kvm_x86_nmi_allowed)(vcpu, true) < 0);
+	 *   - arch/x86/kvm/x86.c|13270| <<kvm_vcpu_has_events>> static_call(kvm_x86_nmi_allowed)(vcpu, false)))
+	 */
 	if (kvm_test_request(KVM_REQ_NMI, vcpu) ||
 	    (vcpu->arch.nmi_pending &&
 	     static_call(kvm_x86_nmi_allowed)(vcpu, false)))
@@ -12300,6 +13504,12 @@ int kvm_arch_vcpu_should_kick(struct kvm_vcpu *vcpu)
 
 int kvm_arch_interrupt_allowed(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下调用kvm_x86_interrupt_allowed():
+	 *   - arch/x86/kvm/x86.c|9719| <<inject_pending_event>> r = can_inject ? static_call(kvm_x86_interrupt_allowed)(vcpu, true) : -EBUSY;
+	 *   - arch/x86/kvm/x86.c|9749| <<inject_pending_event>> WARN_ON(static_call(kvm_x86_interrupt_allowed)(vcpu, true) < 0);
+	 *   - arch/x86/kvm/x86.c|13272| <<kvm_arch_interrupt_allowed>> return static_call(kvm_x86_interrupt_allowed)(vcpu, false);
+	 */
 	return static_call(kvm_x86_interrupt_allowed)(vcpu, false);
 }
 
@@ -12541,6 +13751,17 @@ void kvm_arch_async_page_present(struct kvm_vcpu *vcpu,
 	    kvm_pv_async_pf_enabled(vcpu) &&
 	    !apf_put_user_ready(vcpu, work->arch.token)) {
 		vcpu->arch.apf.pageready_pending = true;
+		/*
+		 * 在以下使用kvm_apic_set_irq():
+		 *   - arch/x86/kvm/hyperv.c|828| <<stimer_notify_direct>> return !kvm_apic_set_irq(vcpu, &irq, NULL);
+		 *   - arch/x86/kvm/hyperv.c|1899| <<kvm_send_ipi_to_many>> kvm_apic_set_irq(vcpu, &irq, NULL);
+		 *   - arch/x86/kvm/irq_comm.c|94| <<kvm_irq_delivery_to_apic>> r += kvm_apic_set_irq(vcpu, irq, dest_map);
+		 *   - arch/x86/kvm/irq_comm.c|125| <<kvm_irq_delivery_to_apic>> r = kvm_apic_set_irq(lowest, irq, dest_map);
+		 *   - arch/x86/kvm/lapic.c|1218| <<__pv_send_ipi>> count += kvm_apic_set_irq(vcpu, irq, NULL);
+		 *   - arch/x86/kvm/lapic.c|1699| <<kvm_irq_delivery_to_apic_fast>> *r = kvm_apic_set_irq(src->vcpu, irq, dest_map);
+		 *   - arch/x86/kvm/lapic.c|1712| <<kvm_irq_delivery_to_apic_fast>> *r += kvm_apic_set_irq(dst[i]->vcpu, irq, dest_map);
+		 *   - arch/x86/kvm/x86.c|13639| <<kvm_arch_async_page_present>> kvm_apic_set_irq(vcpu, &irq, NULL);
+		 */
 		kvm_apic_set_irq(vcpu, &irq, NULL);
 	}
 
@@ -12550,6 +13771,14 @@ void kvm_arch_async_page_present(struct kvm_vcpu *vcpu,
 
 void kvm_arch_async_page_present_queued(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用KVM_REQ_APF_READY:
+	 *   - arch/x86/kvm/lapic.c|621| <<apic_set_spiv>> kvm_make_request(KVM_REQ_APF_READY, apic->vcpu);
+	 *   - arch/x86/kvm/lapic.c|3303| <<kvm_lapic_set_base>> kvm_make_request(KVM_REQ_APF_READY, vcpu);
+	 *   - arch/x86/kvm/x86.c|13246| <<kvm_arch_async_page_present_queued>> kvm_make_request(KVM_REQ_APF_READY, vcpu);
+	 *
+	 * 处理的函数kvm_check_async_pf_completion()
+	 */
 	kvm_make_request(KVM_REQ_APF_READY, vcpu);
 	if (!vcpu->arch.apf.pageready_pending)
 		kvm_vcpu_kick(vcpu);
diff --git a/arch/x86/kvm/x86.h b/arch/x86/kvm/x86.h
index f7854e742e8c..bd3d9584915b 100644
--- a/arch/x86/kvm/x86.h
+++ b/arch/x86/kvm/x86.h
@@ -112,6 +112,15 @@ static inline void kvm_clear_exception_queue(struct kvm_vcpu *vcpu)
 	vcpu->arch.exception.injected = false;
 }
 
+/*
+ * 在以下使用kvm_queue_interrupt():
+ *   - arch/x86/kvm/svm/svm.c|4045| <<svm_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, false);
+ *   - arch/x86/kvm/svm/svm.c|4048| <<svm_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, true);
+ *   - arch/x86/kvm/vmx/vmx.c|6768| <<__vmx_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, type == INTR_TYPE_SOFT_INTR);
+ *   - arch/x86/kvm/x86.c|4713| <<kvm_vcpu_ioctl_interrupt>> kvm_queue_interrupt(vcpu, irq->irq, false);
+ *   - arch/x86/kvm/x86.c|9490| <<inject_pending_event>> kvm_queue_interrupt(vcpu, irq, false);
+ *   - arch/x86/kvm/x86.c|11223| <<__set_sregs>> kvm_queue_interrupt(vcpu, pending_vec, false);
+ */
 static inline void kvm_queue_interrupt(struct kvm_vcpu *vcpu, u8 vector,
 	bool soft)
 {
@@ -120,11 +129,29 @@ static inline void kvm_queue_interrupt(struct kvm_vcpu *vcpu, u8 vector,
 	vcpu->arch.interrupt.nr = vector;
 }
 
+/*
+ * 在以下调用kvm_clear_interrupt_queue():
+ *   - arch/x86/kvm/svm/nested.c|1017| <<nested_svm_vmexit>> kvm_clear_interrupt_queue(vcpu);
+ *   - arch/x86/kvm/svm/svm.c|2556| <<task_switch_interception>> kvm_clear_interrupt_queue(vcpu);
+ *   - arch/x86/kvm/svm/svm.c|4012| <<svm_complete_interrupts>> kvm_clear_interrupt_queue(vcpu);
+ *   - arch/x86/kvm/vmx/nested.c|4645| <<nested_vmx_vmexit>> kvm_clear_interrupt_queue(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|5440| <<handle_task_switch>> kvm_clear_interrupt_queue(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|6799| <<__vmx_complete_interrupts>> kvm_clear_interrupt_queue(vcpu);
+ *   - arch/x86/kvm/x86.c|11947| <<kvm_vcpu_reset>> kvm_clear_interrupt_queue(vcpu);
+ */
 static inline void kvm_clear_interrupt_queue(struct kvm_vcpu *vcpu)
 {
 	vcpu->arch.interrupt.injected = false;
 }
 
+/*
+ * 在以下使用kvm_event_needs_reinjection():
+ *   - arch/x86/kvm/mmu/mmu.c|4031| <<kvm_handle_page_fault>> if (kvm_event_needs_reinjection(vcpu))
+ *   - arch/x86/kvm/svm/nested.c|1288| <<svm_check_nested_events>> kvm_event_needs_reinjection(vcpu) || svm->nested.nested_run_pending;
+ *   - arch/x86/kvm/vmx/nested.c|3921| <<vmx_check_nested_events>> vmx->nested.nested_run_pending || kvm_event_needs_reinjection(vcpu);
+ *   - arch/x86/kvm/x86.c|4785| <<kvm_vcpu_ready_for_interrupt_injection>> !kvm_event_needs_reinjection(vcpu) &&
+ *   - arch/x86/kvm/x86.c|13061| <<kvm_can_do_async_pf>> kvm_event_needs_reinjection(vcpu) ||
+ */
 static inline bool kvm_event_needs_reinjection(struct kvm_vcpu *vcpu)
 {
 	return vcpu->arch.exception.injected || vcpu->arch.interrupt.injected ||
@@ -391,6 +418,12 @@ static inline bool kvm_cstate_in_guest(struct kvm *kvm)
 
 DECLARE_PER_CPU(struct kvm_vcpu *, current_vcpu);
 
+/*
+ * 在以下使用kvm_before_interrupt():
+ *   - arch/x86/kvm/svm/svm.c|4206| <<svm_vcpu_run>> kvm_before_interrupt(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|6920| <<handle_interrupt_nmi_irqoff>> kvm_before_interrupt(vcpu);
+ *   - arch/x86/kvm/x86.c|11036| <<vcpu_enter_guest>> kvm_before_interrupt(vcpu);
+ */
 static inline void kvm_before_interrupt(struct kvm_vcpu *vcpu)
 {
 	__this_cpu_write(current_vcpu, vcpu);
diff --git a/drivers/acpi/acpica/dbexec.c b/drivers/acpi/acpica/dbexec.c
index d3a9521e2dc8..78134e2119ff 100644
--- a/drivers/acpi/acpica/dbexec.c
+++ b/drivers/acpi/acpica/dbexec.c
@@ -692,6 +692,26 @@ acpi_db_create_execution_thread(char *method_name_arg,
 		return;
 	}
 
+	/*
+	 * 在以下调用acpi_os_execute():
+	 *   - drivers/acpi/acpica/dbexec.c|695| <<acpi_db_create_execution_thread>> status = acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+	 *            acpi_db_single_execution_thread, &acpi_gbl_db_method_info);
+	 *   - drivers/acpi/acpica/dbexec.c|849| <<acpi_db_create_execution_threads>> acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+	 *            acpi_db_method_thread, &acpi_gbl_db_method_info);
+	 *   - drivers/acpi/acpica/dbxface.c|448| <<acpi_initialize_debugger>> status = acpi_os_execute(OSL_DEBUGGER_MAIN_THREAD,
+	 *            acpi_db_execute_thread, NULL);
+	 *   - drivers/acpi/acpica/evgpe.c|526| <<acpi_ev_asynch_execute_gpe_method>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_ev_asynch_enable_gpe, gpe_event_info);
+	 *   - drivers/acpi/acpica/evgpe.c|823| <<acpi_ev_gpe_dispatch>> status = acpi_os_execute(OSL_GPE_HANDLER,
+	 *            acpi_ev_asynch_execute_gpe_method, gpe_event_info);
+	 *   - drivers/acpi/acpica/evmisc.c|139| <<acpi_ev_queue_notify_request>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_ev_notify_dispatch, info);
+	 *   - drivers/acpi/bus.c|539| <<acpi_device_fixed_event>> acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_notify_device_fixed, data);
+	 *   - drivers/acpi/sbshc.c|232| <<smbus_alarm>> acpi_os_execute(OSL_NOTIFY_HANDLER, acpi_smbus_callback, hc);
+	 *   - drivers/platform/x86/dell/dell-rbtn.c|278| <<rbtn_resume>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            rbtn_clear_suspended_flag, rbtn_data);
+	 */
 	status = acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
 				 acpi_db_single_execution_thread,
 				 &acpi_gbl_db_method_info);
@@ -845,6 +865,26 @@ acpi_db_create_execution_threads(char *num_threads_arg,
 		       num_threads, num_loops);
 
 	for (i = 0; i < (num_threads); i++) {
+		/*
+		 * 在以下调用acpi_os_execute():
+		 *   - drivers/acpi/acpica/dbexec.c|695| <<acpi_db_create_execution_thread>> status = acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+		 *            acpi_db_single_execution_thread, &acpi_gbl_db_method_info);
+		 *   - drivers/acpi/acpica/dbexec.c|849| <<acpi_db_create_execution_threads>> acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+		 *            acpi_db_method_thread, &acpi_gbl_db_method_info);
+		 *   - drivers/acpi/acpica/dbxface.c|448| <<acpi_initialize_debugger>> status = acpi_os_execute(OSL_DEBUGGER_MAIN_THREAD,
+		 *            acpi_db_execute_thread, NULL);
+		 *   - drivers/acpi/acpica/evgpe.c|526| <<acpi_ev_asynch_execute_gpe_method>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            acpi_ev_asynch_enable_gpe, gpe_event_info);
+		 *   - drivers/acpi/acpica/evgpe.c|823| <<acpi_ev_gpe_dispatch>> status = acpi_os_execute(OSL_GPE_HANDLER,
+		 *            acpi_ev_asynch_execute_gpe_method, gpe_event_info);
+		 *   - drivers/acpi/acpica/evmisc.c|139| <<acpi_ev_queue_notify_request>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            acpi_ev_notify_dispatch, info);
+		 *   - drivers/acpi/bus.c|539| <<acpi_device_fixed_event>> acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            acpi_notify_device_fixed, data);
+		 *   - drivers/acpi/sbshc.c|232| <<smbus_alarm>> acpi_os_execute(OSL_NOTIFY_HANDLER, acpi_smbus_callback, hc);
+		 *   - drivers/platform/x86/dell/dell-rbtn.c|278| <<rbtn_resume>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            rbtn_clear_suspended_flag, rbtn_data);
+		 */
 		status =
 		    acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
 				    acpi_db_method_thread,
diff --git a/drivers/acpi/acpica/dbxface.c b/drivers/acpi/acpica/dbxface.c
index 9dfd693cda3e..ac899207a957 100644
--- a/drivers/acpi/acpica/dbxface.c
+++ b/drivers/acpi/acpica/dbxface.c
@@ -445,6 +445,26 @@ acpi_status acpi_initialize_debugger(void)
 		/* Create the debug execution thread to execute commands */
 
 		acpi_gbl_db_threads_terminated = FALSE;
+		/*
+		 * 在以下调用acpi_os_execute():
+		 *   - drivers/acpi/acpica/dbexec.c|695| <<acpi_db_create_execution_thread>> status = acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+		 *            acpi_db_single_execution_thread, &acpi_gbl_db_method_info);
+		 *   - drivers/acpi/acpica/dbexec.c|849| <<acpi_db_create_execution_threads>> acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+		 *            acpi_db_method_thread, &acpi_gbl_db_method_info);
+		 *   - drivers/acpi/acpica/dbxface.c|448| <<acpi_initialize_debugger>> status = acpi_os_execute(OSL_DEBUGGER_MAIN_THREAD,
+		 *            acpi_db_execute_thread, NULL);
+		 *   - drivers/acpi/acpica/evgpe.c|526| <<acpi_ev_asynch_execute_gpe_method>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            acpi_ev_asynch_enable_gpe, gpe_event_info);
+		 *   - drivers/acpi/acpica/evgpe.c|823| <<acpi_ev_gpe_dispatch>> status = acpi_os_execute(OSL_GPE_HANDLER,
+		 *            acpi_ev_asynch_execute_gpe_method, gpe_event_info);
+		 *   - drivers/acpi/acpica/evmisc.c|139| <<acpi_ev_queue_notify_request>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            acpi_ev_notify_dispatch, info);
+		 *   - drivers/acpi/bus.c|539| <<acpi_device_fixed_event>> acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            acpi_notify_device_fixed, data);
+		 *   - drivers/acpi/sbshc.c|232| <<smbus_alarm>> acpi_os_execute(OSL_NOTIFY_HANDLER, acpi_smbus_callback, hc);
+		 *   - drivers/platform/x86/dell/dell-rbtn.c|278| <<rbtn_resume>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            rbtn_clear_suspended_flag, rbtn_data);
+		 */
 		status = acpi_os_execute(OSL_DEBUGGER_MAIN_THREAD,
 					 acpi_db_execute_thread, NULL);
 		if (ACPI_FAILURE(status)) {
diff --git a/drivers/acpi/acpica/dswexec.c b/drivers/acpi/acpica/dswexec.c
index f2d2267054af..793d3c1a9c15 100644
--- a/drivers/acpi/acpica/dswexec.c
+++ b/drivers/acpi/acpica/dswexec.c
@@ -26,6 +26,10 @@ ACPI_MODULE_NAME("dswexec")
 /*
  * Dispatch table for opcode classes
  */
+/*
+ * 在以下使用acpi_gbl_op_type_dispatch[]:
+ *   - drivers/acpi/acpica/dswexec.c|453| <<acpi_ds_exec_end_op>> acpi_gbl_op_type_dispatch[op_type] (walk_state);
+ */
 static acpi_execute_op acpi_gbl_op_type_dispatch[] = {
 	acpi_ex_opcode_0A_0T_1R,
 	acpi_ex_opcode_1A_0T_0R,
@@ -324,6 +328,48 @@ acpi_ds_exec_begin_op(struct acpi_walk_state *walk_state,
  *
  ****************************************************************************/
 
+/*
+ * hotplug pci的时候调用三次.
+ *                      
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq         
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt     
+ *                            
+ * [0] acpi_os_execute       
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op  
+ * [0] acpi_ps_parse_loop   
+ * [0] acpi_ps_parse_aml        
+ * [0] acpi_ps_execute_method   
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work         
+ * [0] worker_thread            
+ * [0] kthread                      
+ * [0] ret_from_fork                                            
+ *                                                              
+ * [0] acpi_os_execute          
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred         
+ * [0] process_one_work                         
+ * [0] worker_thread                                            
+ * [0] kthread                          
+ * [0] ret_from_fork 
+ *
+ * 在以下使用acpi_ds_exec_end_op():
+ *   - drivers/acpi/acpica/dswload.c|78| <<acpi_ds_init_callbacks>> walk_state->ascending_callback = acpi_ds_exec_end_op;
+ *
+ * acpi_ex_opcode_2A_0T_0R()
+ */
 acpi_status acpi_ds_exec_end_op(struct acpi_walk_state *walk_state)
 {
 	union acpi_parse_object *op;
@@ -409,6 +455,10 @@ acpi_status acpi_ds_exec_end_op(struct acpi_walk_state *walk_state)
 			 * routine. There is one routine per opcode "type" based upon the
 			 * number of opcode arguments and return type.
 			 */
+			/*
+			 * 这里!!!!
+			 * acpi_ex_opcode_2A_0T_0R()
+			 */
 			status =
 			    acpi_gbl_op_type_dispatch[op_type] (walk_state);
 		} else {
diff --git a/drivers/acpi/acpica/evgpe.c b/drivers/acpi/acpica/evgpe.c
index c5a06882bdf6..c29c04c4bfb8 100644
--- a/drivers/acpi/acpica/evgpe.c
+++ b/drivers/acpi/acpica/evgpe.c
@@ -330,6 +330,43 @@ struct acpi_gpe_event_info *acpi_ev_get_gpe_event_info(acpi_handle gpe_device,
 		(gpe_number, obj_desc->device.gpe_block));
 }
 
+/*
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ */
 /*******************************************************************************
  *
  * FUNCTION:    acpi_ev_gpe_detect
@@ -373,14 +410,26 @@ u32 acpi_ev_gpe_detect(struct acpi_gpe_xrupt_info *gpe_xrupt_list)
 
 	/* Examine all GPE blocks attached to this interrupt level */
 
+	/*
+	 * struct acpi_gpe_block_info *gpe_block;
+	 */
 	gpe_block = gpe_xrupt_list->gpe_block_list_head;
 	while (gpe_block) {
+		/*
+		 * 这个while循环就一个block,
+		 * gpe_device->name.ascii = "_GPE".
+		 *
+		 * struct acpi_namespace_node *gpe_device;
+		 */
 		gpe_device = gpe_block->node;
 
 		/*
 		 * Read all of the 8-bit GPE status and enable registers in this GPE
 		 * block, saving all of them. Find all currently active GP events.
 		 */
+		/*
+		 * hot-add测试register_count也是8个
+		 */
 		for (i = 0; i < gpe_block->register_count; i++) {
 
 			/* Get the next status/enable pair */
@@ -391,6 +440,9 @@ u32 acpi_ev_gpe_detect(struct acpi_gpe_xrupt_info *gpe_xrupt_list)
 			 * Optimization: If there are no GPEs enabled within this
 			 * register, we can safely ignore the entire register.
 			 */
+			/*
+			 * 只有0的能跳过这里
+			 */
 			if (!(gpe_register_info->enable_for_run |
 			      gpe_register_info->enable_for_wake)) {
 				ACPI_DEBUG_PRINT((ACPI_DB_INTERRUPTS,
@@ -410,10 +462,24 @@ u32 acpi_ev_gpe_detect(struct acpi_gpe_xrupt_info *gpe_xrupt_list)
 
 			/* Now look at the individual GPEs in this byte register */
 
+			/*
+			 * 8个
+			 */
 			for (j = 0; j < ACPI_GPE_REGISTER_WIDTH; j++) {
 
 				/* Detect and dispatch one GPE bit */
 
+				/*
+				 * gpe_block都链接在gpe_block_list_head
+				 *
+				 * struct acpi_gpe_block_info *gpe_block;
+				 * -> struct acpi_namespace_node *node; (gpe_device->name.ascii = "_GPE".)
+				 * -> struct acpi_gpe_register_info *register_info;
+				 * -> struct acpi_gpe_event_info *event_info;
+				 *
+				 *
+				 * struct acpi_gpe_event_info *gpe_event_info;
+				 */
 				gpe_event_info =
 				    &gpe_block->
 				    event_info[((acpi_size)i *
@@ -421,6 +487,13 @@ u32 acpi_ev_gpe_detect(struct acpi_gpe_xrupt_info *gpe_xrupt_list)
 				gpe_number =
 				    j + gpe_register_info->base_gpe_number;
 				acpi_os_release_lock(acpi_gbl_gpe_lock, flags);
+				/*
+				 * 在以下调用acpi_ev_detect_gpe():
+				 *   - drivers/acpi/acpica/evgpe.c|471| <<acpi_ev_gpe_detect>> acpi_ev_detect_gpe(gpe_device, gpe_event_info, gpe_number);
+				 *   - drivers/acpi/acpica/evxface.c|980| <<acpi_remove_gpe_handler>> (void )acpi_ev_detect_gpe(gpe_device, gpe_event_info, gpe_number);
+				 *   - drivers/acpi/acpica/evxfgpe.c|118| <<acpi_enable_gpe>> (void )acpi_ev_detect_gpe(gpe_device, gpe_event_info, gpe_number);
+				 *   - drivers/acpi/acpica/evxfgpe.c|657| <<acpi_dispatch_gpe>> return acpi_ev_detect_gpe(gpe_device, NULL, gpe_number);
+				 */
 				int_status |=
 				    acpi_ev_detect_gpe(gpe_device,
 						       gpe_event_info,
@@ -429,6 +502,9 @@ u32 acpi_ev_gpe_detect(struct acpi_gpe_xrupt_info *gpe_xrupt_list)
 			}
 		}
 
+		/*
+		 * 选择下一个
+		 */
 		gpe_block = gpe_block->next;
 	}
 
@@ -452,6 +528,64 @@ u32 acpi_ev_gpe_detect(struct acpi_gpe_xrupt_info *gpe_xrupt_list)
  *
  ******************************************************************************/
 
+/*
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request ==> acpi_ev_notify_dispatch
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ *
+ * [0] acpi_hotplug_schedule
+ * [0] acpi_bus_notify
+ * [0] acpi_ev_notify_dispatch
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ *
+ * struct acpi_gpe_block_info *gpe_block;
+ * -> struct acpi_namespace_node *node; (gpe_device->name.ascii = "_GPE".)
+ * -> struct acpi_gpe_register_info *register_info;
+ * -> struct acpi_gpe_event_info *event_info;
+ *
+ * debug测试的时候只有i=0, j=1执行了这里
+ * gpe_number=1
+ * (插入第二个第三个还是这样)
+ * 应该是ACPI_GPE_DISPATCH_METHOD
+ */
 static void ACPI_SYSTEM_XFACE acpi_ev_asynch_execute_gpe_method(void *context)
 {
 	struct acpi_gpe_event_info *gpe_event_info = context;
@@ -478,6 +612,9 @@ static void ACPI_SYSTEM_XFACE acpi_ev_asynch_execute_gpe_method(void *context)
 		 */
 		notify = gpe_event_info->dispatch.notify_list;
 		while (ACPI_SUCCESS(status) && notify) {
+			/*
+			 * 似乎这里非常重要!!! 也不一定, 好吧不是!!!
+			 */
 			status =
 			    acpi_ev_queue_notify_request(notify->device_node,
 							 ACPI_NOTIFY_DEVICE_WAKE);
@@ -495,6 +632,20 @@ static void ACPI_SYSTEM_XFACE acpi_ev_asynch_execute_gpe_method(void *context)
 		if (!info) {
 			status = AE_NO_MEMORY;
 		} else {
+			/*
+			 * struct acpi_gpe_block_info *gpe_block;
+			 * -> struct acpi_namespace_node *node; (gpe_device->name.ascii = "_GPE".)
+			 * -> struct acpi_gpe_register_info *register_info;
+			 * -> struct acpi_gpe_event_info *event_info;
+			 *
+			 * debug测试的时候只有i=0, j=1执行了这里
+			 * gpe_number=1
+			 * (插入第二个第三个还是这样)
+			 * 应该是ACPI_GPE_DISPATCH_METHOD
+			 *
+			 * 这里测试的
+			 * acpi_ut_get_node_name(gpe_event_info->dispatch.method_node)是"_E01"
+			 */
 			/*
 			 * Invoke the GPE Method (_Lxx, _Exx) i.e., evaluate the
 			 * _Lxx/_Exx control method that corresponds to this GPE
@@ -503,6 +654,11 @@ static void ACPI_SYSTEM_XFACE acpi_ev_asynch_execute_gpe_method(void *context)
 			    gpe_event_info->dispatch.method_node;
 			info->flags = ACPI_IGNORE_RETURN_VALUE;
 
+			/*
+			 * 先执行这里!!!!!
+			 *
+			 * struct acpi_evaluate_info *info;
+			 */
 			status = acpi_ns_evaluate(info);
 			ACPI_FREE(info);
 		}
@@ -523,6 +679,28 @@ static void ACPI_SYSTEM_XFACE acpi_ev_asynch_execute_gpe_method(void *context)
 
 	/* Defer enabling of GPE until all notify handlers are done */
 
+	/*
+	 * 在以下调用acpi_os_execute():
+	 *   - drivers/acpi/acpica/dbexec.c|695| <<acpi_db_create_execution_thread>> status = acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+	 *            acpi_db_single_execution_thread, &acpi_gbl_db_method_info);
+	 *   - drivers/acpi/acpica/dbexec.c|849| <<acpi_db_create_execution_threads>> acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+	 *            acpi_db_method_thread, &acpi_gbl_db_method_info);
+	 *   - drivers/acpi/acpica/dbxface.c|448| <<acpi_initialize_debugger>> status = acpi_os_execute(OSL_DEBUGGER_MAIN_THREAD,
+	 *            acpi_db_execute_thread, NULL);
+	 *   - drivers/acpi/acpica/evgpe.c|526| <<acpi_ev_asynch_execute_gpe_method>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_ev_asynch_enable_gpe, gpe_event_info);
+	 *   - drivers/acpi/acpica/evgpe.c|823| <<acpi_ev_gpe_dispatch>> status = acpi_os_execute(OSL_GPE_HANDLER,
+	 *            acpi_ev_asynch_execute_gpe_method, gpe_event_info);
+	 *   - drivers/acpi/acpica/evmisc.c|139| <<acpi_ev_queue_notify_request>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_ev_notify_dispatch, info);
+	 *   - drivers/acpi/bus.c|539| <<acpi_device_fixed_event>> acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_notify_device_fixed, data);
+	 *   - drivers/acpi/sbshc.c|232| <<smbus_alarm>> acpi_os_execute(OSL_NOTIFY_HANDLER, acpi_smbus_callback, hc);
+	 *   - drivers/platform/x86/dell/dell-rbtn.c|278| <<rbtn_resume>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            rbtn_clear_suspended_flag, rbtn_data);
+	 *
+	 * struct acpi_gpe_event_info *gpe_event_info = context;
+	 */
 	status = acpi_os_execute(OSL_NOTIFY_HANDLER,
 				 acpi_ev_asynch_enable_gpe, gpe_event_info);
 	if (ACPI_SUCCESS(status)) {
@@ -549,6 +727,11 @@ static void ACPI_SYSTEM_XFACE acpi_ev_asynch_execute_gpe_method(void *context)
  *
  ******************************************************************************/
 
+/*
+ * 在以下使用acpi_ev_asynch_enable_gpe():
+ *   - drivers/acpi/acpica/evgpe.c|630| <<acpi_ev_asynch_execute_gpe_method>> status = acpi_os_execute(OSL_NOTIFY_HANDLER, acpi_ev_asynch_enable_gpe, gpe_event_info);
+ *   - drivers/acpi/acpica/evgpe.c|636| <<acpi_ev_asynch_execute_gpe_method>> acpi_ev_asynch_enable_gpe(gpe_event_info);
+ */
 static void ACPI_SYSTEM_XFACE acpi_ev_asynch_enable_gpe(void *context)
 {
 	struct acpi_gpe_event_info *gpe_event_info = context;
@@ -622,6 +805,56 @@ acpi_status acpi_ev_finish_gpe(struct acpi_gpe_event_info *gpe_event_info)
  *
  ******************************************************************************/
 
+/*
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * 在以下调用acpi_ev_detect_gpe():
+ *   - drivers/acpi/acpica/evgpe.c|471| <<acpi_ev_gpe_detect>> acpi_ev_detect_gpe(gpe_device, gpe_event_info, gpe_number);
+ *   - drivers/acpi/acpica/evxface.c|980| <<acpi_remove_gpe_handler>> (void )acpi_ev_detect_gpe(gpe_device, gpe_event_info, gpe_number);
+ *   - drivers/acpi/acpica/evxfgpe.c|118| <<acpi_enable_gpe>> (void )acpi_ev_detect_gpe(gpe_device, gpe_event_info, gpe_number);
+ *   - drivers/acpi/acpica/evxfgpe.c|657| <<acpi_dispatch_gpe>> return acpi_ev_detect_gpe(gpe_device, NULL, gpe_number);
+ *
+ * gpe_block都链接在gpe_block_list_head
+ *
+ * struct acpi_gpe_block_info *gpe_block;
+ * -> struct acpi_namespace_node *node; (gpe_device->name.ascii = "_GPE".)
+ * -> struct acpi_gpe_register_info *register_info;
+ * -> struct acpi_gpe_event_info *event_info;
+ */
 u32
 acpi_ev_detect_gpe(struct acpi_namespace_node *gpe_device,
 		   struct acpi_gpe_event_info *gpe_event_info, u32 gpe_number)
@@ -720,6 +953,18 @@ acpi_ev_detect_gpe(struct acpi_namespace_node *gpe_device,
 	} else {
 		/* Dispatch the event to a standard handler or method. */
 
+		/*
+		 * struct acpi_gpe_block_info *gpe_block;
+		 * -> struct acpi_namespace_node *node; (gpe_device->name.ascii = "_GPE".)
+		 * -> struct acpi_gpe_register_info *register_info;
+		 * -> struct acpi_gpe_event_info *event_info;
+		 *
+		 * debug测试的时候只有i=0, j=1执行了这里
+		 * gpe_number=1
+		 * (插入第二个第三个还是这样)
+		 *
+		 * 这里???
+		 */
 		int_status |= acpi_ev_gpe_dispatch(gpe_device,
 						   gpe_event_info, gpe_number);
 	}
@@ -744,6 +989,57 @@ acpi_ev_detect_gpe(struct acpi_namespace_node *gpe_device,
  *
  ******************************************************************************/
 
+/*
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * 在以下使用acpi_ev_gpe_dispatch():
+ *   - drivers/acpi/acpica/dbcmds.c|1055| <<acpi_db_generate_gpe>> (void )acpi_ev_gpe_dispatch(NULL, gpe_event_info, gpe_number);
+ *   - drivers/acpi/acpica/evgpe.c|866| <<acpi_ev_detect_gpe>> int_status |= acpi_ev_gpe_dispatch(gpe_device, gpe_event_info, gpe_number);
+ *
+ * struct acpi_gpe_block_info *gpe_block;
+ * -> struct acpi_namespace_node *node; (gpe_device->name.ascii = "_GPE".)
+ * -> struct acpi_gpe_register_info *register_info;
+ * -> struct acpi_gpe_event_info *event_info;
+ *
+ * debug测试的时候只有i=0, j=1执行了这里
+ * gpe_number=1
+ * (插入第二个第三个还是这样)
+ * 应该是ACPI_GPE_DISPATCH_METHOD
+ */
 u32
 acpi_ev_gpe_dispatch(struct acpi_namespace_node *gpe_device,
 		     struct acpi_gpe_event_info *gpe_event_info, u32 gpe_number)
@@ -795,6 +1091,9 @@ acpi_ev_gpe_dispatch(struct acpi_namespace_node *gpe_device,
 	 * If there is neither a handler nor a method, leave the GPE
 	 * disabled.
 	 */
+	/*
+	 * hot-add应该是ACPI_GPE_DISPATCH_METHOD
+	 */
 	switch (ACPI_GPE_DISPATCH_TYPE(gpe_event_info->flags)) {
 	case ACPI_GPE_DISPATCH_HANDLER:
 
@@ -816,6 +1115,37 @@ acpi_ev_gpe_dispatch(struct acpi_namespace_node *gpe_device,
 
 	case ACPI_GPE_DISPATCH_METHOD:
 	case ACPI_GPE_DISPATCH_NOTIFY:
+		/*
+		 * 在以下调用acpi_os_execute():
+		 *   - drivers/acpi/acpica/dbexec.c|695| <<acpi_db_create_execution_thread>> status = acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+		 *            acpi_db_single_execution_thread, &acpi_gbl_db_method_info);
+		 *   - drivers/acpi/acpica/dbexec.c|849| <<acpi_db_create_execution_threads>> acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+		 *            acpi_db_method_thread, &acpi_gbl_db_method_info);
+		 *   - drivers/acpi/acpica/dbxface.c|448| <<acpi_initialize_debugger>> status = acpi_os_execute(OSL_DEBUGGER_MAIN_THREAD,
+		 *            acpi_db_execute_thread, NULL);
+		 *   - drivers/acpi/acpica/evgpe.c|526| <<acpi_ev_asynch_execute_gpe_method>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            acpi_ev_asynch_enable_gpe, gpe_event_info);
+		 *   - drivers/acpi/acpica/evgpe.c|823| <<acpi_ev_gpe_dispatch>> status = acpi_os_execute(OSL_GPE_HANDLER,
+		 *            acpi_ev_asynch_execute_gpe_method, gpe_event_info);
+		 *   - drivers/acpi/acpica/evmisc.c|139| <<acpi_ev_queue_notify_request>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            acpi_ev_notify_dispatch, info);
+		 *   - drivers/acpi/bus.c|539| <<acpi_device_fixed_event>> acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            acpi_notify_device_fixed, data);
+		 *   - drivers/acpi/sbshc.c|232| <<smbus_alarm>> acpi_os_execute(OSL_NOTIFY_HANDLER, acpi_smbus_callback, hc);
+		 *   - drivers/platform/x86/dell/dell-rbtn.c|278| <<rbtn_resume>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            rbtn_clear_suspended_flag, rbtn_data);
+		 *
+		 *
+		 * struct acpi_gpe_block_info *gpe_block;
+		 * -> struct acpi_namespace_node *node; (gpe_device->name.ascii = "_GPE".)
+		 * -> struct acpi_gpe_register_info *register_info;
+		 * -> struct acpi_gpe_event_info *event_info;
+		 *
+		 * debug测试的时候只有i=0, j=1执行了这里
+		 * gpe_number=1
+		 * (插入第二个第三个还是这样)
+		 * 应该是ACPI_GPE_DISPATCH_METHOD
+		 */
 		/*
 		 * Execute the method associated with the GPE
 		 * NOTE: Level-triggered GPEs are cleared after the method completes.
diff --git a/drivers/acpi/acpica/evmisc.c b/drivers/acpi/acpica/evmisc.c
index f14ebcd610ab..8e5f031301d7 100644
--- a/drivers/acpi/acpica/evmisc.c
+++ b/drivers/acpi/acpica/evmisc.c
@@ -64,11 +64,92 @@ u8 acpi_ev_is_notify_object(struct acpi_namespace_node *node)
  *
  ******************************************************************************/
 
+/*
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ *
+ * [0] acpi_hotplug_schedule
+ * [0] acpi_bus_notify
+ * [0] acpi_ev_notify_dispatch
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * static acpi_execute_op acpi_gbl_op_type_dispatch[] = {
+ *     acpi_ex_opcode_0A_0T_1R,
+ *     acpi_ex_opcode_1A_0T_0R,
+ *     acpi_ex_opcode_1A_0T_1R,
+ *     acpi_ex_opcode_1A_1T_0R,
+ *     acpi_ex_opcode_1A_1T_1R,
+ *     acpi_ex_opcode_2A_0T_0R,
+ *     acpi_ex_opcode_2A_0T_1R,
+ *     acpi_ex_opcode_2A_1T_1R,
+ *     acpi_ex_opcode_2A_2T_1R,
+ *     acpi_ex_opcode_3A_0T_0R,
+ *     acpi_ex_opcode_3A_1T_1R,
+ *     acpi_ex_opcode_6A_0T_1R
+ *
+ * 在以下使用acpi_ev_queue_notify_request():
+ *   - drivers/acpi/acpica/dbcmds.c|386| <<acpi_db_send_notify>> status = acpi_ev_queue_notify_request(node, value);
+ *   - drivers/acpi/acpica/evgpe.c|482| <<acpi_ev_asynch_execute_gpe_method>> acpi_ev_queue_notify_request(notify->device_node, ACPI_NOTIFY_DEVICE_WAKE);
+ *   - drivers/acpi/acpica/exoparg2.c|96| <<acpi_ex_opcode_2A_0T_0R>> status = acpi_ev_queue_notify_request(node, value);
+ *
+ * 要看acpi_ex_opcode_2A_0T_0R()!!!
+ */
 acpi_status
 acpi_ev_queue_notify_request(struct acpi_namespace_node *node, u32 notify_value)
 {
 	union acpi_operand_object *obj_desc;
 	union acpi_operand_object *handler_list_head = NULL;
+	/*
+	 * union acpi_generic_state {
+	 *     struct acpi_common_state common;
+	 *     struct acpi_control_state control;
+	 *     struct acpi_update_state update;
+	 *     struct acpi_scope_state scope;
+	 *     struct acpi_pscope_state parse_scope;
+	 *     struct acpi_pkg_state pkg;
+	 *     struct acpi_thread_state thread;
+	 *     struct acpi_result_values results;
+	 *     struct acpi_notify_info notify;
+	 * };
+	 */
 	union acpi_generic_state *info;
 	u8 handler_list_id = 0;
 	acpi_status status = AE_OK;
@@ -116,6 +197,18 @@ acpi_ev_queue_notify_request(struct acpi_namespace_node *node, u32 notify_value)
 
 	/* Setup notify info and schedule the notify dispatcher */
 
+	/*
+	 * 在以下调用acpi_ut_create_generic_state():
+	 *   - drivers/acpi/acpica/dswscope.c|92| <<acpi_ds_scope_stack_push>> scope_info = acpi_ut_create_generic_state();
+	 *   - drivers/acpi/acpica/dswstate.c|198| <<acpi_ds_result_stack_push>> state = acpi_ut_create_generic_state();
+	 *   - drivers/acpi/acpica/evmisc.c|184| <<acpi_ev_queue_notify_request>> info = acpi_ut_create_generic_state();
+	 *   - drivers/acpi/acpica/psscope.c|78| <<acpi_ps_init_scope>> scope = acpi_ut_create_generic_state();
+	 *   - drivers/acpi/acpica/psscope.c|119| <<acpi_ps_push_scope>> scope = acpi_ut_create_generic_state();
+	 *   - drivers/acpi/acpica/utstate.c|121| <<acpi_ut_create_thread_state>> state = acpi_ut_create_generic_state();
+	 *   - drivers/acpi/acpica/utstate.c|165| <<acpi_ut_create_update_state>> state = acpi_ut_create_generic_state();
+	 *   - drivers/acpi/acpica/utstate.c|201| <<acpi_ut_create_pkg_state>> state = acpi_ut_create_generic_state();
+	 *   - drivers/acpi/acpica/utstate.c|238| <<acpi_ut_create_control_state>> state = acpi_ut_create_generic_state();
+	 */
 	info = acpi_ut_create_generic_state();
 	if (!info) {
 		return (AE_NO_MEMORY);
@@ -123,12 +216,40 @@ acpi_ev_queue_notify_request(struct acpi_namespace_node *node, u32 notify_value)
 
 	info->common.descriptor_type = ACPI_DESC_TYPE_STATE_NOTIFY;
 
+	/*
+	 * union acpi_generic_state *info;
+	 * -> struct acpi_notify_info notify;
+	 *    -> struct acpi_namespace_node *node;
+	 */
 	info->notify.node = node;
 	info->notify.value = (u16)notify_value;
 	info->notify.handler_list_id = handler_list_id;
 	info->notify.handler_list_head = handler_list_head;
 	info->notify.global = &acpi_gbl_global_notify[handler_list_id];
 
+	/*
+	 * Add第一个PCI.
+	 * acpi_ut_get_node_name(node) = "S00_"
+	 * acpi_ut_get_type_name(node->type) = "Device"
+	 * notify_value = 0x01
+	 * acpi_ut_get_notify_name(notify_value, ACPI_TYPE_ANY) = "Device Check"
+	 * node = "0000000000dc4999"
+	 *
+	 * Add第二个PCI.
+	 * acpi_ut_get_node_name(node) = "S00_"
+	 * acpi_ut_get_type_name(node->type) = "Device"
+	 * notify_value = 0x01
+	 * acpi_ut_get_notify_name(notify_value, ACPI_TYPE_ANY) = "Device Check"
+	 * node = "00000000864355e2"
+	 *
+	 * 然后删除:
+	 * Dispatching Notify on [S00_] (Device) Value 0x03 (Eject Request) Node 00000000864355e2
+	 *
+	 * 再Add一次第二个.
+	 * Dispatching Notify on [S00_] (Device) Value 0x01 (Device Check) Node 00000000864355e2
+	 *
+	 * acpi_ut_get_notify_name()竟然编译不过???
+	 */
 	ACPI_DEBUG_PRINT((ACPI_DB_INFO,
 			  "Dispatching Notify on [%4.4s] (%s) Value 0x%2.2X (%s) Node %p\n",
 			  acpi_ut_get_node_name(node),
@@ -136,6 +257,35 @@ acpi_ev_queue_notify_request(struct acpi_namespace_node *node, u32 notify_value)
 			  acpi_ut_get_notify_name(notify_value, ACPI_TYPE_ANY),
 			  node));
 
+	/*
+	 * 在以下调用acpi_os_execute():
+	 *   - drivers/acpi/acpica/dbexec.c|695| <<acpi_db_create_execution_thread>> status = acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+	 *            acpi_db_single_execution_thread, &acpi_gbl_db_method_info);
+	 *   - drivers/acpi/acpica/dbexec.c|849| <<acpi_db_create_execution_threads>> acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+	 *            acpi_db_method_thread, &acpi_gbl_db_method_info);
+	 *   - drivers/acpi/acpica/dbxface.c|448| <<acpi_initialize_debugger>> status = acpi_os_execute(OSL_DEBUGGER_MAIN_THREAD,
+	 *            acpi_db_execute_thread, NULL);
+	 *   - drivers/acpi/acpica/evgpe.c|526| <<acpi_ev_asynch_execute_gpe_method>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_ev_asynch_enable_gpe, gpe_event_info);
+	 *   - drivers/acpi/acpica/evgpe.c|823| <<acpi_ev_gpe_dispatch>> status = acpi_os_execute(OSL_GPE_HANDLER,
+	 *            acpi_ev_asynch_execute_gpe_method, gpe_event_info);
+	 *   - drivers/acpi/acpica/evmisc.c|139| <<acpi_ev_queue_notify_request>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_ev_notify_dispatch, info);
+	 *   - drivers/acpi/bus.c|539| <<acpi_device_fixed_event>> acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_notify_device_fixed, data);
+	 *   - drivers/acpi/sbshc.c|232| <<smbus_alarm>> acpi_os_execute(OSL_NOTIFY_HANDLER, acpi_smbus_callback, hc);
+	 *   - drivers/platform/x86/dell/dell-rbtn.c|278| <<rbtn_resume>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            rbtn_clear_suspended_flag, rbtn_data);
+	 *
+	 * [0] acpi_hotplug_schedule
+	 * [0] acpi_bus_notify
+	 * [0] acpi_ev_notify_dispatch
+	 * [0] acpi_os_execute_deferred
+	 * [0] process_one_work
+	 * [0] worker_thread
+	 * [0] kthread
+	 * [0] ret_from_fork
+	 */
 	status = acpi_os_execute(OSL_NOTIFY_HANDLER,
 				 acpi_ev_notify_dispatch, info);
 	if (ACPI_FAILURE(status)) {
@@ -158,6 +308,57 @@ acpi_ev_queue_notify_request(struct acpi_namespace_node *node, u32 notify_value)
  *
  ******************************************************************************/
 
+/*
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ *
+ *
+ * [0] acpi_hotplug_schedule
+ * [0] acpi_bus_notify
+ * [0] acpi_ev_notify_dispatch
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * 在以下使用acpi_ev_notify_dispatch():
+ *   - drivers/acpi/acpica/evmisc.c|160| <<acpi_ev_queue_notify_request>> status = acpi_os_execute(OSL_NOTIFY_HANDLER, acpi_ev_notify_dispatch, info);
+ */
 static void ACPI_SYSTEM_XFACE acpi_ev_notify_dispatch(void *context)
 {
 	union acpi_generic_state *info = (union acpi_generic_state *)context;
@@ -165,6 +366,20 @@ static void ACPI_SYSTEM_XFACE acpi_ev_notify_dispatch(void *context)
 
 	ACPI_FUNCTION_ENTRY();
 
+	/*
+	 * union acpi_generic_state *info:
+	 * -> struct acpi_notify_info notify;
+	 *    -> struct acpi_namespace_node *node;
+	 *
+	 * 在以下使用acpi_bus_notify():
+	 *   -  drivers/acpi/bus.c|1335| <<acpi_bus_init>> status =
+	 *                  acpi_install_notify_handler(ACPI_ROOT_OBJECT, ACPI_SYSTEM_NOTIFY,
+	 *                                              &acpi_bus_notify, NULL);
+	 *
+	 * 定义是:
+	 * static void acpi_bus_notify(acpi_handle handle, u32 type, void *data)
+	 */
+
 	/* Invoke a global notify handler if installed */
 
 	if (info->notify.global->handler) {
diff --git a/drivers/acpi/acpica/evsci.c b/drivers/acpi/acpica/evsci.c
index 3915ff61412b..3213f53c03b3 100644
--- a/drivers/acpi/acpica/evsci.c
+++ b/drivers/acpi/acpica/evsci.c
@@ -73,6 +73,51 @@ u32 acpi_ev_sci_dispatch(void)
  *
  ******************************************************************************/
 
+/*
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * 在以下使用acpi_ev_sci_xrupt_handler():
+ *   - drivers/acpi/acpica/evsci.c|171| <<acpi_ev_install_sci_handler>> status =
+ *                 acpi_os_install_interrupt_handler((u32) acpi_gbl_FADT.sci_interrupt,
+ *                 cpi_ev_sci_xrupt_handler, acpi_gbl_gpe_xrupt_list_head);
+ *   - drivers/acpi/acpica/evsci.c|207| <<acpi_ev_remove_all_sci_handlers>> status =
+ *                 acpi_os_remove_interrupt_handler((u32) acpi_gbl_FADT.sci_interrupt,
+ *                 acpi_ev_sci_xrupt_handler);
+ */
 static u32 ACPI_SYSTEM_XFACE acpi_ev_sci_xrupt_handler(void *context)
 {
 	struct acpi_gpe_xrupt_info *gpe_xrupt_list = context;
@@ -91,6 +136,19 @@ static u32 ACPI_SYSTEM_XFACE acpi_ev_sci_xrupt_handler(void *context)
 	 */
 	interrupt_handled |= acpi_ev_fixed_event_detect();
 
+	/*
+	 * [0] acpi_os_execute
+	 * [0] acpi_ev_gpe_dispatch
+	 * [0] acpi_ev_detect_gpe
+	 * [0] acpi_ev_gpe_detect
+	 * [0] acpi_ev_sci_xrupt_handler
+	 * [0] acpi_irq
+	 * [0] __handle_irq_event_percpu
+	 * [0] handle_irq_event
+	 * [0] handle_fasteoi_irq
+	 * [0] __common_interrupt
+	 * [0] common_interrupt
+	 */
 	/*
 	 * General Purpose Events:
 	 * Check for and dispatch any GPEs that have occurred
diff --git a/drivers/acpi/acpica/exoparg2.c b/drivers/acpi/acpica/exoparg2.c
index 10323ab186da..f448ed795277 100644
--- a/drivers/acpi/acpica/exoparg2.c
+++ b/drivers/acpi/acpica/exoparg2.c
@@ -52,8 +52,66 @@ ACPI_MODULE_NAME("exoparg2")
  * ALLOCATION:  Deletes both operands
  *
  ******************************************************************************/
+/*
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq         
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt     
+ *                            
+ * [0] acpi_os_execute       
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op  
+ * [0] acpi_ps_parse_loop   
+ * [0] acpi_ps_parse_aml        
+ * [0] acpi_ps_execute_method   
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work         
+ * [0] worker_thread            
+ * [0] kthread                      
+ * [0] ret_from_fork                                            
+ *                                                              
+ * [0] acpi_os_execute          
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred         
+ * [0] process_one_work                         
+ * [0] worker_thread                                            
+ * [0] kthread                          
+ * [0] ret_from_fork
+ *
+ *
+ * static acpi_execute_op acpi_gbl_op_type_dispatch[] = {
+ *     acpi_ex_opcode_0A_0T_1R,
+ *     acpi_ex_opcode_1A_0T_0R,
+ *     acpi_ex_opcode_1A_0T_1R,
+ *     acpi_ex_opcode_1A_1T_0R,
+ *     acpi_ex_opcode_1A_1T_1R,
+ *     acpi_ex_opcode_2A_0T_0R,
+ *     acpi_ex_opcode_2A_0T_1R,
+ *     acpi_ex_opcode_2A_1T_1R,
+ *     acpi_ex_opcode_2A_2T_1R,
+ *     acpi_ex_opcode_3A_0T_0R,
+ *     acpi_ex_opcode_3A_1T_1R,
+ *     acpi_ex_opcode_6A_0T_1R
+ * };
+ *
+ * 在以下使用acpi_gbl_op_type_dispatch[]:
+ *   - drivers/acpi/acpica/dswexec.c|453| <<acpi_ds_exec_end_op>> acpi_gbl_op_type_dispatch[op_type] (walk_state);
+ */
 acpi_status acpi_ex_opcode_2A_0T_0R(struct acpi_walk_state *walk_state)
 {
+	/*
+	 * struct acpi_walk_state *walk_state;
+	 * -> union acpi_operand_object *operands[ACPI_OBJ_NUM_OPERANDS + 1];
+	 */
 	union acpi_operand_object **operand = &walk_state->operands[0];
 	struct acpi_namespace_node *node;
 	u32 value;
@@ -93,6 +151,9 @@ acpi_status acpi_ex_opcode_2A_0T_0R(struct acpi_walk_state *walk_state)
 		 * from this thread -- because handlers may in turn run other
 		 * control methods.
 		 */
+		/*
+		 * 执行这里!!!
+		 */
 		status = acpi_ev_queue_notify_request(node, value);
 		break;
 
diff --git a/drivers/acpi/acpica/nseval.c b/drivers/acpi/acpica/nseval.c
index 63748ac699f7..a10aa62022ed 100644
--- a/drivers/acpi/acpica/nseval.c
+++ b/drivers/acpi/acpica/nseval.c
@@ -39,6 +39,127 @@ ACPI_MODULE_NAME("nseval")
  * MUTEX:       Locks interpreter
  *
  ******************************************************************************/
+/*
+ * _SB.PCI0.S29.S00._ADR (Integer)
+ *
+ * [0] acpi_ns_evaluate+0xe7/0x2ae
+ * [0] acpi_evaluate_object
+ * [0] acpi_evaluate_integer
+ * [0] acpi_find_child_device
+ * [0] acpi_pci_find_companion
+ * [0] pci_set_acpi_fwnode
+ * [0] pci_setup_device
+ * [0] pci_scan_single_device
+ * [0] pci_scan_slot
+ * [0] acpiphp_hotplug_notify
+ * [0] acpi_device_hotplug
+ * [0] acpi_hotplug_work_fn
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ *
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ *
+ * struct acpi_gpe_block_info *gpe_block;
+ * -> struct acpi_namespace_node *node; (gpe_device->name.ascii = "_GPE".)
+ * -> struct acpi_gpe_register_info *register_info;
+ * -> struct acpi_gpe_event_info *event_info;
+ *
+ * debug测试的时候只有i=0, j=1执行了这里
+ * gpe_number=1
+ * (插入第二个第三个还是这样)
+ * 应该是ACPI_GPE_DISPATCH_METHOD
+ *
+ * 这里测试的
+ * acpi_ut_get_node_name(gpe_event_info->dispatch.method_node)是"_E01"
+ *
+ *     Scope (_GPE)
+ *     {
+ *         Method (_E01, 0, NotSerialized)  // _Exx: Edge-Triggered GPE, xx=0x00-0xFF
+ *         {
+ *             Acquire (\_SB.PCI0.BLCK, 0xFFFF)
+ *             \_SB.PCI0.PCNT ()
+ *             Release (\_SB.PCI0.BLCK)
+ *         }
+ *     }
+ *
+ *         Method (PCNT, 0, NotSerialized)
+ *         {
+ *             ^S2C.PCNT ()
+ *             ^S2A.PCNT ()
+ *             ^S29.PCNT ()
+ *             ^S28.PCNT ()
+ *             ^S27.PCNT ()
+ *         }
+ *
+ * 其中一个例子
+ *        Scope (S29)
+ *         {
+ *             Method (PCNT, 0, NotSerialized)
+ *             {
+ *                 BNUM = 0x02
+ *                 DVNT (PCIU, One)
+ *                 DVNT (PCID, 0x03)
+ *             }
+ *         }
+ *
+ *
+ *                 Method (DVNT, 2, NotSerialized)
+ *                 {
+ *                     If ((Arg0 & One))
+ *                     {
+ *                         Notify (S00, Arg1)
+ *                     }
+ *                }
+ *
+ * 在以下调用acpi_ns_evaluate():
+ *   - drivers/acpi/acpica/evgpe.c|598| <<acpi_ev_asynch_execute_gpe_method>> status = acpi_ns_evaluate(info);
+ *   - drivers/acpi/acpica/evregion.c|630| <<acpi_ev_execute_reg_method>> status = acpi_ns_evaluate(info);
+ *   - drivers/acpi/acpica/hwxface.c|362| <<acpi_get_sleep_type_data>> status = acpi_ns_evaluate(info);
+ *   - drivers/acpi/acpica/nsinit.c|156| <<acpi_ns_initialize_devices>> status = acpi_ns_evaluate(info.evaluate_info);
+ *   - drivers/acpi/acpica/nsinit.c|176| <<acpi_ns_initialize_devices>> status = acpi_ns_evaluate(info.evaluate_info);
+ *   - drivers/acpi/acpica/nsinit.c|645| <<acpi_ns_init_one_device>> status = acpi_ns_evaluate(info);
+ *   - drivers/acpi/acpica/nsxfeval.c|354| <<acpi_evaluate_object>> status = acpi_ns_evaluate(info);
+ *   - drivers/acpi/acpica/rsutils.c|746| <<acpi_rs_set_srs_method_data>> status = acpi_ns_evaluate(info);
+ *   - drivers/acpi/acpica/uteval.c|60| <<acpi_ut_evaluate_object>> status = acpi_ns_evaluate(info);
+ */
 acpi_status acpi_ns_evaluate(struct acpi_evaluate_info *info)
 {
 	acpi_status status;
@@ -49,6 +170,10 @@ acpi_status acpi_ns_evaluate(struct acpi_evaluate_info *info)
 		return_ACPI_STATUS(AE_BAD_PARAMETER);
 	}
 
+	/*
+	 * 从acpi_ev_asynch_execute_gpe_method()过来的话
+	 * 感觉就设置了prefix_node和flags
+	 */
 	if (!info->node) {
 		/*
 		 * Get the actual namespace node for the target object if we
@@ -100,6 +225,15 @@ acpi_status acpi_ns_evaluate(struct acpi_evaluate_info *info)
 
 	/* Optional object evaluation log */
 
+	/*
+	 * 从acpi_ev_asynch_execute_gpe_method()进来
+	 * 这里"%s (%s)\n"显示的是:
+	 * "_GPE._E01 (Method)"
+	 *
+	 * 从这里接着往下走, 怎么变成了ACPI的handle的呢???
+	 *
+	 * BTW, 稍后来到这里的时候是"_SB.PCI0.S2A.S00._DSM (Method)"
+	 */
 	ACPI_DEBUG_PRINT_RAW((ACPI_DB_EVALUATION,
 			      "%-26s:  %s (%s)\n", "   Enter evaluation",
 			      &info->full_pathname[1],
@@ -202,6 +336,10 @@ acpi_status acpi_ns_evaluate(struct acpi_evaluate_info *info)
 		 * here before calling into the AML parser
 		 */
 		acpi_ex_enter_interpreter();
+		/*
+		 * 这里吧
+		 * 只在这里调用
+		 */
 		status = acpi_ps_execute_method(info);
 		acpi_ex_exit_interpreter();
 		break;
diff --git a/drivers/acpi/acpica/nsnames.c b/drivers/acpi/acpica/nsnames.c
index d91153f65700..00adf10529ea 100644
--- a/drivers/acpi/acpica/nsnames.c
+++ b/drivers/acpi/acpica/nsnames.c
@@ -137,6 +137,9 @@ acpi_ns_handle_to_pathname(acpi_handle target_handle,
 
 	ACPI_FUNCTION_TRACE_PTR(ns_handle_to_pathname, target_handle);
 
+	/*
+	 * struct acpi_namespace_node *node;
+	 */
 	node = acpi_ns_validate_handle(target_handle);
 	if (!node) {
 		return_ACPI_STATUS(AE_BAD_PARAMETER);
diff --git a/drivers/acpi/acpica/nsxfeval.c b/drivers/acpi/acpica/nsxfeval.c
index f9d059647cc5..9c8a396ee144 100644
--- a/drivers/acpi/acpica/nsxfeval.c
+++ b/drivers/acpi/acpica/nsxfeval.c
@@ -922,6 +922,13 @@ ACPI_EXPORT_SYMBOL(acpi_detach_data)
  *              and execute a callback before returning.
  *
  ******************************************************************************/
+/*
+ * 在以下调用acpi_get_data_full():
+ *   - drivers/acpi/acpica/nsxfeval.c|979| <<acpi_get_data>> return acpi_get_data_full(obj_handle, handler, data, NULL);
+ *   - drivers/acpi/scan.c|576| <<acpi_get_data>> status = acpi_get_data_full(handle, acpi_scan_drop_device, (void **)&adev, callback);
+ *
+ * callback的一个例子是get_acpi_device()
+ */
 acpi_status
 acpi_get_data_full(acpi_handle obj_handle, acpi_object_handler handler,
 		   void **data, void (*callback)(void *))
@@ -950,6 +957,9 @@ acpi_get_data_full(acpi_handle obj_handle, acpi_object_handler handler,
 
 	status = acpi_ns_get_attached_data(node, handler, data);
 	if (ACPI_SUCCESS(status) && callback) {
+		/*
+		 * 比如get_acpi_device()
+		 */
 		callback(*data);
 	}
 
diff --git a/drivers/acpi/acpica/nsxfname.c b/drivers/acpi/acpica/nsxfname.c
index 03487546da5a..76caa414d8a2 100644
--- a/drivers/acpi/acpica/nsxfname.c
+++ b/drivers/acpi/acpica/nsxfname.c
@@ -145,6 +145,9 @@ acpi_get_name(acpi_handle handle, u32 name_type, struct acpi_buffer *buffer)
 		return (status);
 	}
 
+	/*
+	 * 应该是ACPI_FULL_PATHNAME
+	 */
 	if (name_type == ACPI_FULL_PATHNAME ||
 	    name_type == ACPI_FULL_PATHNAME_NO_TRAILING) {
 
diff --git a/drivers/acpi/acpica/psloop.c b/drivers/acpi/acpica/psloop.c
index 4b51dd939f29..7b4f74ecdb73 100644
--- a/drivers/acpi/acpica/psloop.c
+++ b/drivers/acpi/acpica/psloop.c
@@ -218,6 +218,43 @@ acpi_ps_get_arguments(struct acpi_walk_state *walk_state,
  *
  ******************************************************************************/
 
+/*
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ */
 acpi_status acpi_ps_parse_loop(struct acpi_walk_state *walk_state)
 {
 	acpi_status status = AE_OK;
@@ -522,6 +559,10 @@ acpi_status acpi_ps_parse_loop(struct acpi_walk_state *walk_state)
 			walk_state->op = op;
 			walk_state->opcode = op->common.aml_opcode;
 
+			/*
+			 * 这里很重要
+			 * acpi_ds_exec_end_op()
+			 */
 			status = walk_state->ascending_callback(walk_state);
 			status =
 			    acpi_ps_next_parse_state(walk_state, op, status);
diff --git a/drivers/acpi/acpica/psparse.c b/drivers/acpi/acpica/psparse.c
index 7eb7a81619a3..6155b1a12690 100644
--- a/drivers/acpi/acpica/psparse.c
+++ b/drivers/acpi/acpica/psparse.c
@@ -405,6 +405,43 @@ acpi_ps_next_parse_state(struct acpi_walk_state *walk_state,
  *
  ******************************************************************************/
 
+/*
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ */
 acpi_status acpi_ps_parse_aml(struct acpi_walk_state *walk_state)
 {
 	acpi_status status;
@@ -472,6 +509,9 @@ acpi_status acpi_ps_parse_aml(struct acpi_walk_state *walk_state)
 			 * The parse_loop executes AML until the method terminates
 			 * or calls another method.
 			 */
+			/*
+			 * 在这里????
+			 */
 			status = acpi_ps_parse_loop(walk_state);
 		}
 
diff --git a/drivers/acpi/acpica/psxface.c b/drivers/acpi/acpica/psxface.c
index fd0f28c7af1e..f5ebc868ac0b 100644
--- a/drivers/acpi/acpica/psxface.c
+++ b/drivers/acpi/acpica/psxface.c
@@ -81,6 +81,47 @@ acpi_debug_trace(const char *name, u32 debug_level, u32 debug_layer, u32 flags)
  *
  ******************************************************************************/
 
+/*
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ *
+ * 在以下使用acpi_ps_execute_method():
+ *   - drivers/acpi/acpica/nseval.c|313| <<acpi_ns_evaluate>> status = acpi_ps_execute_method(info);
+ */
 acpi_status acpi_ps_execute_method(struct acpi_evaluate_info *info)
 {
 	acpi_status status;
@@ -187,6 +228,9 @@ acpi_status acpi_ps_execute_method(struct acpi_evaluate_info *info)
 
 	/* Parse the AML */
 
+	/*
+	 * 在这里??
+	 */
 	status = acpi_ps_parse_aml(walk_state);
 
 	/* walk_state was deleted by parse_aml */
diff --git a/drivers/acpi/acpica/utstate.c b/drivers/acpi/acpica/utstate.c
index a2484556a6b5..512c874c95c0 100644
--- a/drivers/acpi/acpica/utstate.c
+++ b/drivers/acpi/acpica/utstate.c
@@ -81,6 +81,18 @@ union acpi_generic_state *acpi_ut_pop_generic_state(union acpi_generic_state
  *
  ******************************************************************************/
 
+/*
+ * 在以下调用acpi_ut_create_generic_state():
+ *   - drivers/acpi/acpica/dswscope.c|92| <<acpi_ds_scope_stack_push>> scope_info = acpi_ut_create_generic_state();
+ *   - drivers/acpi/acpica/dswstate.c|198| <<acpi_ds_result_stack_push>> state = acpi_ut_create_generic_state();
+ *   - drivers/acpi/acpica/evmisc.c|184| <<acpi_ev_queue_notify_request>> info = acpi_ut_create_generic_state();
+ *   - drivers/acpi/acpica/psscope.c|78| <<acpi_ps_init_scope>> scope = acpi_ut_create_generic_state();
+ *   - drivers/acpi/acpica/psscope.c|119| <<acpi_ps_push_scope>> scope = acpi_ut_create_generic_state();
+ *   - drivers/acpi/acpica/utstate.c|121| <<acpi_ut_create_thread_state>> state = acpi_ut_create_generic_state();
+ *   - drivers/acpi/acpica/utstate.c|165| <<acpi_ut_create_update_state>> state = acpi_ut_create_generic_state();
+ *   - drivers/acpi/acpica/utstate.c|201| <<acpi_ut_create_pkg_state>> state = acpi_ut_create_generic_state();
+ *   - drivers/acpi/acpica/utstate.c|238| <<acpi_ut_create_control_state>> state = acpi_ut_create_generic_state();
+ */
 union acpi_generic_state *acpi_ut_create_generic_state(void)
 {
 	union acpi_generic_state *state;
diff --git a/drivers/acpi/bus.c b/drivers/acpi/bus.c
index 30938e61d54b..952e4f397ed8 100644
--- a/drivers/acpi/bus.c
+++ b/drivers/acpi/bus.c
@@ -445,6 +445,22 @@ static void acpi_bus_osc_negotiate_usb_control(void)
  * ---------------
  * Callback for all 'system-level' device notifications (values 0x00-0x7F).
  */
+/*
+ * [0] acpi_hotplug_schedule
+ * [0] acpi_bus_notify
+ * [0] acpi_ev_notify_dispatch
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ *
+ * 在以下使用acpi_bus_notify():
+ *   -  drivers/acpi/bus.c|1335| <<acpi_bus_init>> status =
+ *                  acpi_install_notify_handler(ACPI_ROOT_OBJECT, ACPI_SYSTEM_NOTIFY,
+ *                                              &acpi_bus_notify, NULL);
+ */
 static void acpi_bus_notify(acpi_handle handle, u32 type, void *data)
 {
 	struct acpi_device *adev;
@@ -496,6 +512,14 @@ static void acpi_bus_notify(acpi_handle handle, u32 type, void *data)
 		break;
 	}
 
+	/*
+	 * 在以下调用acpi_bus_get_acpi_device():
+	 *   - drivers/acpi/bus.c|508| <<acpi_bus_notify>> adev = acpi_bus_get_acpi_device(handle);
+	 *   - drivers/acpi/device_pm.c|447| <<acpi_pm_notify_handler>> adev = acpi_bus_get_acpi_device(handle);
+	 *   - drivers/acpi/irq.c|127| <<acpi_get_irq_source_fwhandle>> device = acpi_bus_get_acpi_device(handle);
+	 *   - drivers/acpi/scan.c|2223| <<acpi_dev_get_first_consumer_dev_cb>> adev = acpi_bus_get_acpi_device(dep->consumer);
+	 *   - drivers/acpi/scan.c|2276| <<acpi_scan_clear_dep>> struct acpi_device *adev = acpi_bus_get_acpi_device(dep->consumer);
+	 */
 	adev = acpi_bus_get_acpi_device(handle);
 	if (!adev)
 		goto err;
@@ -536,6 +560,26 @@ static void acpi_notify_device_fixed(void *data)
 
 static u32 acpi_device_fixed_event(void *data)
 {
+	/*
+	 * 在以下调用acpi_os_execute():
+	 *   - drivers/acpi/acpica/dbexec.c|695| <<acpi_db_create_execution_thread>> status = acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+	 *            acpi_db_single_execution_thread, &acpi_gbl_db_method_info);
+	 *   - drivers/acpi/acpica/dbexec.c|849| <<acpi_db_create_execution_threads>> acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+	 *            acpi_db_method_thread, &acpi_gbl_db_method_info);
+	 *   - drivers/acpi/acpica/dbxface.c|448| <<acpi_initialize_debugger>> status = acpi_os_execute(OSL_DEBUGGER_MAIN_THREAD,
+	 *            acpi_db_execute_thread, NULL);
+	 *   - drivers/acpi/acpica/evgpe.c|526| <<acpi_ev_asynch_execute_gpe_method>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_ev_asynch_enable_gpe, gpe_event_info);
+	 *   - drivers/acpi/acpica/evgpe.c|823| <<acpi_ev_gpe_dispatch>> status = acpi_os_execute(OSL_GPE_HANDLER,
+	 *            acpi_ev_asynch_execute_gpe_method, gpe_event_info);
+	 *   - drivers/acpi/acpica/evmisc.c|139| <<acpi_ev_queue_notify_request>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_ev_notify_dispatch, info);
+	 *   - drivers/acpi/bus.c|539| <<acpi_device_fixed_event>> acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_notify_device_fixed, data);
+	 *   - drivers/acpi/sbshc.c|232| <<smbus_alarm>> acpi_os_execute(OSL_NOTIFY_HANDLER, acpi_smbus_callback, hc);
+	 *   - drivers/platform/x86/dell/dell-rbtn.c|278| <<rbtn_resume>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            rbtn_clear_suspended_flag, rbtn_data);
+	 */
 	acpi_os_execute(OSL_NOTIFY_HANDLER, acpi_notify_device_fixed, data);
 	return ACPI_INTERRUPT_HANDLED;
 }
diff --git a/drivers/acpi/osl.c b/drivers/acpi/osl.c
index 45c5c0e45e33..11d816d0f3ba 100644
--- a/drivers/acpi/osl.c
+++ b/drivers/acpi/osl.c
@@ -63,6 +63,12 @@ static int (*__acpi_os_prepare_extended_sleep)(u8 sleep_state, u32 val_a,
 				      u32 val_b);
 
 static acpi_osd_handler acpi_irq_handler;
+/*
+ * 在以下使用acpi_irq_context:
+ *   - drivers/acpi/osl.c|66| <<global>> static void *acpi_irq_context;
+ *   - drivers/acpi/osl.c|550| <<acpi_irq>> handled = (*acpi_irq_handler) (acpi_irq_context);
+ *   - drivers/acpi/osl.c|585| <<acpi_os_install_interrupt_handler>> acpi_irq_context = context;
+ */
 static void *acpi_irq_context;
 static struct workqueue_struct *kacpid_wq;
 static struct workqueue_struct *kacpi_notify_wq;
@@ -547,6 +553,12 @@ static irqreturn_t acpi_irq(int irq, void *dev_id)
 {
 	u32 handled;
 
+	/*
+	 * 在以下使用acpi_irq_context:
+	 *   - drivers/acpi/osl.c|66| <<global>> static void *acpi_irq_context;
+	 *   - drivers/acpi/osl.c|550| <<acpi_irq>> handled = (*acpi_irq_handler) (acpi_irq_context);
+	 *   - drivers/acpi/osl.c|585| <<acpi_os_install_interrupt_handler>> acpi_irq_context = context;
+	 */
 	handled = (*acpi_irq_handler) (acpi_irq_context);
 
 	if (handled) {
@@ -582,6 +594,12 @@ acpi_os_install_interrupt_handler(u32 gsi, acpi_osd_handler handler,
 	}
 
 	acpi_irq_handler = handler;
+	/*
+	 * 在以下使用acpi_irq_context:
+	 *   - drivers/acpi/osl.c|66| <<global>> static void *acpi_irq_context;
+	 *   - drivers/acpi/osl.c|550| <<acpi_irq>> handled = (*acpi_irq_handler) (acpi_irq_context);
+	 *   - drivers/acpi/osl.c|585| <<acpi_os_install_interrupt_handler>> acpi_irq_context = context;
+	 */
 	acpi_irq_context = context;
 	if (request_irq(irq, acpi_irq, IRQF_SHARED, "acpi", acpi_irq)) {
 		pr_err("SCI (IRQ%d) allocation failed\n", irq);
@@ -841,8 +859,20 @@ acpi_os_write_pci_configuration(struct acpi_pci_id * pci_id, u32 reg,
 }
 #endif
 
+/*
+ * 在以下使用acpi_os_execute_deferred():
+ *   - drivers/acpi/osl.c|1104| <<acpi_os_execute>> INIT_WORK(&dpc->work, acpi_os_execute_deferred);
+ *   - drivers/acpi/osl.c|1107| <<acpi_os_execute>> INIT_WORK(&dpc->work, acpi_os_execute_deferred);
+ */
 static void acpi_os_execute_deferred(struct work_struct *work)
 {
+	/*
+	 * struct acpi_os_dpc {
+	 *     acpi_osd_exec_callback function;
+	 *     void *context;
+	 *     struct work_struct work;
+	 * };
+	 */
 	struct acpi_os_dpc *dpc = container_of(work, struct acpi_os_dpc, work);
 
 	dpc->function(dpc->context);
@@ -1058,6 +1088,65 @@ int __init acpi_debugger_init(void)
  *
  ******************************************************************************/
 
+/*
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ *
+ * 在以下调用acpi_os_execute():
+ *   - drivers/acpi/acpica/dbexec.c|695| <<acpi_db_create_execution_thread>> status = acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+ *            acpi_db_single_execution_thread, &acpi_gbl_db_method_info);
+ *   - drivers/acpi/acpica/dbexec.c|849| <<acpi_db_create_execution_threads>> acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+ *            acpi_db_method_thread, &acpi_gbl_db_method_info);
+ *   - drivers/acpi/acpica/dbxface.c|448| <<acpi_initialize_debugger>> status = acpi_os_execute(OSL_DEBUGGER_MAIN_THREAD,
+ *            acpi_db_execute_thread, NULL);
+ *   - drivers/acpi/acpica/evgpe.c|526| <<acpi_ev_asynch_execute_gpe_method>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+ *            acpi_ev_asynch_enable_gpe, gpe_event_info);
+ *   - drivers/acpi/acpica/evgpe.c|823| <<acpi_ev_gpe_dispatch>> status = acpi_os_execute(OSL_GPE_HANDLER,
+ *            acpi_ev_asynch_execute_gpe_method, gpe_event_info);
+ *   - drivers/acpi/acpica/evmisc.c|139| <<acpi_ev_queue_notify_request>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+ *            acpi_ev_notify_dispatch, info);
+ *   - drivers/acpi/bus.c|539| <<acpi_device_fixed_event>> acpi_os_execute(OSL_NOTIFY_HANDLER,
+ *            acpi_notify_device_fixed, data);
+ *   - drivers/acpi/sbshc.c|232| <<smbus_alarm>> acpi_os_execute(OSL_NOTIFY_HANDLER, acpi_smbus_callback, hc);
+ *   - drivers/platform/x86/dell/dell-rbtn.c|278| <<rbtn_resume>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+ *            rbtn_clear_suspended_flag, rbtn_data);
+ *
+ * hotplug的时候type好像是2, 1, 1
+ */
 acpi_status acpi_os_execute(acpi_execute_type type,
 			    acpi_osd_exec_callback function, void *context)
 {
@@ -1087,6 +1176,13 @@ acpi_status acpi_os_execute(acpi_execute_type type,
 	 * having a static work_struct.
 	 */
 
+	/*
+	 * struct acpi_os_dpc {
+	 *     acpi_osd_exec_callback function;
+	 *     void *context;
+	 *     struct work_struct work;
+	 * };
+	 */
 	dpc = kzalloc(sizeof(struct acpi_os_dpc), GFP_ATOMIC);
 	if (!dpc)
 		return AE_NO_MEMORY;
@@ -1152,6 +1248,18 @@ struct acpi_hp_work {
 	u32 src;
 };
 
+/*
+ * [0] acpiphp_hotplug_notify
+ * [0] acpi_device_hotplug
+ * [0] acpi_hotplug_work_fn
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * 在以下使用acpi_hotplug_work_fn():
+ *   - drivers/acpi/osl.c|1210| <<acpi_hotplug_schedule>> INIT_WORK(&hpw->work, acpi_hotplug_work_fn);
+ */
 static void acpi_hotplug_work_fn(struct work_struct *work)
 {
 	struct acpi_hp_work *hpw = container_of(work, struct acpi_hp_work, work);
@@ -1161,6 +1269,20 @@ static void acpi_hotplug_work_fn(struct work_struct *work)
 	kfree(hpw);
 }
 
+/*
+ * [0] acpi_hotplug_schedule
+ * [0] acpi_bus_notify
+ * [0] acpi_ev_notify_dispatch
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * 在以下调用acpi_hotplug_schedule():
+ *   - drivers/acpi/bus.c|522| <<acpi_bus_notify>> if (ACPI_SUCCESS(acpi_hotplug_schedule(adev, type)))
+ *   - drivers/acpi/device_sysfs.c|388| <<eject_store>> status = acpi_hotplug_schedule(acpi_device, ACPI_OST_EC_OSPM_EJECT);
+ */
 acpi_status acpi_hotplug_schedule(struct acpi_device *adev, u32 src)
 {
 	struct acpi_hp_work *hpw;
diff --git a/drivers/acpi/scan.c b/drivers/acpi/scan.c
index e7d4a39e539f..77178c61b551 100644
--- a/drivers/acpi/scan.c
+++ b/drivers/acpi/scan.c
@@ -376,6 +376,83 @@ static int acpi_generic_hotplug_event(struct acpi_device *adev, u32 type)
 	return -EINVAL;
 }
 
+/*
+ * [  433.553792] <intr> acpi:624: ACPI: GPE event 0x01
+ * [  433.554104] [426] acpi:462: ACPI: \_SB_.PCI0.S29_.S00_: ACPI: ACPI_NOTIFY_DEVICE_CHECK event
+ * [  433.554110] [426] acpi:1168: ACPI: \_SB_.PCI0.S29_.S00_: ACPI: OSL: Scheduling hotplug event 1 for deferred handling
+ * [  433.554178] [97] acpiphp:803: ACPI: \_SB_.PCI0.S29_.S00_: acpiphp_glue: Device check in hotplug_event()
+ * [  433.554184] [97] acpi:579: ACPI: \_SB_.PCI0.S29_.S00_._ADR: ACPI: No context!
+ * [  433.554186] [97] acpi:579: ACPI: \_SB_.PCI0.S29_.S00_.ASUN: ACPI: No context!
+ * [  433.554188] [97] acpi:579: ACPI: \_SB_.PCI0.S29_.S00_._DSM: ACPI: No context!
+ * [  433.554190] [97] acpi:579: ACPI: \_SB_.PCI0.S29_.S00_._SUN: ACPI: No context!
+ * [  433.554191] [97] acpi:579: ACPI: \_SB_.PCI0.S29_.S00_._EJ0: ACPI: No context!
+ * [  433.554197] [97] acpi:28: ACPI: \_SB_.PCI0.S29_.S00_: ACPI: utils: Evaluate [_STA]: AE_NOT_FOUND
+ * [  433.554199] [97] acpi:125: ACPI: Device [S00] status [0000000f]
+ * [  433.554356] [97] acpi:273: ACPI: \_SB_.PCI0.S29_.S00_: ACPI: utils: Return value [0]
+ * [  433.554359] [97] acpi:273: ACPI: \_SB_.PCI0.S29_.S00_: ACPI: utils: Return value [0]
+ * [  433.554419] pci 0000:02:00.0: [1af4:1048] type 00 class 0x010000
+ * [  433.555885] pci 0000:02:00.0: reg 0x14: [mem 0x00000000-0x00000fff]
+ * [  433.557122] pci 0000:02:00.0: reg 0x20: [mem 0x00000000-0x00003fff 64bit pref]
+ * [  433.559748] [97] edr:233: pci 0000:02:00.0: EDR: Notify handler installed
+ * [  433.559766] [97] acpi:324: wakeup wakeup15: No ACPI support
+ * [  433.559838] [97] acpi:318: ACPI: \_SB_.PCI0.S29_.S00_: ACPI: Bound to device 0000:02:00.0
+ * [  433.560376] [97] acpi:28: ACPI: \_SB_.PCI0.S29_.S00_: ACPI: utils: Evaluate [_STA]: AE_NOT_FOUND
+ * [  433.560402] [97] acpi:579: ACPI: \_SB_.PCI0.S29_.S00_._ADR: ACPI: No context!
+ * [  433.560404] [97] acpi:579: ACPI: \_SB_.PCI0.S29_.S00_.ASUN: ACPI: No context!
+ * [  433.560405] [97] acpi:579: ACPI: \_SB_.PCI0.S29_.S00_._DSM: ACPI: No context!
+ * [  433.560407] [97] acpi:579: ACPI: \_SB_.PCI0.S29_.S00_._SUN: ACPI: No context!
+ * [  433.560409] [97] acpi:579: ACPI: \_SB_.PCI0.S29_.S00_._EJ0: ACPI: No context!
+ * [  433.560411] [97] acpi:28: ACPI: \_SB_.PCI0.S29_.S00_: ACPI: utils: Evaluate [_STA]: AE_NOT_FOUND
+ * [  433.560412] [97] acpi:125: ACPI: Device [S00] status [0000000f]
+ * [  433.560430] pci 0000:02:00.0: BAR 4: assigned [mem 0x802000000-0x802003fff 64bit pref]
+ * [  433.561843] pci 0000:02:00.0: BAR 1: assigned [mem 0x81200000-0x81200fff]
+ * [  433.563130] [97] acpi:1591: pciback 0000:02:00.0: Adding to IOMMU failed: -19
+ * [  433.563136] [97] setup_irq:27: pciback 0000:02:00.0: runtime IRQ mapping not provided by arch
+ * [  433.563161] [97] acpi:1591: virtio-pci 0000:02:00.0: Adding to IOMMU failed: -19
+ * [  433.563164] [97] setup_irq:27: virtio-pci 0000:02:00.0: runtime IRQ mapping not provided by arch
+ * [  433.563197] virtio-pci 0000:02:00.0: enabling device (0000 -> 0002)
+ * [  433.565778] [97] acpi:190: ACPI: PCI: 0000:00:05[A] -> \_SB_.GSIF[0]
+ * [  433.565782] [97] acpi:327: virtio-pci 0000:02:00.0: Derived GSI INT A from 0000:00:05.1
+ * [  433.565786] [97] acpi:649: ACPI: \_SB_.GSIF: ACPI: PCI: Link is referenced
+ * [  433.565791] [97] acpi:466: virtio-pci 0000:02:00.0: PCI INT A -> Link[GSIF] -> GSI 21 (level, high) -> IRQ 21
+ * [  433.566517] [97] pci:4371: virtio-pci 0000:02:00.0: enabling bus mastering
+ * [  433.567195] [97] acpi:324: virtio virtio1: No ACPI support
+ * [  433.567502] [97] acpi:324: workqueue scsi_tmf_7: No ACPI support
+ * [  433.568580] scsi host7: Virtio SCSI HBA
+ * [  433.569371] [97] acpi:324: scsi host7: No ACPI support
+ * [  433.569420] [97] acpi:324: scsi_host host7: No ACPI support
+ * [  433.574553] scsi 7:0:1:0: Direct-Access     LIO-ORG  storage02        4.0  PQ: 0 ANSI: 6
+ * [  433.589101] [1935] acpi:324: scsi target7:0:1: No ACPI support
+ * [  433.589137] scsi 7:0:1:0: alua: supports implicit and explicit TPGS
+ * [  433.590341] scsi 7:0:1:0: alua: device naa.6001405428c34d0d8a342cdbb4597c72 port group 0 rel port 1
+ * [  433.591927] [1935] acpi:324: scsi 7:0:1:0: No ACPI support
+ * [  433.591985] [1935] acpi:324: scsi_device 7:0:1:0: No ACPI support
+ * [  433.592021] [1935] acpi:324: scsi_generic sg3: No ACPI support
+ * [  433.592093] [105] acpi:324: scsi_disk 7:0:1:0: No ACPI support
+ * [  433.592302] sd 7:0:1:0: Attached scsi generic sg3 type 0
+ * [  433.592332] sd 7:0:1:0: [sdc] 262144 512-byte logical blocks: (134 MB/128 MiB)
+ * [  433.593213] [1935] acpi:324: bsg 7:0:1:0: No ACPI support
+ * [  433.594767] sd 7:0:1:0: [sdc] Write Protect is off
+ * [  433.595651] sd 7:0:1:0: [sdc] Mode Sense: 43 00 10 08
+ * [  433.595722] sd 7:0:1:0: [sdc] Write cache: enabled, read cache: enabled, supports DPO and FUA
+ * [  433.597263] sd 7:0:1:0: alua: transition timeout set to 60 seconds
+ * [  433.597270] sd 7:0:1:0: alua: port group 00 state A non-preferred supports TOlUSNA
+ * [  433.703687] sd 7:0:1:0: [sdc] Optimal transfer size 8388608 bytes
+ * [  433.705139] [105] acpi:324: block sdc: No ACPI support
+ * [  433.705660] [105] acpi:324: bdi 8:32: No ACPI support
+ * [  433.706272] sd 7:0:1:0: [sdc] Attached SCSI disk
+ *
+ * [0] acpiphp_hotplug_notify
+ * [0] acpi_device_hotplug
+ * [0] acpi_hotplug_work_fn
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * 在以下调用acpi_device_hotplug():
+ *   - drivers/acpi/osl.c|1250| <<acpi_hotplug_work_fn>> acpi_device_hotplug(hpw->adev, hpw->src);
+ */
 void acpi_device_hotplug(struct acpi_device *adev, u32 src)
 {
 	u32 ost_code = ACPI_OST_SC_NON_SPECIFIC_FAILURE;
@@ -406,6 +483,9 @@ void acpi_device_hotplug(struct acpi_device *adev, u32 src)
 		 * There may be additional notify handlers for device objects
 		 * without the .event() callback, so ignore them here.
 		 */
+		/*
+		 * 应该是acpiphp_hotplug_notify()
+		 */
 		if (notify)
 			error = notify(adev, src);
 		else
@@ -567,12 +647,23 @@ static void acpi_scan_drop_device(acpi_handle handle, void *context)
 	mutex_unlock(&acpi_device_del_lock);
 }
 
+/*
+ * 在以下使用handle_to_device():
+ *   - drivers/acpi/scan.c|590| <<acpi_bus_get_device>> *device = handle_to_device(handle, NULL);
+ *   - drivers/acpi/scan.c|607| <<acpi_fetch_acpi_dev>> return handle_to_device(handle, NULL);
+ *   - drivers/acpi/scan.c|618| <<acpi_bus_get_acpi_device>> return handle_to_device(handle, get_acpi_device);
+ */
 static struct acpi_device *handle_to_device(acpi_handle handle,
 					    void (*callback)(void *))
 {
 	struct acpi_device *adev = NULL;
 	acpi_status status;
 
+	/*
+	 * 在以下调用acpi_get_data_full():
+	 *   - drivers/acpi/acpica/nsxfeval.c|979| <<acpi_get_data>> return acpi_get_data_full(obj_handle, handler, data, NULL);
+	 *   - drivers/acpi/scan.c|576| <<acpi_get_data>> status = acpi_get_data_full(handle, acpi_scan_drop_device, (void **)&adev, callback);
+	 */
 	status = acpi_get_data_full(handle, acpi_scan_drop_device,
 				    (void **)&adev, callback);
 	if (ACPI_FAILURE(status) || !adev) {
@@ -587,6 +678,12 @@ int acpi_bus_get_device(acpi_handle handle, struct acpi_device **device)
 	if (!device)
 		return -EINVAL;
 
+	/*
+	 * 在以下使用handle_to_device():
+	 *   - drivers/acpi/scan.c|590| <<acpi_bus_get_device>> *device = handle_to_device(handle, NULL);
+	 *   - drivers/acpi/scan.c|607| <<acpi_fetch_acpi_dev>> return handle_to_device(handle, NULL);
+	 *   - drivers/acpi/scan.c|618| <<acpi_bus_get_acpi_device>> return handle_to_device(handle, get_acpi_device);
+	 */
 	*device = handle_to_device(handle, NULL);
 	if (!*device)
 		return -ENODEV;
@@ -604,6 +701,12 @@ EXPORT_SYMBOL(acpi_bus_get_device);
  */
 struct acpi_device *acpi_fetch_acpi_dev(acpi_handle handle)
 {
+	/*
+	 * 在以下使用handle_to_device():
+	 *   - drivers/acpi/scan.c|590| <<acpi_bus_get_device>> *device = handle_to_device(handle, NULL);
+	 *   - drivers/acpi/scan.c|607| <<acpi_fetch_acpi_dev>> return handle_to_device(handle, NULL);
+	 *   - drivers/acpi/scan.c|618| <<acpi_bus_get_acpi_device>> return handle_to_device(handle, get_acpi_device);
+	 */
 	return handle_to_device(handle, NULL);
 }
 EXPORT_SYMBOL_GPL(acpi_fetch_acpi_dev);
@@ -613,8 +716,22 @@ static void get_acpi_device(void *dev)
 	acpi_dev_get(dev);
 }
 
+/*
+ * 在以下调用acpi_bus_get_acpi_device():
+ *   - drivers/acpi/bus.c|508| <<acpi_bus_notify>> adev = acpi_bus_get_acpi_device(handle);
+ *   - drivers/acpi/device_pm.c|447| <<acpi_pm_notify_handler>> adev = acpi_bus_get_acpi_device(handle);
+ *   - drivers/acpi/irq.c|127| <<acpi_get_irq_source_fwhandle>> device = acpi_bus_get_acpi_device(handle);
+ *   - drivers/acpi/scan.c|2223| <<acpi_dev_get_first_consumer_dev_cb>> adev = acpi_bus_get_acpi_device(dep->consumer);
+ *   - drivers/acpi/scan.c|2276| <<acpi_scan_clear_dep>> struct acpi_device *adev = acpi_bus_get_acpi_device(dep->consumer);
+ */
 struct acpi_device *acpi_bus_get_acpi_device(acpi_handle handle)
 {
+	/*
+	 * 在以下使用handle_to_device():
+	 *   - drivers/acpi/scan.c|590| <<acpi_bus_get_device>> *device = handle_to_device(handle, NULL);
+	 *   - drivers/acpi/scan.c|607| <<acpi_fetch_acpi_dev>> return handle_to_device(handle, NULL);
+	 *   - drivers/acpi/scan.c|618| <<acpi_bus_get_acpi_device>> return handle_to_device(handle, get_acpi_device);
+	 */
 	return handle_to_device(handle, get_acpi_device);
 }
 
@@ -1793,6 +1910,25 @@ static void acpi_scan_init_status(struct acpi_device *adev)
 		acpi_set_device_status(adev, 0);
 }
 
+/*
+ * [0] acpi_add_single_object
+ * [0] acpi_bus_check_add
+ * [0] acpi_ns_walk_namespace
+ * [0] acpi_walk_namespace
+ * [0] acpi_bus_scan
+ * [0] acpi_scan_init
+ * [0] acpi_init
+ * [0] do_one_initcall
+ * [0] kernel_init_freeable
+ * [0] kernel_init
+ * [0] ret_from_fork
+ *
+ * 在以下使用acpi_add_single_object():
+ *   - drivers/acpi/scan.c|2182| <<acpi_bus_check_add>> acpi_add_single_object(&device, handle, type, !check_dep);
+ *   - drivers/acpi/scan.c|2560| <<acpi_bus_register_early_device>> result = acpi_add_single_object(&device, NULL, type, false);
+ *   - drivers/acpi/scan.c|2579| <<acpi_bus_scan_fixed>> result = acpi_add_single_object(&device, NULL, ACPI_BUS_TYPE_POWER_BUTTON, false);
+ *   - drivers/acpi/scan.c|2595| <<acpi_bus_scan_fixed>> result = acpi_add_single_object(&device, NULL, ACPI_BUS_TYPE_SLEEP_BUTTON, false);
+ */
 static int acpi_add_single_object(struct acpi_device **child,
 				  acpi_handle handle, int type, bool dep_init)
 {
@@ -2014,6 +2150,13 @@ static u32 acpi_scan_check_dep(acpi_handle handle, bool check_dep)
 
 static bool acpi_bus_scan_second_pass;
 
+/*
+ * 在以下使用acpi_bus_check_add():
+ *   - drivers/acpi/scan.c|2198| <<acpi_bus_check_add_1>> return acpi_bus_check_add(handle, true, (struct acpi_device **)ret_p);
+ *   - drivers/acpi/scan.c|2204| <<acpi_bus_check_add_2>> return acpi_bus_check_add(handle, false, (struct acpi_device **)ret_p);
+ *   - drivers/acpi/scan.c|2494| <<acpi_bus_scan>> if (ACPI_SUCCESS(acpi_bus_check_add(handle, true, &device)))
+ *   - drivers/acpi/scan.c|2511| <<acpi_bus_scan>> if (ACPI_SUCCESS(acpi_bus_check_add(handle, false, &device)))
+ */
 static acpi_status acpi_bus_check_add(acpi_handle handle, bool check_dep,
 				      struct acpi_device **adev_p)
 {
@@ -2062,6 +2205,13 @@ static acpi_status acpi_bus_check_add(acpi_handle handle, bool check_dep,
 	 * If check_dep is true at this point, the device has no dependencies,
 	 * or the creation of the device object would have been postponed above.
 	 */
+	/*
+	 * 在以下使用acpi_add_single_object():
+	 *   - drivers/acpi/scan.c|2182| <<acpi_bus_check_add>> acpi_add_single_object(&device, handle, type, !check_dep);
+	 *   - drivers/acpi/scan.c|2560| <<acpi_bus_register_early_device>> result = acpi_add_single_object(&device, NULL, type, false);
+	 *   - drivers/acpi/scan.c|2579| <<acpi_bus_scan_fixed>> result = acpi_add_single_object(&device, NULL, ACPI_BUS_TYPE_POWER_BUTTON, false);
+	 *   - drivers/acpi/scan.c|2595| <<acpi_bus_scan_fixed>> result = acpi_add_single_object(&device, NULL, ACPI_BUS_TYPE_SLEEP_BUTTON, false);
+	 */
 	acpi_add_single_object(&device, handle, type, !check_dep);
 	if (!device)
 		return AE_CTRL_DEPTH;
@@ -2078,12 +2228,26 @@ static acpi_status acpi_bus_check_add(acpi_handle handle, bool check_dep,
 static acpi_status acpi_bus_check_add_1(acpi_handle handle, u32 lvl_not_used,
 					void *not_used, void **ret_p)
 {
+	/*
+	 * 在以下使用acpi_bus_check_add():
+	 *   - drivers/acpi/scan.c|2198| <<acpi_bus_check_add_1>> return acpi_bus_check_add(handle, true, (struct acpi_device **)ret_p);
+	 *   - drivers/acpi/scan.c|2204| <<acpi_bus_check_add_2>> return acpi_bus_check_add(handle, false, (struct acpi_device **)ret_p);
+	 *   - drivers/acpi/scan.c|2494| <<acpi_bus_scan>> if (ACPI_SUCCESS(acpi_bus_check_add(handle, true, &device)))
+	 *   - drivers/acpi/scan.c|2511| <<acpi_bus_scan>> if (ACPI_SUCCESS(acpi_bus_check_add(handle, false, &device)))
+	 */
 	return acpi_bus_check_add(handle, true, (struct acpi_device **)ret_p);
 }
 
 static acpi_status acpi_bus_check_add_2(acpi_handle handle, u32 lvl_not_used,
 					void *not_used, void **ret_p)
 {
+	/*
+	 * 在以下使用acpi_bus_check_add():
+	 *   - drivers/acpi/scan.c|2198| <<acpi_bus_check_add_1>> return acpi_bus_check_add(handle, true, (struct acpi_device **)ret_p);
+	 *   - drivers/acpi/scan.c|2204| <<acpi_bus_check_add_2>> return acpi_bus_check_add(handle, false, (struct acpi_device **)ret_p);
+	 *   - drivers/acpi/scan.c|2494| <<acpi_bus_scan>> if (ACPI_SUCCESS(acpi_bus_check_add(handle, true, &device)))
+	 *   - drivers/acpi/scan.c|2511| <<acpi_bus_scan>> if (ACPI_SUCCESS(acpi_bus_check_add(handle, false, &device)))
+	 */
 	return acpi_bus_check_add(handle, false, (struct acpi_device **)ret_p);
 }
 
@@ -2374,6 +2538,13 @@ int acpi_bus_scan(acpi_handle handle)
 
 	/* Pass 1: Avoid enumerating devices with missing dependencies. */
 
+	/*
+	 * 在以下使用acpi_bus_check_add():
+	 *   - drivers/acpi/scan.c|2198| <<acpi_bus_check_add_1>> return acpi_bus_check_add(handle, true, (struct acpi_device **)ret_p);
+	 *   - drivers/acpi/scan.c|2204| <<acpi_bus_check_add_2>> return acpi_bus_check_add(handle, false, (struct acpi_device **)ret_p);
+	 *   - drivers/acpi/scan.c|2494| <<acpi_bus_scan>> if (ACPI_SUCCESS(acpi_bus_check_add(handle, true, &device)))
+	 *   - drivers/acpi/scan.c|2511| <<acpi_bus_scan>> if (ACPI_SUCCESS(acpi_bus_check_add(handle, false, &device)))
+	 */
 	if (ACPI_SUCCESS(acpi_bus_check_add(handle, true, &device)))
 		acpi_walk_namespace(ACPI_TYPE_ANY, handle, ACPI_UINT32_MAX,
 				    acpi_bus_check_add_1, NULL, NULL,
@@ -2391,6 +2562,13 @@ int acpi_bus_scan(acpi_handle handle)
 
 	device = NULL;
 
+	/*
+	 * 在以下使用acpi_bus_check_add():
+	 *   - drivers/acpi/scan.c|2198| <<acpi_bus_check_add_1>> return acpi_bus_check_add(handle, true, (struct acpi_device **)ret_p);
+	 *   - drivers/acpi/scan.c|2204| <<acpi_bus_check_add_2>> return acpi_bus_check_add(handle, false, (struct acpi_device **)ret_p);
+	 *   - drivers/acpi/scan.c|2494| <<acpi_bus_scan>> if (ACPI_SUCCESS(acpi_bus_check_add(handle, true, &device)))
+	 *   - drivers/acpi/scan.c|2511| <<acpi_bus_scan>> if (ACPI_SUCCESS(acpi_bus_check_add(handle, false, &device)))
+	 */
 	if (ACPI_SUCCESS(acpi_bus_check_add(handle, false, &device)))
 		acpi_walk_namespace(ACPI_TYPE_ANY, handle, ACPI_UINT32_MAX,
 				    acpi_bus_check_add_2, NULL, NULL,
@@ -2435,11 +2613,22 @@ void acpi_bus_trim(struct acpi_device *adev)
 }
 EXPORT_SYMBOL_GPL(acpi_bus_trim);
 
+/*
+ * 在以下调用acpi_bus_register_early_device():
+ *   - drivers/acpi/ec.c|1835| <<acpi_ec_ecdt_start>> acpi_bus_register_early_device(ACPI_BUS_TYPE_ECDT_EC);
+ */
 int acpi_bus_register_early_device(int type)
 {
 	struct acpi_device *device = NULL;
 	int result;
 
+	/*
+	 * 在以下使用acpi_add_single_object():
+	 *   - drivers/acpi/scan.c|2182| <<acpi_bus_check_add>> acpi_add_single_object(&device, handle, type, !check_dep);
+	 *   - drivers/acpi/scan.c|2560| <<acpi_bus_register_early_device>> result = acpi_add_single_object(&device, NULL, type, false);
+	 *   - drivers/acpi/scan.c|2579| <<acpi_bus_scan_fixed>> result = acpi_add_single_object(&device, NULL, ACPI_BUS_TYPE_POWER_BUTTON, false);
+	 *   - drivers/acpi/scan.c|2595| <<acpi_bus_scan_fixed>> result = acpi_add_single_object(&device, NULL, ACPI_BUS_TYPE_SLEEP_BUTTON, false);
+	 */
 	result = acpi_add_single_object(&device, NULL, type, false);
 	if (result)
 		return result;
@@ -2459,6 +2648,13 @@ static int acpi_bus_scan_fixed(void)
 	if (!(acpi_gbl_FADT.flags & ACPI_FADT_POWER_BUTTON)) {
 		struct acpi_device *device = NULL;
 
+		/*
+		 * 在以下使用acpi_add_single_object():
+		 *   - drivers/acpi/scan.c|2182| <<acpi_bus_check_add>> acpi_add_single_object(&device, handle, type, !check_dep);
+		 *   - drivers/acpi/scan.c|2560| <<acpi_bus_register_early_device>> result = acpi_add_single_object(&device, NULL, type, false);
+		 *   - drivers/acpi/scan.c|2579| <<acpi_bus_scan_fixed>> result = acpi_add_single_object(&device, NULL, ACPI_BUS_TYPE_POWER_BUTTON, false);
+		 *   - drivers/acpi/scan.c|2595| <<acpi_bus_scan_fixed>> result = acpi_add_single_object(&device, NULL, ACPI_BUS_TYPE_SLEEP_BUTTON, false);
+		 */
 		result = acpi_add_single_object(&device, NULL,
 						ACPI_BUS_TYPE_POWER_BUTTON, false);
 		if (result)
@@ -2475,6 +2671,13 @@ static int acpi_bus_scan_fixed(void)
 	if (!(acpi_gbl_FADT.flags & ACPI_FADT_SLEEP_BUTTON)) {
 		struct acpi_device *device = NULL;
 
+		/*
+		 * 在以下使用acpi_add_single_object():
+		 *   - drivers/acpi/scan.c|2182| <<acpi_bus_check_add>> acpi_add_single_object(&device, handle, type, !check_dep);
+		 *   - drivers/acpi/scan.c|2560| <<acpi_bus_register_early_device>> result = acpi_add_single_object(&device, NULL, type, false);
+		 *   - drivers/acpi/scan.c|2579| <<acpi_bus_scan_fixed>> result = acpi_add_single_object(&device, NULL, ACPI_BUS_TYPE_POWER_BUTTON, false);
+		 *   - drivers/acpi/scan.c|2595| <<acpi_bus_scan_fixed>> result = acpi_add_single_object(&device, NULL, ACPI_BUS_TYPE_SLEEP_BUTTON, false);
+		 */
 		result = acpi_add_single_object(&device, NULL,
 						ACPI_BUS_TYPE_SLEEP_BUTTON, false);
 		if (result)
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/eq.c b/drivers/net/ethernet/mellanox/mlx5/core/eq.c
index 6e3a51046560..8df7db2d768c 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/eq.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eq.c
@@ -1210,6 +1210,12 @@ mlx5_comp_irq_get_affinity_mask(struct mlx5_core_dev *dev, int vector)
 	return NULL;
 }
 
+/*
+ * 在以下调用mlx5_comp_vector_get_cpu():
+ *   - drivers/net/ethernet/mellanox/mlx5/core/en/trap.c|133| <<mlx5e_open_trap>> int cpu = mlx5_comp_vector_get_cpu(priv->mdev, 0);
+ *   - drivers/net/ethernet/mellanox/mlx5/core/en_main.c|2532| <<mlx5e_open_channel>> int cpu = mlx5_comp_vector_get_cpu(priv->mdev, ix);
+ *   - drivers/net/ethernet/mellanox/mlx5/core/en_main.c|2950| <<mlx5e_set_default_xps_cpumasks>> int cpu = mlx5_comp_vector_get_cpu(mdev, irq);
+ */
 int mlx5_comp_vector_get_cpu(struct mlx5_core_dev *dev, int vector)
 {
 	struct cpumask *mask;
diff --git a/drivers/pci/hotplug/acpiphp_glue.c b/drivers/pci/hotplug/acpiphp_glue.c
index f031302ad401..142b19e133c9 100644
--- a/drivers/pci/hotplug/acpiphp_glue.c
+++ b/drivers/pci/hotplug/acpiphp_glue.c
@@ -56,6 +56,10 @@ static void free_bridge(struct kref *kref);
  *
  * Call under acpi_hp_context_lock.
  */
+/*
+ * 在以下使用acpiphp_init_context():
+ *   - drivers/pci/hotplug/acpiphp_glue.c|255| <<acpiphp_add_context>> context = acpiphp_init_context(adev);
+ */
 static struct acpiphp_context *acpiphp_init_context(struct acpi_device *adev)
 {
 	struct acpiphp_context *context;
@@ -117,12 +121,28 @@ static inline void put_bridge(struct acpiphp_bridge *bridge)
 	kref_put(&bridge->ref, free_bridge);
 }
 
+/*
+ * 在以下调用acpiphp_grab_context():
+ *   - drivers/pci/hotplug/acpiphp_glue.c|195| <<acpiphp_post_dock_fixup>> struct acpiphp_context *context = acpiphp_grab_context(adev);
+ *   - drivers/pci/hotplug/acpiphp_glue.c|861| <<acpiphp_hotplug_notify>> context = acpiphp_grab_context(adev);
+ */
 static struct acpiphp_context *acpiphp_grab_context(struct acpi_device *adev)
 {
 	struct acpiphp_context *context;
 
 	acpi_lock_hp_context();
 
+	/*
+	 * struct acpi_device *adev:
+	 * -> struct acpi_hotplug_context *hp;
+	 *
+	 * struct acpiphp_context {
+	 *     struct acpi_hotplug_context hp;
+	 *     struct acpiphp_func func;
+	 *     struct acpiphp_bridge *bridge;
+	 *     unsigned int refcount;
+	 * };
+	 */
 	context = acpiphp_get_context(adev);
 	if (!context)
 		goto unlock;
@@ -223,6 +243,10 @@ static void acpiphp_post_dock_fixup(struct acpi_device *adev)
  * @data: The object's parent ACPIPHP bridge.
  * @rv: Not used.
  */
+/*
+ * 在以下使用acpiphp_add_context():
+ *   - drivers/pci/hotplug/acpiphp_glue.c|916| <<acpiphp_enumerate_slots>> acpiphp_add_context, NULL, bridge, NULL);
+ */
 static acpi_status acpiphp_add_context(acpi_handle handle, u32 lvl, void *data,
 				       void **rv)
 {
@@ -771,10 +795,31 @@ void acpiphp_check_host_bridge(struct acpi_device *adev)
 
 static int acpiphp_disable_and_eject_slot(struct acpiphp_slot *slot);
 
+/*
+ * 在以下调用hotplug_event():
+ *   - drivers/pci/hotplug/acpiphp_glue.c|836| <<acpiphp_hotplug_notify>> hotplug_event(type, context);
+ */
 static void hotplug_event(u32 type, struct acpiphp_context *context)
 {
+	/*
+	 * struct acpiphp_context *context:
+	 * -> struct acpi_hotplug_context hp;
+	 *    -> struct acpi_device *self;
+	 */
 	acpi_handle handle = context->hp.self->handle;
 	struct acpiphp_func *func = &context->func;
+	/*
+	 * struct acpiphp_slot {
+	 *     struct list_head node;
+	 *     struct pci_bus *bus;
+	 *     struct list_head funcs;          one slot may have different
+         *                                      objects (i.e. for each function)
+	 *     struct slot *slot;
+	 *
+	 *     u8              device;         // pci device# 
+	 *     u32             flags;          // see below 
+	 * };
+	 */
 	struct acpiphp_slot *slot = func->slot;
 	struct acpiphp_bridge *bridge;
 
@@ -825,14 +870,34 @@ static void hotplug_event(u32 type, struct acpiphp_context *context)
 		put_bridge(bridge);
 }
 
+/*
+ * [0] acpiphp_hotplug_notify
+ * [0] acpi_device_hotplug
+ * [0] acpi_hotplug_work_fn
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * 在以下使用acpiphp_hotplug_notify():
+ *   - drivers/pci/hotplug/acpiphp_glue.c|72| <<acpiphp_init_context>> context->hp.notify = acpiphp_hotplug_notify;
+ */
 static int acpiphp_hotplug_notify(struct acpi_device *adev, u32 type)
 {
 	struct acpiphp_context *context;
 
+	/*
+	 * 在以下调用acpiphp_grab_context():
+	 *   - drivers/pci/hotplug/acpiphp_glue.c|195| <<acpiphp_post_dock_fixup>> struct acpiphp_context *context = acpiphp_grab_context(adev);
+	 *   - drivers/pci/hotplug/acpiphp_glue.c|861| <<acpiphp_hotplug_notify>> context = acpiphp_grab_context(adev);
+	 */
 	context = acpiphp_grab_context(adev);
 	if (!context)
 		return -ENODATA;
 
+	/*
+	 * 只在此处调用
+	 */
 	hotplug_event(type, context);
 	acpiphp_let_context_go(context);
 	return 0;
@@ -845,6 +910,35 @@ static int acpiphp_hotplug_notify(struct acpi_device *adev, u32 type)
  * A "slot" is an object associated with a PCI device number.  All functions
  * (PCI devices) with the same bus and device number belong to the same slot.
  */
+/*
+ * [0] acpiphp_init_context
+ * [0] acpiphp_add_context
+ * [0] acpi_ns_walk_namespace
+ * [0] acpi_walk_namespace
+ * [0] acpiphp_enumerate_slots
+ * [0] acpi_pci_add_bus
+ * [0] pci_alloc_child_bus
+ * [0] pci_scan_bridge_extend
+ * [0] pci_scan_child_bus_extend
+ * [0] acpi_pci_root_create
+ * [0] pci_acpi_scan_root
+ * [0] acpi_pci_root_add
+ * [0] acpi_bus_attach
+ * [0] acpi_bus_attach
+ * [0] acpi_bus_attach
+ * [0] acpi_bus_scan
+ * [0] acpi_scan_init
+ * [0] acpi_init
+ * [0] do_one_initcall
+ * [0] kernel_init_freeable
+ * [0] kernel_init
+ * [0] ret_from_fork
+ *
+ * 在以下调用acpiphp_enumerate_slots():
+ *   - drivers/pci/pci-acpi.c|1170| <<acpi_pci_add_bus>> acpiphp_enumerate_slots(bus);
+ *
+ * acpiphp_enumerate_slots()针对每一个bus调用一次
+ */
 void acpiphp_enumerate_slots(struct pci_bus *bus)
 {
 	struct acpiphp_bridge *bridge;
diff --git a/drivers/pci/pci-acpi.c b/drivers/pci/pci-acpi.c
index 8f4a4fc48efa..3210cfa3389a 100644
--- a/drivers/pci/pci-acpi.c
+++ b/drivers/pci/pci-acpi.c
@@ -935,6 +935,10 @@ static pci_power_t acpi_pci_choose_state(struct pci_dev *pdev)
 
 static struct acpi_device *acpi_pci_find_companion(struct device *dev);
 
+/*
+ * 在以下使用pci_set_acpi_fwnode():
+ *   - drivers/pci/probe.c|1855| <<pci_setup_device>> pci_set_acpi_fwnode(dev);
+ */
 void pci_set_acpi_fwnode(struct pci_dev *dev)
 {
 	if (!dev_fwnode(&dev->dev) && !pci_dev_is_added(dev))
diff --git a/include/linux/kvm_host.h b/include/linux/kvm_host.h
index d6b37eef1b32..8d2f613b8485 100644
--- a/include/linux/kvm_host.h
+++ b/include/linux/kvm_host.h
@@ -753,6 +753,23 @@ struct kvm {
 	struct srcu_struct irq_srcu;
 	pid_t userspace_pid;
 	unsigned int max_halt_poll_ns;
+	/*
+	 * 在以下使用kvm->dirty_ring_size:
+	 *   - arch/x86/kvm/x86.c|10381| <<vcpu_enter_guest>> if (unlikely(vcpu->kvm->dirty_ring_size &&
+	 *   - virt/kvm/kvm_main.c|1563| <<kvm_prepare_memory_region>> else if (!kvm->dirty_ring_size) {
+	 *   - virt/kvm/kvm_main.c|2007| <<kvm_get_dirty_log>> if (kvm->dirty_ring_size)
+	 *   - virt/kvm/kvm_main.c|2072| <<kvm_get_dirty_log_protect>> if (kvm->dirty_ring_size)
+	 *   - virt/kvm/kvm_main.c|2184| <<kvm_clear_dirty_log_protect>> if (kvm->dirty_ring_size)
+	 *   - virt/kvm/kvm_main.c|3302| <<mark_page_dirty_in_slot>> if (kvm->dirty_ring_size)
+	 *   - virt/kvm/kvm_main.c|3706| <<kvm_page_in_dirty_ring>> return (pgoff >= KVM_DIRTY_LOG_PAGE_OFFSET)
+	 *           && (pgoff < KVM_DIRTY_LOG_PAGE_OFFSET + kvm->dirty_ring_size / PAGE_SIZE);
+	 *   - virt/kvm/kvm_main.c|3849| <<kvm_vm_ioctl_create_vcpu>> if (kvm->dirty_ring_size) {
+	 *   - virt/kvm/kvm_main.c|3851| <<kvm_vm_ioctl_create_vcpu>> r = kvm_dirty_ring_alloc(&vcpu->dirty_ring, 
+	 *           id, kvm->dirty_ring_size);
+	 *   - virt/kvm/kvm_main.c|4459| <<kvm_vm_ioctl_enable_dirty_log_ring>> if (kvm->dirty_ring_size)
+	 *   - virt/kvm/kvm_main.c|4468| <<kvm_vm_ioctl_enable_dirty_log_ring>> kvm->dirty_ring_size = size;
+	 *   - virt/kvm/kvm_main.c|4482| <<kvm_vm_ioctl_reset_dirty_pages>> if (!kvm->dirty_ring_size)
+	 */
 	u32 dirty_ring_size;
 	bool vm_bugged;
 	bool vm_dead;
@@ -842,6 +859,9 @@ static inline struct kvm_vcpu *kvm_get_vcpu(struct kvm *kvm, int i)
 	return kvm->vcpus[i];
 }
 
+/*
+ * 在kvm_vm_ioctl_create_vcpu()增加kvm->online_vcpus.
+ */
 #define kvm_for_each_vcpu(idx, vcpup, kvm) \
 	for (idx = 0; \
 	     idx < atomic_read(&kvm->online_vcpus) && \
@@ -1877,6 +1897,18 @@ static inline void kvm_make_request(int req, struct kvm_vcpu *vcpu)
 	set_bit(req & KVM_REQUEST_MASK, (void *)&vcpu->requests);
 }
 
+/*
+ * 在以下调用kvm_request_pending():
+ *   - arch/arm64/kvm/arm.c|682| <<check_vcpu_requests>> if (kvm_request_pending(vcpu)) {
+ *   - arch/arm64/kvm/arm.c|754| <<kvm_vcpu_exit_request>> return kvm_request_pending(vcpu) ||
+ *   - arch/mips/kvm/vz.c|2433| <<kvm_vz_check_requests>> if (!kvm_request_pending(vcpu))
+ *   - arch/powerpc/kvm/booke.c|714| <<kvmppc_core_prepare_to_enter>> if (kvm_request_pending(vcpu)) {
+ *   - arch/powerpc/kvm/powerpc.c|51| <<kvm_arch_vcpu_runnable>> return !!(v->arch.pending_exceptions) || kvm_request_pending(v);
+ *   - arch/powerpc/kvm/powerpc.c|113| <<kvmppc_prepare_to_enter>> if (kvm_request_pending(vcpu)) {
+ *   - arch/s390/kvm/kvm-s390.c|3824| <<kvm_s390_handle_requests>> if (!kvm_request_pending(vcpu))
+ *   - arch/x86/kvm/x86.c|2116| <<kvm_vcpu_exit_request>> return vcpu->mode == EXITING_GUEST_MODE || kvm_request_pending(vcpu) ||
+ *   - arch/x86/kvm/x86.c|10389| <<vcpu_enter_guest>> if (kvm_request_pending(vcpu)) {
+ */
 static inline bool kvm_request_pending(struct kvm_vcpu *vcpu)
 {
 	return READ_ONCE(vcpu->requests);
diff --git a/include/linux/sched.h b/include/linux/sched.h
index 7a9e7c52d323..b1e80c66ebf6 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -938,6 +938,12 @@ struct task_struct {
 	UEK_KABI_RENAME(unsigned in_eventfd_signal, unsigned in_eventfd):1;
 #endif
 #ifdef	CONFIG_CPU_SUP_INTEL
+	/*
+	 * 在以下使用task_struct->reported_split_lock:
+	 *   - arch/x86/kernel/cpu/intel.c|1373| <<split_lock_warn>> if (!current->reported_split_lock)
+	 *   - arch/x86/kernel/cpu/intel.c|1376| <<split_lock_warn>> current->reported_split_lock = 1;
+	 *   - kernel/fork.c|989| <<dup_task_struct>> tsk->reported_split_lock = 0;
+	 */
 	UEK_KABI_FILL_HOLE(unsigned reported_split_lock:1)
 #endif
 
diff --git a/virt/kvm/eventfd.c b/virt/kvm/eventfd.c
index 37e3a49f4e76..15903171bac7 100644
--- a/virt/kvm/eventfd.c
+++ b/virt/kvm/eventfd.c
@@ -338,6 +338,9 @@ kvm_irqfd_assign(struct kvm *kvm, struct kvm_irqfd *args)
 
 		mutex_lock(&kvm->irqfds.resampler_lock);
 
+		/*
+		 * 似乎resampler_list也基本不怎么用
+		 */
 		list_for_each_entry(resampler,
 				    &kvm->irqfds.resampler_list, link) {
 			if (resampler->notifier.gsi == irqfd->gsi) {
@@ -448,6 +451,10 @@ kvm_irqfd_assign(struct kvm *kvm, struct kvm_irqfd *args)
 	return ret;
 }
 
+/*
+ * 在以下使用kvm_irq_has_notifier():
+ *   - arch/x86/kvm/ioapic.c|448| <<kvm_ioapic_scan_entry>> kvm_irq_has_notifier(ioapic->kvm, KVM_IRQCHIP_IOAPIC, index) ||
+ */
 bool kvm_irq_has_notifier(struct kvm *kvm, unsigned irqchip, unsigned pin)
 {
 	struct kvm_irq_ack_notifier *kian;
@@ -455,6 +462,9 @@ bool kvm_irq_has_notifier(struct kvm *kvm, unsigned irqchip, unsigned pin)
 
 	idx = srcu_read_lock(&kvm->irq_srcu);
 	gsi = kvm_irq_map_chip_pin(kvm, irqchip, pin);
+	/*
+	 * 似乎irq_ack_notifier_list不怎么用
+	 */
 	if (gsi != -1)
 		hlist_for_each_entry_srcu(kian, &kvm->irq_ack_notifier_list,
 					  link, srcu_read_lock_held(&kvm->irq_srcu))
@@ -828,6 +838,30 @@ static int kvm_assign_ioeventfd_idx(struct kvm *kvm,
 
 	kvm_iodevice_init(&p->dev, &ioeventfd_ops);
 
+	/*
+	 * 在以下使用kvm_io_bus_register_dev():
+	 *   - arch/arm64/kvm/vgic/vgic-its.c|1840| <<vgic_register_its_iodev>> ret = kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS,
+	 *                    iodev->base_addr, KVM_VGIC_V3_ITS_SIZE, &iodev->dev);
+	 *   - arch/arm64/kvm/vgic/vgic-mmio-v3.c|743| <<vgic_register_redist_iodev>> ret = kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS,
+	 *                    rd_base, 2 * SZ_64K, &rd_dev->dev);
+	 *   - arch/arm64/kvm/vgic/vgic-mmio.c|1096| <<vgic_register_dist_iodev>> ret = kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS,
+	 *                    dist_base_address, len, &io_device->dev);
+	 *   - arch/mips/kvm/loongson_ipi.c|209| <<kvm_init_loongson_ipi>> kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS, addr, 0x400, device);
+	 *   - arch/powerpc/kvm/mpic.c|1449| <<map_mmio>> kvm_io_bus_register_dev(opp->kvm, KVM_MMIO_BUS,
+	 *                    opp->reg_base, OPENPIC_REG_SIZE, &opp->mmio);
+	 *   - arch/x86/kvm/i8254.c|705| <<kvm_create_pit>> ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS,
+	 *                    KVM_PIT_BASE_ADDRESS, KVM_PIT_MEM_LENGTH, &pit->dev);
+	 *   - arch/x86/kvm/i8254.c|712| <<kvm_create_pit>> ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS,
+	 *                    KVM_SPEAKER_BASE_ADDRESS, 4, &pit->speaker_dev);
+	 *   - arch/x86/kvm/i8259.c|607| <<kvm_pic_init>> ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS, 0x20, 2, &s->dev_master);
+	 *   - arch/x86/kvm/i8259.c|612| <<kvm_pic_init>> ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS, 0xa0, 2, &s->dev_slave);
+	 *   - arch/x86/kvm/i8259.c|616| <<kvm_pic_init>> ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS, 0x4d0, 2, &s->dev_elcr);
+	 *   - arch/x86/kvm/ioapic.c|1014| <<kvm_ioapic_init>> ret = kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS,
+	 *                    ioapic->base_address, IOAPIC_MEM_LENGTH, &ioapic->dev);
+	 *   - virt/kvm/coalesced_mmio.c|156| <<kvm_vm_ioctl_register_coalesced_mmio>> ret = kvm_io_bus_register_dev(kvm,
+	 *                    zone->pio ? KVM_PIO_BUS : KVM_MMIO_BUS, zone->addr, zone->size, &dev->dev);
+	 *   - virt/kvm/eventfd.c|841| <<kvm_assign_ioeventfd_idx>> ret = kvm_io_bus_register_dev(kvm, bus_idx, p->addr, p->length, &p->dev);
+	 */
 	ret = kvm_io_bus_register_dev(kvm, bus_idx, p->addr, p->length,
 				      &p->dev);
 	if (ret < 0)
diff --git a/virt/kvm/irqchip.c b/virt/kvm/irqchip.c
index 79dcd4cd5c60..a5e47aa32c03 100644
--- a/virt/kvm/irqchip.c
+++ b/virt/kvm/irqchip.c
@@ -66,6 +66,17 @@ int kvm_send_userspace_msi(struct kvm *kvm, struct kvm_msi *msi)
 	return kvm_set_msi(&route, kvm, KVM_USERSPACE_IRQ_SOURCE_ID, 1, false);
 }
 
+/*
+ * 在以下调用kvm_set_irq():
+ *   - arch/x86/kvm/i8254.c|251| <<pit_do_work>> kvm_set_irq(kvm, pit->irq_source_id, 0, 1, false);
+ *   - arch/x86/kvm/i8254.c|252| <<pit_do_work>> kvm_set_irq(kvm, pit->irq_source_id, 0, 0, false);
+ *   - arch/x86/kvm/x86.c|6014| <<kvm_vm_ioctl_irq_line>> irq_event->status = kvm_set_irq(kvm, KVM_USERSPACE_IRQ_SOURCE_ID, irq_event->irq, irq_event->level, line_status);
+ *   - virt/kvm/eventfd.c|49| <<irqfd_inject>> kvm_set_irq(kvm, KVM_USERSPACE_IRQ_SOURCE_ID, irqfd->gsi, 1, false);
+ *   - virt/kvm/eventfd.c|51| <<irqfd_inject>> kvm_set_irq(kvm, KVM_USERSPACE_IRQ_SOURCE_ID, irqfd->gsi, 0, false);
+ *   - virt/kvm/eventfd.c|54| <<irqfd_inject>> kvm_set_irq(kvm, KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID, irqfd->gsi, 1, false);
+ *   - virt/kvm/eventfd.c|75| <<irqfd_resampler_ack>> kvm_set_irq(kvm, KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID, resampler->notifier.gsi, 0, false);
+ *   - virt/kvm/eventfd.c|100| <<irqfd_resampler_shutdown>> kvm_set_irq(kvm, KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID, resampler->notifier.gsi, 0, false);
+ */
 /*
  * Return value:
  *  < 0   Interrupt was ignored (masked or not delivered for other reasons)
@@ -75,6 +86,12 @@ int kvm_send_userspace_msi(struct kvm *kvm, struct kvm_msi *msi)
 int kvm_set_irq(struct kvm *kvm, int irq_source_id, u32 irq, int level,
 		bool line_status)
 {
+	/*
+	 * #define KVM_IRQCHIP_PIC_MASTER   0
+	 * #define KVM_IRQCHIP_PIC_SLAVE    1
+	 * #define KVM_IRQCHIP_IOAPIC       2
+	 * #define KVM_NR_IRQCHIPS          3
+	 */
 	struct kvm_kernel_irq_routing_entry irq_set[KVM_NR_IRQCHIPS];
 	int ret = -1, i, idx;
 
@@ -170,6 +187,41 @@ bool __weak kvm_arch_can_set_irq_routing(struct kvm *kvm)
 	return true;
 }
 
+/*
+ * 265 把irq从CPU=5换到CPU=6上.
+ * 266
+ * 267        CPU 5/KVM-51857   [011] ..... 435912.873065: vfio_pci_set_msi_trigger <-vfio_pci_core_ioctl
+ * 268        CPU 5/KVM-51857   [011] ..... 435912.873068: vfio_msi_set_vector_signal <-vfio_msi_set_block
+ * 269        CPU 5/KVM-51857   [011] ..... 435912.873069: irq_bypass_unregister_producer <-vfio_msi_set_vector_signal
+ * 270        CPU 5/KVM-51857   [011] ..... 435912.873070: kvm_arch_irq_bypass_del_producer <-__disconnect
+ * 271        CPU 5/KVM-51857   [011] ..... 435912.873070: vmx_pi_update_irte <-kvm_arch_irq_bypass_del_producer
+ * 272        CPU 5/KVM-51857   [011] ..... 435912.873102: irq_bypass_register_producer <-vfio_msi_set_vector_signal
+ * 273
+ * 274        CPU 5/KVM-51857   [011] ..... 435912.873255: kvm_set_irq_routing <-kvm_vm_ioctl
+ * 275        CPU 5/KVM-51857   [011] ..... 435912.873263: kvm_irq_routing_update <-kvm_set_irq_routing
+ * 276        CPU 5/KVM-51857   [011] d.... 435912.873263: irqfd_update <-kvm_irq_routing_update
+ * 277        CPU 5/KVM-51857   [011] d.... 435912.873264: kvm_arch_update_irqfd_routing <-kvm_irq_routing_update
+ * 278        CPU 5/KVM-51857   [011] d.... 435912.873264: vmx_pi_update_irte <-kvm_irq_routing_update
+ * 279        CPU 5/KVM-51857   [011] d.... 435912.873266: irqfd_update <-kvm_irq_routing_update
+ * 280        CPU 5/KVM-51857   [011] d.... 435912.873266: irqfd_update <-kvm_irq_routing_update
+ * 281        CPU 5/KVM-51857   [011] d.... 435912.873266: kvm_arch_update_irqfd_routing <-kvm_irq_routing_update
+ * 282        CPU 5/KVM-51857   [011] d.... 435912.873266: vmx_pi_update_irte <-kvm_irq_routing_update
+ * 283
+ * 284        CPU 5/KVM-51857   [011] ..... 435912.873290: vfio_pci_set_msi_trigger <-vfio_pci_core_ioctl
+ * 285        CPU 5/KVM-51857   [011] ..... 435912.873291: vfio_msi_set_vector_signal <-vfio_msi_set_block
+ * 286        CPU 5/KVM-51857   [011] ..... 435912.873291: irq_bypass_unregister_producer <-vfio_msi_set_vector_signal
+ * 287        CPU 5/KVM-51857   [011] ..... 435912.873311: irq_bypass_register_producer <-vfio_msi_set_vector_signal
+ * 288        CPU 5/KVM-51857   [011] ..... 435912.873312: kvm_arch_irq_bypass_add_producer <-__connect
+ * 289        CPU 5/KVM-51857   [011] ..... 435912.873312: vmx_pi_update_irte <-kvm_arch_irq_bypass_add_producer
+ *
+ * Add或者Del vCPU会调用:
+ *
+ * kvm_set_irq_routing
+ * kvm_vm_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ */
 int kvm_set_irq_routing(struct kvm *kvm,
 			const struct kvm_irq_routing_entry *ue,
 			unsigned nr,
diff --git a/virt/kvm/kvm_main.c b/virt/kvm/kvm_main.c
index 36896443375a..43677f994fdc 100644
--- a/virt/kvm/kvm_main.c
+++ b/virt/kvm/kvm_main.c
@@ -438,6 +438,10 @@ void *kvm_mmu_memory_cache_alloc(struct kvm_mmu_memory_cache *mc)
 }
 #endif
 
+/*
+ * 在以下调用kvm_vcpu_init():
+ *   - virt/kvm/kvm_main.c|3835| <<kvm_vm_ioctl_create_vcpu>> kvm_vcpu_init(vcpu, kvm, id);
+ */
 static void kvm_vcpu_init(struct kvm_vcpu *vcpu, struct kvm *kvm, unsigned id)
 {
 	mutex_init(&vcpu->mutex);
@@ -3420,6 +3424,13 @@ update_halt_poll_stats(struct kvm_vcpu *vcpu, u64 poll_ns, bool waited)
 /*
  * The vCPU has executed a HLT instruction with in-kernel mode enabled.
  */
+/*
+ * x86和arm在以下使用kvm_vcpu_block():
+ *   - arch/arm64/kvm/handle_exit.c|98| <<kvm_handle_wfx>> kvm_vcpu_block(vcpu);
+ *   - arch/arm64/kvm/psci.c|49| <<kvm_psci_vcpu_suspend>> kvm_vcpu_block(vcpu);
+ *   - arch/x86/kvm/x86.c|11226| <<vcpu_block>> kvm_vcpu_block(vcpu);
+ *   - arch/x86/kvm/x86.c|11445| <<kvm_arch_vcpu_ioctl_run>> kvm_vcpu_block(vcpu);
+ */
 void kvm_vcpu_block(struct kvm_vcpu *vcpu)
 {
 	bool halt_poll_allowed = !kvm_arch_no_poll(vcpu);
@@ -3796,6 +3807,10 @@ static void kvm_create_vcpu_debugfs(struct kvm_vcpu *vcpu)
 /*
  * Creates some virtual cpus.  Good luck creating more than one.
  */
+/*
+ * 在以下调用kvm_vm_ioctl_create_vcpu():
+ *   - virt/kvm/kvm_main.c|4593| <<kvm_vm_ioctl(KVM_CREATE_VCPU)>> r = kvm_vm_ioctl_create_vcpu(kvm, arg);
+ */
 static int kvm_vm_ioctl_create_vcpu(struct kvm *kvm, u32 id)
 {
 	int r;
@@ -5240,6 +5255,30 @@ int kvm_io_bus_read(struct kvm_vcpu *vcpu, enum kvm_bus bus_idx, gpa_t addr,
 	return r < 0 ? r : 0;
 }
 
+/*
+ * 在以下使用kvm_io_bus_register_dev():
+ *   - arch/arm64/kvm/vgic/vgic-its.c|1840| <<vgic_register_its_iodev>> ret = kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS,
+ *                    iodev->base_addr, KVM_VGIC_V3_ITS_SIZE, &iodev->dev);
+ *   - arch/arm64/kvm/vgic/vgic-mmio-v3.c|743| <<vgic_register_redist_iodev>> ret = kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS,
+ *                    rd_base, 2 * SZ_64K, &rd_dev->dev);
+ *   - arch/arm64/kvm/vgic/vgic-mmio.c|1096| <<vgic_register_dist_iodev>> ret = kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS,
+ *                    dist_base_address, len, &io_device->dev);
+ *   - arch/mips/kvm/loongson_ipi.c|209| <<kvm_init_loongson_ipi>> kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS, addr, 0x400, device);
+ *   - arch/powerpc/kvm/mpic.c|1449| <<map_mmio>> kvm_io_bus_register_dev(opp->kvm, KVM_MMIO_BUS,
+ *                    opp->reg_base, OPENPIC_REG_SIZE, &opp->mmio);
+ *   - arch/x86/kvm/i8254.c|705| <<kvm_create_pit>> ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS,
+ *                    KVM_PIT_BASE_ADDRESS, KVM_PIT_MEM_LENGTH, &pit->dev);
+ *   - arch/x86/kvm/i8254.c|712| <<kvm_create_pit>> ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS,
+ *                    KVM_SPEAKER_BASE_ADDRESS, 4, &pit->speaker_dev);
+ *   - arch/x86/kvm/i8259.c|607| <<kvm_pic_init>> ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS, 0x20, 2, &s->dev_master);
+ *   - arch/x86/kvm/i8259.c|612| <<kvm_pic_init>> ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS, 0xa0, 2, &s->dev_slave);
+ *   - arch/x86/kvm/i8259.c|616| <<kvm_pic_init>> ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS, 0x4d0, 2, &s->dev_elcr);
+ *   - arch/x86/kvm/ioapic.c|1014| <<kvm_ioapic_init>> ret = kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS,
+ *                    ioapic->base_address, IOAPIC_MEM_LENGTH, &ioapic->dev);
+ *   - virt/kvm/coalesced_mmio.c|156| <<kvm_vm_ioctl_register_coalesced_mmio>> ret = kvm_io_bus_register_dev(kvm,
+ *                    zone->pio ? KVM_PIO_BUS : KVM_MMIO_BUS, zone->addr, zone->size, &dev->dev);
+ *   - virt/kvm/eventfd.c|841| <<kvm_assign_ioeventfd_idx>> ret = kvm_io_bus_register_dev(kvm, bus_idx, p->addr, p->length, &p->dev);
+ */
 /* Caller must hold slots_lock. */
 int kvm_io_bus_register_dev(struct kvm *kvm, enum kvm_bus bus_idx, gpa_t addr,
 			    int len, struct kvm_io_device *dev)
-- 
2.39.5 (Apple Git-154)

