From c52c455b97d940aaa1acb0e84fd230abd4e72d94 Mon Sep 17 00:00:00 2001
From: Dongli Zhang <dongli.zhang0129@gmail.com>
Date: Wed, 27 Aug 2025 22:46:50 -0700
Subject: [PATCH 1/1] linux v5.15.0-306.177.4.1

Signed-off-by: Dongli Zhang <dongli.zhang0129@gmail.com>
---
 arch/x86/include/asm/apicdef.h               |   23 +
 arch/x86/include/asm/irq_remapping.h         |    9 +
 arch/x86/include/asm/kvm_host.h              |  524 +++
 arch/x86/include/asm/pvclock.h               |    7 +
 arch/x86/kernel/apic/apic.c                  |   15 +
 arch/x86/kernel/apic/io_apic.c               |    5 +
 arch/x86/kernel/cpu/intel.c                  |  470 +++
 arch/x86/kernel/kvmclock.c                   |    6 +
 arch/x86/kernel/process.c                    |    6 +
 arch/x86/kernel/pvclock.c                    |   13 +
 arch/x86/kernel/smpboot.c                    |   24 +
 arch/x86/kvm/debugfs.c                       |   30 +
 arch/x86/kvm/hyperv.c                        |   42 +
 arch/x86/kvm/i8254.c                         |    8 +
 arch/x86/kvm/ioapic.c                        |  323 ++
 arch/x86/kvm/ioapic.h                        |   14 +
 arch/x86/kvm/irq.c                           |  105 +
 arch/x86/kvm/irq.h                           |   13 +
 arch/x86/kvm/irq_comm.c                      |  258 ++
 arch/x86/kvm/lapic.c                         | 2025 +++++++++++
 arch/x86/kvm/lapic.h                         |  308 ++
 arch/x86/kvm/mmu.h                           |    5 +
 arch/x86/kvm/pmu.c                           |   11 +
 arch/x86/kvm/svm/avic.c                      |   69 +
 arch/x86/kvm/svm/svm.c                       |  127 +
 arch/x86/kvm/vmx/nested.c                    |   55 +
 arch/x86/kvm/vmx/posted_intr.c               |   45 +
 arch/x86/kvm/vmx/vmx.c                       |  776 +++++
 arch/x86/kvm/vmx/vmx.h                       |   66 +
 arch/x86/kvm/x86.c                           | 3215 +++++++++++++++++-
 arch/x86/kvm/x86.h                           |   65 +
 drivers/acpi/acpica/dbexec.c                 |   40 +
 drivers/acpi/acpica/dbxface.c                |   20 +
 drivers/acpi/acpica/dswexec.c                |   50 +
 drivers/acpi/acpica/evgpe.c                  |  330 ++
 drivers/acpi/acpica/evmisc.c                 |  215 ++
 drivers/acpi/acpica/evsci.c                  |   58 +
 drivers/acpi/acpica/exoparg2.c               |   61 +
 drivers/acpi/acpica/nseval.c                 |  138 +
 drivers/acpi/acpica/nsnames.c                |    3 +
 drivers/acpi/acpica/nsxfeval.c               |   10 +
 drivers/acpi/acpica/nsxfname.c               |    3 +
 drivers/acpi/acpica/psloop.c                 |   41 +
 drivers/acpi/acpica/psparse.c                |   40 +
 drivers/acpi/acpica/psxface.c                |   44 +
 drivers/acpi/acpica/utstate.c                |   12 +
 drivers/acpi/bus.c                           |   44 +
 drivers/acpi/osl.c                           |  122 +
 drivers/acpi/scan.c                          |  203 ++
 drivers/clocksource/hyperv_timer.c           |    6 +
 drivers/iommu/intel/irq_remapping.c          |    9 +
 drivers/net/ethernet/mellanox/mlx5/core/eq.c |    6 +
 drivers/nvme/target/rdma.c                   |   15 +
 drivers/pci/hotplug/acpiphp_glue.c           |   94 +
 drivers/pci/pci-acpi.c                       |    4 +
 drivers/target/target_core_spc.c             |    9 +
 drivers/target/target_core_transport.c       |   20 +
 drivers/vfio/pci/vfio_pci_intrs.c            |   10 +
 include/clocksource/hyperv_timer.h           |   12 +
 include/linux/kvm_host.h                     |   50 +
 include/linux/sched.h                        |    6 +
 include/target/target_core_base.h            |    8 +
 virt/kvm/eventfd.c                           |   66 +
 virt/kvm/irqchip.c                           |   56 +
 virt/kvm/kvm_main.c                          |  188 +
 65 files changed, 10653 insertions(+), 2 deletions(-)

diff --git a/arch/x86/include/asm/apicdef.h b/arch/x86/include/asm/apicdef.h
index 863c2cad5872..7f4752325b2b 100644
--- a/arch/x86/include/asm/apicdef.h
+++ b/arch/x86/include/asm/apicdef.h
@@ -18,6 +18,29 @@
  */
 #define IO_APIC_SLOT_SIZE		1024
 
+/*
+ * 在以下使用APIC_ID:
+ *   - arch/x86/kvm/svm/svm.c|119| <<global>> { .index = X2APIC_MSR(APIC_ID), .always = false },
+ *   - arch/x86/include/asm/apic.h|204| <<native_apic_msr_write>> if (reg == APIC_DFR || reg == APIC_ID || reg == APIC_LDR ||
+ *   - arch/x86/include/asm/apic.h|487| <<read_apic_id>> unsigned int reg = apic_read(APIC_ID);
+ *   - arch/x86/kernel/apic/apic.c|1797| <<setup_nox2apic>> int apicid = native_apic_msr_read(APIC_ID);
+ *   - arch/x86/kernel/apic/apic.c|2586| <<apic_bsp_up_setup>> apic_write(APIC_ID, apic->set_apic_id(boot_cpu_physical_apicid));
+ *   - arch/x86/kernel/apic/apic.c|2668| <<lapic_suspend>> apic_pm_state.apic_id = apic_read(APIC_ID);
+ *   - arch/x86/kernel/apic/apic.c|2745| <<lapic_resume>> apic_write(APIC_ID, apic_pm_state.apic_id);
+ *   - arch/x86/kernel/apic/apic_flat_64.c|91| <<read_xapic_id>> return flat_get_apic_id(apic_read(APIC_ID));
+ *   - arch/x86/kernel/apic/vector.c|1157| <<print_local_APIC>> v = apic_read(APIC_ID);
+ *   - arch/x86/kernel/apic/x2apic_uv_x.c|811| <<uv_read_apic_id>> return x2apic_get_apic_id(apic_read(APIC_ID));
+ *   - arch/x86/kernel/smpboot.c|689| <<__inquire_remote_apic>> unsigned i, regs[] = { APIC_ID >> 4, APIC_LVR >> 4, APIC_SPIV >> 4 };
+ *   - arch/x86/kvm/lapic.c|381| <<kvm_apic_set_xapic_id>> kvm_lapic_set_reg(apic, APIC_ID, id << 24);
+ *   - arch/x86/kvm/lapic.c|408| <<kvm_apic_set_x2apic_id>> kvm_lapic_set_reg(apic, APIC_ID, id);
+ *   - arch/x86/kvm/lapic.c|1762| <<kvm_lapic_reg_read>> APIC_REG_MASK(APIC_ID) |
+ *   - arch/x86/kvm/lapic.c|2393| <<kvm_lapic_reg_write>> case APIC_ID:
+ *   - arch/x86/kvm/lapic.c|3094| <<kvm_apic_state_fixup>> u32 *id = (u32 *)(s->regs + APIC_ID);
+ *   - arch/x86/kvm/lapic.h|305| <<kvm_xapic_id>> return kvm_lapic_get_reg(apic, APIC_ID) >> 24;
+ *   - arch/x86/kvm/svm/avic.c|675| <<is_avic_unaccelerated_access_trap>> case APIC_ID:
+ *   - arch/x86/xen/apic.c|63| <<xen_apic_read>> if (reg != APIC_ID)
+ *   - tools/testing/selftests/kvm/x86_64/xapic_ipi_test.c|100| <<halter_guest_code>> data->halter_apic_id = GET_APIC_ID_FIELD(xapic_read_reg(APIC_ID));
+ */
 #define	APIC_ID		0x20
 
 #define	APIC_LVR	0x30
diff --git a/arch/x86/include/asm/irq_remapping.h b/arch/x86/include/asm/irq_remapping.h
index 7a2ed154a5e1..791c6f7601ca 100644
--- a/arch/x86/include/asm/irq_remapping.h
+++ b/arch/x86/include/asm/irq_remapping.h
@@ -26,6 +26,15 @@ enum {
 	IRQ_REMAP_X2APIC_MODE,
 };
 
+/*
+ * 在以下使用vcpu_data->pi_desc_addr:
+ *   - arch/x86/kvm/svm/avic.c|928| <<get_pi_vcpu_info>> vcpu_info->pi_desc_addr = __sme_set(page_to_phys((*svm)->avic_backing_page));
+ *   - arch/x86/kvm/svm/avic.c|1035| <<avic_pi_update_irte>> trace_kvm_pi_irte_update(host_irq,... vcpu_info.pi_desc_addr, set);
+ *   - arch/x86/kvm/vmx/posted_intr.c|337| <<vmx_pi_update_irte>> vcpu_info.pi_desc_addr = __pa(&to_vmx(vcpu)->pi_desc);
+ *   - arch/x86/kvm/vmx/posted_intr.c|341| <<vmx_pi_update_irte>> trace_kvm_pi_irte_update(host_irq,... vcpu_info.vector, vcpu_info.pi_desc_addr, set);
+ *   - drivers/iommu/intel/irq_remapping.c|1221| <<intel_ir_set_vcpu_affinity>> irte_pi.pda_l = (vcpu_pi_info->pi_desc_addr >>
+ *   - drivers/iommu/intel/irq_remapping.c|1223| <<intel_ir_set_vcpu_affinity>> irte_pi.pda_h = (vcpu_pi_info->pi_desc_addr >> 32) &
+ */
 struct vcpu_data {
 	u64 pi_desc_addr;	/* Physical address of PI Descriptor */
 	u32 vector;		/* Guest vector of the interrupt */
diff --git a/arch/x86/include/asm/kvm_host.h b/arch/x86/include/asm/kvm_host.h
index 8a710af8003c..6fd5f1ad8934 100644
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@ -70,6 +70,26 @@
 #define KVM_REQ_REPORT_TPR_ACCESS	KVM_ARCH_REQ(1)
 #define KVM_REQ_TRIPLE_FAULT		KVM_ARCH_REQ(2)
 #define KVM_REQ_MMU_SYNC		KVM_ARCH_REQ(3)
+/*
+ * 在以下使用KVM_REQ_CLOCK_UPDATE:
+ *   - arch/x86/kvm/x86.c|3167| <<kvm_gen_update_masterclock>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|3395| <<kvm_guest_time_update>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, v);
+ *   - arch/x86/kvm/x86.c|3498| <<kvmclock_update_fn>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|3507| <<kvm_gen_kvmclock_update>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, v);
+ *   - arch/x86/kvm/x86.c|3901| <<kvm_set_msr_common(MSR_IA32_TSC_ADJUST)>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|4950| <<kvm_arch_vcpu_load>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|5618| <<kvm_set_guest_paused>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|7018| <<kvm_arch_vm_ioctl>> kvm_make_all_cpus_request(kvm, KVM_REQ_CLOCK_UPDATE);
+ *   - arch/x86/kvm/x86.c|9225| <<kvm_hyperv_tsc_notifier>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|9286| <<__kvmclock_cpufreq_notifier>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|11150| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_CLOCK_UPDATE, vcpu)) {
+ *   - arch/x86/kvm/x86.c|11643| <<vcpu_enter_guest>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|13274| <<kvm_arch_hardware_enable>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/xen.c|371| <<kvm_xen_vcpu_set_attr>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/xen.c|394| <<kvm_xen_vcpu_set_attr>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+ *
+ * 处理KVM_REQ_CLOCK_UPDATE的函数: kvm_guest_time_update()
+ */
 #define KVM_REQ_CLOCK_UPDATE		KVM_ARCH_REQ(4)
 #define KVM_REQ_LOAD_MMU_PGD		KVM_ARCH_REQ(5)
 #define KVM_REQ_EVENT			KVM_ARCH_REQ(6)
@@ -79,11 +99,31 @@
 #define KVM_REQ_PMU			KVM_ARCH_REQ(10)
 #define KVM_REQ_PMI			KVM_ARCH_REQ(11)
 #define KVM_REQ_SMI			KVM_ARCH_REQ(12)
+/*
+ * 在以下使用KVM_REQ_MASTERCLOCK_UPDATE():
+ *   - arch/x86/kvm/hyperv.c|1411| <<kvm_hv_set_msr_pw>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|2444| <<kvm_write_system_time>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|2647| <<kvm_track_tsc_matching>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|9496| <<pvclock_gtod_update_fn>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|11224| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu))
+ *   - arch/x86/kvm/x86.c|13427| <<kvm_arch_hardware_enable>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/xen.c|58| <<kvm_xen_shared_info_init>> kvm_make_all_cpus_request(kvm, KVM_REQ_MASTERCLOCK_UPDATE);
+ *
+ * 处理KVM_REQ_MASTERCLOCK_UPDATE的函数: kvm_gen_update_masterclock()
+ */
 #define KVM_REQ_MASTERCLOCK_UPDATE	KVM_ARCH_REQ(13)
 #define KVM_REQ_MCLOCK_INPROGRESS \
 	KVM_ARCH_REQ_FLAGS(14, KVM_REQUEST_WAIT | KVM_REQUEST_NO_WAKEUP)
 #define KVM_REQ_SCAN_IOAPIC \
 	KVM_ARCH_REQ_FLAGS(15, KVM_REQUEST_WAIT | KVM_REQUEST_NO_WAKEUP)
+/*
+ * 在以下使用KVM_REQ_GLOBAL_CLOCK_UPDATE:
+ *   - arch/x86/kvm/x86.c|2529| <<kvm_write_system_time>> kvm_make_request(KVM_REQ_GLOBAL_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|5532| <<kvm_arch_vcpu_load>> kvm_make_request(KVM_REQ_GLOBAL_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|11816| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_GLOBAL_CLOCK_UPDATE, vcpu))
+ *
+ * 处理KVM_REQ_GLOBAL_CLOCK_UPDATE的函数: kvm_gen_kvmclock_update()
+ */
 #define KVM_REQ_GLOBAL_CLOCK_UPDATE	KVM_ARCH_REQ(16)
 #define KVM_REQ_APIC_PAGE_RELOAD \
 	KVM_ARCH_REQ_FLAGS(17, KVM_REQUEST_WAIT | KVM_REQUEST_NO_WAKEUP)
@@ -632,17 +672,94 @@ struct kvm_vcpu_arch {
 	u32 pkru;
 	u32 hflags;
 	u64 efer;
+	/*
+	 * 在以下设置kvm_vcpu_arch->apic_base (看似修改的地方):
+	 *   - arch/x86/kvm/lapic.c|2926| <<kvm_lapic_set_base>> vcpu->arch.apic_base = value;
+	 *   - arch/x86/kvm/lapic.c|3256| <<kvm_create_lapic>> vcpu->arch.apic_base = MSR_IA32_APICBASE_ENABLE;
+	 * 在以下使用kvm_vcpu_arch->apic_base:
+	 *   - arch/x86/kvm/cpuid.c|222| <<__kvm_update_cpuid_runtime>> cpuid_entry_change(best, X86_FEATURE_APIC, vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE);
+	 *   - arch/x86/kvm/lapic.c|2862| <<kvm_free_lapic>> if (!(vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE))
+	 *   - arch/x86/kvm/lapic.c|2923| <<kvm_lapic_set_base>> u64 old_value = vcpu->arch.apic_base;
+	 *   - arch/x86/kvm/lapic.c|2974| <<kvm_lapic_set_base>> apic->base_address = apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_BASE;
+	 *   - arch/x86/kvm/lapic.c|3454| <<kvm_apic_set_state>> kvm_lapic_set_base(vcpu, vcpu->arch.apic_base);
+	 *   - arch/x86/kvm/lapic.h|231| <<kvm_apic_hw_enabled>> return apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE;
+	 *   - arch/x86/kvm/lapic.h|256| <<apic_x2apic_mode>> return apic->vcpu->arch.apic_base & X2APIC_ENABLE;
+	 *   - arch/x86/kvm/lapic.h|300| <<kvm_apic_mode>> return apic_base & (MSR_IA32_APICBASE_ENABLE | X2APIC_ENABLE);
+	 *   - arch/x86/kvm/vmx/nested.c|878| <<nested_vmx_msr_check_common>> if (CC(vcpu->arch.apic_base & X2APIC_ENABLE && e->index >> 8 == 0x8))
+	 *   - arch/x86/kvm/x86.c|466| <<kvm_get_apic_base>> return vcpu->arch.apic_base;
+	 *   - arch/x86/kvm/x86.c|12215| <<kvm_vcpu_is_bsp>> return (vcpu->arch.apic_base & MSR_IA32_APICBASE_BSP) != 0;
+	 */
 	u64 apic_base;
 	struct kvm_lapic *apic;    /* kernel irqchip context */
+	/*
+	 * 在以下设置kvm_vcpu_arch->apicv_active:
+	 *   - arch/x86/kvm/x86.c|9800| <<kvm_vcpu_update_apicv>> vcpu->arch.apicv_active = activate;
+	 *   - arch/x86/kvm/x86.c|11393| <<kvm_arch_vcpu_create>> vcpu->arch.apicv_active = true;
+	 * 在以下使用kvm_vcpu_arch->apicv_active:
+	 *   - arch/x86/kvm/lapic.c|553| <<kvm_apic_update_irr>> if (unlikely(!vcpu->arch.apicv_active && irr_updated))
+	 *   - arch/x86/kvm/lapic.c|602| <<apic_clear_irr>> if (unlikely(vcpu->arch.apicv_active)) {
+	 *   - arch/x86/kvm/lapic.c|654| <<apic_set_isr>> if (unlikely(vcpu->arch.apicv_active))
+	 *   - arch/x86/kvm/lapic.c|714| <<apic_clear_isr>> if (unlikely(vcpu->arch.apicv_active))
+	 *   - arch/x86/kvm/lapic.c|1827| <<lapic_timer_int_injected>> if (vcpu->arch.apicv_active)
+	 *   - arch/x86/kvm/lapic.c|1944| <<apic_timer_expired>> if (!from_timer_fn && vcpu->arch.apicv_active) {
+	 *   - arch/x86/kvm/lapic.c|2613| <<kvm_apic_update_apicv>> if (vcpu->arch.apicv_active) {
+	 *   - arch/x86/kvm/lapic.c|2703| <<kvm_lapic_reset>> if (vcpu->arch.apicv_active) {
+	 *   - arch/x86/kvm/lapic.c|3003| <<kvm_apic_set_state>> if (vcpu->arch.apicv_active) {
+	 *   - arch/x86/kvm/lapic.h|241| <<kvm_vcpu_apicv_active>> return vcpu->arch.apic && vcpu->arch.apicv_active;
+	 *   - arch/x86/kvm/svm/svm.c|3661| <<svm_complete_interrupt_delivery>> if (!READ_ONCE(vcpu->arch.apicv_active)) {
+	 *   - arch/x86/kvm/vmx/vmx.c|4114| <<vmx_deliver_posted_interrupt>> if (!vcpu->arch.apicv_active)
+	 *   - arch/x86/kvm/x86.c|9241| <<update_cr8_intercept>> if (vcpu->arch.apicv_active)
+	 *   - arch/x86/kvm/x86.c|9797| <<kvm_vcpu_update_apicv>> if (vcpu->arch.apicv_active == activate)
+	 *   - arch/x86/kvm/x86.c|9810| <<kvm_vcpu_update_apicv>> if (!vcpu->arch.apicv_active)
+	 *   - arch/x86/kvm/x86.c|12441| <<kvm_arch_dy_has_pending_interrupt>> if (vcpu->arch.apicv_active &&
+	 *          static_call(kvm_x86_dy_apicv_has_pending_interrupt)(vcpu))
+	 */
 	bool apicv_active;
+	/*
+	 * 在以下使用kvm_vcpu_arch->load_eoi_exitmap_pending:
+	 *   - arch/x86/kvm/kvm_cache_regs.h|184| <<leave_guest_mode>> if (vcpu->arch.load_eoi_exitmap_pending) {
+	 *   - arch/x86/kvm/kvm_cache_regs.h|185| <<leave_guest_mode>> vcpu->arch.load_eoi_exitmap_pending = false;
+	 *   - arch/x86/kvm/x86.c|9850| <<vcpu_scan_ioapic>> vcpu->arch.load_eoi_exitmap_pending = true;
+	 */
 	bool load_eoi_exitmap_pending;
+	/*
+	 * 在以下使用kvm_vcpu_arch->ioapic_handled_vectors:
+	 *   - arch/x86/kvm/lapic.c|1273| <<kvm_ioapic_handles_vector>> return test_bit(vector, apic->vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|9840| <<vcpu_scan_ioapic>> bitmap_zero(vcpu->arch.ioapic_handled_vectors, 256);
+	 *   - arch/x86/kvm/x86.c|9845| <<vcpu_scan_ioapic>> kvm_scan_ioapic_routes(vcpu, vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|9847| <<vcpu_scan_ioapic>> kvm_ioapic_scan_entry(vcpu, vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|9864| <<vcpu_load_eoi_exitmap>> bitmap_or((ulong *)eoi_exit_bitmap, vcpu->arch.ioapic_handled_vectors,
+	 *              to_hv_synic(vcpu)->vec_bitmap, 256);
+	 *   - arch/x86/kvm/x86.c|9871| <<vcpu_load_eoi_exitmap>> static_call(kvm_x86_load_eoi_exitmap)(vcpu, (u64 *)vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|10004| <<vcpu_enter_guest>> if (test_bit(vcpu->arch.pending_ioapic_eoi, vcpu->arch.ioapic_handled_vectors)) {
+	 */
 	DECLARE_BITMAP(ioapic_handled_vectors, 256);
+	/*
+	 * 在以下使用kvm_vcpu_arch->apic_attention:
+	 *   - arch/x86/kvm/lapic.c|1283| <<pv_eoi_set_pending>> __set_bit(KVM_APIC_PV_EOI_PENDING, &vcpu->arch.apic_attention);
+	 *   - arch/x86/kvm/lapic.c|1291| <<pv_eoi_clr_pending>> __clear_bit(KVM_APIC_PV_EOI_PENDING, &vcpu->arch.apic_attention);
+	 *   - arch/x86/kvm/lapic.c|3541| <<kvm_lapic_reset>> vcpu->arch.apic_attention = 0;
+	 *   - arch/x86/kvm/lapic.c|4066| <<kvm_lapic_sync_from_vapic>> if (test_bit(KVM_APIC_PV_EOI_PENDING, &vcpu->arch.apic_attention))
+	 *   - arch/x86/kvm/lapic.c|4069| <<kvm_lapic_sync_from_vapic>> if (!test_bit(KVM_APIC_CHECK_VAPIC, &vcpu->arch.apic_attention))
+	 *   - arch/x86/kvm/lapic.c|4128| <<kvm_lapic_sync_to_vapic>> if (!test_bit(KVM_APIC_CHECK_VAPIC, &vcpu->arch.apic_attention))
+	 *   - arch/x86/kvm/lapic.c|4151| <<kvm_lapic_set_vapic_addr>> __set_bit(KVM_APIC_CHECK_VAPIC, &vcpu->arch.apic_attention);
+	 *   - arch/x86/kvm/lapic.c|4153| <<kvm_lapic_set_vapic_addr>> __clear_bit(KVM_APIC_CHECK_VAPIC, &vcpu->arch.apic_attention);
+	 *   - arch/x86/kvm/x86.c|10895| <<vcpu_enter_guest>> if (vcpu->arch.apic_attention)
+	 *   - arch/x86/kvm/x86.c|10926| <<vcpu_enter_guest>> if (unlikely(vcpu->arch.apic_attention))
+	 */
 	unsigned long apic_attention;
 	int32_t apic_arb_prio;
 	int mp_state;
 	u64 ia32_misc_enable_msr;
 	u64 smbase;
 	u64 smi_count;
+	/*
+	 * 在以下使用kvm_vcpu_arch->at_instruction_boundary:
+	 *   - arch/x86/kvm/svm/svm.c|4585| <<svm_handle_exit_irqoff>> vcpu->arch.at_instruction_boundary = true;
+	 *   - arch/x86/kvm/vmx/vmx.c|6979| <<handle_external_interrupt_irqoff>> vcpu->arch.at_instruction_boundary = true;
+	 *   - arch/x86/kvm/x86.c|4744| <<kvm_steal_time_set_preempted>> if (!vcpu->arch.at_instruction_boundary) {
+	 *   - arch/x86/kvm/x86.c|11223| <<vcpu_run>> vcpu->arch.at_instruction_boundary = false;
+	 */
 	bool at_instruction_boundary;
 	bool tpr_access_reporting;
 	bool xsaves_enabled;
@@ -747,9 +864,29 @@ struct kvm_vcpu_arch {
 
 	gpa_t time;
 	struct pvclock_vcpu_time_info hv_clock;
+	/*
+	 * 在以下使用kvm_vcpu_arch->hw_tsc_khz:
+	 *   - arch/x86/kvm/x86.c|3825| <<kvm_guest_time_update>> if (unlikely(vcpu->hw_tsc_khz != tgt_tsc_khz)) {
+	 *   - arch/x86/kvm/x86.c|3829| <<kvm_guest_time_update>> vcpu->hw_tsc_khz = tgt_tsc_khz;
+	 */
 	unsigned int hw_tsc_khz;
 	struct gfn_to_hva_cache pv_time;
+	/*
+	 * 在以下使用kvm_vcpu_arch->pv_time_enabled:
+	 *   - arch/x86/kvm/x86.c|2590| <<kvm_write_system_time>> vcpu->arch.pv_time_enabled = false;
+	 *   - arch/x86/kvm/x86.c|2597| <<kvm_write_system_time>> vcpu->arch.pv_time_enabled = true;
+	 *   - arch/x86/kvm/x86.c|4248| <<kvm_guest_time_update>> if (vcpu->pv_time_enabled)
+	 *   - arch/x86/kvm/x86.c|4519| <<kvmclock_reset>> vcpu->arch.pv_time_enabled = false;
+	 *   - arch/x86/kvm/x86.c|6537| <<kvm_set_guest_paused>> if (!vcpu->arch.pv_time_enabled)
+	 *   - arch/x86/kvm/x86.c|7610| <<kvm_arch_suspend_notifier>> if (!vcpu->arch.pv_time_enabled)
+	 */
 	bool pv_time_enabled;
+	/*
+	 * 在以下使用kvm_vcpu_arch->pvclock_set_guest_stopped_request:
+	 *   - arch/x86/kvm/x86.c|3993| <<kvm_setup_pvclock_page>> if (vcpu->pvclock_set_guest_stopped_request) {
+	 *   - arch/x86/kvm/x86.c|3995| <<kvm_setup_pvclock_page>> vcpu->pvclock_set_guest_stopped_request = false;
+	 *   - arch/x86/kvm/x86.c|6539| <<kvm_set_guest_paused>> vcpu->arch.pvclock_set_guest_stopped_request = true;
+	 */
 	/* set guest stopped flag in pvclock flags field */
 	bool pvclock_set_guest_stopped_request;
 
@@ -760,24 +897,151 @@ struct kvm_vcpu_arch {
 		struct gfn_to_hva_cache cache;
 	} st;
 
+	/*
+	 * 在以下使用kvm_vcpu_arch->l1_tsc_offset:
+	 *   - arch/x86/kvm/svm/nested.c|619| <<nested_vmcb02_prepare_control>> vcpu->arch.l1_tsc_offset + svm->nested.ctl.tsc_offset;
+	 *   - arch/x86/kvm/svm/nested.c|972| <<nested_svm_vmexit>> svm->vcpu.arch.tsc_offset = svm->vcpu.arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/svm/svm.c|1290| <<svm_write_tsc_offset>> svm->vmcb01.ptr->control.tsc_offset = vcpu->arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/vmx/nested.c|2602| <<prepare_vmcs02>> vcpu->arch.tsc_offset = kvm_calc_nested_tsc_offset(vcpu->arch.l1_tsc_offset,
+	 *          vmx_get_l2_tsc_offset(vcpu), vmx_get_l2_tsc_multiplier(vcpu));
+	 *   - arch/x86/kvm/vmx/nested.c|4648| <<nested_vmx_vmexit>> vcpu->arch.tsc_offset = vcpu->arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/x86.c|3066| <<kvm_read_l1_tsc>> return vcpu->arch.l1_tsc_offset + kvm_scale_tsc(vcpu, host_tsc,
+	 *          vcpu->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|3105| <<kvm_vcpu_write_tsc_offset>> trace_kvm_write_tsc_offset( ... vcpu->arch.l1_tsc_offset,
+	 *   - arch/x86/kvm/x86.c|3108| <<kvm_vcpu_write_tsc_offset>> vcpu->arch.l1_tsc_offset = l1_offset;
+	 *   - arch/x86/kvm/x86.c|3373| <<adjust_tsc_offset_guest>> u64 tsc_offset = vcpu->arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/x86.c|4746| <<kvm_set_msr_common(MSR_IA32_TSC)>> u64 adj = kvm_compute_l1_tsc_offset(vcpu, data) - vcpu->arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/x86.c|5090| <<kvm_get_msr_common(MSR_IA32_TSC)>> offset = vcpu->arch.l1_tsc_offset;
+	 */
 	u64 l1_tsc_offset;
 	u64 tsc_offset; /* current tsc offset */
+	/*
+	 * 在以下设置kvm_vcpu_arch->last_guest_tsc:
+	 *   - arch/x86/kvm/x86.c|3348| <<kvm_synchronize_tsc>> vcpu->arch.last_guest_tsc = data;
+	 *   - arch/x86/kvm/x86.c|4233| <<kvm_guest_time_update>> vcpu->last_guest_tsc = tsc_timestamp;
+	 *   - arch/x86/kvm/x86.c|12679| <<vcpu_enter_guest>> vcpu->arch.last_guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 * 在以下使用kvm_vcpu_arch->last_guest_tsc:
+	 *   - arch/x86/kvm/x86.c|5893| <<kvm_arch_vcpu_load>> u64 offset = kvm_compute_l1_tsc_offset(vcpu, vcpu->arch.last_guest_tsc);
+	 *
+	 * 在kvm_arch_vcpu_load()只有kvm_check_tsc_unstable()的时候
+	 * 才使用vcpu->arch.last_guest_tsc
+	 * 所以stable的情况下基本用不到
+	 */
 	u64 last_guest_tsc;
+	/*
+	 * 在以下使用kvm_vcpu_arch->last_host_tsc:
+	 *   - arch/x86/kvm/x86.c|4745| <<kvm_arch_vcpu_load>> s64 tsc_delta = !vcpu->arch.last_host_tsc ? 0 :
+	 *   - arch/x86/kvm/x86.c|4746| <<kvm_arch_vcpu_load>> rdtsc() - vcpu->arch.last_host_tsc;
+	 *   - arch/x86/kvm/x86.c|4857| <<kvm_arch_vcpu_put>> vcpu->arch.last_host_tsc = rdtsc();
+	 *   - arch/x86/kvm/x86.c|12955| <<kvm_arch_hardware_enable>> if (stable && vcpu->arch.last_host_tsc > local_tsc) {
+	 *   - arch/x86/kvm/x86.c|12957| <<kvm_arch_hardware_enable>> if (vcpu->arch.last_host_tsc > max_tsc)
+	 *   - arch/x86/kvm/x86.c|12958| <<kvm_arch_hardware_enable>> max_tsc = vcpu->arch.last_host_tsc;
+	 *   - arch/x86/kvm/x86.c|13007| <<kvm_arch_hardware_enable>> vcpu->arch.last_host_tsc = local_tsc;
+	 */
 	u64 last_host_tsc;
 	u64 tsc_offset_adjustment;
 	u64 this_tsc_nsec;
 	u64 this_tsc_write;
 	u64 this_tsc_generation;
+	/*
+	 * 在以下使用kvm_vcpu_arch->tsc_catchup:
+	 *   - arch/x86/kvm/x86.c|2727| <<set_tsc_khz>> vcpu->arch.tsc_catchup = 1;
+	 *   - arch/x86/kvm/x86.c|4150| <<kvm_guest_time_update>> if (vcpu->tsc_catchup) {
+	 *   - arch/x86/kvm/x86.c|5901| <<kvm_arch_vcpu_load>> vcpu->arch.tsc_catchup = 1;
+	 */
 	bool tsc_catchup;
+	/*
+	 * 在以下使用kvm_vcpu_arch->tsc_always_catchup:
+	 *   - arch/x86/kvm/x86.c|2728| <<set_tsc_khz>> vcpu->arch.tsc_always_catchup = 1;
+	 *   - arch/x86/kvm/x86.c|10707| <<kvm_pv_clock_pairing>> if (vcpu->arch.tsc_always_catchup)
+	 *   - arch/x86/kvm/x86.c|12760| <<vcpu_enter_guest>> if (unlikely(vcpu->arch.tsc_always_catchup))
+	 */
 	bool tsc_always_catchup;
+	/*
+	 * 在以下使用kvm_vcpu_arch->virtual_tsc_shift:
+	 *   - arch/x86/kvm/x86.c|2684| <<kvm_set_tsc_khz>> kvm_get_time_scale(user_tsc_khz * 1000LL,
+	 *           NSEC_PER_SEC, &vcpu->arch.virtual_tsc_shift, &vcpu->arch.virtual_tsc_mult);
+	 *   - arch/x86/kvm/x86.c|2707| <<compute_guest_tsc>> u64 tsc = pvclock_scale_delta(kernel_ns-vcpu->arch.this_tsc_nsec,
+	 *           vcpu->arch.virtual_tsc_mult, vcpu->arch.virtual_tsc_shift);
+	 *   - arch/x86/kvm/x86.h|382| <<nsec_to_cycles>> return pvclock_scale_delta(nsec,
+	 *           vcpu->arch.virtual_tsc_mult, vcpu->arch.virtual_tsc_shift);
+	 */
 	s8 virtual_tsc_shift;
+	/*
+	 * 在以下使用kvm_vcpu_arch->arch.virtual_tsc_mult:
+	 *   - arch/x86/kvm/x86.c|2697| <<kvm_set_tsc_khz>> kvm_get_time_scale(user_tsc_khz * 1000LL,
+	 *           NSEC_PER_SEC, &vcpu->arch.virtual_tsc_shift, &vcpu->arch.virtual_tsc_mult);
+	 *   - arch/x86/kvm/x86.c|2754| <<compute_guest_tsc>> u64 tsc = pvclock_scale_delta(kernel_ns-vcpu->arch.this_tsc_nsec,
+	 *           vcpu->arch.virtual_tsc_mult, vcpu->arch.virtual_tsc_shift);
+	 *   - arch/x86/kvm/x86.h|390| <<nsec_to_cycles>> return pvclock_scale_delta(nsec,
+	 *           vcpu->arch.virtual_tsc_mult, vcpu->arch.virtual_tsc_shift);
+	 */
 	u32 virtual_tsc_mult;
+	/*
+	 * 在以下设置kvm_vcpu_arch->virtual_tsc_khz:
+	 *   - arch/x86/kvm/x86.c|2561| <<kvm_set_tsc_khz>> vcpu->arch.virtual_tsc_khz = user_tsc_khz;
+	 * 在以下使用kvm_vcpu_arch->virtual_tsc_khz:
+	 *   - arch/x86/kvm/hyperv.c|1697| <<kvm_hv_get_msr>> data = (u64)vcpu->arch.virtual_tsc_khz * 1000;
+	 *   - arch/x86/kvm/lapic.c|2843| <<__wait_lapic_expire>> do_div(delay_ns, vcpu->arch.virtual_tsc_khz);
+	 *   - arch/x86/kvm/lapic.c|2863| <<adjust_lapic_timer_advance>> do_div(ns, vcpu->arch.virtual_tsc_khz);
+	 *   - arch/x86/kvm/lapic.c|2868| <<adjust_lapic_timer_advance>> do_div(ns, vcpu->arch.virtual_tsc_khz);
+	 *   - arch/x86/kvm/lapic.c|3002| <<start_sw_tscdeadline>> unsigned long this_tsc_khz = vcpu->arch.virtual_tsc_khz;
+	 *   - arch/x86/kvm/vmx/nested.c|2111| <<vmx_start_preemption_timer>> if (vcpu->arch.virtual_tsc_khz == 0)
+	 *   - arch/x86/kvm/vmx/nested.c|2116| <<vmx_start_preemption_timer>> do_div(preemption_timeout, vcpu->arch.virtual_tsc_khz);
+	 *   - arch/x86/kvm/vmx/nested.c|4059| <<vmx_get_preemption_timer_value>> value = ktime_to_ns(remaining) * vcpu->arch.virtual_tsc_khz;
+	 *   - arch/x86/kvm/x86.c|2775| <<kvm_synchronize_tsc>> if (vcpu->arch.virtual_tsc_khz) {
+	 *   - arch/x86/kvm/x86.c|2786| <<kvm_synchronize_tsc>> u64 tsc_hz = vcpu->arch.virtual_tsc_khz * 1000LL;
+	 *   - arch/x86/kvm/x86.c|2804| <<kvm_synchronize_tsc>> vcpu->arch.virtual_tsc_khz == kvm->arch.last_tsc_khz) {
+	 *   - arch/x86/kvm/x86.c|2837| <<kvm_synchronize_tsc>> kvm->arch.last_tsc_khz = vcpu->arch.virtual_tsc_khz;
+	 *   - arch/x86/kvm/x86.c|5786| <<kvm_arch_vcpu_ioctl(KVM_GET_TSC_KHZ)>> r = vcpu->arch.virtual_tsc_khz;
+	 */
 	u32 virtual_tsc_khz;
 	s64 ia32_tsc_adjust_msr;
 	u64 msr_ia32_power_ctl;
+	/*
+	 * 在以下设置kvm_vcpu_arch->l1_tsc_scaling_ratio:
+	 *   - arch/x86/kvm/x86.c|3170| <<kvm_vcpu_write_tsc_multiplier>> vcpu->arch.l1_tsc_scaling_ratio = l1_multiplier;
+	 * 在以下使用kvm_vcpu_arch->l1_tsc_scaling_ratio:
+	 *   - arch/x86/kvm/vmx/nested.c|2607| <<prepare_vmcs02>> vcpu->arch.tsc_scaling_ratio =
+	 *          kvm_calc_nested_tsc_multiplier(vcpu->arch.l1_tsc_scaling_ratio, vmx_get_l2_tsc_multiplier(vcpu));
+	 *   - arch/x86/kvm/vmx/nested.c|4650| <<nested_vmx_vmexit>> vcpu->arch.tsc_scaling_ratio = vcpu->arch.l1_tsc_scaling_ratio;
+	 *   - arch/x86/kvm/vmx/vmx.c|8401| <<vmx_set_hv_timer>> if (vcpu->arch.l1_tsc_scaling_ratio != kvm_default_tsc_scaling_ratio &&
+	 *          delta_tsc && u64_shl_div_u64(delta_tsc, kvm_tsc_scaling_ratio_frac_bits, vcpu->arch.l1_tsc_scaling_ratio, &delta_tsc))
+	 *   - arch/x86/kvm/vmx/vmx.c|8404| <<vmx_set_hv_timer>> if (vcpu->arch.l1_tsc_scaling_ratio != kvm_default_tsc_scaling_ratio &&
+	 *          delta_tsc && u64_shl_div_u64(delta_tsc, kvm_tsc_scaling_ratio_frac_bits, vcpu->arch.l1_tsc_scaling_ratio, &delta_tsc))
+	 *   - arch/x86/kvm/x86.c|3036| <<kvm_compute_l1_tsc_offset>> tsc = kvm_scale_tsc(vcpu, rdtsc(), vcpu->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|3083| <<kvm_read_l1_tsc>> return vcpu->arch.l1_tsc_offset + kvm_scale_tsc(vcpu, host_tsc, vcpu->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|3437| <<adjust_tsc_offset_host>> if (vcpu->arch.l1_tsc_scaling_ratio != kvm_default_tsc_scaling_ratio)
+	 *   - arch/x86/kvm/x86.c|3448| <<adjust_tsc_offset_host>> adjustment = kvm_scale_tsc(vcpu, (u64) adjustment, vcpu->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|4197| <<kvm_guest_time_update>> tgt_tsc_khz = kvm_scale_tsc(v, tgt_tsc_khz, v->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|5171| <<kvm_get_msr_common(MSR_IA32_TSC)>> ratio = vcpu->arch.l1_tsc_scaling_ratio;
+	 */
 	u64 l1_tsc_scaling_ratio;
+	/*
+	 * 在以下设置kvm_vcpu_arch->tsc_scaling_ratio:
+	 *   - arch/x86/kvm/vmx/nested.c|2606| <<prepare_vmcs02>> vcpu->arch.tsc_scaling_ratio = kvm_calc_nested_tsc_multiplier(
+	 *   - arch/x86/kvm/vmx/nested.c|4650| <<nested_vmx_vmexit>> vcpu->arch.tsc_scaling_ratio = vcpu->arch.l1_tsc_scaling_ratio;
+	 *   - arch/x86/kvm/x86.c|3183| <<kvm_vcpu_write_tsc_multiplier>> vcpu->arch.tsc_scaling_ratio = kvm_calc_nested_tsc_multiplier(
+	 *   - arch/x86/kvm/x86.c|3187| <<kvm_vcpu_write_tsc_multiplier>> vcpu->arch.tsc_scaling_ratio = l1_multiplier;
+
+	 * 在以下使用kvm_vcpu_arch->tsc_scaling_ratio:
+	 *   - arch/x86/kvm/debugfs.c|43| <<vcpu_get_tsc_scaling_ratio>> *val = vcpu->arch.tsc_scaling_ratio;
+	 *   - arch/x86/kvm/lapic.c|2838| <<__wait_lapic_expire>> if (vcpu->arch.tsc_scaling_ratio == kvm_default_tsc_scaling_ratio) {
+	 *   - arch/x86/kvm/svm/svm.c|1640| <<svm_prepare_guest_switch>> __svm_write_tsc_multiplier(vcpu->arch.tsc_scaling_ratio);
+	 *   - arch/x86/kvm/vmx/nested.c|2612| <<prepare_vmcs02>> vmcs_write64(TSC_MULTIPLIER, vcpu->arch.tsc_scaling_ratio);
+	 *   - arch/x86/kvm/vmx/nested.c|4711| <<nested_vmx_vmexit>> vmcs_write64(TSC_MULTIPLIER, vcpu->arch.tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|3206| <<kvm_vcpu_write_tsc_multiplier>> static_call(kvm_x86_write_tsc_multiplier)(vcpu, vcpu->arch.tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|5189| <<kvm_get_msr_common>> ratio = vcpu->arch.tsc_scaling_ratio;
+	 */
 	u64 tsc_scaling_ratio; /* current scaling ratio */
 
+	/*
+	 * 在以下使用kvm_vcpu_arch->nmi_queued:
+	 *   - arch/x86/kvm/x86.c|874| <<kvm_inject_nmi>> atomic_inc(&vcpu->arch.nmi_queued);
+	 *   - arch/x86/kvm/x86.c|5158| <<kvm_vcpu_ioctl_x86_set_vcpu_events>> atomic_set(&vcpu->arch.nmi_queued, events->nmi.pending);
+	 *   - arch/x86/kvm/x86.c|9855| <<process_nmi>> vcpu->arch.nmi_pending += atomic_xchg(&vcpu->arch.nmi_queued, 0);
+	 *   - arch/x86/kvm/x86.c|12376| <<kvm_vcpu_reset>> atomic_set(&vcpu->arch.nmi_queued, 0);
+	 */
 	atomic_t nmi_queued;  /* unprocessed asynchronous NMIs */
 	/* Number of NMIs pending injection, not including hardware vNMIs. */
 	unsigned int nmi_pending;
@@ -823,6 +1087,14 @@ struct kvm_vcpu_arch {
 	unsigned long last_retry_addr;
 
 	struct {
+		/*
+		 * 在以下使用kvm的halted:
+		 *   - arch/x86/kvm/x86.c|10791| <<vcpu_enter_guest>> vcpu->arch.apf.halted = true;
+		 *   - arch/x86/kvm/x86.c|11346| <<vcpu_block>> vcpu->arch.apf.halted = false;
+		 *   - arch/x86/kvm/x86.c|11362| <<kvm_vcpu_running>> !vcpu->arch.apf.halted);
+		 *   - arch/x86/kvm/x86.c|12566| <<kvm_vcpu_reset>> vcpu->arch.apf.halted = false;
+		 *   - arch/x86/kvm/x86.c|13776| <<kvm_arch_async_page_present>> vcpu->arch.apf.halted = false;
+		 */
 		bool halted;
 		gfn_t gfns[ASYNC_PF_PER_VCPU];
 		struct gfn_to_hva_cache data;
@@ -872,10 +1144,34 @@ struct kvm_vcpu_arch {
 
 	/* pv related host specific info */
 	struct {
+		/*
+		 * 在以下使用kvm_vcpu_arch的pv_unhalted:
+		 *   - arch/x86/kvm/lapic.c|2005| <<__apic_accept_irq>> vcpu->arch.pv.pv_unhalted = 1;
+		 *   - arch/x86/kvm/x86.c|11341| <<vcpu_block>> vcpu->arch.pv.pv_unhalted = false;
+		 *   - arch/x86/kvm/x86.c|11793| <<kvm_arch_vcpu_ioctl_get_mpstate>> vcpu->arch.pv.pv_unhalted)
+		 *   - arch/x86/kvm/x86.c|13430| <<kvm_vcpu_has_events>> if (vcpu->arch.pv.pv_unhalted)
+		 *   - arch/x86/kvm/x86.c|13483| <<kvm_arch_dy_runnable>> if (READ_ONCE(vcpu->arch.pv.pv_unhalted))
+		 */
 		bool pv_unhalted;
 	} pv;
 
+	/*
+	 * 在以下使用kvm_vcpu_arch->pending_ioapic_eoi:
+	 *   - arch/x86/kvm/lapic.c|1286| <<kvm_ioapic_send_eoi>> apic->vcpu->arch.pending_ioapic_eoi = vector;
+	 *   - arch/x86/kvm/x86.c|10008| <<vcpu_enter_guest(KVM_REQ_IOAPIC_EOI_EXIT)>> BUG_ON(vcpu->arch.pending_ioapic_eoi > 255);
+	 *   - arch/x86/kvm/x86.c|10009| <<vcpu_enter_guest(KVM_REQ_IOAPIC_EOI_EXIT)>> if (test_bit(vcpu->arch.pending_ioapic_eoi,
+	 *   - arch/x86/kvm/x86.c|10013| <<vcpu_enter_guest(KVM_REQ_IOAPIC_EOI_EXIT)>> vcpu->arch.pending_ioapic_eoi;
+	 */
 	int pending_ioapic_eoi;
+	/*
+	 * 在以下使用kvm_vcpu_arch->pending_external_vector:
+	 *   - arch/x86/kvm/irq.c|37| <<pending_userspace_extint>> return v->arch.pending_external_vector != -1;
+	 *   - arch/x86/kvm/irq.c|121| <<kvm_cpu_get_extint>> int vector = v->arch.pending_external_vector;
+	 *   - arch/x86/kvm/irq.c|123| <<kvm_cpu_get_extint>> v->arch.pending_external_vector = -1;
+	 *   - arch/x86/kvm/x86.c|4691| <<kvm_vcpu_ioctl_interrupt>> if (vcpu->arch.pending_external_vector != -1)
+	 *   - arch/x86/kvm/x86.c|4694| <<kvm_vcpu_ioctl_interrupt>> vcpu->arch.pending_external_vector = irq->irq;
+	 *   - arch/x86/kvm/x86.c|11281| <<kvm_arch_vcpu_create>> vcpu->arch.pending_external_vector = -1;
+	 */
 	int pending_external_vector;
 
 	/* be preempted when it's in kernel-mode(cpl=0) */
@@ -884,6 +1180,25 @@ struct kvm_vcpu_arch {
 	/* Flush the L1 Data cache for L1TF mitigation on VMENTER */
 	bool l1tf_flush_l1d;
 
+	/*
+	 * 在以下使用kvm_vcpu_arch->last_vmentry_cpu:
+	 *   - arch/x86/kvm/cpuid.c|349| <<kvm_set_cpuid>> if (vcpu->arch.last_vmentry_cpu != -1)
+	 *   - arch/x86/kvm/mmu/mmu.c|5018| <<kvm_mmu_after_set_cpuid>> if (vcpu->arch.last_vmentry_cpu != -1) {
+	 *   - arch/x86/kvm/svm/sev.c|2607| <<pre_sev_run>> if (sd->sev_vmcbs[asid] == svm->vmcb && svm->vcpu.arch.last_vmentry_cpu == cpu)
+	 *   - arch/x86/kvm/svm/svm.c|3341| <<dump_vmcb>> pr_err("VMCB %p, last attempted VMRUN on CPU %d\n",
+	 *                                    svm->current_vmcb->ptr, vcpu->arch.last_vmentry_cpu);
+	 *   - arch/x86/kvm/svm/svm.c|3465| <<svm_handle_invalid_exit>> vcpu->run->internal.data[1] = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/svm/svm.c|3540| <<handle_exit>> kvm_run->fail_entry.cpu = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/vmx/vmx.c|4996| <<handle_exception_nmi>> vcpu->run->internal.data[3] = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/vmx/vmx.c|5971| <<dump_vmcs>> pr_err("VMCS %p, last attempted VM-entry on CPU %d\n",
+	 *                                    vmx->loaded_vmcs->vmcs, vcpu->arch.last_vmentry_cpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|6195| <<__vmx_handle_exit>> vcpu->run->fail_entry.cpu = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/vmx/vmx.c|6204| <<__vmx_handle_exit>> vcpu->run->fail_entry.cpu = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/vmx/vmx.c|6232| <<__vmx_handle_exit>> vcpu->run->internal.data[ndata++] = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/vmx/vmx.c|6292| <<__vmx_handle_exit>> vcpu->run->internal.data[1] = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/x86.c|10741| <<vcpu_enter_guest>> vcpu->arch.last_vmentry_cpu = vcpu->cpu;
+	 *   - arch/x86/kvm/x86.c|11799| <<kvm_arch_vcpu_create>> vcpu->arch.last_vmentry_cpu = -1;
+	 */
 	/* Host CPU on which VM-entry was most recently attempted */
 	int last_vmentry_cpu;
 
@@ -948,6 +1263,18 @@ struct kvm_apic_map {
 		struct kvm_lapic *xapic_flat_map[8];
 		struct kvm_lapic *xapic_cluster_map[16][4];
 	};
+	/*
+	 * 在以下使用kvm_apic_map->phys_map[]:
+	 *   - arch/x86/kvm/lapic.c|289| <<kvm_apic_map_get_logical_dest>> *cluster = &map->phys_map[offset];
+	 *   - arch/x86/kvm/lapic.c|534| <<kvm_recalculate_apic_map>> new->phys_map[x2apic_id] = apic;
+	 *   - arch/x86/kvm/lapic.c|539| <<kvm_recalculate_apic_map>> if (!apic_x2apic_mode(apic) && !new->phys_map[xapic_id])
+	 *   - arch/x86/kvm/lapic.c|540| <<kvm_recalculate_apic_map>> new->phys_map[xapic_id] = apic;
+	 *   - arch/x86/kvm/lapic.c|1287| <<__pv_send_ipi>> if (map->phys_map[min + i]) {
+	 *   - arch/x86/kvm/lapic.c|1288| <<__pv_send_ipi>> vcpu = map->phys_map[min + i]->vcpu;
+	 *   - arch/x86/kvm/lapic.c|1738| <<kvm_apic_map_get_dest_lapic>> *dst = &map->phys_map[dest_id];
+	 *   - arch/x86/kvm/x86.c|9433| <<kvm_sched_yield>> if (likely(map) && dest_id <= map->max_apic_id && map->phys_map[dest_id])
+	 *   - arch/x86/kvm/x86.c|9434| <<kvm_sched_yield>> target = map->phys_map[dest_id]->vcpu;
+	 */
 	struct kvm_lapic *phys_map[];
 };
 
@@ -1139,14 +1466,56 @@ struct kvm_arch {
 	struct kvm_ioapic *vioapic;
 	struct kvm_pit *vpit;
 	atomic_t vapics_in_nmi_mode;
+	/*
+	 * 在以下使用kvm_arch->apic_map_lock:
+	 *   - arch/x86/kvm/lapic.c|375| <<kvm_recalculate_apic_map>> mutex_lock(&kvm->arch.apic_map_lock);
+	 *   - arch/x86/kvm/lapic.c|383| <<kvm_recalculate_apic_map>> mutex_unlock(&kvm->arch.apic_map_lock);
+	 *   - arch/x86/kvm/lapic.c|506| <<kvm_recalculate_apic_map>> old = rcu_dereference_protected(kvm->arch.apic_map,
+	 *                                     lockdep_is_held(&kvm->arch.apic_map_lock));
+	 *   - arch/x86/kvm/lapic.c|514| <<kvm_recalculate_apic_map>> mutex_unlock(&kvm->arch.apic_map_lock);
+	 *   - arch/x86/kvm/x86.c|12397| <<kvm_arch_init_vm>> mutex_init(&kvm->arch.apic_map_lock);
+	 */
 	struct mutex apic_map_lock;
+	/*
+	 * 在以下使用kvm_arch->apic_map:
+	 *   - arch/x86/kvm/lapic.c|581| <<kvm_recalculate_apic_map>> old = rcu_dereference_protected(kvm->arch.apic_map,
+	 *   - arch/x86/kvm/lapic.c|583| <<kvm_recalculate_apic_map>> rcu_assign_pointer(kvm->arch.apic_map, new);
+	 *   - arch/x86/kvm/lapic.c|1305| <<kvm_pv_send_ipi>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1772| <<kvm_irq_delivery_to_apic_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1825| <<kvm_intr_is_single_vcpu_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|2023| <<kvm_bitmap_or_dest_vcpus>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|9391| <<kvm_sched_yield>> map = rcu_dereference(vcpu->kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|13061| <<kvm_arch_destroy_vm>> kvfree(rcu_dereference_check(kvm->arch.apic_map, 1));
+	 */
 	struct kvm_apic_map __rcu *apic_map;
+	/*
+	 * 在以下使用kvm_arch->apic_map_dirty:
+	 *   - arch/x86/kvm/lapic.c|279| <<kvm_recalculate_apic_map>> if (atomic_read_acquire(&kvm->arch.apic_map_dirty) == CLEAN)
+	 *   - arch/x86/kvm/lapic.c|290| <<kvm_recalculate_apic_map>> if (atomic_cmpxchg_acquire(&kvm->arch.apic_map_dirty,
+	 *   - arch/x86/kvm/lapic.c|378| <<kvm_recalculate_apic_map>> atomic_cmpxchg_release(&kvm->arch.apic_map_dirty,
+	 *   - arch/x86/kvm/lapic.c|401| <<apic_set_spiv>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|441| <<kvm_apic_set_xapic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|447| <<kvm_apic_set_ldr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|453| <<kvm_apic_set_dfr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|496| <<kvm_apic_set_x2apic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|2862| <<kvm_lapic_set_base>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|3370| <<kvm_apic_set_state>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 */
 	atomic_t apic_map_dirty;
 
 	/* Protects apic_access_memslot_enabled and apicv_inhibit_reasons */
 	struct rw_semaphore apicv_update_lock;
 
 	bool apic_access_memslot_enabled;
+	/*
+	 * 在以下使用kvm_arch->apicv_inhibit_reasons:
+	 *   - arch/x86/kvm/x86.c|9007| <<kvm_apicv_activated>> return (READ_ONCE(kvm->arch.apicv_inhibit_reasons) == 0);
+	 *   - arch/x86/kvm/x86.c|9013| <<kvm_vcpu_apicv_activated>> ulong vm_reasons = READ_ONCE(vcpu->kvm->arch.apicv_inhibit_reasons);
+	 *   - arch/x86/kvm/x86.c|9033| <<kvm_apicv_init>> unsigned long *inhibits = &kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|9830| <<__kvm_set_or_clear_apicv_inhibit>> old = new = kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|9848| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 *   - arch/x86/kvm/x86.c|9857| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 */
 	unsigned long apicv_inhibit_reasons;
 
 	gpa_t wall_clock;
@@ -1156,27 +1525,129 @@ struct kvm_arch {
 	bool pause_in_guest;
 	bool cstate_in_guest;
 
+	/*
+	 * 在以下使用kvm_arch->irq_sources_bitmap:
+	 *   - arch/x86/kvm/irq_comm.c|187| <<kvm_request_irq_source_id>> unsigned long *bitmap = &kvm->arch.irq_sources_bitmap;
+	 *   - arch/x86/kvm/irq_comm.c|219| <<kvm_free_irq_source_id>> clear_bit(irq_source_id, &kvm->arch.irq_sources_bitmap);
+	 *   - arch/x86/kvm/x86.c|11732| <<kvm_arch_init_vm>> set_bit(KVM_USERSPACE_IRQ_SOURCE_ID, &kvm->arch.irq_sources_bitmap);
+	 *   - arch/x86/kvm/x86.c|11735| <<kvm_arch_init_vm>> set_bit(KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID, &kvm->arch.irq_sources_bitmap);
+	 */
 	unsigned long irq_sources_bitmap;
+	/*
+	 * 在以下设置kvm_arch->kvmclock_offset:
+	 *   - arch/x86/kvm/x86.c|6814| <<kvm_arch_vm_ioctl(KVM_SET_CLOCK)>> ka->kvmclock_offset = user_ns.clock - now_ns;
+	 *   - arch/x86/kvm/x86.c|13280| <<kvm_arch_init_vm>> kvm->arch.kvmclock_offset = -get_kvmclock_base_ns();
+	 * 在以下使用kvm_arch->kvmclock_offset:
+	 *   - arch/x86/kvm/pmu.c|342| <<kvm_pmu_rdpmc_vmware>> ctr_val = ktime_get_boottime_ns() + vcpu->kvm->arch.kvmclock_offset;
+	 *   - arch/x86/kvm/x86.c|3141| <<get_kvmclock_ns>> return get_kvmclock_base_ns() + ka->kvmclock_offset;
+	 *   - arch/x86/kvm/x86.c|3145| <<get_kvmclock_ns>> hv_clock.system_time = ka->master_kernel_ns + ka->kvmclock_offset;
+	 *   - arch/x86/kvm/x86.c|3167| <<get_kvmclock_ns>> ret = get_kvmclock_base_ns() + ka->kvmclock_offset;
+	 *   - arch/x86/kvm/x86.c|3307| <<kvm_guest_time_update>> vcpu->hv_clock.system_time = kernel_ns + v->kvm->arch.kvmclock_offset;
+	 */
 	s64 kvmclock_offset;
 	raw_spinlock_t tsc_write_lock;
+	/*
+	 * 在以下使用kvm_arch->last_tsc_nsec:
+	 *   - arch/x86/kvm/x86.c|3254| <<kvm_synchronize_tsc>> elapsed = ns - kvm->arch.last_tsc_nsec;
+	 *   - arch/x86/kvm/x86.c|3353| <<kvm_synchronize_tsc>> kvm->arch.last_tsc_nsec = ns;
+	 *   - arch/x86/kvm/x86.c|14529| <<kvm_arch_hardware_enable>> kvm->arch.last_tsc_nsec = 0;
+	 */
 	u64 last_tsc_nsec;
+	/*
+	 * 在以下使用kvm_arch->last_tsc_write:
+	 *   - arch/x86/kvm/x86.c|3280| <<kvm_synchronize_tsc>> u64 tsc_exp = kvm->arch.last_tsc_write +
+	 *                                                              nsec_to_cycles(vcpu, elapsed);
+	 *   - arch/x86/kvm/x86.c|3354| <<kvm_synchronize_tsc>> kvm->arch.last_tsc_write = data;
+	 *   - arch/x86/kvm/x86.c|14530| <<kvm_arch_hardware_enable>> kvm->arch.last_tsc_write = 0;
+	 */
 	u64 last_tsc_write;
 	u32 last_tsc_khz;
 	u64 cur_tsc_nsec;
 	u64 cur_tsc_write;
 	u64 cur_tsc_offset;
 	u64 cur_tsc_generation;
+	/*
+	 * 在以下使用kvm_arch->nr_vcpus_matched_tsc:
+	 *   - arch/x86/kvm/x86.c|2850| <<kvm_track_tsc_matching>> bool use_master_clock = (ka->nr_vcpus_matched_tsc + 1 ==
+	 *   - arch/x86/kvm/x86.c|2876| <<kvm_track_tsc_matching>> trace_kvm_track_tsc(vcpu->vcpu_id, ka->nr_vcpus_matched_tsc,
+	 *   - arch/x86/kvm/x86.c|3190| <<kvm_synchronize_tsc>> kvm->arch.nr_vcpus_matched_tsc = 0;
+	 *   - arch/x86/kvm/x86.c|3192| <<kvm_synchronize_tsc>> kvm->arch.nr_vcpus_matched_tsc++;
+	 *   - arch/x86/kvm/x86.c|3399| <<pvclock_update_vm_gtod_copy>> vcpus_matched = (ka->nr_vcpus_matched_tsc + 1 ==
+	 */
 	int nr_vcpus_matched_tsc;
 
+	/*
+	 * 使用kvm_arch->pvclock_gtod_sync_lock的函数:
+	 *   - kvm_synchronize_tsc()
+	 *   - kvm_gen_update_masterclock()
+	 *   - get_kvmclock_ns()
+	 *   - kvm_guest_time_update()
+	 *   - kvm_arch_vm_ioctl(KVM_SET_CLOCK)
+	 *   - kvm_hyperv_tsc_notifier()
+	 *   - kvm_arch_init_vm()
+	 */
 	raw_spinlock_t pvclock_gtod_sync_lock;
+	/*
+	 * 在以下设置kvm_arch->use_master_clock:
+	 *   - arch/x86/kvm/x86.c|3073| <<pvclock_update_vm_gtod_copy>> ka->use_master_clock = host_tsc_clocksource && vcpus_matched
+	 * 在以下使用kvm_arch->use_master_clock:
+	 *   - arch/x86/kvm/x86.c|2620| <<kvm_track_tsc_matching>> if ((ka->use_master_clock && new_generation) ||
+	 *   - arch/x86/kvm/x86.c|2621| <<kvm_track_tsc_matching>> (ka->use_master_clock != use_master_clock))
+	 *   - arch/x86/kvm/x86.c|2626| <<kvm_track_tsc_matching>> ka->use_master_clock, gtod->clock.vclock_mode);
+	 *   - arch/x86/kvm/x86.c|3077| <<pvclock_update_vm_gtod_copy>> if (ka->use_master_clock)
+	 *   - arch/x86/kvm/x86.c|3081| <<pvclock_update_vm_gtod_copy>> trace_kvm_update_master_clock(ka->use_master_clock, vclock_mode,
+	 *   - arch/x86/kvm/x86.c|3130| <<get_kvmclock_ns>> if (!ka->use_master_clock) {
+	 *   - arch/x86/kvm/x86.c|3232| <<kvm_guest_time_update>> use_master_clock = ka->use_master_clock;
+	 *   - arch/x86/kvm/x86.c|4817| <<kvm_arch_vcpu_load>> if (!vcpu->kvm->arch.use_master_clock || vcpu->cpu == -1)
+	 *   - arch/x86/kvm/x86.c|6791| <<kvm_arch_vm_ioctl(KVM_SET_CLOCK)>> if (kvm->arch.use_master_clock)
+	 *   - arch/x86/kvm/x86.c|6807| <<kvm_arch_vm_ioctl(KVM_GET_CLOCK)>> user_ns.flags = kvm->arch.use_master_clock ? KVM_CLOCK_TSC_STABLE : 0;
+	 */
 	bool use_master_clock;
+	/*
+	 * 在以下设置kvm_arch->master_kernel_ns:
+	 *   - arch/x86/kvm/x86.c|3070| <<pvclock_update_vm_gtod_copy>> &ka->master_kernel_ns,
+	 *   - arch/x86/kvm/x86.c|3145| <<get_kvmclock_ns>> hv_clock.system_time = ka->master_kernel_ns + ka->kvmclock_offset;
+	 *   - arch/x86/kvm/x86.c|3254| <<kvm_guest_time_update>> kernel_ns = ka->master_kernel_ns;
+	 *   - arch/x86/kvm/x86.c|6811| <<kvm_arch_vm_ioctl>> now_ns = ka->master_kernel_ns;
+	 */
 	u64 master_kernel_ns;
+	/*
+	 * 在以下使用kvm_arch->master_cycle_now:
+	 *   - arch/x86/kvm/x86.c|3071| <<pvclock_update_vm_gtod_copy>> host_tsc_clocksource =
+	 *               kvm_get_time_and_clockread(&ka->master_kernel_ns, &ka->master_cycle_now);
+	 *   - arch/x86/kvm/x86.c|3144| <<get_kvmclock_ns>> hv_clock.tsc_timestamp = ka->master_cycle_now;
+	 *   - arch/x86/kvm/x86.c|3253| <<kvm_guest_time_update>> host_tsc = ka->master_cycle_now;
+	 */
 	u64 master_cycle_now;
+	/*
+	 * 在以下使用kvm_arch->kvmclock_update_work:
+	 *   - arch/x86/kvm/x86.c|3508| <<kvm_gen_kvmclock_update>> schedule_delayed_work(&kvm->arch.kvmclock_update_work, KVMCLOCK_UPDATE_DELAY);
+	 *   - arch/x86/kvm/x86.c|3529| <<kvmclock_sync_fn>> schedule_delayed_work(&kvm->arch.kvmclock_update_work, 0);
+	 *   - arch/x86/kvm/x86.c|13529| <<kvm_arch_init_vm>> INIT_DELAYED_WORK(&kvm->arch.kvmclock_update_work, kvmclock_update_fn);
+	 *   - arch/x86/kvm/x86.c|13578| <<kvm_arch_sync_events>> cancel_delayed_work_sync(&kvm->arch.kvmclock_update_work);
+	 *
+	 * kvmclock_update_fn()
+	 */
 	struct delayed_work kvmclock_update_work;
+	/*
+	 * 在以下使用kvm_arch->kvmclock_sync_work:
+	 *   - arch/x86/kvm/x86.c|3535| <<kvmclock_sync_fn>> schedule_delayed_work(&kvm->arch.kvmclock_sync_work, KVMCLOCK_SYNC_PERIOD);
+	 *   - arch/x86/kvm/x86.c|12997| <<kvm_arch_vcpu_postcreate>> schedule_delayed_work(&kvm->arch.kvmclock_sync_work, KVMCLOCK_SYNC_PERIOD);
+	 *   - arch/x86/kvm/x86.c|13530| <<kvm_arch_init_vm>> INIT_DELAYED_WORK(&kvm->arch.kvmclock_sync_work, kvmclock_sync_fn);
+	 *   - arch/x86/kvm/x86.c|13577| <<kvm_arch_sync_events>> cancel_delayed_work_sync(&kvm->arch.kvmclock_sync_work);
+	 *
+	 * kvmclock_sync_fn()
+	 */
 	struct delayed_work kvmclock_sync_work;
 
 	struct kvm_xen_hvm_config xen_hvm_config;
 
+	/*
+	 * 在以下使用kvm_arch->mask_notifier_list:
+	 *   - arch/x86/kvm/irq_comm.c|234| <<kvm_register_irq_mask_notifier>> hlist_add_head_rcu(&kimn->link, &kvm->arch.mask_notifier_list);
+	 *   - arch/x86/kvm/irq_comm.c|256| <<kvm_fire_mask_notifiers>> hlist_for_each_entry_rcu(kimn, &kvm->arch.mask_notifier_list, link)
+	 *   - arch/x86/kvm/x86.c|11763| <<kvm_arch_init_vm>> INIT_HLIST_HEAD(&kvm->arch.mask_notifier_list);
+	 */
 	/* reads protected by irq_srcu, writes by irq_lock */
 	struct hlist_head mask_notifier_list;
 
@@ -1195,11 +1666,38 @@ struct kvm_arch {
 	int cpu_dirty_logging_count;
 
 	enum kvm_irqchip_mode irqchip_mode;
+	/*
+	 * 在以下使用kvm_arch->nr_reserved_ioapic_pins:
+	 *   - arch/x86/kvm/irq_comm.c|405| <<kvm_scan_ioapic_routes>> nr_ioapic_pins =
+	 *               min_t(u32, table->nr_rt_entries, kvm->arch.nr_reserved_ioapic_pins);
+	 *   - arch/x86/kvm/x86.c|5796| <<kvm_vm_ioctl_enable_cap>>
+	 *               kvm->arch.nr_reserved_ioapic_pins = cap->args[0];
+	 */
 	u8 nr_reserved_ioapic_pins;
 
 	bool disabled_lapic_found;
 
+	/*
+	 * 在以下使用kvm_arch->x2apic_format:
+	 *   - arch/x86/kvm/irq_comm.c|137| <<kvm_set_msi_irq>> trace_kvm_msi_set_irq(msg.address_lo | (kvm->arch.x2apic_format ?
+	 *   - arch/x86/kvm/irq_comm.c|140| <<kvm_set_msi_irq>> irq->dest_id = x86_msi_msg_get_destid(&msg, kvm->arch.x2apic_format);
+	 *   - arch/x86/kvm/irq_comm.c|154| <<kvm_msi_route_invalid>> return kvm->arch.x2apic_format && (e->msi.address_hi & 0xff);
+	 *   - arch/x86/kvm/lapic.c|3673| <<kvm_apic_state_fixup>> if (vcpu->kvm->arch.x2apic_format) {
+	 *   - arch/x86/kvm/x86.c|5933| <<kvm_vm_ioctl_enable_cap>> kvm->arch.x2apic_format = true;
+	 *
+	 *     x2apic_format = false,
+	 *     x2apic_broadcast_quirk_disabled = false,
+	 */
 	bool x2apic_format;
+	/*
+	 * 在以下使用kvm_arch->x2apic_broadcast_quirk_disabled:
+	 *   - arch/x86/kvm/lapic.c|1356| <<kvm_apic_mda>> if (!vcpu->kvm->arch.x2apic_broadcast_quirk_disabled &&
+	 *   - arch/x86/kvm/lapic.c|1435| <<kvm_apic_is_broadcast_dest>> if (kvm->arch.x2apic_broadcast_quirk_disabled) {
+	 *   - arch/x86/kvm/x86.c|5935| <<kvm_vm_ioctl_enable_cap>> kvm->arch.x2apic_broadcast_quirk_disabled = true;
+	 *
+	 *     x2apic_format = false,
+	 *     x2apic_broadcast_quirk_disabled = false,
+	 */
 	bool x2apic_broadcast_quirk_disabled;
 
 	bool guest_can_read_msr_platform_info;
@@ -1872,15 +2370,41 @@ void __kvm_set_or_clear_apicv_inhibit(struct kvm *kvm,
 void kvm_set_or_clear_apicv_inhibit(struct kvm *kvm,
 				    enum kvm_apicv_inhibit reason, bool set);
 
+/*
+ * 在以下使用kvm_set_apicv_inhibit():
+ *   - arch/x86/kvm/i8254.c|308| <<kvm_pit_set_reinject>> kvm_set_apicv_inhibit(kvm, APICV_INHIBIT_REASON_PIT_REINJ);
+ *   - arch/x86/kvm/lapic.c|337| <<kvm_recalculate_apic_map>> kvm_set_apicv_inhibit(kvm, APICV_INHIBIT_REASON_APIC_ID_MODIFIED);
+ *   - arch/x86/kvm/lapic.c|2715| <<kvm_lapic_set_base>> kvm_set_apicv_inhibit(apic->vcpu->kvm, APICV_INHIBIT_REASON_APIC_BASE_MODIFIED);
+ *   - arch/x86/kvm/svm/sev.c|263| <<sev_guest_init>> kvm_set_apicv_inhibit(kvm, APICV_INHIBIT_REASON_SEV);
+ *   - arch/x86/kvm/svm/svm.c|3855| <<svm_enable_irq_window>> kvm_set_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+ */
 static inline void kvm_set_apicv_inhibit(struct kvm *kvm,
 					 enum kvm_apicv_inhibit reason)
 {
+	/*
+	 * 在以下调用kvm_set_or_clear_apicv_inhibit():
+	 *   - arch/x86/include/asm/kvm_host.h|2021| <<kvm_set_apicv_inhibit>> kvm_set_or_clear_apicv_inhibit(kvm, reason, true);
+	 *   - arch/x86/include/asm/kvm_host.h|2027| <<kvm_clear_apicv_inhibit>> kvm_set_or_clear_apicv_inhibit(kvm, reason, false);
+	 */
 	kvm_set_or_clear_apicv_inhibit(kvm, reason, true);
 }
 
+/*
+ * 在以下使用kvm_clear_apicv_inhibit():
+ *   - arch/x86/kvm/i8254.c|314| <<kvm_pit_set_reinject>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_PIT_REINJ);
+ *   - arch/x86/kvm/lapic.c|579| <<kvm_recalculate_apic_map>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_APIC_ID_MODIFIED);
+ *   - arch/x86/kvm/svm/svm.c|3235| <<interrupt_window_interception>> kvm_clear_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+ *   - arch/x86/kvm/x86.c|6050| <<kvm_vm_ioctl_enable_cap(KVM_CAP_SPLIT_IRQCHIP)>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
+ *   - arch/x86/kvm/x86.c|6465| <<kvm_arch_vm_ioctl(KVM_CREATE_IRQCHIP)>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
+ */
 static inline void kvm_clear_apicv_inhibit(struct kvm *kvm,
 					   enum kvm_apicv_inhibit reason)
 {
+	/*
+	 * 在以下调用kvm_set_or_clear_apicv_inhibit():
+	 *   - arch/x86/include/asm/kvm_host.h|2021| <<kvm_set_apicv_inhibit>> kvm_set_or_clear_apicv_inhibit(kvm, reason, true);
+	 *   - arch/x86/include/asm/kvm_host.h|2027| <<kvm_clear_apicv_inhibit>> kvm_set_or_clear_apicv_inhibit(kvm, reason, false);
+	 */
 	kvm_set_or_clear_apicv_inhibit(kvm, reason, false);
 }
 
diff --git a/arch/x86/include/asm/pvclock.h b/arch/x86/include/asm/pvclock.h
index 19b695ff2c68..20fb6b021ea1 100644
--- a/arch/x86/include/asm/pvclock.h
+++ b/arch/x86/include/asm/pvclock.h
@@ -78,6 +78,13 @@ static inline u64 pvclock_scale_delta(u64 delta, u32 mul_frac, int shift)
 	return product;
 }
 
+/*
+ * 在以下使用__pvclock_read_cycles():
+ *   - arch/x86/include/asm/vdso/gettimeofday.h|231| <<vread_pvclock>> ret = __pvclock_read_cycles(pvti, rdtsc_ordered());
+ *   - arch/x86/kernel/pvclock.c|76| <<pvclock_clocksource_read>> ret = __pvclock_read_cycles(src, rdtsc_ordered());
+ *   - arch/x86/kvm/x86.c|3146| <<get_kvmclock_ns>> ret = __pvclock_read_cycles(&hv_clock, rdtsc());
+ *   - drivers/ptp/ptp_kvm_x86.c|123| <<kvm_arch_ptp_get_crosststamp>> *cycle = __pvclock_read_cycles(src, clock_pair->tsc);
+ */
 static __always_inline
 u64 __pvclock_read_cycles(const struct pvclock_vcpu_time_info *src, u64 tsc)
 {
diff --git a/arch/x86/kernel/apic/apic.c b/arch/x86/kernel/apic/apic.c
index 518663e794af..a442f6e71325 100644
--- a/arch/x86/kernel/apic/apic.c
+++ b/arch/x86/kernel/apic/apic.c
@@ -1212,6 +1212,11 @@ void clear_local_APIC(void)
  * in that state and it's not clear from the SDM whether it still responds
  * to INIT/SIPI messages. Stay on the safe side and use software disable.
  */
+/*
+ * 在以下使用apic_soft_disable():
+ *   - arch/x86/kernel/apic/apic.c|1236| <<disable_local_APIC>> apic_soft_disable();
+ *   - arch/x86/kernel/smpboot.c|1741| <<native_cpu_disable>> apic_soft_disable();
+ */
 void apic_soft_disable(void)
 {
 	u32 value;
@@ -1764,6 +1769,12 @@ enum {
 };
 static int x2apic_state;
 
+/*
+ * 在以下使用__x2apic_disable():
+ *   - arch/x86/kernel/apic/apic.c|1805| <<setup_nox2apic>> __x2apic_disable();
+ *   - arch/x86/kernel/apic/apic.c|1822| <<x2apic_setup>> __x2apic_disable();
+ *   - arch/x86/kernel/apic/apic.c|1842| <<x2apic_disable>> __x2apic_disable();
+ */
 static void __x2apic_disable(void)
 {
 	u64 msr;
@@ -1825,6 +1836,10 @@ void x2apic_setup(void)
 	__x2apic_enable();
 }
 
+/*
+ * 在以下使用x2apic_disable():
+ *   - arch/x86/kernel/apic/apic.c|1870| <<try_to_enable_x2apic>> x2apic_disable();
+ */
 static __init void x2apic_disable(void)
 {
 	u32 x2apic_id, state = x2apic_state;
diff --git a/arch/x86/kernel/apic/io_apic.c b/arch/x86/kernel/apic/io_apic.c
index 586ea838a5a1..22f9c3bc4c2a 100644
--- a/arch/x86/kernel/apic/io_apic.c
+++ b/arch/x86/kernel/apic/io_apic.c
@@ -1896,6 +1896,11 @@ static void ioapic_setup_msg_from_msi(struct irq_data *irq_data,
 	entry->ir_index_0_14		= msg.arch_addr_lo.dmar_index_0_14;
 }
 
+/*
+ * 在以下使用ioapic_configure_entry():
+ *   - arch/x86/kernel/apic/io_apic.c|1920| <<ioapic_set_affinity>> ioapic_configure_entry(irq_data);
+ *   - arch/x86/kernel/apic/io_apic.c|3078| <<mp_irqdomain_activate>> ioapic_configure_entry(irq_data);
+ */
 static void ioapic_configure_entry(struct irq_data *irqd)
 {
 	struct mp_chip_data *mpd = irqd->chip_data;
diff --git a/arch/x86/kernel/cpu/intel.c b/arch/x86/kernel/cpu/intel.c
index 0ad97eea771e..b271e25c5642 100644
--- a/arch/x86/kernel/cpu/intel.c
+++ b/arch/x86/kernel/cpu/intel.c
@@ -53,7 +53,28 @@ enum split_lock_detect_state {
  * sld_state_setup() will switch this to sld_warn on systems that support
  * split lock/bus lock detect, unless there is a command line override.
  */
+/*
+ * 在以下使用sld_state:
+ *   - arch/x86/kernel/cpu/intel.c|60| <<global>> static enum split_lock_detect_state sld_state __ro_after_init = sld_off;
+ *   - arch/x86/kernel/cpu/intel.c|1100| <<sld_state_setup>> sld_state = state;
+ *   - arch/x86/kernel/cpu/intel.c|1144| <<split_lock_init>> if (sld_state == sld_ratelimit) {
+ *   - arch/x86/kernel/cpu/intel.c|1150| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+ *   - arch/x86/kernel/cpu/intel.c|1222| <<handle_guest_split_lock>> if (sld_state == sld_warn) {
+ *   - arch/x86/kernel/cpu/intel.c|1229| <<handle_guest_split_lock>> sld_state == sld_fatal ? "fatal" : "bogus", ip);
+ *   - arch/x86/kernel/cpu/intel.c|1248| <<bus_lock_init>> (sld_state == sld_warn || sld_state == sld_fatal)) ||
+ *   - arch/x86/kernel/cpu/intel.c|1249| <<bus_lock_init>> sld_state == sld_off) {
+ *   - arch/x86/kernel/cpu/intel.c|1264| <<handle_user_split_lock>> if ((regs->flags & X86_EFLAGS_AC) || sld_state == sld_fatal)
+ *   - arch/x86/kernel/cpu/intel.c|1272| <<handle_bus_lock>> switch (sld_state) {
+ *   - arch/x86/kernel/cpu/intel.c|1355| <<sld_state_show>> switch (sld_state) {
+ */
 static enum split_lock_detect_state sld_state __ro_after_init = sld_off;
+/*
+ * 在以下使用msr_test_ctrl_cache:
+ *   - arch/x86/kernel/cpu/intel.c|71| <<global>> static u64 msr_test_ctrl_cache __ro_after_init;
+ *   - arch/x86/kernel/cpu/intel.c|1173| <<__split_lock_setup>> rdmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
+ *   - arch/x86/kernel/cpu/intel.c|1188| <<__split_lock_setup>> wrmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
+ *   - arch/x86/kernel/cpu/intel.c|1200| <<sld_update_msr>> u64 test_ctrl_val = msr_test_ctrl_cache;
+ */
 static u64 msr_test_ctrl_cache __ro_after_init;
 
 /*
@@ -61,6 +82,12 @@ static u64 msr_test_ctrl_cache __ro_after_init;
  * MSR_TEST_CTL unless the CPU is one of the whitelisted models.  Writing it
  * on CPUs that do not support SLD can cause fireworks, even when writing '0'.
  */
+/*
+ * 在以下使用cpu_model_supports_sld:
+ *   - arch/x86/kernel/cpu/intel.c|64| <<global>> static bool cpu_model_supports_sld __ro_after_init;
+ *   - arch/x86/kernel/cpu/intel.c|1145| <<split_lock_init>> if (cpu_model_supports_sld)
+ *   - arch/x86/kernel/cpu/intel.c|1341| <<split_lock_setup>> cpu_model_supports_sld = true;
+ */
 static bool cpu_model_supports_sld __ro_after_init;
 
 /*
@@ -998,6 +1025,14 @@ cpu_dev_register(intel_cpu_dev);
 #undef pr_fmt
 #define pr_fmt(fmt) "x86/split lock detection: " fmt
 
+/*
+ * enum split_lock_detect_state {
+ *     sld_off = 0,
+ *     sld_warn,
+ *     sld_fatal,
+ *     sld_ratelimit,
+ * };
+ */
 static const struct {
 	const char			*option;
 	enum split_lock_detect_state	state;
@@ -1008,9 +1043,29 @@ static const struct {
 	{ "ratelimit:", sld_ratelimit },
 };
 
+/*
+ * 在以下使用bld_ratelimit:
+ *   - arch/x86/kernel/cpu/intel.c|1052| <<match_option>> ratelimit_state_init(&bld_ratelimit, HZ, ratelimit);
+ *   - arch/x86/kernel/cpu/intel.c|1053| <<match_option>> ratelimit_set_flags(&bld_ratelimit, RATELIMIT_MSG_ON_RELEASE);
+ *   - arch/x86/kernel/cpu/intel.c|1273| <<handle_bus_lock>> while (!__ratelimit(&bld_ratelimit))
+ *   - arch/x86/kernel/cpu/intel.c|1376| <<sld_state_show>> pr_info("#DB: setting system wide bus lock rate limit to %u/sec\n",
+ *                                             bld_ratelimit.burst);
+ */
 static struct ratelimit_state bld_ratelimit;
 
+/*
+ * 在以下使用sysctl_sld_mitigate:
+ *   - arch/x86/kernel/cpu/intel.c|1013| <<global>> static unsigned int sysctl_sld_mitigate = 1;
+ *   - arch/x86/kernel/cpu/intel.c|1020| <<global>> .data = &sysctl_sld_mitigate,
+ *   - arch/x86/kernel/cpu/intel.c|1190| <<split_lock_warn>> if (sysctl_sld_mitigate) {
+ */
 static unsigned int sysctl_sld_mitigate = 1;
+/*
+ * 在以下使用buslock_sem:
+ *   - arch/x86/kernel/cpu/intel.c|1063| <<global>> static DEFINE_SEMAPHORE(buslock_sem);
+ *   - arch/x86/kernel/cpu/intel.c|1313| <<__split_lock_reenable_unlock>> up(&buslock_sem);
+ *   - arch/x86/kernel/cpu/intel.c|1389| <<split_lock_warn>> if (down_interruptible(&buslock_sem) == -EINTR)
+ */
 static DEFINE_SEMAPHORE(buslock_sem);
 
 #ifdef CONFIG_PROC_SYSCTL
@@ -1029,6 +1084,9 @@ static struct ctl_table sld_sysctls[] = {
 
 static int __init sld_mitigate_sysctl_init(void)
 {
+	/*
+	 * sysctl_sld_mitigate
+	 */
 	register_sysctl_init("kernel", sld_sysctls);
 	return 0;
 }
@@ -1057,12 +1115,34 @@ static inline bool match_option(const char *arg, int arglen, const char *opt)
 	return len == arglen;
 }
 
+/*
+ * 在以下调用split_lock_verify_msr():
+ *   - arch/x86/kernel/cpu/intel.c|1101| <<__split_lock_setup>> if (!split_lock_verify_msr(false)) {
+ *   - arch/x86/kernel/cpu/intel.c|1108| <<__split_lock_setup>> if (!split_lock_verify_msr(true)) {
+ *   - arch/x86/kernel/cpu/intel.c|1141| <<split_lock_init>> split_lock_verify_msr(false);
+ *   - arch/x86/kernel/cpu/intel.c|1146| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+ */
 static bool split_lock_verify_msr(bool on)
 {
 	u64 ctrl, tmp;
 
+	/*
+	 * 在以下使用MSR_TEST_CTRL:
+	 *   - arch/x86/kernel/cpu/intel.c|1129| <<split_lock_verify_msr>> if (rdmsrl_safe(MSR_TEST_CTRL, &ctrl))
+	 *   - arch/x86/kernel/cpu/intel.c|1141| <<split_lock_verify_msr>> if (wrmsrl_safe(MSR_TEST_CTRL, ctrl))
+	 *   - arch/x86/kernel/cpu/intel.c|1143| <<split_lock_verify_msr>> rdmsrl(MSR_TEST_CTRL, tmp);
+	 *   - arch/x86/kernel/cpu/intel.c|1223| <<__split_lock_setup>> rdmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
+	 *   - arch/x86/kernel/cpu/intel.c|1238| <<__split_lock_setup>> wrmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
+	 *   - arch/x86/kernel/cpu/intel.c|1293| <<sld_update_msr>> wrmsrl(MSR_TEST_CTRL, test_ctrl_val);
+	 */
 	if (rdmsrl_safe(MSR_TEST_CTRL, &ctrl))
 		return false;
+	/*
+	 * 在以下使用MSR_TEST_CTRL_SPLIT_LOCK_DETECT:
+	 *   - arch/x86/kernel/cpu/intel.c|1132| <<split_lock_verify_msr>> ctrl |= MSR_TEST_CTRL_SPLIT_LOCK_DETECT;
+	 *   - arch/x86/kernel/cpu/intel.c|1134| <<split_lock_verify_msr>> ctrl &= ~MSR_TEST_CTRL_SPLIT_LOCK_DETECT;
+	 *   - arch/x86/kernel/cpu/intel.c|1275| <<sld_update_msr>> test_ctrl_val |= MSR_TEST_CTRL_SPLIT_LOCK_DETECT;
+	 */
 	if (on)
 		ctrl |= MSR_TEST_CTRL_SPLIT_LOCK_DETECT;
 	else
@@ -1073,8 +1153,22 @@ static bool split_lock_verify_msr(bool on)
 	return ctrl == tmp;
 }
 
+/*
+ * 在以下调用sld_state_setup():
+ *   - arch/x86/kernel/cpu/intel.c|1675| <<sld_setup>> sld_state_setup();
+ */
 static void __init sld_state_setup(void)
 {
+	/*
+	 * enum split_lock_detect_state {
+	 *     sld_off = 0,
+	 *     sld_warn,
+	 *     sld_fatal,
+	 *     sld_ratelimit,
+	 * };
+	 *
+	 * 默认是sld_warn.
+	 */
 	enum split_lock_detect_state state = sld_warn;
 	char arg[20];
 	int i, ret;
@@ -1093,18 +1187,65 @@ static void __init sld_state_setup(void)
 			}
 		}
 	}
+	/*
+	 * 在以下使用sld_state:
+	 *   - arch/x86/kernel/cpu/intel.c|60| <<global>> static enum split_lock_detect_state sld_state __ro_after_init = sld_off;
+	 *   - arch/x86/kernel/cpu/intel.c|1100| <<sld_state_setup>> sld_state = state;
+	 *   - arch/x86/kernel/cpu/intel.c|1144| <<split_lock_init>> if (sld_state == sld_ratelimit) {
+	 *   - arch/x86/kernel/cpu/intel.c|1150| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+	 *   - arch/x86/kernel/cpu/intel.c|1222| <<handle_guest_split_lock>> if (sld_state == sld_warn) {
+	 *   - arch/x86/kernel/cpu/intel.c|1229| <<handle_guest_split_lock>> sld_state == sld_fatal ? "fatal" : "bogus", ip);
+	 *   - arch/x86/kernel/cpu/intel.c|1248| <<bus_lock_init>> (sld_state == sld_warn || sld_state == sld_fatal)) ||
+	 *   - arch/x86/kernel/cpu/intel.c|1249| <<bus_lock_init>> sld_state == sld_off) {
+	 *   - arch/x86/kernel/cpu/intel.c|1264| <<handle_user_split_lock>> if ((regs->flags & X86_EFLAGS_AC) || sld_state == sld_fatal)
+	 *   - arch/x86/kernel/cpu/intel.c|1272| <<handle_bus_lock>> switch (sld_state) {
+	 *   - arch/x86/kernel/cpu/intel.c|1355| <<sld_state_show>> switch (sld_state) {
+	 */
 	sld_state = state;
 }
 
+/*
+ * 在以下使用__split_lock_setup():
+ *   - arch/x86/kernel/cpu/intel.c|1715| <<split_lock_setup>> __split_lock_setup();
+ */
 static void __init __split_lock_setup(void)
 {
+	/*
+	 * 在以下调用split_lock_verify_msr():
+	 *   - arch/x86/kernel/cpu/intel.c|1101| <<__split_lock_setup>> if (!split_lock_verify_msr(false)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1108| <<__split_lock_setup>> if (!split_lock_verify_msr(true)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1141| <<split_lock_init>> split_lock_verify_msr(false);
+	 *   - arch/x86/kernel/cpu/intel.c|1146| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+	 */
 	if (!split_lock_verify_msr(false)) {
 		pr_info("MSR access failed: Disabled\n");
 		return;
 	}
 
+	/*
+	 * 在以下使用MSR_TEST_CTRL:
+	 *   - arch/x86/kernel/cpu/intel.c|1129| <<split_lock_verify_msr>> if (rdmsrl_safe(MSR_TEST_CTRL, &ctrl))
+	 *   - arch/x86/kernel/cpu/intel.c|1141| <<split_lock_verify_msr>> if (wrmsrl_safe(MSR_TEST_CTRL, ctrl))
+	 *   - arch/x86/kernel/cpu/intel.c|1143| <<split_lock_verify_msr>> rdmsrl(MSR_TEST_CTRL, tmp);
+	 *   - arch/x86/kernel/cpu/intel.c|1223| <<__split_lock_setup>> rdmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
+	 *   - arch/x86/kernel/cpu/intel.c|1238| <<__split_lock_setup>> wrmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
+	 *   - arch/x86/kernel/cpu/intel.c|1293| <<sld_update_msr>> wrmsrl(MSR_TEST_CTRL, test_ctrl_val);
+	 *
+	 * 在以下使用msr_test_ctrl_cache:
+	 *   - arch/x86/kernel/cpu/intel.c|71| <<global>> static u64 msr_test_ctrl_cache __ro_after_init;
+	 *   - arch/x86/kernel/cpu/intel.c|1173| <<__split_lock_setup>> rdmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
+	 *   - arch/x86/kernel/cpu/intel.c|1188| <<__split_lock_setup>> wrmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
+	 *   - arch/x86/kernel/cpu/intel.c|1200| <<sld_update_msr>> u64 test_ctrl_val = msr_test_ctrl_cache;
+	 */
 	rdmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
 
+	/*
+	 * 在以下调用split_lock_verify_msr():
+	 *   - arch/x86/kernel/cpu/intel.c|1101| <<__split_lock_setup>> if (!split_lock_verify_msr(false)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1108| <<__split_lock_setup>> if (!split_lock_verify_msr(true)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1141| <<split_lock_init>> split_lock_verify_msr(false);
+	 *   - arch/x86/kernel/cpu/intel.c|1146| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+	 */
 	if (!split_lock_verify_msr(true)) {
 		pr_info("MSR access failed: Disabled\n");
 		return;
@@ -1113,6 +1254,20 @@ static void __init __split_lock_setup(void)
 	/* Restore the MSR to its cached value. */
 	wrmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
 
+	/*
+	 * 在以下使用X86_FEATURE_SPLIT_LOCK_DETECT:
+	 *   - arch/x86/kernel/cpu/intel.c|1149| <<sld_state_setup>> if (!boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) &&
+	 *   - arch/x86/kernel/cpu/intel.c|1221| <<__split_lock_setup>> setup_force_cpu_cap(X86_FEATURE_SPLIT_LOCK_DETECT);
+	 *   - arch/x86/kernel/cpu/intel.c|1475| <<bus_lock_init>> if ((boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) &&
+	 *   - arch/x86/kernel/cpu/intel.c|1621| <<sld_state_show>> !boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 *   - arch/x86/kernel/cpu/intel.c|1643| <<sld_state_show>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1653| <<sld_state_show>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1657| <<sld_state_show>> boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) ?
+	 *   - arch/x86/kvm/vmx/vmx.c|4917| <<vmx_guest_inject_ac>> if (!boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 *   - arch/x86/kvm/x86.c|7297| <<emulator_cmpxchg_emulated>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 *
+	 * 只在此处设置X86_FEATURE_SPLIT_LOCK_DETECT
+	 */
 	setup_force_cpu_cap(X86_FEATURE_SPLIT_LOCK_DETECT);
 }
 
@@ -1121,18 +1276,66 @@ static void __init __split_lock_setup(void)
  * is not implemented as one thread could undo the setting of the other
  * thread immediately after dropping the lock anyway.
  */
+/*
+ * 在以下使用sld_update_msr():
+ *   - arch/x86/kernel/cpu/intel.c|1239| <<__split_lock_reenable_unlock>> sld_update_msr(true);
+ *   - arch/x86/kernel/cpu/intel.c|1247| <<__split_lock_reenable>> sld_update_msr(true);
+ *   - arch/x86/kernel/cpu/intel.c|1263| <<splitlock_cpu_offline>> sld_update_msr(true);
+ *   - arch/x86/kernel/cpu/intel.c|1305| <<split_lock_warn>> sld_update_msr(false);
+ *
+ * MSR_TEST_CTRL is per core, but we treat it like a per CPU MSR. Locking
+ * is not implemented as one thread could undo the setting of the other
+ * thread immediately after dropping the lock anyway.
+ */
 static void sld_update_msr(bool on)
 {
+	/*
+	 * 在以下使用msr_test_ctrl_cache:
+	 *   - arch/x86/kernel/cpu/intel.c|71| <<global>> static u64 msr_test_ctrl_cache __ro_after_init;
+	 *   - arch/x86/kernel/cpu/intel.c|1173| <<__split_lock_setup>> rdmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
+	 *   - arch/x86/kernel/cpu/intel.c|1188| <<__split_lock_setup>> wrmsrl(MSR_TEST_CTRL, msr_test_ctrl_cache);
+	 *   - arch/x86/kernel/cpu/intel.c|1200| <<sld_update_msr>> u64 test_ctrl_val = msr_test_ctrl_cache;0
+	 */
 	u64 test_ctrl_val = msr_test_ctrl_cache;
 
+	/*
+	 * 在以下使用MSR_TEST_CTRL_SPLIT_LOCK_DETECT:
+	 *   - arch/x86/kernel/cpu/intel.c|1132| <<split_lock_verify_msr>> ctrl |= MSR_TEST_CTRL_SPLIT_LOCK_DETECT;
+	 *   - arch/x86/kernel/cpu/intel.c|1134| <<split_lock_verify_msr>> ctrl &= ~MSR_TEST_CTRL_SPLIT_LOCK_DETECT;
+	 *   - arch/x86/kernel/cpu/intel.c|1275| <<sld_update_msr>> test_ctrl_val |= MSR_TEST_CTRL_SPLIT_LOCK_DETECT;
+	 */
 	if (on)
 		test_ctrl_val |= MSR_TEST_CTRL_SPLIT_LOCK_DETECT;
 
 	wrmsrl(MSR_TEST_CTRL, test_ctrl_val);
 }
 
+/*
+ * 在以下调用split_lock_init():
+ *   - arch/x86/kernel/cpu/intel.c|758| <<init_intel>> split_lock_init();
+ */
 static void split_lock_init(void)
 {
+	/*
+	 * 在以下使用sld_state:
+	 *   - arch/x86/kernel/cpu/intel.c|60| <<global>> static enum split_lock_detect_state sld_state __ro_after_init = sld_off;
+	 *   - arch/x86/kernel/cpu/intel.c|1100| <<sld_state_setup>> sld_state = state;
+	 *   - arch/x86/kernel/cpu/intel.c|1144| <<split_lock_init>> if (sld_state == sld_ratelimit) {
+	 *   - arch/x86/kernel/cpu/intel.c|1150| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+	 *   - arch/x86/kernel/cpu/intel.c|1222| <<handle_guest_split_lock>> if (sld_state == sld_warn) {
+	 *   - arch/x86/kernel/cpu/intel.c|1229| <<handle_guest_split_lock>> sld_state == sld_fatal ? "fatal" : "bogus", ip);
+	 *   - arch/x86/kernel/cpu/intel.c|1248| <<bus_lock_init>> (sld_state == sld_warn || sld_state == sld_fatal)) ||
+	 *   - arch/x86/kernel/cpu/intel.c|1249| <<bus_lock_init>> sld_state == sld_off) {
+	 *   - arch/x86/kernel/cpu/intel.c|1264| <<handle_user_split_lock>> if ((regs->flags & X86_EFLAGS_AC) || sld_state == sld_fatal)
+	 *   - arch/x86/kernel/cpu/intel.c|1272| <<handle_bus_lock>> switch (sld_state) {
+	 *   - arch/x86/kernel/cpu/intel.c|1355| <<sld_state_show>> switch (sld_state) {
+	 *
+	 * 在以下调用split_lock_verify_msr():
+	 *   - arch/x86/kernel/cpu/intel.c|1101| <<__split_lock_setup>> if (!split_lock_verify_msr(false)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1108| <<__split_lock_setup>> if (!split_lock_verify_msr(true)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1141| <<split_lock_init>> split_lock_verify_msr(false);
+	 *   - arch/x86/kernel/cpu/intel.c|1146| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+	 */
 	/*
 	 * #DB for bus lock handles ratelimit and #AC for split lock is
 	 * disabled.
@@ -1142,22 +1345,80 @@ static void split_lock_init(void)
 		return;
 	}
 
+	/*
+	 * enum split_lock_detect_state {
+	 *     sld_off = 0,
+	 *     sld_warn,
+	 *     sld_fatal,
+	 *     sld_ratelimit,
+	 * };
+	 *
+	 * 在以下调用split_lock_verify_msr():
+	 *   - arch/x86/kernel/cpu/intel.c|1101| <<__split_lock_setup>> if (!split_lock_verify_msr(false)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1108| <<__split_lock_setup>> if (!split_lock_verify_msr(true)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1141| <<split_lock_init>> split_lock_verify_msr(false);
+	 *   - arch/x86/kernel/cpu/intel.c|1146| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+	 */
 	if (cpu_model_supports_sld)
 		split_lock_verify_msr(sld_state != sld_off);
 }
 
+/*
+ * 在以下使用__split_lock_reenable_unlock():
+ *   - arch/x86/kernel/cpu/intel.c|1320| <<global>> static DECLARE_DELAYED_WORK(sl_reenable_unlock, __split_lock_reenable_unlock);
+ */
 static void __split_lock_reenable_unlock(struct work_struct *work)
 {
+	/*
+	 * 在以下使用sld_update_msr():
+	 *   - arch/x86/kernel/cpu/intel.c|1239| <<__split_lock_reenable_unlock>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1247| <<__split_lock_reenable>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1263| <<splitlock_cpu_offline>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1305| <<split_lock_warn>> sld_update_msr(false);
+	 *
+	 * MSR_TEST_CTRL is per core, but we treat it like a per CPU MSR. Locking
+	 * is not implemented as one thread could undo the setting of the other
+	 * thread immediately after dropping the lock anyway.
+	 */
 	sld_update_msr(true);
+	/*
+	 * 在以下使用buslock_sem:
+	 *   - arch/x86/kernel/cpu/intel.c|1063| <<global>> static DEFINE_SEMAPHORE(buslock_sem);
+	 *   - arch/x86/kernel/cpu/intel.c|1313| <<__split_lock_reenable_unlock>> up(&buslock_sem);
+	 *   - arch/x86/kernel/cpu/intel.c|1389| <<split_lock_warn>> if (down_interruptible(&buslock_sem) == -EINTR)
+	 */
 	up(&buslock_sem);
 }
 
+/*
+ * 在以下调用sl_reenable_unlock:
+ *   - arch/x86/kernel/cpu/intel.c|1391| <<split_lock_warn>> work = &sl_reenable_unlock;
+ */
 static DECLARE_DELAYED_WORK(sl_reenable_unlock, __split_lock_reenable_unlock);
 
+/*
+ * 在以下使用__split_lock_reenable():
+ *   - arch/x86/kernel/cpu/intel.c|1333| <<global>> static DECLARE_DELAYED_WORK(sl_reenable, __split_lock_reenable);
+ */
 static void __split_lock_reenable(struct work_struct *work)
 {
+	/*
+	 * 在以下使用sld_update_msr():
+	 *   - arch/x86/kernel/cpu/intel.c|1239| <<__split_lock_reenable_unlock>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1247| <<__split_lock_reenable>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1263| <<splitlock_cpu_offline>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1305| <<split_lock_warn>> sld_update_msr(false);
+	 *
+	 * MSR_TEST_CTRL is per core, but we treat it like a per CPU MSR. Locking
+	 * is not implemented as one thread could undo the setting of the other
+	 * thread immediately after dropping the lock anyway.
+	 */
 	sld_update_msr(true);
 }
+/*
+ * 在以下调用sl_reenable:
+ *   - arch/x86/kernel/cpu/intel.c|1393| <<split_lock_warn>> work = &sl_reenable;
+ */
 static DECLARE_DELAYED_WORK(sl_reenable, __split_lock_reenable);
 
 /*
@@ -1172,21 +1433,49 @@ static DECLARE_DELAYED_WORK(sl_reenable, __split_lock_reenable);
  */
 static int splitlock_cpu_offline(unsigned int cpu)
 {
+	/*
+	 * 在以下使用sld_update_msr():
+	 *   - arch/x86/kernel/cpu/intel.c|1239| <<__split_lock_reenable_unlock>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1247| <<__split_lock_reenable>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1263| <<splitlock_cpu_offline>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1305| <<split_lock_warn>> sld_update_msr(false);
+	 *
+	 * MSR_TEST_CTRL is per core, but we treat it like a per CPU MSR. Locking
+	 * is not implemented as one thread could undo the setting of the other
+	 * thread immediately after dropping the lock anyway.
+	 */
 	sld_update_msr(true);
 
 	return 0;
 }
 
+/*
+ * 在以下使用split_lock_warn():
+ *   - arch/x86/kernel/cpu/intel.c|1219| <<handle_guest_split_lock>> split_lock_warn(ip);
+ *   - arch/x86/kernel/cpu/intel.c|1262| <<handle_user_split_lock>> split_lock_warn(regs->ip);
+ */
 static void split_lock_warn(unsigned long ip)
 {
 	struct delayed_work *work;
 	int cpu;
 
+	/*
+	 * 在以下使用task_struct->reported_split_lock:
+	 *   - arch/x86/kernel/cpu/intel.c|1373| <<split_lock_warn>> if (!current->reported_split_lock)
+	 *   - arch/x86/kernel/cpu/intel.c|1376| <<split_lock_warn>> current->reported_split_lock = 1;
+	 *   - kernel/fork.c|989| <<dup_task_struct>> tsk->reported_split_lock = 0;
+	 */
 	if (!current->reported_split_lock)
 		pr_warn_ratelimited("#AC: %s/%d took a split_lock trap at address: 0x%lx\n",
 				    current->comm, current->pid, ip);
 	current->reported_split_lock = 1;
 
+	/*
+	 * 在以下使用sysctl_sld_mitigate:
+	 *   - arch/x86/kernel/cpu/intel.c|1013| <<global>> static unsigned int sysctl_sld_mitigate = 1;
+	 *   - arch/x86/kernel/cpu/intel.c|1020| <<global>> .data = &sysctl_sld_mitigate,
+	 *   - arch/x86/kernel/cpu/intel.c|1190| <<split_lock_warn>> if (sysctl_sld_mitigate) {
+	 */
 	if (sysctl_sld_mitigate) {
 		/*
 		 * misery factor #1:
@@ -1194,28 +1483,81 @@ static void split_lock_warn(unsigned long ip)
 		 */
 		if (msleep_interruptible(10) > 0)
 			return;
+		/*
+		 * 在以下使用buslock_sem:
+		 *   - arch/x86/kernel/cpu/intel.c|1063| <<global>> static DEFINE_SEMAPHORE(buslock_sem);
+		 *   - arch/x86/kernel/cpu/intel.c|1313| <<__split_lock_reenable_unlock>> up(&buslock_sem);
+		 *   - arch/x86/kernel/cpu/intel.c|1389| <<split_lock_warn>> if (down_interruptible(&buslock_sem) == -EINTR)
+		 */
 		/*
 		 * Misery factor #2:
 		 * only allow one buslocked disabled core at a time.
 		 */
 		if (down_interruptible(&buslock_sem) == -EINTR)
 			return;
+		/*
+		 * static DECLARE_DELAYED_WORK(sl_reenable_unlock, __split_lock_reenable_unlock);
+		 */
 		work = &sl_reenable_unlock;
 	} else {
+		/*
+		 * static DECLARE_DELAYED_WORK(sl_reenable, __split_lock_reenable);
+		 */
 		work = &sl_reenable;
 	}
 
 	cpu = get_cpu();
 	schedule_delayed_work_on(cpu, work, 2);
 
+	/*
+	 * 在以下使用sld_update_msr():
+	 *   - arch/x86/kernel/cpu/intel.c|1239| <<__split_lock_reenable_unlock>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1247| <<__split_lock_reenable>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1263| <<splitlock_cpu_offline>> sld_update_msr(true);
+	 *   - arch/x86/kernel/cpu/intel.c|1305| <<split_lock_warn>> sld_update_msr(false);
+	 *
+	 * MSR_TEST_CTRL is per core, but we treat it like a per CPU MSR. Locking
+	 * is not implemented as one thread could undo the setting of the other
+	 * thread immediately after dropping the lock anyway.
+	 */
 	/* Disable split lock detection on this CPU to make progress */
 	sld_update_msr(false);
 	put_cpu();
 }
 
+/*
+ * 在以下使用handle_guest_split_lock():
+ *   - arch/x86/kvm/vmx/vmx.c|5069| <<handle_exception_nmi(AC_VECTOR)>> if (handle_guest_split_lock(kvm_rip_read(vcpu)))
+ */
 bool handle_guest_split_lock(unsigned long ip)
 {
+	/*
+	 * 在以下使用sld_state:
+	 *   - arch/x86/kernel/cpu/intel.c|60| <<global>> static enum split_lock_detect_state sld_state __ro_after_init = sld_off;
+	 *   - arch/x86/kernel/cpu/intel.c|1100| <<sld_state_setup>> sld_state = state;
+	 *   - arch/x86/kernel/cpu/intel.c|1144| <<split_lock_init>> if (sld_state == sld_ratelimit) {
+	 *   - arch/x86/kernel/cpu/intel.c|1150| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+	 *   - arch/x86/kernel/cpu/intel.c|1222| <<handle_guest_split_lock>> if (sld_state == sld_warn) {
+	 *   - arch/x86/kernel/cpu/intel.c|1229| <<handle_guest_split_lock>> sld_state == sld_fatal ? "fatal" : "bogus", ip);
+	 *   - arch/x86/kernel/cpu/intel.c|1248| <<bus_lock_init>> (sld_state == sld_warn || sld_state == sld_fatal)) ||
+	 *   - arch/x86/kernel/cpu/intel.c|1249| <<bus_lock_init>> sld_state == sld_off) {
+	 *   - arch/x86/kernel/cpu/intel.c|1264| <<handle_user_split_lock>> if ((regs->flags & X86_EFLAGS_AC) || sld_state == sld_fatal)
+	 *   - arch/x86/kernel/cpu/intel.c|1272| <<handle_bus_lock>> switch (sld_state) {
+	 *   - arch/x86/kernel/cpu/intel.c|1355| <<sld_state_show>> switch (sld_state) {
+	 *
+	 * enum split_lock_detect_state {
+	 *     sld_off = 0,
+	 *     sld_warn,
+	 *     sld_fatal,
+	 *     sld_ratelimit,
+	 * };
+	 */
 	if (sld_state == sld_warn) {
+		/*
+		 * 在以下使用split_lock_warn():
+		 *   - arch/x86/kernel/cpu/intel.c|1219| <<handle_guest_split_lock>> split_lock_warn(ip);
+		 *   - arch/x86/kernel/cpu/intel.c|1262| <<handle_user_split_lock>> split_lock_warn(regs->ip);
+		 */
 		split_lock_warn(ip);
 		return true;
 	}
@@ -1240,6 +1582,32 @@ static void bus_lock_init(void)
 
 	rdmsrl(MSR_IA32_DEBUGCTLMSR, val);
 
+	/*
+	 * 在以下使用X86_FEATURE_SPLIT_LOCK_DETECT:
+	 *   - arch/x86/kernel/cpu/intel.c|1149| <<sld_state_setup>> if (!boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) &&
+	 *   - arch/x86/kernel/cpu/intel.c|1221| <<__split_lock_setup>> setup_force_cpu_cap(X86_FEATURE_SPLIT_LOCK_DETECT);
+	 *   - arch/x86/kernel/cpu/intel.c|1475| <<bus_lock_init>> if ((boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) &&
+	 *   - arch/x86/kernel/cpu/intel.c|1621| <<sld_state_show>> !boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 *   - arch/x86/kernel/cpu/intel.c|1643| <<sld_state_show>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1653| <<sld_state_show>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1657| <<sld_state_show>> boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) ?
+	 *   - arch/x86/kvm/vmx/vmx.c|4917| <<vmx_guest_inject_ac>> if (!boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 *   - arch/x86/kvm/x86.c|7297| <<emulator_cmpxchg_emulated>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 *
+	 *
+	 * 在以下使用sld_state:
+	 *   - arch/x86/kernel/cpu/intel.c|60| <<global>> static enum split_lock_detect_state sld_state __ro_after_init = sld_off;
+	 *   - arch/x86/kernel/cpu/intel.c|1100| <<sld_state_setup>> sld_state = state;
+	 *   - arch/x86/kernel/cpu/intel.c|1144| <<split_lock_init>> if (sld_state == sld_ratelimit) {
+	 *   - arch/x86/kernel/cpu/intel.c|1150| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+	 *   - arch/x86/kernel/cpu/intel.c|1222| <<handle_guest_split_lock>> if (sld_state == sld_warn) {
+	 *   - arch/x86/kernel/cpu/intel.c|1229| <<handle_guest_split_lock>> sld_state == sld_fatal ? "fatal" : "bogus", ip);
+	 *   - arch/x86/kernel/cpu/intel.c|1248| <<bus_lock_init>> (sld_state == sld_warn || sld_state == sld_fatal)) ||
+	 *   - arch/x86/kernel/cpu/intel.c|1249| <<bus_lock_init>> sld_state == sld_off) {
+	 *   - arch/x86/kernel/cpu/intel.c|1264| <<handle_user_split_lock>> if ((regs->flags & X86_EFLAGS_AC) || sld_state == sld_fatal)
+	 *   - arch/x86/kernel/cpu/intel.c|1272| <<handle_bus_lock>> switch (sld_state) {
+	 *   - arch/x86/kernel/cpu/intel.c|1355| <<sld_state_show>> switch (sld_state) {
+	 */
 	if ((boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) &&
 	    (sld_state == sld_warn || sld_state == sld_fatal)) ||
 	    sld_state == sld_off) {
@@ -1255,20 +1623,69 @@ static void bus_lock_init(void)
 	wrmsrl(MSR_IA32_DEBUGCTLMSR, val);
 }
 
+/*
+ * 在以下使用handle_user_split_lock():
+ *   - arch/x86/kernel/traps.c|305| <<DEFINE_IDTENTRY_ERRORCODE(exc_alignment_check)>> if (handle_user_split_lock(regs, error_code))
+ */
 bool handle_user_split_lock(struct pt_regs *regs, long error_code)
 {
+	/*
+	 * 在以下使用sld_state:
+	 *   - arch/x86/kernel/cpu/intel.c|60| <<global>> static enum split_lock_detect_state sld_state __ro_after_init = sld_off;
+	 *   - arch/x86/kernel/cpu/intel.c|1100| <<sld_state_setup>> sld_state = state;
+	 *   - arch/x86/kernel/cpu/intel.c|1144| <<split_lock_init>> if (sld_state == sld_ratelimit) {
+	 *   - arch/x86/kernel/cpu/intel.c|1150| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+	 *   - arch/x86/kernel/cpu/intel.c|1222| <<handle_guest_split_lock>> if (sld_state == sld_warn) {
+	 *   - arch/x86/kernel/cpu/intel.c|1229| <<handle_guest_split_lock>> sld_state == sld_fatal ? "fatal" : "bogus", ip);
+	 *   - arch/x86/kernel/cpu/intel.c|1248| <<bus_lock_init>> (sld_state == sld_warn || sld_state == sld_fatal)) ||
+	 *   - arch/x86/kernel/cpu/intel.c|1249| <<bus_lock_init>> sld_state == sld_off) {
+	 *   - arch/x86/kernel/cpu/intel.c|1264| <<handle_user_split_lock>> if ((regs->flags & X86_EFLAGS_AC) || sld_state == sld_fatal)
+	 *   - arch/x86/kernel/cpu/intel.c|1272| <<handle_bus_lock>> switch (sld_state) {
+	 *   - arch/x86/kernel/cpu/intel.c|1355| <<sld_state_show>> switch (sld_state) {
+	 */
 	if ((regs->flags & X86_EFLAGS_AC) || sld_state == sld_fatal)
 		return false;
+	/*
+	 * 在以下使用split_lock_warn():
+	 *   - arch/x86/kernel/cpu/intel.c|1219| <<handle_guest_split_lock>> split_lock_warn(ip);
+	 *   - arch/x86/kernel/cpu/intel.c|1262| <<handle_user_split_lock>> split_lock_warn(regs->ip);
+	 */
 	split_lock_warn(regs->ip);
 	return true;
 }
 
+/*
+ * 在以下调用handle_bus_lock():
+ *   - arch/x86/kernel/traps.c|1011| <<exc_debug_user>> handle_bus_lock(regs);
+ */
 void handle_bus_lock(struct pt_regs *regs)
 {
+	/*
+	 * 在以下使用sld_state:
+	 *   - arch/x86/kernel/cpu/intel.c|60| <<global>> static enum split_lock_detect_state sld_state __ro_after_init = sld_off;
+	 *   - arch/x86/kernel/cpu/intel.c|1100| <<sld_state_setup>> sld_state = state;
+	 *   - arch/x86/kernel/cpu/intel.c|1144| <<split_lock_init>> if (sld_state == sld_ratelimit) {
+	 *   - arch/x86/kernel/cpu/intel.c|1150| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+	 *   - arch/x86/kernel/cpu/intel.c|1222| <<handle_guest_split_lock>> if (sld_state == sld_warn) {
+	 *   - arch/x86/kernel/cpu/intel.c|1229| <<handle_guest_split_lock>> sld_state == sld_fatal ? "fatal" : "bogus", ip);
+	 *   - arch/x86/kernel/cpu/intel.c|1248| <<bus_lock_init>> (sld_state == sld_warn || sld_state == sld_fatal)) ||
+	 *   - arch/x86/kernel/cpu/intel.c|1249| <<bus_lock_init>> sld_state == sld_off) {
+	 *   - arch/x86/kernel/cpu/intel.c|1264| <<handle_user_split_lock>> if ((regs->flags & X86_EFLAGS_AC) || sld_state == sld_fatal)
+	 *   - arch/x86/kernel/cpu/intel.c|1272| <<handle_bus_lock>> switch (sld_state) {
+	 *   - arch/x86/kernel/cpu/intel.c|1355| <<sld_state_show>> switch (sld_state) {
+	 */
 	switch (sld_state) {
 	case sld_off:
 		break;
 	case sld_ratelimit:
+		/*
+		 * 在以下使用bld_ratelimit:
+		 *   - arch/x86/kernel/cpu/intel.c|1052| <<match_option>> ratelimit_state_init(&bld_ratelimit, HZ, ratelimit);
+		 *   - arch/x86/kernel/cpu/intel.c|1053| <<match_option>> ratelimit_set_flags(&bld_ratelimit, RATELIMIT_MSG_ON_RELEASE);
+		 *   - arch/x86/kernel/cpu/intel.c|1273| <<handle_bus_lock>> while (!__ratelimit(&bld_ratelimit))
+		 *   - arch/x86/kernel/cpu/intel.c|1376| <<sld_state_show>> pr_info("#DB: setting system wide bus lock rate limit to %u/sec\n",
+		 *                                             bld_ratelimit.burst);
+		 */
 		/* Enforce no more than bld_ratelimit bus locks/sec. */
 		while (!__ratelimit(&bld_ratelimit))
 			msleep(20);
@@ -1312,6 +1729,10 @@ static const struct x86_cpu_id split_lock_cpu_ids[] __initconst = {
 	{}
 };
 
+/*
+ * called by:
+ *   - arch/x86/kernel/cpu/intel.c|1774| <<sld_setup>> split_lock_setup(c);
+ */
 static void __init split_lock_setup(struct cpuinfo_x86 *c)
 {
 	const struct x86_cpu_id *m;
@@ -1338,16 +1759,49 @@ static void __init split_lock_setup(struct cpuinfo_x86 *c)
 		return;
 	}
 
+	/*
+	 * 在以下使用cpu_model_supports_sld:
+	 *   - arch/x86/kernel/cpu/intel.c|64| <<global>> static bool cpu_model_supports_sld __ro_after_init;
+	 *   - arch/x86/kernel/cpu/intel.c|1145| <<split_lock_init>> if (cpu_model_supports_sld)
+	 *   - arch/x86/kernel/cpu/intel.c|1341| <<split_lock_setup>> cpu_model_supports_sld = true;
+	 */
 	cpu_model_supports_sld = true;
 	__split_lock_setup();
 }
 
+/*
+ * called by:
+ *   - arch/x86/kernel/cpu/intel.c|1776| <<sld_setup>> sld_state_show();
+ *
+ * early_identify_cpu()
+ * -> sld_setup()
+ *    -> split_lock_setup() --> 检测支持吗: cpu_model_supports_sld
+ *    -> sld_state_setup()
+ *    -> sld_state_show()
+ */
 static void sld_state_show(void)
 {
 	if (!boot_cpu_has(X86_FEATURE_BUS_LOCK_DETECT) &&
 	    !boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
 		return;
 
+	/*
+	 * 在以下使用sld_state:
+	 *   - arch/x86/kernel/cpu/intel.c|60| <<global>> static enum split_lock_detect_state sld_state __ro_after_init = sld_off;
+	 *   - arch/x86/kernel/cpu/intel.c|1100| <<sld_state_setup>> sld_state = state;
+	 *   - arch/x86/kernel/cpu/intel.c|1144| <<split_lock_init>> if (sld_state == sld_ratelimit) {
+	 *   - arch/x86/kernel/cpu/intel.c|1150| <<split_lock_init>> split_lock_verify_msr(sld_state != sld_off);
+	 *   - arch/x86/kernel/cpu/intel.c|1222| <<handle_guest_split_lock>> if (sld_state == sld_warn) {
+	 *   - arch/x86/kernel/cpu/intel.c|1229| <<handle_guest_split_lock>> sld_state == sld_fatal ? "fatal" : "bogus", ip);
+	 *   - arch/x86/kernel/cpu/intel.c|1248| <<bus_lock_init>> (sld_state == sld_warn || sld_state == sld_fatal)) ||
+	 *   - arch/x86/kernel/cpu/intel.c|1249| <<bus_lock_init>> sld_state == sld_off) {
+	 *   - arch/x86/kernel/cpu/intel.c|1264| <<handle_user_split_lock>> if ((regs->flags & X86_EFLAGS_AC) || sld_state == sld_fatal)
+	 *   - arch/x86/kernel/cpu/intel.c|1272| <<handle_bus_lock>> switch (sld_state) {
+	 *   - arch/x86/kernel/cpu/intel.c|1355| <<sld_state_show>> switch (sld_state) {
+	 *
+	 * 1025 #undef pr_fmt   
+	 * 1026 #define pr_fmt(fmt) "x86/split lock detection: " fmt
+	 */
 	switch (sld_state) {
 	case sld_off:
 		pr_info("disabled\n");
@@ -1372,12 +1826,28 @@ static void sld_state_show(void)
 		}
 		break;
 	case sld_ratelimit:
+		/*
+		 * // Intel-defined CPU features, CPUID level 0x00000007:0 (ECX), word 16
+		 * #define X86_FEATURE_BUS_LOCK_DETECT     (16*32+24) // Bus Lock detect
+		 *
+		 *
+		 * 在以下使用bld_ratelimit:
+		 *   - arch/x86/kernel/cpu/intel.c|1052| <<match_option>> ratelimit_state_init(&bld_ratelimit, HZ, ratelimit);
+		 *   - arch/x86/kernel/cpu/intel.c|1053| <<match_option>> ratelimit_set_flags(&bld_ratelimit, RATELIMIT_MSG_ON_RELEASE);
+		 *   - arch/x86/kernel/cpu/intel.c|1273| <<handle_bus_lock>> while (!__ratelimit(&bld_ratelimit))
+		 *   - arch/x86/kernel/cpu/intel.c|1376| <<sld_state_show>> pr_info("#DB: setting system wide bus lock rate limit to %u/sec\n",
+		 *                                             bld_ratelimit.burst);
+		 */
 		if (boot_cpu_has(X86_FEATURE_BUS_LOCK_DETECT))
 			pr_info("#DB: setting system wide bus lock rate limit to %u/sec\n", bld_ratelimit.burst);
 		break;
 	}
 }
 
+/*
+ * 在以下调用sld_setup():
+ *   - arch/x86/kernel/cpu/common.c|1604| <<early_identify_cpu>> sld_setup(c);
+ */
 void __init sld_setup(struct cpuinfo_x86 *c)
 {
 	split_lock_setup(c);
diff --git a/arch/x86/kernel/kvmclock.c b/arch/x86/kernel/kvmclock.c
index 8e1cd291aed3..dfe0bd0e920a 100644
--- a/arch/x86/kernel/kvmclock.c
+++ b/arch/x86/kernel/kvmclock.c
@@ -71,6 +71,12 @@ static int kvm_set_wallclock(const struct timespec64 *now)
 	return -ENODEV;
 }
 
+/*
+ * 在以下使用kvm_clock_read():
+ *   - arch/x86/kernel/kvmclock.c|86| <<kvm_clock_get_cycles>> return kvm_clock_read();
+ *   - arch/x86/kernel/kvmclock.c|91| <<kvm_sched_clock_read>> return kvm_clock_read() - kvm_sched_clock_offset;
+ *   - arch/x86/kernel/kvmclock.c|98| <<kvm_sched_clock_init>> kvm_sched_clock_offset = kvm_clock_read();
+ */
 static u64 kvm_clock_read(void)
 {
 	u64 ret;
diff --git a/arch/x86/kernel/process.c b/arch/x86/kernel/process.c
index ac222eaf8c6e..8d4713c8de43 100644
--- a/arch/x86/kernel/process.c
+++ b/arch/x86/kernel/process.c
@@ -708,6 +708,12 @@ void arch_cpu_idle_enter(void)
 	local_touch_nmi();
 }
 
+/*
+ * [0] arch_cpu_idle_dead
+ * [0] do_idle
+ * [0] cpu_startup_entry
+ * [0] secondary_startup_64_no_verify
+ */
 void arch_cpu_idle_dead(void)
 {
 	play_dead();
diff --git a/arch/x86/kernel/pvclock.c b/arch/x86/kernel/pvclock.c
index eda37df016f0..153526eabbaf 100644
--- a/arch/x86/kernel/pvclock.c
+++ b/arch/x86/kernel/pvclock.c
@@ -64,6 +64,12 @@ u8 pvclock_read_flags(struct pvclock_vcpu_time_info *src)
 	return flags & valid_flags;
 }
 
+/*
+ * 在以下使用pvclock_clocksource_read():
+ *   - arch/x86/kernel/kvmclock.c|79| <<kvm_clock_read>> ret = pvclock_clocksource_read(this_cpu_pvti());
+ *   - arch/x86/kernel/pvclock.c|144| <<pvclock_read_wallclock>> delta = pvclock_clocksource_read(vcpu_time);
+ *   - arch/x86/xen/time.c|53| <<xen_clocksource_read>> ret = pvclock_clocksource_read(src);
+ */
 u64 pvclock_clocksource_read(struct pvclock_vcpu_time_info *src)
 {
 	unsigned version;
@@ -73,6 +79,13 @@ u64 pvclock_clocksource_read(struct pvclock_vcpu_time_info *src)
 
 	do {
 		version = pvclock_read_begin(src);
+		/*
+		 * 在以下使用__pvclock_read_cycles():
+		 *   - arch/x86/include/asm/vdso/gettimeofday.h|231| <<vread_pvclock>> ret = __pvclock_read_cycles(pvti, rdtsc_ordered());
+		 *   - arch/x86/kernel/pvclock.c|76| <<pvclock_clocksource_read>> ret = __pvclock_read_cycles(src, rdtsc_ordered());
+		 *   - arch/x86/kvm/x86.c|3146| <<get_kvmclock_ns>> ret = __pvclock_read_cycles(&hv_clock, rdtsc());
+		 *   - drivers/ptp/ptp_kvm_x86.c|123| <<kvm_arch_ptp_get_crosststamp>> *cycle = __pvclock_read_cycles(src, clock_pair->tsc);
+		 */
 		ret = __pvclock_read_cycles(src, rdtsc_ordered());
 		flags = src->flags;
 	} while (pvclock_read_retry(src, version));
diff --git a/arch/x86/kernel/smpboot.c b/arch/x86/kernel/smpboot.c
index da93793dc107..ae85bf7eeb37 100644
--- a/arch/x86/kernel/smpboot.c
+++ b/arch/x86/kernel/smpboot.c
@@ -915,6 +915,10 @@ wakeup_secondary_cpu_via_init(int phys_apicid, unsigned long start_eip)
 	return (send_status | accept_status);
 }
 
+/*
+ * 在以下使用announce_cpu():
+ *   - arch/x86/kernel/smpboot.c|1142| <<do_boot_cpu>> announce_cpu(cpu, apicid);
+ */
 /* reduce the number of lines printed when booting a large cpu count system */
 static void announce_cpu(int cpu, int apicid)
 {
@@ -1120,6 +1124,10 @@ slaunch_wakeup_cpu_from_txt(int cpu, int apicid)
  * Returns zero if CPU booted OK, else error code from
  * ->wakeup_secondary_cpu.
  */
+/*
+ * 在以下使用do_boot_cpu():
+ *   - arch/x86/kernel/smpboot.c|1283| <<native_cpu_up>> err = do_boot_cpu(apicid, cpu, tidle, &cpu0_nmi_registered);
+ */
 static int do_boot_cpu(int apicid, int cpu, struct task_struct *idle,
 		       int *cpu0_nmi_registered)
 {
@@ -1735,6 +1743,22 @@ int native_cpu_disable(void)
 	return 0;
 }
 
+/*
+ * [0] common_cpu_die
+ * [0] takedown_cpu
+ * [0] cpuhp_invoke_callback
+ * [0] __cpuhp_invoke_callback_range
+ * [0] _cpu_down
+ * [0] cpu_device_down
+ * [0] device_offline
+ * [0] online_store
+ * [0] kernfs_fop_write_iter
+ * [0] new_sync_write
+ * [0] vfs_write
+ * [0] ksys_write
+ * [0] do_syscall_64
+ * [0] entry_SYSCALL_64_after_hwframe
+ */
 int common_cpu_die(unsigned int cpu)
 {
 	int ret = 0;
diff --git a/arch/x86/kvm/debugfs.c b/arch/x86/kvm/debugfs.c
index 9240b3b7f8dd..7177af3b2704 100644
--- a/arch/x86/kvm/debugfs.c
+++ b/arch/x86/kvm/debugfs.c
@@ -48,6 +48,21 @@ DEFINE_SIMPLE_ATTRIBUTE(vcpu_tsc_scaling_fops, vcpu_get_tsc_scaling_ratio, NULL,
 
 static int vcpu_get_tsc_scaling_frac_bits(void *data, u64 *val)
 {
+	/*
+	 * 在以下使用kvm_tsc_scaling_ratio_frac_bits:
+	 *   - arch/x86/kvm/debugfs.c|51| <<vcpu_get_tsc_scaling_frac_bits>> *val = kvm_tsc_scaling_ratio_frac_bits;
+	 *   - arch/x86/kvm/svm/svm.c|1117| <<svm_hardware_setup>> kvm_tsc_scaling_ratio_frac_bits = 32;
+	 *   - arch/x86/kvm/vmx/vmx.c|8358| <<vmx_set_hv_timer>> if (vcpu->arch.l1_tsc_scaling_ratio != kvm_default_tsc_scaling_ratio
+	 *              && delta_tsc && u64_shl_div_u64(delta_tsc, kvm_tsc_scaling_ratio_frac_bits, vcpu->arch.l1_tsc_scaling_ratio, &delta_tsc))
+	 *   - arch/x86/kvm/vmx/vmx.c|8789| <<hardware_setup>> kvm_tsc_scaling_ratio_frac_bits = 48;
+	 *   - arch/x86/kvm/x86.c|2561| <<set_tsc_khz>> ratio = mul_u64_u32_div(1ULL << kvm_tsc_scaling_ratio_frac_bits, user_tsc_khz, tsc_khz);
+	 *   - arch/x86/kvm/x86.c|2702| <<__scale_tsc>> return mul_u64_u64_shr(tsc, ratio, kvm_tsc_scaling_ratio_frac_bits);
+	 *   - arch/x86/kvm/x86.c|2740| <<kvm_calc_nested_tsc_offset>> nested_offset = mul_s64_u64_shr((s64) l1_offset,
+	 *              l2_multiplier, kvm_tsc_scaling_ratio_frac_bits);
+	 *   - arch/x86/kvm/x86.c|2751| <<kvm_calc_nested_tsc_multiplier>> return mul_u64_u64_shr(l1_multiplier, l2_multiplier,
+	 *              kvm_tsc_scaling_ratio_frac_bits);
+	 *   - arch/x86/kvm/x86.c|13707| <<kvm_arch_hardware_setup>> kvm_default_tsc_scaling_ratio = 1ULL << kvm_tsc_scaling_ratio_frac_bits;
+	 */
 	*val = kvm_tsc_scaling_ratio_frac_bits;
 	return 0;
 }
@@ -66,6 +81,21 @@ void kvm_arch_create_vcpu_debugfs(struct kvm_vcpu *vcpu, struct dentry *debugfs_
 				    debugfs_dentry, vcpu,
 				    &vcpu_timer_advance_ns_fops);
 
+	/*
+	 * 在以下设置kvm_has_tsc_control:
+	 *   - arch/x86/kvm/svm/svm.c|1115| <<svm_hardware_setup>> kvm_has_tsc_control = true;
+	 *   - arch/x86/kvm/vmx/vmx.c|8787| <<hardware_setup>> kvm_has_tsc_control = true;
+	 * 在以下使用kvm_has_tsc_control:
+	 *   - arch/x86/kvm/debugfs.c|69| <<kvm_arch_create_vcpu_debugfs>> if (kvm_has_tsc_control) {
+	 *   - arch/x86/kvm/vmx/nested.c|2581| <<prepare_vmcs02>> if (kvm_has_tsc_control)
+	 *   - arch/x86/kvm/vmx/nested.c|4680| <<nested_vmx_vmexit>> if (kvm_has_tsc_control)
+	 *   - arch/x86/kvm/x86.c|2579| <<set_tsc_khz>> if (!kvm_has_tsc_control) {
+	 *   - arch/x86/kvm/x86.c|2843| <<kvm_vcpu_write_tsc_multiplier>> if (kvm_has_tsc_control)
+	 *   - arch/x86/kvm/x86.c|3607| <<kvm_guest_time_update>> if (kvm_has_tsc_control)
+	 *   - arch/x86/kvm/x86.c|4951| <<kvm_vm_ioctl_check_extension>> r = kvm_has_tsc_control;
+	 *   - arch/x86/kvm/x86.c|6207| <<kvm_arch_vcpu_ioctl(KVM_SET_TSC_KHZ)>> if (kvm_has_tsc_control &
+	 *   - arch/x86/kvm/x86.c|13736| <<kvm_arch_hardware_setup>> if (kvm_has_tsc_control) {
+	 */
 	if (kvm_has_tsc_control) {
 		debugfs_create_file("tsc-scaling-ratio", 0444,
 				    debugfs_dentry, vcpu,
diff --git a/arch/x86/kvm/hyperv.c b/arch/x86/kvm/hyperv.c
index 1baaf481680d..509ea15a15c3 100644
--- a/arch/x86/kvm/hyperv.c
+++ b/arch/x86/kvm/hyperv.c
@@ -88,6 +88,11 @@ static bool synic_has_vector_auto_eoi(struct kvm_vcpu_hv_synic *synic,
 	return false;
 }
 
+/*
+ * 在以下使用synic_update_vector():
+ *   - arch/x86/kvm/hyperv.c|166| <<synic_set_sint>> synic_update_vector(synic, old_vector);
+ *   - arch/x86/kvm/hyperv.c|168| <<synic_set_sint>> synic_update_vector(synic, vector);
+ */
 static void synic_update_vector(struct kvm_vcpu_hv_synic *synic,
 				int vector)
 {
@@ -125,6 +130,14 @@ static void synic_update_vector(struct kvm_vcpu_hv_synic *synic,
 	else
 		hv->synic_auto_eoi_used--;
 
+	/*
+	 * 在以下调用__kvm_set_or_clear_apicv_inhibit():
+	 *   - arch/x86/kvm/hyperv.c|132| <<synic_update_vector>> __kvm_set_or_clear_apicv_inhibit(vcpu->kvm,
+	 *          APICV_INHIBIT_REASON_HYPERV, !!hv->synic_auto_eoi_used);
+	 *   - arch/x86/kvm/x86.c|10434| <<kvm_set_or_clear_apicv_inhibit>> __kvm_set_or_clear_apicv_inhibit(kvm, reason, set);
+	 *   - arch/x86/kvm/x86.c|12032| <<kvm_arch_vcpu_guestdbg_update_apicv_inhibit>> __kvm_set_or_clear_apicv_inhibit(kvm,
+	 *          APICV_INHIBIT_REASON_BLOCKIRQ, set);
+	 */
 	/*
 	 * Inhibit APICv if any vCPU is using SynIC's AutoEOI, which relies on
 	 * the hypervisor to manually inject IRQs.
@@ -479,6 +492,15 @@ static int synic_set_irq(struct kvm_vcpu_hv_synic *synic, u32 sint)
 	irq.vector = vector;
 	irq.level = 1;
 
+	/*
+	 * 在以下使用kvm_irq_delivery_to_apic():
+	 *   - arch/x86/kvm/hyperv.c|495| <<synic_set_irq>> ret = kvm_irq_delivery_to_apic(vcpu->kvm, vcpu->arch.apic, &irq, NULL);
+	 *   - arch/x86/kvm/ioapic.c|673| <<ioapic_service>> ret = kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe,
+	 *   - arch/x86/kvm/ioapic.c|677| <<ioapic_service>> ret = kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe, NULL);
+	 *   - arch/x86/kvm/irq_comm.c|214| <<kvm_set_msi>> return kvm_irq_delivery_to_apic(kvm, NULL, &irq, NULL);
+	 *   - arch/x86/kvm/lapic.c|2293| <<kvm_apic_send_ipi>> kvm_irq_delivery_to_apic(apic->vcpu->kvm, apic, &irq, NULL);
+	 *   - arch/x86/kvm/x86.c|9314| <<kvm_pv_kick_cpu_op>> kvm_irq_delivery_to_apic(kvm, NULL, &lapic_irq, NULL);
+	 */
 	ret = kvm_irq_delivery_to_apic(vcpu->kvm, vcpu->arch.apic, &irq, NULL);
 	trace_kvm_hv_synic_set_irq(vcpu->vcpu_id, sint, irq.vector, ret);
 	return ret;
@@ -1084,6 +1106,10 @@ static int kvm_hv_msr_set_crash_data(struct kvm *kvm, u32 index, u64 data)
  *
  * These two equivalencies are implemented in this function.
  */
+/*
+ * 在以下使用compute_tsc_page_parameters():
+ *   - arch/x86/kvm/hyperv.c|1202| <<kvm_hv_setup_tsc_page>> if (!compute_tsc_page_parameters(hv_clock, &hv->tsc_ref))
+ */
 static bool compute_tsc_page_parameters(struct pvclock_vcpu_time_info *hv_clock,
 					struct ms_hyperv_tsc_page *tsc_ref)
 {
@@ -1133,6 +1159,10 @@ static inline bool tsc_page_update_unsafe(struct kvm_hv *hv)
 		hv->hv_tsc_emulation_control;
 }
 
+/*
+ * 在以下使用kvm_hv_setup_tsc_page():
+ *   - arch/x86/kvm/x86.c|4271| <<kvm_guest_time_update>> kvm_hv_setup_tsc_page(v->kvm, &vcpu->hv_clock);
+ */
 void kvm_hv_setup_tsc_page(struct kvm *kvm,
 			   struct pvclock_vcpu_time_info *hv_clock)
 {
@@ -1209,6 +1239,10 @@ void kvm_hv_setup_tsc_page(struct kvm *kvm,
 	mutex_unlock(&hv->hv_lock);
 }
 
+/*
+ * 在以下使用kvm_hv_invalidate_tsc_page():
+ *   - arch/x86/kvm/x86.c|3756| <<kvm_gen_update_masterclock>> kvm_hv_invalidate_tsc_page(kvm);
+ */
 void kvm_hv_invalidate_tsc_page(struct kvm *kvm)
 {
 	struct kvm_hv *hv = to_kvm_hv(kvm);
@@ -1238,6 +1272,14 @@ void kvm_hv_invalidate_tsc_page(struct kvm *kvm)
 	 * cache generation against the memslots generation.
 	 */
 	idx = srcu_read_lock(&kvm->srcu);
+	/*
+	 * struct ms_hyperv_tsc_page {
+	 *     volatile u32 tsc_sequence;
+	 *     u32 reserved1;
+	 *     volatile u64 tsc_scale;
+	 *     volatile s64 tsc_offset;
+	 * } __packed;
+	 */
 	if (kvm_write_guest(kvm, gfn_to_gpa(gfn),
 			    &hv->tsc_ref, sizeof(hv->tsc_ref.tsc_sequence)))
 		hv->hv_tsc_page_status = HV_TSC_PAGE_BROKEN;
diff --git a/arch/x86/kvm/i8254.c b/arch/x86/kvm/i8254.c
index 043dd4af1848..de33901a68a8 100644
--- a/arch/x86/kvm/i8254.c
+++ b/arch/x86/kvm/i8254.c
@@ -311,6 +311,14 @@ void kvm_pit_set_reinject(struct kvm_pit *pit, bool reinject)
 		kvm_register_irq_ack_notifier(kvm, &ps->irq_ack_notifier);
 		kvm_register_irq_mask_notifier(kvm, 0, &pit->mask_notifier);
 	} else {
+		/*
+		 * 在以下使用kvm_clear_apicv_inhibit():
+		 *   - arch/x86/kvm/i8254.c|314| <<kvm_pit_set_reinject>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_PIT_REINJ);
+		 *   - arch/x86/kvm/lapic.c|579| <<kvm_recalculate_apic_map>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_APIC_ID_MODIFIED);
+		 *   - arch/x86/kvm/svm/svm.c|3235| <<interrupt_window_interception>> kvm_clear_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+		 *   - arch/x86/kvm/x86.c|6050| <<kvm_vm_ioctl_enable_cap(KVM_CAP_SPLIT_IRQCHIP)>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
+		 *   - arch/x86/kvm/x86.c|6465| <<kvm_arch_vm_ioctl(KVM_CREATE_IRQCHIP)>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
+		 */
 		kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_PIT_REINJ);
 		kvm_unregister_irq_ack_notifier(kvm, &ps->irq_ack_notifier);
 		kvm_unregister_irq_mask_notifier(kvm, 0, &pit->mask_notifier);
diff --git a/arch/x86/kvm/ioapic.c b/arch/x86/kvm/ioapic.c
index 4e0f52660842..8bc71b392b20 100644
--- a/arch/x86/kvm/ioapic.c
+++ b/arch/x86/kvm/ioapic.c
@@ -80,6 +80,20 @@ static unsigned long ioapic_read_indirect(struct kvm_ioapic *ioapic,
 				u32 index = array_index_nospec(
 					redir_index, IOAPIC_NUM_PINS);
 
+				/*
+				 * 在以下使用kvm_ioapic->redirtbl[IOAPIC_NUM_PINS]:
+				 *   - arch/x86/kvm/ioapic.c|83| <<ioapic_read_indirect>> redir_content = ioapic->redirtbl[index].bits;
+				 *   - arch/x86/kvm/ioapic.c|117| <<__rtc_irq_eoi_tracking_restore_one>> e = &ioapic->redirtbl[RTC_GSI];
+				 *   - arch/x86/kvm/ioapic.c|189| <<ioapic_lazy_update_eoi>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+				 *   - arch/x86/kvm/ioapic.c|215| <<ioapic_set_irq>> entry = ioapic->redirtbl[irq];
+				 *   - arch/x86/kvm/ioapic.c|294| <<kvm_ioapic_scan_entry>> e = &ioapic->redirtbl[index];
+				 *   - arch/x86/kvm/ioapic.c|343| <<ioapic_write_indirect>> e = &ioapic->redirtbl[index];
+				 *   - arch/x86/kvm/ioapic.c|415| <<ioapic_service>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+				 *   - arch/x86/kvm/ioapic.c|490| <<kvm_ioapic_eoi_inject_work>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+				 *   - arch/x86/kvm/ioapic.c|508| <<kvm_ioapic_update_eoi_one>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
+				 *   - arch/x86/kvm/ioapic.c|558| <<kvm_ioapic_update_eoi>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+				 *   - arch/x86/kvm/ioapic.c|670| <<kvm_ioapic_reset>> ioapic->redirtbl[i].fields.mask = 1;
+				 */
 				redir_content = ioapic->redirtbl[index].bits;
 			}
 
@@ -114,7 +128,40 @@ static void __rtc_irq_eoi_tracking_restore_one(struct kvm_vcpu *vcpu)
 	struct dest_map *dest_map = &ioapic->rtc_status.dest_map;
 	union kvm_ioapic_redirect_entry *e;
 
+	/*
+	 * 在以下使用kvm_ioapic->redirtbl[IOAPIC_NUM_PINS]:
+	 *   - arch/x86/kvm/ioapic.c|83| <<ioapic_read_indirect>> redir_content = ioapic->redirtbl[index].bits;
+	 *   - arch/x86/kvm/ioapic.c|117| <<__rtc_irq_eoi_tracking_restore_one>> e = &ioapic->redirtbl[RTC_GSI];
+	 *   - arch/x86/kvm/ioapic.c|189| <<ioapic_lazy_update_eoi>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|215| <<ioapic_set_irq>> entry = ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|294| <<kvm_ioapic_scan_entry>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|343| <<ioapic_write_indirect>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|415| <<ioapic_service>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|490| <<kvm_ioapic_eoi_inject_work>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|508| <<kvm_ioapic_update_eoi_one>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
+	 *   - arch/x86/kvm/ioapic.c|558| <<kvm_ioapic_update_eoi>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|670| <<kvm_ioapic_reset>> ioapic->redirtbl[i].fields.mask = 1;
+	 */
 	e = &ioapic->redirtbl[RTC_GSI];
+	/*
+	 * 在以下调用kvm_apic_match_dest():
+	 *   - arch/x86/kvm/ioapic.c|146| <<__rtc_irq_eoi_tracking_restore_one>> if (!kvm_apic_match_dest(vcpu, NULL,
+	 *          APIC_DEST_NOSHORT, e->fields.dest_id, kvm_lapic_irq_dest_mode(!!e->fields.dest_mode)))
+	 *   - arch/x86/kvm/ioapic.c|234| <<ioapic_lazy_update_eoi>> if (!kvm_apic_match_dest(vcpu, NULL,
+	 *          APIC_DEST_NOSHORT, entry->fields.dest_id, entry->fields.dest_mode) ||
+	 *   - arch/x86/kvm/ioapic.c|414| <<kvm_ioapic_scan_entry>> if (kvm_apic_match_dest(vcpu, NULL,
+	 *          APIC_DEST_NOSHORT, e->fields.dest_id, dm) ||
+	 *   - arch/x86/kvm/irq_comm.c|68| <<kvm_irq_delivery_to_apic>> if (!kvm_apic_match_dest(vcpu, src,
+	 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+	 *   - arch/x86/kvm/irq_comm.c|359| <<kvm_intr_is_single_vcpu>> if (!kvm_apic_match_dest(vcpu, NULL,
+	 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+	 *   - arch/x86/kvm/irq_comm.c|442| <<kvm_scan_ioapic_routes>> if (irq.trig_mode && (kvm_apic_match_dest(vcpu, NULL,
+	 *          APIC_DEST_NOSHORT, irq.dest_id, irq.dest_mode) ||
+	 *   - arch/x86/kvm/lapic.c|1262| <<kvm_bitmap_or_dest_vcpus>> if (!kvm_apic_match_dest(vcpu, NULL,
+	 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+	 *   - arch/x86/kvm/svm/avic.c|461| <<avic_kick_target_vcpus>> if (kvm_apic_match_dest(vcpu, source,
+	 *          icrl & APIC_SHORT_MASK, dest, icrl & APIC_DEST_MASK)) {
+	 */
 	if (!kvm_apic_match_dest(vcpu, NULL, APIC_DEST_NOSHORT,
 				 e->fields.dest_id,
 				 kvm_lapic_irq_dest_mode(!!e->fields.dest_mode)))
@@ -186,9 +233,42 @@ static void ioapic_lazy_update_eoi(struct kvm_ioapic *ioapic, int irq)
 {
 	int i;
 	struct kvm_vcpu *vcpu;
+	/*
+	 * 在以下使用kvm_ioapic->redirtbl[IOAPIC_NUM_PINS]:
+	 *   - arch/x86/kvm/ioapic.c|83| <<ioapic_read_indirect>> redir_content = ioapic->redirtbl[index].bits;
+	 *   - arch/x86/kvm/ioapic.c|117| <<__rtc_irq_eoi_tracking_restore_one>> e = &ioapic->redirtbl[RTC_GSI];
+	 *   - arch/x86/kvm/ioapic.c|189| <<ioapic_lazy_update_eoi>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|215| <<ioapic_set_irq>> entry = ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|294| <<kvm_ioapic_scan_entry>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|343| <<ioapic_write_indirect>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|415| <<ioapic_service>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|490| <<kvm_ioapic_eoi_inject_work>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|508| <<kvm_ioapic_update_eoi_one>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
+	 *   - arch/x86/kvm/ioapic.c|558| <<kvm_ioapic_update_eoi>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|670| <<kvm_ioapic_reset>> ioapic->redirtbl[i].fields.mask = 1;
+	 */
 	union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
 
 	kvm_for_each_vcpu(i, vcpu, ioapic->kvm) {
+		/*
+		 * 在以下调用kvm_apic_match_dest():
+		 *   - arch/x86/kvm/ioapic.c|146| <<__rtc_irq_eoi_tracking_restore_one>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, e->fields.dest_id, kvm_lapic_irq_dest_mode(!!e->fields.dest_mode)))
+		 *   - arch/x86/kvm/ioapic.c|234| <<ioapic_lazy_update_eoi>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, entry->fields.dest_id, entry->fields.dest_mode) ||
+		 *   - arch/x86/kvm/ioapic.c|414| <<kvm_ioapic_scan_entry>> if (kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, e->fields.dest_id, dm) ||
+		 *   - arch/x86/kvm/irq_comm.c|68| <<kvm_irq_delivery_to_apic>> if (!kvm_apic_match_dest(vcpu, src,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/irq_comm.c|359| <<kvm_intr_is_single_vcpu>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/irq_comm.c|442| <<kvm_scan_ioapic_routes>> if (irq.trig_mode && (kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, irq.dest_id, irq.dest_mode) ||
+		 *   - arch/x86/kvm/lapic.c|1262| <<kvm_bitmap_or_dest_vcpus>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/svm/avic.c|461| <<avic_kick_target_vcpus>> if (kvm_apic_match_dest(vcpu, source,
+		 *          icrl & APIC_SHORT_MASK, dest, icrl & APIC_DEST_MASK)) {
+		 */
 		if (!kvm_apic_match_dest(vcpu, NULL, APIC_DEST_NOSHORT,
 					 entry->fields.dest_id,
 					 entry->fields.dest_mode) ||
@@ -212,6 +292,20 @@ static int ioapic_set_irq(struct kvm_ioapic *ioapic, unsigned int irq,
 	u32 old_irr;
 	int edge, ret;
 
+	/*
+	 * 在以下使用kvm_ioapic->redirtbl[IOAPIC_NUM_PINS]:
+	 *   - arch/x86/kvm/ioapic.c|83| <<ioapic_read_indirect>> redir_content = ioapic->redirtbl[index].bits;
+	 *   - arch/x86/kvm/ioapic.c|117| <<__rtc_irq_eoi_tracking_restore_one>> e = &ioapic->redirtbl[RTC_GSI];
+	 *   - arch/x86/kvm/ioapic.c|189| <<ioapic_lazy_update_eoi>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|215| <<ioapic_set_irq>> entry = ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|294| <<kvm_ioapic_scan_entry>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|343| <<ioapic_write_indirect>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|415| <<ioapic_service>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|490| <<kvm_ioapic_eoi_inject_work>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|508| <<kvm_ioapic_update_eoi_one>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
+	 *   - arch/x86/kvm/ioapic.c|558| <<kvm_ioapic_update_eoi>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|670| <<kvm_ioapic_reset>> ioapic->redirtbl[i].fields.mask = 1;
+	 */
 	entry = ioapic->redirtbl[irq];
 	edge = (entry.fields.trig_mode == IOAPIC_EDGE_TRIG);
 
@@ -276,6 +370,10 @@ static void kvm_ioapic_inject_all(struct kvm_ioapic *ioapic, unsigned long irr)
 }
 
 
+/*
+ * 在以下使用kvm_ioapic_scan_entry():
+ *   - arch/x86/kvm/x86.c|9917| <<vcpu_scan_ioapic>> kvm_ioapic_scan_entry(vcpu, vcpu->arch.ioapic_handled_vectors);
+ */
 void kvm_ioapic_scan_entry(struct kvm_vcpu *vcpu, ulong *ioapic_handled_vectors)
 {
 	struct kvm_ioapic *ioapic = vcpu->kvm->arch.vioapic;
@@ -285,18 +383,97 @@ void kvm_ioapic_scan_entry(struct kvm_vcpu *vcpu, ulong *ioapic_handled_vectors)
 
 	spin_lock(&ioapic->lock);
 
+	/*
+	 * struct dest_map {
+	 * map = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
+	 * 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
+	 * 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},
+	 *
+	 * 第一次设置的地方
+	 * 看着似乎rtc_statu的bit都是空
+	 */
 	/* Make sure we see any missing RTC EOI */
 	if (test_bit(vcpu->vcpu_id, dest_map->map))
 		__set_bit(dest_map->vectors[vcpu->vcpu_id],
 			  ioapic_handled_vectors);
 
+	/*
+	 * union kvm_ioapic_redirect_entry {
+	 *     bits = 144115188075888682,
+	 *     fields = {
+	 *       vector = 42 '*',
+	 *       delivery_mode = 0 '\000',
+	 *       dest_mode = 0 '\000',
+	 *       delivery_status = 0 '\000',
+	 *       polarity = 0 '\000',
+	 *       remote_irr = 0 '\000',
+	 *       trig_mode = 1 '\001',
+	 *       mask = 0 '\000',
+	 *       reserve = 0 '\000',
+	 *       reserved = "\000\000\000",
+	 *       dest_id = 2 '\002'
+	 *     }
+	 *  }
+	 *
+	 * 57 union kvm_ioapic_redirect_entry {
+	 * 58         u64 bits;
+	 * 59         struct {
+	 * 60                 u8 vector;
+	 * 61                 u8 delivery_mode:3;
+	 * 62                 u8 dest_mode:1;
+	 * 63                 u8 delivery_status:1;
+	 * 64                 u8 polarity:1;
+	 * 65                 u8 remote_irr:1;
+	 * 66                 u8 trig_mode:1;
+	 * 67                 u8 mask:1;
+	 * 68                 u8 reserve:7;
+	 * 69                 u8 reserved[4];
+	 * 70                 u8 dest_id;
+	 * 71         } fields;
+	 * 72 };
+	 */
 	for (index = 0; index < IOAPIC_NUM_PINS; index++) {
+		/*
+		 * 在以下使用kvm_ioapic->redirtbl[IOAPIC_NUM_PINS]:
+		 *   - arch/x86/kvm/ioapic.c|83| <<ioapic_read_indirect>> redir_content = ioapic->redirtbl[index].bits;
+		 *   - arch/x86/kvm/ioapic.c|117| <<__rtc_irq_eoi_tracking_restore_one>> e = &ioapic->redirtbl[RTC_GSI];
+		 *   - arch/x86/kvm/ioapic.c|189| <<ioapic_lazy_update_eoi>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+		 *   - arch/x86/kvm/ioapic.c|215| <<ioapic_set_irq>> entry = ioapic->redirtbl[irq];
+		 *   - arch/x86/kvm/ioapic.c|294| <<kvm_ioapic_scan_entry>> e = &ioapic->redirtbl[index];
+		 *   - arch/x86/kvm/ioapic.c|343| <<ioapic_write_indirect>> e = &ioapic->redirtbl[index];
+		 *   - arch/x86/kvm/ioapic.c|415| <<ioapic_service>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+		 *   - arch/x86/kvm/ioapic.c|490| <<kvm_ioapic_eoi_inject_work>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+		 *   - arch/x86/kvm/ioapic.c|508| <<kvm_ioapic_update_eoi_one>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
+		 *   - arch/x86/kvm/ioapic.c|558| <<kvm_ioapic_update_eoi>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+		 *   - arch/x86/kvm/ioapic.c|670| <<kvm_ioapic_reset>> ioapic->redirtbl[i].fields.mask = 1;
+		 *
+		 * 只在这里一个地方使用kvm_irq_has_notifier(), 返回false的概率大
+		 */
 		e = &ioapic->redirtbl[index];
 		if (e->fields.trig_mode == IOAPIC_LEVEL_TRIG ||
 		    kvm_irq_has_notifier(ioapic->kvm, KVM_IRQCHIP_IOAPIC, index) ||
 		    index == RTC_GSI) {
 			u16 dm = kvm_lapic_irq_dest_mode(!!e->fields.dest_mode);
 
+			/*
+			 * 在以下调用kvm_apic_match_dest():
+			 *   - arch/x86/kvm/ioapic.c|146| <<__rtc_irq_eoi_tracking_restore_one>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, e->fields.dest_id, kvm_lapic_irq_dest_mode(!!e->fields.dest_mode)))
+			 *   - arch/x86/kvm/ioapic.c|234| <<ioapic_lazy_update_eoi>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, entry->fields.dest_id, entry->fields.dest_mode) ||
+			 *   - arch/x86/kvm/ioapic.c|414| <<kvm_ioapic_scan_entry>> if (kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, e->fields.dest_id, dm) ||
+			 *   - arch/x86/kvm/irq_comm.c|68| <<kvm_irq_delivery_to_apic>> if (!kvm_apic_match_dest(vcpu, src,
+			 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+			 *   - arch/x86/kvm/irq_comm.c|359| <<kvm_intr_is_single_vcpu>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+			 *   - arch/x86/kvm/irq_comm.c|442| <<kvm_scan_ioapic_routes>> if (irq.trig_mode && (kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, irq.dest_id, irq.dest_mode) ||
+			 *   - arch/x86/kvm/lapic.c|1262| <<kvm_bitmap_or_dest_vcpus>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+			 *   - arch/x86/kvm/svm/avic.c|461| <<avic_kick_target_vcpus>> if (kvm_apic_match_dest(vcpu, source,
+			 *          icrl & APIC_SHORT_MASK, dest, icrl & APIC_DEST_MASK)) {
+			 */
 			if (kvm_apic_match_dest(vcpu, NULL, APIC_DEST_NOSHORT,
 						e->fields.dest_id, dm) ||
 			    kvm_apic_pending_eoi(vcpu, e->fields.vector))
@@ -314,6 +491,10 @@ void kvm_arch_post_irq_ack_notifier_list_update(struct kvm *kvm)
 	kvm_make_scan_ioapic_request(kvm);
 }
 
+/*
+ * 在以下使用ioapic_write_indirect():
+ *   - arch/x86/kvm/ioapic.c|907| <<ioapic_mmio_write>> ioapic_write_indirect(ioapic, data);
+ */
 static void ioapic_write_indirect(struct kvm_ioapic *ioapic, u32 val)
 {
 	unsigned index;
@@ -340,6 +521,24 @@ static void ioapic_write_indirect(struct kvm_ioapic *ioapic, u32 val)
 		if (index >= IOAPIC_NUM_PINS)
 			return;
 		index = array_index_nospec(index, IOAPIC_NUM_PINS);
+		/*
+		 * union kvm_ioapic_redirect_entry {
+		 *     u64 bits;
+		 *     struct {
+		 *         u8 vector;
+		 *         u8 delivery_mode:3;
+		 *         u8 dest_mode:1;
+		 *         u8 delivery_status:1;
+		 *         u8 polarity:1;
+		 *         u8 remote_irr:1;
+		 *         u8 trig_mode:1;
+		 *         u8 mask:1;
+		 *         u8 reserve:7;
+		 *         u8 reserved[4];
+		 *         u8 dest_id;
+		 *      } fields;
+		 * };
+		 */
 		e = &ioapic->redirtbl[index];
 		mask_before = e->fields.mask;
 		/* Preserve read-only fields */
@@ -347,6 +546,9 @@ static void ioapic_write_indirect(struct kvm_ioapic *ioapic, u32 val)
 		old_delivery_status = e->fields.delivery_status;
 		old_dest_id = e->fields.dest_id;
 		old_dest_mode = e->fields.dest_mode;
+		/*
+		 * 主要在这里修改!
+		 */
 		if (ioapic->ioregsel & 1) {
 			e->bits &= 0xffffffff;
 			e->bits |= (u64) val << 32;
@@ -410,8 +612,35 @@ static void ioapic_write_indirect(struct kvm_ioapic *ioapic, u32 val)
 	}
 }
 
+/*
+ * hot-add和hot-del都调用
+ *
+ * ioapic_service
+ * ioapic_set_irq
+ * kvm_ioapic_set_irq
+ * kvm_set_irq
+ * kvm_vm_ioctl_irq_line
+ * kvm_vm_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ */
 static int ioapic_service(struct kvm_ioapic *ioapic, int irq, bool line_status)
 {
+	/*
+	 * 在以下使用kvm_ioapic->redirtbl[IOAPIC_NUM_PINS]:
+	 *   - arch/x86/kvm/ioapic.c|83| <<ioapic_read_indirect>> redir_content = ioapic->redirtbl[index].bits;
+	 *   - arch/x86/kvm/ioapic.c|117| <<__rtc_irq_eoi_tracking_restore_one>> e = &ioapic->redirtbl[RTC_GSI];
+	 *   - arch/x86/kvm/ioapic.c|189| <<ioapic_lazy_update_eoi>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|215| <<ioapic_set_irq>> entry = ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|294| <<kvm_ioapic_scan_entry>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|343| <<ioapic_write_indirect>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|415| <<ioapic_service>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|490| <<kvm_ioapic_eoi_inject_work>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|508| <<kvm_ioapic_update_eoi_one>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
+	 *   - arch/x86/kvm/ioapic.c|558| <<kvm_ioapic_update_eoi>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|670| <<kvm_ioapic_reset>> ioapic->redirtbl[i].fields.mask = 1;
+	 */
 	union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
 	struct kvm_lapic_irq irqe;
 	int ret;
@@ -441,6 +670,15 @@ static int ioapic_service(struct kvm_ioapic *ioapic, int irq, bool line_status)
 		 * if rtc_irq_check_coalesced returns false).
 		 */
 		BUG_ON(ioapic->rtc_status.pending_eoi != 0);
+		/*
+		 * 在以下使用kvm_irq_delivery_to_apic():
+		 *   - arch/x86/kvm/hyperv.c|495| <<synic_set_irq>> ret = kvm_irq_delivery_to_apic(vcpu->kvm, vcpu->arch.apic, &irq, NULL);
+		 *   - arch/x86/kvm/ioapic.c|673| <<ioapic_service>> ret = kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe,
+		 *   - arch/x86/kvm/ioapic.c|677| <<ioapic_service>> ret = kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe, NULL);
+		 *   - arch/x86/kvm/irq_comm.c|214| <<kvm_set_msi>> return kvm_irq_delivery_to_apic(kvm, NULL, &irq, NULL);
+		 *   - arch/x86/kvm/lapic.c|2293| <<kvm_apic_send_ipi>> kvm_irq_delivery_to_apic(apic->vcpu->kvm, apic, &irq, NULL);
+		 *   - arch/x86/kvm/x86.c|9314| <<kvm_pv_kick_cpu_op>> kvm_irq_delivery_to_apic(kvm, NULL, &lapic_irq, NULL);
+		 */
 		ret = kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe,
 					       &ioapic->rtc_status.dest_map);
 		ioapic->rtc_status.pending_eoi = (ret < 0 ? 0 : ret);
@@ -487,6 +725,20 @@ static void kvm_ioapic_eoi_inject_work(struct work_struct *work)
 						 eoi_inject.work);
 	spin_lock(&ioapic->lock);
 	for (i = 0; i < IOAPIC_NUM_PINS; i++) {
+		/*
+		 * 在以下使用kvm_ioapic->redirtbl[IOAPIC_NUM_PINS]:
+		 *   - arch/x86/kvm/ioapic.c|83| <<ioapic_read_indirect>> redir_content = ioapic->redirtbl[index].bits;
+		 *   - arch/x86/kvm/ioapic.c|117| <<__rtc_irq_eoi_tracking_restore_one>> e = &ioapic->redirtbl[RTC_GSI];
+		 *   - arch/x86/kvm/ioapic.c|189| <<ioapic_lazy_update_eoi>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+		 *   - arch/x86/kvm/ioapic.c|215| <<ioapic_set_irq>> entry = ioapic->redirtbl[irq];
+		 *   - arch/x86/kvm/ioapic.c|294| <<kvm_ioapic_scan_entry>> e = &ioapic->redirtbl[index];
+		 *   - arch/x86/kvm/ioapic.c|343| <<ioapic_write_indirect>> e = &ioapic->redirtbl[index];
+		 *   - arch/x86/kvm/ioapic.c|415| <<ioapic_service>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+		 *   - arch/x86/kvm/ioapic.c|490| <<kvm_ioapic_eoi_inject_work>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+		 *   - arch/x86/kvm/ioapic.c|508| <<kvm_ioapic_update_eoi_one>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
+		 *   - arch/x86/kvm/ioapic.c|558| <<kvm_ioapic_update_eoi>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+		 *   - arch/x86/kvm/ioapic.c|670| <<kvm_ioapic_reset>> ioapic->redirtbl[i].fields.mask = 1;
+		 */
 		union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
 
 		if (ent->fields.trig_mode != IOAPIC_LEVEL_TRIG)
@@ -499,12 +751,39 @@ static void kvm_ioapic_eoi_inject_work(struct work_struct *work)
 }
 
 #define IOAPIC_SUCCESSIVE_IRQ_MAX_COUNT 10000
+/*
+ * kvm_ioapic_update_eoi
+ * kvm_apic_set_eoi_accelerated
+ * handle_apic_eoi_induced
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ */
 static void kvm_ioapic_update_eoi_one(struct kvm_vcpu *vcpu,
 				      struct kvm_ioapic *ioapic,
 				      int trigger_mode,
 				      int pin)
 {
 	struct kvm_lapic *apic = vcpu->arch.apic;
+	/*
+	 * 在以下使用kvm_ioapic->redirtbl[IOAPIC_NUM_PINS]:
+	 *   - arch/x86/kvm/ioapic.c|83| <<ioapic_read_indirect>> redir_content = ioapic->redirtbl[index].bits;
+	 *   - arch/x86/kvm/ioapic.c|117| <<__rtc_irq_eoi_tracking_restore_one>> e = &ioapic->redirtbl[RTC_GSI];
+	 *   - arch/x86/kvm/ioapic.c|189| <<ioapic_lazy_update_eoi>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|215| <<ioapic_set_irq>> entry = ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|294| <<kvm_ioapic_scan_entry>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|343| <<ioapic_write_indirect>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|415| <<ioapic_service>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|490| <<kvm_ioapic_eoi_inject_work>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|508| <<kvm_ioapic_update_eoi_one>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
+	 *   - arch/x86/kvm/ioapic.c|558| <<kvm_ioapic_update_eoi>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|670| <<kvm_ioapic_reset>> ioapic->redirtbl[i].fields.mask = 1;
+	 */
 	union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
 
 	/*
@@ -547,6 +826,22 @@ static void kvm_ioapic_update_eoi_one(struct kvm_vcpu *vcpu,
 	}
 }
 
+/*
+ * kvm_ioapic_update_eoi
+ * kvm_apic_set_eoi_accelerated
+ * handle_apic_eoi_induced
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * 在以下使用kvm_ioapic_update_eoi():
+ *   - arch/x86/kvm/lapic.c|2113| <<kvm_ioapic_send_eoi>> kvm_ioapic_update_eoi(apic->vcpu, vector, trigger_mode);
+ */
 void kvm_ioapic_update_eoi(struct kvm_vcpu *vcpu, int vector, int trigger_mode)
 {
 	int i;
@@ -555,6 +850,20 @@ void kvm_ioapic_update_eoi(struct kvm_vcpu *vcpu, int vector, int trigger_mode)
 	spin_lock(&ioapic->lock);
 	rtc_irq_eoi(ioapic, vcpu, vector);
 	for (i = 0; i < IOAPIC_NUM_PINS; i++) {
+		/*
+		 * 在以下使用kvm_ioapic->redirtbl[IOAPIC_NUM_PINS]:
+		 *   - arch/x86/kvm/ioapic.c|83| <<ioapic_read_indirect>> redir_content = ioapic->redirtbl[index].bits;
+		 *   - arch/x86/kvm/ioapic.c|117| <<__rtc_irq_eoi_tracking_restore_one>> e = &ioapic->redirtbl[RTC_GSI];
+		 *   - arch/x86/kvm/ioapic.c|189| <<ioapic_lazy_update_eoi>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+		 *   - arch/x86/kvm/ioapic.c|215| <<ioapic_set_irq>> entry = ioapic->redirtbl[irq];
+		 *   - arch/x86/kvm/ioapic.c|294| <<kvm_ioapic_scan_entry>> e = &ioapic->redirtbl[index];
+		 *   - arch/x86/kvm/ioapic.c|343| <<ioapic_write_indirect>> e = &ioapic->redirtbl[index];
+		 *   - arch/x86/kvm/ioapic.c|415| <<ioapic_service>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+		 *   - arch/x86/kvm/ioapic.c|490| <<kvm_ioapic_eoi_inject_work>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+		 *   - arch/x86/kvm/ioapic.c|508| <<kvm_ioapic_update_eoi_one>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
+		 *   - arch/x86/kvm/ioapic.c|558| <<kvm_ioapic_update_eoi>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+		 *   - arch/x86/kvm/ioapic.c|670| <<kvm_ioapic_reset>> ioapic->redirtbl[i].fields.mask = 1;
+		 */
 		union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
 
 		if (ent->fields.vector != vector)
@@ -666,6 +975,20 @@ static void kvm_ioapic_reset(struct kvm_ioapic *ioapic)
 	int i;
 
 	cancel_delayed_work_sync(&ioapic->eoi_inject);
+	/*
+	 * 在以下使用kvm_ioapic->redirtbl[IOAPIC_NUM_PINS]:
+	 *   - arch/x86/kvm/ioapic.c|83| <<ioapic_read_indirect>> redir_content = ioapic->redirtbl[index].bits;
+	 *   - arch/x86/kvm/ioapic.c|117| <<__rtc_irq_eoi_tracking_restore_one>> e = &ioapic->redirtbl[RTC_GSI];
+	 *   - arch/x86/kvm/ioapic.c|189| <<ioapic_lazy_update_eoi>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|215| <<ioapic_set_irq>> entry = ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|294| <<kvm_ioapic_scan_entry>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|343| <<ioapic_write_indirect>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|415| <<ioapic_service>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|490| <<kvm_ioapic_eoi_inject_work>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|508| <<kvm_ioapic_update_eoi_one>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
+	 *   - arch/x86/kvm/ioapic.c|558| <<kvm_ioapic_update_eoi>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|670| <<kvm_ioapic_reset>> ioapic->redirtbl[i].fields.mask = 1;
+	 */
 	for (i = 0; i < IOAPIC_NUM_PINS; i++)
 		ioapic->redirtbl[i].fields.mask = 1;
 	ioapic->base_address = IOAPIC_DEFAULT_BASE_ADDRESS;
diff --git a/arch/x86/kvm/ioapic.h b/arch/x86/kvm/ioapic.h
index f1b2b2a6ff4d..ac3cbdd17bcf 100644
--- a/arch/x86/kvm/ioapic.h
+++ b/arch/x86/kvm/ioapic.h
@@ -77,6 +77,20 @@ struct kvm_ioapic {
 	u32 id;
 	u32 irr;
 	u32 pad;
+	/*
+	 * 在以下使用kvm_ioapic->redirtbl[IOAPIC_NUM_PINS]:
+	 *   - arch/x86/kvm/ioapic.c|83| <<ioapic_read_indirect>> redir_content = ioapic->redirtbl[index].bits;
+	 *   - arch/x86/kvm/ioapic.c|117| <<__rtc_irq_eoi_tracking_restore_one>> e = &ioapic->redirtbl[RTC_GSI];
+	 *   - arch/x86/kvm/ioapic.c|189| <<ioapic_lazy_update_eoi>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|215| <<ioapic_set_irq>> entry = ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|294| <<kvm_ioapic_scan_entry>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|343| <<ioapic_write_indirect>> e = &ioapic->redirtbl[index];
+	 *   - arch/x86/kvm/ioapic.c|415| <<ioapic_service>> union kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];
+	 *   - arch/x86/kvm/ioapic.c|490| <<kvm_ioapic_eoi_inject_work>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|508| <<kvm_ioapic_update_eoi_one>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[pin];
+	 *   - arch/x86/kvm/ioapic.c|558| <<kvm_ioapic_update_eoi>> union kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];
+	 *   - arch/x86/kvm/ioapic.c|670| <<kvm_ioapic_reset>> ioapic->redirtbl[i].fields.mask = 1;
+	 */
 	union kvm_ioapic_redirect_entry redirtbl[IOAPIC_NUM_PINS];
 	unsigned long irq_states[IOAPIC_NUM_PINS];
 	struct kvm_io_device dev;
diff --git a/arch/x86/kvm/irq.c b/arch/x86/kvm/irq.c
index 172b05343cfd..3cb12dfeef6e 100644
--- a/arch/x86/kvm/irq.c
+++ b/arch/x86/kvm/irq.c
@@ -20,6 +20,14 @@
  * check if there are pending timer events
  * to be processed.
  */
+/*
+ * 在以下使用kvm_cpu_has_pending_timer():
+ *   - arch/x86/kvm/x86.c|11445| <<vcpu_run>> if (kvm_cpu_has_pending_timer(vcpu))
+ *   - virt/kvm/kvm_main.c|3402| <<kvm_vcpu_check_block>> if (kvm_cpu_has_pending_timer(vcpu))
+ *
+ * 检查APIC的Timer寄存器是不是开了
+ * 并且是不是有pending的
+ */
 int kvm_cpu_has_pending_timer(struct kvm_vcpu *vcpu)
 {
 	if (lapic_in_kernel(vcpu))
@@ -41,6 +49,16 @@ static int pending_userspace_extint(struct kvm_vcpu *v)
  * check if there is pending interrupt from
  * non-APIC source without intack.
  */
+/*
+ * 在以下调用kvm_cpu_has_extint():
+ *   - arch/x86/kvm/irq.c|86| <<kvm_cpu_has_injectable_intr>> if (kvm_cpu_has_extint(v))
+ *   - arch/x86/kvm/irq.c|115| <<kvm_cpu_has_interrupt>> if (kvm_cpu_has_extint(v))
+ *   - arch/x86/kvm/irq.c|135| <<kvm_cpu_get_extint>> if (!kvm_cpu_has_extint(v)) {
+ *   - arch/x86/kvm/x86.c|4850| <<kvm_cpu_accept_dm_intr>> if (kvm_cpu_has_extint(vcpu))
+ *
+ * check if there is pending interrupt from
+ * non-APIC source without intack.
+ */
 int kvm_cpu_has_extint(struct kvm_vcpu *v)
 {
 	/*
@@ -63,6 +81,11 @@ int kvm_cpu_has_extint(struct kvm_vcpu *v)
 	if (!kvm_apic_accept_pic_intr(v))
 		return 0;
 
+	/*
+	 * on: KVM模拟全部
+	 * split: QEMU模拟IOAPIC和PIC,KVM模拟LAPIC
+	 * off:QEMU 模拟全部
+	 */
 	if (irqchip_split(v->kvm))
 		return pending_userspace_extint(v);
 	else
@@ -75,14 +98,39 @@ int kvm_cpu_has_extint(struct kvm_vcpu *v)
  * interrupt from apic will handled by hardware,
  * we don't need to check it here.
  */
+/*
+ * 在以下使用kvm_cpu_has_injectable_intr():
+ *   - arch/x86/kvm/svm/svm.c|2448| <<svm_set_gif>> kvm_cpu_has_injectable_intr(&svm->vcpu))
+ *   - arch/x86/kvm/x86.c|9412| <<inject_pending_event>> if (kvm_cpu_has_injectable_intr(vcpu)) {
+ *   - arch/x86/kvm/x86.c|9425| <<inject_pending_event>> if (kvm_cpu_has_injectable_intr(vcpu))
+ */
 int kvm_cpu_has_injectable_intr(struct kvm_vcpu *v)
 {
+	/*
+	 * 在以下调用kvm_cpu_has_extint():
+	 *   - arch/x86/kvm/irq.c|86| <<kvm_cpu_has_injectable_intr>> if (kvm_cpu_has_extint(v))
+	 *   - arch/x86/kvm/irq.c|115| <<kvm_cpu_has_interrupt>> if (kvm_cpu_has_extint(v))
+	 *   - arch/x86/kvm/irq.c|135| <<kvm_cpu_get_extint>> if (!kvm_cpu_has_extint(v)) {
+	 *   - arch/x86/kvm/x86.c|4850| <<kvm_cpu_accept_dm_intr>> if (kvm_cpu_has_extint(vcpu))
+	 *
+	 * check if there is pending interrupt from
+	 * non-APIC source without intack.
+	 */
 	if (kvm_cpu_has_extint(v))
 		return 1;
 
 	if (!is_guest_mode(v) && kvm_vcpu_apicv_active(v))
 		return 0;
 
+	/*
+	 * 在以下使用kvm_apic_has_interrupt():
+	 *   - arch/x86/kvm/irq.c|86| <<kvm_cpu_has_injectable_intr>> return kvm_apic_has_interrupt(v) != -1;
+	 *   - arch/x86/kvm/irq.c|99| <<kvm_cpu_has_interrupt>> return kvm_apic_has_interrupt(v) != -1;
+	 *   - arch/x86/kvm/lapic.c|2841| <<kvm_get_apic_interrupt>> int vector = kvm_apic_has_interrupt(vcpu);
+	 *   - arch/x86/kvm/vmx/nested.c|3627| <<nested_vmx_run>> kvm_apic_has_interrupt(vcpu) == vmx->nested.posted_intr_nv) {
+	 *
+	 * 似乎选出最大的irr, 不选isr
+	 */
 	return kvm_apic_has_interrupt(v) != -1; /* LAPIC */
 }
 EXPORT_SYMBOL_GPL(kvm_cpu_has_injectable_intr);
@@ -91,11 +139,34 @@ EXPORT_SYMBOL_GPL(kvm_cpu_has_injectable_intr);
  * check if there is pending interrupt without
  * intack.
  */
+/*
+ * 在以下使用kvm_cpu_has_interrupt():
+ *   - arch/x86/kvm/svm/nested.c|1334| <<svm_check_nested_events>> if (kvm_cpu_has_interrupt(vcpu) && !svm_interrupt_blocked(vcpu)) {
+ *   - arch/x86/kvm/vmx/nested.c|4021| <<vmx_check_nested_events>> if (kvm_cpu_has_interrupt(vcpu) && !vmx_interrupt_blocked(vcpu)) {
+ *   - arch/x86/kvm/x86.c|12828| <<kvm_vcpu_has_events>> (kvm_cpu_has_interrupt(vcpu) ||
+ */
 int kvm_cpu_has_interrupt(struct kvm_vcpu *v)
 {
+	/*
+	 * 在以下调用kvm_cpu_has_extint():
+	 *   - arch/x86/kvm/irq.c|86| <<kvm_cpu_has_injectable_intr>> if (kvm_cpu_has_extint(v))
+	 *   - arch/x86/kvm/irq.c|115| <<kvm_cpu_has_interrupt>> if (kvm_cpu_has_extint(v))
+	 *   - arch/x86/kvm/irq.c|135| <<kvm_cpu_get_extint>> if (!kvm_cpu_has_extint(v)) {
+	 *   - arch/x86/kvm/x86.c|4850| <<kvm_cpu_accept_dm_intr>> if (kvm_cpu_has_extint(vcpu))
+	 *
+	 * check if there is pending interrupt from
+	 * non-APIC source without intack.
+	 */
 	if (kvm_cpu_has_extint(v))
 		return 1;
 
+	/*
+	 * 在以下使用kvm_apic_has_interrupt():
+	 *   - arch/x86/kvm/irq.c|86| <<kvm_cpu_has_injectable_intr>> return kvm_apic_has_interrupt(v) != -1;
+	 *   - arch/x86/kvm/irq.c|99| <<kvm_cpu_has_interrupt>> return kvm_apic_has_interrupt(v) != -1;
+	 *   - arch/x86/kvm/lapic.c|2841| <<kvm_get_apic_interrupt>> int vector = kvm_apic_has_interrupt(vcpu);
+	 *   - arch/x86/kvm/vmx/nested.c|3627| <<nested_vmx_run>> kvm_apic_has_interrupt(vcpu) == vmx->nested.posted_intr_nv) {
+	 */
 	return kvm_apic_has_interrupt(v) != -1;	/* LAPIC */
 }
 EXPORT_SYMBOL_GPL(kvm_cpu_has_interrupt);
@@ -106,6 +177,16 @@ EXPORT_SYMBOL_GPL(kvm_cpu_has_interrupt);
  */
 static int kvm_cpu_get_extint(struct kvm_vcpu *v)
 {
+	/*
+	 * 在以下调用kvm_cpu_has_extint():
+	 *   - arch/x86/kvm/irq.c|86| <<kvm_cpu_has_injectable_intr>> if (kvm_cpu_has_extint(v))
+	 *   - arch/x86/kvm/irq.c|115| <<kvm_cpu_has_interrupt>> if (kvm_cpu_has_extint(v))
+	 *   - arch/x86/kvm/irq.c|135| <<kvm_cpu_get_extint>> if (!kvm_cpu_has_extint(v)) {
+	 *   - arch/x86/kvm/x86.c|4850| <<kvm_cpu_accept_dm_intr>> if (kvm_cpu_has_extint(vcpu))
+	 *
+	 * check if there is pending interrupt from
+	 * non-APIC source without intack.
+	 */
 	if (!kvm_cpu_has_extint(v)) {
 		WARN_ON(!lapic_in_kernel(v));
 		return -1;
@@ -117,6 +198,11 @@ static int kvm_cpu_get_extint(struct kvm_vcpu *v)
 	if (kvm_xen_has_interrupt(v))
 		return v->kvm->arch.xen.upcall_vector;
 
+	/*
+	 * on: KVM模拟全部
+	 * split: QEMU模拟IOAPIC和PIC,KVM模拟LAPIC
+	 * off:QEMU 模拟全部
+	 */
 	if (irqchip_split(v->kvm)) {
 		int vector = v->arch.pending_external_vector;
 
@@ -129,16 +215,35 @@ static int kvm_cpu_get_extint(struct kvm_vcpu *v)
 /*
  * Read pending interrupt vector and intack.
  */
+/*
+ * 在以下调用kvm_cpu_get_interrupt():
+ *   - arch/x86/kvm/vmx/nested.c|4709| <<nested_vmx_vmexit>> int irq = kvm_cpu_get_interrupt(vcpu);
+ *   - arch/x86/kvm/x86.c|9417| <<inject_pending_event>> int irq = kvm_cpu_get_interrupt(vcpu);
+ *
+ * vcpu_enter_guest()
+ * -> inject_pending_event()
+ *    -> kvm_cpu_get_interrupt()
+ *       -> kvm_get_apic_interrupt()
+ *          -> apic_set_isr()
+ */
 int kvm_cpu_get_interrupt(struct kvm_vcpu *v)
 {
 	int vector = kvm_cpu_get_extint(v);
 	if (vector != -1)
 		return vector;			/* PIC */
 
+	/*
+	 * 只在此处调用
+	 * 这个函数会把IRR的bit移动到ISR.
+	 */
 	return kvm_get_apic_interrupt(v);	/* APIC */
 }
 EXPORT_SYMBOL_GPL(kvm_cpu_get_interrupt);
 
+/*
+ * 只在这里使用kvm_inject_pending_timer_irqs():
+ *   - arch/x86/kvm/x86.c|11509| <<vcpu_run>> kvm_inject_pending_timer_irqs(vcpu);
+ */
 void kvm_inject_pending_timer_irqs(struct kvm_vcpu *vcpu)
 {
 	if (lapic_in_kernel(vcpu))
diff --git a/arch/x86/kvm/irq.h b/arch/x86/kvm/irq.h
index c2d7cfe82d00..1f0011c8606f 100644
--- a/arch/x86/kvm/irq.h
+++ b/arch/x86/kvm/irq.h
@@ -64,6 +64,19 @@ void kvm_pic_destroy(struct kvm *kvm);
 int kvm_pic_read_irq(struct kvm *kvm);
 void kvm_pic_update_irq(struct kvm_pic *s);
 
+/*
+ * 在以下使用irqchip_split():
+ *   - arch/x86/kvm/irq.c|76| <<kvm_cpu_has_extint>> if (irqchip_split(v->kvm))
+ *   - arch/x86/kvm/irq.c|188| <<kvm_cpu_get_extint>> if (irqchip_split(v->kvm)) {
+ *   - arch/x86/kvm/irq_comm.c|379| <<kvm_set_routing_entry>> if (irqchip_split(kvm))
+ *   - arch/x86/kvm/irq_comm.c|509| <<kvm_arch_post_irq_routing_update>> if (!irqchip_split(kvm))
+ *   - arch/x86/kvm/lapic.c|2102| <<kvm_ioapic_send_eoi>> if (irqchip_split(apic->vcpu->kvm)) {
+ *   - arch/x86/kvm/x86.c|10453| <<vcpu_scan_ioapic>> if (irqchip_split(vcpu->kvm))
+ *
+ * on: KVM模拟全部
+ * split: QEMU模拟IOAPIC和PIC,KVM模拟LAPIC
+ * off:QEMU 模拟全部
+ */
 static inline int irqchip_split(struct kvm *kvm)
 {
 	int mode = kvm->arch.irqchip_mode;
diff --git a/arch/x86/kvm/irq_comm.c b/arch/x86/kvm/irq_comm.c
index 025b65502fce..65d22f5c4f26 100644
--- a/arch/x86/kvm/irq_comm.c
+++ b/arch/x86/kvm/irq_comm.c
@@ -42,6 +42,15 @@ static int kvm_set_ioapic_irq(struct kvm_kernel_irq_routing_entry *e,
 				line_status);
 }
 
+/*
+ * 在以下使用kvm_irq_delivery_to_apic():
+ *   - arch/x86/kvm/hyperv.c|495| <<synic_set_irq>> ret = kvm_irq_delivery_to_apic(vcpu->kvm, vcpu->arch.apic, &irq, NULL);
+ *   - arch/x86/kvm/ioapic.c|673| <<ioapic_service>> ret = kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe,
+ *   - arch/x86/kvm/ioapic.c|677| <<ioapic_service>> ret = kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe, NULL);
+ *   - arch/x86/kvm/irq_comm.c|214| <<kvm_set_msi>> return kvm_irq_delivery_to_apic(kvm, NULL, &irq, NULL);
+ *   - arch/x86/kvm/lapic.c|2293| <<kvm_apic_send_ipi>> kvm_irq_delivery_to_apic(apic->vcpu->kvm, apic, &irq, NULL);
+ *   - arch/x86/kvm/x86.c|9314| <<kvm_pv_kick_cpu_op>> kvm_irq_delivery_to_apic(kvm, NULL, &lapic_irq, NULL);
+ */
 int kvm_irq_delivery_to_apic(struct kvm *kvm, struct kvm_lapic *src,
 		struct kvm_lapic_irq *irq, struct dest_map *dest_map)
 {
@@ -50,6 +59,11 @@ int kvm_irq_delivery_to_apic(struct kvm *kvm, struct kvm_lapic *src,
 	unsigned long dest_vcpu_bitmap[BITS_TO_LONGS(KVM_MAX_VCPUS)];
 	unsigned int dest_vcpus = 0;
 
+	/*
+	 * 在以下使用kvm_irq_delivery_to_apic_fast():
+	 *   - arch/x86/kvm/irq_comm.c|53| <<kvm_irq_delivery_to_apic>> if (kvm_irq_delivery_to_apic_fast(kvm, src, irq, &r, dest_map))
+	 *   - arch/x86/kvm/irq_comm.c|246| <<kvm_arch_set_irq_inatomic>> if (kvm_irq_delivery_to_apic_fast(kvm, NULL, &irq, &r, NULL))
+	 */
 	if (kvm_irq_delivery_to_apic_fast(kvm, src, irq, &r, dest_map))
 		return r;
 
@@ -65,6 +79,25 @@ int kvm_irq_delivery_to_apic(struct kvm *kvm, struct kvm_lapic *src,
 		if (!kvm_apic_present(vcpu))
 			continue;
 
+		/*
+		 * 在以下调用kvm_apic_match_dest():
+		 *   - arch/x86/kvm/ioapic.c|146| <<__rtc_irq_eoi_tracking_restore_one>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, e->fields.dest_id, kvm_lapic_irq_dest_mode(!!e->fields.dest_mode)))
+		 *   - arch/x86/kvm/ioapic.c|234| <<ioapic_lazy_update_eoi>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, entry->fields.dest_id, entry->fields.dest_mode) ||
+		 *   - arch/x86/kvm/ioapic.c|414| <<kvm_ioapic_scan_entry>> if (kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, e->fields.dest_id, dm) ||
+		 *   - arch/x86/kvm/irq_comm.c|68| <<kvm_irq_delivery_to_apic>> if (!kvm_apic_match_dest(vcpu, src,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/irq_comm.c|359| <<kvm_intr_is_single_vcpu>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/irq_comm.c|442| <<kvm_scan_ioapic_routes>> if (irq.trig_mode && (kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, irq.dest_id, irq.dest_mode) ||
+		 *   - arch/x86/kvm/lapic.c|1262| <<kvm_bitmap_or_dest_vcpus>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/svm/avic.c|461| <<avic_kick_target_vcpus>> if (kvm_apic_match_dest(vcpu, source,
+		 *          icrl & APIC_SHORT_MASK, dest, icrl & APIC_DEST_MASK)) {
+		 */
 		if (!kvm_apic_match_dest(vcpu, src, irq->shorthand,
 					irq->dest_id, irq->dest_mode))
 			continue;
@@ -72,8 +105,28 @@ int kvm_irq_delivery_to_apic(struct kvm *kvm, struct kvm_lapic *src,
 		if (!kvm_lowest_prio_delivery(irq)) {
 			if (r < 0)
 				r = 0;
+			/*
+			 * 在以下使用kvm_apic_set_irq():
+			 *   - arch/x86/kvm/hyperv.c|828| <<stimer_notify_direct>> return !kvm_apic_set_irq(vcpu, &irq, NULL);
+			 *   - arch/x86/kvm/hyperv.c|1899| <<kvm_send_ipi_to_many>> kvm_apic_set_irq(vcpu, &irq, NULL);
+			 *   - arch/x86/kvm/irq_comm.c|94| <<kvm_irq_delivery_to_apic>> r += kvm_apic_set_irq(vcpu, irq, dest_map);
+			 *   - arch/x86/kvm/irq_comm.c|125| <<kvm_irq_delivery_to_apic>> r = kvm_apic_set_irq(lowest, irq, dest_map);
+			 *   - arch/x86/kvm/lapic.c|1218| <<__pv_send_ipi>> count += kvm_apic_set_irq(vcpu, irq, NULL);
+			 *   - arch/x86/kvm/lapic.c|1699| <<kvm_irq_delivery_to_apic_fast>> *r = kvm_apic_set_irq(src->vcpu, irq, dest_map);
+			 *   - arch/x86/kvm/lapic.c|1712| <<kvm_irq_delivery_to_apic_fast>> *r += kvm_apic_set_irq(dst[i]->vcpu, irq, dest_map);
+			 *   - arch/x86/kvm/x86.c|13639| <<kvm_arch_async_page_present>> kvm_apic_set_irq(vcpu, &irq, NULL);
+			 */
 			r += kvm_apic_set_irq(vcpu, irq, dest_map);
 		} else if (kvm_apic_sw_enabled(vcpu->arch.apic)) {
+			/*
+			 * 在以下使用kvm_apic_sw_enabled():
+			 *   - arch/x86/kvm/irq_comm.c|95| <<kvm_irq_delivery_to_apic>> } else if (kvm_apic_sw_enabled(vcpu->arch.apic)) {
+			 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+			 *   - arch/x86/kvm/lapic.c|424| <<kvm_recalculate_apic_map>> if (!kvm_apic_sw_enabled(apic))
+			 *   - arch/x86/kvm/lapic.c|2720| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+			 *   - arch/x86/kvm/lapic.c|2731| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+			 *   - arch/x86/kvm/lapic.h|251| <<kvm_lapic_enabled>> return kvm_apic_present(vcpu) && kvm_apic_sw_enabled(vcpu->arch.apic);
+			 */
 			if (!kvm_vector_hashing_enabled()) {
 				if (!lowest)
 					lowest = vcpu;
@@ -93,12 +146,31 @@ int kvm_irq_delivery_to_apic(struct kvm *kvm, struct kvm_lapic *src,
 		lowest = kvm_get_vcpu(kvm, idx);
 	}
 
+	/*
+	 * 在以下使用kvm_apic_set_irq():
+	 *   - arch/x86/kvm/hyperv.c|828| <<stimer_notify_direct>> return !kvm_apic_set_irq(vcpu, &irq, NULL);
+	 *   - arch/x86/kvm/hyperv.c|1899| <<kvm_send_ipi_to_many>> kvm_apic_set_irq(vcpu, &irq, NULL);
+	 *   - arch/x86/kvm/irq_comm.c|94| <<kvm_irq_delivery_to_apic>> r += kvm_apic_set_irq(vcpu, irq, dest_map);
+	 *   - arch/x86/kvm/irq_comm.c|125| <<kvm_irq_delivery_to_apic>> r = kvm_apic_set_irq(lowest, irq, dest_map);
+	 *   - arch/x86/kvm/lapic.c|1218| <<__pv_send_ipi>> count += kvm_apic_set_irq(vcpu, irq, NULL);
+	 *   - arch/x86/kvm/lapic.c|1699| <<kvm_irq_delivery_to_apic_fast>> *r = kvm_apic_set_irq(src->vcpu, irq, dest_map);
+	 *   - arch/x86/kvm/lapic.c|1712| <<kvm_irq_delivery_to_apic_fast>> *r += kvm_apic_set_irq(dst[i]->vcpu, irq, dest_map);
+	 *   - arch/x86/kvm/x86.c|13639| <<kvm_arch_async_page_present>> kvm_apic_set_irq(vcpu, &irq, NULL);
+	 */
 	if (lowest)
 		r = kvm_apic_set_irq(lowest, irq, dest_map);
 
 	return r;
 }
 
+/*
+ * 在以下使用kvm_set_msi_irq():
+ *   - arch/x86/kvm/irq_comm.c|226| <<kvm_set_msi>> kvm_set_msi_irq(kvm, e, &irq);
+ *   - arch/x86/kvm/irq_comm.c|272| <<kvm_arch_set_irq_inatomic>> kvm_set_msi_irq(kvm, e, &irq);
+ *   - arch/x86/kvm/irq_comm.c|603| <<kvm_scan_ioapic_routes>> kvm_set_msi_irq(vcpu->kvm, entry, &irq);
+ *   - arch/x86/kvm/svm/avic.c|916| <<get_pi_vcpu_info>> kvm_set_msi_irq(kvm, e, &irq);
+ *   - arch/x86/kvm/vmx/posted_intr.c|319| <<vmx_pi_update_irte>> kvm_set_msi_irq(kvm, e, &irq);
+ */
 void kvm_set_msi_irq(struct kvm *kvm, struct kvm_kernel_irq_routing_entry *e,
 		     struct kvm_lapic_irq *irq)
 {
@@ -109,6 +181,17 @@ void kvm_set_msi_irq(struct kvm *kvm, struct kvm_kernel_irq_routing_entry *e,
 	trace_kvm_msi_set_irq(msg.address_lo | (kvm->arch.x2apic_format ?
 			      (u64)msg.address_hi << 32 : 0), msg.data);
 
+	/*
+	 * 在以下使用kvm_arch->x2apic_format:
+	 *   - arch/x86/kvm/irq_comm.c|137| <<kvm_set_msi_irq>> trace_kvm_msi_set_irq(msg.address_lo | (kvm->arch.x2apic_format ?
+	 *   - arch/x86/kvm/irq_comm.c|140| <<kvm_set_msi_irq>> irq->dest_id = x86_msi_msg_get_destid(&msg, kvm->arch.x2apic_format);
+	 *   - arch/x86/kvm/irq_comm.c|154| <<kvm_msi_route_invalid>> return kvm->arch.x2apic_format && (e->msi.address_hi & 0xff);
+	 *   - arch/x86/kvm/lapic.c|3673| <<kvm_apic_state_fixup>> if (vcpu->kvm->arch.x2apic_format) {
+	 *   - arch/x86/kvm/x86.c|5933| <<kvm_vm_ioctl_enable_cap>> kvm->arch.x2apic_format = true;
+	 *
+	 *     x2apic_format = false,
+	 *     x2apic_broadcast_quirk_disabled = false,
+	 */
 	irq->dest_id = x86_msi_msg_get_destid(&msg, kvm->arch.x2apic_format);
 	irq->vector = msg.arch_data.vector;
 	irq->dest_mode = kvm_lapic_irq_dest_mode(msg.arch_addr_lo.dest_mode_logical);
@@ -123,9 +206,25 @@ EXPORT_SYMBOL_GPL(kvm_set_msi_irq);
 static inline bool kvm_msi_route_invalid(struct kvm *kvm,
 		struct kvm_kernel_irq_routing_entry *e)
 {
+	/*
+	 * 在以下使用kvm_arch->x2apic_format:
+	 *   - arch/x86/kvm/irq_comm.c|137| <<kvm_set_msi_irq>> trace_kvm_msi_set_irq(msg.address_lo | (kvm->arch.x2apic_format ?
+	 *   - arch/x86/kvm/irq_comm.c|140| <<kvm_set_msi_irq>> irq->dest_id = x86_msi_msg_get_destid(&msg, kvm->arch.x2apic_format);
+	 *   - arch/x86/kvm/irq_comm.c|154| <<kvm_msi_route_invalid>> return kvm->arch.x2apic_format && (e->msi.address_hi & 0xff);
+	 *   - arch/x86/kvm/lapic.c|3673| <<kvm_apic_state_fixup>> if (vcpu->kvm->arch.x2apic_format) {
+	 *   - arch/x86/kvm/x86.c|5933| <<kvm_vm_ioctl_enable_cap>> kvm->arch.x2apic_format = true;
+	 *
+	 *     x2apic_format = false,
+	 *     x2apic_broadcast_quirk_disabled = false,
+	 */
 	return kvm->arch.x2apic_format && (e->msi.address_hi & 0xff);
 }
 
+/*
+ * 在以下使用kvm_set_msi():
+ *   - arch/x86/kvm/irq_comm.c|440| <<kvm_set_routing_entry>> e->set = kvm_set_msi;
+ *   - virt/kvm/irqchip.c|66| <<kvm_send_userspace_msi>> return kvm_set_msi(&route, kvm, KVM_USERSPACE_IRQ_SOURCE_ID, 1, false);
+ */
 int kvm_set_msi(struct kvm_kernel_irq_routing_entry *e,
 		struct kvm *kvm, int irq_source_id, int level, bool line_status)
 {
@@ -137,8 +236,25 @@ int kvm_set_msi(struct kvm_kernel_irq_routing_entry *e,
 	if (!level)
 		return -1;
 
+	/*
+	 * 在以下使用kvm_set_msi_irq():
+	 *   - arch/x86/kvm/irq_comm.c|226| <<kvm_set_msi>> kvm_set_msi_irq(kvm, e, &irq);
+	 *   - arch/x86/kvm/irq_comm.c|272| <<kvm_arch_set_irq_inatomic>> kvm_set_msi_irq(kvm, e, &irq);
+	 *   - arch/x86/kvm/irq_comm.c|603| <<kvm_scan_ioapic_routes>> kvm_set_msi_irq(vcpu->kvm, entry, &irq);
+	 *   - arch/x86/kvm/svm/avic.c|916| <<get_pi_vcpu_info>> kvm_set_msi_irq(kvm, e, &irq);
+	 *   - arch/x86/kvm/vmx/posted_intr.c|319| <<vmx_pi_update_irte>> kvm_set_msi_irq(kvm, e, &irq);
+	 */
 	kvm_set_msi_irq(kvm, e, &irq);
 
+	/*
+	 * 在以下使用kvm_irq_delivery_to_apic():
+	 *   - arch/x86/kvm/hyperv.c|495| <<synic_set_irq>> ret = kvm_irq_delivery_to_apic(vcpu->kvm, vcpu->arch.apic, &irq, NULL);
+	 *   - arch/x86/kvm/ioapic.c|673| <<ioapic_service>> ret = kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe,
+	 *   - arch/x86/kvm/ioapic.c|677| <<ioapic_service>> ret = kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe, NULL);
+	 *   - arch/x86/kvm/irq_comm.c|214| <<kvm_set_msi>> return kvm_irq_delivery_to_apic(kvm, NULL, &irq, NULL);
+	 *   - arch/x86/kvm/lapic.c|2293| <<kvm_apic_send_ipi>> kvm_irq_delivery_to_apic(apic->vcpu->kvm, apic, &irq, NULL);
+	 *   - arch/x86/kvm/x86.c|9314| <<kvm_pv_kick_cpu_op>> kvm_irq_delivery_to_apic(kvm, NULL, &lapic_irq, NULL);
+	 */
 	return kvm_irq_delivery_to_apic(kvm, NULL, &irq, NULL);
 }
 
@@ -153,6 +269,11 @@ static int kvm_hv_set_sint(struct kvm_kernel_irq_routing_entry *e,
 	return kvm_hv_synic_set_irq(kvm, e->hv_sint.vcpu, e->hv_sint.sint);
 }
 
+/*
+ * 在以下调用kvm_arch_set_irq_inatomic():
+ *   - virt/kvm/eventfd.c|206| <<irqfd_wakeup>> if (kvm_arch_set_irq_inatomic(&irq, kvm,
+ *           KVM_USERSPACE_IRQ_SOURCE_ID, 1, false) == -EWOULDBLOCK)
+ */
 int kvm_arch_set_irq_inatomic(struct kvm_kernel_irq_routing_entry *e,
 			      struct kvm *kvm, int irq_source_id, int level,
 			      bool line_status)
@@ -169,8 +290,33 @@ int kvm_arch_set_irq_inatomic(struct kvm_kernel_irq_routing_entry *e,
 		if (kvm_msi_route_invalid(kvm, e))
 			return -EINVAL;
 
+		/*
+		 * struct kvm_lapic_irq {
+		 *     u32 vector;
+		 *     u16 delivery_mode;
+		 *     u16 dest_mode;
+		 *     bool level;
+		 *     u16 trig_mode;
+		 *     u32 shorthand;
+		 *     u32 dest_id;
+		 *     bool msi_redir_hint;
+		 * };
+		 *
+		 *
+		 * 在以下使用kvm_set_msi_irq():
+		 *   - arch/x86/kvm/irq_comm.c|226| <<kvm_set_msi>> kvm_set_msi_irq(kvm, e, &irq);
+		 *   - arch/x86/kvm/irq_comm.c|272| <<kvm_arch_set_irq_inatomic>> kvm_set_msi_irq(kvm, e, &irq);
+		 *   - arch/x86/kvm/irq_comm.c|603| <<kvm_scan_ioapic_routes>> kvm_set_msi_irq(vcpu->kvm, entry, &irq);
+		 *   - arch/x86/kvm/svm/avic.c|916| <<get_pi_vcpu_info>> kvm_set_msi_irq(kvm, e, &irq);
+		 *   - arch/x86/kvm/vmx/posted_intr.c|319| <<vmx_pi_update_irte>> kvm_set_msi_irq(kvm, e, &irq);
+		 */
 		kvm_set_msi_irq(kvm, e, &irq);
 
+		/*
+		 * 在以下使用kvm_irq_delivery_to_apic_fast():
+		 *   - arch/x86/kvm/irq_comm.c|53| <<kvm_irq_delivery_to_apic>> if (kvm_irq_delivery_to_apic_fast(kvm, src, irq, &r, dest_map))
+		 *   - arch/x86/kvm/irq_comm.c|246| <<kvm_arch_set_irq_inatomic>> if (kvm_irq_delivery_to_apic_fast(kvm, NULL, &irq, &r, NULL))
+		 */
 		if (kvm_irq_delivery_to_apic_fast(kvm, NULL, &irq, &r, NULL))
 			return r;
 		break;
@@ -182,8 +328,19 @@ int kvm_arch_set_irq_inatomic(struct kvm_kernel_irq_routing_entry *e,
 	return -EWOULDBLOCK;
 }
 
+/*
+ * 在以下使用kvm_request_irq_source_id():
+ *   - arch/x86/kvm/i8254.c|670| <<kvm_create_pit>> pit->irq_source_id = kvm_request_irq_source_id(kvm);
+ */
 int kvm_request_irq_source_id(struct kvm *kvm)
 {
+	/*
+	 * 在以下使用kvm_arch->irq_sources_bitmap:
+	 *   - arch/x86/kvm/irq_comm.c|187| <<kvm_request_irq_source_id>> unsigned long *bitmap = &kvm->arch.irq_sources_bitmap;
+	 *   - arch/x86/kvm/irq_comm.c|219| <<kvm_free_irq_source_id>> clear_bit(irq_source_id, &kvm->arch.irq_sources_bitmap);
+	 *   - arch/x86/kvm/x86.c|11732| <<kvm_arch_init_vm>> set_bit(KVM_USERSPACE_IRQ_SOURCE_ID, &kvm->arch.irq_sources_bitmap);
+	 *   - arch/x86/kvm/x86.c|11735| <<kvm_arch_init_vm>> set_bit(KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID, &kvm->arch.irq_sources_bitmap);
+	 */
 	unsigned long *bitmap = &kvm->arch.irq_sources_bitmap;
 	int irq_source_id;
 
@@ -216,6 +373,13 @@ void kvm_free_irq_source_id(struct kvm *kvm, int irq_source_id)
 		printk(KERN_ERR "kvm: IRQ source ID out of range!\n");
 		goto unlock;
 	}
+	/*
+	 * 在以下使用kvm_arch->irq_sources_bitmap:
+	 *   - arch/x86/kvm/irq_comm.c|187| <<kvm_request_irq_source_id>> unsigned long *bitmap = &kvm->arch.irq_sources_bitmap;
+	 *   - arch/x86/kvm/irq_comm.c|219| <<kvm_free_irq_source_id>> clear_bit(irq_source_id, &kvm->arch.irq_sources_bitmap);
+	 *   - arch/x86/kvm/x86.c|11732| <<kvm_arch_init_vm>> set_bit(KVM_USERSPACE_IRQ_SOURCE_ID, &kvm->arch.irq_sources_bitmap);
+	 *   - arch/x86/kvm/x86.c|11735| <<kvm_arch_init_vm>> set_bit(KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID, &kvm->arch.irq_sources_bitmap);
+	 */
 	clear_bit(irq_source_id, &kvm->arch.irq_sources_bitmap);
 	if (!irqchip_kernel(kvm))
 		goto unlock;
@@ -231,6 +395,12 @@ void kvm_register_irq_mask_notifier(struct kvm *kvm, int irq,
 {
 	mutex_lock(&kvm->irq_lock);
 	kimn->irq = irq;
+	/*
+	 * 在以下使用kvm_arch->mask_notifier_list:
+	 *   - arch/x86/kvm/irq_comm.c|234| <<kvm_register_irq_mask_notifier>> hlist_add_head_rcu(&kimn->link, &kvm->arch.mask_notifier_list);
+	 *   - arch/x86/kvm/irq_comm.c|256| <<kvm_fire_mask_notifiers>> hlist_for_each_entry_rcu(kimn, &kvm->arch.mask_notifier_list, link)
+	 *   - arch/x86/kvm/x86.c|11763| <<kvm_arch_init_vm>> INIT_HLIST_HEAD(&kvm->arch.mask_notifier_list);
+	 */
 	hlist_add_head_rcu(&kimn->link, &kvm->arch.mask_notifier_list);
 	mutex_unlock(&kvm->irq_lock);
 }
@@ -252,6 +422,12 @@ void kvm_fire_mask_notifiers(struct kvm *kvm, unsigned irqchip, unsigned pin,
 
 	idx = srcu_read_lock(&kvm->irq_srcu);
 	gsi = kvm_irq_map_chip_pin(kvm, irqchip, pin);
+	/*
+	 * 在以下使用kvm_arch->mask_notifier_list:
+	 *   - arch/x86/kvm/irq_comm.c|234| <<kvm_register_irq_mask_notifier>> hlist_add_head_rcu(&kimn->link, &kvm->arch.mask_notifier_list);
+	 *   - arch/x86/kvm/irq_comm.c|256| <<kvm_fire_mask_notifiers>> hlist_for_each_entry_rcu(kimn, &kvm->arch.mask_notifier_list, link)
+	 *   - arch/x86/kvm/x86.c|11763| <<kvm_arch_init_vm>> INIT_HLIST_HEAD(&kvm->arch.mask_notifier_list);
+	 */
 	if (gsi != -1)
 		hlist_for_each_entry_rcu(kimn, &kvm->arch.mask_notifier_list, link)
 			if (kimn->irq == gsi)
@@ -274,6 +450,11 @@ int kvm_set_routing_entry(struct kvm *kvm,
 	 */
 	switch (ue->type) {
 	case KVM_IRQ_ROUTING_IRQCHIP:
+		/*
+		 * on: KVM模拟全部
+		 * split: QEMU模拟IOAPIC和PIC,KVM模拟LAPIC
+		 * off:QEMU 模拟全部
+		 */
 		if (irqchip_split(kvm))
 			return -EINVAL;
 		e->irqchip.pin = ue->u.irqchip.pin;
@@ -317,12 +498,34 @@ int kvm_set_routing_entry(struct kvm *kvm,
 	return 0;
 }
 
+/*
+ * 在以下使用kvm_intr_is_single_vcpu():
+ *   - arch/x86/kvm/svm/avic.c|918| <<get_pi_vcpu_info>> if (!kvm_intr_is_single_vcpu(kvm, &irq, &vcpu) ||
+ *   - arch/x86/kvm/vmx/posted_intr.c|310| <<vmx_pi_update_irte>> if (!kvm_intr_is_single_vcpu(kvm, &irq, &vcpu) ||
+ */
 bool kvm_intr_is_single_vcpu(struct kvm *kvm, struct kvm_lapic_irq *irq,
 			     struct kvm_vcpu **dest_vcpu)
 {
 	int i, r = 0;
 	struct kvm_vcpu *vcpu;
 
+	/*
+	 * 在以下调用kvm_intr_is_single_vcpu_fast():
+	 *   - arch/x86/kvm/irq_comm.c|471| <<kvm_intr_is_single_vcpu>> if (kvm_intr_is_single_vcpu_fast(kvm, irq, dest_vcpu))
+	 *
+	 * This routine tries to handle interrupts in posted mode, here is how
+	 * it deals with different cases:
+	 * - For single-destination interrupts, handle it in posted mode
+	 * - Else if vector hashing is enabled and it is a lowest-priority
+	 *   interrupt, handle it in posted mode and use the following mechanism
+	 *   to find the destination vCPU.
+	 *      1. For lowest-priority interrupts, store all the possible
+	 *         destination vCPUs in an array.
+	 *      2. Use "guest vector % max number of destination vCPUs" to find
+	 *         the right destination vCPU in the array for the lowest-priority
+	 *         interrupt.
+	 * - Otherwise, use remapped mode to inject the interrupt.
+	 */
 	if (kvm_intr_is_single_vcpu_fast(kvm, irq, dest_vcpu))
 		return true;
 
@@ -330,6 +533,25 @@ bool kvm_intr_is_single_vcpu(struct kvm *kvm, struct kvm_lapic_irq *irq,
 		if (!kvm_apic_present(vcpu))
 			continue;
 
+		/*
+		 * 在以下调用kvm_apic_match_dest():
+		 *   - arch/x86/kvm/ioapic.c|146| <<__rtc_irq_eoi_tracking_restore_one>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, e->fields.dest_id, kvm_lapic_irq_dest_mode(!!e->fields.dest_mode)))
+		 *   - arch/x86/kvm/ioapic.c|234| <<ioapic_lazy_update_eoi>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, entry->fields.dest_id, entry->fields.dest_mode) ||
+		 *   - arch/x86/kvm/ioapic.c|414| <<kvm_ioapic_scan_entry>> if (kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, e->fields.dest_id, dm) ||
+		 *   - arch/x86/kvm/irq_comm.c|68| <<kvm_irq_delivery_to_apic>> if (!kvm_apic_match_dest(vcpu, src,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/irq_comm.c|359| <<kvm_intr_is_single_vcpu>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/irq_comm.c|442| <<kvm_scan_ioapic_routes>> if (irq.trig_mode && (kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, irq.dest_id, irq.dest_mode) ||
+		 *   - arch/x86/kvm/lapic.c|1262| <<kvm_bitmap_or_dest_vcpus>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/svm/avic.c|461| <<avic_kick_target_vcpus>> if (kvm_apic_match_dest(vcpu, source,
+		 *          icrl & APIC_SHORT_MASK, dest, icrl & APIC_DEST_MASK)) {
+		 */
 		if (!kvm_apic_match_dest(vcpu, NULL, irq->shorthand,
 					irq->dest_id, irq->dest_mode))
 			continue;
@@ -385,11 +607,20 @@ int kvm_setup_empty_irq_routing(struct kvm *kvm)
 
 void kvm_arch_post_irq_routing_update(struct kvm *kvm)
 {
+	/*
+	 * on: KVM模拟全部
+	 * split: QEMU模拟IOAPIC和PIC,KVM模拟LAPIC
+	 * off:QEMU 模拟全部
+	 */
 	if (!irqchip_split(kvm))
 		return;
 	kvm_make_scan_ioapic_request(kvm);
 }
 
+/*
+ * 只在一个地方调用kvm_scan_ioapic_routes():
+ *   - arch/x86/kvm/x86.c|9856| <<vcpu_scan_ioapic>> kvm_scan_ioapic_routes(vcpu, vcpu->arch.ioapic_handled_vectors);
+ */
 void kvm_scan_ioapic_routes(struct kvm_vcpu *vcpu,
 			    ulong *ioapic_handled_vectors)
 {
@@ -410,8 +641,35 @@ void kvm_scan_ioapic_routes(struct kvm_vcpu *vcpu,
 			if (entry->type != KVM_IRQ_ROUTING_MSI)
 				continue;
 
+			/*
+			 * 在以下使用kvm_set_msi_irq():
+			 *   - arch/x86/kvm/irq_comm.c|226| <<kvm_set_msi>> kvm_set_msi_irq(kvm, e, &irq);
+			 *   - arch/x86/kvm/irq_comm.c|272| <<kvm_arch_set_irq_inatomic>> kvm_set_msi_irq(kvm, e, &irq);
+			 *   - arch/x86/kvm/irq_comm.c|603| <<kvm_scan_ioapic_routes>> kvm_set_msi_irq(vcpu->kvm, entry, &irq);
+			 *   - arch/x86/kvm/svm/avic.c|916| <<get_pi_vcpu_info>> kvm_set_msi_irq(kvm, e, &irq);
+			 *   - arch/x86/kvm/vmx/posted_intr.c|319| <<vmx_pi_update_irte>> kvm_set_msi_irq(kvm, e, &irq);
+			 */
 			kvm_set_msi_irq(vcpu->kvm, entry, &irq);
 
+			/*
+			 * 在以下调用kvm_apic_match_dest():
+			 *   - arch/x86/kvm/ioapic.c|146| <<__rtc_irq_eoi_tracking_restore_one>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, e->fields.dest_id, kvm_lapic_irq_dest_mode(!!e->fields.dest_mode)))
+			 *   - arch/x86/kvm/ioapic.c|234| <<ioapic_lazy_update_eoi>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, entry->fields.dest_id, entry->fields.dest_mode) ||
+			 *   - arch/x86/kvm/ioapic.c|414| <<kvm_ioapic_scan_entry>> if (kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, e->fields.dest_id, dm) ||
+			 *   - arch/x86/kvm/irq_comm.c|68| <<kvm_irq_delivery_to_apic>> if (!kvm_apic_match_dest(vcpu, src,
+			 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+			 *   - arch/x86/kvm/irq_comm.c|359| <<kvm_intr_is_single_vcpu>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+			 *   - arch/x86/kvm/irq_comm.c|442| <<kvm_scan_ioapic_routes>> if (irq.trig_mode && (kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, irq.dest_id, irq.dest_mode) ||
+			 *   - arch/x86/kvm/lapic.c|1262| <<kvm_bitmap_or_dest_vcpus>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+			 *   - arch/x86/kvm/svm/avic.c|461| <<avic_kick_target_vcpus>> if (kvm_apic_match_dest(vcpu, source,
+			 *          icrl & APIC_SHORT_MASK, dest, icrl & APIC_DEST_MASK)) {
+			 */
 			if (irq.trig_mode &&
 			    (kvm_apic_match_dest(vcpu, NULL, APIC_DEST_NOSHORT,
 						 irq.dest_id, irq.dest_mode) ||
diff --git a/arch/x86/kvm/lapic.c b/arch/x86/kvm/lapic.c
index 43c2722ef25e..1b09cb137603 100644
--- a/arch/x86/kvm/lapic.c
+++ b/arch/x86/kvm/lapic.c
@@ -43,6 +43,66 @@
 #include "cpuid.h"
 #include "hyperv.h"
 
+/*
+ * | 项目                 | MSR_IA32_APICBASE       | SPIV (0xF0)                |
+ * | ------------------ | ------------------------- | -------------------------- |
+ * | 控制粒度               | 硬件级,全局关闭                  | 软件级,关闭中断处理                 |
+ * | 生效范围               | 关闭整个 Local APIC           | 保留结构但不响应中断                 |
+ * | 通常使用时机             | BIOS,操作系统启动阶段             | 操作系统运行时                    |
+ * | 会影响 APIC MMIO 寄存器吗 | 是,APIC 基址无效后不能访问 APIC 寄存器 | 否,仍然可访问 APIC 寄存器           |
+ * | 对中断的影响             | 完全禁用中断(包括 INIT, STARTUP)  | 仅禁用普通中断,某些特殊中断(如 NMI)有效    |
+ * | 典型用途               | 内核初始化前设置,关闭 SMP 支持        | 操作系统禁用中断(如使用 IOAPIC 或 PIC) |
+ *
+ *
+ * 如果你只把SPIV 的使能位关掉(即SPIV[8]=0),CPU不会响应普通中断,但Local APIC结构还在,
+ * 依然可以接收INIT或IPI等特殊信号.
+ *
+ * 如果你把MSR_IA32_APICBASE[11]=0,则整个Local APIC被禁用,APIC MMIO区也不能访问,
+ * 连 INIT,STARTUP都可能无法正确使用.
+ */
+
+/*
+ * 下面两个函数很重要.
+ *
+ * vmx_inject_irq()
+ * vmx_hwapic_isr_update()
+ */
+
+/*
+ * 在以下使用apic的regs:
+ *   - arch/x86/kvm/lapic.c|88| <<kvm_lapic_set_reg>> __kvm_lapic_set_reg(apic->regs, reg_off, val);
+ *   - arch/x86/kvm/lapic.c|99| <<kvm_lapic_get_reg64>> return __kvm_lapic_get_reg64(apic->regs, reg);
+ *   - arch/x86/kvm/lapic.c|111| <<kvm_lapic_set_reg64>> __kvm_lapic_set_reg64(apic->regs, reg, val);
+ *   - arch/x86/kvm/lapic.c|123| <<kvm_apic_pending_eoi>> return apic_test_vector(vector, apic->regs + APIC_ISR) ||
+ *   - arch/x86/kvm/lapic.c|124| <<kvm_apic_pending_eoi>> apic_test_vector(vector, apic->regs + APIC_IRR);
+ *   - arch/x86/kvm/lapic.c|682| <<kvm_apic_update_irr>> bool irr_updated = __kvm_apic_update_irr(pir, apic->regs, max_irr);
+ *   - arch/x86/kvm/lapic.c|707| <<apic_search_irr>> return find_highest_vector(apic->regs + APIC_IRR);
+ *   - arch/x86/kvm/lapic.c|750| <<apic_clear_irr>> kvm_lapic_clear_vector(vec, apic->regs + APIC_IRR);
+ *   - arch/x86/kvm/lapic.c|770| <<apic_clear_irr>> kvm_lapic_clear_vector(vec, apic->regs + APIC_IRR);
+ *   - arch/x86/kvm/lapic.c|790| <<apic_set_isr>> if (__apic_test_and_set_vector(vec, apic->regs + APIC_ISR))
+ *   - arch/x86/kvm/lapic.c|878| <<apic_find_highest_isr>> result = find_highest_vector(apic->regs + APIC_ISR);
+ *   - arch/x86/kvm/lapic.c|891| <<apic_clear_isr>> if (!__apic_test_and_clear_vector(vec, apic->regs + APIC_ISR))
+ *   - arch/x86/kvm/lapic.c|1553| <<__apic_accept_irq>> if (apic_test_vector(vector, apic->regs + APIC_TMR) != !!trig_mode) {
+ *   - arch/x86/kvm/lapic.c|1556| <<__apic_accept_irq>> kvm_lapic_set_vector(vector, apic->regs + APIC_TMR);
+ *   - arch/x86/kvm/lapic.c|1559| <<__apic_accept_irq>> kvm_lapic_clear_vector(vector, apic->regs + APIC_TMR);
+ *   - arch/x86/kvm/lapic.c|1730| <<kvm_ioapic_send_eoi>> if (apic_test_vector(vector, apic->regs + APIC_TMR))
+ *   - arch/x86/kvm/lapic.c|2060| <<lapic_timer_int_injected>> void *bitmap = apic->regs + APIC_ISR;
+ *   - arch/x86/kvm/lapic.c|2063| <<lapic_timer_int_injected>> bitmap = apic->regs + APIC_IRR;
+ *   - arch/x86/kvm/lapic.c|2833| <<kvm_free_lapic>> if (apic->regs)
+ *   - arch/x86/kvm/lapic.c|2834| <<kvm_free_lapic>> free_page((unsigned long )apic->regs);
+ *   - arch/x86/kvm/lapic.c|2995| <<kvm_apic_update_apicv>> apic->isr_count = count_vectors(apic->regs + APIC_ISR);
+ *   - arch/x86/kvm/lapic.c|3198| <<kvm_create_lapic>> apic->regs = (void *)get_zeroed_page(GFP_KERNEL_ACCOUNT);
+ *   - arch/x86/kvm/lapic.c|3199| <<kvm_create_lapic>> if (!apic->regs) {
+ *   - arch/x86/kvm/lapic.c|3373| <<kvm_apic_get_state>> memcpy(s->regs, vcpu->arch.apic->regs, sizeof(*s));
+ *   - arch/x86/kvm/lapic.c|3413| <<kvm_apic_set_state>> apic_set_spiv(apic, *((u32 *)(s->regs + APIC_SPIV)));
+ *   - arch/x86/kvm/lapic.c|3433| <<kvm_apic_set_state>> memcpy(vcpu->arch.apic->regs, s->regs, sizeof(*s));
+ *   - arch/x86/kvm/lapic.h|184| <<kvm_lapic_set_irr>> kvm_lapic_set_vector(vec, apic->regs + APIC_IRR);
+ *   - arch/x86/kvm/lapic.h|214| <<kvm_lapic_get_reg>> return __kvm_lapic_get_reg(apic->regs, reg_off);
+ *   - arch/x86/kvm/svm/avic.c|294| <<avic_init_backing_page>> if (!vcpu->arch.apic->regs)
+ *   - arch/x86/kvm/svm/avic.c|305| <<avic_init_backing_page>> svm->avic_backing_page = virt_to_page(vcpu->arch.apic->regs);
+ *   - arch/x86/kvm/vmx/vmx.c|4590| <<init_vmcs>> ivmcs_write64(VIRTUAL_APIC_PAGE_ADDR, __pa(vmx->vcpu.arch.apic->regs));
+ */
+
 #ifndef CONFIG_X86_64
 #define mod_64(x, y) ((x) - (y) * div64_u64(x, y))
 #else
@@ -104,6 +164,14 @@ static __always_inline void kvm_lapic_set_reg64(struct kvm_lapic *apic,
 	__kvm_lapic_set_reg64(apic->regs, reg, val);
 }
 
+/*
+ * 在以下使用apic_test_vector():
+ *   - arch/x86/kvm/lapic.c|176| <<kvm_apic_pending_eoi>> return apic_test_vector(vector, apic->regs + APIC_ISR) ||
+ *   - arch/x86/kvm/lapic.c|177| <<kvm_apic_pending_eoi>> apic_test_vector(vector, apic->regs + APIC_IRR);
+ *   - arch/x86/kvm/lapic.c|2104| <<__apic_accept_irq>> if (apic_test_vector(vector, apic->regs + APIC_TMR) != !!trig_mode) {
+ *   - arch/x86/kvm/lapic.c|2324| <<kvm_ioapic_send_eoi>> if (apic_test_vector(vector, apic->regs + APIC_TMR))
+ *   - arch/x86/kvm/lapic.c|2723| <<lapic_timer_int_injected>> if (apic_test_vector(vec, bitmap))
+ */
 static inline int apic_test_vector(int vec, void *bitmap)
 {
 	return test_bit(VEC_POS(vec), (bitmap) + REG_POS(vec));
@@ -113,6 +181,14 @@ bool kvm_apic_pending_eoi(struct kvm_vcpu *vcpu, int vector)
 {
 	struct kvm_lapic *apic = vcpu->arch.apic;
 
+	/*
+	 * 在以下使用apic_test_vector():
+	 *   - arch/x86/kvm/lapic.c|176| <<kvm_apic_pending_eoi>> return apic_test_vector(vector, apic->regs + APIC_ISR) ||
+	 *   - arch/x86/kvm/lapic.c|177| <<kvm_apic_pending_eoi>> apic_test_vector(vector, apic->regs + APIC_IRR);
+	 *   - arch/x86/kvm/lapic.c|2104| <<__apic_accept_irq>> if (apic_test_vector(vector, apic->regs + APIC_TMR) != !!trig_mode) {
+	 *   - arch/x86/kvm/lapic.c|2324| <<kvm_ioapic_send_eoi>> if (apic_test_vector(vector, apic->regs + APIC_TMR))
+	 *   - arch/x86/kvm/lapic.c|2723| <<lapic_timer_int_injected>> if (apic_test_vector(vec, bitmap))
+	 */
 	return apic_test_vector(vector, apic->regs + APIC_ISR) ||
 		apic_test_vector(vector, apic->regs + APIC_IRR);
 }
@@ -127,11 +203,56 @@ static inline int __apic_test_and_clear_vector(int vec, void *bitmap)
 	return __test_and_clear_bit(VEC_POS(vec), (bitmap) + REG_POS(vec));
 }
 
+/*
+ * 在以下使用apic_hw_disabled:
+ *   - arch/x86/kvm/lapic.c|190| <<global>> __read_mostly DEFINE_STATIC_KEY_DEFERRED_FALSE(apic_hw_disabled, HZ);
+ *   - arch/x86/kvm/lapic.c|3253| <<kvm_free_lapic>> static_branch_slow_dec_deferred(&apic_hw_disabled);
+ *   - arch/x86/kvm/lapic.c|3460| <<kvm_lapic_set_base>> static_branch_slow_dec_deferred(&apic_hw_disabled);
+ *   - arch/x86/kvm/lapic.c|3472| <<kvm_lapic_set_base>> static_branch_inc(&apic_hw_disabled.key);
+ *   - arch/x86/kvm/lapic.c|4580| <<kvm_lapic_exit>> static_key_deferred_flush(&apic_hw_disabled);
+ *   - arch/x86/kvm/lapic.c|4581| <<kvm_lapic_exit>> WARN_ON(static_branch_unlikely(&apic_hw_disabled.key));
+ *   - arch/x86/kvm/lapic.h|290| <<kvm_apic_hw_enabled>> if (static_branch_unlikely(&apic_hw_disabled.key))
+ */
 __read_mostly DEFINE_STATIC_KEY_DEFERRED_FALSE(apic_hw_disabled, HZ);
+/*
+ * 在以下使用apic_sw_disabled:
+ *   - arch/x86/kvm/lapic.c|191| <<global>> __read_mostly DEFINE_STATIC_KEY_DEFERRED_FALSE(apic_sw_disabled, HZ);
+ *   - arch/x86/kvm/lapic.c|599| <<apic_set_spiv>> static_branch_slow_dec_deferred(&apic_sw_disabled);
+ *   - arch/x86/kvm/lapic.c|601| <<apic_set_spiv>> static_branch_inc(&apic_sw_disabled.key);
+ *   - arch/x86/kvm/lapic.c|3263| <<kvm_free_lapic>> static_branch_slow_dec_deferred(&apic_sw_disabled);
+ *   - arch/x86/kvm/lapic.c|3840| <<kvm_create_lapic>> static_branch_inc(&apic_sw_disabled.key);
+ *   - arch/x86/kvm/lapic.c|4582| <<kvm_lapic_exit>> static_key_deferred_flush(&apic_sw_disabled);
+ *   - arch/x86/kvm/lapic.c|4583| <<kvm_lapic_exit>> WARN_ON(static_branch_unlikely(&apic_sw_disabled.key));
+ *   - arch/x86/kvm/lapic.h|315| <<kvm_apic_sw_enabled>> if (static_branch_unlikely(&apic_sw_disabled.key))
+ */
 __read_mostly DEFINE_STATIC_KEY_DEFERRED_FALSE(apic_sw_disabled, HZ);
 
+/*
+ * 在以下使用apic_enabled():
+ *   - arch/x86/kvm/lapic.c|1655| <<__apic_accept_irq>> if (unlikely(!apic_enabled(apic)))
+ *   - arch/x86/kvm/lapic.c|3388| <<apic_has_pending_timer>> if (apic_enabled(apic) && apic_lvt_enabled(apic, APIC_LVTT))
+ */
 static inline int apic_enabled(struct kvm_lapic *apic)
 {
+	/*
+	 * 在以下使用kvm_apic_sw_enabled():
+	 *   - arch/x86/kvm/irq_comm.c|95| <<kvm_irq_delivery_to_apic>> } else if (kvm_apic_sw_enabled(vcpu->arch.apic)) {
+	 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+	 *   - arch/x86/kvm/lapic.c|424| <<kvm_recalculate_apic_map>> if (!kvm_apic_sw_enabled(apic))
+	 *   - arch/x86/kvm/lapic.c|2720| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+	 *   - arch/x86/kvm/lapic.c|2731| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+	 *   - arch/x86/kvm/lapic.h|251| <<kvm_lapic_enabled>> return kvm_apic_present(vcpu) && kvm_apic_sw_enabled(vcpu->arch.apic);
+	 *
+	 * 在以下调用kvm_apic_hw_enabled():
+	 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+	 *   - arch/x86/kvm/lapic.c|2040| <<apic_mmio_read>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2125| <<lapic_timer_int_injected>> if (kvm_apic_hw_enabled(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2809| <<apic_mmio_write>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|3330| <<kvm_apic_local_deliver>> if (kvm_apic_hw_enabled(apic) && !(reg & APIC_LVT_MASKED)) {
+	 *   - arch/x86/kvm/lapic.c|3443| <<kvm_apic_accept_pic_intr>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 *   - arch/x86/kvm/lapic.h|246| <<kvm_apic_present>> return lapic_in_kernel(vcpu) && kvm_apic_hw_enabled(vcpu->arch.apic);
+	 *   - arch/x86/kvm/x86.c|10218| <<vcpu_load_eoi_exitmap>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 */
 	return kvm_apic_sw_enabled(apic) &&	kvm_apic_hw_enabled(apic);
 }
 
@@ -166,6 +287,11 @@ static bool kvm_use_posted_timer_interrupt(struct kvm_vcpu *vcpu)
 	return kvm_can_post_timer_interrupt(vcpu) && vcpu->mode == IN_GUEST_MODE;
 }
 
+/*
+ * 在以下使用kvm_apic_map_get_logical_dest():
+ *   - arch/x86/kvm/lapic.c|610| <<kvm_recalculate_apic_map>> if (!kvm_apic_map_get_logical_dest(new, ldr, &cluster, &mask))
+ *   - arch/x86/kvm/lapic.c|1825| <<kvm_apic_map_get_dest_lapic>> if (!kvm_apic_map_get_logical_dest(map, irq->dest_id, dst, (u16 *)bitmap))
+ */
 static inline bool kvm_apic_map_get_logical_dest(struct kvm_apic_map *map,
 		u32 dest_id, struct kvm_lapic ***cluster, u16 *mask) {
 	switch (map->mode) {
@@ -181,6 +307,18 @@ static inline bool kvm_apic_map_get_logical_dest(struct kvm_apic_map *map,
 			cluster_size = min(max_apic_id - offset + 1, 16U);
 
 			offset = array_index_nospec(offset, map->max_apic_id + 1);
+			/*
+			 * 在以下使用kvm_apic_map->phys_map[]:
+			 *   - arch/x86/kvm/lapic.c|289| <<kvm_apic_map_get_logical_dest>> *cluster = &map->phys_map[offset];
+			 *   - arch/x86/kvm/lapic.c|534| <<kvm_recalculate_apic_map>> new->phys_map[x2apic_id] = apic;
+			 *   - arch/x86/kvm/lapic.c|539| <<kvm_recalculate_apic_map>> if (!apic_x2apic_mode(apic) && !new->phys_map[xapic_id])
+			 *   - arch/x86/kvm/lapic.c|540| <<kvm_recalculate_apic_map>> new->phys_map[xapic_id] = apic;
+			 *   - arch/x86/kvm/lapic.c|1287| <<__pv_send_ipi>> if (map->phys_map[min + i]) {
+			 *   - arch/x86/kvm/lapic.c|1288| <<__pv_send_ipi>> vcpu = map->phys_map[min + i]->vcpu;
+			 *   - arch/x86/kvm/lapic.c|1738| <<kvm_apic_map_get_dest_lapic>> *dst = &map->phys_map[dest_id];
+			 *   - arch/x86/kvm/x86.c|9433| <<kvm_sched_yield>> if (likely(map) && dest_id <= map->max_apic_id && map->phys_map[dest_id])
+			 *   - arch/x86/kvm/x86.c|9434| <<kvm_sched_yield>> target = map->phys_map[dest_id]->vcpu;
+			 */
 			*cluster = &map->phys_map[offset];
 			*mask = dest_id & (0xffff >> (16 - cluster_size));
 		} else {
@@ -222,6 +360,82 @@ enum {
 	DIRTY
 };
 
+/*
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_vcpu_reset
+ * kvm_apic_accept_events
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_lapic_reg_write
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ *
+ * 根据测试online/offline不会调用
+ * hot-remove cpu不会调用
+ * hot-add cpu会调用3次.
+ *
+ * kvm_recalculate_apic_map+0x1'
+ * kvm_set_apic_base+0xbe'
+ * vmx_set_msr+0x5f4'
+ * __kvm_set_msr+0x9d'
+ * kvm_arch_vcpu_ioctl+0xa20'
+ * kvm_vcpu_ioctl+0x552'
+ * __x64_sys_ioctl+0x8f'
+ * do_syscall_64+0x35'
+ * entry_SYSCALL_64_after_hwframe+0x6e'
+ *
+ * kvm_recalculate_apic_map+0x1'
+ * kvm_set_apic_base+0xbe'
+ * __set_sregs_common.constprop.0+0x165'
+ * kvm_arch_vcpu_ioctl+0x908'
+ * kvm_vcpu_ioctl+0x552'
+ * __x64_sys_ioctl+0x8f'
+ * do_syscall_64+0x35'
+ * entry_SYSCALL_64_after_hwframe+0x6e'
+ *
+ * kvm_recalculate_apic_map+0x1'
+ * kvm_set_apic_base+0xbe'
+ * vmx_set_msr+0x5f4'
+ * __kvm_set_msr+0x9d'
+ * kvm_emulate_wrmsr+0x38'
+ * vmx_handle_exit+0xe'
+ * vcpu_enter_guest+0x86f'
+ * vcpu_run+0x4e'
+ * kvm_arch_vcpu_ioctl_run+0xc8'
+ * kvm_vcpu_ioctl+0x2a8'
+ * __x64_sys_ioctl+0x8f'
+ * do_syscall_64+0x35'
+ * entry_SYSCALL_64_after_hwframe+0x6e'
+ *
+ *
+ * 在以下调用kvm_recalculate_apic_map():
+ *   - arch/x86/kvm/lapic.c|2441| <<kvm_lapic_reg_write>> kvm_recalculate_apic_map(apic->vcpu->kvm);
+ *   - arch/x86/kvm/lapic.c|2718| <<kvm_lapic_reset>> kvm_recalculate_apic_map(vcpu->kvm);
+ *   - arch/x86/kvm/lapic.c|2995| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+ *   - arch/x86/kvm/lapic.c|3001| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+ *   - arch/x86/kvm/x86.c|493| <<kvm_set_apic_base>> kvm_recalculate_apic_map(vcpu->kvm);
+ */
 void kvm_recalculate_apic_map(struct kvm *kvm)
 {
 	struct kvm_apic_map *new, *old = NULL;
@@ -230,6 +444,21 @@ void kvm_recalculate_apic_map(struct kvm *kvm)
 	u32 max_id = 255; /* enough space for any xAPIC ID */
 	bool xapic_id_mismatch = false;
 
+	/*
+	 * 在以下使用kvm_arch->apic_map_dirty:
+	 *   - arch/x86/kvm/lapic.c|279| <<kvm_recalculate_apic_map>> if (atomic_read_acquire(&kvm->arch.apic_map_dirty) == CLEAN)
+	 *   - arch/x86/kvm/lapic.c|290| <<kvm_recalculate_apic_map>> if (atomic_cmpxchg_acquire(&kvm->arch.apic_map_dirty,
+	 *                                  DIRTY, UPDATE_IN_PROGRESS) == CLEAN) {
+	 *   - arch/x86/kvm/lapic.c|378| <<kvm_recalculate_apic_map>> atomic_cmpxchg_release(&kvm->arch.apic_map_dirty,
+	 *                                  UPDATE_IN_PROGRESS, CLEAN);
+	 *   - arch/x86/kvm/lapic.c|401| <<apic_set_spiv>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|441| <<kvm_apic_set_xapic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|447| <<kvm_apic_set_ldr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|453| <<kvm_apic_set_dfr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|496| <<kvm_apic_set_x2apic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|2862| <<kvm_lapic_set_base>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|3370| <<kvm_apic_set_state>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 */
 	/* Read kvm->arch.apic_map_dirty before kvm->arch.apic_map.  */
 	if (atomic_read_acquire(&kvm->arch.apic_map_dirty) == CLEAN)
 		return;
@@ -237,6 +466,15 @@ void kvm_recalculate_apic_map(struct kvm *kvm)
 	WARN_ONCE(!irqchip_in_kernel(kvm),
 		  "Dirty APIC map without an in-kernel local APIC");
 
+	/*
+	 * 在以下使用kvm_arch->apic_map_lock:
+	 *   - arch/x86/kvm/lapic.c|375| <<kvm_recalculate_apic_map>> mutex_lock(&kvm->arch.apic_map_lock);
+	 *   - arch/x86/kvm/lapic.c|383| <<kvm_recalculate_apic_map>> mutex_unlock(&kvm->arch.apic_map_lock);
+	 *   - arch/x86/kvm/lapic.c|506| <<kvm_recalculate_apic_map>> old = rcu_dereference_protected(kvm->arch.apic_map,
+	 *                                     lockdep_is_held(&kvm->arch.apic_map_lock));
+	 *   - arch/x86/kvm/lapic.c|514| <<kvm_recalculate_apic_map>> mutex_unlock(&kvm->arch.apic_map_lock);
+	 *   - arch/x86/kvm/x86.c|12397| <<kvm_arch_init_vm>> mutex_init(&kvm->arch.apic_map_lock);
+	 */
 	mutex_lock(&kvm->arch.apic_map_lock);
 	/*
 	 * Read kvm->arch.apic_map_dirty before kvm->arch.apic_map
@@ -249,10 +487,16 @@ void kvm_recalculate_apic_map(struct kvm *kvm)
 		return;
 	}
 
+	/*
+	 * apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE;
+	 */
 	kvm_for_each_vcpu(i, vcpu, kvm)
 		if (kvm_apic_present(vcpu))
 			max_id = max(max_id, kvm_x2apic_id(vcpu->arch.apic));
 
+	/*
+	 * 全都初始化为0
+	 */
 	new = kvzalloc(sizeof(struct kvm_apic_map) +
 	                   sizeof(struct kvm_lapic *) * ((u64)max_id + 1),
 			   GFP_KERNEL_ACCOUNT);
@@ -270,12 +514,47 @@ void kvm_recalculate_apic_map(struct kvm *kvm)
 		u8 xapic_id;
 		u32 x2apic_id;
 
+		/*
+		 * apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE;
+		 */
 		if (!kvm_apic_present(vcpu))
 			continue;
 
+		/*
+		 * 在以下使用kvm_apic_set_xapic_id():
+		 *   - arch/x86/kvm/lapic.c|2455| <<kvm_lapic_reg_write(APIC_ID)>> kvm_apic_set_xapic_id(apic, val >> 24);
+		 *   - arch/x86/kvm/lapic.c|2756| <<kvm_lapic_set_base>> kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
+		 *   - arch/x86/kvm/lapic.c|2871| <<kvm_lapic_reset>> kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
+		 *
+		 *
+		 * 返回: return kvm_lapic_get_reg(apic, APIC_ID) >> 24;
+		 */
 		xapic_id = kvm_xapic_id(apic);
+		/*
+		 * 返回: return apic->vcpu->vcpu_id;
+		 */
 		x2apic_id = kvm_x2apic_id(apic);
 
+		/*
+		 * 在以下设置kvm_vcpu_arch->apic_base (看似修改的地方):
+		 *   - arch/x86/kvm/lapic.c|2926| <<kvm_lapic_set_base>> vcpu->arch.apic_base = value;
+		 *   - arch/x86/kvm/lapic.c|3256| <<kvm_create_lapic>> vcpu->arch.apic_base = MSR_IA32_APICBASE_ENABLE;
+		 * 在以下使用kvm_vcpu_arch->apic_base:
+		 *   - arch/x86/kvm/cpuid.c|222| <<__kvm_update_cpuid_runtime>> cpuid_entry_change(best, X86_FEATURE_APIC, vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE);
+		 *   - arch/x86/kvm/lapic.c|2862| <<kvm_free_lapic>> if (!(vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE))
+		 *   - arch/x86/kvm/lapic.c|2923| <<kvm_lapic_set_base>> u64 old_value = vcpu->arch.apic_base;
+		 *   - arch/x86/kvm/lapic.c|2974| <<kvm_lapic_set_base>> apic->base_address = apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_BASE;
+		 *   - arch/x86/kvm/lapic.c|3454| <<kvm_apic_set_state>> kvm_lapic_set_base(vcpu, vcpu->arch.apic_base);
+		 *   - arch/x86/kvm/lapic.h|231| <<kvm_apic_hw_enabled>> return apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE;
+		 *   - arch/x86/kvm/lapic.h|256| <<apic_x2apic_mode>> return apic->vcpu->arch.apic_base & X2APIC_ENABLE;
+		 *   - arch/x86/kvm/lapic.h|300| <<kvm_apic_mode>> return apic_base & (MSR_IA32_APICBASE_ENABLE | X2APIC_ENABLE);
+		 *   - arch/x86/kvm/vmx/nested.c|878| <<nested_vmx_msr_check_common>> if (CC(vcpu->arch.apic_base & X2APIC_ENABLE && e->index >> 8 == 0x8))
+		 *   - arch/x86/kvm/x86.c|466| <<kvm_get_apic_base>> return vcpu->arch.apic_base;
+		 *   - arch/x86/kvm/x86.c|12215| <<kvm_vcpu_is_bsp>> return (vcpu->arch.apic_base & MSR_IA32_APICBASE_BSP) != 0;
+		 *
+		 * 返回:
+		 * return apic->vcpu->arch.apic_base & X2APIC_ENABLE;
+		 */
 		/*
 		 * Deliberately truncate the vCPU ID when detecting a mismatched
 		 * APIC ID to avoid false positives if the vCPU ID, i.e. x2APIC
@@ -285,6 +564,23 @@ void kvm_recalculate_apic_map(struct kvm *kvm)
 		if (!apic_x2apic_mode(apic) && xapic_id != (u8)vcpu->vcpu_id)
 			xapic_id_mismatch = true;
 
+		/*
+		 * 在以下使用kvm_apic_map->phys_map[]:
+		 *   - arch/x86/kvm/lapic.c|289| <<kvm_apic_map_get_logical_dest>> *cluster = &map->phys_map[offset];
+		 *   - arch/x86/kvm/lapic.c|534| <<kvm_recalculate_apic_map>> new->phys_map[x2apic_id] = apic;
+		 *   - arch/x86/kvm/lapic.c|539| <<kvm_recalculate_apic_map>> if (!apic_x2apic_mode(apic) && !new->phys_map[xapic_id])
+		 *   - arch/x86/kvm/lapic.c|540| <<kvm_recalculate_apic_map>> new->phys_map[xapic_id] = apic;
+		 *   - arch/x86/kvm/lapic.c|1287| <<__pv_send_ipi>> if (map->phys_map[min + i]) {
+		 *   - arch/x86/kvm/lapic.c|1288| <<__pv_send_ipi>> vcpu = map->phys_map[min + i]->vcpu;
+		 *   - arch/x86/kvm/lapic.c|1738| <<kvm_apic_map_get_dest_lapic>> *dst = &map->phys_map[dest_id];
+		 *   - arch/x86/kvm/x86.c|9433| <<kvm_sched_yield>> if (likely(map) && dest_id <= map->max_apic_id && map->phys_map[dest_id])
+		 *   - arch/x86/kvm/x86.c|9434| <<kvm_sched_yield>> target = map->phys_map[dest_id]->vcpu;
+		 */
+
+		/*
+		 * 只要是符合x2apic可以无条件覆盖
+		 * 甚至可以覆盖xapic的
+		 */
 		/* Hotplug hack: see kvm_apic_match_physical_addr(), ... */
 		if ((apic_x2apic_mode(apic) || x2apic_id > 0xff) &&
 				x2apic_id <= new->max_apic_id)
@@ -293,15 +589,30 @@ void kvm_recalculate_apic_map(struct kvm *kvm)
 		 * ... xAPIC ID of VCPUs with APIC ID > 0xff will wrap-around,
 		 * prevent them from masking VCPUs with APIC ID <= 0xff.
 		 */
+		/*
+		 * 但是xapic的不能覆盖x2apic的
+		 */
 		if (!apic_x2apic_mode(apic) && !new->phys_map[xapic_id])
 			new->phys_map[xapic_id] = apic;
 
+		/*
+		 * 在以下使用kvm_apic_sw_enabled():
+		 *   - arch/x86/kvm/irq_comm.c|95| <<kvm_irq_delivery_to_apic>> } else if (kvm_apic_sw_enabled(vcpu->arch.apic)) {
+		 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+		 *   - arch/x86/kvm/lapic.c|424| <<kvm_recalculate_apic_map>> if (!kvm_apic_sw_enabled(apic))
+		 *   - arch/x86/kvm/lapic.c|2720| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+		 *   - arch/x86/kvm/lapic.c|2731| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+		 *   - arch/x86/kvm/lapic.h|251| <<kvm_lapic_enabled>> return kvm_apic_present(vcpu) && kvm_apic_sw_enabled(vcpu->arch.apic);
+		 */
 		if (!kvm_apic_sw_enabled(apic))
 			continue;
 
 		ldr = kvm_lapic_get_reg(apic, APIC_LDR);
 
 		if (apic_x2apic_mode(apic)) {
+			/*
+			 * struct kvm_apic_map *new, *old = NULL;
+			 */
 			new->mode |= KVM_APIC_MODE_X2APIC;
 		} else if (ldr) {
 			ldr = GET_APIC_LOGICAL_ID(ldr);
@@ -311,6 +622,11 @@ void kvm_recalculate_apic_map(struct kvm *kvm)
 				new->mode |= KVM_APIC_MODE_XAPIC_CLUSTER;
 		}
 
+		/*
+		 * 在以下使用kvm_apic_map_get_logical_dest():
+		 *   - arch/x86/kvm/lapic.c|610| <<kvm_recalculate_apic_map>> if (!kvm_apic_map_get_logical_dest(new, ldr, &cluster, &mask))
+		 *   - arch/x86/kvm/lapic.c|1825| <<kvm_apic_map_get_dest_lapic>> if (!kvm_apic_map_get_logical_dest(map, irq->dest_id, dst, (u16 *)bitmap))
+		 */
 		if (!kvm_apic_map_get_logical_dest(new, ldr, &cluster, &mask))
 			continue;
 
@@ -318,11 +634,25 @@ void kvm_recalculate_apic_map(struct kvm *kvm)
 			cluster[ffs(mask) - 1] = apic;
 	}
 out:
+	/*
+	 * 就在这一个地方修改APICV_INHIBIT_REASON_APIC_ID_MODIFIED
+	 */
 	if (xapic_id_mismatch)
 		kvm_set_apicv_inhibit(kvm, APICV_INHIBIT_REASON_APIC_ID_MODIFIED);
 	else
 		kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_APIC_ID_MODIFIED);
 
+	/*
+	 * 在以下使用kvm_arch->apic_map:
+	 *   - arch/x86/kvm/lapic.c|581| <<kvm_recalculate_apic_map>> old = rcu_dereference_protected(kvm->arch.apic_map,
+	 *   - arch/x86/kvm/lapic.c|583| <<kvm_recalculate_apic_map>> rcu_assign_pointer(kvm->arch.apic_map, new);
+	 *   - arch/x86/kvm/lapic.c|1305| <<kvm_pv_send_ipi>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1772| <<kvm_irq_delivery_to_apic_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1825| <<kvm_intr_is_single_vcpu_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|2023| <<kvm_bitmap_or_dest_vcpus>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|9391| <<kvm_sched_yield>> map = rcu_dereference(vcpu->kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|13061| <<kvm_arch_destroy_vm>> kvfree(rcu_dereference_check(kvm->arch.apic_map, 1));
+	 */
 	old = rcu_dereference_protected(kvm->arch.apic_map,
 			lockdep_is_held(&kvm->arch.apic_map_lock));
 	rcu_assign_pointer(kvm->arch.apic_map, new);
@@ -337,33 +667,130 @@ void kvm_recalculate_apic_map(struct kvm *kvm)
 	if (old)
 		call_rcu(&old->rcu, kvm_apic_map_free);
 
+	/*
+	 * 在以下使用kvm_make_scan_ioapic_request():
+	 *   - arch/x86/kvm/ioapic.c|485| <<kvm_arch_post_irq_ack_notifier_list_update>> kvm_make_scan_ioapic_request(kvm);
+	 *   - arch/x86/kvm/ioapic.c|578| <<ioapic_write_indirect>> kvm_make_scan_ioapic_request(ioapic->kvm);
+	 *   - arch/x86/kvm/ioapic.c|1011| <<kvm_set_ioapic>> kvm_make_scan_ioapic_request(kvm);
+	 *   - arch/x86/kvm/irq_comm.c|454| <<kvm_arch_post_irq_routing_update>> kvm_make_scan_ioapic_request(kvm);
+	 *   - arch/x86/kvm/lapic.c|347| <<kvm_recalculate_apic_map>> kvm_make_scan_ioapic_request(kvm);
+	 */
 	kvm_make_scan_ioapic_request(kvm);
 }
 
+/*
+ * 在以下调用apic_set_spiv():
+ *   - arch/x86/kvm/lapic.c|2786| <<kvm_lapic_reg_write(APIC_SPIV)>> apic_set_spiv(apic, val & mask);
+ *   - arch/x86/kvm/lapic.c|3389| <<kvm_lapic_reset>> apic_set_spiv(apic, 0xff);
+ *   - arch/x86/kvm/lapic.c|3817| <<kvm_apic_set_state>> apic_set_spiv(apic, *((u32 *)(s->regs + APIC_SPIV)));
+ */
 static inline void apic_set_spiv(struct kvm_lapic *apic, u32 val)
 {
 	bool enabled = val & APIC_SPIV_APIC_ENABLED;
 
 	kvm_lapic_set_reg(apic, APIC_SPIV, val);
 
+	/*
+	 * 在以下使用kvm_lapic->sw_enabled:
+	 *   - arch/x86/kvm/lapic.c|474| <<apic_set_spiv>> if (enabled != apic->sw_enabled) {
+	 *   - arch/x86/kvm/lapic.c|475| <<apic_set_spiv>> apic->sw_enabled = enabled;
+	 *   - arch/x86/kvm/lapic.c|2899| <<kvm_free_lapic>> if (!apic->sw_enabled)
+	 *   - arch/x86/kvm/lapic.h|260| <<kvm_apic_sw_enabled>> return apic->sw_enabled;
+	 */
 	if (enabled != apic->sw_enabled) {
 		apic->sw_enabled = enabled;
+		/*
+		 * 在以下使用apic_sw_disabled:
+		 *   - arch/x86/kvm/lapic.c|191| <<global>> __read_mostly DEFINE_STATIC_KEY_DEFERRED_FALSE(apic_sw_disabled, HZ);
+		 *   - arch/x86/kvm/lapic.c|599| <<apic_set_spiv>> static_branch_slow_dec_deferred(&apic_sw_disabled);
+		 *   - arch/x86/kvm/lapic.c|601| <<apic_set_spiv>> static_branch_inc(&apic_sw_disabled.key);
+		 *   - arch/x86/kvm/lapic.c|3263| <<kvm_free_lapic>> static_branch_slow_dec_deferred(&apic_sw_disabled);
+		 *   - arch/x86/kvm/lapic.c|3840| <<kvm_create_lapic>> static_branch_inc(&apic_sw_disabled.key);
+		 *   - arch/x86/kvm/lapic.c|4582| <<kvm_lapic_exit>> static_key_deferred_flush(&apic_sw_disabled);
+		 *   - arch/x86/kvm/lapic.c|4583| <<kvm_lapic_exit>> WARN_ON(static_branch_unlikely(&apic_sw_disabled.key));
+		 *   - arch/x86/kvm/lapic.h|315| <<kvm_apic_sw_enabled>> if (static_branch_unlikely(&apic_sw_disabled.key))
+		 */
 		if (enabled)
 			static_branch_slow_dec_deferred(&apic_sw_disabled);
 		else
 			static_branch_inc(&apic_sw_disabled.key);
 
+		/*
+		 * 在以下使用kvm_arch->apic_map_dirty:
+		 *   - arch/x86/kvm/lapic.c|279| <<kvm_recalculate_apic_map>> if (atomic_read_acquire(&kvm->arch.apic_map_dirty) == CLEAN)
+		 *   - arch/x86/kvm/lapic.c|290| <<kvm_recalculate_apic_map>> if (atomic_cmpxchg_acquire(&kvm->arch.apic_map_dirty,
+		 *   - arch/x86/kvm/lapic.c|378| <<kvm_recalculate_apic_map>> atomic_cmpxchg_release(&kvm->arch.apic_map_dirty,
+		 *   - arch/x86/kvm/lapic.c|401| <<apic_set_spiv>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+		 *   - arch/x86/kvm/lapic.c|441| <<kvm_apic_set_xapic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+		 *   - arch/x86/kvm/lapic.c|447| <<kvm_apic_set_ldr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+		 *   - arch/x86/kvm/lapic.c|453| <<kvm_apic_set_dfr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+		 *   - arch/x86/kvm/lapic.c|496| <<kvm_apic_set_x2apic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+		 *   - arch/x86/kvm/lapic.c|2862| <<kvm_lapic_set_base>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+		 *   - arch/x86/kvm/lapic.c|3370| <<kvm_apic_set_state>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+		 */
 		atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
 	}
 
+	/*
+	 * 在以下使用KVM_REQ_APF_READY:
+	 *   - arch/x86/kvm/lapic.c|621| <<apic_set_spiv>> kvm_make_request(KVM_REQ_APF_READY, apic->vcpu);
+	 *   - arch/x86/kvm/lapic.c|3303| <<kvm_lapic_set_base>> kvm_make_request(KVM_REQ_APF_READY, vcpu);
+	 *   - arch/x86/kvm/x86.c|13246| <<kvm_arch_async_page_present_queued>> kvm_make_request(KVM_REQ_APF_READY, vcpu);
+	 *
+	 * 处理的函数kvm_check_async_pf_completion()
+	 */
 	/* Check if there are APF page ready requests pending */
 	if (enabled)
 		kvm_make_request(KVM_REQ_APF_READY, apic->vcpu);
 }
 
+/*
+ * 在以下使用kvm_apic_set_xapic_id():
+ *   - arch/x86/kvm/lapic.c|2455| <<kvm_lapic_reg_write(APIC_ID)>> kvm_apic_set_xapic_id(apic, val >> 24);
+ *   - arch/x86/kvm/lapic.c|2756| <<kvm_lapic_set_base>> kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
+ *   - arch/x86/kvm/lapic.c|2871| <<kvm_lapic_reset>> kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
+ *
+ * 其实kvm_apic_set_state()也会修改APIC_ID
+ */
 static inline void kvm_apic_set_xapic_id(struct kvm_lapic *apic, u8 id)
 {
+	/*
+	 * 在以下使用APIC_ID:
+	 *   - arch/x86/kvm/svm/svm.c|119| <<global>> { .index = X2APIC_MSR(APIC_ID), .always = false },
+	 *   - arch/x86/include/asm/apic.h|204| <<native_apic_msr_write>> if (reg == APIC_DFR || reg == APIC_ID || reg == APIC_LDR ||
+	 *   - arch/x86/include/asm/apic.h|487| <<read_apic_id>> unsigned int reg = apic_read(APIC_ID);
+	 *   - arch/x86/kernel/apic/apic.c|1797| <<setup_nox2apic>> int apicid = native_apic_msr_read(APIC_ID);
+	 *   - arch/x86/kernel/apic/apic.c|2586| <<apic_bsp_up_setup>> apic_write(APIC_ID, apic->set_apic_id(boot_cpu_physical_apicid));
+	 *   - arch/x86/kernel/apic/apic.c|2668| <<lapic_suspend>> apic_pm_state.apic_id = apic_read(APIC_ID);
+	 *   - arch/x86/kernel/apic/apic.c|2745| <<lapic_resume>> apic_write(APIC_ID, apic_pm_state.apic_id);
+	 *   - arch/x86/kernel/apic/apic_flat_64.c|91| <<read_xapic_id>> return flat_get_apic_id(apic_read(APIC_ID));
+	 *   - arch/x86/kernel/apic/vector.c|1157| <<print_local_APIC>> v = apic_read(APIC_ID);
+	 *   - arch/x86/kernel/apic/x2apic_uv_x.c|811| <<uv_read_apic_id>> return x2apic_get_apic_id(apic_read(APIC_ID));
+	 *   - arch/x86/kernel/smpboot.c|689| <<__inquire_remote_apic>> unsigned i, regs[] = { APIC_ID >> 4, APIC_LVR >> 4, APIC_SPIV >> 4 };
+	 *   - arch/x86/kvm/lapic.c|381| <<kvm_apic_set_xapic_id>> kvm_lapic_set_reg(apic, APIC_ID, id << 24);
+	 *   - arch/x86/kvm/lapic.c|408| <<kvm_apic_set_x2apic_id>> kvm_lapic_set_reg(apic, APIC_ID, id);
+	 *   - arch/x86/kvm/lapic.c|1762| <<kvm_lapic_reg_read>> APIC_REG_MASK(APIC_ID) |
+	 *   - arch/x86/kvm/lapic.c|2393| <<kvm_lapic_reg_write>> case APIC_ID:
+	 *   - arch/x86/kvm/lapic.c|3094| <<kvm_apic_state_fixup>> u32 *id = (u32 *)(s->regs + APIC_ID);
+	 *   - arch/x86/kvm/lapic.h|305| <<kvm_xapic_id>> return kvm_lapic_get_reg(apic, APIC_ID) >> 24;
+	 *   - arch/x86/kvm/svm/avic.c|675| <<is_avic_unaccelerated_access_trap>> case APIC_ID:
+	 *   - arch/x86/xen/apic.c|63| <<xen_apic_read>> if (reg != APIC_ID)
+	 *   - tools/testing/selftests/kvm/x86_64/xapic_ipi_test.c|100| <<halter_guest_code>> data->halter_apic_id = GET_APIC_ID_FIELD(xapic_read_reg(APIC_ID));
+	 */
 	kvm_lapic_set_reg(apic, APIC_ID, id << 24);
+	/*
+	 * 在以下使用kvm_arch->apic_map_dirty:
+	 *   - arch/x86/kvm/lapic.c|279| <<kvm_recalculate_apic_map>> if (atomic_read_acquire(&kvm->arch.apic_map_dirty) == CLEAN)
+	 *   - arch/x86/kvm/lapic.c|290| <<kvm_recalculate_apic_map>> if (atomic_cmpxchg_acquire(&kvm->arch.apic_map_dirty,
+	 *   - arch/x86/kvm/lapic.c|378| <<kvm_recalculate_apic_map>> atomic_cmpxchg_release(&kvm->arch.apic_map_dirty,
+	 *   - arch/x86/kvm/lapic.c|401| <<apic_set_spiv>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|441| <<kvm_apic_set_xapic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|447| <<kvm_apic_set_ldr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|453| <<kvm_apic_set_dfr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|496| <<kvm_apic_set_x2apic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|2862| <<kvm_lapic_set_base>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|3370| <<kvm_apic_set_state>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 */
 	atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
 }
 
@@ -384,14 +811,54 @@ static inline u32 kvm_apic_calc_x2apic_ldr(u32 id)
 	return ((id >> 4) << 16) | (1 << (id & 0xf));
 }
 
+/*
+ * 只在此处使用kvm_apic_set_x2apic_id():
+ *   - arch/x86/kvm/lapic.c|2767| <<kvm_lapic_set_base>> kvm_apic_set_x2apic_id(apic, vcpu->vcpu_id);
+ */
 static inline void kvm_apic_set_x2apic_id(struct kvm_lapic *apic, u32 id)
 {
 	u32 ldr = kvm_apic_calc_x2apic_ldr(id);
 
 	WARN_ON_ONCE(id != apic->vcpu->vcpu_id);
 
+	/*
+	 * 在以下使用APIC_ID:
+	 *   - arch/x86/kvm/svm/svm.c|119| <<global>> { .index = X2APIC_MSR(APIC_ID), .always = false },
+	 *   - arch/x86/include/asm/apic.h|204| <<native_apic_msr_write>> if (reg == APIC_DFR || reg == APIC_ID || reg == APIC_LDR ||
+	 *   - arch/x86/include/asm/apic.h|487| <<read_apic_id>> unsigned int reg = apic_read(APIC_ID);
+	 *   - arch/x86/kernel/apic/apic.c|1797| <<setup_nox2apic>> int apicid = native_apic_msr_read(APIC_ID);
+	 *   - arch/x86/kernel/apic/apic.c|2586| <<apic_bsp_up_setup>> apic_write(APIC_ID, apic->set_apic_id(boot_cpu_physical_apicid));
+	 *   - arch/x86/kernel/apic/apic.c|2668| <<lapic_suspend>> apic_pm_state.apic_id = apic_read(APIC_ID);
+	 *   - arch/x86/kernel/apic/apic.c|2745| <<lapic_resume>> apic_write(APIC_ID, apic_pm_state.apic_id);
+	 *   - arch/x86/kernel/apic/apic_flat_64.c|91| <<read_xapic_id>> return flat_get_apic_id(apic_read(APIC_ID));
+	 *   - arch/x86/kernel/apic/vector.c|1157| <<print_local_APIC>> v = apic_read(APIC_ID);
+	 *   - arch/x86/kernel/apic/x2apic_uv_x.c|811| <<uv_read_apic_id>> return x2apic_get_apic_id(apic_read(APIC_ID));
+	 *   - arch/x86/kernel/smpboot.c|689| <<__inquire_remote_apic>> unsigned i, regs[] = { APIC_ID >> 4, APIC_LVR >> 4, APIC_SPIV >> 4 };
+	 *   - arch/x86/kvm/lapic.c|381| <<kvm_apic_set_xapic_id>> kvm_lapic_set_reg(apic, APIC_ID, id << 24);
+	 *   - arch/x86/kvm/lapic.c|408| <<kvm_apic_set_x2apic_id>> kvm_lapic_set_reg(apic, APIC_ID, id);
+	 *   - arch/x86/kvm/lapic.c|1762| <<kvm_lapic_reg_read>> APIC_REG_MASK(APIC_ID) |
+	 *   - arch/x86/kvm/lapic.c|2393| <<kvm_lapic_reg_write>> case APIC_ID:
+	 *   - arch/x86/kvm/lapic.c|3094| <<kvm_apic_state_fixup>> u32 *id = (u32 *)(s->regs + APIC_ID);
+	 *   - arch/x86/kvm/lapic.h|305| <<kvm_xapic_id>> return kvm_lapic_get_reg(apic, APIC_ID) >> 24;
+	 *   - arch/x86/kvm/svm/avic.c|675| <<is_avic_unaccelerated_access_trap>> case APIC_ID:
+	 *   - arch/x86/xen/apic.c|63| <<xen_apic_read>> if (reg != APIC_ID)
+	 *   - tools/testing/selftests/kvm/x86_64/xapic_ipi_test.c|100| <<halter_guest_code>> data->halter_apic_id = GET_APIC_ID_FIELD(xapic_read_reg(APIC_ID));
+	 */
 	kvm_lapic_set_reg(apic, APIC_ID, id);
 	kvm_lapic_set_reg(apic, APIC_LDR, ldr);
+	/*
+	 * 在以下使用kvm_arch->apic_map_dirty:
+	 *   - arch/x86/kvm/lapic.c|279| <<kvm_recalculate_apic_map>> if (atomic_read_acquire(&kvm->arch.apic_map_dirty) == CLEAN)
+	 *   - arch/x86/kvm/lapic.c|290| <<kvm_recalculate_apic_map>> if (atomic_cmpxchg_acquire(&kvm->arch.apic_map_dirty,
+	 *   - arch/x86/kvm/lapic.c|378| <<kvm_recalculate_apic_map>> atomic_cmpxchg_release(&kvm->arch.apic_map_dirty,
+	 *   - arch/x86/kvm/lapic.c|401| <<apic_set_spiv>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|441| <<kvm_apic_set_xapic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|447| <<kvm_apic_set_ldr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|453| <<kvm_apic_set_dfr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|496| <<kvm_apic_set_x2apic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|2862| <<kvm_lapic_set_base>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|3370| <<kvm_apic_set_state>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 */
 	atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
 }
 
@@ -464,6 +931,10 @@ static int find_highest_vector(void *bitmap)
 	return -1;
 }
 
+/*
+ * 在以下使用count_vectors():
+ *   - arch/x86/kvm/lapic.c|3854| <<kvm_apic_update_apicv>> apic->isr_count = count_vectors(apic->regs + APIC_ISR);
+ */
 static u8 count_vectors(void *bitmap)
 {
 	int vec;
@@ -478,6 +949,15 @@ static u8 count_vectors(void *bitmap)
 	return count;
 }
 
+/*
+ * 在以下使用__kvm_apic_update_irr():
+ *   - arch/x86/kvm/lapic.c|527| <<kvm_apic_update_irr>> bool irr_updated = __kvm_apic_update_irr(pir, apic->regs, max_irr);
+ *   - arch/x86/kvm/vmx/nested.c|3832| <<vmx_complete_nested_posted_interrupt>> __kvm_apic_update_irr(vmx->nested.pi_desc->pir,
+ *
+ * vmx_sync_pir_to_irr()
+ * -> kvm_apic_update_irr()
+ *    -> __kvm_apic_update_irr()
+ */
 bool __kvm_apic_update_irr(u32 *pir, void *regs, int *max_irr)
 {
 	u32 i, vec;
@@ -514,11 +994,43 @@ bool __kvm_apic_update_irr(u32 *pir, void *regs, int *max_irr)
 }
 EXPORT_SYMBOL_GPL(__kvm_apic_update_irr);
 
+/*
+ * 只在以下调用kvm_apic_update_irr():
+ *   - arch/x86/kvm/vmx/vmx.c|6490| <<vmx_sync_pir_to_irr>> kvm_apic_update_irr(vcpu, vmx->pi_desc.pir, &max_irr);
+ *
+ * vmx_sync_pir_to_irr()
+ * -> kvm_apic_update_irr()
+ *    -> __kvm_apic_update_irr()
+ */
 bool kvm_apic_update_irr(struct kvm_vcpu *vcpu, u32 *pir, int *max_irr)
 {
 	struct kvm_lapic *apic = vcpu->arch.apic;
+	/*
+	 * 在以下使用__kvm_apic_update_irr():
+	 *   - arch/x86/kvm/lapic.c|527| <<kvm_apic_update_irr>> bool irr_updated = __kvm_apic_update_irr(pir, apic->regs, max_irr);
+	 *   - arch/x86/kvm/vmx/nested.c|3832| <<vmx_complete_nested_posted_interrupt>> __kvm_apic_update_irr(vmx->nested.pi_desc->pir,
+	 *
+	 * vmx_sync_pir_to_irr()
+	 * -> kvm_apic_update_irr()
+	 *    -> __kvm_apic_update_irr()
+	 */
 	bool irr_updated = __kvm_apic_update_irr(pir, apic->regs, max_irr);
 
+	/*
+	 * 在以下使用kvm_lapic->irr_pending:
+	 *   - arch/x86/kvm/lapic.c|530| <<kvm_apic_update_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|548| <<apic_find_highest_irr>> if (!apic->irr_pending)
+	 *   - arch/x86/kvm/lapic.c|569| <<apic_clear_irr>> apic->irr_pending = false;
+	 *   - arch/x86/kvm/lapic.c|572| <<apic_clear_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|2519| <<kvm_apic_update_apicv>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|2968| <<apic_sync_pv_eoi_to_guest>> apic->irr_pending ||
+	 *   - arch/x86/kvm/lapic.h|154| <<kvm_lapic_set_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/svm/avic.c|434| <<avic_kick_target_vcpus_fast>> target_vcpu->arch.apic->irr_pending = true;
+	 *   - arch/x86/kvm/svm/avic.c|482| <<avic_kick_target_vcpus>> vcpu->arch.apic->irr_pending = true;
+	 *
+	 * 理论上来说:
+	 * irr_pending is always true when apicv is activated.
+	 */
 	if (unlikely(!vcpu->arch.apicv_active && irr_updated))
 		apic->irr_pending = true;
 	return irr_updated;
@@ -534,6 +1046,21 @@ static inline int apic_find_highest_irr(struct kvm_lapic *apic)
 {
 	int result;
 
+	/*
+	 * 在以下使用kvm_lapic->irr_pending:
+	 *   - arch/x86/kvm/lapic.c|530| <<kvm_apic_update_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|548| <<apic_find_highest_irr>> if (!apic->irr_pending)
+	 *   - arch/x86/kvm/lapic.c|569| <<apic_clear_irr>> apic->irr_pending = false;
+	 *   - arch/x86/kvm/lapic.c|572| <<apic_clear_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|2519| <<kvm_apic_update_apicv>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|2968| <<apic_sync_pv_eoi_to_guest>> apic->irr_pending ||
+	 *   - arch/x86/kvm/lapic.h|154| <<kvm_lapic_set_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/svm/avic.c|434| <<avic_kick_target_vcpus_fast>> target_vcpu->arch.apic->irr_pending = true;
+	 *   - arch/x86/kvm/svm/avic.c|482| <<avic_kick_target_vcpus>> vcpu->arch.apic->irr_pending = true;
+	 *
+	 * 理论上来说:
+	 * irr_pending is always true when apicv is activated.
+	 */
 	/*
 	 * Note that irr_pending is just a hint. It will be always
 	 * true with virtual interrupt delivery enabled.
@@ -559,6 +1086,21 @@ static inline void apic_clear_irr(int vec, struct kvm_lapic *apic)
 		static_call(kvm_x86_hwapic_irr_update)(vcpu,
 				apic_find_highest_irr(apic));
 	} else {
+		/*
+		 * 在以下使用kvm_lapic->irr_pending:
+		 *   - arch/x86/kvm/lapic.c|530| <<kvm_apic_update_irr>> apic->irr_pending = true;
+		 *   - arch/x86/kvm/lapic.c|548| <<apic_find_highest_irr>> if (!apic->irr_pending)
+		 *   - arch/x86/kvm/lapic.c|569| <<apic_clear_irr>> apic->irr_pending = false;
+		 *   - arch/x86/kvm/lapic.c|572| <<apic_clear_irr>> apic->irr_pending = true;
+		 *   - arch/x86/kvm/lapic.c|2519| <<kvm_apic_update_apicv>> apic->irr_pending = true;
+		 *   - arch/x86/kvm/lapic.c|2968| <<apic_sync_pv_eoi_to_guest>> apic->irr_pending ||
+		 *   - arch/x86/kvm/lapic.h|154| <<kvm_lapic_set_irr>> apic->irr_pending = true;
+		 *   - arch/x86/kvm/svm/avic.c|434| <<avic_kick_target_vcpus_fast>> target_vcpu->arch.apic->irr_pending = true;
+		 *   - arch/x86/kvm/svm/avic.c|482| <<avic_kick_target_vcpus>> vcpu->arch.apic->irr_pending = true;
+		 *
+		 * 理论上来说:
+		 * irr_pending is always true when apicv is activated.
+		 */
 		apic->irr_pending = false;
 		kvm_lapic_clear_vector(vec, apic->regs + APIC_IRR);
 		if (apic_search_irr(apic) != -1)
@@ -572,6 +1114,16 @@ void kvm_apic_clear_irr(struct kvm_vcpu *vcpu, int vec)
 }
 EXPORT_SYMBOL_GPL(kvm_apic_clear_irr);
 
+/*
+ * 只在以下调用apic_set_isr():
+ *   - arch/x86/kvm/lapic.c|2870| <<kvm_get_apic_interrupt>> apic_set_isr(vector, apic);
+ *
+ * vcpu_enter_guest()
+ * -> inject_pending_event()
+ *    -> kvm_cpu_get_interrupt()
+ *       -> kvm_get_apic_interrupt()
+ *          -> apic_set_isr()
+ */
 static inline void apic_set_isr(int vec, struct kvm_lapic *apic)
 {
 	struct kvm_vcpu *vcpu;
@@ -586,11 +1138,40 @@ static inline void apic_set_isr(int vec, struct kvm_lapic *apic)
 	 * because the processor can modify ISR under the hood.  Instead
 	 * just set SVI.
 	 */
+	/*
+	 * 在以下调用kvm_x86_hwapic_isr_update:
+	 *   - arch/x86/kvm/lapic.c|1003| <<apic_set_isr>> static_call(kvm_x86_hwapic_isr_update)(vcpu, vec);
+	 *   - arch/x86/kvm/lapic.c|1129| <<apic_clear_isr>> static_call(kvm_x86_hwapic_isr_update)(vcpu, apic_find_highest_isr(apic));
+	 *   - arch/x86/kvm/lapic.c|3622| <<kvm_lapic_reset>> static_call(kvm_x86_hwapic_isr_update)(vcpu, -1);
+	 *   - arch/x86/kvm/lapic.c|4127| <<kvm_apic_set_state>> static_call(kvm_x86_hwapic_isr_update)(vcpu, apic_find_highest_isr(apic));
+	 *
+	 * vmx_hwapic_isr_update()
+	 */
 	if (unlikely(vcpu->arch.apicv_active))
 		static_call(kvm_x86_hwapic_isr_update)(vcpu, vec);
 	else {
+		/*
+		 * 在以下使用kvm_lapic->isr_count:
+		 *   - arch/x86/kvm/lapic.c|657| <<apic_set_isr>> ++apic->isr_count;
+		 *   - arch/x86/kvm/lapic.c|658| <<apic_set_isr>> BUG_ON(apic->isr_count > MAX_APIC_VECTOR);
+		 *   - arch/x86/kvm/lapic.c|684| <<apic_find_highest_isr>> if (!apic->isr_count)
+		 *   - arch/x86/kvm/lapic.c|718| <<apic_clear_isr>> --apic->isr_count;
+		 *   - arch/x86/kvm/lapic.c|719| <<apic_clear_isr>> BUG_ON(apic->isr_count < 0);
+		 *   - arch/x86/kvm/lapic.c|2631| <<kvm_apic_update_apicv>> apic->isr_count = 1;
+		 *   - arch/x86/kvm/lapic.c|2639| <<kvm_apic_update_apicv>> apic->isr_count = count_vectors(apic->regs + APIC_ISR);
+		 */
 		++apic->isr_count;
 		BUG_ON(apic->isr_count > MAX_APIC_VECTOR);
+		/*
+		 * 在以下使用kvm_lapic->highest_isr_cache:
+		 *   - arch/x86/kvm/lapic.c|675| <<apic_set_isr>> apic->highest_isr_cache = vec;
+		 *   - arch/x86/kvm/lapic.c|697| <<apic_find_highest_isr>> if (likely(apic->highest_isr_cache != -1))
+		 *   - arch/x86/kvm/lapic.c|698| <<apic_find_highest_isr>> return apic->highest_isr_cache;
+		 *   - arch/x86/kvm/lapic.c|734| <<apic_clear_isr>> apic->highest_isr_cache = -1;
+		 *   - arch/x86/kvm/lapic.c|2669| <<kvm_apic_update_apicv>> apic->highest_isr_cache = -1;
+		 *   - arch/x86/kvm/lapic.c|3170| <<apic_sync_pv_eoi_to_guest>> apic->highest_isr_cache == -1 ||
+		 *   - arch/x86/kvm/lapic.c|3172| <<apic_sync_pv_eoi_to_guest>> kvm_ioapic_handles_vector(apic, apic->highest_isr_cache)) {
+		 */
 		/*
 		 * ISR (in service register) bit is set when injecting an interrupt.
 		 * The highest vector is injected. Thus the latest bit set matches
@@ -600,6 +1181,14 @@ static inline void apic_set_isr(int vec, struct kvm_lapic *apic)
 	}
 }
 
+/*
+ * 在以下调用apic_find_highest_isr():
+ *   - arch/x86/kvm/lapic.c|700| <<apic_clear_isr>> apic_find_highest_isr(apic));
+ *   - arch/x86/kvm/lapic.c|858| <<__apic_update_ppr>> isr = apic_find_highest_isr(apic);
+ *   - arch/x86/kvm/lapic.c|1486| <<apic_set_eoi>> int vector = apic_find_highest_isr(apic);
+ *   - arch/x86/kvm/lapic.c|2963| <<kvm_apic_set_state>> apic_find_highest_isr(apic));
+ *   - arch/x86/kvm/lapic.c|3097| <<kvm_lapic_sync_to_vapic>> max_isr = apic_find_highest_isr(apic);
+ */
 static inline int apic_find_highest_isr(struct kvm_lapic *apic)
 {
 	int result;
@@ -608,8 +1197,28 @@ static inline int apic_find_highest_isr(struct kvm_lapic *apic)
 	 * Note that isr_count is always 1, and highest_isr_cache
 	 * is always -1, with APIC virtualization enabled.
 	 */
+	/*
+	 * 在以下使用kvm_lapic->isr_count:
+	 *   - arch/x86/kvm/lapic.c|657| <<apic_set_isr>> ++apic->isr_count;
+	 *   - arch/x86/kvm/lapic.c|658| <<apic_set_isr>> BUG_ON(apic->isr_count > MAX_APIC_VECTOR);
+	 *   - arch/x86/kvm/lapic.c|684| <<apic_find_highest_isr>> if (!apic->isr_count)
+	 *   - arch/x86/kvm/lapic.c|718| <<apic_clear_isr>> --apic->isr_count;
+	 *   - arch/x86/kvm/lapic.c|719| <<apic_clear_isr>> BUG_ON(apic->isr_count < 0);
+	 *   - arch/x86/kvm/lapic.c|2631| <<kvm_apic_update_apicv>> apic->isr_count = 1;
+	 *   - arch/x86/kvm/lapic.c|2639| <<kvm_apic_update_apicv>> apic->isr_count = count_vectors(apic->regs + APIC_ISR);
+	 */
 	if (!apic->isr_count)
 		return -1;
+	/*
+	 * 在以下使用kvm_lapic->highest_isr_cache:
+	 *   - arch/x86/kvm/lapic.c|675| <<apic_set_isr>> apic->highest_isr_cache = vec;
+	 *   - arch/x86/kvm/lapic.c|697| <<apic_find_highest_isr>> if (likely(apic->highest_isr_cache != -1))
+	 *   - arch/x86/kvm/lapic.c|698| <<apic_find_highest_isr>> return apic->highest_isr_cache;
+	 *   - arch/x86/kvm/lapic.c|734| <<apic_clear_isr>> apic->highest_isr_cache = -1;
+	 *   - arch/x86/kvm/lapic.c|2669| <<kvm_apic_update_apicv>> apic->highest_isr_cache = -1;
+	 *   - arch/x86/kvm/lapic.c|3170| <<apic_sync_pv_eoi_to_guest>> apic->highest_isr_cache == -1 ||
+	 *   - arch/x86/kvm/lapic.c|3172| <<apic_sync_pv_eoi_to_guest>> kvm_ioapic_handles_vector(apic, apic->highest_isr_cache)) {
+	 */
 	if (likely(apic->highest_isr_cache != -1))
 		return apic->highest_isr_cache;
 
@@ -619,6 +1228,10 @@ static inline int apic_find_highest_isr(struct kvm_lapic *apic)
 	return result;
 }
 
+/*
+ * 在以下使用apic_clear_isr():
+ *   - arch/x86/kvm/lapic.c|1497| <<apic_set_eoi>> apic_clear_isr(vector, apic);
+ */
 static inline void apic_clear_isr(int vec, struct kvm_lapic *apic)
 {
 	struct kvm_vcpu *vcpu;
@@ -627,6 +1240,29 @@ static inline void apic_clear_isr(int vec, struct kvm_lapic *apic)
 
 	vcpu = apic->vcpu;
 
+	/*
+	 * 在以下设置kvm_vcpu_arch->apicv_active:
+	 *   - arch/x86/kvm/x86.c|9800| <<kvm_vcpu_update_apicv>> vcpu->arch.apicv_active = activate;
+	 *   - arch/x86/kvm/x86.c|11393| <<kvm_arch_vcpu_create>> vcpu->arch.apicv_active = true;
+	 * 在以下使用kvm_vcpu_arch->apicv_active:
+	 *   - arch/x86/kvm/lapic.c|553| <<kvm_apic_update_irr>> if (unlikely(!vcpu->arch.apicv_active && irr_updated))
+	 *   - arch/x86/kvm/lapic.c|602| <<apic_clear_irr>> if (unlikely(vcpu->arch.apicv_active)) {
+	 *   - arch/x86/kvm/lapic.c|654| <<apic_set_isr>> if (unlikely(vcpu->arch.apicv_active))
+	 *   - arch/x86/kvm/lapic.c|714| <<apic_clear_isr>> if (unlikely(vcpu->arch.apicv_active))
+	 *   - arch/x86/kvm/lapic.c|1827| <<lapic_timer_int_injected>> if (vcpu->arch.apicv_active)
+	 *   - arch/x86/kvm/lapic.c|1944| <<apic_timer_expired>> if (!from_timer_fn && vcpu->arch.apicv_active) {
+	 *   - arch/x86/kvm/lapic.c|2613| <<kvm_apic_update_apicv>> if (vcpu->arch.apicv_active) {
+	 *   - arch/x86/kvm/lapic.c|2703| <<kvm_lapic_reset>> if (vcpu->arch.apicv_active) {
+	 *   - arch/x86/kvm/lapic.c|3003| <<kvm_apic_set_state>> if (vcpu->arch.apicv_active) {
+	 *   - arch/x86/kvm/lapic.h|241| <<kvm_vcpu_apicv_active>> return vcpu->arch.apic && vcpu->arch.apicv_active;
+	 *   - arch/x86/kvm/svm/svm.c|3661| <<svm_complete_interrupt_delivery>> if (!READ_ONCE(vcpu->arch.apicv_active)) {
+	 *   - arch/x86/kvm/vmx/vmx.c|4114| <<vmx_deliver_posted_interrupt>> if (!vcpu->arch.apicv_active)
+	 *   - arch/x86/kvm/x86.c|9241| <<update_cr8_intercept>> if (vcpu->arch.apicv_active)
+	 *   - arch/x86/kvm/x86.c|9797| <<kvm_vcpu_update_apicv>> if (vcpu->arch.apicv_active == activate)
+	 *   - arch/x86/kvm/x86.c|9810| <<kvm_vcpu_update_apicv>> if (!vcpu->arch.apicv_active)
+	 *   - arch/x86/kvm/x86.c|12441| <<kvm_arch_dy_has_pending_interrupt>> if (vcpu->arch.apicv_active &&
+	 *          static_call(kvm_x86_dy_apicv_has_pending_interrupt)(vcpu))
+	 */
 	/*
 	 * We do get here for APIC virtualization enabled if the guest
 	 * uses the Hyper-V APIC enlightenment.  In this case we may need
@@ -634,16 +1270,50 @@ static inline void apic_clear_isr(int vec, struct kvm_lapic *apic)
 	 * on the other hand isr_count and highest_isr_cache are unused
 	 * and must be left alone.
 	 */
+	/*
+	 * 在以下调用kvm_x86_hwapic_isr_update:
+	 *   - arch/x86/kvm/lapic.c|1003| <<apic_set_isr>> static_call(kvm_x86_hwapic_isr_update)(vcpu, vec);
+	 *   - arch/x86/kvm/lapic.c|1129| <<apic_clear_isr>> static_call(kvm_x86_hwapic_isr_update)(vcpu, apic_find_highest_isr(apic));
+	 *   - arch/x86/kvm/lapic.c|3622| <<kvm_lapic_reset>> static_call(kvm_x86_hwapic_isr_update)(vcpu, -1);
+	 *   - arch/x86/kvm/lapic.c|4127| <<kvm_apic_set_state>> static_call(kvm_x86_hwapic_isr_update)(vcpu, apic_find_highest_isr(apic));
+	 *
+	 * vmx_hwapic_isr_update()
+	 */
 	if (unlikely(vcpu->arch.apicv_active))
 		static_call(kvm_x86_hwapic_isr_update)(vcpu,
 						apic_find_highest_isr(apic));
 	else {
+		/*
+		 * 在以下使用kvm_lapic->isr_count:
+		 *   - arch/x86/kvm/lapic.c|657| <<apic_set_isr>> ++apic->isr_count;
+		 *   - arch/x86/kvm/lapic.c|658| <<apic_set_isr>> BUG_ON(apic->isr_count > MAX_APIC_VECTOR);
+		 *   - arch/x86/kvm/lapic.c|684| <<apic_find_highest_isr>> if (!apic->isr_count)
+		 *   - arch/x86/kvm/lapic.c|718| <<apic_clear_isr>> --apic->isr_count;
+		 *   - arch/x86/kvm/lapic.c|719| <<apic_clear_isr>> BUG_ON(apic->isr_count < 0);
+		 *   - arch/x86/kvm/lapic.c|2631| <<kvm_apic_update_apicv>> apic->isr_count = 1;
+		 *   - arch/x86/kvm/lapic.c|2639| <<kvm_apic_update_apicv>> apic->isr_count = count_vectors(apic->regs + APIC_ISR);
+		 */
 		--apic->isr_count;
 		BUG_ON(apic->isr_count < 0);
+		/*
+		 * 在以下使用kvm_lapic->highest_isr_cache:
+		 *   - arch/x86/kvm/lapic.c|675| <<apic_set_isr>> apic->highest_isr_cache = vec;
+		 *   - arch/x86/kvm/lapic.c|697| <<apic_find_highest_isr>> if (likely(apic->highest_isr_cache != -1))
+		 *   - arch/x86/kvm/lapic.c|698| <<apic_find_highest_isr>> return apic->highest_isr_cache;
+		 *   - arch/x86/kvm/lapic.c|734| <<apic_clear_isr>> apic->highest_isr_cache = -1;
+		 *   - arch/x86/kvm/lapic.c|2669| <<kvm_apic_update_apicv>> apic->highest_isr_cache = -1;
+		 *   - arch/x86/kvm/lapic.c|3170| <<apic_sync_pv_eoi_to_guest>> apic->highest_isr_cache == -1 ||
+		 *   - arch/x86/kvm/lapic.c|3172| <<apic_sync_pv_eoi_to_guest>> kvm_ioapic_handles_vector(apic, apic->highest_isr_cache)) {
+		 */
 		apic->highest_isr_cache = -1;
 	}
 }
 
+/*
+ * 在以下使用kvm_lapic_find_highest_irr():
+ *   - arch/x86/kvm/vmx/vmx.c|6502| <<vmx_sync_pir_to_irr>> max_irr = kvm_lapic_find_highest_irr(vcpu);
+ *   - arch/x86/kvm/x86.c|9245| <<update_cr8_intercept>> max_irr = kvm_lapic_find_highest_irr(vcpu);
+ */
 int kvm_lapic_find_highest_irr(struct kvm_vcpu *vcpu)
 {
 	/* This may race with setting of irr in __apic_accept_irq() and
@@ -659,11 +1329,29 @@ static int __apic_accept_irq(struct kvm_lapic *apic, int delivery_mode,
 			     int vector, int level, int trig_mode,
 			     struct dest_map *dest_map);
 
+/*
+ * 在以下使用kvm_apic_set_irq():
+ *   - arch/x86/kvm/hyperv.c|828| <<stimer_notify_direct>> return !kvm_apic_set_irq(vcpu, &irq, NULL);
+ *   - arch/x86/kvm/hyperv.c|1899| <<kvm_send_ipi_to_many>> kvm_apic_set_irq(vcpu, &irq, NULL);
+ *   - arch/x86/kvm/irq_comm.c|94| <<kvm_irq_delivery_to_apic>> r += kvm_apic_set_irq(vcpu, irq, dest_map);
+ *   - arch/x86/kvm/irq_comm.c|125| <<kvm_irq_delivery_to_apic>> r = kvm_apic_set_irq(lowest, irq, dest_map);
+ *   - arch/x86/kvm/lapic.c|1218| <<__pv_send_ipi>> count += kvm_apic_set_irq(vcpu, irq, NULL);
+ *   - arch/x86/kvm/lapic.c|1699| <<kvm_irq_delivery_to_apic_fast>> *r = kvm_apic_set_irq(src->vcpu, irq, dest_map);
+ *   - arch/x86/kvm/lapic.c|1712| <<kvm_irq_delivery_to_apic_fast>> *r += kvm_apic_set_irq(dst[i]->vcpu, irq, dest_map);
+ *   - arch/x86/kvm/x86.c|13639| <<kvm_arch_async_page_present>> kvm_apic_set_irq(vcpu, &irq, NULL);
+ */
 int kvm_apic_set_irq(struct kvm_vcpu *vcpu, struct kvm_lapic_irq *irq,
 		     struct dest_map *dest_map)
 {
 	struct kvm_lapic *apic = vcpu->arch.apic;
 
+	/*
+	 * 在以下使用__apic_accept_irq():
+	 *   - arch/x86/kvm/lapic.c|1345| <<kvm_apic_set_irq>> return __apic_accept_irq(apic,
+	 *          irq->delivery_mode, irq->vector, irq->level, irq->trig_mode, dest_map);
+	 *   - arch/x86/kvm/lapic.c|4149| <<kvm_apic_local_deliver>> r = __apic_accept_irq(apic,
+	 *          mode, vector, 1, trig_mode, NULL);
+	 */
 	return __apic_accept_irq(apic, irq->delivery_mode, irq->vector,
 			irq->level, irq->trig_mode, dest_map);
 }
@@ -679,8 +1367,31 @@ static int __pv_send_ipi(unsigned long *ipi_bitmap, struct kvm_apic_map *map,
 
 	for_each_set_bit(i, ipi_bitmap,
 		min((u32)BITS_PER_LONG, (map->max_apic_id - min + 1))) {
+		/*
+		 * 在以下使用kvm_apic_map->phys_map[]:
+		 *   - arch/x86/kvm/lapic.c|289| <<kvm_apic_map_get_logical_dest>> *cluster = &map->phys_map[offset];
+		 *   - arch/x86/kvm/lapic.c|534| <<kvm_recalculate_apic_map>> new->phys_map[x2apic_id] = apic;
+		 *   - arch/x86/kvm/lapic.c|539| <<kvm_recalculate_apic_map>> if (!apic_x2apic_mode(apic) && !new->phys_map[xapic_id])
+		 *   - arch/x86/kvm/lapic.c|540| <<kvm_recalculate_apic_map>> new->phys_map[xapic_id] = apic;
+		 *   - arch/x86/kvm/lapic.c|1287| <<__pv_send_ipi>> if (map->phys_map[min + i]) {
+		 *   - arch/x86/kvm/lapic.c|1288| <<__pv_send_ipi>> vcpu = map->phys_map[min + i]->vcpu;
+		 *   - arch/x86/kvm/lapic.c|1738| <<kvm_apic_map_get_dest_lapic>> *dst = &map->phys_map[dest_id];
+		 *   - arch/x86/kvm/x86.c|9433| <<kvm_sched_yield>> if (likely(map) && dest_id <= map->max_apic_id && map->phys_map[dest_id])
+		 *   - arch/x86/kvm/x86.c|9434| <<kvm_sched_yield>> target = map->phys_map[dest_id]->vcpu;
+		 */
 		if (map->phys_map[min + i]) {
 			vcpu = map->phys_map[min + i]->vcpu;
+			/*
+			 * 在以下使用kvm_apic_set_irq():
+			 *   - arch/x86/kvm/hyperv.c|828| <<stimer_notify_direct>> return !kvm_apic_set_irq(vcpu, &irq, NULL);
+			 *   - arch/x86/kvm/hyperv.c|1899| <<kvm_send_ipi_to_many>> kvm_apic_set_irq(vcpu, &irq, NULL);
+			 *   - arch/x86/kvm/irq_comm.c|94| <<kvm_irq_delivery_to_apic>> r += kvm_apic_set_irq(vcpu, irq, dest_map);
+			 *   - arch/x86/kvm/irq_comm.c|125| <<kvm_irq_delivery_to_apic>> r = kvm_apic_set_irq(lowest, irq, dest_map);
+			 *   - arch/x86/kvm/lapic.c|1218| <<__pv_send_ipi>> count += kvm_apic_set_irq(vcpu, irq, NULL);
+			 *   - arch/x86/kvm/lapic.c|1699| <<kvm_irq_delivery_to_apic_fast>> *r = kvm_apic_set_irq(src->vcpu, irq, dest_map);
+			 *   - arch/x86/kvm/lapic.c|1712| <<kvm_irq_delivery_to_apic_fast>> *r += kvm_apic_set_irq(dst[i]->vcpu, irq, dest_map);
+			 *   - arch/x86/kvm/x86.c|13639| <<kvm_arch_async_page_present>> kvm_apic_set_irq(vcpu, &irq, NULL);
+			 */
 			count += kvm_apic_set_irq(vcpu, irq, NULL);
 		}
 	}
@@ -706,6 +1417,17 @@ int kvm_pv_send_ipi(struct kvm *kvm, unsigned long ipi_bitmap_low,
 	irq.trig_mode = icr & APIC_INT_LEVELTRIG;
 
 	rcu_read_lock();
+	/*
+	 * 在以下使用kvm_arch->apic_map:
+	 *   - arch/x86/kvm/lapic.c|581| <<kvm_recalculate_apic_map>> old = rcu_dereference_protected(kvm->arch.apic_map,
+	 *   - arch/x86/kvm/lapic.c|583| <<kvm_recalculate_apic_map>> rcu_assign_pointer(kvm->arch.apic_map, new);
+	 *   - arch/x86/kvm/lapic.c|1305| <<kvm_pv_send_ipi>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1772| <<kvm_irq_delivery_to_apic_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1825| <<kvm_intr_is_single_vcpu_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|2023| <<kvm_bitmap_or_dest_vcpus>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|9391| <<kvm_sched_yield>> map = rcu_dereference(vcpu->kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|13061| <<kvm_arch_destroy_vm>> kvfree(rcu_dereference_check(kvm->arch.apic_map, 1));
+	 */
 	map = rcu_dereference(kvm->arch.apic_map);
 
 	count = -EOPNOTSUPP;
@@ -735,6 +1457,18 @@ static int pv_eoi_get_user(struct kvm_vcpu *vcpu, u8 *val)
 
 static inline bool pv_eoi_enabled(struct kvm_vcpu *vcpu)
 {
+	/*
+	 *     pv_eoi = {
+	 *       msr_val = 0,
+	 *        data = {
+	 *          generation = 0,
+	 *          gpa = 0,
+	 *          hva = 0,
+	 *          len = 0,
+	 *          memslot = 0x0
+	 *        }
+	 *     },
+	 */
 	return vcpu->arch.pv_eoi.msr_val & KVM_MSR_ENABLED;
 }
 
@@ -763,9 +1497,17 @@ static void pv_eoi_clr_pending(struct kvm_vcpu *vcpu)
 	__clear_bit(KVM_APIC_PV_EOI_PENDING, &vcpu->arch.apic_attention);
 }
 
+/*
+ * 在以下使用apic_has_interrupt_for_ppr():
+ *   - arch/x86/kvm/lapic.c|1342| <<apic_update_ppr>> apic_has_interrupt_for_ppr(apic, ppr) != -1)
+ *   - arch/x86/kvm/lapic.c|3716| <<kvm_apic_has_interrupt>> return apic_has_interrupt_for_ppr(apic, ppr);
+ */
 static int apic_has_interrupt_for_ppr(struct kvm_lapic *apic, u32 ppr)
 {
 	int highest_irr;
+	/*
+	 * vmx_sync_pir_to_irr()
+	 */
 	if (kvm_x86_ops.sync_pir_to_irr)
 		highest_irr = static_call(kvm_x86_sync_pir_to_irr)(apic->vcpu);
 	else
@@ -775,6 +1517,12 @@ static int apic_has_interrupt_for_ppr(struct kvm_lapic *apic, u32 ppr)
 	return highest_irr;
 }
 
+/*
+ * 在以下使用__apic_update_ppr():
+ *   - arch/x86/kvm/lapic.c|1266| <<apic_update_ppr>> if (__apic_update_ppr(apic, &ppr) &&
+ *   - arch/x86/kvm/lapic.c|3587| <<kvm_apic_has_interrupt>> __apic_update_ppr(apic, &ppr);
+ *   - arch/x86/kvm/lapic.c|3672| <<kvm_get_apic_interrupt>> __apic_update_ppr(apic, &ppr);
+ */
 static bool __apic_update_ppr(struct kvm_lapic *apic, u32 *new_ppr)
 {
 	u32 tpr, isrv, ppr, old_ppr;
@@ -782,6 +1530,14 @@ static bool __apic_update_ppr(struct kvm_lapic *apic, u32 *new_ppr)
 
 	old_ppr = kvm_lapic_get_reg(apic, APIC_PROCPRI);
 	tpr = kvm_lapic_get_reg(apic, APIC_TASKPRI);
+	/*
+	 * 在以下调用apic_find_highest_isr():
+	 *   - arch/x86/kvm/lapic.c|700| <<apic_clear_isr>> apic_find_highest_isr(apic));
+	 *   - arch/x86/kvm/lapic.c|858| <<__apic_update_ppr>> isr = apic_find_highest_isr(apic);
+	 *   - arch/x86/kvm/lapic.c|1486| <<apic_set_eoi>> int vector = apic_find_highest_isr(apic);
+	 *   - arch/x86/kvm/lapic.c|2963| <<kvm_apic_set_state>> apic_find_highest_isr(apic));
+	 *   - arch/x86/kvm/lapic.c|3097| <<kvm_lapic_sync_to_vapic>> max_isr = apic_find_highest_isr(apic);
+	 */
 	isr = apic_find_highest_isr(apic);
 	isrv = (isr != -1) ? isr : 0;
 
@@ -797,10 +1553,25 @@ static bool __apic_update_ppr(struct kvm_lapic *apic, u32 *new_ppr)
 	return ppr < old_ppr;
 }
 
+/*
+ * 在以下使用apic_update_ppr():
+ *   - arch/x86/kvm/lapic.c|1361| <<kvm_apic_update_ppr>> apic_update_ppr(vcpu->arch.apic);
+ *   - arch/x86/kvm/lapic.c|1368| <<apic_set_tpr>> apic_update_ppr(apic);
+ *   - arch/x86/kvm/lapic.c|1996| <<apic_set_eoi>> apic_update_ppr(apic);
+ *   - arch/x86/kvm/lapic.c|2115| <<__apic_read>> apic_update_ppr(apic);
+ *   - arch/x86/kvm/lapic.c|3544| <<kvm_lapic_reset>> apic_update_ppr(apic);
+ *   - arch/x86/kvm/lapic.c|3816| <<kvm_get_apic_interrupt>> apic_update_ppr(apic);
+ *   - arch/x86/kvm/lapic.c|4014| <<kvm_apic_set_state>> apic_update_ppr(apic);
+ */
 static void apic_update_ppr(struct kvm_lapic *apic)
 {
 	u32 ppr;
 
+	/*
+	 * 在以下使用apic_has_interrupt_for_ppr():
+	 *   - arch/x86/kvm/lapic.c|1342| <<apic_update_ppr>> apic_has_interrupt_for_ppr(apic, ppr) != -1)
+	 *   - arch/x86/kvm/lapic.c|3716| <<kvm_apic_has_interrupt>> return apic_has_interrupt_for_ppr(apic, ppr);
+	 */
 	if (__apic_update_ppr(apic, &ppr) &&
 	    apic_has_interrupt_for_ppr(apic, ppr) != -1)
 		kvm_make_request(KVM_REQ_EVENT, apic->vcpu);
@@ -808,6 +1579,16 @@ static void apic_update_ppr(struct kvm_lapic *apic)
 
 void kvm_apic_update_ppr(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用apic_update_ppr():
+	 *   - arch/x86/kvm/lapic.c|1361| <<kvm_apic_update_ppr>> apic_update_ppr(vcpu->arch.apic);
+	 *   - arch/x86/kvm/lapic.c|1368| <<apic_set_tpr>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|1996| <<apic_set_eoi>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|2115| <<__apic_read>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|3544| <<kvm_lapic_reset>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|3816| <<kvm_get_apic_interrupt>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|4014| <<kvm_apic_set_state>> apic_update_ppr(apic);
+	 */
 	apic_update_ppr(vcpu->arch.apic);
 }
 EXPORT_SYMBOL_GPL(kvm_apic_update_ppr);
@@ -815,6 +1596,16 @@ EXPORT_SYMBOL_GPL(kvm_apic_update_ppr);
 static void apic_set_tpr(struct kvm_lapic *apic, u32 tpr)
 {
 	kvm_lapic_set_reg(apic, APIC_TASKPRI, tpr);
+	/*
+	 * 在以下使用apic_update_ppr():
+	 *   - arch/x86/kvm/lapic.c|1361| <<kvm_apic_update_ppr>> apic_update_ppr(vcpu->arch.apic);
+	 *   - arch/x86/kvm/lapic.c|1368| <<apic_set_tpr>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|1996| <<apic_set_eoi>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|2115| <<__apic_read>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|3544| <<kvm_lapic_reset>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|3816| <<kvm_get_apic_interrupt>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|4014| <<kvm_apic_set_state>> apic_update_ppr(apic);
+	 */
 	apic_update_ppr(apic);
 }
 
@@ -891,6 +1682,15 @@ static u32 kvm_apic_mda(struct kvm_vcpu *vcpu, unsigned int dest_id,
 {
 	bool ipi = source != NULL;
 
+	/*
+	 * 在以下使用kvm_arch->x2apic_broadcast_quirk_disabled:
+	 *   - arch/x86/kvm/lapic.c|1356| <<kvm_apic_mda>> if (!vcpu->kvm->arch.x2apic_broadcast_quirk_disabled &&
+	 *   - arch/x86/kvm/lapic.c|1435| <<kvm_apic_is_broadcast_dest>> if (kvm->arch.x2apic_broadcast_quirk_disabled) {
+	 *   - arch/x86/kvm/x86.c|5935| <<kvm_vm_ioctl_enable_cap>> kvm->arch.x2apic_broadcast_quirk_disabled = true;
+	 *
+	 *     x2apic_format = false,
+	 *     x2apic_broadcast_quirk_disabled = false,
+	 */
 	if (!vcpu->kvm->arch.x2apic_broadcast_quirk_disabled &&
 	    !ipi && dest_id == APIC_BROADCAST && apic_x2apic_mode(target))
 		return X2APIC_BROADCAST;
@@ -898,6 +1698,25 @@ static u32 kvm_apic_mda(struct kvm_vcpu *vcpu, unsigned int dest_id,
 	return dest_id;
 }
 
+/*
+ * 在以下调用kvm_apic_match_dest():
+ *   - arch/x86/kvm/ioapic.c|146| <<__rtc_irq_eoi_tracking_restore_one>> if (!kvm_apic_match_dest(vcpu, NULL,
+ *          APIC_DEST_NOSHORT, e->fields.dest_id, kvm_lapic_irq_dest_mode(!!e->fields.dest_mode)))
+ *   - arch/x86/kvm/ioapic.c|234| <<ioapic_lazy_update_eoi>> if (!kvm_apic_match_dest(vcpu, NULL,
+ *          APIC_DEST_NOSHORT, entry->fields.dest_id, entry->fields.dest_mode) ||
+ *   - arch/x86/kvm/ioapic.c|414| <<kvm_ioapic_scan_entry>> if (kvm_apic_match_dest(vcpu, NULL,
+ *          APIC_DEST_NOSHORT, e->fields.dest_id, dm) ||
+ *   - arch/x86/kvm/irq_comm.c|68| <<kvm_irq_delivery_to_apic>> if (!kvm_apic_match_dest(vcpu, src,
+ *          irq->shorthand, irq->dest_id, irq->dest_mode))
+ *   - arch/x86/kvm/irq_comm.c|359| <<kvm_intr_is_single_vcpu>> if (!kvm_apic_match_dest(vcpu, NULL,
+ *          irq->shorthand, irq->dest_id, irq->dest_mode))
+ *   - arch/x86/kvm/irq_comm.c|442| <<kvm_scan_ioapic_routes>> if (irq.trig_mode && (kvm_apic_match_dest(vcpu, NULL,
+ *          APIC_DEST_NOSHORT, irq.dest_id, irq.dest_mode) ||
+ *   - arch/x86/kvm/lapic.c|1262| <<kvm_bitmap_or_dest_vcpus>> if (!kvm_apic_match_dest(vcpu, NULL,
+ *          irq->shorthand, irq->dest_id, irq->dest_mode))
+ *   - arch/x86/kvm/svm/avic.c|461| <<avic_kick_target_vcpus>> if (kvm_apic_match_dest(vcpu, source,
+ *          icrl & APIC_SHORT_MASK, dest, icrl & APIC_DEST_MASK)) {
+ */
 bool kvm_apic_match_dest(struct kvm_vcpu *vcpu, struct kvm_lapic *source,
 			   int shorthand, unsigned int dest, int dest_mode)
 {
@@ -951,6 +1770,15 @@ static void kvm_apic_disabled_lapic_found(struct kvm *kvm)
 static bool kvm_apic_is_broadcast_dest(struct kvm *kvm, struct kvm_lapic **src,
 		struct kvm_lapic_irq *irq, struct kvm_apic_map *map)
 {
+	/*
+	 * 在以下使用kvm_arch->x2apic_broadcast_quirk_disabled:
+	 *   - arch/x86/kvm/lapic.c|1356| <<kvm_apic_mda>> if (!vcpu->kvm->arch.x2apic_broadcast_quirk_disabled &&
+	 *   - arch/x86/kvm/lapic.c|1435| <<kvm_apic_is_broadcast_dest>> if (kvm->arch.x2apic_broadcast_quirk_disabled) {
+	 *   - arch/x86/kvm/x86.c|5935| <<kvm_vm_ioctl_enable_cap>> kvm->arch.x2apic_broadcast_quirk_disabled = true;
+	 *
+	 *     x2apic_format = false,
+	 *     x2apic_broadcast_quirk_disabled = false,
+	 */
 	if (kvm->arch.x2apic_broadcast_quirk_disabled) {
 		if ((irq->dest_id == APIC_BROADCAST &&
 				map->mode != KVM_APIC_MODE_X2APIC))
@@ -974,6 +1802,20 @@ static bool kvm_apic_is_broadcast_dest(struct kvm *kvm, struct kvm_lapic **src,
  * means that the interrupt should be dropped.  In this case, *bitmap would be
  * zero and *dst undefined.
  */
+/*
+ * 在以下使用kvm_apic_map_get_dest_lapic():
+ *   - arch/x86/kvm/lapic.c|1768| <<kvm_irq_delivery_to_apic_fast>> ret = kvm_apic_map_get_dest_lapic(kvm, &src, irq, map, &dst, &bitmap);
+ *   - arch/x86/kvm/lapic.c|1821| <<kvm_intr_is_single_vcpu_fast>> if (kvm_apic_map_get_dest_lapic(kvm, NULL, irq, map, &dst, &bitmap) &&
+ *   - arch/x86/kvm/lapic.c|2019| <<kvm_bitmap_or_dest_vcpus>> ret = kvm_apic_map_get_dest_lapic(kvm, &src, irq, map, &dest_vcpu, &bitmap);
+ *
+ * 注释:
+ * Return true if the interrupt can be handled by using *bitmap as index mask
+ * for valid destinations in *dst array.
+ * Return false if kvm_apic_map_get_dest_lapic did nothing useful.
+ * Note: we may have zero kvm_lapic destinations when we return true, which
+ * means that the interrupt should be dropped.  In this case, *bitmap would be
+ * zero and *dst undefined.
+ */
 static inline bool kvm_apic_map_get_dest_lapic(struct kvm *kvm,
 		struct kvm_lapic **src, struct kvm_lapic_irq *irq,
 		struct kvm_apic_map *map, struct kvm_lapic ***dst,
@@ -996,6 +1838,18 @@ static inline bool kvm_apic_map_get_dest_lapic(struct kvm *kvm,
 			*bitmap = 0;
 		} else {
 			u32 dest_id = array_index_nospec(irq->dest_id, map->max_apic_id + 1);
+			/*
+			 * 在以下使用kvm_apic_map->phys_map[]:
+			 *   - arch/x86/kvm/lapic.c|289| <<kvm_apic_map_get_logical_dest>> *cluster = &map->phys_map[offset];
+			 *   - arch/x86/kvm/lapic.c|534| <<kvm_recalculate_apic_map>> new->phys_map[x2apic_id] = apic;
+			 *   - arch/x86/kvm/lapic.c|539| <<kvm_recalculate_apic_map>> if (!apic_x2apic_mode(apic) && !new->phys_map[xapic_id])
+			 *   - arch/x86/kvm/lapic.c|540| <<kvm_recalculate_apic_map>> new->phys_map[xapic_id] = apic;
+			 *   - arch/x86/kvm/lapic.c|1287| <<__pv_send_ipi>> if (map->phys_map[min + i]) {
+			 *   - arch/x86/kvm/lapic.c|1288| <<__pv_send_ipi>> vcpu = map->phys_map[min + i]->vcpu;
+			 *   - arch/x86/kvm/lapic.c|1738| <<kvm_apic_map_get_dest_lapic>> *dst = &map->phys_map[dest_id];
+			 *   - arch/x86/kvm/x86.c|9433| <<kvm_sched_yield>> if (likely(map) && dest_id <= map->max_apic_id && map->phys_map[dest_id])
+			 *   - arch/x86/kvm/x86.c|9434| <<kvm_sched_yield>> target = map->phys_map[dest_id]->vcpu;
+			 */
 			*dst = &map->phys_map[dest_id];
 			*bitmap = 1;
 		}
@@ -1003,6 +1857,11 @@ static inline bool kvm_apic_map_get_dest_lapic(struct kvm *kvm,
 	}
 
 	*bitmap = 0;
+	/*
+	 * 在以下使用kvm_apic_map_get_logical_dest():
+	 *   - arch/x86/kvm/lapic.c|610| <<kvm_recalculate_apic_map>> if (!kvm_apic_map_get_logical_dest(new, ldr, &cluster, &mask))
+	 *   - arch/x86/kvm/lapic.c|1825| <<kvm_apic_map_get_dest_lapic>> if (!kvm_apic_map_get_logical_dest(map, irq->dest_id, dst, (u16 *)bitmap))
+	 */
 	if (!kvm_apic_map_get_logical_dest(map, irq->dest_id, dst,
 				(u16 *)bitmap))
 		return false;
@@ -1040,6 +1899,11 @@ static inline bool kvm_apic_map_get_dest_lapic(struct kvm *kvm,
 	return true;
 }
 
+/*
+ * 在以下使用kvm_irq_delivery_to_apic_fast():
+ *   - arch/x86/kvm/irq_comm.c|53| <<kvm_irq_delivery_to_apic>> if (kvm_irq_delivery_to_apic_fast(kvm, src, irq, &r, dest_map))
+ *   - arch/x86/kvm/irq_comm.c|246| <<kvm_arch_set_irq_inatomic>> if (kvm_irq_delivery_to_apic_fast(kvm, NULL, &irq, &r, NULL))
+ */
 bool kvm_irq_delivery_to_apic_fast(struct kvm *kvm, struct kvm_lapic *src,
 		struct kvm_lapic_irq *irq, int *r, struct dest_map *dest_map)
 {
@@ -1061,14 +1925,50 @@ bool kvm_irq_delivery_to_apic_fast(struct kvm *kvm, struct kvm_lapic *src,
 	}
 
 	rcu_read_lock();
+	/*
+	 * 在以下使用kvm_arch->apic_map:
+	 *   - arch/x86/kvm/lapic.c|581| <<kvm_recalculate_apic_map>> old = rcu_dereference_protected(kvm->arch.apic_map,
+	 *   - arch/x86/kvm/lapic.c|583| <<kvm_recalculate_apic_map>> rcu_assign_pointer(kvm->arch.apic_map, new);
+	 *   - arch/x86/kvm/lapic.c|1305| <<kvm_pv_send_ipi>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1772| <<kvm_irq_delivery_to_apic_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1825| <<kvm_intr_is_single_vcpu_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|2023| <<kvm_bitmap_or_dest_vcpus>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|9391| <<kvm_sched_yield>> map = rcu_dereference(vcpu->kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|13061| <<kvm_arch_destroy_vm>> kvfree(rcu_dereference_check(kvm->arch.apic_map, 1));
+	 */
 	map = rcu_dereference(kvm->arch.apic_map);
 
+	/*
+	 * 在以下使用kvm_apic_map_get_dest_lapic():
+	 *   - arch/x86/kvm/lapic.c|1768| <<kvm_irq_delivery_to_apic_fast>> ret = kvm_apic_map_get_dest_lapic(kvm, &src, irq, map, &dst, &bitmap);
+	 *   - arch/x86/kvm/lapic.c|1821| <<kvm_intr_is_single_vcpu_fast>> if (kvm_apic_map_get_dest_lapic(kvm, NULL, irq, map, &dst, &bitmap) &&
+	 *   - arch/x86/kvm/lapic.c|2019| <<kvm_bitmap_or_dest_vcpus>> ret = kvm_apic_map_get_dest_lapic(kvm, &src, irq, map, &dest_vcpu, &bitmap);
+	 *
+	 * 注释:
+	 * Return true if the interrupt can be handled by using *bitmap as index mask
+	 * for valid destinations in *dst array.
+	 * Return false if kvm_apic_map_get_dest_lapic did nothing useful.
+	 * Note: we may have zero kvm_lapic destinations when we return true, which
+	 * means that the interrupt should be dropped.  In this case, *bitmap would be
+	 * zero and *dst undefined.
+	 */
 	ret = kvm_apic_map_get_dest_lapic(kvm, &src, irq, map, &dst, &bitmap);
 	if (ret) {
 		*r = 0;
 		for_each_set_bit(i, &bitmap, 16) {
 			if (!dst[i])
 				continue;
+			/*
+			 * 在以下使用kvm_apic_set_irq():
+			 *   - arch/x86/kvm/hyperv.c|828| <<stimer_notify_direct>> return !kvm_apic_set_irq(vcpu, &irq, NULL);
+			 *   - arch/x86/kvm/hyperv.c|1899| <<kvm_send_ipi_to_many>> kvm_apic_set_irq(vcpu, &irq, NULL);
+			 *   - arch/x86/kvm/irq_comm.c|94| <<kvm_irq_delivery_to_apic>> r += kvm_apic_set_irq(vcpu, irq, dest_map);
+			 *   - arch/x86/kvm/irq_comm.c|125| <<kvm_irq_delivery_to_apic>> r = kvm_apic_set_irq(lowest, irq, dest_map);
+			 *   - arch/x86/kvm/lapic.c|1218| <<__pv_send_ipi>> count += kvm_apic_set_irq(vcpu, irq, NULL);
+			 *   - arch/x86/kvm/lapic.c|1699| <<kvm_irq_delivery_to_apic_fast>> *r = kvm_apic_set_irq(src->vcpu, irq, dest_map);
+			 *   - arch/x86/kvm/lapic.c|1712| <<kvm_irq_delivery_to_apic_fast>> *r += kvm_apic_set_irq(dst[i]->vcpu, irq, dest_map);
+			 *   - arch/x86/kvm/x86.c|13639| <<kvm_arch_async_page_present>> kvm_apic_set_irq(vcpu, &irq, NULL);
+			 */
 			*r += kvm_apic_set_irq(dst[i]->vcpu, irq, dest_map);
 		}
 	}
@@ -1091,6 +1991,23 @@ bool kvm_irq_delivery_to_apic_fast(struct kvm *kvm, struct kvm_lapic *src,
  *	   interrupt.
  * - Otherwise, use remapped mode to inject the interrupt.
  */
+/*
+ * 在以下调用kvm_intr_is_single_vcpu_fast():
+ *   - arch/x86/kvm/irq_comm.c|471| <<kvm_intr_is_single_vcpu>> if (kvm_intr_is_single_vcpu_fast(kvm, irq, dest_vcpu))
+ *
+ * This routine tries to handle interrupts in posted mode, here is how
+ * it deals with different cases:
+ * - For single-destination interrupts, handle it in posted mode
+ * - Else if vector hashing is enabled and it is a lowest-priority
+ *   interrupt, handle it in posted mode and use the following mechanism
+ *   to find the destination vCPU.
+ *      1. For lowest-priority interrupts, store all the possible
+ *         destination vCPUs in an array.
+ *      2. Use "guest vector % max number of destination vCPUs" to find
+ *         the right destination vCPU in the array for the lowest-priority
+ *         interrupt.
+ * - Otherwise, use remapped mode to inject the interrupt.
+ */
 bool kvm_intr_is_single_vcpu_fast(struct kvm *kvm, struct kvm_lapic_irq *irq,
 			struct kvm_vcpu **dest_vcpu)
 {
@@ -1103,8 +2020,33 @@ bool kvm_intr_is_single_vcpu_fast(struct kvm *kvm, struct kvm_lapic_irq *irq,
 		return false;
 
 	rcu_read_lock();
+	/*
+	 * 在以下使用kvm_arch->apic_map:
+	 *   - arch/x86/kvm/lapic.c|581| <<kvm_recalculate_apic_map>> old = rcu_dereference_protected(kvm->arch.apic_map,
+	 *   - arch/x86/kvm/lapic.c|583| <<kvm_recalculate_apic_map>> rcu_assign_pointer(kvm->arch.apic_map, new);
+	 *   - arch/x86/kvm/lapic.c|1305| <<kvm_pv_send_ipi>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1772| <<kvm_irq_delivery_to_apic_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1825| <<kvm_intr_is_single_vcpu_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|2023| <<kvm_bitmap_or_dest_vcpus>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|9391| <<kvm_sched_yield>> map = rcu_dereference(vcpu->kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|13061| <<kvm_arch_destroy_vm>> kvfree(rcu_dereference_check(kvm->arch.apic_map, 1));
+	 */
 	map = rcu_dereference(kvm->arch.apic_map);
 
+	/*
+	 * 在以下使用kvm_apic_map_get_dest_lapic():
+	 *   - arch/x86/kvm/lapic.c|1768| <<kvm_irq_delivery_to_apic_fast>> ret = kvm_apic_map_get_dest_lapic(kvm, &src, irq, map, &dst, &bitmap);
+	 *   - arch/x86/kvm/lapic.c|1821| <<kvm_intr_is_single_vcpu_fast>> if (kvm_apic_map_get_dest_lapic(kvm, NULL, irq, map, &dst, &bitmap) &&
+	 *   - arch/x86/kvm/lapic.c|2019| <<kvm_bitmap_or_dest_vcpus>> ret = kvm_apic_map_get_dest_lapic(kvm, &src, irq, map, &dest_vcpu, &bitmap);
+	 *
+	 * 注释:
+	 * Return true if the interrupt can be handled by using *bitmap as index mask
+	 * for valid destinations in *dst array.
+	 * Return false if kvm_apic_map_get_dest_lapic did nothing useful.
+	 * Note: we may have zero kvm_lapic destinations when we return true, which
+	 * means that the interrupt should be dropped.  In this case, *bitmap would be
+	 * zero and *dst undefined.
+	 */
 	if (kvm_apic_map_get_dest_lapic(kvm, NULL, irq, map, &dst, &bitmap) &&
 			hweight16(bitmap) == 1) {
 		unsigned long i = find_first_bit(&bitmap, 16);
@@ -1119,10 +2061,65 @@ bool kvm_intr_is_single_vcpu_fast(struct kvm *kvm, struct kvm_lapic_irq *irq,
 	return ret;
 }
 
+/*
+ * 其他的:
+ * __apic_accept_irq
+ * __pv_send_ipi
+ * kvm_pv_send_ipi
+ * kvm_emulate_hypercall
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * __apic_accept_irq
+ * kvm_irq_delivery_to_apic
+ * kvm_apic_send_ipi
+ * kvm_x2apic_icr_write
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ */
+/*
+ * 关于RESCHEDULE_VECTOR (0xfd)
+ *
+ * __apic_accept_irq
+ * kvm_irq_delivery_to_apic_fast
+ * kvm_irq_delivery_to_apic
+ * kvm_apic_send_ipi
+ * kvm_x2apic_icr_write
+ * handle_fastpath_set_msr_irqoff
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ */
 /*
  * Add a pending IRQ into lapic.
  * Return 1 if successfully added and 0 if discarded.
  */
+/*
+ * 在以下使用__apic_accept_irq():
+ *   - arch/x86/kvm/lapic.c|1345| <<kvm_apic_set_irq>> return __apic_accept_irq(apic,
+ *          irq->delivery_mode, irq->vector, irq->level, irq->trig_mode, dest_map);
+ *   - arch/x86/kvm/lapic.c|4149| <<kvm_apic_local_deliver>> r = __apic_accept_irq(apic,
+ *          mode, vector, 1, trig_mode, NULL);
+ */
 static int __apic_accept_irq(struct kvm_lapic *apic, int delivery_mode,
 			     int vector, int level, int trig_mode,
 			     struct dest_map *dest_map)
@@ -1151,6 +2148,30 @@ static int __apic_accept_irq(struct kvm_lapic *apic, int delivery_mode,
 			dest_map->vectors[vcpu->vcpu_id] = vector;
 		}
 
+		/*
+		 * 在APIC中,TMR是Trigger Mode Register(触发方式寄存器),它的作用
+		 * 是记录每个中断向量是边沿触发还是电平触发.
+		 *
+		 * TMR[x] = 0 -> 中断向量x是边沿触发
+		 * TMR[x] = 1 -> 中断向量x是电平触发
+		 *
+		 * 对于边沿触发,中断发生后就结束,不再重复处理
+		 * 对于电平触发,需要在处理完成后确认信号已解除,
+		 * 否则中断会再次被触发(因为信号电平还在)
+		 *
+		 * 假设中断向量45是电平触发,那么:
+		 * TMR[45] = 1
+		 * 当中断控制器检测到45的信号为低电平时,会记录它在IRR(中断请求寄存器)中
+		 * 处理中断后,系统必须通知设备"我处理完了",否则设备保持信号为低电平,45 会一直被重复触发
+		 *
+		 *
+		 * 在以下使用apic_test_vector():
+		 *   - arch/x86/kvm/lapic.c|176| <<kvm_apic_pending_eoi>> return apic_test_vector(vector, apic->regs + APIC_ISR) ||
+		 *   - arch/x86/kvm/lapic.c|177| <<kvm_apic_pending_eoi>> apic_test_vector(vector, apic->regs + APIC_IRR);
+		 *   - arch/x86/kvm/lapic.c|2104| <<__apic_accept_irq>> if (apic_test_vector(vector, apic->regs + APIC_TMR) != !!trig_mode) {
+		 *   - arch/x86/kvm/lapic.c|2324| <<kvm_ioapic_send_eoi>> if (apic_test_vector(vector, apic->regs + APIC_TMR))
+		 *   - arch/x86/kvm/lapic.c|2723| <<lapic_timer_int_injected>> if (apic_test_vector(vec, bitmap))
+		 */
 		if (apic_test_vector(vector, apic->regs + APIC_TMR) != !!trig_mode) {
 			if (trig_mode)
 				kvm_lapic_set_vector(vector,
@@ -1160,12 +2181,24 @@ static int __apic_accept_irq(struct kvm_lapic *apic, int delivery_mode,
 						       apic->regs + APIC_TMR);
 		}
 
+		/*
+		 * vmx_deliver_interrupt()
+		 * svm_deliver_interrupt()
+		 */
 		static_call(kvm_x86_deliver_interrupt)(apic, delivery_mode,
 						       trig_mode, vector);
 		break;
 
 	case APIC_DM_REMRD:
 		result = 1;
+		/*
+		 * 在以下使用kvm_vcpu_arch的pv_unhalted:
+		 *   - arch/x86/kvm/lapic.c|2005| <<__apic_accept_irq>> vcpu->arch.pv.pv_unhalted = 1;
+		 *   - arch/x86/kvm/x86.c|11341| <<vcpu_block>> vcpu->arch.pv.pv_unhalted = false;
+		 *   - arch/x86/kvm/x86.c|11793| <<kvm_arch_vcpu_ioctl_get_mpstate>> vcpu->arch.pv.pv_unhalted)
+		 *   - arch/x86/kvm/x86.c|13430| <<kvm_vcpu_has_events>> if (vcpu->arch.pv.pv_unhalted)
+		 *   - arch/x86/kvm/x86.c|13483| <<kvm_arch_dy_runnable>> if (READ_ONCE(vcpu->arch.pv.pv_unhalted))
+		 */
 		vcpu->arch.pv.pv_unhalted = 1;
 		kvm_make_request(KVM_REQ_EVENT, vcpu);
 		kvm_vcpu_kick(vcpu);
@@ -1225,6 +2258,11 @@ static int __apic_accept_irq(struct kvm_lapic *apic, int delivery_mode,
  * out the destination vcpus array and set the bitmap or it traverses to
  * each available vcpu to identify the same.
  */
+/*
+ * 在以下使用kvm_bitmap_or_dest_vcpus():
+ *   - arch/x86/kvm/ioapic.c|590| <<ioapic_write_indirect>> kvm_bitmap_or_dest_vcpus(ioapic->kvm, &irq,
+ *   - arch/x86/kvm/ioapic.c|603| <<ioapic_write_indirect>> kvm_bitmap_or_dest_vcpus(ioapic->kvm, &irq,
+ */
 void kvm_bitmap_or_dest_vcpus(struct kvm *kvm, struct kvm_lapic_irq *irq,
 			      unsigned long *vcpu_bitmap)
 {
@@ -1237,8 +2275,33 @@ void kvm_bitmap_or_dest_vcpus(struct kvm *kvm, struct kvm_lapic_irq *irq,
 	bool ret;
 
 	rcu_read_lock();
+	/*
+	 * 在以下使用kvm_arch->apic_map:
+	 *   - arch/x86/kvm/lapic.c|581| <<kvm_recalculate_apic_map>> old = rcu_dereference_protected(kvm->arch.apic_map,
+	 *   - arch/x86/kvm/lapic.c|583| <<kvm_recalculate_apic_map>> rcu_assign_pointer(kvm->arch.apic_map, new);
+	 *   - arch/x86/kvm/lapic.c|1305| <<kvm_pv_send_ipi>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1772| <<kvm_irq_delivery_to_apic_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1825| <<kvm_intr_is_single_vcpu_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|2023| <<kvm_bitmap_or_dest_vcpus>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|9391| <<kvm_sched_yield>> map = rcu_dereference(vcpu->kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|13061| <<kvm_arch_destroy_vm>> kvfree(rcu_dereference_check(kvm->arch.apic_map, 1));
+	 */
 	map = rcu_dereference(kvm->arch.apic_map);
 
+	/*
+	 * 在以下使用kvm_apic_map_get_dest_lapic():
+	 *   - arch/x86/kvm/lapic.c|1768| <<kvm_irq_delivery_to_apic_fast>> ret = kvm_apic_map_get_dest_lapic(kvm, &src, irq, map, &dst, &bitmap);
+	 *   - arch/x86/kvm/lapic.c|1821| <<kvm_intr_is_single_vcpu_fast>> if (kvm_apic_map_get_dest_lapic(kvm, NULL, irq, map, &dst, &bitmap) &&
+	 *   - arch/x86/kvm/lapic.c|2019| <<kvm_bitmap_or_dest_vcpus>> ret = kvm_apic_map_get_dest_lapic(kvm, &src, irq, map, &dest_vcpu, &bitmap);
+	 *
+	 * 注释:
+	 * Return true if the interrupt can be handled by using *bitmap as index mask
+	 * for valid destinations in *dst array.
+	 * Return false if kvm_apic_map_get_dest_lapic did nothing useful.
+	 * Note: we may have zero kvm_lapic destinations when we return true, which
+	 * means that the interrupt should be dropped.  In this case, *bitmap would be
+	 * zero and *dst undefined.
+	 */
 	ret = kvm_apic_map_get_dest_lapic(kvm, &src, irq, map, &dest_vcpu,
 					  &bitmap);
 	if (ret) {
@@ -1252,6 +2315,25 @@ void kvm_bitmap_or_dest_vcpus(struct kvm *kvm, struct kvm_lapic_irq *irq,
 		kvm_for_each_vcpu(i, vcpu, kvm) {
 			if (!kvm_apic_present(vcpu))
 				continue;
+			/*
+			 * 在以下调用kvm_apic_match_dest():
+			 *   - arch/x86/kvm/ioapic.c|146| <<__rtc_irq_eoi_tracking_restore_one>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, e->fields.dest_id, kvm_lapic_irq_dest_mode(!!e->fields.dest_mode)))
+			 *   - arch/x86/kvm/ioapic.c|234| <<ioapic_lazy_update_eoi>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, entry->fields.dest_id, entry->fields.dest_mode) ||
+			 *   - arch/x86/kvm/ioapic.c|414| <<kvm_ioapic_scan_entry>> if (kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, e->fields.dest_id, dm) ||
+			 *   - arch/x86/kvm/irq_comm.c|68| <<kvm_irq_delivery_to_apic>> if (!kvm_apic_match_dest(vcpu, src,
+			 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+			 *   - arch/x86/kvm/irq_comm.c|359| <<kvm_intr_is_single_vcpu>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+			 *   - arch/x86/kvm/irq_comm.c|442| <<kvm_scan_ioapic_routes>> if (irq.trig_mode && (kvm_apic_match_dest(vcpu, NULL,
+			 *          APIC_DEST_NOSHORT, irq.dest_id, irq.dest_mode) ||
+			 *   - arch/x86/kvm/lapic.c|1262| <<kvm_bitmap_or_dest_vcpus>> if (!kvm_apic_match_dest(vcpu, NULL,
+			 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+			 *   - arch/x86/kvm/svm/avic.c|461| <<avic_kick_target_vcpus>> if (kvm_apic_match_dest(vcpu, source,
+			 *          icrl & APIC_SHORT_MASK, dest, icrl & APIC_DEST_MASK)) {
+			 */
 			if (!kvm_apic_match_dest(vcpu, NULL,
 						 irq->shorthand,
 						 irq->dest_id,
@@ -1268,11 +2350,32 @@ int kvm_apic_compare_prio(struct kvm_vcpu *vcpu1, struct kvm_vcpu *vcpu2)
 	return vcpu1->arch.apic_arb_prio - vcpu2->arch.apic_arb_prio;
 }
 
+/*
+ * 在以下使用kvm_ioapic_handles_vector():
+ *   - arch/x86/kvm/lapic.c|1397| <<kvm_ioapic_send_eoi>> if (!kvm_ioapic_handles_vector(apic, vector))
+ *   - arch/x86/kvm/lapic.c|2972| <<apic_sync_pv_eoi_to_guest>> kvm_ioapic_handles_vector(apic, apic->highest_isr_cache)) {
+ */
 static bool kvm_ioapic_handles_vector(struct kvm_lapic *apic, int vector)
 {
+	/*
+	 * 在以下使用kvm_vcpu_arch->ioapic_handled_vectors:
+	 *   - arch/x86/kvm/lapic.c|1273| <<kvm_ioapic_handles_vector>> return test_bit(vector, apic->vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|9840| <<vcpu_scan_ioapic>> bitmap_zero(vcpu->arch.ioapic_handled_vectors, 256);
+	 *   - arch/x86/kvm/x86.c|9845| <<vcpu_scan_ioapic>> kvm_scan_ioapic_routes(vcpu, vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|9847| <<vcpu_scan_ioapic>> kvm_ioapic_scan_entry(vcpu, vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|9864| <<vcpu_load_eoi_exitmap>> bitmap_or((ulong *)eoi_exit_bitmap, vcpu->arch.ioapic_handled_vectors,
+	 *              to_hv_synic(vcpu)->vec_bitmap, 256);
+	 *   - arch/x86/kvm/x86.c|9871| <<vcpu_load_eoi_exitmap>> static_call(kvm_x86_load_eoi_exitmap)(vcpu, (u64 *)vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|10004| <<vcpu_enter_guest>> if (test_bit(vcpu->arch.pending_ioapic_eoi, vcpu->arch.ioapic_handled_vectors)) {
+	 */
 	return test_bit(vector, apic->vcpu->arch.ioapic_handled_vectors);
 }
 
+/*
+ * 在以下调用kvm_ioapic_send_eoi():
+ *   - arch/x86/kvm/lapic.c|1435| <<apic_set_eoi>> kvm_ioapic_send_eoi(apic, vector);
+ *   - arch/x86/kvm/lapic.c|1450| <<kvm_apic_set_eoi_accelerated>> kvm_ioapic_send_eoi(apic, vector);
+ */
 static void kvm_ioapic_send_eoi(struct kvm_lapic *apic, int vector)
 {
 	int trigger_mode;
@@ -1281,6 +2384,11 @@ static void kvm_ioapic_send_eoi(struct kvm_lapic *apic, int vector)
 	if (!kvm_ioapic_handles_vector(apic, vector))
 		return;
 
+	/*
+	 * on: KVM模拟全部
+	 * split: QEMU模拟IOAPIC和PIC,KVM模拟LAPIC
+	 * off:QEMU 模拟全部
+	 */
 	/* Request a KVM exit to inform the userspace IOAPIC. */
 	if (irqchip_split(apic->vcpu->kvm)) {
 		apic->vcpu->arch.pending_ioapic_eoi = vector;
@@ -1288,6 +2396,14 @@ static void kvm_ioapic_send_eoi(struct kvm_lapic *apic, int vector)
 		return;
 	}
 
+	/*
+	 * 在以下使用apic_test_vector():
+	 *   - arch/x86/kvm/lapic.c|176| <<kvm_apic_pending_eoi>> return apic_test_vector(vector, apic->regs + APIC_ISR) ||
+	 *   - arch/x86/kvm/lapic.c|177| <<kvm_apic_pending_eoi>> apic_test_vector(vector, apic->regs + APIC_IRR);
+	 *   - arch/x86/kvm/lapic.c|2104| <<__apic_accept_irq>> if (apic_test_vector(vector, apic->regs + APIC_TMR) != !!trig_mode) {
+	 *   - arch/x86/kvm/lapic.c|2324| <<kvm_ioapic_send_eoi>> if (apic_test_vector(vector, apic->regs + APIC_TMR))
+	 *   - arch/x86/kvm/lapic.c|2723| <<lapic_timer_int_injected>> if (apic_test_vector(vec, bitmap))
+	 */
 	if (apic_test_vector(vector, apic->regs + APIC_TMR))
 		trigger_mode = IOAPIC_LEVEL_TRIG;
 	else
@@ -1296,6 +2412,11 @@ static void kvm_ioapic_send_eoi(struct kvm_lapic *apic, int vector)
 	kvm_ioapic_update_eoi(apic->vcpu, vector, trigger_mode);
 }
 
+/*
+ * 在以下使用apic_set_eoi():
+ *   - arch/x86/kvm/lapic.c|2274| <<kvm_lapic_reg_write(APIC_EOI)>> apic_set_eoi(apic);
+ *   - arch/x86/kvm/lapic.c|3015| <<apic_sync_pv_eoi_from_guest>> vector = apic_set_eoi(apic);
+ */
 static int apic_set_eoi(struct kvm_lapic *apic)
 {
 	int vector = apic_find_highest_isr(apic);
@@ -1309,7 +2430,20 @@ static int apic_set_eoi(struct kvm_lapic *apic)
 	if (vector == -1)
 		return vector;
 
+	/*
+	 * 只在此处调用apic_clear_isr()
+	 */
 	apic_clear_isr(vector, apic);
+	/*
+	 * 在以下使用apic_update_ppr():
+	 *   - arch/x86/kvm/lapic.c|1361| <<kvm_apic_update_ppr>> apic_update_ppr(vcpu->arch.apic);
+	 *   - arch/x86/kvm/lapic.c|1368| <<apic_set_tpr>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|1996| <<apic_set_eoi>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|2115| <<__apic_read>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|3544| <<kvm_lapic_reset>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|3816| <<kvm_get_apic_interrupt>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|4014| <<kvm_apic_set_state>> apic_update_ppr(apic);
+	 */
 	apic_update_ppr(apic);
 
 	if (to_hv_vcpu(apic->vcpu) &&
@@ -1325,6 +2459,10 @@ static int apic_set_eoi(struct kvm_lapic *apic)
  * this interface assumes a trap-like exit, which has already finished
  * desired side effect including vISR and vPPR update.
  */
+/*
+ * 在以下使用kvm_apic_set_eoi_accelerated():
+ *   - arch/x86/kvm/vmx/vmx.c|5643| <<handle_apic_eoi_induced>> kvm_apic_set_eoi_accelerated(vcpu, vector);
+ */
 void kvm_apic_set_eoi_accelerated(struct kvm_vcpu *vcpu, int vector)
 {
 	struct kvm_lapic *apic = vcpu->arch.apic;
@@ -1336,6 +2474,14 @@ void kvm_apic_set_eoi_accelerated(struct kvm_vcpu *vcpu, int vector)
 }
 EXPORT_SYMBOL_GPL(kvm_apic_set_eoi_accelerated);
 
+/*
+ * 在以下使用kvm_apic_send_ipi():
+ *   - arch/x86/kvm/lapic.c|3410| <<kvm_lapic_reg_write(APIC_ICR)>> kvm_apic_send_ipi(apic, val, kvm_lapic_get_reg(apic, APIC_ICR2));
+ *   - arch/x86/kvm/lapic.c|3502| <<kvm_lapic_reg_write(APIC_SELF_IPI)>> kvm_apic_send_ipi(apic, APIC_DEST_SELF | val, 0);
+ *   - arch/x86/kvm/lapic.c|3607| <<kvm_apic_write_nodecode>> kvm_apic_send_ipi(apic, (u32)val, (u32)(val >> 32));
+ *   - arch/x86/kvm/lapic.c|4830| <<kvm_x2apic_icr_write>> kvm_apic_send_ipi(apic, (u32)data, (u32)(data >> 32));
+ *   - arch/x86/kvm/svm/avic.c|538| <<avic_incomplete_ipi_interception>> kvm_apic_send_ipi(apic, icrl, icrh);
+ */
 void kvm_apic_send_ipi(struct kvm_lapic *apic, u32 icr_low, u32 icr_high)
 {
 	struct kvm_lapic_irq irq;
@@ -1357,6 +2503,15 @@ void kvm_apic_send_ipi(struct kvm_lapic *apic, u32 icr_low, u32 icr_high)
 
 	trace_kvm_apic_ipi(icr_low, irq.dest_id);
 
+	/*
+	 * 在以下使用kvm_irq_delivery_to_apic():
+	 *   - arch/x86/kvm/hyperv.c|495| <<synic_set_irq>> ret = kvm_irq_delivery_to_apic(vcpu->kvm, vcpu->arch.apic, &irq, NULL);
+	 *   - arch/x86/kvm/ioapic.c|673| <<ioapic_service>> ret = kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe,
+	 *   - arch/x86/kvm/ioapic.c|677| <<ioapic_service>> ret = kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe, NULL);
+	 *   - arch/x86/kvm/irq_comm.c|214| <<kvm_set_msi>> return kvm_irq_delivery_to_apic(kvm, NULL, &irq, NULL);
+	 *   - arch/x86/kvm/lapic.c|2293| <<kvm_apic_send_ipi>> kvm_irq_delivery_to_apic(apic->vcpu->kvm, apic, &irq, NULL);
+	 *   - arch/x86/kvm/x86.c|9314| <<kvm_pv_kick_cpu_op>> kvm_irq_delivery_to_apic(kvm, NULL, &lapic_irq, NULL);
+	 */
 	kvm_irq_delivery_to_apic(apic->vcpu->kvm, apic, &irq, NULL);
 }
 EXPORT_SYMBOL_GPL(kvm_apic_send_ipi);
@@ -1386,6 +2541,10 @@ static u32 apic_get_tmcct(struct kvm_lapic *apic)
 	return tmcct;
 }
 
+/*
+ * 在以下使用__report_tpr_access():
+ *   - arch/x86/kvm/lapic.c|2064| <<report_tpr_access>> __report_tpr_access(apic, write);
+ */
 static void __report_tpr_access(struct kvm_lapic *apic, bool write)
 {
 	struct kvm_vcpu *vcpu = apic->vcpu;
@@ -1396,6 +2555,11 @@ static void __report_tpr_access(struct kvm_lapic *apic, bool write)
 	run->tpr_access.is_write = write;
 }
 
+/*
+ * 在以下使用report_tpr_access():
+ *   - arch/x86/kvm/lapic.c|2089| <<__apic_read(APIC_TASKPRI)>> report_tpr_access(apic, false);
+ *   - arch/x86/kvm/lapic.c|2821| <<kvm_lapic_reg_write(APIC_TASKPRI)>> report_tpr_access(apic, true);
+ */
 static inline void report_tpr_access(struct kvm_lapic *apic, bool write)
 {
 	if (apic->vcpu->arch.tpr_access_reporting)
@@ -1420,6 +2584,16 @@ static u32 __apic_read(struct kvm_lapic *apic, unsigned int offset)
 		val = apic_get_tmcct(apic);
 		break;
 	case APIC_PROCPRI:
+		/*
+		 * 在以下使用apic_update_ppr():
+		 *   - arch/x86/kvm/lapic.c|1361| <<kvm_apic_update_ppr>> apic_update_ppr(vcpu->arch.apic);
+		 *   - arch/x86/kvm/lapic.c|1368| <<apic_set_tpr>> apic_update_ppr(apic);
+		 *   - arch/x86/kvm/lapic.c|1996| <<apic_set_eoi>> apic_update_ppr(apic);
+		 *   - arch/x86/kvm/lapic.c|2115| <<__apic_read>> apic_update_ppr(apic);
+		 *   - arch/x86/kvm/lapic.c|3544| <<kvm_lapic_reset>> apic_update_ppr(apic);
+		 *   - arch/x86/kvm/lapic.c|3816| <<kvm_get_apic_interrupt>> apic_update_ppr(apic);
+		 *   - arch/x86/kvm/lapic.c|4014| <<kvm_apic_set_state>> apic_update_ppr(apic);
+		 */
 		apic_update_ppr(apic);
 		val = kvm_lapic_get_reg(apic, offset);
 		break;
@@ -1523,6 +2697,17 @@ static int apic_mmio_read(struct kvm_vcpu *vcpu, struct kvm_io_device *this,
 	if (!apic_mmio_in_range(apic, address))
 		return -EOPNOTSUPP;
 
+	/*
+	 * 在以下调用kvm_apic_hw_enabled():
+	 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+	 *   - arch/x86/kvm/lapic.c|2040| <<apic_mmio_read>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2125| <<lapic_timer_int_injected>> if (kvm_apic_hw_enabled(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2809| <<apic_mmio_write>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|3330| <<kvm_apic_local_deliver>> if (kvm_apic_hw_enabled(apic) && !(reg & APIC_LVT_MASKED)) {
+	 *   - arch/x86/kvm/lapic.c|3443| <<kvm_apic_accept_pic_intr>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 *   - arch/x86/kvm/lapic.h|246| <<kvm_apic_present>> return lapic_in_kernel(vcpu) && kvm_apic_hw_enabled(vcpu->arch.apic);
+	 *   - arch/x86/kvm/x86.c|10218| <<vcpu_load_eoi_exitmap>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 */
 	if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
 		if (!kvm_check_has_quirk(vcpu->kvm,
 					 KVM_X86_QUIRK_LAPIC_MMIO_HOLE))
@@ -1608,6 +2793,17 @@ static bool lapic_timer_int_injected(struct kvm_vcpu *vcpu)
 	struct kvm_lapic *apic = vcpu->arch.apic;
 	u32 reg = kvm_lapic_get_reg(apic, APIC_LVTT);
 
+	/*
+	 * 在以下调用kvm_apic_hw_enabled():
+	 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+	 *   - arch/x86/kvm/lapic.c|2040| <<apic_mmio_read>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2125| <<lapic_timer_int_injected>> if (kvm_apic_hw_enabled(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2809| <<apic_mmio_write>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|3330| <<kvm_apic_local_deliver>> if (kvm_apic_hw_enabled(apic) && !(reg & APIC_LVT_MASKED)) {
+	 *   - arch/x86/kvm/lapic.c|3443| <<kvm_apic_accept_pic_intr>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 *   - arch/x86/kvm/lapic.h|246| <<kvm_apic_present>> return lapic_in_kernel(vcpu) && kvm_apic_hw_enabled(vcpu->arch.apic);
+	 *   - arch/x86/kvm/x86.c|10218| <<vcpu_load_eoi_exitmap>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 */
 	if (kvm_apic_hw_enabled(apic)) {
 		int vec = reg & APIC_VECTOR_MASK;
 		void *bitmap = apic->regs + APIC_ISR;
@@ -1615,6 +2811,14 @@ static bool lapic_timer_int_injected(struct kvm_vcpu *vcpu)
 		if (vcpu->arch.apicv_active)
 			bitmap = apic->regs + APIC_IRR;
 
+		/*
+		 * 在以下使用apic_test_vector():
+		 *   - arch/x86/kvm/lapic.c|176| <<kvm_apic_pending_eoi>> return apic_test_vector(vector, apic->regs + APIC_ISR) ||
+		 *   - arch/x86/kvm/lapic.c|177| <<kvm_apic_pending_eoi>> apic_test_vector(vector, apic->regs + APIC_IRR);
+		 *   - arch/x86/kvm/lapic.c|2104| <<__apic_accept_irq>> if (apic_test_vector(vector, apic->regs + APIC_TMR) != !!trig_mode) {
+		 *   - arch/x86/kvm/lapic.c|2324| <<kvm_ioapic_send_eoi>> if (apic_test_vector(vector, apic->regs + APIC_TMR))
+		 *   - arch/x86/kvm/lapic.c|2723| <<lapic_timer_int_injected>> if (apic_test_vector(vec, bitmap))
+		 */
 		if (apic_test_vector(vec, bitmap))
 			return true;
 	}
@@ -1632,6 +2836,21 @@ static inline void __wait_lapic_expire(struct kvm_vcpu *vcpu, u64 guest_cycles)
 	 * always for VMX enabled hardware.
 	 */
 	if (vcpu->arch.tsc_scaling_ratio == kvm_default_tsc_scaling_ratio) {
+		/*
+		 * 在以下使用nsec_to_cycles():
+		 *   - arch/x86/kvm/lapic.c|2840| <<__wait_lapic_expire>> __delay(min(guest_cycles,
+		 *          nsec_to_cycles(vcpu, timer_advance_ns)));
+		 *   - arch/x86/kvm/lapic.c|3052| <<update_target_expiration>> nsec_to_cycles(apic->vcpu, ns_remaining_new) -
+		 *                                                             nsec_to_cycles(apic->vcpu, ns_remaining_old);
+		 *   - arch/x86/kvm/lapic.c|3053| <<update_target_expiration>> nsec_to_cycles(apic->vcpu, ns_remaining_new) -
+		 *                                                             nsec_to_cycles(apic->vcpu, ns_remaining_old);
+		 *   - arch/x86/kvm/lapic.c|3097| <<set_target_expiration>> nsec_to_cycles(apic->vcpu, deadline);
+		 *   - arch/x86/kvm/lapic.c|3121| <<advance_periodic_target_expiration>> nsec_to_cycles(apic->vcpu, delta);
+		 *   - arch/x86/kvm/vmx/vmx.c|8347| <<vmx_set_hv_timer>> lapic_timer_advance_cycles = nsec_to_cycles(vcpu,
+		 *          ktimer->timer_advance_ns);
+		 *   - arch/x86/kvm/x86.c|3042| <<kvm_synchronize_tsc>> nsec_to_cycles(vcpu, elapsed);
+		 *   - arch/x86/kvm/x86.c|3065| <<kvm_synchronize_tsc>> u64 delta = nsec_to_cycles(vcpu, elapsed);
+		 */
 		__delay(min(guest_cycles,
 			nsec_to_cycles(vcpu, timer_advance_ns)));
 	} else {
@@ -1678,6 +2897,13 @@ static void __kvm_wait_lapic_expire(struct kvm_vcpu *vcpu)
 	tsc_deadline = apic->lapic_timer.expired_tscdeadline;
 	apic->lapic_timer.expired_tscdeadline = 0;
 	guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	/*
+	 * 在以下使用kvm_timer->advance_expire_delta:
+	 *   - arch/x86/kvm/lapic.c|2382| <<__kvm_wait_lapic_expire>> apic->lapic_timer.advance_expire_delta = guest_tsc - tsc_deadline;
+	 *   - arch/x86/kvm/lapic.c|2385| <<__kvm_wait_lapic_expire>> adjust_lapic_timer_advance(vcpu, apic->lapic_timer.advance_expire_delta);
+	 *   - arch/x86/kvm/x86.c|10872| <<vcpu_enter_guest>> s64 delta = vcpu->arch.apic->lapic_timer.advance_expire_delta;
+	 *   - arch/x86/kvm/x86.c|10875| <<vcpu_enter_guest>> vcpu->arch.apic->lapic_timer.advance_expire_delta = S64_MIN;
+	 */
 	apic->lapic_timer.advance_expire_delta = guest_tsc - tsc_deadline;
 
 	if (lapic_timer_advance_dynamic) {
@@ -1705,6 +2931,12 @@ void kvm_wait_lapic_expire(struct kvm_vcpu *vcpu)
 }
 EXPORT_SYMBOL_GPL(kvm_wait_lapic_expire);
 
+/*
+ * 在以下使用kvm_apic_inject_pending_timer_irqs():
+ *   - arch/x86/kvm/lapic.c|2715| <<apic_timer_expired>> kvm_apic_inject_pending_timer_irqs(apic);
+ *   - arch/x86/kvm/lapic.c|2730| <<apic_timer_expired>> kvm_apic_inject_pending_timer_irqs(apic);
+ *   - arch/x86/kvm/lapic.c|4084| <<kvm_inject_apic_timer_irqs>> kvm_apic_inject_pending_timer_irqs(apic);
+ */
 static void kvm_apic_inject_pending_timer_irqs(struct kvm_lapic *apic)
 {
 	struct kvm_timer *ktimer = &apic->lapic_timer;
@@ -1731,6 +2963,12 @@ static void apic_timer_expired(struct kvm_lapic *apic, bool from_timer_fn)
 
 	if (!from_timer_fn && vcpu->arch.apicv_active) {
 		WARN_ON(kvm_get_running_vcpu() != vcpu);
+		/*
+		 * 在以下使用kvm_apic_inject_pending_timer_irqs():
+		 *   - arch/x86/kvm/lapic.c|2715| <<apic_timer_expired>> kvm_apic_inject_pending_timer_irqs(apic);
+		 *   - arch/x86/kvm/lapic.c|2730| <<apic_timer_expired>> kvm_apic_inject_pending_timer_irqs(apic);
+		 *   - arch/x86/kvm/lapic.c|4084| <<kvm_inject_apic_timer_irqs>> kvm_apic_inject_pending_timer_irqs(apic);
+		 */
 		kvm_apic_inject_pending_timer_irqs(apic);
 		return;
 	}
@@ -1746,11 +2984,24 @@ static void apic_timer_expired(struct kvm_lapic *apic, bool from_timer_fn)
 		if (vcpu->arch.apic->lapic_timer.expired_tscdeadline &&
 		    vcpu->arch.apic->lapic_timer.timer_advance_ns)
 			__kvm_wait_lapic_expire(vcpu);
+		/*
+		 * 在以下使用kvm_apic_inject_pending_timer_irqs():
+		 *   - arch/x86/kvm/lapic.c|2715| <<apic_timer_expired>> kvm_apic_inject_pending_timer_irqs(apic);
+		 *   - arch/x86/kvm/lapic.c|2730| <<apic_timer_expired>> kvm_apic_inject_pending_timer_irqs(apic);
+		 *   - arch/x86/kvm/lapic.c|4084| <<kvm_inject_apic_timer_irqs>> kvm_apic_inject_pending_timer_irqs(apic);
+		 */
 		kvm_apic_inject_pending_timer_irqs(apic);
 		return;
 	}
 
 	atomic_inc(&apic->lapic_timer.pending);
+	/*
+	 * 在以下使用KVM_REQ_UNBLOCK:
+	 *   - arch/x86/kvm/lapic.c|2735| <<apic_timer_expired>> kvm_make_request(KVM_REQ_UNBLOCK, vcpu);
+	 *   - arch/x86/kvm/vmx/posted_intr.c|256| <<vmx_pi_start_assignment>> kvm_make_all_cpus_request(kvm, KVM_REQ_UNBLOCK);
+	 *   - arch/x86/kvm/x86.c|11444| <<vcpu_run>> kvm_clear_request(KVM_REQ_UNBLOCK, vcpu);
+	 *   - virt/kvm/kvm_main.c|3406| <<kvm_vcpu_check_block>> if (kvm_check_request(KVM_REQ_UNBLOCK, vcpu))
+	 */
 	kvm_make_request(KVM_REQ_UNBLOCK, vcpu);
 	if (from_timer_fn)
 		kvm_vcpu_kick(vcpu);
@@ -1812,6 +3063,21 @@ static void update_target_expiration(struct kvm_lapic *apic, uint32_t old_diviso
 	ns_remaining_new = mul_u64_u32_div(ns_remaining_old,
 	                                   apic->divide_count, old_divisor);
 
+	/*
+	 * 在以下使用nsec_to_cycles():
+	 *   - arch/x86/kvm/lapic.c|2840| <<__wait_lapic_expire>> __delay(min(guest_cycles,
+	 *          nsec_to_cycles(vcpu, timer_advance_ns)));
+	 *   - arch/x86/kvm/lapic.c|3052| <<update_target_expiration>> nsec_to_cycles(apic->vcpu, ns_remaining_new) -
+	 *                                                             nsec_to_cycles(apic->vcpu, ns_remaining_old);
+	 *   - arch/x86/kvm/lapic.c|3053| <<update_target_expiration>> nsec_to_cycles(apic->vcpu, ns_remaining_new) -
+	 *                                                             nsec_to_cycles(apic->vcpu, ns_remaining_old);
+	 *   - arch/x86/kvm/lapic.c|3097| <<set_target_expiration>> nsec_to_cycles(apic->vcpu, deadline);
+	 *   - arch/x86/kvm/lapic.c|3121| <<advance_periodic_target_expiration>> nsec_to_cycles(apic->vcpu, delta);
+	 *   - arch/x86/kvm/vmx/vmx.c|8347| <<vmx_set_hv_timer>> lapic_timer_advance_cycles = nsec_to_cycles(vcpu,
+	 *          ktimer->timer_advance_ns);
+	 *   - arch/x86/kvm/x86.c|3042| <<kvm_synchronize_tsc>> nsec_to_cycles(vcpu, elapsed);
+	 *   - arch/x86/kvm/x86.c|3065| <<kvm_synchronize_tsc>> u64 delta = nsec_to_cycles(vcpu, elapsed);
+	 */
 	apic->lapic_timer.tscdeadline +=
 		nsec_to_cycles(apic->vcpu, ns_remaining_new) -
 		nsec_to_cycles(apic->vcpu, ns_remaining_old);
@@ -1857,6 +3123,21 @@ static bool set_target_expiration(struct kvm_lapic *apic, u32 count_reg)
 		}
 	}
 
+	/*
+	 * 在以下使用nsec_to_cycles():
+	 *   - arch/x86/kvm/lapic.c|2840| <<__wait_lapic_expire>> __delay(min(guest_cycles,
+	 *          nsec_to_cycles(vcpu, timer_advance_ns)));
+	 *   - arch/x86/kvm/lapic.c|3052| <<update_target_expiration>> nsec_to_cycles(apic->vcpu, ns_remaining_new) -
+	 *                                                             nsec_to_cycles(apic->vcpu, ns_remaining_old);
+	 *   - arch/x86/kvm/lapic.c|3053| <<update_target_expiration>> nsec_to_cycles(apic->vcpu, ns_remaining_new) -
+	 *                                                             nsec_to_cycles(apic->vcpu, ns_remaining_old);
+	 *   - arch/x86/kvm/lapic.c|3097| <<set_target_expiration>> nsec_to_cycles(apic->vcpu, deadline);
+	 *   - arch/x86/kvm/lapic.c|3121| <<advance_periodic_target_expiration>> nsec_to_cycles(apic->vcpu, delta);
+	 *   - arch/x86/kvm/vmx/vmx.c|8347| <<vmx_set_hv_timer>> lapic_timer_advance_cycles = nsec_to_cycles(vcpu,
+	 *          ktimer->timer_advance_ns);
+	 *   - arch/x86/kvm/x86.c|3042| <<kvm_synchronize_tsc>> nsec_to_cycles(vcpu, elapsed);
+	 *   - arch/x86/kvm/x86.c|3065| <<kvm_synchronize_tsc>> u64 delta = nsec_to_cycles(vcpu, elapsed);
+	 */
 	apic->lapic_timer.tscdeadline = kvm_read_l1_tsc(apic->vcpu, tscl) +
 		nsec_to_cycles(apic->vcpu, deadline);
 	apic->lapic_timer.target_expiration = ktime_add_ns(now, deadline);
@@ -1881,6 +3162,21 @@ static void advance_periodic_target_expiration(struct kvm_lapic *apic)
 		ktime_add_ns(apic->lapic_timer.target_expiration,
 				apic->lapic_timer.period);
 	delta = ktime_sub(apic->lapic_timer.target_expiration, now);
+	/*
+	 * 在以下使用nsec_to_cycles():
+	 *   - arch/x86/kvm/lapic.c|2840| <<__wait_lapic_expire>> __delay(min(guest_cycles,
+	 *          nsec_to_cycles(vcpu, timer_advance_ns)));
+	 *   - arch/x86/kvm/lapic.c|3052| <<update_target_expiration>> nsec_to_cycles(apic->vcpu, ns_remaining_new) -
+	 *                                                             nsec_to_cycles(apic->vcpu, ns_remaining_old);
+	 *   - arch/x86/kvm/lapic.c|3053| <<update_target_expiration>> nsec_to_cycles(apic->vcpu, ns_remaining_new) -
+	 *                                                             nsec_to_cycles(apic->vcpu, ns_remaining_old);
+	 *   - arch/x86/kvm/lapic.c|3097| <<set_target_expiration>> nsec_to_cycles(apic->vcpu, deadline);
+	 *   - arch/x86/kvm/lapic.c|3121| <<advance_periodic_target_expiration>> nsec_to_cycles(apic->vcpu, delta);
+	 *   - arch/x86/kvm/vmx/vmx.c|8347| <<vmx_set_hv_timer>> lapic_timer_advance_cycles = nsec_to_cycles(vcpu,
+	 *          ktimer->timer_advance_ns);
+	 *   - arch/x86/kvm/x86.c|3042| <<kvm_synchronize_tsc>> nsec_to_cycles(vcpu, elapsed);
+	 *   - arch/x86/kvm/x86.c|3065| <<kvm_synchronize_tsc>> u64 delta = nsec_to_cycles(vcpu, elapsed);
+	 */
 	apic->lapic_timer.tscdeadline = kvm_read_l1_tsc(apic->vcpu, tscl) +
 		nsec_to_cycles(apic->vcpu, delta);
 }
@@ -2033,6 +3329,10 @@ void kvm_lapic_switch_to_sw_timer(struct kvm_vcpu *vcpu)
 }
 EXPORT_SYMBOL_GPL(kvm_lapic_switch_to_sw_timer);
 
+/*
+ * 在以下使用kvm_lapic_restart_hv_timer():
+ *   - arch/x86/kvm/x86.c|4546| <<kvm_arch_vcpu_load>> kvm_lapic_restart_hv_timer(vcpu);
+ */
 void kvm_lapic_restart_hv_timer(struct kvm_vcpu *vcpu)
 {
 	struct kvm_lapic *apic = vcpu->arch.apic;
@@ -2070,6 +3370,44 @@ static void apic_manage_nmi_watchdog(struct kvm_lapic *apic, u32 lvt0_val)
 	}
 }
 
+/*
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_vcpu_reset
+ * kvm_apic_accept_events
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_lapic_reg_write
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ *
+ * 在以下调用kvm_lapic_reg_write():
+ *   - arch/x86/kvm/lapic.c|2638| <<apic_mmio_write>> kvm_lapic_reg_write(apic, offset & 0xff0, val);
+ *   - arch/x86/kvm/lapic.c|2645| <<kvm_lapic_set_eoi>> kvm_lapic_reg_write(vcpu->arch.apic, APIC_EOI, 0);
+ *   - arch/x86/kvm/lapic.c|2667| <<kvm_apic_write_nodecode>> kvm_lapic_reg_write(apic, offset, (u32)val);
+ *   - arch/x86/kvm/lapic.c|3496| <<kvm_lapic_msr_write>> return kvm_lapic_reg_write(apic, reg, (u32)data);
+ *   - arch/x86/kvm/svm/avic.c|665| <<avic_unaccel_trap_write>> kvm_lapic_reg_write(apic, offset, kvm_lapic_get_reg(apic, offset));
+ */
 int kvm_lapic_reg_write(struct kvm_lapic *apic, u32 reg, u32 val)
 {
 	int ret = 0;
@@ -2079,6 +3417,12 @@ int kvm_lapic_reg_write(struct kvm_lapic *apic, u32 reg, u32 val)
 	switch (reg) {
 	case APIC_ID:		/* Local APIC ID */
 		if (!apic_x2apic_mode(apic)) {
+			/*
+			 * 在以下使用kvm_apic_set_xapic_id():
+			 *   - arch/x86/kvm/lapic.c|2455| <<kvm_lapic_reg_write(APIC_ID)>> kvm_apic_set_xapic_id(apic, val >> 24);
+			 *   - arch/x86/kvm/lapic.c|2756| <<kvm_lapic_set_base>> kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
+			 *   - arch/x86/kvm/lapic.c|2871| <<kvm_lapic_reset>> kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
+			 */
 			kvm_apic_set_xapic_id(apic, val >> 24);
 		} else {
 			ret = 1;
@@ -2155,6 +3499,15 @@ int kvm_lapic_reg_write(struct kvm_lapic *apic, u32 reg, u32 val)
 		size_t size;
 		u32 index;
 
+		/*
+		 * 在以下使用kvm_apic_sw_enabled():
+		 *   - arch/x86/kvm/irq_comm.c|95| <<kvm_irq_delivery_to_apic>> } else if (kvm_apic_sw_enabled(vcpu->arch.apic)) {
+		 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+		 *   - arch/x86/kvm/lapic.c|424| <<kvm_recalculate_apic_map>> if (!kvm_apic_sw_enabled(apic))
+		 *   - arch/x86/kvm/lapic.c|2720| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+		 *   - arch/x86/kvm/lapic.c|2731| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+		 *   - arch/x86/kvm/lapic.h|251| <<kvm_lapic_enabled>> return kvm_apic_present(vcpu) && kvm_apic_sw_enabled(vcpu->arch.apic);
+		 */
 		if (!kvm_apic_sw_enabled(apic))
 			val |= APIC_LVT_MASKED;
 		size = ARRAY_SIZE(apic_lvt_mask);
@@ -2166,6 +3519,15 @@ int kvm_lapic_reg_write(struct kvm_lapic *apic, u32 reg, u32 val)
 	}
 
 	case APIC_LVTT:
+		/*
+		 * 在以下使用kvm_apic_sw_enabled():
+		 *   - arch/x86/kvm/irq_comm.c|95| <<kvm_irq_delivery_to_apic>> } else if (kvm_apic_sw_enabled(vcpu->arch.apic)) {
+		 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+		 *   - arch/x86/kvm/lapic.c|424| <<kvm_recalculate_apic_map>> if (!kvm_apic_sw_enabled(apic))
+		 *   - arch/x86/kvm/lapic.c|2720| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+		 *   - arch/x86/kvm/lapic.c|2731| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+		 *   - arch/x86/kvm/lapic.h|251| <<kvm_lapic_enabled>> return kvm_apic_present(vcpu) && kvm_apic_sw_enabled(vcpu->arch.apic);
+		 */
 		if (!kvm_apic_sw_enabled(apic))
 			val |= APIC_LVT_MASKED;
 		val &= (apic_lvt_mask[0] | apic->lapic_timer.timer_mode_mask);
@@ -2220,6 +3582,14 @@ int kvm_lapic_reg_write(struct kvm_lapic *apic, u32 reg, u32 val)
 	 * was toggled, the APIC ID changed, etc...   The maps are marked dirty
 	 * on relevant changes, i.e. this is a nop for most writes.
 	 */
+	/*
+	 * 在以下调用kvm_recalculate_apic_map():
+	 *   - arch/x86/kvm/lapic.c|2441| <<kvm_lapic_reg_write>> kvm_recalculate_apic_map(apic->vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|2718| <<kvm_lapic_reset>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|2995| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|3001| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/x86.c|493| <<kvm_set_apic_base>> kvm_recalculate_apic_map(vcpu->kvm);
+	 */
 	kvm_recalculate_apic_map(apic->vcpu->kvm);
 
 	return ret;
@@ -2236,6 +3606,17 @@ static int apic_mmio_write(struct kvm_vcpu *vcpu, struct kvm_io_device *this,
 	if (!apic_mmio_in_range(apic, address))
 		return -EOPNOTSUPP;
 
+	/*
+	 * 在以下调用kvm_apic_hw_enabled():
+	 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+	 *   - arch/x86/kvm/lapic.c|2040| <<apic_mmio_read>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2125| <<lapic_timer_int_injected>> if (kvm_apic_hw_enabled(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2809| <<apic_mmio_write>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|3330| <<kvm_apic_local_deliver>> if (kvm_apic_hw_enabled(apic) && !(reg & APIC_LVT_MASKED)) {
+	 *   - arch/x86/kvm/lapic.c|3443| <<kvm_apic_accept_pic_intr>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 *   - arch/x86/kvm/lapic.h|246| <<kvm_apic_present>> return lapic_in_kernel(vcpu) && kvm_apic_hw_enabled(vcpu->arch.apic);
+	 *   - arch/x86/kvm/x86.c|10218| <<vcpu_load_eoi_exitmap>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 */
 	if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
 		if (!kvm_check_has_quirk(vcpu->kvm,
 					 KVM_X86_QUIRK_LAPIC_MMIO_HOLE))
@@ -2254,6 +3635,14 @@ static int apic_mmio_write(struct kvm_vcpu *vcpu, struct kvm_io_device *this,
 
 	val = *(u32*)data;
 
+	/*
+	 * 在以下调用kvm_lapic_reg_write():
+	 *   - arch/x86/kvm/lapic.c|2638| <<apic_mmio_write>> kvm_lapic_reg_write(apic, offset & 0xff0, val);
+	 *   - arch/x86/kvm/lapic.c|2645| <<kvm_lapic_set_eoi>> kvm_lapic_reg_write(vcpu->arch.apic, APIC_EOI, 0);
+	 *   - arch/x86/kvm/lapic.c|2667| <<kvm_apic_write_nodecode>> kvm_lapic_reg_write(apic, offset, (u32)val);
+	 *   - arch/x86/kvm/lapic.c|3496| <<kvm_lapic_msr_write>> return kvm_lapic_reg_write(apic, reg, (u32)data);
+	 *   - arch/x86/kvm/svm/avic.c|665| <<avic_unaccel_trap_write>> kvm_lapic_reg_write(apic, offset, kvm_lapic_get_reg(apic, offset));
+	 */
 	kvm_lapic_reg_write(apic, offset & 0xff0, val);
 
 	return 0;
@@ -2261,6 +3650,14 @@ static int apic_mmio_write(struct kvm_vcpu *vcpu, struct kvm_io_device *this,
 
 void kvm_lapic_set_eoi(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下调用kvm_lapic_reg_write():
+	 *   - arch/x86/kvm/lapic.c|2638| <<apic_mmio_write>> kvm_lapic_reg_write(apic, offset & 0xff0, val);
+	 *   - arch/x86/kvm/lapic.c|2645| <<kvm_lapic_set_eoi>> kvm_lapic_reg_write(vcpu->arch.apic, APIC_EOI, 0);
+	 *   - arch/x86/kvm/lapic.c|2667| <<kvm_apic_write_nodecode>> kvm_lapic_reg_write(apic, offset, (u32)val);
+	 *   - arch/x86/kvm/lapic.c|3496| <<kvm_lapic_msr_write>> return kvm_lapic_reg_write(apic, reg, (u32)data);
+	 *   - arch/x86/kvm/svm/avic.c|665| <<avic_unaccel_trap_write>> kvm_lapic_reg_write(apic, offset, kvm_lapic_get_reg(apic, offset));
+	 */
 	kvm_lapic_reg_write(vcpu->arch.apic, APIC_EOI, 0);
 }
 EXPORT_SYMBOL_GPL(kvm_lapic_set_eoi);
@@ -2283,6 +3680,14 @@ void kvm_apic_write_nodecode(struct kvm_vcpu *vcpu, u32 offset)
 	} else {
 		/* TODO: optimize to just emulate side effect w/o one more write */
 		val = kvm_lapic_get_reg(apic, offset);
+		/*
+		 * 在以下调用kvm_lapic_reg_write():
+		 *   - arch/x86/kvm/lapic.c|2638| <<apic_mmio_write>> kvm_lapic_reg_write(apic, offset & 0xff0, val);
+		 *   - arch/x86/kvm/lapic.c|2645| <<kvm_lapic_set_eoi>> kvm_lapic_reg_write(vcpu->arch.apic, APIC_EOI, 0);
+		 *   - arch/x86/kvm/lapic.c|2667| <<kvm_apic_write_nodecode>> kvm_lapic_reg_write(apic, offset, (u32)val);
+		 *   - arch/x86/kvm/lapic.c|3496| <<kvm_lapic_msr_write>> return kvm_lapic_reg_write(apic, reg, (u32)data);
+		 *   - arch/x86/kvm/svm/avic.c|665| <<avic_unaccel_trap_write>> kvm_lapic_reg_write(apic, offset, kvm_lapic_get_reg(apic, offset));
+		 */
 		kvm_lapic_reg_write(apic, offset, (u32)val);
 	}
 }
@@ -2300,6 +3705,13 @@ void kvm_free_lapic(struct kvm_vcpu *vcpu)
 	if (!(vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE))
 		static_branch_slow_dec_deferred(&apic_hw_disabled);
 
+	/*
+	 * 在以下使用kvm_lapic->sw_enabled:
+	 *   - arch/x86/kvm/lapic.c|474| <<apic_set_spiv>> if (enabled != apic->sw_enabled) {
+	 *   - arch/x86/kvm/lapic.c|475| <<apic_set_spiv>> apic->sw_enabled = enabled;
+	 *   - arch/x86/kvm/lapic.c|2899| <<kvm_free_lapic>> if (!apic->sw_enabled)
+	 *   - arch/x86/kvm/lapic.h|260| <<kvm_apic_sw_enabled>> return apic->sw_enabled;
+	 */
 	if (!apic->sw_enabled)
 		static_branch_slow_dec_deferred(&apic_sw_disabled);
 
@@ -2350,13 +3762,135 @@ u64 kvm_lapic_get_cr8(struct kvm_vcpu *vcpu)
 	return (tpr & 0xf0) >> 4;
 }
 
+/*
+ * virsh hot-add的时候一共调用五次.
+ *
+ * 185171  185801  CPU 17/KVM      kvm_lapic_set_base
+ * 185171  185801  CPU 17/KVM      kvm_lapic_set_base
+ * 185171  185801  CPU 17/KVM      kvm_lapic_set_base
+ * 185171  185801  CPU 17/KVM      kvm_lapic_set_base
+ * 185171  185801  CPU 17/KVM      kvm_lapic_set_base
+ *
+ * kvm_lapic_set_base
+ * kvm_lapic_reset
+ * kvm_vcpu_reset
+ * kvm_arch_vcpu_create
+ * kvm_vm_ioctl_create_vcpu
+ * kvm_vm_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * kvm_lapic_set_base
+ * kvm_set_apic_base
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_arch_vcpu_ioctl
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * kvm_lapic_set_base
+ * kvm_set_apic_base
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * kvm_lapic_set_base
+ * kvm_set_apic_base
+ * __set_sregs_common.constprop.0
+ * kvm_arch_vcpu_ioctl
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * kvm_lapic_set_base
+ * kvm_apic_set_state
+ * kvm_arch_vcpu_ioctl
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ *
+ * 这是另外的一组.
+ *
+ * kvm_lapic_set_base
+ * kvm_set_apic_base
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_arch_vcpu_ioctl
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * kvm_lapic_set_base
+ * kvm_set_apic_base
+ * __set_sregs_common.constprop.0
+ * kvm_arch_vcpu_ioctl
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * kvm_lapic_set_base
+ * kvm_set_apic_base
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * kvm_lapic_set_base
+ * kvm_apic_set_state
+ * kvm_arch_vcpu_ioctl
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ *
+ * 在以下使用kvm_lapic_set_base():
+ *   - arch/x86/kvm/lapic.c|2661| <<kvm_lapic_reset>> kvm_lapic_set_base(vcpu, msr_val);
+ *   - arch/x86/kvm/lapic.c|2989| <<kvm_apic_set_state>> kvm_lapic_set_base(vcpu, vcpu->arch.apic_base);
+ *   - arch/x86/kvm/x86.c|492| <<kvm_set_apic_base>> kvm_lapic_set_base(vcpu, msr_info->data);
+ */
 void kvm_lapic_set_base(struct kvm_vcpu *vcpu, u64 value)
 {
 	u64 old_value = vcpu->arch.apic_base;
 	struct kvm_lapic *apic = vcpu->arch.apic;
 
+	/*
+	 * 在以下设置kvm_vcpu_arch->apic_base (看似修改的地方):
+	 *   - arch/x86/kvm/lapic.c|2926| <<kvm_lapic_set_base>> vcpu->arch.apic_base = value;
+	 *   - arch/x86/kvm/lapic.c|3256| <<kvm_create_lapic>> vcpu->arch.apic_base = MSR_IA32_APICBASE_ENABLE;
+	 *
+	 * struct kvm_vcpu:
+	 * -> struct kvm_vcpu_arch arch;
+	 *    -> u64 apic_base;
+	 */
 	vcpu->arch.apic_base = value;
 
+	/*
+	 * 如果新旧不同的bit里有MSR_IA32_APICBASE_ENABLE ...
+	 */
 	if ((old_value ^ value) & MSR_IA32_APICBASE_ENABLE)
 		kvm_update_cpuid_runtime(vcpu);
 
@@ -2365,17 +3899,61 @@ void kvm_lapic_set_base(struct kvm_vcpu *vcpu, u64 value)
 
 	/* update jump label if enable bit changes */
 	if ((old_value ^ value) & MSR_IA32_APICBASE_ENABLE) {
+		/*
+		 * 如果新的value是enable
+		 */
 		if (value & MSR_IA32_APICBASE_ENABLE) {
+			/*
+			 * 在以下使用kvm_apic_set_xapic_id():
+			 *   - arch/x86/kvm/lapic.c|2455| <<kvm_lapic_reg_write(APIC_ID)>> kvm_apic_set_xapic_id(apic, val >> 24);
+			 *   - arch/x86/kvm/lapic.c|2756| <<kvm_lapic_set_base>> kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
+			 *   - arch/x86/kvm/lapic.c|2871| <<kvm_lapic_reset>> kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
+			 */
 			kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
+			/*
+			 * 在以下使用apic_hw_disabled:
+			 *   - arch/x86/kvm/lapic.c|190| <<global>> __read_mostly DEFINE_STATIC_KEY_DEFERRED_FALSE(apic_hw_disabled, HZ);
+			 *   - arch/x86/kvm/lapic.c|3253| <<kvm_free_lapic>> static_branch_slow_dec_deferred(&apic_hw_disabled);
+			 *   - arch/x86/kvm/lapic.c|3460| <<kvm_lapic_set_base>> static_branch_slow_dec_deferred(&apic_hw_disabled);
+			 *   - arch/x86/kvm/lapic.c|3472| <<kvm_lapic_set_base>> static_branch_inc(&apic_hw_disabled.key);
+			 *   - arch/x86/kvm/lapic.c|4580| <<kvm_lapic_exit>> static_key_deferred_flush(&apic_hw_disabled);
+			 *   - arch/x86/kvm/lapic.c|4581| <<kvm_lapic_exit>> WARN_ON(static_branch_unlikely(&apic_hw_disabled.key));
+			 *   - arch/x86/kvm/lapic.h|290| <<kvm_apic_hw_enabled>> if (static_branch_unlikely(&apic_hw_disabled.key))
+			 */
 			static_branch_slow_dec_deferred(&apic_hw_disabled);
+			/*
+			 * 在以下使用KVM_REQ_APF_READY:
+			 *   - arch/x86/kvm/lapic.c|621| <<apic_set_spiv>> kvm_make_request(KVM_REQ_APF_READY, apic->vcpu);
+			 *   - arch/x86/kvm/lapic.c|3303| <<kvm_lapic_set_base>> kvm_make_request(KVM_REQ_APF_READY, vcpu);
+			 *   - arch/x86/kvm/x86.c|13246| <<kvm_arch_async_page_present_queued>> kvm_make_request(KVM_REQ_APF_READY, vcpu);
+			 *
+			 * 处理的函数kvm_check_async_pf_completion()
+			 */
 			/* Check if there are APF page ready requests pending */
 			kvm_make_request(KVM_REQ_APF_READY, vcpu);
 		} else {
 			static_branch_inc(&apic_hw_disabled.key);
+			/*
+			 * 在以下使用kvm_arch->apic_map_dirty:
+			 *   - arch/x86/kvm/lapic.c|279| <<kvm_recalculate_apic_map>> if (atomic_read_acquire(&kvm->arch.apic_map_dirty) == CLEAN)
+			 *   - arch/x86/kvm/lapic.c|290| <<kvm_recalculate_apic_map>> if (atomic_cmpxchg_acquire(&kvm->arch.apic_map_dirty,
+			 *   - arch/x86/kvm/lapic.c|378| <<kvm_recalculate_apic_map>> atomic_cmpxchg_release(&kvm->arch.apic_map_dirty,
+			 *   - arch/x86/kvm/lapic.c|401| <<apic_set_spiv>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+			 *   - arch/x86/kvm/lapic.c|441| <<kvm_apic_set_xapic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+			 *   - arch/x86/kvm/lapic.c|447| <<kvm_apic_set_ldr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+			 *   - arch/x86/kvm/lapic.c|453| <<kvm_apic_set_dfr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+			 *   - arch/x86/kvm/lapic.c|496| <<kvm_apic_set_x2apic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+			 *   - arch/x86/kvm/lapic.c|2862| <<kvm_lapic_set_base>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+			 *   - arch/x86/kvm/lapic.c|3370| <<kvm_apic_set_state>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+			 */
 			atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
 		}
 	}
 
+	/*
+	 * 只在此处使用kvm_apic_set_x2apic_id():
+	 *   - arch/x86/kvm/lapic.c|2767| <<kvm_lapic_set_base>> kvm_apic_set_x2apic_id(apic, vcpu->vcpu_id);
+	 */
 	if (((old_value ^ value) & X2APIC_ENABLE) && (value & X2APIC_ENABLE))
 		kvm_apic_set_x2apic_id(apic, vcpu->vcpu_id);
 
@@ -2394,13 +3972,44 @@ void kvm_lapic_set_base(struct kvm_vcpu *vcpu, u64 value)
 	}
 }
 
+/*
+ * 在以下使用kvm_apic_update_apicv():
+ *   - arch/x86/kvm/lapic.c|2828| <<kvm_lapic_reset>> kvm_apic_update_apicv(vcpu);
+ *   - arch/x86/kvm/lapic.c|3192| <<kvm_apic_set_state>> kvm_apic_update_apicv(vcpu);
+ *   - arch/x86/kvm/x86.c|9877| <<kvm_vcpu_update_apicv>> kvm_apic_update_apicv(vcpu);
+ */
 void kvm_apic_update_apicv(struct kvm_vcpu *vcpu)
 {
 	struct kvm_lapic *apic = vcpu->arch.apic;
 
 	if (vcpu->arch.apicv_active) {
+		/*
+		 * 在以下使用kvm_lapic->irr_pending:
+		 *   - arch/x86/kvm/lapic.c|530| <<kvm_apic_update_irr>> apic->irr_pending = true;
+		 *   - arch/x86/kvm/lapic.c|548| <<apic_find_highest_irr>> if (!apic->irr_pending)
+		 *   - arch/x86/kvm/lapic.c|569| <<apic_clear_irr>> apic->irr_pending = false;
+		 *   - arch/x86/kvm/lapic.c|572| <<apic_clear_irr>> apic->irr_pending = true;
+		 *   - arch/x86/kvm/lapic.c|2519| <<kvm_apic_update_apicv>> apic->irr_pending = true;
+		 *   - arch/x86/kvm/lapic.c|2968| <<apic_sync_pv_eoi_to_guest>> apic->irr_pending ||
+		 *   - arch/x86/kvm/lapic.h|154| <<kvm_lapic_set_irr>> apic->irr_pending = true;
+		 *   - arch/x86/kvm/svm/avic.c|434| <<avic_kick_target_vcpus_fast>> target_vcpu->arch.apic->irr_pending = true;
+		 *   - arch/x86/kvm/svm/avic.c|482| <<avic_kick_target_vcpus>> vcpu->arch.apic->irr_pending = true;
+		 *
+		 * 理论上来说:
+		 * irr_pending is always true when apicv is activated.
+		 */
 		/* irr_pending is always true when apicv is activated. */
 		apic->irr_pending = true;
+		/*
+		 * 在以下使用kvm_lapic->isr_count:
+		 *   - arch/x86/kvm/lapic.c|657| <<apic_set_isr>> ++apic->isr_count;
+		 *   - arch/x86/kvm/lapic.c|658| <<apic_set_isr>> BUG_ON(apic->isr_count > MAX_APIC_VECTOR);
+		 *   - arch/x86/kvm/lapic.c|684| <<apic_find_highest_isr>> if (!apic->isr_count)
+		 *   - arch/x86/kvm/lapic.c|718| <<apic_clear_isr>> --apic->isr_count;
+		 *   - arch/x86/kvm/lapic.c|719| <<apic_clear_isr>> BUG_ON(apic->isr_count < 0);
+		 *   - arch/x86/kvm/lapic.c|2631| <<kvm_apic_update_apicv>> apic->isr_count = 1;
+		 *   - arch/x86/kvm/lapic.c|2639| <<kvm_apic_update_apicv>> apic->isr_count = count_vectors(apic->regs + APIC_ISR);
+		 */
 		apic->isr_count = 1;
 	} else {
 		/*
@@ -2411,20 +4020,63 @@ void kvm_apic_update_apicv(struct kvm_vcpu *vcpu)
 		 */
 		apic->isr_count = count_vectors(apic->regs + APIC_ISR);
 	}
+	/*
+	 * 在以下使用kvm_lapic->highest_isr_cache:
+	 *   - arch/x86/kvm/lapic.c|675| <<apic_set_isr>> apic->highest_isr_cache = vec;
+	 *   - arch/x86/kvm/lapic.c|697| <<apic_find_highest_isr>> if (likely(apic->highest_isr_cache != -1))
+	 *   - arch/x86/kvm/lapic.c|698| <<apic_find_highest_isr>> return apic->highest_isr_cache;
+	 *   - arch/x86/kvm/lapic.c|734| <<apic_clear_isr>> apic->highest_isr_cache = -1;
+	 *   - arch/x86/kvm/lapic.c|2669| <<kvm_apic_update_apicv>> apic->highest_isr_cache = -1;
+	 *   - arch/x86/kvm/lapic.c|3170| <<apic_sync_pv_eoi_to_guest>> apic->highest_isr_cache == -1 ||
+	 *   - arch/x86/kvm/lapic.c|3172| <<apic_sync_pv_eoi_to_guest>> kvm_ioapic_handles_vector(apic, apic->highest_isr_cache)) {
+	 */
 	apic->highest_isr_cache = -1;
 }
 EXPORT_SYMBOL_GPL(kvm_apic_update_apicv);
 
+/*
+ * init_event = 0
+ * [0] kvm_lapic_reset
+ * [0] kvm_vcpu_reset
+ * [0] kvm_arch_vcpu_create
+ * [0] kvm_vm_ioctl
+ * [0] __x64_sys_ioctl
+ * [0] do_syscall_64
+ * [0] entry_SYSCALL_64_after_hwframe
+ *
+ * init_event = 1
+ * [0] kvm_lapic_reset
+ * [0] kvm_vcpu_reset
+ * [0] kvm_apic_accept_events
+ * [0] kvm_arch_vcpu_ioctl_run
+ * [0] kvm_vcpu_ioctl
+ * [0] __x64_sys_ioctl
+ * [0] do_syscall_64
+ * [0] entry_SYSCALL_64_after_hwframe
+ *
+ *
+ * 在以下使用kvm_lapic_reset():
+ *  - arch/x86/kvm/x86.c|11672| <<kvm_vcpu_reset>> kvm_lapic_reset(vcpu, init_event);
+ */
 void kvm_lapic_reset(struct kvm_vcpu *vcpu, bool init_event)
 {
 	struct kvm_lapic *apic = vcpu->arch.apic;
 	u64 msr_val;
 	int i;
 
+	/*
+	 * 只有kvm_arch_vcpu_create()的时候init_event是false
+	 */
 	if (!init_event) {
 		msr_val = APIC_DEFAULT_PHYS_BASE | MSR_IA32_APICBASE_ENABLE;
 		if (kvm_vcpu_is_reset_bsp(vcpu))
 			msr_val |= MSR_IA32_APICBASE_BSP;
+		/*
+		 * 在以下使用kvm_lapic_set_base():
+		 *   - arch/x86/kvm/lapic.c|2661| <<kvm_lapic_reset>> kvm_lapic_set_base(vcpu, msr_val);
+		 *   - arch/x86/kvm/lapic.c|2989| <<kvm_apic_set_state>> kvm_lapic_set_base(vcpu, vcpu->arch.apic_base);
+		 *   - arch/x86/kvm/x86.c|492| <<kvm_set_apic_base>> kvm_lapic_set_base(vcpu, msr_info->data);
+		 */
 		kvm_lapic_set_base(vcpu, msr_val);
 	}
 
@@ -2434,6 +4086,12 @@ void kvm_lapic_reset(struct kvm_vcpu *vcpu, bool init_event)
 	/* Stop the timer in case it's a reset to an active apic */
 	hrtimer_cancel(&apic->lapic_timer.timer);
 
+	/*
+	 * 在以下使用kvm_apic_set_xapic_id():
+	 *   - arch/x86/kvm/lapic.c|2455| <<kvm_lapic_reg_write(APIC_ID)>> kvm_apic_set_xapic_id(apic, val >> 24);
+	 *   - arch/x86/kvm/lapic.c|2756| <<kvm_lapic_set_base>> kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
+	 *   - arch/x86/kvm/lapic.c|2871| <<kvm_lapic_reset>> kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
+	 */
 	/* The xAPIC ID is set at RESET even if the APIC was already enabled. */
 	if (!init_event)
 		kvm_apic_set_xapic_id(apic, vcpu->vcpu_id);
@@ -2467,21 +4125,72 @@ void kvm_lapic_reset(struct kvm_vcpu *vcpu, bool init_event)
 		kvm_lapic_set_reg(apic, APIC_ISR + 0x10 * i, 0);
 		kvm_lapic_set_reg(apic, APIC_TMR + 0x10 * i, 0);
 	}
+	/*
+	 * 在以下使用kvm_apic_update_apicv():
+	 *   - arch/x86/kvm/lapic.c|2828| <<kvm_lapic_reset>> kvm_apic_update_apicv(vcpu);
+	 *   - arch/x86/kvm/lapic.c|3192| <<kvm_apic_set_state>> kvm_apic_update_apicv(vcpu);
+	 *   - arch/x86/kvm/x86.c|9877| <<kvm_vcpu_update_apicv>> kvm_apic_update_apicv(vcpu);
+	 */
 	kvm_apic_update_apicv(vcpu);
 	update_divide_count(apic);
 	atomic_set(&apic->lapic_timer.pending, 0);
 
 	vcpu->arch.pv_eoi.msr_val = 0;
+	/*
+	 * 在以下使用apic_update_ppr():
+	 *   - arch/x86/kvm/lapic.c|1361| <<kvm_apic_update_ppr>> apic_update_ppr(vcpu->arch.apic);
+	 *   - arch/x86/kvm/lapic.c|1368| <<apic_set_tpr>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|1996| <<apic_set_eoi>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|2115| <<__apic_read>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|3544| <<kvm_lapic_reset>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|3816| <<kvm_get_apic_interrupt>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|4014| <<kvm_apic_set_state>> apic_update_ppr(apic);
+	 */
 	apic_update_ppr(apic);
 	if (vcpu->arch.apicv_active) {
+		/*
+		 * vmx_apicv_post_state_restore()
+		 */
 		static_call(kvm_x86_apicv_post_state_restore)(vcpu);
+		/*
+		 * vmx_hwapic_irr_update()
+		 */
 		static_call(kvm_x86_hwapic_irr_update)(vcpu, -1);
+		/*
+		 * 在以下调用kvm_x86_hwapic_isr_update:
+		 *   - arch/x86/kvm/lapic.c|1003| <<apic_set_isr>> static_call(kvm_x86_hwapic_isr_update)(vcpu, vec);
+		 *   - arch/x86/kvm/lapic.c|1129| <<apic_clear_isr>> static_call(kvm_x86_hwapic_isr_update)(vcpu, apic_find_highest_isr(apic));
+		 *   - arch/x86/kvm/lapic.c|3622| <<kvm_lapic_reset>> static_call(kvm_x86_hwapic_isr_update)(vcpu, -1);
+		 *   - arch/x86/kvm/lapic.c|4127| <<kvm_apic_set_state>> static_call(kvm_x86_hwapic_isr_update)(vcpu, apic_find_highest_isr(apic));
+		 *
+		 * vmx_hwapic_isr_update()
+		 */
 		static_call(kvm_x86_hwapic_isr_update)(vcpu, -1);
 	}
 
 	vcpu->arch.apic_arb_prio = 0;
 	vcpu->arch.apic_attention = 0;
 
+	/*
+	 * __kvm_set_or_clear_apicv_inhibit
+	 * __kvm_set_or_clear_apicv_inhibit
+	 * kvm_set_or_clear_apicv_inhibit
+	 * kvm_recalculate_apic_map
+	 * kvm_vcpu_reset
+	 * kvm_apic_accept_events
+	 * kvm_arch_vcpu_ioctl_run
+	 * kvm_vcpu_ioctl
+	 * __x64_sys_ioctl
+	 * do_syscall_64
+	 * entry_SYSCALL_64_after_hwframe
+	 *
+	 * 在以下调用kvm_recalculate_apic_map():
+	 *   - arch/x86/kvm/lapic.c|2441| <<kvm_lapic_reg_write>> kvm_recalculate_apic_map(apic->vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|2718| <<kvm_lapic_reset>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|2995| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|3001| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/x86.c|493| <<kvm_set_apic_base>> kvm_recalculate_apic_map(vcpu->kvm);
+	 */
 	kvm_recalculate_apic_map(vcpu->kvm);
 }
 
@@ -2496,6 +4205,10 @@ static bool lapic_is_periodic(struct kvm_lapic *apic)
 	return apic_lvtt_period(apic);
 }
 
+/*
+ * 在以下使用apic_has_pending_timer():
+ *   - arch/x86/kvm/irq.c|26| <<kvm_cpu_has_pending_timer>> return apic_has_pending_timer(vcpu);
+ */
 int apic_has_pending_timer(struct kvm_vcpu *vcpu)
 {
 	struct kvm_lapic *apic = vcpu->arch.apic;
@@ -2506,17 +4219,41 @@ int apic_has_pending_timer(struct kvm_vcpu *vcpu)
 	return 0;
 }
 
+/*
+ * 在以下使用kvm_apic_local_deliver():
+ *   - arch/x86/kvm/lapic.c|2918| <<kvm_apic_inject_pending_timer_irqs>> kvm_apic_local_deliver(apic, APIC_LVTT);
+ *   - arch/x86/kvm/lapic.c|4190| <<kvm_apic_nmi_wd_deliver>> kvm_apic_local_deliver(apic, APIC_LVT0);
+ *   - arch/x86/kvm/pmu.c|383| <<kvm_pmu_deliver_pmi>> kvm_apic_local_deliver(vcpu->arch.apic, APIC_LVTPC);
+ */
 int kvm_apic_local_deliver(struct kvm_lapic *apic, int lvt_type)
 {
 	u32 reg = kvm_lapic_get_reg(apic, lvt_type);
 	int vector, mode, trig_mode;
 	int r;
 
+	/*
+	 * 在以下调用kvm_apic_hw_enabled():
+	 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+	 *   - arch/x86/kvm/lapic.c|2040| <<apic_mmio_read>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2125| <<lapic_timer_int_injected>> if (kvm_apic_hw_enabled(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2809| <<apic_mmio_write>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|3330| <<kvm_apic_local_deliver>> if (kvm_apic_hw_enabled(apic) && !(reg & APIC_LVT_MASKED)) {
+	 *   - arch/x86/kvm/lapic.c|3443| <<kvm_apic_accept_pic_intr>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 *   - arch/x86/kvm/lapic.h|246| <<kvm_apic_present>> return lapic_in_kernel(vcpu) && kvm_apic_hw_enabled(vcpu->arch.apic);
+	 *   - arch/x86/kvm/x86.c|10218| <<vcpu_load_eoi_exitmap>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 */
 	if (kvm_apic_hw_enabled(apic) && !(reg & APIC_LVT_MASKED)) {
 		vector = reg & APIC_VECTOR_MASK;
 		mode = reg & APIC_MODE_MASK;
 		trig_mode = reg & APIC_LVT_LEVEL_TRIGGER;
 
+		/*
+		 * 在以下使用__apic_accept_irq():
+		 *   - arch/x86/kvm/lapic.c|1345| <<kvm_apic_set_irq>> return __apic_accept_irq(apic,
+		 *          irq->delivery_mode, irq->vector, irq->level, irq->trig_mode, dest_map);
+		 *   - arch/x86/kvm/lapic.c|4149| <<kvm_apic_local_deliver>> r = __apic_accept_irq(apic,
+		 *          mode, vector, 1, trig_mode, NULL);
+		 */
 		r = __apic_accept_irq(apic, mode, vector, 1, trig_mode, NULL);
 		if (r && lvt_type == APIC_LVTPC &&
 		    guest_cpuid_is_intel_compatible(apic->vcpu))
@@ -2590,6 +4327,17 @@ int kvm_create_lapic(struct kvm_vcpu *vcpu, int timer_advance_ns)
 	 * apic_hw_disabled; the full RESET value is set by kvm_lapic_reset().
 	 */
 	vcpu->arch.apic_base = MSR_IA32_APICBASE_ENABLE;
+	/*
+	 * 在以下使用apic_sw_disabled:
+	 *   - arch/x86/kvm/lapic.c|191| <<global>> __read_mostly DEFINE_STATIC_KEY_DEFERRED_FALSE(apic_sw_disabled, HZ);
+	 *   - arch/x86/kvm/lapic.c|599| <<apic_set_spiv>> static_branch_slow_dec_deferred(&apic_sw_disabled);
+	 *   - arch/x86/kvm/lapic.c|601| <<apic_set_spiv>> static_branch_inc(&apic_sw_disabled.key);
+	 *   - arch/x86/kvm/lapic.c|3263| <<kvm_free_lapic>> static_branch_slow_dec_deferred(&apic_sw_disabled);
+	 *   - arch/x86/kvm/lapic.c|3840| <<kvm_create_lapic>> static_branch_inc(&apic_sw_disabled.key);
+	 *   - arch/x86/kvm/lapic.c|4582| <<kvm_lapic_exit>> static_key_deferred_flush(&apic_sw_disabled);
+	 *   - arch/x86/kvm/lapic.c|4583| <<kvm_lapic_exit>> WARN_ON(static_branch_unlikely(&apic_sw_disabled.key));
+	 *   - arch/x86/kvm/lapic.h|315| <<kvm_apic_sw_enabled>> if (static_branch_unlikely(&apic_sw_disabled.key))
+	 */
 	static_branch_inc(&apic_sw_disabled.key); /* sw disabled at reset */
 	kvm_iodevice_init(&apic->dev, &apic_mmio_ops);
 
@@ -2601,6 +4349,13 @@ int kvm_create_lapic(struct kvm_vcpu *vcpu, int timer_advance_ns)
 	return -ENOMEM;
 }
 
+/*
+ * 在以下使用kvm_apic_has_interrupt():
+ *   - arch/x86/kvm/irq.c|86| <<kvm_cpu_has_injectable_intr>> return kvm_apic_has_interrupt(v) != -1;
+ *   - arch/x86/kvm/irq.c|99| <<kvm_cpu_has_interrupt>> return kvm_apic_has_interrupt(v) != -1;
+ *   - arch/x86/kvm/lapic.c|2841| <<kvm_get_apic_interrupt>> int vector = kvm_apic_has_interrupt(vcpu);
+ *   - arch/x86/kvm/vmx/nested.c|3627| <<nested_vmx_run>> kvm_apic_has_interrupt(vcpu) == vmx->nested.posted_intr_nv) {
+ */
 int kvm_apic_has_interrupt(struct kvm_vcpu *vcpu)
 {
 	struct kvm_lapic *apic = vcpu->arch.apic;
@@ -2609,7 +4364,22 @@ int kvm_apic_has_interrupt(struct kvm_vcpu *vcpu)
 	if (!kvm_apic_present(vcpu))
 		return -1;
 
+	/*
+	 * 在以下使用__apic_update_ppr():
+	 *   - arch/x86/kvm/lapic.c|1266| <<apic_update_ppr>> if (__apic_update_ppr(apic, &ppr) &&
+	 *   - arch/x86/kvm/lapic.c|3587| <<kvm_apic_has_interrupt>> __apic_update_ppr(apic, &ppr);
+	 *   - arch/x86/kvm/lapic.c|3672| <<kvm_get_apic_interrupt>> __apic_update_ppr(apic, &ppr);
+	 *
+	 * 什么也不修改
+	 */
 	__apic_update_ppr(apic, &ppr);
+	/*
+	 * 在以下使用apic_has_interrupt_for_ppr():
+	 *   - arch/x86/kvm/lapic.c|1342| <<apic_update_ppr>> apic_has_interrupt_for_ppr(apic, ppr) != -1)
+	 *   - arch/x86/kvm/lapic.c|3716| <<kvm_apic_has_interrupt>> return apic_has_interrupt_for_ppr(apic, ppr);
+	 *
+	 * 等同调用vmx_sync_pir_to_irr()
+	 */
 	return apic_has_interrupt_for_ppr(apic, ppr);
 }
 EXPORT_SYMBOL_GPL(kvm_apic_has_interrupt);
@@ -2618,6 +4388,17 @@ int kvm_apic_accept_pic_intr(struct kvm_vcpu *vcpu)
 {
 	u32 lvt0 = kvm_lapic_get_reg(vcpu->arch.apic, APIC_LVT0);
 
+	/*
+	 * 在以下调用kvm_apic_hw_enabled():
+	 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+	 *   - arch/x86/kvm/lapic.c|2040| <<apic_mmio_read>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2125| <<lapic_timer_int_injected>> if (kvm_apic_hw_enabled(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2809| <<apic_mmio_write>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|3330| <<kvm_apic_local_deliver>> if (kvm_apic_hw_enabled(apic) && !(reg & APIC_LVT_MASKED)) {
+	 *   - arch/x86/kvm/lapic.c|3443| <<kvm_apic_accept_pic_intr>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 *   - arch/x86/kvm/lapic.h|246| <<kvm_apic_present>> return lapic_in_kernel(vcpu) && kvm_apic_hw_enabled(vcpu->arch.apic);
+	 *   - arch/x86/kvm/x86.c|10218| <<vcpu_load_eoi_exitmap>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 */
 	if (!kvm_apic_hw_enabled(vcpu->arch.apic))
 		return 1;
 	if ((lvt0 & APIC_LVT_MASKED) == 0 &&
@@ -2626,18 +4407,47 @@ int kvm_apic_accept_pic_intr(struct kvm_vcpu *vcpu)
 	return 0;
 }
 
+/*
+ * 在以下使用kvm_inject_apic_timer_irqs():
+ *   - arch/x86/kvm/irq.c|246| <<kvm_inject_pending_timer_irqs>> kvm_inject_apic_timer_irqs(vcpu);
+ */
 void kvm_inject_apic_timer_irqs(struct kvm_vcpu *vcpu)
 {
 	struct kvm_lapic *apic = vcpu->arch.apic;
 
 	if (atomic_read(&apic->lapic_timer.pending) > 0) {
+		/*
+		 * 在以下使用kvm_apic_inject_pending_timer_irqs():
+		 *   - arch/x86/kvm/lapic.c|2715| <<apic_timer_expired>> kvm_apic_inject_pending_timer_irqs(apic);
+		 *   - arch/x86/kvm/lapic.c|2730| <<apic_timer_expired>> kvm_apic_inject_pending_timer_irqs(apic);
+		 *   - arch/x86/kvm/lapic.c|4084| <<kvm_inject_apic_timer_irqs>> kvm_apic_inject_pending_timer_irqs(apic);
+		 */
 		kvm_apic_inject_pending_timer_irqs(apic);
 		atomic_set(&apic->lapic_timer.pending, 0);
 	}
 }
 
+/*
+ * 在以下调用kvm_get_apic_interrupt():
+ *   - arch/x86/kvm/irq.c|138| <<kvm_cpu_get_interrupt>> return kvm_get_apic_interrupt(v);
+ *
+ * vcpu_enter_guest()
+ * -> inject_pending_event()
+ *    -> kvm_cpu_get_interrupt()
+ *       -> kvm_get_apic_interrupt()
+ *          -> apic_set_isr()
+ *
+ * 这个函数会把IRR的bit移动到ISR.
+ */
 int kvm_get_apic_interrupt(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用kvm_apic_has_interrupt():
+	 *   - arch/x86/kvm/irq.c|86| <<kvm_cpu_has_injectable_intr>> return kvm_apic_has_interrupt(v) != -1;
+	 *   - arch/x86/kvm/irq.c|99| <<kvm_cpu_has_interrupt>> return kvm_apic_has_interrupt(v) != -1;
+	 *   - arch/x86/kvm/lapic.c|2841| <<kvm_get_apic_interrupt>> int vector = kvm_apic_has_interrupt(vcpu);
+	 *   - arch/x86/kvm/vmx/nested.c|3627| <<nested_vmx_run>> kvm_apic_has_interrupt(vcpu) == vmx->nested.posted_intr_nv) {
+	 */
 	int vector = kvm_apic_has_interrupt(vcpu);
 	struct kvm_lapic *apic = vcpu->arch.apic;
 	u32 ppr;
@@ -2652,6 +4462,9 @@ int kvm_get_apic_interrupt(struct kvm_vcpu *vcpu)
 	 * because the process would deliver it through the IDT.
 	 */
 
+	/*
+	 * 从irr上清空
+	 */
 	apic_clear_irr(vector, apic);
 	if (to_hv_vcpu(vcpu) && test_bit(vector, to_hv_synic(vcpu)->auto_eoi_bitmap)) {
 		/*
@@ -2659,6 +4472,16 @@ int kvm_get_apic_interrupt(struct kvm_vcpu *vcpu)
 		 * interrupt above PPR, so check whether to raise another
 		 * KVM_REQ_EVENT.
 		 */
+		/*
+		 * 在以下使用apic_update_ppr():
+		 *   - arch/x86/kvm/lapic.c|1361| <<kvm_apic_update_ppr>> apic_update_ppr(vcpu->arch.apic);
+		 *   - arch/x86/kvm/lapic.c|1368| <<apic_set_tpr>> apic_update_ppr(apic);
+		 *   - arch/x86/kvm/lapic.c|1996| <<apic_set_eoi>> apic_update_ppr(apic);
+		 *   - arch/x86/kvm/lapic.c|2115| <<__apic_read>> apic_update_ppr(apic);
+		 *   - arch/x86/kvm/lapic.c|3544| <<kvm_lapic_reset>> apic_update_ppr(apic);
+		 *   - arch/x86/kvm/lapic.c|3816| <<kvm_get_apic_interrupt>> apic_update_ppr(apic);
+		 *   - arch/x86/kvm/lapic.c|4014| <<kvm_apic_set_state>> apic_update_ppr(apic);
+		 */
 		apic_update_ppr(apic);
 	} else {
 		/*
@@ -2667,13 +4490,33 @@ int kvm_get_apic_interrupt(struct kvm_vcpu *vcpu)
 		 * a concurrent interrupt injection, but that would have
 		 * triggered KVM_REQ_EVENT already.
 		 */
+		/*
+		 * 这里set了ISR!
+		 * 只在这一个地方调用
+		 */
 		apic_set_isr(vector, apic);
+		/*
+		 * 在以下使用__apic_update_ppr():
+		 *   - arch/x86/kvm/lapic.c|1266| <<apic_update_ppr>> if (__apic_update_ppr(apic, &ppr) &&
+		 *   - arch/x86/kvm/lapic.c|3587| <<kvm_apic_has_interrupt>> __apic_update_ppr(apic, &ppr);
+		 *   - arch/x86/kvm/lapic.c|3672| <<kvm_get_apic_interrupt>> __apic_update_ppr(apic, &ppr);
+		 */
 		__apic_update_ppr(apic, &ppr);
 	}
 
 	return vector;
 }
 
+/*
+ * 在以下调用kvm_apic_state_fixup():
+ *   - arch/x86/kvm/lapic.c|3114| <<kvm_apic_get_state>> return kvm_apic_state_fixup(vcpu, s, false);
+ *   - arch/x86/kvm/lapic.c|3136| <<kvm_apic_set_state>> r = kvm_apic_state_fixup(vcpu, s, true);
+ *
+ * #define KVM_APIC_REG_SIZE 0x400
+ * struct kvm_lapic_state {
+ *     char regs[KVM_APIC_REG_SIZE];
+ * };
+ */
 static int kvm_apic_state_fixup(struct kvm_vcpu *vcpu,
 		struct kvm_lapic_state *s, bool set)
 {
@@ -2682,6 +4525,17 @@ static int kvm_apic_state_fixup(struct kvm_vcpu *vcpu,
 		u32 *ldr = (u32 *)(s->regs + APIC_LDR);
 		u64 icr;
 
+		/*
+		 * 在以下使用kvm_arch->x2apic_format:
+		 *   - arch/x86/kvm/irq_comm.c|137| <<kvm_set_msi_irq>> trace_kvm_msi_set_irq(msg.address_lo | (kvm->arch.x2apic_format ?
+		 *   - arch/x86/kvm/irq_comm.c|140| <<kvm_set_msi_irq>> irq->dest_id = x86_msi_msg_get_destid(&msg, kvm->arch.x2apic_format);
+		 *   - arch/x86/kvm/irq_comm.c|154| <<kvm_msi_route_invalid>> return kvm->arch.x2apic_format && (e->msi.address_hi & 0xff);
+		 *   - arch/x86/kvm/lapic.c|3673| <<kvm_apic_state_fixup>> if (vcpu->kvm->arch.x2apic_format) {
+		 *   - arch/x86/kvm/x86.c|5933| <<kvm_vm_ioctl_enable_cap>> kvm->arch.x2apic_format = true;
+		 *
+		 *     x2apic_format = false,
+		 *     x2apic_broadcast_quirk_disabled = false,
+		 */
 		if (vcpu->kvm->arch.x2apic_format) {
 			if (*id != vcpu->vcpu_id)
 				return -EINVAL;
@@ -2712,8 +4566,18 @@ static int kvm_apic_state_fixup(struct kvm_vcpu *vcpu,
 	return 0;
 }
 
+/*
+ * 在以下使用kvm_apic_get_state():
+ *   - arch/x86/kvm/x86.c|4852| <<kvm_vcpu_ioctl_get_lapic>> return kvm_apic_get_state(vcpu, s);
+ */
 int kvm_apic_get_state(struct kvm_vcpu *vcpu, struct kvm_lapic_state *s)
 {
+	/*
+	 * struct kvm_vcpu *vcpu:
+	 * -> struct kvm_vcpu_arch arch;
+	 *    -> struct kvm_lapic *apic;
+	 *       -> void *regs;
+	 */
 	memcpy(s->regs, vcpu->arch.apic->regs, sizeof(*s));
 
 	/*
@@ -2723,29 +4587,125 @@ int kvm_apic_get_state(struct kvm_vcpu *vcpu, struct kvm_lapic_state *s)
 	__kvm_lapic_set_reg(s->regs, APIC_TMCCT,
 			    __apic_read(vcpu->arch.apic, APIC_TMCCT));
 
+	/*
+	 * 在以下调用kvm_apic_state_fixup():
+	 *   - arch/x86/kvm/lapic.c|3114| <<kvm_apic_get_state>> return kvm_apic_state_fixup(vcpu, s, false);
+	 *   - arch/x86/kvm/lapic.c|3136| <<kvm_apic_set_state>> r = kvm_apic_state_fixup(vcpu, s, true);
+	 */
 	return kvm_apic_state_fixup(vcpu, s, false);
 }
 
+/*
+ * 在以下使用kvm_apic_set_state():
+ *   - arch/x86/kvm/x86.c|4654| <<kvm_vcpu_ioctl_set_lapic>> r = kvm_apic_set_state(vcpu, s);
+ *
+ * 根据测试, 只在add的时候调用:
+ * kvm_apic_set_state
+ * kvm_arch_vcpu_ioctl
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * kvm_arch_vcpu_ioctl(KVM_SET_LAPIC)
+ * -> kvm_vcpu_ioctl_set_lapic()
+ *    -> kvm_apic_set_state()
+ *       -> kvm_recalculate_apic_map() -> 只有kvm_apic_state_fixup() > 0的时候
+ *       -> kvm_recalculate_apic_map()
+ */
 int kvm_apic_set_state(struct kvm_vcpu *vcpu, struct kvm_lapic_state *s)
 {
 	struct kvm_lapic *apic = vcpu->arch.apic;
 	int r;
 
+	/*
+	 * 在以下设置kvm_vcpu_arch->apic_base (看似修改的地方):
+	 *   - arch/x86/kvm/lapic.c|2926| <<kvm_lapic_set_base>> vcpu->arch.apic_base = value;
+	 *   - arch/x86/kvm/lapic.c|3256| <<kvm_create_lapic>> vcpu->arch.apic_base = MSR_IA32_APICBASE_ENABLE;
+	 *
+	 *
+	 * 在以下使用kvm_lapic_set_base():
+	 *   - arch/x86/kvm/lapic.c|2661| <<kvm_lapic_reset>> kvm_lapic_set_base(vcpu, msr_val);
+	 *   - arch/x86/kvm/lapic.c|2989| <<kvm_apic_set_state>> kvm_lapic_set_base(vcpu, vcpu->arch.apic_base);
+	 *   - arch/x86/kvm/x86.c|492| <<kvm_set_apic_base>> kvm_lapic_set_base(vcpu, msr_info->data);
+	 *
+	 * 这一行在2024年被删掉了.
+	 * 8166d25579120590ad0ec4ece02afd00a3c54f6a
+	 * KVM: x86: Drop superfluous kvm_lapic_set_base() call when setting APIC state
+	 */
 	kvm_lapic_set_base(vcpu, vcpu->arch.apic_base);
+	/*
+	 * #define KVM_APIC_REG_SIZE 0x400
+	 * struct kvm_lapic_state {
+	 *     char regs[KVM_APIC_REG_SIZE];
+	 * };
+	 *
+	 * 在以下调用apic_set_spiv():
+	 *   - arch/x86/kvm/lapic.c|2786| <<kvm_lapic_reg_write(APIC_SPIV)>> apic_set_spiv(apic, val & mask);
+	 *   - arch/x86/kvm/lapic.c|3389| <<kvm_lapic_reset>> apic_set_spiv(apic, 0xff);
+	 *   - arch/x86/kvm/lapic.c|3817| <<kvm_apic_set_state>> apic_set_spiv(apic, *((u32 *)(s->regs + APIC_SPIV)));
+	 */
 	/* set SPIV separately to get count of SW disabled APICs right */
 	apic_set_spiv(apic, *((u32 *)(s->regs + APIC_SPIV)));
 
+	/*
+	 * 在以下调用kvm_apic_state_fixup():
+	 *   - arch/x86/kvm/lapic.c|3114| <<kvm_apic_get_state>> return kvm_apic_state_fixup(vcpu, s, false);
+	 *   - arch/x86/kvm/lapic.c|3136| <<kvm_apic_set_state>> r = kvm_apic_state_fixup(vcpu, s, true);
+	 *
+	 * 只有在apic_x2apic_mode(vcpu->arch.apic)的时候才真正生效
+	 * 这里fix的是s里面的!
+	 */
 	r = kvm_apic_state_fixup(vcpu, s, true);
 	if (r) {
+		/*
+		 * 在以下调用kvm_recalculate_apic_map():
+		 *   - arch/x86/kvm/lapic.c|2441| <<kvm_lapic_reg_write>> kvm_recalculate_apic_map(apic->vcpu->kvm);
+		 *   - arch/x86/kvm/lapic.c|2718| <<kvm_lapic_reset>> kvm_recalculate_apic_map(vcpu->kvm);
+		 *   - arch/x86/kvm/lapic.c|2995| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+		 *   - arch/x86/kvm/lapic.c|3001| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+		 *   - arch/x86/kvm/x86.c|493| <<kvm_set_apic_base>> kvm_recalculate_apic_map(vcpu->kvm);
+		 */
 		kvm_recalculate_apic_map(vcpu->kvm);
 		return r;
 	}
 	memcpy(vcpu->arch.apic->regs, s->regs, sizeof(*s));
 
+	/*
+	 * 在以下使用kvm_arch->apic_map_dirty:
+	 *   - arch/x86/kvm/lapic.c|279| <<kvm_recalculate_apic_map>> if (atomic_read_acquire(&kvm->arch.apic_map_dirty) == CLEAN)
+	 *   - arch/x86/kvm/lapic.c|290| <<kvm_recalculate_apic_map>> if (atomic_cmpxchg_acquire(&kvm->arch.apic_map_dirty,
+	 *   - arch/x86/kvm/lapic.c|378| <<kvm_recalculate_apic_map>> atomic_cmpxchg_release(&kvm->arch.apic_map_dirty,
+	 *   - arch/x86/kvm/lapic.c|401| <<apic_set_spiv>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|441| <<kvm_apic_set_xapic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|447| <<kvm_apic_set_ldr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|453| <<kvm_apic_set_dfr>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|496| <<kvm_apic_set_x2apic_id>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|2862| <<kvm_lapic_set_base>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 *   - arch/x86/kvm/lapic.c|3370| <<kvm_apic_set_state>> atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	 */
 	atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
+	/*
+	 * 在以下调用kvm_recalculate_apic_map():
+	 *   - arch/x86/kvm/lapic.c|2441| <<kvm_lapic_reg_write>> kvm_recalculate_apic_map(apic->vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|2718| <<kvm_lapic_reset>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|2995| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|3001| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/x86.c|493| <<kvm_set_apic_base>> kvm_recalculate_apic_map(vcpu->kvm);
+	 */
 	kvm_recalculate_apic_map(vcpu->kvm);
 	kvm_apic_set_version(vcpu);
 
+	/*
+	 * 在以下使用apic_update_ppr():
+	 *   - arch/x86/kvm/lapic.c|1361| <<kvm_apic_update_ppr>> apic_update_ppr(vcpu->arch.apic);
+	 *   - arch/x86/kvm/lapic.c|1368| <<apic_set_tpr>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|1996| <<apic_set_eoi>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|2115| <<__apic_read>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|3544| <<kvm_lapic_reset>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|3816| <<kvm_get_apic_interrupt>> apic_update_ppr(apic);
+	 *   - arch/x86/kvm/lapic.c|4014| <<kvm_apic_set_state>> apic_update_ppr(apic);
+	 */
 	apic_update_ppr(apic);
 	cancel_apic_timer(apic);
 	apic->lapic_timer.expired_tscdeadline = 0;
@@ -2754,11 +4714,32 @@ int kvm_apic_set_state(struct kvm_vcpu *vcpu, struct kvm_lapic_state *s)
 	update_divide_count(apic);
 	__start_apic_timer(apic, APIC_TMCCT);
 	kvm_lapic_set_reg(apic, APIC_TMCCT, 0);
+	/*
+	 * 在以下使用kvm_apic_update_apicv():
+	 *   - arch/x86/kvm/lapic.c|2828| <<kvm_lapic_reset>> kvm_apic_update_apicv(vcpu);
+	 *   - arch/x86/kvm/lapic.c|3192| <<kvm_apic_set_state>> kvm_apic_update_apicv(vcpu);
+	 *   - arch/x86/kvm/x86.c|9877| <<kvm_vcpu_update_apicv>> kvm_apic_update_apicv(vcpu);
+	 */
 	kvm_apic_update_apicv(vcpu);
 	if (vcpu->arch.apicv_active) {
+		/*
+		 * vmx_apicv_post_state_restore()
+		 */
 		static_call(kvm_x86_apicv_post_state_restore)(vcpu);
+		/*
+		 * 在以下调用kvm_x86_hwapic_isr_update:
+		 *   - arch/x86/kvm/lapic.c|1003| <<apic_set_isr>> static_call(kvm_x86_hwapic_isr_update)(vcpu, vec);
+		 *   - arch/x86/kvm/lapic.c|1129| <<apic_clear_isr>> static_call(kvm_x86_hwapic_isr_update)(vcpu, apic_find_highest_isr(apic));
+		 *   - arch/x86/kvm/lapic.c|3622| <<kvm_lapic_reset>> static_call(kvm_x86_hwapic_isr_update)(vcpu, -1);
+		 *   - arch/x86/kvm/lapic.c|4127| <<kvm_apic_set_state>> static_call(kvm_x86_hwapic_isr_update)(vcpu, apic_find_highest_isr(apic));
+		 *
+		 * vmx_hwapic_irr_update()
+		 */
 		static_call(kvm_x86_hwapic_irr_update)(vcpu,
 				apic_find_highest_irr(apic));
+		/*
+		 * vmx_hwapic_isr_update()
+		 */
 		static_call(kvm_x86_hwapic_isr_update)(vcpu,
 				apic_find_highest_isr(apic));
 	}
@@ -2821,6 +4802,11 @@ static void apic_sync_pv_eoi_from_guest(struct kvm_vcpu *vcpu,
 	trace_kvm_pv_eoi(apic, vector);
 }
 
+/*
+ * 在以下调用kvm_lapic_sync_from_vapic():
+ *   - arch/x86/kvm/x86.c|10896| <<vcpu_enter_guest>> kvm_lapic_sync_from_vapic(vcpu);
+ *   - arch/x86/kvm/x86.c|10927| <<vcpu_enter_guest>> kvm_lapic_sync_from_vapic(vcpu);
+ */
 void kvm_lapic_sync_from_vapic(struct kvm_vcpu *vcpu)
 {
 	u32 data;
@@ -2847,6 +4833,21 @@ void kvm_lapic_sync_from_vapic(struct kvm_vcpu *vcpu)
 static void apic_sync_pv_eoi_to_guest(struct kvm_vcpu *vcpu,
 					struct kvm_lapic *apic)
 {
+	/*
+	 * 在以下使用kvm_lapic->irr_pending:
+	 *   - arch/x86/kvm/lapic.c|530| <<kvm_apic_update_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|548| <<apic_find_highest_irr>> if (!apic->irr_pending)
+	 *   - arch/x86/kvm/lapic.c|569| <<apic_clear_irr>> apic->irr_pending = false;
+	 *   - arch/x86/kvm/lapic.c|572| <<apic_clear_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|2519| <<kvm_apic_update_apicv>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|2968| <<apic_sync_pv_eoi_to_guest>> apic->irr_pending ||
+	 *   - arch/x86/kvm/lapic.h|154| <<kvm_lapic_set_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/svm/avic.c|434| <<avic_kick_target_vcpus_fast>> target_vcpu->arch.apic->irr_pending = true;
+	 *   - arch/x86/kvm/svm/avic.c|482| <<avic_kick_target_vcpus>> vcpu->arch.apic->irr_pending = true;
+	 *
+	 * 理论上来说:
+	 * irr_pending is always true when apicv is activated.
+	 */
 	if (!pv_eoi_enabled(vcpu) ||
 	    /* IRR set or many bits in ISR: could be nested. */
 	    apic->irr_pending ||
@@ -2945,6 +4946,14 @@ static int kvm_lapic_msr_write(struct kvm_lapic *apic, u32 reg, u64 data)
 	if (data >> 32)
 		return 1;
 
+	/*
+	 * 在以下调用kvm_lapic_reg_write():
+	 *   - arch/x86/kvm/lapic.c|2638| <<apic_mmio_write>> kvm_lapic_reg_write(apic, offset & 0xff0, val);
+	 *   - arch/x86/kvm/lapic.c|2645| <<kvm_lapic_set_eoi>> kvm_lapic_reg_write(vcpu->arch.apic, APIC_EOI, 0);
+	 *   - arch/x86/kvm/lapic.c|2667| <<kvm_apic_write_nodecode>> kvm_lapic_reg_write(apic, offset, (u32)val);
+	 *   - arch/x86/kvm/lapic.c|3496| <<kvm_lapic_msr_write>> return kvm_lapic_reg_write(apic, reg, (u32)data);
+	 *   - arch/x86/kvm/svm/avic.c|665| <<avic_unaccel_trap_write>> kvm_lapic_reg_write(apic, offset, kvm_lapic_get_reg(apic, offset));
+	 */
 	return kvm_lapic_reg_write(apic, reg, (u32)data);
 }
 
@@ -3010,6 +5019,13 @@ int kvm_lapic_enable_pv_eoi(struct kvm_vcpu *vcpu, u64 data, unsigned long len)
 	return kvm_gfn_to_hva_cache_init(vcpu->kvm, ghc, addr, new_len);
 }
 
+/*
+ * 在以下使用kvm_apic_accept_events():
+ *   - arch/x86/kvm/x86.c|10552| <<vcpu_enter_guest>> r = kvm_apic_accept_events(vcpu);
+ *   - arch/x86/kvm/x86.c|10877| <<vcpu_block>> if (kvm_apic_accept_events(vcpu) < 0)
+ *   - arch/x86/kvm/x86.c|11077| <<kvm_arch_vcpu_ioctl_run>> if (kvm_apic_accept_events(vcpu) < 0) {
+ *   - arch/x86/kvm/x86.c|11313| <<kvm_arch_vcpu_ioctl_get_mpstate>> r = kvm_apic_accept_events(vcpu);
+ */
 int kvm_apic_accept_events(struct kvm_vcpu *vcpu)
 {
 	struct kvm_lapic *apic = vcpu->arch.apic;
@@ -3058,6 +5074,15 @@ int kvm_apic_accept_events(struct kvm_vcpu *vcpu)
 
 	if (test_bit(KVM_APIC_INIT, &pe)) {
 		clear_bit(KVM_APIC_INIT, &apic->pending_events);
+		/*
+		 * 在以下使用:
+		 *   - arch/x86/kvm/lapic.c|3537| <<kvm_apic_accept_events>> kvm_vcpu_reset(vcpu, true);
+		 *   - arch/x86/kvm/svm/svm.c|2230| <<shutdown_interception>> kvm_vcpu_reset(vcpu, true);
+		 *   - arch/x86/kvm/x86.c|11655| <<kvm_arch_vcpu_create>> kvm_vcpu_reset(vcpu, false);
+		 *
+		 * 只在VM里面online/offline也会调用kvm_vcpu_reset()
+		 * online的时候调用
+		 */
 		kvm_vcpu_reset(vcpu, true);
 		if (kvm_vcpu_is_bsp(apic->vcpu))
 			vcpu->arch.mp_state = KVM_MP_STATE_RUNNABLE;
diff --git a/arch/x86/kvm/lapic.h b/arch/x86/kvm/lapic.h
index ee42eef92f32..bae8a76de911 100644
--- a/arch/x86/kvm/lapic.h
+++ b/arch/x86/kvm/lapic.h
@@ -38,6 +38,13 @@ struct kvm_timer {
 	u64 tscdeadline;
 	u64 expired_tscdeadline;
 	u32 timer_advance_ns;
+	/*
+	 * 在以下使用kvm_timer->advance_expire_delta:
+	 *   - arch/x86/kvm/lapic.c|2382| <<__kvm_wait_lapic_expire>> apic->lapic_timer.advance_expire_delta = guest_tsc - tsc_deadline;
+	 *   - arch/x86/kvm/lapic.c|2385| <<__kvm_wait_lapic_expire>> adjust_lapic_timer_advance(vcpu, apic->lapic_timer.advance_expire_delta);
+	 *   - arch/x86/kvm/x86.c|10872| <<vcpu_enter_guest>> s64 delta = vcpu->arch.apic->lapic_timer.advance_expire_delta;
+	 *   - arch/x86/kvm/x86.c|10875| <<vcpu_enter_guest>> vcpu->arch.apic->lapic_timer.advance_expire_delta = S64_MIN;
+	 */
 	s64 advance_expire_delta;
 	atomic_t pending;			/* accumulated triggered timers */
 	bool hv_timer_in_use;
@@ -49,11 +56,53 @@ struct kvm_lapic {
 	struct kvm_timer lapic_timer;
 	u32 divide_count;
 	struct kvm_vcpu *vcpu;
+	/*
+	 * 在以下使用kvm_lapic->sw_enabled:
+	 *   - arch/x86/kvm/lapic.c|474| <<apic_set_spiv>> if (enabled != apic->sw_enabled) {
+	 *   - arch/x86/kvm/lapic.c|475| <<apic_set_spiv>> apic->sw_enabled = enabled;
+	 *   - arch/x86/kvm/lapic.c|2899| <<kvm_free_lapic>> if (!apic->sw_enabled)
+	 *   - arch/x86/kvm/lapic.h|260| <<kvm_apic_sw_enabled>> return apic->sw_enabled;
+	 */
 	bool sw_enabled;
+	/*
+	 * 在以下使用kvm_lapic->irr_pending:
+	 *   - arch/x86/kvm/lapic.c|530| <<kvm_apic_update_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|548| <<apic_find_highest_irr>> if (!apic->irr_pending)
+	 *   - arch/x86/kvm/lapic.c|569| <<apic_clear_irr>> apic->irr_pending = false;
+	 *   - arch/x86/kvm/lapic.c|572| <<apic_clear_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|2519| <<kvm_apic_update_apicv>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|2968| <<apic_sync_pv_eoi_to_guest>> apic->irr_pending ||
+	 *   - arch/x86/kvm/lapic.h|154| <<kvm_lapic_set_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/svm/avic.c|434| <<avic_kick_target_vcpus_fast>> target_vcpu->arch.apic->irr_pending = true;
+	 *   - arch/x86/kvm/svm/avic.c|482| <<avic_kick_target_vcpus>> vcpu->arch.apic->irr_pending = true;
+	 *
+	 * 理论上来说:
+	 * irr_pending is always true when apicv is activated.
+	 */
 	bool irr_pending;
 	bool lvt0_in_nmi_mode;
+	/*
+	 * 在以下使用kvm_lapic->isr_count:
+	 *   - arch/x86/kvm/lapic.c|657| <<apic_set_isr>> ++apic->isr_count;
+	 *   - arch/x86/kvm/lapic.c|658| <<apic_set_isr>> BUG_ON(apic->isr_count > MAX_APIC_VECTOR);
+	 *   - arch/x86/kvm/lapic.c|684| <<apic_find_highest_isr>> if (!apic->isr_count)
+	 *   - arch/x86/kvm/lapic.c|718| <<apic_clear_isr>> --apic->isr_count;
+	 *   - arch/x86/kvm/lapic.c|719| <<apic_clear_isr>> BUG_ON(apic->isr_count < 0);
+	 *   - arch/x86/kvm/lapic.c|2631| <<kvm_apic_update_apicv>> apic->isr_count = 1;
+	 *   - arch/x86/kvm/lapic.c|2639| <<kvm_apic_update_apicv>> apic->isr_count = count_vectors(apic->regs + APIC_ISR);
+	 */
 	/* Number of bits set in ISR. */
 	s16 isr_count;
+	/*
+	 * 在以下使用kvm_lapic->highest_isr_cache:
+	 *   - arch/x86/kvm/lapic.c|675| <<apic_set_isr>> apic->highest_isr_cache = vec;
+	 *   - arch/x86/kvm/lapic.c|697| <<apic_find_highest_isr>> if (likely(apic->highest_isr_cache != -1))
+	 *   - arch/x86/kvm/lapic.c|698| <<apic_find_highest_isr>> return apic->highest_isr_cache;
+	 *   - arch/x86/kvm/lapic.c|734| <<apic_clear_isr>> apic->highest_isr_cache = -1;
+	 *   - arch/x86/kvm/lapic.c|2669| <<kvm_apic_update_apicv>> apic->highest_isr_cache = -1;
+	 *   - arch/x86/kvm/lapic.c|3170| <<apic_sync_pv_eoi_to_guest>> apic->highest_isr_cache == -1 ||
+	 *   - arch/x86/kvm/lapic.c|3172| <<apic_sync_pv_eoi_to_guest>> kvm_ioapic_handles_vector(apic, apic->highest_isr_cache)) {
+	 */
 	/* The highest vector set in ISR; if -1 - invalid, must scan ISR. */
 	int highest_isr_cache;
 	/**
@@ -64,6 +113,25 @@ struct kvm_lapic {
 	void *regs;
 	gpa_t vapic_addr;
 	struct gfn_to_hva_cache vapic_cache;
+	/*
+	 * 在以下使用kvm_lapic->pending_events:
+	 *   - arch/x86/kvm/lapic.c|2034| <<__apic_accept_irq>> apic->pending_events = (1UL << KVM_APIC_INIT);
+	 *   - arch/x86/kvm/lapic.c|2045| <<__apic_accept_irq>> set_bit(KVM_APIC_SIPI, &apic->pending_events);
+	 *   - arch/x86/kvm/lapic.c|4675| <<kvm_apic_accept_events>> pe = smp_load_acquire(&apic->pending_events);
+	 *   - arch/x86/kvm/lapic.c|4703| <<kvm_apic_accept_events>> clear_bit(KVM_APIC_SIPI, &apic->pending_events);
+	 *   - arch/x86/kvm/lapic.c|4708| <<kvm_apic_accept_events>> clear_bit(KVM_APIC_INIT, &apic->pending_events);
+	 *   - arch/x86/kvm/lapic.c|4725| <<kvm_apic_accept_events>> clear_bit(KVM_APIC_SIPI, &apic->pending_events);
+	 *   - arch/x86/kvm/lapic.h|465| <<kvm_apic_has_events>> return lapic_in_kernel(vcpu) && vcpu->arch.apic->pending_events;
+	 *   - arch/x86/kvm/lapic.h|476| <<kvm_lapic_latched_init>> return lapic_in_kernel(vcpu) && test_bit(KVM_APIC_INIT, &vcpu->arch.apic->pending_events);
+	 *   - arch/x86/kvm/svm/nested.c|1292| <<svm_check_nested_events>> test_bit(KVM_APIC_INIT, &apic->pending_events)) {
+	 *   - arch/x86/kvm/vmx/nested.c|3949| <<vmx_check_nested_events>> test_bit(KVM_APIC_INIT, &apic->pending_events)) {
+	 *   - arch/x86/kvm/vmx/nested.c|3953| <<vmx_check_nested_events>> clear_bit(KVM_APIC_INIT, &apic->pending_events);
+	 *   - arch/x86/kvm/vmx/nested.c|3960| <<vmx_check_nested_events>> test_bit(KVM_APIC_SIPI, &apic->pending_events)) {
+	 *   - arch/x86/kvm/vmx/nested.c|3964| <<vmx_check_nested_events>> clear_bit(KVM_APIC_SIPI, &apic->pending_events);
+	 *   - arch/x86/kvm/x86.c|5198| <<kvm_vcpu_ioctl_x86_set_vcpu_events>> set_bit(KVM_APIC_INIT, &vcpu->arch.apic->pending_events);
+	 *   - arch/x86/kvm/x86.c|5200| <<kvm_vcpu_ioctl_x86_set_vcpu_events>> clear_bit(KVM_APIC_INIT, &vcpu->arch.apic->pending_events);
+	 *   - arch/x86/kvm/x86.c|11890| <<kvm_arch_vcpu_ioctl_set_mpstate>> set_bit(KVM_APIC_SIPI, &vcpu->arch.apic->pending_events);
+	 */
 	unsigned long pending_events;
 	unsigned int sipi_vector;
 };
@@ -134,19 +202,50 @@ void kvm_lapic_exit(void);
 #define VEC_POS(v) ((v) & (32 - 1))
 #define REG_POS(v) (((v) >> 5) << 4)
 
+/*
+ * 在以下使用kvm_lapic_clear_vector():
+ *   - arch/x86/kvm/lapic.c|1057| <<apic_clear_irr>> kvm_lapic_clear_vector(vec, apic->regs + APIC_IRR);
+ *   - arch/x86/kvm/lapic.c|1077| <<apic_clear_irr>> kvm_lapic_clear_vector(vec, apic->regs + APIC_IRR);
+ *   - arch/x86/kvm/lapic.c|2133| <<__apic_accept_irq>> kvm_lapic_clear_vector(vector, apic->regs + APIC_TMR);
+ */
 static inline void kvm_lapic_clear_vector(int vec, void *bitmap)
 {
 	clear_bit(VEC_POS(vec), (bitmap) + REG_POS(vec));
 }
 
+/*
+ * 在以下使用kvm_lapic_set_vector():
+ *   - arch/x86/kvm/lapic.c|2130| <<__apic_accept_irq>> kvm_lapic_set_vector(vector, apic->regs + APIC_TMR);
+ *   - arch/x86/kvm/lapic.h|217| <<kvm_lapic_set_irr>> kvm_lapic_set_vector(vec, apic->regs + APIC_IRR);
+ */
 static inline void kvm_lapic_set_vector(int vec, void *bitmap)
 {
 	set_bit(VEC_POS(vec), (bitmap) + REG_POS(vec));
 }
 
+/*
+ * 在以下使用kvm_lapic_set_irr():
+ *   - arch/x86/kvm/svm/svm.c|3736| <<svm_deliver_interrupt>> kvm_lapic_set_irr(vector, apic);
+ *   - arch/x86/kvm/vmx/vmx.c|4257| <<vmx_deliver_interrupt>> kvm_lapic_set_irr(vector, apic);
+ */
 static inline void kvm_lapic_set_irr(int vec, struct kvm_lapic *apic)
 {
 	kvm_lapic_set_vector(vec, apic->regs + APIC_IRR);
+	/*
+	 * 在以下使用kvm_lapic->irr_pending:
+	 *   - arch/x86/kvm/lapic.c|530| <<kvm_apic_update_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|548| <<apic_find_highest_irr>> if (!apic->irr_pending)
+	 *   - arch/x86/kvm/lapic.c|569| <<apic_clear_irr>> apic->irr_pending = false;
+	 *   - arch/x86/kvm/lapic.c|572| <<apic_clear_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|2519| <<kvm_apic_update_apicv>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/lapic.c|2968| <<apic_sync_pv_eoi_to_guest>> apic->irr_pending ||
+	 *   - arch/x86/kvm/lapic.h|154| <<kvm_lapic_set_irr>> apic->irr_pending = true;
+	 *   - arch/x86/kvm/svm/avic.c|434| <<avic_kick_target_vcpus_fast>> target_vcpu->arch.apic->irr_pending = true;
+	 *   - arch/x86/kvm/svm/avic.c|482| <<avic_kick_target_vcpus>> vcpu->arch.apic->irr_pending = true;
+	 *
+	 * 理论上来说:
+	 * irr_pending is always true when apicv is activated.
+	 */
 	/*
 	 * irr_pending must be true if any interrupt is pending; set it after
 	 * APIC_IRR to avoid race with apic_clear_irr
@@ -173,10 +272,66 @@ static inline bool lapic_in_kernel(struct kvm_vcpu *vcpu)
 	return true;
 }
 
+/*
+ * | 项目                 | MSR_IA32_APICBASE       | SPIV (0xF0)                |
+ * | ------------------ | ------------------------- | -------------------------- |
+ * | 控制粒度               | 硬件级,全局关闭                  | 软件级,关闭中断处理                 |
+ * | 生效范围               | 关闭整个 Local APIC           | 保留结构但不响应中断                 |
+ * | 通常使用时机             | BIOS,操作系统启动阶段             | 操作系统运行时                    |
+ * | 会影响 APIC MMIO 寄存器吗 | 是,APIC 基址无效后不能访问 APIC 寄存器 | 否,仍然可访问 APIC 寄存器           |
+ * | 对中断的影响             | 完全禁用中断(包括 INIT, STARTUP)  | 仅禁用普通中断,某些特殊中断(如 NMI)有效    |
+ * | 典型用途               | 内核初始化前设置,关闭 SMP 支持        | 操作系统禁用中断(如使用 IOAPIC 或 PIC) |
+ *
+ *
+ * 如果你只把SPIV 的使能位关掉(即SPIV[8]=0),CPU不会响应普通中断,但Local APIC结构还在,
+ * 依然可以接收INIT或IPI等特殊信号.
+ *
+ * 如果你把MSR_IA32_APICBASE[11]=0,则整个Local APIC被禁用,APIC MMIO区也不能访问,
+ * 连 INIT,STARTUP都可能无法正确使用.
+ */
+
 extern struct static_key_false_deferred apic_hw_disabled;
 
+/*
+ * 在以下调用kvm_apic_hw_enabled():
+ *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+ *   - arch/x86/kvm/lapic.c|2040| <<apic_mmio_read>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+ *   - arch/x86/kvm/lapic.c|2125| <<lapic_timer_int_injected>> if (kvm_apic_hw_enabled(apic)) {
+ *   - arch/x86/kvm/lapic.c|2809| <<apic_mmio_write>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+ *   - arch/x86/kvm/lapic.c|3330| <<kvm_apic_local_deliver>> if (kvm_apic_hw_enabled(apic) && !(reg & APIC_LVT_MASKED)) {
+ *   - arch/x86/kvm/lapic.c|3443| <<kvm_apic_accept_pic_intr>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+ *   - arch/x86/kvm/lapic.h|246| <<kvm_apic_present>> return lapic_in_kernel(vcpu) && kvm_apic_hw_enabled(vcpu->arch.apic);
+ *   - arch/x86/kvm/x86.c|10218| <<vcpu_load_eoi_exitmap>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+ */
 static inline int kvm_apic_hw_enabled(struct kvm_lapic *apic)
 {
+	/*
+	 * 在以下使用apic_hw_disabled:
+	 *   - arch/x86/kvm/lapic.c|190| <<global>> __read_mostly DEFINE_STATIC_KEY_DEFERRED_FALSE(apic_hw_disabled, HZ);
+	 *   - arch/x86/kvm/lapic.c|3253| <<kvm_free_lapic>> static_branch_slow_dec_deferred(&apic_hw_disabled);
+	 *   - arch/x86/kvm/lapic.c|3460| <<kvm_lapic_set_base>> static_branch_slow_dec_deferred(&apic_hw_disabled);
+	 *   - arch/x86/kvm/lapic.c|3472| <<kvm_lapic_set_base>> static_branch_inc(&apic_hw_disabled.key);
+	 *   - arch/x86/kvm/lapic.c|4580| <<kvm_lapic_exit>> static_key_deferred_flush(&apic_hw_disabled);
+	 *   - arch/x86/kvm/lapic.c|4581| <<kvm_lapic_exit>> WARN_ON(static_branch_unlikely(&apic_hw_disabled.key));
+	 *   - arch/x86/kvm/lapic.h|290| <<kvm_apic_hw_enabled>> if (static_branch_unlikely(&apic_hw_disabled.key))
+	 *
+	 *
+	 * 在以下设置kvm_vcpu_arch->apic_base (看似修改的地方):
+	 *   - arch/x86/kvm/lapic.c|2926| <<kvm_lapic_set_base>> vcpu->arch.apic_base = value;
+	 *   - arch/x86/kvm/lapic.c|3256| <<kvm_create_lapic>> vcpu->arch.apic_base = MSR_IA32_APICBASE_ENABLE;
+	 * 在以下使用kvm_vcpu_arch->apic_base:
+	 *   - arch/x86/kvm/cpuid.c|222| <<__kvm_update_cpuid_runtime>> cpuid_entry_change(best, X86_FEATURE_APIC, vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE);
+	 *   - arch/x86/kvm/lapic.c|2862| <<kvm_free_lapic>> if (!(vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE))
+	 *   - arch/x86/kvm/lapic.c|2923| <<kvm_lapic_set_base>> u64 old_value = vcpu->arch.apic_base;
+	 *   - arch/x86/kvm/lapic.c|2974| <<kvm_lapic_set_base>> apic->base_address = apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_BASE;
+	 *   - arch/x86/kvm/lapic.c|3454| <<kvm_apic_set_state>> kvm_lapic_set_base(vcpu, vcpu->arch.apic_base);
+	 *   - arch/x86/kvm/lapic.h|231| <<kvm_apic_hw_enabled>> return apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE;
+	 *   - arch/x86/kvm/lapic.h|256| <<apic_x2apic_mode>> return apic->vcpu->arch.apic_base & X2APIC_ENABLE;
+	 *   - arch/x86/kvm/lapic.h|300| <<kvm_apic_mode>> return apic_base & (MSR_IA32_APICBASE_ENABLE | X2APIC_ENABLE);
+	 *   - arch/x86/kvm/vmx/nested.c|878| <<nested_vmx_msr_check_common>> if (CC(vcpu->arch.apic_base & X2APIC_ENABLE && e->index >> 8 == 0x8))
+	 *   - arch/x86/kvm/x86.c|466| <<kvm_get_apic_base>> return vcpu->arch.apic_base;
+	 *   - arch/x86/kvm/x86.c|12215| <<kvm_vcpu_is_bsp>> return (vcpu->arch.apic_base & MSR_IA32_APICBASE_BSP) != 0;
+	 */
 	if (static_branch_unlikely(&apic_hw_disabled.key))
 		return apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE;
 	return MSR_IA32_APICBASE_ENABLE;
@@ -184,35 +339,188 @@ static inline int kvm_apic_hw_enabled(struct kvm_lapic *apic)
 
 extern struct static_key_false_deferred apic_sw_disabled;
 
+/*
+ * 在以下使用kvm_apic_sw_enabled():
+ *   - arch/x86/kvm/irq_comm.c|95| <<kvm_irq_delivery_to_apic>> } else if (kvm_apic_sw_enabled(vcpu->arch.apic)) {
+ *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+ *   - arch/x86/kvm/lapic.c|424| <<kvm_recalculate_apic_map>> if (!kvm_apic_sw_enabled(apic))
+ *   - arch/x86/kvm/lapic.c|2720| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+ *   - arch/x86/kvm/lapic.c|2731| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+ *   - arch/x86/kvm/lapic.h|251| <<kvm_lapic_enabled>> return kvm_apic_present(vcpu) && kvm_apic_sw_enabled(vcpu->arch.apic);
+ */
 static inline bool kvm_apic_sw_enabled(struct kvm_lapic *apic)
 {
+	/*
+	 * 在以下使用apic_sw_disabled:
+	 *   - arch/x86/kvm/lapic.c|191| <<global>> __read_mostly DEFINE_STATIC_KEY_DEFERRED_FALSE(apic_sw_disabled, HZ);
+	 *   - arch/x86/kvm/lapic.c|599| <<apic_set_spiv>> static_branch_slow_dec_deferred(&apic_sw_disabled);
+	 *   - arch/x86/kvm/lapic.c|601| <<apic_set_spiv>> static_branch_inc(&apic_sw_disabled.key);
+	 *   - arch/x86/kvm/lapic.c|3263| <<kvm_free_lapic>> static_branch_slow_dec_deferred(&apic_sw_disabled);
+	 *   - arch/x86/kvm/lapic.c|3840| <<kvm_create_lapic>> static_branch_inc(&apic_sw_disabled.key);
+	 *   - arch/x86/kvm/lapic.c|4582| <<kvm_lapic_exit>> static_key_deferred_flush(&apic_sw_disabled);
+	 *   - arch/x86/kvm/lapic.c|4583| <<kvm_lapic_exit>> WARN_ON(static_branch_unlikely(&apic_sw_disabled.key));
+	 *   - arch/x86/kvm/lapic.h|315| <<kvm_apic_sw_enabled>> if (static_branch_unlikely(&apic_sw_disabled.key))
+	 *
+	 *
+	 * 在以下使用kvm_lapic->sw_enabled:
+	 *   - arch/x86/kvm/lapic.c|474| <<apic_set_spiv>> if (enabled != apic->sw_enabled) {
+	 *   - arch/x86/kvm/lapic.c|475| <<apic_set_spiv>> apic->sw_enabled = enabled;
+	 *   - arch/x86/kvm/lapic.c|2899| <<kvm_free_lapic>> if (!apic->sw_enabled)
+	 *   - arch/x86/kvm/lapic.h|260| <<kvm_apic_sw_enabled>> return apic->sw_enabled;
+	 */
 	if (static_branch_unlikely(&apic_sw_disabled.key))
 		return apic->sw_enabled;
 	return true;
 }
 
+/*
+ * | 项目                 | MSR_IA32_APICBASE       | SPIV (0xF0)                |
+ * | ------------------ | ------------------------- | -------------------------- |
+ * | 控制粒度               | 硬件级,全局关闭                  | 软件级,关闭中断处理                 |
+ * | 生效范围               | 关闭整个 Local APIC           | 保留结构但不响应中断                 |
+ * | 通常使用时机             | BIOS,操作系统启动阶段             | 操作系统运行时                    |
+ * | 会影响 APIC MMIO 寄存器吗 | 是,APIC 基址无效后不能访问 APIC 寄存器 | 否,仍然可访问 APIC 寄存器           |
+ * | 对中断的影响             | 完全禁用中断(包括 INIT, STARTUP)  | 仅禁用普通中断,某些特殊中断(如 NMI)有效    |
+ * | 典型用途               | 内核初始化前设置,关闭 SMP 支持        | 操作系统禁用中断(如使用 IOAPIC 或 PIC) |
+ *
+ *
+ * 如果你只把SPIV 的使能位关掉(即SPIV[8]=0),CPU不会响应普通中断,但Local APIC结构还在,
+ * 依然可以接收INIT或IPI等特殊信号.
+ *
+ * 如果你把MSR_IA32_APICBASE[11]=0,则整个Local APIC被禁用,APIC MMIO区也不能访问,
+ * 连 INIT,STARTUP都可能无法正确使用.
+ *
+ *
+ * 在以下调用kvm_apic_present():
+ *   - arch/x86/kvm/irq_comm.c|65| <<kvm_irq_delivery_to_apic>> if (!kvm_apic_present(vcpu))
+ *   - arch/x86/kvm/irq_comm.c|384| <<kvm_intr_is_single_vcpu>> if (!kvm_apic_present(vcpu))
+ *   - arch/x86/kvm/lapic.c|373| <<kvm_recalculate_apic_map>> if (kvm_apic_present(vcpu))
+ *   - arch/x86/kvm/lapic.c|393| <<kvm_recalculate_apic_map>> if (!kvm_apic_present(vcpu))
+ *   - arch/x86/kvm/lapic.c|1764| <<kvm_bitmap_or_dest_vcpus>> if (!kvm_apic_present(vcpu))
+ *   - arch/x86/kvm/lapic.c|2985| <<kvm_get_lapic_tscdeadline_msr>> if (!kvm_apic_present(vcpu) || !apic_lvtt_tscdeadline(apic))
+ *   - arch/x86/kvm/lapic.c|2995| <<kvm_set_lapic_tscdeadline_msr>> if (!kvm_apic_present(vcpu) || !apic_lvtt_tscdeadline(apic))
+ *   - arch/x86/kvm/lapic.c|3501| <<kvm_apic_has_interrupt>> if (!kvm_apic_present(vcpu))
+ *   - arch/x86/kvm/lapic.h|346| <<kvm_lapic_enabled>> return kvm_apic_present(vcpu) && kvm_apic_sw_enabled(vcpu->arch.apic);
+ *   - arch/x86/kvm/x86.c|10149| <<vcpu_scan_ioapic>> if (!kvm_apic_present(vcpu))
+ */
 static inline bool kvm_apic_present(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下调用kvm_apic_hw_enabled():
+	 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+	 *   - arch/x86/kvm/lapic.c|2040| <<apic_mmio_read>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2125| <<lapic_timer_int_injected>> if (kvm_apic_hw_enabled(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2809| <<apic_mmio_write>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|3330| <<kvm_apic_local_deliver>> if (kvm_apic_hw_enabled(apic) && !(reg & APIC_LVT_MASKED)) {
+	 *   - arch/x86/kvm/lapic.c|3443| <<kvm_apic_accept_pic_intr>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 *   - arch/x86/kvm/lapic.h|246| <<kvm_apic_present>> return lapic_in_kernel(vcpu) && kvm_apic_hw_enabled(vcpu->arch.apic);
+	 *   - arch/x86/kvm/x86.c|10218| <<vcpu_load_eoi_exitmap>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 */
 	return lapic_in_kernel(vcpu) && kvm_apic_hw_enabled(vcpu->arch.apic);
 }
 
+/*
+ * 在以下使用kvm_lapic_enabled():
+ *   - arch/x86/kvm/x86.c|10495| <<vcpu_enter_guest>> if (kvm_lapic_enabled(vcpu)) {
+ *   - arch/x86/kvm/x86.c|10555| <<vcpu_enter_guest>> if (kvm_lapic_enabled(vcpu))
+ *   - arch/x86/kvm/x86.c|10620| <<vcpu_enter_guest>> if (kvm_lapic_enabled(vcpu))
+ *   - arch/x86/kvm/x86.c|13109| <<kvm_arch_can_dequeue_async_page_present>> return kvm_lapic_enabled(vcpu) && apf_pageready_slot_free(vcpu);
+ */
 static inline int kvm_lapic_enabled(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用kvm_apic_sw_enabled():
+	 *   - arch/x86/kvm/irq_comm.c|95| <<kvm_irq_delivery_to_apic>> } else if (kvm_apic_sw_enabled(vcpu->arch.apic)) {
+	 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+	 *   - arch/x86/kvm/lapic.c|424| <<kvm_recalculate_apic_map>> if (!kvm_apic_sw_enabled(apic))
+	 *   - arch/x86/kvm/lapic.c|2720| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+	 *   - arch/x86/kvm/lapic.c|2731| <<kvm_lapic_reg_write>> if (!kvm_apic_sw_enabled(apic))
+	 *   - arch/x86/kvm/lapic.h|251| <<kvm_lapic_enabled>> return kvm_apic_present(vcpu) && kvm_apic_sw_enabled(vcpu->arch.apic);
+	 */
 	return kvm_apic_present(vcpu) && kvm_apic_sw_enabled(vcpu->arch.apic);
 }
 
 static inline int apic_x2apic_mode(struct kvm_lapic *apic)
 {
+	/*
+	 * 在以下设置kvm_vcpu_arch->apic_base (看似修改的地方):
+	 *   - arch/x86/kvm/lapic.c|2926| <<kvm_lapic_set_base>> vcpu->arch.apic_base = value;
+	 *   - arch/x86/kvm/lapic.c|3256| <<kvm_create_lapic>> vcpu->arch.apic_base = MSR_IA32_APICBASE_ENABLE;
+	 * 在以下使用kvm_vcpu_arch->apic_base:
+	 *   - arch/x86/kvm/cpuid.c|222| <<__kvm_update_cpuid_runtime>> cpuid_entry_change(best, X86_FEATURE_APIC, vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE);
+	 *   - arch/x86/kvm/lapic.c|2862| <<kvm_free_lapic>> if (!(vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE))
+	 *   - arch/x86/kvm/lapic.c|2923| <<kvm_lapic_set_base>> u64 old_value = vcpu->arch.apic_base;
+	 *   - arch/x86/kvm/lapic.c|2974| <<kvm_lapic_set_base>> apic->base_address = apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_BASE;
+	 *   - arch/x86/kvm/lapic.c|3454| <<kvm_apic_set_state>> kvm_lapic_set_base(vcpu, vcpu->arch.apic_base);
+	 *   - arch/x86/kvm/lapic.h|231| <<kvm_apic_hw_enabled>> return apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE;
+	 *   - arch/x86/kvm/lapic.h|256| <<apic_x2apic_mode>> return apic->vcpu->arch.apic_base & X2APIC_ENABLE;
+	 *   - arch/x86/kvm/lapic.h|300| <<kvm_apic_mode>> return apic_base & (MSR_IA32_APICBASE_ENABLE | X2APIC_ENABLE);
+	 *   - arch/x86/kvm/vmx/nested.c|878| <<nested_vmx_msr_check_common>> if (CC(vcpu->arch.apic_base & X2APIC_ENABLE && e->index >> 8 == 0x8))
+	 *   - arch/x86/kvm/x86.c|466| <<kvm_get_apic_base>> return vcpu->arch.apic_base;
+	 *   - arch/x86/kvm/x86.c|12215| <<kvm_vcpu_is_bsp>> return (vcpu->arch.apic_base & MSR_IA32_APICBASE_BSP) != 0;
+	 */
 	return apic->vcpu->arch.apic_base & X2APIC_ENABLE;
 }
 
+/*
+ * 在以下使用kvm_vcpu_apicv_active():
+ *   - arch/x86/kvm/irq.c|89| <<kvm_cpu_has_injectable_intr>> if (!is_guest_mode(v) && kvm_vcpu_apicv_active(v))
+ *   - arch/x86/kvm/lapic.c|221| <<kvm_can_post_timer_interrupt>> return pi_inject_timer && kvm_vcpu_apicv_active(vcpu) &&
+ *   - arch/x86/kvm/svm/avic.c|964| <<avic_pi_update_irte>> kvm_vcpu_apicv_active(&svm->vcpu)) {
+ *   - arch/x86/kvm/svm/avic.c|1183| <<avic_refresh_apicv_exec_ctrl>> bool activated = kvm_vcpu_apicv_active(vcpu);
+ *   - arch/x86/kvm/svm/avic.c|1213| <<avic_vcpu_blocking>> if (!kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/svm/avic.c|1234| <<avic_vcpu_unblocking>> if (!kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/svm/nested.c|728| <<enter_svm_guest_mode>> if (kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/svm/svm.c|1307| <<init_vmcb>> if (!kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/svm/svm.c|1422| <<init_vmcb>> if (kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/svm/svm.c|1618| <<svm_vcpu_load>> if (kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/svm/svm.c|1624| <<svm_vcpu_put>> if (kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/svm/svm.c|3946| <<sync_lapic_to_cr8>> kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/vmx/nested.c|3402| <<nested_vmx_enter_non_root_mode>> if (likely(!evaluate_pending_interrupts) && kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/vmx/vmx.c|3984| <<vmx_update_msr_bitmap_x2apic>> if (enable_apicv && kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/vmx/vmx.c|4256| <<vmx_pin_based_exec_ctrl>> if (!kvm_vcpu_apicv_active(&vmx->vcpu))
+ *   - arch/x86/kvm/vmx/vmx.c|4303| <<vmx_refresh_apicv_exec_ctrl>> if (kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/vmx/vmx.c|4418| <<vmx_secondary_exec_control>> if (!kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/vmx/vmx.c|4511| <<init_vmcs>> if (kvm_vcpu_apicv_active(&vmx->vcpu)) {
+ *   - arch/x86/kvm/vmx/vmx.c|6613| <<vmx_sync_pir_to_irr>> if (!is_guest_mode(vcpu) && kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/vmx/vmx.c|6630| <<vmx_load_eoi_exitmap>> if (!kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/x86.c|10602| <<vcpu_enter_guest>> WARN_ON_ONCE((kvm_vcpu_apicv_activated(vcpu) != kvm_vcpu_apicv_active(vcpu)) &&
+ */
 static inline bool kvm_vcpu_apicv_active(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下设置kvm_vcpu_arch->apicv_active:
+	 *   - arch/x86/kvm/x86.c|9800| <<kvm_vcpu_update_apicv>> vcpu->arch.apicv_active = activate;
+	 *   - arch/x86/kvm/x86.c|11393| <<kvm_arch_vcpu_create>> vcpu->arch.apicv_active = true;
+	 */
 	return vcpu->arch.apic && vcpu->arch.apicv_active;
 }
 
+/*
+ * 在以下使用kvm_apic_has_events():
+ *   - arch/x86/kvm/x86.c|12773| <<kvm_vcpu_has_events>> if (kvm_apic_has_events(vcpu))
+ */
 static inline bool kvm_apic_has_events(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用kvm_lapic->pending_events:
+	 *   - arch/x86/kvm/lapic.c|2034| <<__apic_accept_irq>> apic->pending_events = (1UL << KVM_APIC_INIT);
+	 *   - arch/x86/kvm/lapic.c|2045| <<__apic_accept_irq>> set_bit(KVM_APIC_SIPI, &apic->pending_events);
+	 *   - arch/x86/kvm/lapic.c|4675| <<kvm_apic_accept_events>> pe = smp_load_acquire(&apic->pending_events);
+	 *   - arch/x86/kvm/lapic.c|4703| <<kvm_apic_accept_events>> clear_bit(KVM_APIC_SIPI, &apic->pending_events);
+	 *   - arch/x86/kvm/lapic.c|4708| <<kvm_apic_accept_events>> clear_bit(KVM_APIC_INIT, &apic->pending_events);
+	 *   - arch/x86/kvm/lapic.c|4725| <<kvm_apic_accept_events>> clear_bit(KVM_APIC_SIPI, &apic->pending_events);
+	 *   - arch/x86/kvm/lapic.h|465| <<kvm_apic_has_events>> return lapic_in_kernel(vcpu) && vcpu->arch.apic->pending_events;
+	 *   - arch/x86/kvm/lapic.h|476| <<kvm_lapic_latched_init>> return lapic_in_kernel(vcpu) && test_bit(KVM_APIC_INIT, &vcpu->arch.apic->pending_events);
+	 *   - arch/x86/kvm/svm/nested.c|1292| <<svm_check_nested_events>> test_bit(KVM_APIC_INIT, &apic->pending_events)) {
+	 *   - arch/x86/kvm/vmx/nested.c|3949| <<vmx_check_nested_events>> test_bit(KVM_APIC_INIT, &apic->pending_events)) {
+	 *   - arch/x86/kvm/vmx/nested.c|3953| <<vmx_check_nested_events>> clear_bit(KVM_APIC_INIT, &apic->pending_events);
+	 *   - arch/x86/kvm/vmx/nested.c|3960| <<vmx_check_nested_events>> test_bit(KVM_APIC_SIPI, &apic->pending_events)) {
+	 *   - arch/x86/kvm/vmx/nested.c|3964| <<vmx_check_nested_events>> clear_bit(KVM_APIC_SIPI, &apic->pending_events);
+	 *   - arch/x86/kvm/x86.c|5198| <<kvm_vcpu_ioctl_x86_set_vcpu_events>> set_bit(KVM_APIC_INIT, &vcpu->arch.apic->pending_events);
+	 *   - arch/x86/kvm/x86.c|5200| <<kvm_vcpu_ioctl_x86_set_vcpu_events>> clear_bit(KVM_APIC_INIT, &vcpu->arch.apic->pending_events);
+	 *   - arch/x86/kvm/x86.c|11890| <<kvm_arch_vcpu_ioctl_set_mpstate>> set_bit(KVM_APIC_SIPI, &vcpu->arch.apic->pending_events);
+	 */
 	return lapic_in_kernel(vcpu) && vcpu->arch.apic->pending_events;
 }
 
diff --git a/arch/x86/kvm/mmu.h b/arch/x86/kvm/mmu.h
index 8669044b1c27..1577233dc1b4 100644
--- a/arch/x86/kvm/mmu.h
+++ b/arch/x86/kvm/mmu.h
@@ -82,6 +82,11 @@ int kvm_mmu_load(struct kvm_vcpu *vcpu);
 void kvm_mmu_unload(struct kvm_vcpu *vcpu);
 void kvm_mmu_sync_roots(struct kvm_vcpu *vcpu);
 
+/*
+ * 在以下使用kvm_mmu_reload():
+ *   - arch/x86/kvm/x86.c|10576| <<vcpu_enter_guest>> r = kvm_mmu_reload(vcpu);
+ *   - arch/x86/kvm/x86.c|13052| <<kvm_arch_async_page_ready>> r = kvm_mmu_reload(vcpu);
+ */
 static inline int kvm_mmu_reload(struct kvm_vcpu *vcpu)
 {
 	if (likely(vcpu->arch.mmu->root_hpa != INVALID_PAGE))
diff --git a/arch/x86/kvm/pmu.c b/arch/x86/kvm/pmu.c
index 62333f9756a3..f622dc146d81 100644
--- a/arch/x86/kvm/pmu.c
+++ b/arch/x86/kvm/pmu.c
@@ -338,6 +338,17 @@ static int kvm_pmu_rdpmc_vmware(struct kvm_vcpu *vcpu, unsigned idx, u64 *data)
 		ctr_val = ktime_get_boottime_ns();
 		break;
 	case VMWARE_BACKDOOR_PMC_APPARENT_TIME:
+		/*
+		 * 在以下设置kvm_arch->kvmclock_offset:
+		 *   - arch/x86/kvm/x86.c|6814| <<kvm_arch_vm_ioctl(KVM_SET_CLOCK)>> ka->kvmclock_offset = user_ns.clock - now_ns;
+		 *   - arch/x86/kvm/x86.c|13280| <<kvm_arch_init_vm>> kvm->arch.kvmclock_offset = -get_kvmclock_base_ns();
+		 * 在以下使用kvm_arch->kvmclock_offset:
+		 *   - arch/x86/kvm/pmu.c|342| <<kvm_pmu_rdpmc_vmware>> ctr_val = ktime_get_boottime_ns() + vcpu->kvm->arch.kvmclock_offset;
+		 *   - arch/x86/kvm/x86.c|3141| <<get_kvmclock_ns>> return get_kvmclock_base_ns() + ka->kvmclock_offset;
+		 *   - arch/x86/kvm/x86.c|3145| <<get_kvmclock_ns>> hv_clock.system_time = ka->master_kernel_ns + ka->kvmclock_offset;
+		 *   - arch/x86/kvm/x86.c|3167| <<get_kvmclock_ns>> ret = get_kvmclock_base_ns() + ka->kvmclock_offset;
+		 *   - arch/x86/kvm/x86.c|3307| <<kvm_guest_time_update>> vcpu->hv_clock.system_time = kernel_ns + v->kvm->arch.kvmclock_offset;
+		 */
 		ctr_val = ktime_get_boottime_ns() +
 			vcpu->kvm->arch.kvmclock_offset;
 		break;
diff --git a/arch/x86/kvm/svm/avic.c b/arch/x86/kvm/svm/avic.c
index df2d33395a48..5a681369c307 100644
--- a/arch/x86/kvm/svm/avic.c
+++ b/arch/x86/kvm/svm/avic.c
@@ -432,6 +432,15 @@ static int avic_kick_target_vcpus_fast(struct kvm *kvm, struct kvm_lapic *source
 		return 0;
 
 	target_vcpu->arch.apic->irr_pending = true;
+	/*
+	 * 在以下使用svm_complete_interrupt_delivery():
+	 *   - arch/x86/kvm/svm/avic.c|435| <<avic_kick_target_vcpus_fast>> svm_complete_interrupt_delivery(target_vcpu,
+	 *              icrl & APIC_MODE_MASK, icrl & APIC_INT_LEVELTRIG, icrl & APIC_VECTOR_MASK);
+	 *   - arch/x86/kvm/svm/avic.c|483| <<avic_kick_target_vcpus>> svm_complete_interrupt_delivery(vcpu,
+	 *              icrl & APIC_MODE_MASK, icrl & APIC_INT_LEVELTRIG, icrl & APIC_VECTOR_MASK);
+	 *   - arch/x86/kvm/svm/svm.c|3698| <<svm_deliver_interrupt>> svm_complete_interrupt_delivery(apic->vcpu,
+	 *              delivery_mode, trig_mode, vector); 
+	 */
 	svm_complete_interrupt_delivery(target_vcpu,
 					icrl & APIC_MODE_MASK,
 					icrl & APIC_INT_LEVELTRIG,
@@ -458,9 +467,37 @@ static void avic_kick_target_vcpus(struct kvm *kvm, struct kvm_lapic *source,
 	 * since entered the guest will have processed pending IRQs at VMRUN.
 	 */
 	kvm_for_each_vcpu(i, vcpu, kvm) {
+		/*
+		 * 在以下调用kvm_apic_match_dest():
+		 *   - arch/x86/kvm/ioapic.c|146| <<__rtc_irq_eoi_tracking_restore_one>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, e->fields.dest_id, kvm_lapic_irq_dest_mode(!!e->fields.dest_mode)))
+		 *   - arch/x86/kvm/ioapic.c|234| <<ioapic_lazy_update_eoi>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, entry->fields.dest_id, entry->fields.dest_mode) ||
+		 *   - arch/x86/kvm/ioapic.c|414| <<kvm_ioapic_scan_entry>> if (kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, e->fields.dest_id, dm) ||
+		 *   - arch/x86/kvm/irq_comm.c|68| <<kvm_irq_delivery_to_apic>> if (!kvm_apic_match_dest(vcpu, src,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/irq_comm.c|359| <<kvm_intr_is_single_vcpu>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/irq_comm.c|442| <<kvm_scan_ioapic_routes>> if (irq.trig_mode && (kvm_apic_match_dest(vcpu, NULL,
+		 *          APIC_DEST_NOSHORT, irq.dest_id, irq.dest_mode) ||
+		 *   - arch/x86/kvm/lapic.c|1262| <<kvm_bitmap_or_dest_vcpus>> if (!kvm_apic_match_dest(vcpu, NULL,
+		 *          irq->shorthand, irq->dest_id, irq->dest_mode))
+		 *   - arch/x86/kvm/svm/avic.c|461| <<avic_kick_target_vcpus>> if (kvm_apic_match_dest(vcpu, source,
+		 *          icrl & APIC_SHORT_MASK, dest, icrl & APIC_DEST_MASK)) {
+		 */
 		if (kvm_apic_match_dest(vcpu, source, icrl & APIC_SHORT_MASK,
 					dest, icrl & APIC_DEST_MASK)) {
 			vcpu->arch.apic->irr_pending = true;
+			/*
+			 * 在以下使用svm_complete_interrupt_delivery():
+			 *   - arch/x86/kvm/svm/avic.c|435| <<avic_kick_target_vcpus_fast>> svm_complete_interrupt_delivery(target_vcpu,
+			 *              icrl & APIC_MODE_MASK, icrl & APIC_INT_LEVELTRIG, icrl & APIC_VECTOR_MASK);
+			 *   - arch/x86/kvm/svm/avic.c|483| <<avic_kick_target_vcpus>> svm_complete_interrupt_delivery(vcpu,
+			 *              icrl & APIC_MODE_MASK, icrl & APIC_INT_LEVELTRIG, icrl & APIC_VECTOR_MASK);
+			 *   - arch/x86/kvm/svm/svm.c|3698| <<svm_deliver_interrupt>> svm_complete_interrupt_delivery(apic->vcpu,
+			 *              delivery_mode, trig_mode, vector); 
+			 */
 			svm_complete_interrupt_delivery(vcpu,
 							icrl & APIC_MODE_MASK,
 							icrl & APIC_INT_LEVELTRIG,
@@ -876,6 +913,14 @@ get_pi_vcpu_info(struct kvm *kvm, struct kvm_kernel_irq_routing_entry *e,
 	struct kvm_lapic_irq irq;
 	struct kvm_vcpu *vcpu = NULL;
 
+	/*
+	 * 在以下使用kvm_set_msi_irq():
+	 *   - arch/x86/kvm/irq_comm.c|226| <<kvm_set_msi>> kvm_set_msi_irq(kvm, e, &irq);
+	 *   - arch/x86/kvm/irq_comm.c|272| <<kvm_arch_set_irq_inatomic>> kvm_set_msi_irq(kvm, e, &irq);
+	 *   - arch/x86/kvm/irq_comm.c|603| <<kvm_scan_ioapic_routes>> kvm_set_msi_irq(vcpu->kvm, entry, &irq);
+	 *   - arch/x86/kvm/svm/avic.c|916| <<get_pi_vcpu_info>> kvm_set_msi_irq(kvm, e, &irq);
+	 *   - arch/x86/kvm/vmx/posted_intr.c|319| <<vmx_pi_update_irte>> kvm_set_msi_irq(kvm, e, &irq);
+	 */
 	kvm_set_msi_irq(kvm, e, &irq);
 
 	if (!kvm_intr_is_single_vcpu(kvm, &irq, &vcpu) ||
@@ -888,6 +933,15 @@ get_pi_vcpu_info(struct kvm *kvm, struct kvm_kernel_irq_routing_entry *e,
 	pr_debug("SVM: %s: use GA mode for irq %u\n", __func__,
 		 irq.vector);
 	*svm = to_svm(vcpu);
+	/*
+	 * 在以下使用vcpu_data->pi_desc_addr:
+	 *   - arch/x86/kvm/svm/avic.c|928| <<get_pi_vcpu_info>> vcpu_info->pi_desc_addr = __sme_set(page_to_phys((*svm)->avic_backing_page));
+	 *   - arch/x86/kvm/svm/avic.c|1035| <<avic_pi_update_irte>> trace_kvm_pi_irte_update(host_irq,... vcpu_info.pi_desc_addr, set);
+	 *   - arch/x86/kvm/vmx/posted_intr.c|337| <<vmx_pi_update_irte>> vcpu_info.pi_desc_addr = __pa(&to_vmx(vcpu)->pi_desc);
+	 *   - arch/x86/kvm/vmx/posted_intr.c|341| <<vmx_pi_update_irte>> trace_kvm_pi_irte_update(host_irq,... vcpu_info.vector, vcpu_info.pi_desc_addr, set);
+	 *   - drivers/iommu/intel/irq_remapping.c|1221| <<intel_ir_set_vcpu_affinity>> irte_pi.pda_l = (vcpu_pi_info->pi_desc_addr >>
+	 *   - drivers/iommu/intel/irq_remapping.c|1223| <<intel_ir_set_vcpu_affinity>> irte_pi.pda_h = (vcpu_pi_info->pi_desc_addr >> 32) &
+	 */
 	vcpu_info->pi_desc_addr = __sme_set(page_to_phys((*svm)->avic_backing_page));
 	vcpu_info->vector = irq.vector;
 
@@ -993,6 +1047,15 @@ int avic_pi_update_irte(struct kvm *kvm, unsigned int host_irq,
 		}
 
 		if (!ret && svm) {
+			/*
+			 * 在以下使用vcpu_data->pi_desc_addr:
+			 *   - arch/x86/kvm/svm/avic.c|928| <<get_pi_vcpu_info>> vcpu_info->pi_desc_addr = __sme_set(page_to_phys((*svm)->avic_backing_page));
+			 *   - arch/x86/kvm/svm/avic.c|1035| <<avic_pi_update_irte>> trace_kvm_pi_irte_update(host_irq,... vcpu_info.pi_desc_addr, set);
+			 *   - arch/x86/kvm/vmx/posted_intr.c|337| <<vmx_pi_update_irte>> vcpu_info.pi_desc_addr = __pa(&to_vmx(vcpu)->pi_desc);
+			 *   - arch/x86/kvm/vmx/posted_intr.c|341| <<vmx_pi_update_irte>> trace_kvm_pi_irte_update(host_irq,... vcpu_info.vector, vcpu_info.pi_desc_addr, set);
+			 *   - drivers/iommu/intel/irq_remapping.c|1221| <<intel_ir_set_vcpu_affinity>> irte_pi.pda_l = (vcpu_pi_info->pi_desc_addr >>
+			 *   - drivers/iommu/intel/irq_remapping.c|1223| <<intel_ir_set_vcpu_affinity>> irte_pi.pda_h = (vcpu_pi_info->pi_desc_addr >> 32) &
+			 */
 			trace_kvm_pi_irte_update(host_irq, svm->vcpu.vcpu_id,
 						 e->gsi, vcpu_info.vector,
 						 vcpu_info.pi_desc_addr, set);
@@ -1012,6 +1075,12 @@ int avic_pi_update_irte(struct kvm *kvm, unsigned int host_irq,
 
 bool avic_check_apicv_inhibit_reasons(enum kvm_apicv_inhibit reason)
 {
+	/*
+	 * 在以下使用APICV_INHIBIT_REASON_IRQWIN:
+	 *   - arch/x86/kvm/svm/avic.c|1056| <<avic_check_apicv_inhibit_reasons>> BIT(APICV_INHIBIT_REASON_IRQWIN) |
+	 *   - arch/x86/kvm/svm/svm.c|3203| <<interrupt_window_interception>> kvm_clear_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+	 *   - arch/x86/kvm/svm/svm.c|3873| <<svm_enable_irq_window>> kvm_set_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+	 */
 	ulong supported = BIT(APICV_INHIBIT_REASON_DISABLE) |
 			  BIT(APICV_INHIBIT_REASON_ABSENT) |
 			  BIT(APICV_INHIBIT_REASON_HYPERV) |
diff --git a/arch/x86/kvm/svm/svm.c b/arch/x86/kvm/svm/svm.c
index 96640c185c6e..8dc766d3a97b 100644
--- a/arch/x86/kvm/svm/svm.c
+++ b/arch/x86/kvm/svm/svm.c
@@ -1112,8 +1112,38 @@ static __init int svm_hardware_setup(void)
 		kvm_enable_efer_bits(EFER_FFXSR);
 
 	if (boot_cpu_has(X86_FEATURE_TSCRATEMSR)) {
+		/*
+		 * 在以下设置kvm_has_tsc_control:
+		 *   - arch/x86/kvm/svm/svm.c|1115| <<svm_hardware_setup>> kvm_has_tsc_control = true;
+		 *   - arch/x86/kvm/vmx/vmx.c|8787| <<hardware_setup>> kvm_has_tsc_control = true;
+		 * 在以下使用kvm_has_tsc_control:
+		 *   - arch/x86/kvm/debugfs.c|69| <<kvm_arch_create_vcpu_debugfs>> if (kvm_has_tsc_control) {
+		 *   - arch/x86/kvm/vmx/nested.c|2581| <<prepare_vmcs02>> if (kvm_has_tsc_control)
+		 *   - arch/x86/kvm/vmx/nested.c|4680| <<nested_vmx_vmexit>> if (kvm_has_tsc_control)
+		 *   - arch/x86/kvm/x86.c|2579| <<set_tsc_khz>> if (!kvm_has_tsc_control) {
+		 *   - arch/x86/kvm/x86.c|2843| <<kvm_vcpu_write_tsc_multiplier>> if (kvm_has_tsc_control)
+		 *   - arch/x86/kvm/x86.c|3607| <<kvm_guest_time_update>> if (kvm_has_tsc_control)
+		 *   - arch/x86/kvm/x86.c|4951| <<kvm_vm_ioctl_check_extension>> r = kvm_has_tsc_control;
+		 *   - arch/x86/kvm/x86.c|6207| <<kvm_arch_vcpu_ioctl(KVM_SET_TSC_KHZ)>> if (kvm_has_tsc_control &
+		 *   - arch/x86/kvm/x86.c|13736| <<kvm_arch_hardware_setup>> if (kvm_has_tsc_control) {
+		 */
 		kvm_has_tsc_control = true;
 		kvm_max_tsc_scaling_ratio = TSC_RATIO_MAX;
+		/*
+		 * 在以下使用kvm_tsc_scaling_ratio_frac_bits:
+		 *   - arch/x86/kvm/debugfs.c|51| <<vcpu_get_tsc_scaling_frac_bits>> *val = kvm_tsc_scaling_ratio_frac_bits;
+		 *   - arch/x86/kvm/svm/svm.c|1117| <<svm_hardware_setup>> kvm_tsc_scaling_ratio_frac_bits = 32;
+		 *   - arch/x86/kvm/vmx/vmx.c|8358| <<vmx_set_hv_timer>> if (vcpu->arch.l1_tsc_scaling_ratio != kvm_default_tsc_scaling_ratio
+		 *              && delta_tsc && u64_shl_div_u64(delta_tsc, kvm_tsc_scaling_ratio_frac_bits, vcpu->arch.l1_tsc_scaling_ratio, &delta_tsc))
+		 *   - arch/x86/kvm/vmx/vmx.c|8789| <<hardware_setup>> kvm_tsc_scaling_ratio_frac_bits = 48;
+		 *   - arch/x86/kvm/x86.c|2561| <<set_tsc_khz>> ratio = mul_u64_u32_div(1ULL << kvm_tsc_scaling_ratio_frac_bits, user_tsc_khz, tsc_khz);
+		 *   - arch/x86/kvm/x86.c|2702| <<__scale_tsc>> return mul_u64_u64_shr(tsc, ratio, kvm_tsc_scaling_ratio_frac_bits);
+		 *   - arch/x86/kvm/x86.c|2740| <<kvm_calc_nested_tsc_offset>> nested_offset = mul_s64_u64_shr((s64) l1_offset,
+		 *              l2_multiplier, kvm_tsc_scaling_ratio_frac_bits);
+		 *   - arch/x86/kvm/x86.c|2751| <<kvm_calc_nested_tsc_multiplier>> return mul_u64_u64_shr(l1_multiplier, l2_multiplier,
+		 *              kvm_tsc_scaling_ratio_frac_bits);
+		 *   - arch/x86/kvm/x86.c|13707| <<kvm_arch_hardware_setup>> kvm_default_tsc_scaling_ratio = 1ULL << kvm_tsc_scaling_ratio_frac_bits;
+		 */
 		kvm_tsc_scaling_ratio_frac_bits = 32;
 	}
 
@@ -1257,6 +1287,22 @@ static void svm_write_tsc_offset(struct kvm_vcpu *vcpu, u64 offset)
 {
 	struct vcpu_svm *svm = to_svm(vcpu);
 
+	/*
+	 * 在以下使用kvm_vcpu_arch->l1_tsc_offset:
+	 *   - arch/x86/kvm/svm/nested.c|619| <<nested_vmcb02_prepare_control>> vcpu->arch.l1_tsc_offset + svm->nested.ctl.tsc_offset;
+	 *   - arch/x86/kvm/svm/nested.c|972| <<nested_svm_vmexit>> svm->vcpu.arch.tsc_offset = svm->vcpu.arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/svm/svm.c|1290| <<svm_write_tsc_offset>> svm->vmcb01.ptr->control.tsc_offset = vcpu->arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/vmx/nested.c|2602| <<prepare_vmcs02>> vcpu->arch.tsc_offset = kvm_calc_nested_tsc_offset(vcpu->arch.l1_tsc_offset,
+	 *          vmx_get_l2_tsc_offset(vcpu), vmx_get_l2_tsc_multiplier(vcpu));
+	 *   - arch/x86/kvm/vmx/nested.c|4648| <<nested_vmx_vmexit>> vcpu->arch.tsc_offset = vcpu->arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/x86.c|3066| <<kvm_read_l1_tsc>> return vcpu->arch.l1_tsc_offset + kvm_scale_tsc(vcpu, host_tsc,
+	 *          vcpu->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|3105| <<kvm_vcpu_write_tsc_offset>> trace_kvm_write_tsc_offset( ... vcpu->arch.l1_tsc_offset,
+	 *   - arch/x86/kvm/x86.c|3108| <<kvm_vcpu_write_tsc_offset>> vcpu->arch.l1_tsc_offset = l1_offset;
+	 *   - arch/x86/kvm/x86.c|3373| <<adjust_tsc_offset_guest>> u64 tsc_offset = vcpu->arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/x86.c|4746| <<kvm_set_msr_common(MSR_IA32_TSC)>> u64 adj = kvm_compute_l1_tsc_offset(vcpu, data) - vcpu->arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/x86.c|5090| <<kvm_get_msr_common(MSR_IA32_TSC)>> offset = vcpu->arch.l1_tsc_offset;
+	 */
 	svm->vmcb01.ptr->control.tsc_offset = vcpu->arch.l1_tsc_offset;
 	svm->vmcb->control.tsc_offset = offset;
 	vmcb_mark_dirty(svm->vmcb, VMCB_INTERCEPTS);
@@ -1678,6 +1724,10 @@ static void svm_cache_reg(struct kvm_vcpu *vcpu, enum kvm_reg reg)
 	}
 }
 
+/*
+ * 在以下使用svm_set_vintr():
+ *   - arch/x86/kvm/svm/svm.c|3875| <<svm_enable_irq_window>> svm_set_vintr(svm);
+ */
 static void svm_set_vintr(struct vcpu_svm *svm)
 {
 	struct vmcb_control_area *control;
@@ -1687,6 +1737,16 @@ static void svm_set_vintr(struct vcpu_svm *svm)
 	 */
 	WARN_ON(kvm_vcpu_apicv_activated(&svm->vcpu));
 
+	/*
+	 * SDM注释:
+	 * When virtualizing interrupt handling, a VMM typically needs only
+	 * gain control when new interrupts
+	 * for a guest arrive or are generated, and when the guest issues an EOI
+	 * (end-of-interrupt). In some circumstances, it may also be necessary
+	 * for the VMM to gain control at the moment interrupts become enabled in
+	 * the guest (i.e., just before the guest takes a virtual interrupt). The
+	 * VMM can do so by enabling the VINTR intercept.
+	 */
 	svm_set_intercept(svm, INTERCEPT_VINTR);
 
 	/*
@@ -1711,6 +1771,12 @@ static void svm_set_vintr(struct vcpu_svm *svm)
 	vmcb_mark_dirty(svm->vmcb, VMCB_INTR);
 }
 
+/*
+ * 在以下使用svm_clear_vintr():
+ *   - arch/x86/kvm/svm/svm.c|2443| <<svm_set_gif>> svm_clear_vintr(svm);
+ *   - arch/x86/kvm/svm/svm.c|2459| <<svm_set_gif>> svm_clear_vintr(svm);
+ *   - arch/x86/kvm/svm/svm.c|3189| <<interrupt_window_interception>> svm_clear_vintr(to_svm(vcpu));
+ */
 static void svm_clear_vintr(struct vcpu_svm *svm)
 {
 	svm_clr_intercept(svm, INTERCEPT_VINTR);
@@ -3186,6 +3252,12 @@ static int msr_interception(struct kvm_vcpu *vcpu)
 static int interrupt_window_interception(struct kvm_vcpu *vcpu)
 {
 	kvm_make_request(KVM_REQ_EVENT, vcpu);
+	/*
+	 * 在以下使用svm_clear_vintr():
+	 *   - arch/x86/kvm/svm/svm.c|2443| <<svm_set_gif>> svm_clear_vintr(svm);
+	 *   - arch/x86/kvm/svm/svm.c|2459| <<svm_set_gif>> svm_clear_vintr(svm);
+	 *   - arch/x86/kvm/svm/svm.c|3189| <<interrupt_window_interception>> svm_clear_vintr(to_svm(vcpu));
+	 */
 	svm_clear_vintr(to_svm(vcpu));
 
 	/*
@@ -3200,6 +3272,19 @@ static int interrupt_window_interception(struct kvm_vcpu *vcpu)
 	 * All vCPUs which run still run nested, will remain to have their
 	 * AVIC still inhibited due to per-cpu AVIC inhibition.
 	 */
+	/*
+	 * 在以下使用kvm_clear_apicv_inhibit():
+	 *   - arch/x86/kvm/i8254.c|314| <<kvm_pit_set_reinject>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_PIT_REINJ);
+	 *   - arch/x86/kvm/lapic.c|579| <<kvm_recalculate_apic_map>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_APIC_ID_MODIFIED);
+	 *   - arch/x86/kvm/svm/svm.c|3235| <<interrupt_window_interception>> kvm_clear_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+	 *   - arch/x86/kvm/x86.c|6050| <<kvm_vm_ioctl_enable_cap(KVM_CAP_SPLIT_IRQCHIP)>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
+	 *   - arch/x86/kvm/x86.c|6465| <<kvm_arch_vm_ioctl(KVM_CREATE_IRQCHIP)>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
+	 *
+	 * 在以下使用APICV_INHIBIT_REASON_IRQWIN:
+	 *   - arch/x86/kvm/svm/avic.c|1056| <<avic_check_apicv_inhibit_reasons>> BIT(APICV_INHIBIT_REASON_IRQWIN) |
+	 *   - arch/x86/kvm/svm/svm.c|3203| <<interrupt_window_interception>> kvm_clear_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+	 *   - arch/x86/kvm/svm/svm.c|3873| <<svm_enable_irq_window>> kvm_set_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+	 */
 	kvm_clear_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
 
 	++vcpu->stat.irq_window_exits;
@@ -3649,6 +3734,15 @@ static void svm_set_irq(struct kvm_vcpu *vcpu, bool reinjected)
 				       SVM_EVTINJ_VALID | type;
 }
 
+/*
+ * 在以下使用svm_complete_interrupt_delivery():
+ *   - arch/x86/kvm/svm/avic.c|435| <<avic_kick_target_vcpus_fast>> svm_complete_interrupt_delivery(target_vcpu,
+ *              icrl & APIC_MODE_MASK, icrl & APIC_INT_LEVELTRIG, icrl & APIC_VECTOR_MASK);
+ *   - arch/x86/kvm/svm/avic.c|483| <<avic_kick_target_vcpus>> svm_complete_interrupt_delivery(vcpu,
+ *              icrl & APIC_MODE_MASK, icrl & APIC_INT_LEVELTRIG, icrl & APIC_VECTOR_MASK);
+ *   - arch/x86/kvm/svm/svm.c|3698| <<svm_deliver_interrupt>> svm_complete_interrupt_delivery(apic->vcpu,
+ *              delivery_mode, trig_mode, vector); 
+ */
 void svm_complete_interrupt_delivery(struct kvm_vcpu *vcpu, int delivery_mode,
 				     int trig_mode, int vector)
 {
@@ -3695,6 +3789,15 @@ static void svm_deliver_interrupt(struct kvm_lapic *apic,  int delivery_mode,
 	 * will signal the doorbell if the CPU has already entered the guest.
 	 */
 	smp_mb__after_atomic();
+	/*
+	 * 在以下使用svm_complete_interrupt_delivery():
+	 *   - arch/x86/kvm/svm/avic.c|435| <<avic_kick_target_vcpus_fast>> svm_complete_interrupt_delivery(target_vcpu,
+	 *              icrl & APIC_MODE_MASK, icrl & APIC_INT_LEVELTRIG, icrl & APIC_VECTOR_MASK);
+	 *   - arch/x86/kvm/svm/avic.c|483| <<avic_kick_target_vcpus>> svm_complete_interrupt_delivery(vcpu,
+	 *              icrl & APIC_MODE_MASK, icrl & APIC_INT_LEVELTRIG, icrl & APIC_VECTOR_MASK);
+	 *   - arch/x86/kvm/svm/svm.c|3698| <<svm_deliver_interrupt>> svm_complete_interrupt_delivery(apic->vcpu,
+	 *              delivery_mode, trig_mode, vector); 
+	 */
 	svm_complete_interrupt_delivery(apic->vcpu, delivery_mode, trig_mode, vector);
 }
 
@@ -3828,6 +3931,11 @@ static int svm_interrupt_allowed(struct kvm_vcpu *vcpu, bool for_injection)
 	return 1;
 }
 
+/*
+ * 在以下调用:
+ *   - arch/x86/kvm/x86.c|9847| <<inject_pending_event>> static_call(kvm_x86_enable_irq_window)(vcpu);
+ *   - arch/x86/kvm/x86.c|10871| <<vcpu_enter_guest>> static_call(kvm_x86_enable_irq_window)(vcpu);
+ */
 static void svm_enable_irq_window(struct kvm_vcpu *vcpu)
 {
 	struct vcpu_svm *svm = to_svm(vcpu);
@@ -3851,6 +3959,12 @@ static void svm_enable_irq_window(struct kvm_vcpu *vcpu)
 		 * on this vCPU, therefore there is no need to request
 		 * the VM wide AVIC inhibition.
 		 */
+		/*
+		 * 在以下使用APICV_INHIBIT_REASON_IRQWIN:
+		 *   - arch/x86/kvm/svm/avic.c|1056| <<avic_check_apicv_inhibit_reasons>> BIT(APICV_INHIBIT_REASON_IRQWIN) |
+		 *   - arch/x86/kvm/svm/svm.c|3203| <<interrupt_window_interception>> kvm_clear_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+		 *   - arch/x86/kvm/svm/svm.c|3873| <<svm_enable_irq_window>> kvm_set_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+		 */
 		if (!is_guest_mode(vcpu))
 			kvm_set_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
 
@@ -4202,6 +4316,12 @@ static __no_kcsan fastpath_t svm_vcpu_run(struct kvm_vcpu *vcpu)
 		vcpu->arch.regs[VCPU_REGS_RIP] = svm->vmcb->save.rip;
 	}
 
+	/*
+	 * 在以下使用kvm_before_interrupt():
+	 *   - arch/x86/kvm/svm/svm.c|4206| <<svm_vcpu_run>> kvm_before_interrupt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|6920| <<handle_interrupt_nmi_irqoff>> kvm_before_interrupt(vcpu);
+	 *   - arch/x86/kvm/x86.c|11036| <<vcpu_enter_guest>> kvm_before_interrupt(vcpu);
+	 */
 	if (unlikely(svm->vmcb->control.exit_code == SVM_EXIT_NMI))
 		kvm_before_interrupt(vcpu);
 
@@ -4581,6 +4701,13 @@ static int svm_check_intercept(struct kvm_vcpu *vcpu,
 
 static void svm_handle_exit_irqoff(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用kvm_vcpu_arch->at_instruction_boundary:
+	 *   - arch/x86/kvm/svm/svm.c|4585| <<svm_handle_exit_irqoff>> vcpu->arch.at_instruction_boundary = true;
+	 *   - arch/x86/kvm/vmx/vmx.c|6979| <<handle_external_interrupt_irqoff>> vcpu->arch.at_instruction_boundary = true;
+	 *   - arch/x86/kvm/x86.c|4744| <<kvm_steal_time_set_preempted>> if (!vcpu->arch.at_instruction_boundary) {
+	 *   - arch/x86/kvm/x86.c|11223| <<vcpu_run>> vcpu->arch.at_instruction_boundary = false;
+	 */
 	if (to_svm(vcpu)->vmcb->control.exit_code == SVM_EXIT_INTR)
 		vcpu->arch.at_instruction_boundary = true;
 }
diff --git a/arch/x86/kvm/vmx/nested.c b/arch/x86/kvm/vmx/nested.c
index ab2a35fe97f8..14473d934c62 100644
--- a/arch/x86/kvm/vmx/nested.c
+++ b/arch/x86/kvm/vmx/nested.c
@@ -977,6 +977,21 @@ static bool nested_vmx_get_vmexit_msr_value(struct kvm_vcpu *vcpu,
 		if (i >= 0) {
 			u64 val = vmx->msr_autostore.guest.val[i].value;
 
+			/*
+			 * 在以下使用kvm_read_l1_tsc():
+			 *   - arch/x86/kvm/hyperv.c|591| <<get_time_ref_counter>> tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+			 *   - arch/x86/kvm/lapic.c|2899| <<__kvm_wait_lapic_expire>> guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+			 *   - arch/x86/kvm/lapic.c|2917| <<__kvm_wait_lapic_expire>> guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+			 *   - arch/x86/kvm/lapic.c|3027| <<start_sw_tscdeadline>> guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+			 *   - arch/x86/kvm/lapic.c|3141| <<set_target_expiration>> apic->lapic_timer.tscdeadline = kvm_read_l1_tsc(apic->vcpu, tscl) +
+			 *   - arch/x86/kvm/lapic.c|3180| <<advance_periodic_target_expiration>> apic->lapic_timer.tscdeadline = kvm_read_l1_tsc(apic->vcpu, tscl) +
+			 *   - arch/x86/kvm/vmx/nested.c|980| <<nested_vmx_get_vmexit_msr_value>> *data = kvm_read_l1_tsc(vcpu, val);
+			 *   - arch/x86/kvm/vmx/nested.c|2086| <<vmx_calc_preemption_timer_value>> u64 l1_scaled_tsc = kvm_read_l1_tsc(vcpu, rdtsc()) >>
+			 *   - arch/x86/kvm/vmx/vmx.c|8345| <<vmx_set_hv_timer>> guest_tscl = kvm_read_l1_tsc(vcpu, tscl);
+			 *   - arch/x86/kvm/x86.c|3885| <<kvm_guest_time_update>> tsc_timestamp = kvm_read_l1_tsc(v, host_tsc);
+			 *   - arch/x86/kvm/x86.c|10375| <<kvm_pv_clock_pairing>> clock_pairing.tsc = kvm_read_l1_tsc(vcpu, cycle);
+			 *   - arch/x86/kvm/x86.c|12309| <<vcpu_enter_guest>> vcpu->arch.last_guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+			 */
 			*data = kvm_read_l1_tsc(vcpu, val);
 			return true;
 		}
@@ -2083,6 +2098,21 @@ static u64 vmx_calc_preemption_timer_value(struct kvm_vcpu *vcpu)
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
 	struct vmcs12 *vmcs12 = get_vmcs12(vcpu);
 
+	/*
+	 * 在以下使用kvm_read_l1_tsc():
+	 *   - arch/x86/kvm/hyperv.c|591| <<get_time_ref_counter>> tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 *   - arch/x86/kvm/lapic.c|2899| <<__kvm_wait_lapic_expire>> guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 *   - arch/x86/kvm/lapic.c|2917| <<__kvm_wait_lapic_expire>> guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 *   - arch/x86/kvm/lapic.c|3027| <<start_sw_tscdeadline>> guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 *   - arch/x86/kvm/lapic.c|3141| <<set_target_expiration>> apic->lapic_timer.tscdeadline = kvm_read_l1_tsc(apic->vcpu, tscl) +
+	 *   - arch/x86/kvm/lapic.c|3180| <<advance_periodic_target_expiration>> apic->lapic_timer.tscdeadline = kvm_read_l1_tsc(apic->vcpu, tscl) +
+	 *   - arch/x86/kvm/vmx/nested.c|980| <<nested_vmx_get_vmexit_msr_value>> *data = kvm_read_l1_tsc(vcpu, val);
+	 *   - arch/x86/kvm/vmx/nested.c|2086| <<vmx_calc_preemption_timer_value>> u64 l1_scaled_tsc = kvm_read_l1_tsc(vcpu, rdtsc()) >>
+	 *   - arch/x86/kvm/vmx/vmx.c|8345| <<vmx_set_hv_timer>> guest_tscl = kvm_read_l1_tsc(vcpu, tscl);
+	 *   - arch/x86/kvm/x86.c|3885| <<kvm_guest_time_update>> tsc_timestamp = kvm_read_l1_tsc(v, host_tsc);
+	 *   - arch/x86/kvm/x86.c|10375| <<kvm_pv_clock_pairing>> clock_pairing.tsc = kvm_read_l1_tsc(vcpu, cycle);
+	 *   - arch/x86/kvm/x86.c|12309| <<vcpu_enter_guest>> vcpu->arch.last_guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 */
 	u64 l1_scaled_tsc = kvm_read_l1_tsc(vcpu, rdtsc()) >>
 			    VMX_MISC_EMULATED_PREEMPTION_TIMER_RATE;
 
@@ -2363,6 +2393,22 @@ static void prepare_vmcs02_early(struct vcpu_vmx *vmx, struct loaded_vmcs *vmcs0
 	 * Interrupt/Exception Fields
 	 */
 	if (vmx->nested.nested_run_pending) {
+		/*
+		 * vmx代码中主要使用VM_ENTRY_INTR_INFO_FIELD的地方:
+		 *   - arch/x86/kvm/vmx/nested.c|2366| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+		 *   - arch/x86/kvm/vmx/nested.c|2377| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+		 *   - arch/x86/kvm/vmx/vmx.c|1732| <<vmx_inject_exception>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr_info);
+		 *   - arch/x86/kvm/vmx/vmx.c|4653| <<vmx_vcpu_reset>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+		 *   - arch/x86/kvm/vmx/vmx.c|4710| <<vmx_inject_irq>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr);
+		 *   - arch/x86/kvm/vmx/vmx.c|4740| <<vmx_inject_nmi>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+		 *   - arch/x86/kvm/vmx/vmx.c|6095| <<dump_vmcs>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+		 *   - arch/x86/kvm/vmx/vmx.c|6952| <<vmx_cancel_injection>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+		 *   - arch/x86/kvm/vmx/vmx.c|6956| <<vmx_cancel_injection>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+		 *
+		 * bit 0-7: Vector of interrupt or exception
+		 * bit 8-10: interrupt type: 0-7不同的数, 0是external interrupt
+		 * bit 31: valid (cleared on every vm exit)
+		 */
 		vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
 			     vmcs12->vm_entry_intr_info_field);
 		vmcs_write32(VM_ENTRY_EXCEPTION_ERROR_CODE,
@@ -4688,6 +4734,15 @@ void nested_vmx_vmexit(struct kvm_vcpu *vcpu, u32 vm_exit_reason,
 
 	if (vmx->nested.reload_vmcs01_apic_access_page) {
 		vmx->nested.reload_vmcs01_apic_access_page = false;
+		/*
+		 * 在以下使用KVM_REQ_APIC_PAGE_RELOAD:
+		 *   - arch/x86/kvm/vmx/nested.c|4691| <<nested_vmx_vmexit>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+		 *   - arch/x86/kvm/vmx/vmx.c|4645| <<vmx_vcpu_reset>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+		 *   - arch/x86/kvm/vmx/vmx.c|6462| <<vmx_set_virtual_apic_mode>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+		 *   - arch/x86/kvm/x86.c|10340| <<kvm_arch_mmu_notifier_invalidate_range>> kvm_make_all_cpus_request(kvm, KVM_REQ_APIC_PAGE_RELOAD);
+		 *
+		 * 处理的函数kvm_vcpu_reload_apic_access_page()
+		 */
 		kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
 	}
 
diff --git a/arch/x86/kvm/vmx/posted_intr.c b/arch/x86/kvm/vmx/posted_intr.c
index cb93a31a77c3..cbedc6f2c663 100644
--- a/arch/x86/kvm/vmx/posted_intr.c
+++ b/arch/x86/kvm/vmx/posted_intr.c
@@ -253,6 +253,13 @@ void vmx_pi_start_assignment(struct kvm *kvm)
 	if (!irq_remapping_cap(IRQ_POSTING_CAP))
 		return;
 
+	/*
+	 * 在以下使用KVM_REQ_UNBLOCK:
+	 *   - arch/x86/kvm/lapic.c|2735| <<apic_timer_expired>> kvm_make_request(KVM_REQ_UNBLOCK, vcpu);
+	 *   - arch/x86/kvm/vmx/posted_intr.c|256| <<vmx_pi_start_assignment>> kvm_make_all_cpus_request(kvm, KVM_REQ_UNBLOCK);
+	 *   - arch/x86/kvm/x86.c|11444| <<vcpu_run>> kvm_clear_request(KVM_REQ_UNBLOCK, vcpu);
+	 *   - virt/kvm/kvm_main.c|3406| <<kvm_vcpu_check_block>> if (kvm_check_request(KVM_REQ_UNBLOCK, vcpu))
+	 */
 	kvm_make_all_cpus_request(kvm, KVM_REQ_UNBLOCK);
 }
 
@@ -265,6 +272,14 @@ void vmx_pi_start_assignment(struct kvm *kvm)
  * @set: set or unset PI
  * returns 0 on success, < 0 on failure
  */
+/*
+ * 在以下调用kvm_x86_pi_update_irte:
+ *   - arch/x86/kvm/x86.c|14122| <<kvm_arch_irq_bypass_add_producer>> ret = static_call(kvm_x86_pi_update_irte)(irqfd->kvm,
+ *   - arch/x86/kvm/x86.c|14147| <<kvm_arch_irq_bypass_del_producer>> ret = static_call(kvm_x86_pi_update_irte)(irqfd->kvm, prod->irq, irqfd->gsi, 0);
+ *   - arch/x86/kvm/x86.c|14158| <<kvm_arch_update_irqfd_routing>> return static_call(kvm_x86_pi_update_irte)(kvm, host_irq, guest_irq, set);
+ *
+ * struct kvm_x86_ops vmx_x86_ops.pi_update_irte = vmx_pi_update_irte
+ */
 int vmx_pi_update_irte(struct kvm *kvm, unsigned int host_irq,
 		       uint32_t guest_irq, bool set)
 {
@@ -306,6 +321,25 @@ int vmx_pi_update_irte(struct kvm *kvm, unsigned int host_irq,
 		 * the PI mechanism, refuse to route others through it.
 		 */
 
+		/*
+		 * struct kvm_lapic_irq {
+		 *     u32 vector;
+		 *     u16 delivery_mode;
+		 *     u16 dest_mode;
+		 *     bool level;
+		 *     u16 trig_mode;
+		 *     u32 shorthand;
+		 *     u32 dest_id; 
+		 *     bool msi_redir_hint;
+		 * };
+		 *
+		 * 在以下使用kvm_set_msi_irq():
+		 *   - arch/x86/kvm/irq_comm.c|226| <<kvm_set_msi>> kvm_set_msi_irq(kvm, e, &irq);
+		 *   - arch/x86/kvm/irq_comm.c|272| <<kvm_arch_set_irq_inatomic>> kvm_set_msi_irq(kvm, e, &irq);
+		 *   - arch/x86/kvm/irq_comm.c|603| <<kvm_scan_ioapic_routes>> kvm_set_msi_irq(vcpu->kvm, entry, &irq);
+		 *   - arch/x86/kvm/svm/avic.c|916| <<get_pi_vcpu_info>> kvm_set_msi_irq(kvm, e, &irq);
+		 *   - arch/x86/kvm/vmx/posted_intr.c|319| <<vmx_pi_update_irte>> kvm_set_msi_irq(kvm, e, &irq);
+		 */
 		kvm_set_msi_irq(kvm, e, &irq);
 		if (!kvm_intr_is_single_vcpu(kvm, &irq, &vcpu) ||
 		    !kvm_irq_is_postable(&irq)) {
@@ -324,6 +358,17 @@ int vmx_pi_update_irte(struct kvm *kvm, unsigned int host_irq,
 			continue;
 		}
 
+		/*
+		 * 在以下使用vcpu_data->pi_desc_addr:
+		 *   - arch/x86/kvm/svm/avic.c|928| <<get_pi_vcpu_info>> vcpu_info->pi_desc_addr = __sme_set(page_to_phys((*svm)->avic_backing_page));
+		 *   - arch/x86/kvm/svm/avic.c|1035| <<avic_pi_update_irte>> trace_kvm_pi_irte_update(host_irq,... vcpu_info.pi_desc_addr, set);
+		 *   - arch/x86/kvm/vmx/posted_intr.c|337| <<vmx_pi_update_irte>> vcpu_info.pi_desc_addr = __pa(&to_vmx(vcpu)->pi_desc);
+		 *   - arch/x86/kvm/vmx/posted_intr.c|341| <<vmx_pi_update_irte>> trace_kvm_pi_irte_update(host_irq,... vcpu_info.vector, vcpu_info.pi_desc_addr, set);
+		 *   - drivers/iommu/intel/irq_remapping.c|1221| <<intel_ir_set_vcpu_affinity>> irte_pi.pda_l = (vcpu_pi_info->pi_desc_addr >>
+		 *   - drivers/iommu/intel/irq_remapping.c|1223| <<intel_ir_set_vcpu_affinity>> irte_pi.pda_h = (vcpu_pi_info->pi_desc_addr >> 32) &
+		 *
+		 * struct vcpu_data vcpu_info;
+		 */
 		vcpu_info.pi_desc_addr = __pa(&to_vmx(vcpu)->pi_desc);
 		vcpu_info.vector = irq.vector;
 
diff --git a/arch/x86/kvm/vmx/vmx.c b/arch/x86/kvm/vmx/vmx.c
index d0a0883599c5..ba641ff39b87 100644
--- a/arch/x86/kvm/vmx/vmx.c
+++ b/arch/x86/kvm/vmx/vmx.c
@@ -515,6 +515,13 @@ static inline void vmx_segment_cache_clear(struct vcpu_vmx *vmx)
 	vmx->segment_cache.bitmask = 0;
 }
 
+/*
+ * 在以下使用host_idt_base:
+ *   - arch/x86/kvm/vmx/vmx.c|518| <<global>> static unsigned long host_idt_base;
+ *   - arch/x86/kvm/vmx/vmx.c|4304| <<vmx_set_constant_host_state>> vmcs_writel(HOST_IDTR_BASE, host_idt_base);
+ *   - arch/x86/kvm/vmx/vmx.c|6972| <<handle_external_interrupt_irqoff>> gate_desc *desc = (gate_desc *)host_idt_base + vector;
+ *   - arch/x86/kvm/vmx/vmx.c|8510| <<hardware_setup>> host_idt_base = dt.address;
+ */
 static unsigned long host_idt_base;
 
 #if IS_ENABLED(CONFIG_HYPERV)
@@ -1182,6 +1189,11 @@ void vmx_set_host_fs_gs(struct vmcs_host_state *host, u16 fs_sel, u16 gs_sel,
 	}
 }
 
+/*
+ * 在以下调用vmx_prepare_switch_to_guest():
+ *   - arch/x86/kvm/vmx/vmx.h|370| <<global>> void vmx_prepare_switch_to_guest(struct kvm_vcpu *vcpu);
+ *   - arch/x86/kvm/vmx/nested.c|3103| <<nested_vmx_check_vmentry_hw>> vmx_prepare_switch_to_guest(vcpu);
+ */
 void vmx_prepare_switch_to_guest(struct kvm_vcpu *vcpu)
 {
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
@@ -1215,6 +1227,16 @@ void vmx_prepare_switch_to_guest(struct kvm_vcpu *vcpu)
     	if (vmx->nested.need_vmcs12_to_shadow_sync)
 		nested_sync_vmcs12_to_shadow(vcpu);
 
+	/*
+	 * 在以下使用vcpu_vmx->guest_state_loaded:
+	 *   - arch/x86/kvm/vmx/nested.c|243| <<vmx_sync_vmcs_host_state>> if (unlikely(!vmx->guest_state_loaded))
+	 *   - arch/x86/kvm/vmx/vmx.c|1223| <<vmx_prepare_switch_to_guest>> if (vmx->guest_state_loaded)
+	 *   - arch/x86/kvm/vmx/vmx.c|1261| <<vmx_prepare_switch_to_guest>> vmx->guest_state_loaded = true;
+	 *   - arch/x86/kvm/vmx/vmx.c|1268| <<vmx_prepare_switch_to_host>> if (!vmx->guest_state_loaded)
+	 *   - arch/x86/kvm/vmx/vmx.c|1299| <<vmx_prepare_switch_to_host>> vmx->guest_state_loaded = false;
+	 *   - arch/x86/kvm/vmx/vmx.c|1307| <<vmx_read_guest_kernel_gs_base>> if (vmx->guest_state_loaded)
+	 *   - arch/x86/kvm/vmx/vmx.c|1316| <<vmx_write_guest_kernel_gs_base>> if (vmx->guest_state_loaded)
+	 */
 	if (vmx->guest_state_loaded)
 		return;
 
@@ -1291,6 +1313,16 @@ static void vmx_prepare_switch_to_host(struct vcpu_vmx *vmx)
 	wrmsrl(MSR_KERNEL_GS_BASE, vmx->msr_host_kernel_gs_base);
 #endif
 	load_fixmap_gdt(raw_smp_processor_id());
+	/*
+	 * 在以下使用vcpu_vmx->guest_state_loaded:
+	 *   - arch/x86/kvm/vmx/nested.c|243| <<vmx_sync_vmcs_host_state>> if (unlikely(!vmx->guest_state_loaded))
+	 *   - arch/x86/kvm/vmx/vmx.c|1223| <<vmx_prepare_switch_to_guest>> if (vmx->guest_state_loaded)
+	 *   - arch/x86/kvm/vmx/vmx.c|1261| <<vmx_prepare_switch_to_guest>> vmx->guest_state_loaded = true;
+	 *   - arch/x86/kvm/vmx/vmx.c|1268| <<vmx_prepare_switch_to_host>> if (!vmx->guest_state_loaded)
+	 *   - arch/x86/kvm/vmx/vmx.c|1299| <<vmx_prepare_switch_to_host>> vmx->guest_state_loaded = false;
+	 *   - arch/x86/kvm/vmx/vmx.c|1307| <<vmx_read_guest_kernel_gs_base>> if (vmx->guest_state_loaded)
+	 *   - arch/x86/kvm/vmx/vmx.c|1316| <<vmx_write_guest_kernel_gs_base>> if (vmx->guest_state_loaded)
+	 */
 	vmx->guest_state_loaded = false;
 	vmx->guest_uret_msrs_loaded = false;
 }
@@ -1674,6 +1706,13 @@ static int vmx_skip_emulated_instruction(struct kvm_vcpu *vcpu)
 	return skip_emulated_instruction(vcpu);
 }
 
+/*
+ * 在以下调用vmx_clear_hlt():
+ *   - arch/x86/kvm/vmx/vmx.c|1734| <<vmx_inject_exception>> vmx_clear_hlt(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|4712| <<vmx_inject_irq>> vmx_clear_hlt(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|4743| <<vmx_inject_nmi>> vmx_clear_hlt(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|7989| <<vmx_enter_smm>> vmx_clear_hlt(vcpu);
+ */
 static void vmx_clear_hlt(struct kvm_vcpu *vcpu)
 {
 	/*
@@ -1690,6 +1729,26 @@ static void vmx_clear_hlt(struct kvm_vcpu *vcpu)
 static void vmx_inject_exception(struct kvm_vcpu *vcpu)
 {
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
+	/*
+	 * struct kvm_vcpu *vcpu:
+	 * -> struct kvm_vcpu_arch arch;
+	 *        struct kvm_queued_exception {
+	 *            bool pending;
+	 *            bool injected;
+	 *            bool has_error_code;
+	 *            u8 nr;
+	 *            u32 error_code;
+	 *            unsigned long payload;
+	 *            bool has_payload;
+	 *            u8 nested_apf;
+	 *        } exception;
+	 *
+	 *        struct kvm_queued_interrupt {
+	 *            bool injected;
+	 *            bool soft;
+	 *            u8 nr;
+	 *        } interrupt;
+	 */
 	unsigned nr = vcpu->arch.exception.nr;
 	bool has_error_code = vcpu->arch.exception.has_error_code;
 	u32 error_code = vcpu->arch.exception.error_code;
@@ -1729,8 +1788,31 @@ static void vmx_inject_exception(struct kvm_vcpu *vcpu)
 	} else
 		intr_info |= INTR_TYPE_HARD_EXCEPTION;
 
+	/*
+	 * vmx代码中主要使用VM_ENTRY_INTR_INFO_FIELD的地方:
+	 *   - arch/x86/kvm/vmx/nested.c|2366| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+	 *   - arch/x86/kvm/vmx/nested.c|2377| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *   - arch/x86/kvm/vmx/vmx.c|1732| <<vmx_inject_exception>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr_info);
+	 *   - arch/x86/kvm/vmx/vmx.c|4653| <<vmx_vcpu_reset>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *   - arch/x86/kvm/vmx/vmx.c|4710| <<vmx_inject_irq>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr);
+	 *   - arch/x86/kvm/vmx/vmx.c|4740| <<vmx_inject_nmi>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+	 *   - arch/x86/kvm/vmx/vmx.c|6095| <<dump_vmcs>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *   - arch/x86/kvm/vmx/vmx.c|6952| <<vmx_cancel_injection>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *   - arch/x86/kvm/vmx/vmx.c|6956| <<vmx_cancel_injection>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *
+	 * bit 0-7: Vector of interrupt or exception
+	 * bit 8-10: interrupt type: 0-7不同的数, 0是external interrupt
+	 * bit 31: valid (cleared on every vm exit)
+	 */
 	vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr_info);
 
+	/*
+	 * 在以下调用vmx_clear_hlt():
+	 *   - arch/x86/kvm/vmx/vmx.c|1734| <<vmx_inject_exception>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|4712| <<vmx_inject_irq>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|4743| <<vmx_inject_nmi>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|7989| <<vmx_enter_smm>> vmx_clear_hlt(vcpu);
+	 */
 	vmx_clear_hlt(vcpu);
 }
 
@@ -2033,6 +2115,36 @@ static u64 vcpu_supported_debugctl(struct kvm_vcpu *vcpu)
 	return debugctl;
 }
 
+/*
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_vcpu_reset
+ * kvm_apic_accept_events
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_lapic_reg_write
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ */
 /*
  * Writes msr value into the appropriate "register".
  * Returns 0 on success, non-0 otherwise.
@@ -3939,6 +4051,11 @@ static void vmx_reset_x2apic_msrs(struct kvm_vcpu *vcpu, u8 mode)
 	}
 }
 
+/*
+ * 在以下使用vmx_update_msr_bitmap_x2apic():
+ *   - arch/x86/kvm/vmx/vmx.c|4313| <<vmx_refresh_apicv_exec_ctrl>> vmx_update_msr_bitmap_x2apic(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|6481| <<vmx_set_virtual_apic_mode>> vmx_update_msr_bitmap_x2apic(vcpu);
+ */
 static void vmx_update_msr_bitmap_x2apic(struct kvm_vcpu *vcpu)
 {
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
@@ -3947,6 +4064,10 @@ static void vmx_update_msr_bitmap_x2apic(struct kvm_vcpu *vcpu)
 	if (!cpu_has_vmx_msr_bitmap())
 		return;
 
+	/*
+	 * #define MSR_BITMAP_MODE_X2APIC          1
+	 * #define MSR_BITMAP_MODE_X2APIC_APICV    2
+	 */
 	if (cpu_has_secondary_exec_ctrls() &&
 	    (secondary_exec_controls_get(vmx) &
 	     SECONDARY_EXEC_VIRTUALIZE_X2APIC_MODE)) {
@@ -4102,6 +4223,10 @@ static int vmx_deliver_nested_posted_interrupt(struct kvm_vcpu *vcpu,
  * 2. If target vcpu isn't running(root mode), kick it to pick up the
  * interrupt from PIR in next vmentry.
  */
+/*
+ * 在以下使用vmx_deliver_posted_interrupt():
+ *   - arch/x86/kvm/vmx/vmx.c|4256| <<vmx_deliver_interrupt>> if (vmx_deliver_posted_interrupt(vcpu, vector)) {
+ */
 static int vmx_deliver_posted_interrupt(struct kvm_vcpu *vcpu, int vector)
 {
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
@@ -4187,6 +4312,13 @@ void vmx_set_constant_host_state(struct vcpu_vmx *vmx)
 	vmcs_write16(HOST_SS_SELECTOR, __KERNEL_DS);  /* 22.2.4 */
 	vmcs_write16(HOST_TR_SELECTOR, GDT_ENTRY_TSS*8);  /* 22.2.4 */
 
+	/*
+	 * 在以下使用host_idt_base:
+	 *   - arch/x86/kvm/vmx/vmx.c|518| <<global>> static unsigned long host_idt_base;
+	 *   - arch/x86/kvm/vmx/vmx.c|4304| <<vmx_set_constant_host_state>> vmcs_writel(HOST_IDTR_BASE, host_idt_base);
+	 *   - arch/x86/kvm/vmx/vmx.c|6972| <<handle_external_interrupt_irqoff>> gate_desc *desc = (gate_desc *)host_idt_base + vector;
+	 *   - arch/x86/kvm/vmx/vmx.c|8510| <<hardware_setup>> host_idt_base = dt.address;
+	 */
 	vmcs_writel(HOST_IDTR_BASE, host_idt_base);   /* 22.2.4 */
 
 	vmcs_writel(HOST_RIP, (unsigned long)vmx_vmexit); /* 22.2.5 */
@@ -4280,6 +4412,11 @@ static void vmx_refresh_apicv_exec_ctrl(struct kvm_vcpu *vcpu)
 					SECONDARY_EXEC_VIRTUAL_INTR_DELIVERY);
 	}
 
+	/*
+	 * 在以下使用vmx_update_msr_bitmap_x2apic():
+	 *   - arch/x86/kvm/vmx/vmx.c|4313| <<vmx_refresh_apicv_exec_ctrl>> vmx_update_msr_bitmap_x2apic(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|6481| <<vmx_set_virtual_apic_mode>> vmx_update_msr_bitmap_x2apic(vcpu);
+	 */
 	vmx_update_msr_bitmap_x2apic(vcpu);
 }
 
@@ -4610,8 +4747,33 @@ static void vmx_vcpu_reset(struct kvm_vcpu *vcpu, bool init_event)
 	if (kvm_mpx_supported())
 		vmcs_write64(GUEST_BNDCFGS, 0);
 
+	/*
+	 * vmx代码中主要使用VM_ENTRY_INTR_INFO_FIELD的地方:
+	 *   - arch/x86/kvm/vmx/nested.c|2366| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+	 *   - arch/x86/kvm/vmx/nested.c|2377| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *   - arch/x86/kvm/vmx/vmx.c|1732| <<vmx_inject_exception>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr_info);
+	 *   - arch/x86/kvm/vmx/vmx.c|4653| <<vmx_vcpu_reset>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *   - arch/x86/kvm/vmx/vmx.c|4710| <<vmx_inject_irq>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr);
+	 *   - arch/x86/kvm/vmx/vmx.c|4740| <<vmx_inject_nmi>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+	 *   - arch/x86/kvm/vmx/vmx.c|6095| <<dump_vmcs>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *   - arch/x86/kvm/vmx/vmx.c|6952| <<vmx_cancel_injection>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *   - arch/x86/kvm/vmx/vmx.c|6956| <<vmx_cancel_injection>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *
+	 * bit 0-7: Vector of interrupt or exception
+	 * bit 8-10: interrupt type: 0-7不同的数, 0是external interrupt
+	 * bit 31: valid (cleared on every vm exit)
+	 */
 	vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);  /* 22.2.1 */
 
+	/*
+	 * 在以下使用KVM_REQ_APIC_PAGE_RELOAD:
+	 *   - arch/x86/kvm/vmx/nested.c|4691| <<nested_vmx_vmexit>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|4645| <<vmx_vcpu_reset>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|6462| <<vmx_set_virtual_apic_mode>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+	 *   - arch/x86/kvm/x86.c|10340| <<kvm_arch_mmu_notifier_invalidate_range>> kvm_make_all_cpus_request(kvm, KVM_REQ_APIC_PAGE_RELOAD);
+	 *
+	 * 处理的函数kvm_vcpu_reload_apic_access_page()
+	 */
 	kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
 
 	vpid_sync_context(vmx->vpid);
@@ -4621,6 +4783,19 @@ static void vmx_vcpu_reset(struct kvm_vcpu *vcpu, bool init_event)
 
 static void vmx_enable_irq_window(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用CPU_BASED_INTR_WINDOW_EXITING:
+	 *   - arch/x86/kvm/vmx/nested.c|2243| <<prepare_vmcs02_early>> exec_control &= ~CPU_BASED_INTR_WINDOW_EXITING;
+	 *   - arch/x86/kvm/vmx/nested.c|3417| <<nested_vmx_enter_non_root_mode>> evaluate_pending_interrupts =
+	 *           exec_controls_get(vmx) & (CPU_BASED_INTR_WINDOW_EXITING | CPU_BASED_NMI_WINDOW_EXITING);
+	 *   - arch/x86/kvm/vmx/nested.c|3673| <<nested_vmx_run>> if (... !(nested_cpu_has(vmcs12, CPU_BASED_INTR_WINDOW_EXITING) &&
+	 *   - arch/x86/kvm/vmx/nested.c|6115| <<nested_vmx_l1_wants_exit>> return nested_cpu_has(vmcs12, CPU_BASED_INTR_WINDOW_EXITING);
+	 *   - arch/x86/kvm/vmx/nested.c|6713| <<nested_vmx_setup_ctls_msrs>> msrs->procbased_ctls_high &= CPU_BASED_INTR_WINDOW_EXITING |
+	 *   - arch/x86/kvm/vmx/vmx.c|4782| <<vmx_enable_irq_window>> exec_controls_setbit(to_vmx(vcpu), CPU_BASED_INTR_WINDOW_EXITING);
+	 *   - arch/x86/kvm/vmx/vmx.c|5562| <<handle_interrupt_window>> exec_controls_clearbit(to_vmx(vcpu), CPU_BASED_INTR_WINDOW_EXITING);
+	 *   - arch/x86/kvm/vmx/vmx.c|5790| <<handle_invalid_guest_state>> intr_window_requested =
+	 *           exec_controls_get(vmx) & CPU_BASED_INTR_WINDOW_EXITING;
+	 */
 	exec_controls_setbit(to_vmx(vcpu), CPU_BASED_INTR_WINDOW_EXITING);
 }
 
@@ -4635,10 +4810,35 @@ static void vmx_enable_nmi_window(struct kvm_vcpu *vcpu)
 	exec_controls_setbit(to_vmx(vcpu), CPU_BASED_NMI_WINDOW_EXITING);
 }
 
+/*
+ * 在以下调用vmx_inject_irq():
+ *   - arch/x86/kvm/x86.c|9518| <<inject_pending_event>> static_call(kvm_x86_inject_irq)(vcpu, true);
+ *   - arch/x86/kvm/x86.c|9637| <<inject_pending_event>> static_call(kvm_x86_inject_irq)(vcpu, false);
+ */
 static void vmx_inject_irq(struct kvm_vcpu *vcpu, bool reinjected)
 {
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
 	uint32_t intr;
+	/*
+	 * struct kvm_vcpu *vcpu:
+	 * -> struct kvm_vcpu_arch arch;
+	 *        struct kvm_queued_exception {
+	 *            bool pending;
+	 *            bool injected;
+	 *            bool has_error_code;
+	 *            u8 nr;
+	 *            u32 error_code;
+	 *            unsigned long payload;
+	 *            bool has_payload;
+	 *            u8 nested_apf;
+	 *        } exception;
+	 *
+	 *        struct kvm_queued_interrupt {
+	 *            bool injected;
+	 *            bool soft;
+	 *            u8 nr;
+	 *        } interrupt;
+	 */
 	int irq = vcpu->arch.interrupt.nr;
 
 	trace_kvm_inj_virq(irq, vcpu->arch.interrupt.soft, reinjected);
@@ -4658,8 +4858,31 @@ static void vmx_inject_irq(struct kvm_vcpu *vcpu, bool reinjected)
 			     vmx->vcpu.arch.event_exit_inst_len);
 	} else
 		intr |= INTR_TYPE_EXT_INTR;
+	/*
+	 * vmx代码中主要使用VM_ENTRY_INTR_INFO_FIELD的地方:
+	 *   - arch/x86/kvm/vmx/nested.c|2366| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+	 *   - arch/x86/kvm/vmx/nested.c|2377| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *   - arch/x86/kvm/vmx/vmx.c|1732| <<vmx_inject_exception>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr_info);
+	 *   - arch/x86/kvm/vmx/vmx.c|4653| <<vmx_vcpu_reset>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *   - arch/x86/kvm/vmx/vmx.c|4710| <<vmx_inject_irq>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr);
+	 *   - arch/x86/kvm/vmx/vmx.c|4740| <<vmx_inject_nmi>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+	 *   - arch/x86/kvm/vmx/vmx.c|6095| <<dump_vmcs>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *   - arch/x86/kvm/vmx/vmx.c|6952| <<vmx_cancel_injection>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *   - arch/x86/kvm/vmx/vmx.c|6956| <<vmx_cancel_injection>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *
+	 * bit 0-7: Vector of interrupt or exception
+	 * bit 8-10: interrupt type: 0-7不同的数, 0是external interrupt
+	 * bit 31: valid (cleared on every vm exit)
+	 */
 	vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr);
 
+	/*
+	 * 在以下调用vmx_clear_hlt():
+	 *   - arch/x86/kvm/vmx/vmx.c|1734| <<vmx_inject_exception>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|4712| <<vmx_inject_irq>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|4743| <<vmx_inject_nmi>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|7989| <<vmx_enter_smm>> vmx_clear_hlt(vcpu);
+	 */
 	vmx_clear_hlt(vcpu);
 }
 
@@ -4688,9 +4911,32 @@ static void vmx_inject_nmi(struct kvm_vcpu *vcpu)
 		return;
 	}
 
+	/*
+	 * vmx代码中主要使用VM_ENTRY_INTR_INFO_FIELD的地方:
+	 *   - arch/x86/kvm/vmx/nested.c|2366| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+	 *   - arch/x86/kvm/vmx/nested.c|2377| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *   - arch/x86/kvm/vmx/vmx.c|1732| <<vmx_inject_exception>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr_info);
+	 *   - arch/x86/kvm/vmx/vmx.c|4653| <<vmx_vcpu_reset>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *   - arch/x86/kvm/vmx/vmx.c|4710| <<vmx_inject_irq>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr);
+	 *   - arch/x86/kvm/vmx/vmx.c|4740| <<vmx_inject_nmi>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+	 *   - arch/x86/kvm/vmx/vmx.c|6095| <<dump_vmcs>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *   - arch/x86/kvm/vmx/vmx.c|6952| <<vmx_cancel_injection>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *   - arch/x86/kvm/vmx/vmx.c|6956| <<vmx_cancel_injection>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *
+	 * bit 0-7: Vector of interrupt or exception
+	 * bit 8-10: interrupt type: 0-7不同的数, 0是external interrupt
+	 * bit 31: valid (cleared on every vm exit)
+	 */
 	vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
 			INTR_TYPE_NMI_INTR | INTR_INFO_VALID_MASK | NMI_VECTOR);
 
+	/*
+	 * 在以下调用vmx_clear_hlt():
+	 *   - arch/x86/kvm/vmx/vmx.c|1734| <<vmx_inject_exception>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|4712| <<vmx_inject_irq>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|4743| <<vmx_inject_nmi>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|7989| <<vmx_enter_smm>> vmx_clear_hlt(vcpu);
+	 */
 	vmx_clear_hlt(vcpu);
 }
 
@@ -4728,6 +4974,11 @@ void vmx_set_nmi_mask(struct kvm_vcpu *vcpu, bool masked)
 	}
 }
 
+/*
+ * 在以下调用vmx_nmi_blocked():
+ *   - arch/x86/kvm/vmx/nested.c|4019| <<vmx_check_nested_events>> if (vcpu->arch.nmi_pending && !vmx_nmi_blocked(vcpu)) {
+ *   - arch/x86/kvm/vmx/vmx.c|4995| <<vmx_nmi_allowed>> return !vmx_nmi_blocked(vcpu);
+ */
 bool vmx_nmi_blocked(struct kvm_vcpu *vcpu)
 {
 	if (is_guest_mode(vcpu) && nested_exit_on_nmi(vcpu))
@@ -4741,6 +4992,12 @@ bool vmx_nmi_blocked(struct kvm_vcpu *vcpu)
 		 GUEST_INTR_STATE_NMI));
 }
 
+/*
+ * 在以下使用kvm_x86_nmi_allowed():
+ *   - arch/x86/kvm/x86.c|9727| <<inject_pending_event>> r = can_inject ? static_call(kvm_x86_nmi_allowed)(vcpu, true) : -EBUSY;
+ *   - arch/x86/kvm/x86.c|9735| <<inject_pending_event>> WARN_ON(static_call(kvm_x86_nmi_allowed)(vcpu, true) < 0);
+ *   - arch/x86/kvm/x86.c|13270| <<kvm_vcpu_has_events>> static_call(kvm_x86_nmi_allowed)(vcpu, false)))
+ */
 static int vmx_nmi_allowed(struct kvm_vcpu *vcpu, bool for_injection)
 {
 	if (to_vmx(vcpu)->nested.nested_run_pending)
@@ -4884,6 +5141,18 @@ static int handle_machine_check(struct kvm_vcpu *vcpu)
  */
 bool vmx_guest_inject_ac(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用X86_FEATURE_SPLIT_LOCK_DETECT:
+	 *   - arch/x86/kernel/cpu/intel.c|1149| <<sld_state_setup>> if (!boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) &&
+	 *   - arch/x86/kernel/cpu/intel.c|1221| <<__split_lock_setup>> setup_force_cpu_cap(X86_FEATURE_SPLIT_LOCK_DETECT);
+	 *   - arch/x86/kernel/cpu/intel.c|1475| <<bus_lock_init>> if ((boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) &&
+	 *   - arch/x86/kernel/cpu/intel.c|1621| <<sld_state_show>> !boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 *   - arch/x86/kernel/cpu/intel.c|1643| <<sld_state_show>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1653| <<sld_state_show>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1657| <<sld_state_show>> boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) ?
+	 *   - arch/x86/kvm/vmx/vmx.c|4917| <<vmx_guest_inject_ac>> if (!boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 *   - arch/x86/kvm/x86.c|7297| <<emulator_cmpxchg_emulated>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 */
 	if (!boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
 		return true;
 
@@ -5318,6 +5587,19 @@ static int handle_tpr_below_threshold(struct kvm_vcpu *vcpu)
 
 static int handle_interrupt_window(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用CPU_BASED_INTR_WINDOW_EXITING:
+	 *   - arch/x86/kvm/vmx/nested.c|2243| <<prepare_vmcs02_early>> exec_control &= ~CPU_BASED_INTR_WINDOW_EXITING;
+	 *   - arch/x86/kvm/vmx/nested.c|3417| <<nested_vmx_enter_non_root_mode>> evaluate_pending_interrupts =
+	 *           exec_controls_get(vmx) & (CPU_BASED_INTR_WINDOW_EXITING | CPU_BASED_NMI_WINDOW_EXITING);
+	 *   - arch/x86/kvm/vmx/nested.c|3673| <<nested_vmx_run>> if (... !(nested_cpu_has(vmcs12, CPU_BASED_INTR_WINDOW_EXITING) &&
+	 *   - arch/x86/kvm/vmx/nested.c|6115| <<nested_vmx_l1_wants_exit>> return nested_cpu_has(vmcs12, CPU_BASED_INTR_WINDOW_EXITING);
+	 *   - arch/x86/kvm/vmx/nested.c|6713| <<nested_vmx_setup_ctls_msrs>> msrs->procbased_ctls_high &= CPU_BASED_INTR_WINDOW_EXITING |
+	 *   - arch/x86/kvm/vmx/vmx.c|4782| <<vmx_enable_irq_window>> exec_controls_setbit(to_vmx(vcpu), CPU_BASED_INTR_WINDOW_EXITING);
+	 *   - arch/x86/kvm/vmx/vmx.c|5562| <<handle_interrupt_window>> exec_controls_clearbit(to_vmx(vcpu), CPU_BASED_INTR_WINDOW_EXITING);
+	 *   - arch/x86/kvm/vmx/vmx.c|5790| <<handle_invalid_guest_state>> intr_window_requested =
+	 *           exec_controls_get(vmx) & CPU_BASED_INTR_WINDOW_EXITING;
+	 */
 	exec_controls_clearbit(to_vmx(vcpu), CPU_BASED_INTR_WINDOW_EXITING);
 
 	kvm_make_request(KVM_REQ_EVENT, vcpu);
@@ -5407,6 +5689,16 @@ static int handle_task_switch(struct kvm_vcpu *vcpu)
 			break;
 		case INTR_TYPE_EXT_INTR:
 		case INTR_TYPE_SOFT_INTR:
+			/*
+			 * 在以下调用kvm_clear_interrupt_queue():
+			 *   - arch/x86/kvm/svm/nested.c|1017| <<nested_svm_vmexit>> kvm_clear_interrupt_queue(vcpu);
+			 *   - arch/x86/kvm/svm/svm.c|2556| <<task_switch_interception>> kvm_clear_interrupt_queue(vcpu);
+			 *   - arch/x86/kvm/svm/svm.c|4012| <<svm_complete_interrupts>> kvm_clear_interrupt_queue(vcpu);
+			 *   - arch/x86/kvm/vmx/nested.c|4645| <<nested_vmx_vmexit>> kvm_clear_interrupt_queue(vcpu);
+			 *   - arch/x86/kvm/vmx/vmx.c|5440| <<handle_task_switch>> kvm_clear_interrupt_queue(vcpu);
+			 *   - arch/x86/kvm/vmx/vmx.c|6799| <<__vmx_complete_interrupts>> kvm_clear_interrupt_queue(vcpu);
+			 *   - arch/x86/kvm/x86.c|11947| <<kvm_vcpu_reset>> kvm_clear_interrupt_queue(vcpu);
+			 */
 			kvm_clear_interrupt_queue(vcpu);
 			break;
 		case INTR_TYPE_HARD_EXCEPTION:
@@ -5517,6 +5809,9 @@ static int handle_ept_misconfig(struct kvm_vcpu *vcpu)
 	return kvm_mmu_page_fault(vcpu, gpa, PFERR_RSVD_MASK, NULL, 0);
 }
 
+/*
+ * EXIT_REASON_NMI_WINDOW
+ */
 static int handle_nmi_window(struct kvm_vcpu *vcpu)
 {
 	if (KVM_BUG_ON(!enable_vnmi, vcpu->kvm))
@@ -5686,10 +5981,22 @@ static int handle_pml_full(struct kvm_vcpu *vcpu)
 	return 1;
 }
 
+/*
+ * 在以下调用handle_fastpath_preemption_timer():
+ *   - arch/x86/kvm/vmx/vmx.c|5704| <<handle_preemption_timer>> handle_fastpath_preemption_timer(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|6875| <<vmx_exit_handlers_fastpath>> return handle_fastpath_preemption_timer(vcpu);
+ */
 static fastpath_t handle_fastpath_preemption_timer(struct kvm_vcpu *vcpu)
 {
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
 
+	/*
+	 * 在以下使用vcpu_vmx->req_immediate_exit:
+	 *   - arch/x86/kvm/vmx/vmx.c|1196| <<vmx_prepare_switch_to_guest>> vmx->req_immediate_exit = false;
+	 *   - arch/x86/kvm/vmx/vmx.c|5906| <<handle_fastpath_preemption_timer>> if (!vmx->req_immediate_exit &&
+	 *   - arch/x86/kvm/vmx/vmx.c|7146| <<vmx_update_hv_timer>> if (vmx->req_immediate_exit) {
+	 *   - arch/x86/kvm/vmx/vmx.c|7907| <<vmx_request_immediate_exit>> to_vmx(vcpu)->req_immediate_exit = true;
+	 */
 	if (!vmx->req_immediate_exit &&
 	    !unlikely(vmx->loaded_vmcs->hv_timer_soft_disabled)) {
 		kvm_lapic_expired_hv_timer(vcpu);
@@ -5801,6 +6108,13 @@ static int (*kvm_vmx_exit_handlers[])(struct kvm_vcpu *vcpu) = {
 static const int kvm_vmx_max_exit_handlers =
 	ARRAY_SIZE(kvm_vmx_exit_handlers);
 
+/*
+ * 在以下使用kvm_x86_get_exit_info():
+ *   - arch/x86/kvm/trace.h|309| <<TRACE_EVENT_KVM_EXIT>> static_call(kvm_x86_get_exit_info)(vcpu, \
+ *   - arch/x86/kvm/x86.c|8150| <<prepare_emulation_failure_exit>> static_call(kvm_x86_get_exit_info)(vcpu, (u32 *)&info[0], &info[1],
+ *
+ * struct kvm_x86_ops vmx_x86_ops.get_exit_info = vmx_get_exit_info()
+ */
 static void vmx_get_exit_info(struct kvm_vcpu *vcpu, u32 *reason,
 			      u64 *info1, u64 *info2,
 			      u32 *intr_info, u32 *error_code)
@@ -5810,7 +6124,35 @@ static void vmx_get_exit_info(struct kvm_vcpu *vcpu, u32 *reason,
 	*reason = vmx->exit_reason.full;
 	*info1 = vmx_get_exit_qual(vcpu);
 	if (!(vmx->exit_reason.failed_vmentry)) {
+		/*
+		 * 在以下使用vcpu_vmx->idt_vectoring_info:
+		 *   - arch/x86/kvm/vmx/vmx.c|5129| <<handle_exception_nmi>> vect_info = vmx->idt_vectoring_info;
+		 *   - arch/x86/kvm/vmx/vmx.c|5622| <<handle_task_switch>> idt_v = (vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK);
+		 *   - arch/x86/kvm/vmx/vmx.c|5623| <<handle_task_switch>> idt_index = (vmx->idt_vectoring_info & VECTORING_INFO_VECTOR_MASK);
+		 *   - arch/x86/kvm/vmx/vmx.c|5624| <<handle_task_switch>> type = (vmx->idt_vectoring_info & VECTORING_INFO_TYPE_MASK);
+		 *   - arch/x86/kvm/vmx/vmx.c|5650| <<handle_task_switch>> if (vmx->idt_vectoring_info &
+		 *   - arch/x86/kvm/vmx/vmx.c|5694| <<handle_ept_violation>> if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&
+		 *   - arch/x86/kvm/vmx/vmx.c|5913| <<handle_pml_full>> if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&
+		 *   - arch/x86/kvm/vmx/vmx.c|6062| <<vmx_get_exit_info>> *info2 = vmx->idt_vectoring_info;
+		 *   - arch/x86/kvm/vmx/vmx.c|6314| <<__vmx_handle_exit>> u32 vectoring_info = vmx->idt_vectoring_info;
+		 *   - arch/x86/kvm/vmx/vmx.c|6989| <<vmx_recover_nmi_blocking>> idtv_info_valid = vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK;
+		 *   - arch/x86/kvm/vmx/vmx.c|7125| <<vmx_complete_interrupts>> __vmx_complete_interrupts(&vmx->vcpu, vmx->idt_vectoring_info,
+		 *   - arch/x86/kvm/vmx/vmx.c|7427| <<vmx_vcpu_run>> vmx->idt_vectoring_info = 0;
+		 *   - arch/x86/kvm/vmx/vmx.c|7439| <<vmx_vcpu_run>> vmx->idt_vectoring_info = vmcs_read32(IDT_VECTORING_INFO_FIELD);
+		 */
 		*info2 = vmx->idt_vectoring_info;
+		/*
+		 * 在以下使用vmx_get_intr_info():
+		 *   - arch/x86/kvm/vmx/nested.c|5790| <<handle_vmfunc>> vmx_get_intr_info(vcpu),
+		 *   - arch/x86/kvm/vmx/nested.c|6031| <<nested_vmx_l0_wants_exit>> intr_info = vmx_get_intr_info(vcpu);
+		 *   - arch/x86/kvm/vmx/nested.c|6103| <<nested_vmx_l1_wants_exit>> intr_info = vmx_get_intr_info(vcpu);
+		 *   - arch/x86/kvm/vmx/nested.c|6257| <<nested_vmx_reflect_vmexit>> exit_intr_info = vmx_get_intr_info(vcpu);
+		 *   - arch/x86/kvm/vmx/vmx.c|5130| <<handle_exception_nmi>> intr_info = vmx_get_intr_info(vcpu);
+		 *   - arch/x86/kvm/vmx/vmx.c|6079| <<vmx_get_exit_info>> *intr_info = vmx_get_intr_info(vcpu);
+		 *   - arch/x86/kvm/vmx/vmx.c|6948| <<handle_exception_nmi_irqoff>> u32 intr_info = vmx_get_intr_info(&vmx->vcpu);
+		 *   - arch/x86/kvm/vmx/vmx.c|6966| <<handle_external_interrupt_irqoff>> u32 intr_info = vmx_get_intr_info(vcpu);
+		 *   - arch/x86/kvm/vmx/vmx.c|7027| <<vmx_recover_nmi_blocking>> exit_intr_info = vmx_get_intr_info(&vmx->vcpu);
+		 */
 		*intr_info = vmx_get_intr_info(vcpu);
 		if (is_exception_with_error_code(*intr_info))
 			*error_code = vmcs_read32(VM_EXIT_INTR_ERROR_CODE);
@@ -6062,6 +6404,22 @@ static int __vmx_handle_exit(struct kvm_vcpu *vcpu, fastpath_t exit_fastpath)
 {
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
 	union vmx_exit_reason exit_reason = vmx->exit_reason;
+	/*
+	 * 在以下使用vcpu_vmx->idt_vectoring_info:
+	 *   - arch/x86/kvm/vmx/vmx.c|5129| <<handle_exception_nmi>> vect_info = vmx->idt_vectoring_info;
+	 *   - arch/x86/kvm/vmx/vmx.c|5622| <<handle_task_switch>> idt_v = (vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK);
+	 *   - arch/x86/kvm/vmx/vmx.c|5623| <<handle_task_switch>> idt_index = (vmx->idt_vectoring_info & VECTORING_INFO_VECTOR_MASK);
+	 *   - arch/x86/kvm/vmx/vmx.c|5624| <<handle_task_switch>> type = (vmx->idt_vectoring_info & VECTORING_INFO_TYPE_MASK);
+	 *   - arch/x86/kvm/vmx/vmx.c|5650| <<handle_task_switch>> if (vmx->idt_vectoring_info &
+	 *   - arch/x86/kvm/vmx/vmx.c|5694| <<handle_ept_violation>> if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&
+	 *   - arch/x86/kvm/vmx/vmx.c|5913| <<handle_pml_full>> if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&
+	 *   - arch/x86/kvm/vmx/vmx.c|6062| <<vmx_get_exit_info>> *info2 = vmx->idt_vectoring_info;
+	 *   - arch/x86/kvm/vmx/vmx.c|6314| <<__vmx_handle_exit>> u32 vectoring_info = vmx->idt_vectoring_info;
+	 *   - arch/x86/kvm/vmx/vmx.c|6989| <<vmx_recover_nmi_blocking>> idtv_info_valid = vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK;
+	 *   - arch/x86/kvm/vmx/vmx.c|7125| <<vmx_complete_interrupts>> __vmx_complete_interrupts(&vmx->vcpu, vmx->idt_vectoring_info,
+	 *   - arch/x86/kvm/vmx/vmx.c|7427| <<vmx_vcpu_run>> vmx->idt_vectoring_info = 0;
+	 *   - arch/x86/kvm/vmx/vmx.c|7439| <<vmx_vcpu_run>> vmx->idt_vectoring_info = vmcs_read32(IDT_VECTORING_INFO_FIELD);
+	 */
 	u32 vectoring_info = vmx->idt_vectoring_info;
 	u16 exit_handler_index;
 
@@ -6236,6 +6594,36 @@ static int __vmx_handle_exit(struct kvm_vcpu *vcpu, fastpath_t exit_fastpath)
 	return 0;
 }
 
+/*
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_vcpu_reset
+ * kvm_apic_accept_events
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_lapic_reg_write
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ */
 static int vmx_handle_exit(struct kvm_vcpu *vcpu, fastpath_t exit_fastpath)
 {
 	int ret = __vmx_handle_exit(vcpu, exit_fastpath);
@@ -6372,6 +6760,15 @@ void vmx_set_virtual_apic_mode(struct kvm_vcpu *vcpu)
 		if (flexpriority_enabled) {
 			sec_exec_control |=
 				SECONDARY_EXEC_VIRTUALIZE_APIC_ACCESSES;
+			/*
+			 * 在以下使用KVM_REQ_APIC_PAGE_RELOAD:
+			 *   - arch/x86/kvm/vmx/nested.c|4691| <<nested_vmx_vmexit>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+			 *   - arch/x86/kvm/vmx/vmx.c|4645| <<vmx_vcpu_reset>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+			 *   - arch/x86/kvm/vmx/vmx.c|6462| <<vmx_set_virtual_apic_mode>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+			 *   - arch/x86/kvm/x86.c|10340| <<kvm_arch_mmu_notifier_invalidate_range>> kvm_make_all_cpus_request(kvm, KVM_REQ_APIC_PAGE_RELOAD);
+			 *
+			 * 处理的函数kvm_vcpu_reload_apic_access_page()
+			 */
 			kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
 
 			/*
@@ -6391,6 +6788,11 @@ void vmx_set_virtual_apic_mode(struct kvm_vcpu *vcpu)
 	}
 	secondary_exec_controls_set(vmx, sec_exec_control);
 
+	/*
+	 * 在以下使用vmx_update_msr_bitmap_x2apic():
+	 *   - arch/x86/kvm/vmx/vmx.c|4313| <<vmx_refresh_apicv_exec_ctrl>> vmx_update_msr_bitmap_x2apic(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|6481| <<vmx_set_virtual_apic_mode>> vmx_update_msr_bitmap_x2apic(vcpu);
+	 */
 	vmx_update_msr_bitmap_x2apic(vcpu);
 }
 
@@ -6422,6 +6824,33 @@ static void vmx_set_apic_access_page_addr(struct kvm_vcpu *vcpu)
 	put_page(page);
 }
 
+/*
+ * vmx_hwapic_isr_update
+ * kvm_lapic_reset
+ * kvm_vcpu_reset
+ * kvm_apic_accept_events
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * vmx_hwapic_isr_update
+ * kvm_apic_set_state
+ * kvm_arch_vcpu_ioctl
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * 在以下调用kvm_x86_hwapic_isr_update:
+ *   - arch/x86/kvm/lapic.c|1003| <<apic_set_isr>> static_call(kvm_x86_hwapic_isr_update)(vcpu, vec);
+ *   - arch/x86/kvm/lapic.c|1129| <<apic_clear_isr>> static_call(kvm_x86_hwapic_isr_update)(vcpu, apic_find_highest_isr(apic));
+ *   - arch/x86/kvm/lapic.c|3622| <<kvm_lapic_reset>> static_call(kvm_x86_hwapic_isr_update)(vcpu, -1);
+ *   - arch/x86/kvm/lapic.c|4127| <<kvm_apic_set_state>> static_call(kvm_x86_hwapic_isr_update)(vcpu, apic_find_highest_isr(apic));
+ *
+ * struct kvm_x86_ops vmx_x86_ops.hwapic_isr_update = vmx_hwapic_isr_update()
+ */
 static void vmx_hwapic_isr_update(struct kvm_vcpu *vcpu, int max_isr)
 {
 	u16 status;
@@ -6439,6 +6868,11 @@ static void vmx_hwapic_isr_update(struct kvm_vcpu *vcpu, int max_isr)
 	}
 }
 
+/*
+ * 在以下使用vmx_set_rvi():
+ *   - arch/x86/kvm/vmx/vmx.c|6884| <<vmx_hwapic_irr_update>> vmx_set_rvi(max_irr);
+ *   - arch/x86/kvm/vmx/vmx.c|6936| <<vmx_sync_pir_to_irr>> vmx_set_rvi(max_irr);
+ */
 static void vmx_set_rvi(int vector)
 {
 	u16 status;
@@ -6447,6 +6881,11 @@ static void vmx_set_rvi(int vector)
 	if (vector == -1)
 		vector = 0;
 
+	/*
+	 * GUEST_INTR_STATUS一共16位
+	 * 低16位是RVI
+	 * 高16位是SVI
+	 */
 	status = vmcs_read16(GUEST_INTR_STATUS);
 	old = (u8)status & 0xff;
 	if ((u8)vector != old) {
@@ -6456,6 +6895,9 @@ static void vmx_set_rvi(int vector)
 	}
 }
 
+/*
+ * struct kvm_x86_ops vmx_x86_opshwapic_irr_update = vmx_hwapic_irr_update()
+ */
 static void vmx_hwapic_irr_update(struct kvm_vcpu *vcpu, int max_irr)
 {
 	/*
@@ -6466,10 +6908,25 @@ static void vmx_hwapic_irr_update(struct kvm_vcpu *vcpu, int max_irr)
 	 * we should not update vmcs02 RVI but instead intercept
 	 * interrupt. Therefore, do nothing when running L2.
 	 */
+	/*
+	 * 在以下使用vmx_set_rvi():
+	 *   - arch/x86/kvm/vmx/vmx.c|6884| <<vmx_hwapic_irr_update>> vmx_set_rvi(max_irr);
+	 *   - arch/x86/kvm/vmx/vmx.c|6936| <<vmx_sync_pir_to_irr>> vmx_set_rvi(max_irr);
+	 */
 	if (!is_guest_mode(vcpu))
 		vmx_set_rvi(max_irr);
 }
 
+/*
+ * 在以下调用kvm_x86_sync_pir_to_irr()
+ *   - arch/x86/kvm/lapic.c|789| <<apic_has_interrupt_for_ppr>> highest_irr = static_call(kvm_x86_sync_pir_to_irr)(apic->vcpu);
+ *   - arch/x86/kvm/x86.c|4623| <<kvm_vcpu_ioctl_get_lapic>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+ *   - arch/x86/kvm/x86.c|9842| <<vcpu_scan_ioapic>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+ *   - arch/x86/kvm/x86.c|10171| <<vcpu_enter_guest>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+ *   - arch/x86/kvm/x86.c|10220| <<vcpu_enter_guest>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+ *
+ * struct kvm_x86_ops vmx_x86_ops.sync_pir_to_irr = vmx_sync_pir_to_irr()
+ */
 static int vmx_sync_pir_to_irr(struct kvm_vcpu *vcpu)
 {
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
@@ -6508,6 +6965,15 @@ static int vmx_sync_pir_to_irr(struct kvm_vcpu *vcpu)
 	 * attempt to post interrupts.  The posted interrupt vector will cause
 	 * a VM-Exit and the subsequent entry will call sync_pir_to_irr.
 	 */
+	/*
+	 * 在以下设置kvm_vcpu_arch->apicv_active:
+	 *   - arch/x86/kvm/x86.c|9800| <<kvm_vcpu_update_apicv>> vcpu->arch.apicv_active = activate;
+	 *   - arch/x86/kvm/x86.c|11393| <<kvm_arch_vcpu_create>> vcpu->arch.apicv_active = true;
+	 *
+	 * 在以下使用vmx_set_rvi():
+	 *   - arch/x86/kvm/vmx/vmx.c|6884| <<vmx_hwapic_irr_update>> vmx_set_rvi(max_irr);
+	 *   - arch/x86/kvm/vmx/vmx.c|6936| <<vmx_sync_pir_to_irr>> vmx_set_rvi(max_irr);
+	 */
 	if (!is_guest_mode(vcpu) && kvm_vcpu_apicv_active(vcpu))
 		vmx_set_rvi(max_irr);
 	else if (got_posted_interrupt)
@@ -6516,6 +6982,13 @@ static int vmx_sync_pir_to_irr(struct kvm_vcpu *vcpu)
 	return max_irr;
 }
 
+/*
+ * 在以下调用kvm_x86_load_eoi_exitmap():
+ *   - arch/x86/kvm/x86.c|9921| <<vcpu_load_eoi_exitmap>> static_call(kvm_x86_load_eoi_exitmap)(vcpu, eoi_exit_bitmap);
+ *   - arch/x86/kvm/x86.c|9928| <<vcpu_load_eoi_exitmap>> static_call(kvm_x86_load_eoi_exitmap)(
+ *
+ * 在以下使用struct kvm_x86_ops vmx_x86_ops.load_eoi_exitmap = vmx_load_eoi_exitmap()
+ */
 static void vmx_load_eoi_exitmap(struct kvm_vcpu *vcpu, u64 *eoi_exit_bitmap)
 {
 	if (!kvm_vcpu_apicv_active(vcpu))
@@ -6537,9 +7010,20 @@ static void vmx_apicv_post_state_restore(struct kvm_vcpu *vcpu)
 
 void vmx_do_interrupt_nmi_irqoff(unsigned long entry);
 
+/*
+ * 在以下调用handle_interrupt_nmi_irqoff():
+ *   - arch/x86/kvm/vmx/vmx.c|6961| <<handle_exception_nmi_irqoff>> handle_interrupt_nmi_irqoff(&vmx->vcpu, nmi_entry);
+ *   - arch/x86/kvm/vmx/vmx.c|6978| <<handle_external_interrupt_irqoff>> handle_interrupt_nmi_irqoff(vcpu, gate_offset(desc));
+ */
 static void handle_interrupt_nmi_irqoff(struct kvm_vcpu *vcpu,
 					unsigned long entry)
 {
+	/*
+	 * 在以下使用kvm_before_interrupt():
+	 *   - arch/x86/kvm/svm/svm.c|4206| <<svm_vcpu_run>> kvm_before_interrupt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|6920| <<handle_interrupt_nmi_irqoff>> kvm_before_interrupt(vcpu);
+	 *   - arch/x86/kvm/x86.c|11036| <<vcpu_enter_guest>> kvm_before_interrupt(vcpu);
+	 */
 	kvm_before_interrupt(vcpu);
 	vmx_do_interrupt_nmi_irqoff(entry);
 	kvm_after_interrupt(vcpu);
@@ -6565,9 +7049,16 @@ static void handle_nm_fault_irqoff(struct kvm_vcpu *vcpu)
 		rdmsrl(MSR_IA32_XFD_ERR, vcpu->arch.guest_fpu.xfd_err);
 }
 
+/*
+ * 处理EXIT_REASON_EXCEPTION_NMI:
+ *   - arch/x86/kvm/vmx/vmx.c|6992| <<vmx_handle_exit_irqoff>> handle_exception_nmi_irqoff(vmx);
+ */
 static void handle_exception_nmi_irqoff(struct vcpu_vmx *vmx)
 {
 	const unsigned long nmi_entry = (unsigned long)asm_exc_nmi_noist;
+	/*
+	 * 告诉VMM(Hypervisor)此次VM-exit是由于某个中断,异常或NMI等原因引起的
+	 */
 	u32 intr_info = vmx_get_intr_info(&vmx->vcpu);
 
 	/* if exit due to PF check for async PF */
@@ -6582,22 +7073,57 @@ static void handle_exception_nmi_irqoff(struct vcpu_vmx *vmx)
 	/* We need to handle NMIs before interrupts are enabled */
 	else if (is_nmi(intr_info))
 		handle_interrupt_nmi_irqoff(&vmx->vcpu, nmi_entry);
+
+	/*
+	 * 在以下调用handle_interrupt_nmi_irqoff():
+	 *   - arch/x86/kvm/vmx/vmx.c|6961| <<handle_exception_nmi_irqoff>> handle_interrupt_nmi_irqoff(&vmx->vcpu, nmi_entry);
+	 *   - arch/x86/kvm/vmx/vmx.c|6978| <<handle_external_interrupt_irqoff>> handle_interrupt_nmi_irqoff(vcpu, gate_offset(desc));
+	 */
 }
 
+/*
+ * 处理EXIT_REASON_EXTERNAL_INTERRUPT:
+ *   - arch/x86/kvm/vmx/vmx.c|6986| <<vmx_handle_exit_irqoff>> handle_external_interrupt_irqoff(vcpu);
+ */
 static void handle_external_interrupt_irqoff(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 告诉VMM(Hypervisor)此次VM-exit是由于某个中断,异常或NMI等原因引起的
+	 */
 	u32 intr_info = vmx_get_intr_info(vcpu);
 	unsigned int vector = intr_info & INTR_INFO_VECTOR_MASK;
+	/*
+	 * 在以下使用host_idt_base:
+	 *   - arch/x86/kvm/vmx/vmx.c|518| <<global>> static unsigned long host_idt_base;
+	 *   - arch/x86/kvm/vmx/vmx.c|4304| <<vmx_set_constant_host_state>> vmcs_writel(HOST_IDTR_BASE, host_idt_base);
+	 *   - arch/x86/kvm/vmx/vmx.c|6972| <<handle_external_interrupt_irqoff>> gate_desc *desc = (gate_desc *)host_idt_base + vector;
+	 *   - arch/x86/kvm/vmx/vmx.c|8510| <<hardware_setup>> host_idt_base = dt.address;
+	 */
 	gate_desc *desc = (gate_desc *)host_idt_base + vector;
 
 	if (KVM_BUG(!is_external_intr(intr_info), vcpu->kvm,
 	    "KVM: unexpected VM-Exit interrupt info: 0x%x", intr_info))
 		return;
 
+	/*
+	 * 在以下调用handle_interrupt_nmi_irqoff():
+	 *   - arch/x86/kvm/vmx/vmx.c|6961| <<handle_exception_nmi_irqoff>> handle_interrupt_nmi_irqoff(&vmx->vcpu, nmi_entry);
+	 *   - arch/x86/kvm/vmx/vmx.c|6978| <<handle_external_interrupt_irqoff>> handle_interrupt_nmi_irqoff(vcpu, gate_offset(desc));
+	 */
 	handle_interrupt_nmi_irqoff(vcpu, gate_offset(desc));
+	/*
+	 * 在以下使用kvm_vcpu_arch->at_instruction_boundary:
+	 *   - arch/x86/kvm/svm/svm.c|4585| <<svm_handle_exit_irqoff>> vcpu->arch.at_instruction_boundary = true;
+	 *   - arch/x86/kvm/vmx/vmx.c|6979| <<handle_external_interrupt_irqoff>> vcpu->arch.at_instruction_boundary = true;
+	 *   - arch/x86/kvm/x86.c|4744| <<kvm_steal_time_set_preempted>> if (!vcpu->arch.at_instruction_boundary) {
+	 *   - arch/x86/kvm/x86.c|11223| <<vcpu_run>> vcpu->arch.at_instruction_boundary = false;
+	 */
 	vcpu->arch.at_instruction_boundary = true;
 }
 
+/*
+ * struct kvm_x86_ops vmx_x86_ops.handle_exit_irqoff = vmx_handle_exit_irqoff()
+ */
 static void vmx_handle_exit_irqoff(struct kvm_vcpu *vcpu)
 {
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
@@ -6674,6 +7200,29 @@ static void vmx_recover_nmi_blocking(struct vcpu_vmx *vmx)
 					      vmx->loaded_vmcs->entry_time));
 }
 
+/*
+ * 在以下使用vcpu_vmx->idt_vectoring_info:
+ *   - arch/x86/kvm/vmx/vmx.c|5129| <<handle_exception_nmi>> vect_info = vmx->idt_vectoring_info;
+ *   - arch/x86/kvm/vmx/vmx.c|5622| <<handle_task_switch>> idt_v = (vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK);
+ *   - arch/x86/kvm/vmx/vmx.c|5623| <<handle_task_switch>> idt_index = (vmx->idt_vectoring_info & VECTORING_INFO_VECTOR_MASK);
+ *   - arch/x86/kvm/vmx/vmx.c|5624| <<handle_task_switch>> type = (vmx->idt_vectoring_info & VECTORING_INFO_TYPE_MASK);
+ *   - arch/x86/kvm/vmx/vmx.c|5650| <<handle_task_switch>> if (vmx->idt_vectoring_info &
+ *   - arch/x86/kvm/vmx/vmx.c|5694| <<handle_ept_violation>> if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&
+ *   - arch/x86/kvm/vmx/vmx.c|5913| <<handle_pml_full>> if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&
+ *   - arch/x86/kvm/vmx/vmx.c|6062| <<vmx_get_exit_info>> *info2 = vmx->idt_vectoring_info;
+ *   - arch/x86/kvm/vmx/vmx.c|6314| <<__vmx_handle_exit>> u32 vectoring_info = vmx->idt_vectoring_info;
+ *   - arch/x86/kvm/vmx/vmx.c|6989| <<vmx_recover_nmi_blocking>> idtv_info_valid = vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK;
+ *   - arch/x86/kvm/vmx/vmx.c|7125| <<vmx_complete_interrupts>> __vmx_complete_interrupts(&vmx->vcpu, vmx->idt_vectoring_info,
+ *   - arch/x86/kvm/vmx/vmx.c|7427| <<vmx_vcpu_run>> vmx->idt_vectoring_info = 0;
+ *   - arch/x86/kvm/vmx/vmx.c|7439| <<vmx_vcpu_run>> vmx->idt_vectoring_info = vmcs_read32(IDT_VECTORING_INFO_FIELD);
+ *
+ *
+ * 在以下使用__vmx_complete_interrupts():
+ *   - arch/x86/kvm/vmx/vmx.c|6842| <<vmx_complete_interrupts>> __vmx_complete_interrupts(&vmx->vcpu, vmx->idt_vectoring_info,
+ *                                        VM_EXIT_INSTRUCTION_LEN, IDT_VECTORING_ERROR_CODE);
+ *   - arch/x86/kvm/vmx/vmx.c|6849| <<vmx_cancel_injection>> __vmx_complete_interrupts(vcpu, vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+ *                                        VM_ENTRY_INSTRUCTION_LEN, VM_ENTRY_EXCEPTION_ERROR_CODE);
+ */
 static void __vmx_complete_interrupts(struct kvm_vcpu *vcpu,
 				      u32 idt_vectoring_info,
 				      int instr_len_field,
@@ -6683,15 +7232,39 @@ static void __vmx_complete_interrupts(struct kvm_vcpu *vcpu,
 	int type;
 	bool idtv_info_valid;
 
+	/*
+	 * 描述原本准备注入给 guest 的中断,但由于 VM-exit 等原因被中断了.
+	 */
+
 	idtv_info_valid = idt_vectoring_info & VECTORING_INFO_VALID_MASK;
 
 	vcpu->arch.nmi_injected = false;
+	/*
+	 * 在以下调用kvm_clear_interrupt_queue():
+	 *   - arch/x86/kvm/svm/nested.c|1017| <<nested_svm_vmexit>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/svm/svm.c|2556| <<task_switch_interception>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/svm/svm.c|4012| <<svm_complete_interrupts>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/vmx/nested.c|4645| <<nested_vmx_vmexit>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|5440| <<handle_task_switch>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|6799| <<__vmx_complete_interrupts>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/x86.c|11947| <<kvm_vcpu_reset>> kvm_clear_interrupt_queue(vcpu);
+	 *
+	 * vcpu->arch.exception.pending = false;
+	 * vcpu->arch.exception.injected = false;
+	 */
 	kvm_clear_exception_queue(vcpu);
+	/*
+	 * vcpu->arch.interrupt.injected = false;
+	 */
 	kvm_clear_interrupt_queue(vcpu);
 
 	if (!idtv_info_valid)
 		return;
 
+	/*
+	 * 这里很重要
+	 * 会触发inject_pending_event()
+	 */
 	kvm_make_request(KVM_REQ_EVENT, vcpu);
 
 	vector = idt_vectoring_info & VECTORING_INFO_VECTOR_MASK;
@@ -6721,6 +7294,29 @@ static void __vmx_complete_interrupts(struct kvm_vcpu *vcpu,
 		vcpu->arch.event_exit_inst_len = vmcs_read32(instr_len_field);
 		fallthrough;
 	case INTR_TYPE_EXT_INTR:
+		/*
+		 * 在以下调用inject_pending_event():
+		 *   - arch/x86/kvm/x86.c|10320| <<vcpu_enter_guest>> r = inject_pending_event(vcpu, &req_immediate_exit);
+		 *
+		 * vcpu_enter_guest()
+		 * -> inject_pending_event()
+		 *    -> kvm_cpu_get_interrupt()
+		 *       -> kvm_get_apic_interrupt()
+		 *          -> apic_set_isr()
+		 *
+		 *
+		 * 在以下使用kvm_queue_interrupt():
+		 *   - arch/x86/kvm/svm/svm.c|4045| <<svm_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, false);
+		 *   - arch/x86/kvm/svm/svm.c|4048| <<svm_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, true);
+		 *   - arch/x86/kvm/vmx/vmx.c|6768| <<__vmx_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, type == INTR_TYPE_SOFT_INTR);
+		 *   - arch/x86/kvm/x86.c|4713| <<kvm_vcpu_ioctl_interrupt>> kvm_queue_interrupt(vcpu, irq->irq, false);
+		 *   - arch/x86/kvm/x86.c|9490| <<inject_pending_event>> kvm_queue_interrupt(vcpu, irq, false);
+		 *   - arch/x86/kvm/x86.c|11223| <<__set_sregs>> kvm_queue_interrupt(vcpu, pending_vec, false);
+		 *
+		 * vcpu->arch.interrupt.injected = true;
+		 * vcpu->arch.interrupt.soft = soft;
+		 * vcpu->arch.interrupt.nr = vector;
+		 */
 		kvm_queue_interrupt(vcpu, vector, type == INTR_TYPE_SOFT_INTR);
 		break;
 	default:
@@ -6728,20 +7324,72 @@ static void __vmx_complete_interrupts(struct kvm_vcpu *vcpu,
 	}
 }
 
+/*
+ * 在以下使用vmx_complete_interrupts():
+ *   - arch/x86/kvm/vmx/vmx.c|7133| <<vmx_vcpu_run>> vmx_complete_interrupts(vmx);
+ */
 static void vmx_complete_interrupts(struct vcpu_vmx *vmx)
 {
+	/*
+	 * 在以下使用vcpu_vmx->idt_vectoring_info:
+	 *   - arch/x86/kvm/vmx/vmx.c|5129| <<handle_exception_nmi>> vect_info = vmx->idt_vectoring_info;
+	 *   - arch/x86/kvm/vmx/vmx.c|5622| <<handle_task_switch>> idt_v = (vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK);
+	 *   - arch/x86/kvm/vmx/vmx.c|5623| <<handle_task_switch>> idt_index = (vmx->idt_vectoring_info & VECTORING_INFO_VECTOR_MASK);
+	 *   - arch/x86/kvm/vmx/vmx.c|5624| <<handle_task_switch>> type = (vmx->idt_vectoring_info & VECTORING_INFO_TYPE_MASK);
+	 *   - arch/x86/kvm/vmx/vmx.c|5650| <<handle_task_switch>> if (vmx->idt_vectoring_info &
+	 *   - arch/x86/kvm/vmx/vmx.c|5694| <<handle_ept_violation>> if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&
+	 *   - arch/x86/kvm/vmx/vmx.c|5913| <<handle_pml_full>> if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&
+	 *   - arch/x86/kvm/vmx/vmx.c|6062| <<vmx_get_exit_info>> *info2 = vmx->idt_vectoring_info;
+	 *   - arch/x86/kvm/vmx/vmx.c|6314| <<__vmx_handle_exit>> u32 vectoring_info = vmx->idt_vectoring_info;
+	 *   - arch/x86/kvm/vmx/vmx.c|6989| <<vmx_recover_nmi_blocking>> idtv_info_valid = vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK;
+	 *   - arch/x86/kvm/vmx/vmx.c|7125| <<vmx_complete_interrupts>> __vmx_complete_interrupts(&vmx->vcpu, vmx->idt_vectoring_info,
+	 *   - arch/x86/kvm/vmx/vmx.c|7427| <<vmx_vcpu_run>> vmx->idt_vectoring_info = 0;
+	 *   - arch/x86/kvm/vmx/vmx.c|7439| <<vmx_vcpu_run>> vmx->idt_vectoring_info = vmcs_read32(IDT_VECTORING_INFO_FIELD);
+	 *
+	 * 在以下使用__vmx_complete_interrupts():
+	 *   - arch/x86/kvm/vmx/vmx.c|6842| <<vmx_complete_interrupts>> __vmx_complete_interrupts(&vmx->vcpu, vmx->idt_vectoring_info,
+	 *                                        VM_EXIT_INSTRUCTION_LEN, IDT_VECTORING_ERROR_CODE);
+	 *   - arch/x86/kvm/vmx/vmx.c|6849| <<vmx_cancel_injection>> __vmx_complete_interrupts(vcpu, vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *                                        VM_ENTRY_INSTRUCTION_LEN, VM_ENTRY_EXCEPTION_ERROR_CODE);
+	 */
 	__vmx_complete_interrupts(&vmx->vcpu, vmx->idt_vectoring_info,
 				  VM_EXIT_INSTRUCTION_LEN,
 				  IDT_VECTORING_ERROR_CODE);
 }
 
+/*
+ * struct kvm_x86_ops vmx_x86_ops.cancel_injection = vmx_cancel_injection()
+ */
 static void vmx_cancel_injection(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用__vmx_complete_interrupts():
+	 *   - arch/x86/kvm/vmx/vmx.c|6842| <<vmx_complete_interrupts>> __vmx_complete_interrupts(&vmx->vcpu, vmx->idt_vectoring_info,
+	 *                                        VM_EXIT_INSTRUCTION_LEN, IDT_VECTORING_ERROR_CODE);
+	 *   - arch/x86/kvm/vmx/vmx.c|6849| <<vmx_cancel_injection>> __vmx_complete_interrupts(vcpu, vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *                                        VM_ENTRY_INSTRUCTION_LEN, VM_ENTRY_EXCEPTION_ERROR_CODE);
+	 */
 	__vmx_complete_interrupts(vcpu,
 				  vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
 				  VM_ENTRY_INSTRUCTION_LEN,
 				  VM_ENTRY_EXCEPTION_ERROR_CODE);
 
+	/*
+	 * vmx代码中主要使用VM_ENTRY_INTR_INFO_FIELD的地方:
+	 *   - arch/x86/kvm/vmx/nested.c|2366| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+	 *   - arch/x86/kvm/vmx/nested.c|2377| <<prepare_vmcs02_early>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *   - arch/x86/kvm/vmx/vmx.c|1732| <<vmx_inject_exception>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr_info);
+	 *   - arch/x86/kvm/vmx/vmx.c|4653| <<vmx_vcpu_reset>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *   - arch/x86/kvm/vmx/vmx.c|4710| <<vmx_inject_irq>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, intr);
+	 *   - arch/x86/kvm/vmx/vmx.c|4740| <<vmx_inject_nmi>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD,
+	 *   - arch/x86/kvm/vmx/vmx.c|6095| <<dump_vmcs>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *   - arch/x86/kvm/vmx/vmx.c|6952| <<vmx_cancel_injection>> vmcs_read32(VM_ENTRY_INTR_INFO_FIELD),
+	 *   - arch/x86/kvm/vmx/vmx.c|6956| <<vmx_cancel_injection>> vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
+	 *
+	 * bit 0-7: Vector of interrupt or exception
+	 * bit 8-10: interrupt type: 0-7不同的数, 0是external interrupt
+	 * bit 31: valid (cleared on every vm exit)
+	 */
 	vmcs_write32(VM_ENTRY_INTR_INFO_FIELD, 0);
 }
 
@@ -6769,6 +7417,13 @@ static void vmx_update_hv_timer(struct kvm_vcpu *vcpu)
 	u64 tscl;
 	u32 delta_tsc;
 
+	/*
+	 * 在以下使用vcpu_vmx->req_immediate_exit:
+	 *   - arch/x86/kvm/vmx/vmx.c|1196| <<vmx_prepare_switch_to_guest>> vmx->req_immediate_exit = false;
+	 *   - arch/x86/kvm/vmx/vmx.c|5906| <<handle_fastpath_preemption_timer>> if (!vmx->req_immediate_exit &&
+	 *   - arch/x86/kvm/vmx/vmx.c|7146| <<vmx_update_hv_timer>> if (vmx->req_immediate_exit) {
+	 *   - arch/x86/kvm/vmx/vmx.c|7907| <<vmx_request_immediate_exit>> to_vmx(vcpu)->req_immediate_exit = true;
+	 */
 	if (vmx->req_immediate_exit) {
 		vmcs_write32(VMX_PREEMPTION_TIMER_VALUE, 0);
 		vmx->loaded_vmcs->hv_timer_soft_disabled = false;
@@ -6822,6 +7477,10 @@ void noinstr vmx_spec_ctrl_restore_host(struct vcpu_vmx *vmx,
 	barrier_nospec();
 }
 
+/*
+ * 在以下调用vmx_exit_handlers_fastpath():
+ *   - arch/x86/kvm/vmx/vmx.c|7069| <<vmx_vcpu_run>> return vmx_exit_handlers_fastpath(vcpu);
+ */
 static fastpath_t vmx_exit_handlers_fastpath(struct kvm_vcpu *vcpu)
 {
 	switch (to_vmx(vcpu)->exit_reason.basic) {
@@ -7006,6 +7665,24 @@ static fastpath_t vmx_vcpu_run(struct kvm_vcpu *vcpu)
 	if (unlikely((u16)vmx->exit_reason.basic == EXIT_REASON_MCE_DURING_VMENTRY))
 		kvm_machine_check();
 
+	/*
+	 * 在以下使用vcpu_vmx->idt_vectoring_info:
+	 *   - arch/x86/kvm/vmx/vmx.c|5129| <<handle_exception_nmi>> vect_info = vmx->idt_vectoring_info;
+	 *   - arch/x86/kvm/vmx/vmx.c|5622| <<handle_task_switch>> idt_v = (vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK);
+	 *   - arch/x86/kvm/vmx/vmx.c|5623| <<handle_task_switch>> idt_index = (vmx->idt_vectoring_info & VECTORING_INFO_VECTOR_MASK);
+	 *   - arch/x86/kvm/vmx/vmx.c|5624| <<handle_task_switch>> type = (vmx->idt_vectoring_info & VECTORING_INFO_TYPE_MASK);
+	 *   - arch/x86/kvm/vmx/vmx.c|5650| <<handle_task_switch>> if (vmx->idt_vectoring_info &
+	 *   - arch/x86/kvm/vmx/vmx.c|5694| <<handle_ept_violation>> if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&
+	 *   - arch/x86/kvm/vmx/vmx.c|5913| <<handle_pml_full>> if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&
+	 *   - arch/x86/kvm/vmx/vmx.c|6062| <<vmx_get_exit_info>> *info2 = vmx->idt_vectoring_info;
+	 *   - arch/x86/kvm/vmx/vmx.c|6314| <<__vmx_handle_exit>> u32 vectoring_info = vmx->idt_vectoring_info;
+	 *   - arch/x86/kvm/vmx/vmx.c|6989| <<vmx_recover_nmi_blocking>> idtv_info_valid = vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK;
+	 *   - arch/x86/kvm/vmx/vmx.c|7125| <<vmx_complete_interrupts>> __vmx_complete_interrupts(&vmx->vcpu, vmx->idt_vectoring_info,
+	 *   - arch/x86/kvm/vmx/vmx.c|7427| <<vmx_vcpu_run>> vmx->idt_vectoring_info = 0;
+	 *   - arch/x86/kvm/vmx/vmx.c|7439| <<vmx_vcpu_run>> vmx->idt_vectoring_info = vmcs_read32(IDT_VECTORING_INFO_FIELD);
+	 *
+	 * 描述原本准备注入给 guest 的中断,但由于 VM-exit 等原因被中断了.
+	 */
 	if (likely(!vmx->exit_reason.failed_vmentry))
 		vmx->idt_vectoring_info = vmcs_read32(IDT_VECTORING_INFO_FIELD);
 
@@ -7017,6 +7694,9 @@ static fastpath_t vmx_vcpu_run(struct kvm_vcpu *vcpu)
 	vmx->loaded_vmcs->launched = 1;
 
 	vmx_recover_nmi_blocking(vmx);
+	/*
+	 * 只在这里使用
+	 */
 	vmx_complete_interrupts(vmx);
 
 	if (is_guest_mode(vcpu))
@@ -7526,6 +8206,13 @@ static __init void vmx_set_cpu_caps(void)
 
 static void vmx_request_immediate_exit(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用vcpu_vmx->req_immediate_exit:
+	 *   - arch/x86/kvm/vmx/vmx.c|1196| <<vmx_prepare_switch_to_guest>> vmx->req_immediate_exit = false;
+	 *   - arch/x86/kvm/vmx/vmx.c|5906| <<handle_fastpath_preemption_timer>> if (!vmx->req_immediate_exit &&
+	 *   - arch/x86/kvm/vmx/vmx.c|7146| <<vmx_update_hv_timer>> if (vmx->req_immediate_exit) {
+	 *   - arch/x86/kvm/vmx/vmx.c|7907| <<vmx_request_immediate_exit>> to_vmx(vcpu)->req_immediate_exit = true;
+	 */
 	to_vmx(vcpu)->req_immediate_exit = true;
 }
 
@@ -7655,8 +8342,38 @@ static int vmx_set_hv_timer(struct kvm_vcpu *vcpu, u64 guest_deadline_tsc,
 
 	vmx = to_vmx(vcpu);
 	tscl = rdtsc();
+	/*
+	 * 在以下使用kvm_read_l1_tsc():
+	 *   - arch/x86/kvm/hyperv.c|591| <<get_time_ref_counter>> tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 *   - arch/x86/kvm/lapic.c|2899| <<__kvm_wait_lapic_expire>> guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 *   - arch/x86/kvm/lapic.c|2917| <<__kvm_wait_lapic_expire>> guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 *   - arch/x86/kvm/lapic.c|3027| <<start_sw_tscdeadline>> guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 *   - arch/x86/kvm/lapic.c|3141| <<set_target_expiration>> apic->lapic_timer.tscdeadline = kvm_read_l1_tsc(apic->vcpu, tscl) +
+	 *   - arch/x86/kvm/lapic.c|3180| <<advance_periodic_target_expiration>> apic->lapic_timer.tscdeadline = kvm_read_l1_tsc(apic->vcpu, tscl) +
+	 *   - arch/x86/kvm/vmx/nested.c|980| <<nested_vmx_get_vmexit_msr_value>> *data = kvm_read_l1_tsc(vcpu, val);
+	 *   - arch/x86/kvm/vmx/nested.c|2086| <<vmx_calc_preemption_timer_value>> u64 l1_scaled_tsc = kvm_read_l1_tsc(vcpu, rdtsc()) >>
+	 *   - arch/x86/kvm/vmx/vmx.c|8345| <<vmx_set_hv_timer>> guest_tscl = kvm_read_l1_tsc(vcpu, tscl);
+	 *   - arch/x86/kvm/x86.c|3885| <<kvm_guest_time_update>> tsc_timestamp = kvm_read_l1_tsc(v, host_tsc);
+	 *   - arch/x86/kvm/x86.c|10375| <<kvm_pv_clock_pairing>> clock_pairing.tsc = kvm_read_l1_tsc(vcpu, cycle);
+	 *   - arch/x86/kvm/x86.c|12309| <<vcpu_enter_guest>> vcpu->arch.last_guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 */
 	guest_tscl = kvm_read_l1_tsc(vcpu, tscl);
 	delta_tsc = max(guest_deadline_tsc, guest_tscl) - guest_tscl;
+	/*
+	 * 在以下使用nsec_to_cycles():
+	 *   - arch/x86/kvm/lapic.c|2840| <<__wait_lapic_expire>> __delay(min(guest_cycles,
+	 *          nsec_to_cycles(vcpu, timer_advance_ns)));
+	 *   - arch/x86/kvm/lapic.c|3052| <<update_target_expiration>> nsec_to_cycles(apic->vcpu, ns_remaining_new) -
+	 *                                                             nsec_to_cycles(apic->vcpu, ns_remaining_old);
+	 *   - arch/x86/kvm/lapic.c|3053| <<update_target_expiration>> nsec_to_cycles(apic->vcpu, ns_remaining_new) -
+	 *                                                             nsec_to_cycles(apic->vcpu, ns_remaining_old);
+	 *   - arch/x86/kvm/lapic.c|3097| <<set_target_expiration>> nsec_to_cycles(apic->vcpu, deadline);
+	 *   - arch/x86/kvm/lapic.c|3121| <<advance_periodic_target_expiration>> nsec_to_cycles(apic->vcpu, delta);
+	 *   - arch/x86/kvm/vmx/vmx.c|8347| <<vmx_set_hv_timer>> lapic_timer_advance_cycles = nsec_to_cycles(vcpu,
+	 *          ktimer->timer_advance_ns);
+	 *   - arch/x86/kvm/x86.c|3042| <<kvm_synchronize_tsc>> nsec_to_cycles(vcpu, elapsed);
+	 *   - arch/x86/kvm/x86.c|3065| <<kvm_synchronize_tsc>> u64 delta = nsec_to_cycles(vcpu, elapsed);
+	 */
 	lapic_timer_advance_cycles = nsec_to_cycles(vcpu,
 						    ktimer->timer_advance_ns);
 
@@ -7665,6 +8382,21 @@ static int vmx_set_hv_timer(struct kvm_vcpu *vcpu, u64 guest_deadline_tsc,
 	else
 		delta_tsc = 0;
 
+	/*
+	 * 在以下使用kvm_tsc_scaling_ratio_frac_bits:
+	 *   - arch/x86/kvm/debugfs.c|51| <<vcpu_get_tsc_scaling_frac_bits>> *val = kvm_tsc_scaling_ratio_frac_bits;
+	 *   - arch/x86/kvm/svm/svm.c|1117| <<svm_hardware_setup>> kvm_tsc_scaling_ratio_frac_bits = 32;
+	 *   - arch/x86/kvm/vmx/vmx.c|8358| <<vmx_set_hv_timer>> if (vcpu->arch.l1_tsc_scaling_ratio != kvm_default_tsc_scaling_ratio
+	 *              && delta_tsc && u64_shl_div_u64(delta_tsc, kvm_tsc_scaling_ratio_frac_bits, vcpu->arch.l1_tsc_scaling_ratio, &delta_tsc))
+	 *   - arch/x86/kvm/vmx/vmx.c|8789| <<hardware_setup>> kvm_tsc_scaling_ratio_frac_bits = 48;
+	 *   - arch/x86/kvm/x86.c|2561| <<set_tsc_khz>> ratio = mul_u64_u32_div(1ULL << kvm_tsc_scaling_ratio_frac_bits, user_tsc_khz, tsc_khz);
+	 *   - arch/x86/kvm/x86.c|2702| <<__scale_tsc>> return mul_u64_u64_shr(tsc, ratio, kvm_tsc_scaling_ratio_frac_bits);
+	 *   - arch/x86/kvm/x86.c|2740| <<kvm_calc_nested_tsc_offset>> nested_offset = mul_s64_u64_shr((s64) l1_offset,
+	 *              l2_multiplier, kvm_tsc_scaling_ratio_frac_bits);
+	 *   - arch/x86/kvm/x86.c|2751| <<kvm_calc_nested_tsc_multiplier>> return mul_u64_u64_shr(l1_multiplier, l2_multiplier,
+	 *              kvm_tsc_scaling_ratio_frac_bits);
+	 *   - arch/x86/kvm/x86.c|13707| <<kvm_arch_hardware_setup>> kvm_default_tsc_scaling_ratio = 1ULL << kvm_tsc_scaling_ratio_frac_bits;
+	 */
 	/* Convert to host delta tsc if tsc scaling is enabled */
 	if (vcpu->arch.l1_tsc_scaling_ratio != kvm_default_tsc_scaling_ratio &&
 	    delta_tsc && u64_shl_div_u64(delta_tsc,
@@ -7759,6 +8491,13 @@ static int vmx_enter_smm(struct kvm_vcpu *vcpu, char *smstate)
 
 	vmx->nested.smm.vmxon = vmx->nested.vmxon;
 	vmx->nested.vmxon = false;
+	/*
+	 * 在以下调用vmx_clear_hlt():
+	 *   - arch/x86/kvm/vmx/vmx.c|1734| <<vmx_inject_exception>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|4712| <<vmx_inject_irq>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|4743| <<vmx_inject_nmi>> vmx_clear_hlt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|7989| <<vmx_enter_smm>> vmx_clear_hlt(vcpu);
+	 */
 	vmx_clear_hlt(vcpu);
 	return 0;
 }
@@ -7997,6 +8736,13 @@ static __init int hardware_setup(void)
 	int r, ept_lpage_level;
 
 	store_idt(&dt);
+	/*
+	 * 在以下使用host_idt_base:
+	 *   - arch/x86/kvm/vmx/vmx.c|518| <<global>> static unsigned long host_idt_base;
+	 *   - arch/x86/kvm/vmx/vmx.c|4304| <<vmx_set_constant_host_state>> vmcs_writel(HOST_IDTR_BASE, host_idt_base);
+	 *   - arch/x86/kvm/vmx/vmx.c|6972| <<handle_external_interrupt_irqoff>> gate_desc *desc = (gate_desc *)host_idt_base + vector;
+	 *   - arch/x86/kvm/vmx/vmx.c|8510| <<hardware_setup>> host_idt_base = dt.address;
+	 */
 	host_idt_base = dt.address;
 
 	vmx_setup_user_return_msrs();
@@ -8083,8 +8829,38 @@ static __init int hardware_setup(void)
 		vmx_x86_ops.sync_pir_to_irr = NULL;
 
 	if (cpu_has_vmx_tsc_scaling()) {
+		/*
+		 * 在以下设置kvm_has_tsc_control:
+		 *   - arch/x86/kvm/svm/svm.c|1115| <<svm_hardware_setup>> kvm_has_tsc_control = true;
+		 *   - arch/x86/kvm/vmx/vmx.c|8787| <<hardware_setup>> kvm_has_tsc_control = true;
+		 * 在以下使用kvm_has_tsc_control:
+		 *   - arch/x86/kvm/debugfs.c|69| <<kvm_arch_create_vcpu_debugfs>> if (kvm_has_tsc_control) {
+		 *   - arch/x86/kvm/vmx/nested.c|2581| <<prepare_vmcs02>> if (kvm_has_tsc_control)
+		 *   - arch/x86/kvm/vmx/nested.c|4680| <<nested_vmx_vmexit>> if (kvm_has_tsc_control)
+		 *   - arch/x86/kvm/x86.c|2579| <<set_tsc_khz>> if (!kvm_has_tsc_control) {
+		 *   - arch/x86/kvm/x86.c|2843| <<kvm_vcpu_write_tsc_multiplier>> if (kvm_has_tsc_control)
+		 *   - arch/x86/kvm/x86.c|3607| <<kvm_guest_time_update>> if (kvm_has_tsc_control)
+		 *   - arch/x86/kvm/x86.c|4951| <<kvm_vm_ioctl_check_extension>> r = kvm_has_tsc_control;
+		 *   - arch/x86/kvm/x86.c|6207| <<kvm_arch_vcpu_ioctl(KVM_SET_TSC_KHZ)>> if (kvm_has_tsc_control &
+		 *   - arch/x86/kvm/x86.c|13736| <<kvm_arch_hardware_setup>> if (kvm_has_tsc_control) {
+		 */
 		kvm_has_tsc_control = true;
 		kvm_max_tsc_scaling_ratio = KVM_VMX_TSC_MULTIPLIER_MAX;
+		/*
+		 * 在以下使用kvm_tsc_scaling_ratio_frac_bits:
+		 *   - arch/x86/kvm/debugfs.c|51| <<vcpu_get_tsc_scaling_frac_bits>> *val = kvm_tsc_scaling_ratio_frac_bits;
+		 *   - arch/x86/kvm/svm/svm.c|1117| <<svm_hardware_setup>> kvm_tsc_scaling_ratio_frac_bits = 32;
+		 *   - arch/x86/kvm/vmx/vmx.c|8358| <<vmx_set_hv_timer>> if (vcpu->arch.l1_tsc_scaling_ratio != kvm_default_tsc_scaling_ratio
+		 *              && delta_tsc && u64_shl_div_u64(delta_tsc, kvm_tsc_scaling_ratio_frac_bits, vcpu->arch.l1_tsc_scaling_ratio, &delta_tsc))
+		 *   - arch/x86/kvm/vmx/vmx.c|8789| <<hardware_setup>> kvm_tsc_scaling_ratio_frac_bits = 48;
+		 *   - arch/x86/kvm/x86.c|2561| <<set_tsc_khz>> ratio = mul_u64_u32_div(1ULL << kvm_tsc_scaling_ratio_frac_bits, user_tsc_khz, tsc_khz);
+		 *   - arch/x86/kvm/x86.c|2702| <<__scale_tsc>> return mul_u64_u64_shr(tsc, ratio, kvm_tsc_scaling_ratio_frac_bits);
+		 *   - arch/x86/kvm/x86.c|2740| <<kvm_calc_nested_tsc_offset>> nested_offset = mul_s64_u64_shr((s64) l1_offset,
+		 *              l2_multiplier, kvm_tsc_scaling_ratio_frac_bits);
+		 *   - arch/x86/kvm/x86.c|2751| <<kvm_calc_nested_tsc_multiplier>> return mul_u64_u64_shr(l1_multiplier, l2_multiplier,
+		 *              kvm_tsc_scaling_ratio_frac_bits);
+		 *   - arch/x86/kvm/x86.c|13707| <<kvm_arch_hardware_setup>> kvm_default_tsc_scaling_ratio = 1ULL << kvm_tsc_scaling_ratio_frac_bits;
+		 */
 		kvm_tsc_scaling_ratio_frac_bits = 48;
 	}
 
diff --git a/arch/x86/kvm/vmx/vmx.h b/arch/x86/kvm/vmx/vmx.h
index 8a2ab6cff744..56bff8408743 100644
--- a/arch/x86/kvm/vmx/vmx.h
+++ b/arch/x86/kvm/vmx/vmx.h
@@ -241,6 +241,11 @@ struct nested_vmx {
 struct vcpu_vmx {
 	struct kvm_vcpu       vcpu;
 	u8                    fail;
+	/*
+	 * 在以下使用vcpu_vmx->x2apic_msr_bitmap_mode:
+	 *   - arch/x86/kvm/vmx/vmx.c|4050| <<vmx_update_msr_bitmap_x2apic>> if (mode == vmx->x2apic_msr_bitmap_mode)
+	 *   - arch/x86/kvm/vmx/vmx.c|4053| <<vmx_update_msr_bitmap_x2apic>> vmx->x2apic_msr_bitmap_mode = mode;
+	 */
 	u8		      x2apic_msr_bitmap_mode;
 
 	/*
@@ -250,10 +255,46 @@ struct vcpu_vmx {
 	 * values.  If false, host state is loaded in the CPU registers
 	 * and vmx->loaded_vmcs->host_state is invalid.
 	 */
+	/*
+	 * 在以下使用vcpu_vmx->guest_state_loaded:
+	 *   - arch/x86/kvm/vmx/nested.c|243| <<vmx_sync_vmcs_host_state>> if (unlikely(!vmx->guest_state_loaded))
+	 *   - arch/x86/kvm/vmx/vmx.c|1223| <<vmx_prepare_switch_to_guest>> if (vmx->guest_state_loaded)
+	 *   - arch/x86/kvm/vmx/vmx.c|1261| <<vmx_prepare_switch_to_guest>> vmx->guest_state_loaded = true;
+	 *   - arch/x86/kvm/vmx/vmx.c|1268| <<vmx_prepare_switch_to_host>> if (!vmx->guest_state_loaded)
+	 *   - arch/x86/kvm/vmx/vmx.c|1299| <<vmx_prepare_switch_to_host>> vmx->guest_state_loaded = false;
+	 *   - arch/x86/kvm/vmx/vmx.c|1307| <<vmx_read_guest_kernel_gs_base>> if (vmx->guest_state_loaded)
+	 *   - arch/x86/kvm/vmx/vmx.c|1316| <<vmx_write_guest_kernel_gs_base>> if (vmx->guest_state_loaded)
+	 */
 	bool		      guest_state_loaded;
 
 	unsigned long         exit_qualification;
+	/*
+	 * 在以下使用vcpu_vmx->exit_intr_info:
+	 *   - arch/x86/kvm/vmx/vmx.c|7322| <<vmx_vcpu_run>> vmx->exit_intr_info = 0;
+	 *   - arch/x86/kvm/vmx/vmx.h|584| <<vmx_get_intr_info>> vmx->exit_intr_info = vmcs_read32(VM_EXIT_INTR_INFO);
+	 *   - arch/x86/kvm/vmx/vmx.h|586| <<vmx_get_intr_info>> return vmx->exit_intr_info;
+	 *
+	 * 告诉VMM(Hypervisor)此次VM-exit是由于某个中断,异常或NMI等原因引起的
+	 */
 	u32                   exit_intr_info;
+	/*
+	 * 在以下使用vcpu_vmx->idt_vectoring_info:
+	 *   - arch/x86/kvm/vmx/vmx.c|5129| <<handle_exception_nmi>> vect_info = vmx->idt_vectoring_info;
+	 *   - arch/x86/kvm/vmx/vmx.c|5622| <<handle_task_switch>> idt_v = (vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK);
+	 *   - arch/x86/kvm/vmx/vmx.c|5623| <<handle_task_switch>> idt_index = (vmx->idt_vectoring_info & VECTORING_INFO_VECTOR_MASK);
+	 *   - arch/x86/kvm/vmx/vmx.c|5624| <<handle_task_switch>> type = (vmx->idt_vectoring_info & VECTORING_INFO_TYPE_MASK);
+	 *   - arch/x86/kvm/vmx/vmx.c|5650| <<handle_task_switch>> if (vmx->idt_vectoring_info &
+	 *   - arch/x86/kvm/vmx/vmx.c|5694| <<handle_ept_violation>> if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&
+	 *   - arch/x86/kvm/vmx/vmx.c|5913| <<handle_pml_full>> if (!(to_vmx(vcpu)->idt_vectoring_info & VECTORING_INFO_VALID_MASK) &&
+	 *   - arch/x86/kvm/vmx/vmx.c|6062| <<vmx_get_exit_info>> *info2 = vmx->idt_vectoring_info;
+	 *   - arch/x86/kvm/vmx/vmx.c|6314| <<__vmx_handle_exit>> u32 vectoring_info = vmx->idt_vectoring_info;
+	 *   - arch/x86/kvm/vmx/vmx.c|6989| <<vmx_recover_nmi_blocking>> idtv_info_valid = vmx->idt_vectoring_info & VECTORING_INFO_VALID_MASK;
+	 *   - arch/x86/kvm/vmx/vmx.c|7125| <<vmx_complete_interrupts>> __vmx_complete_interrupts(&vmx->vcpu, vmx->idt_vectoring_info,
+	 *   - arch/x86/kvm/vmx/vmx.c|7427| <<vmx_vcpu_run>> vmx->idt_vectoring_info = 0;
+	 *   - arch/x86/kvm/vmx/vmx.c|7439| <<vmx_vcpu_run>> vmx->idt_vectoring_info = vmcs_read32(IDT_VECTORING_INFO_FIELD);
+	 *
+	 * 描述原本准备注入给 guest 的中断,但由于 VM-exit 等原因被中断了.
+	 */
 	u32                   idt_vectoring_info;
 	ulong                 rflags;
 
@@ -319,6 +360,13 @@ struct vcpu_vmx {
 	unsigned int ple_window;
 	bool ple_window_dirty;
 
+	/*
+	 * 在以下使用vcpu_vmx->req_immediate_exit:
+	 *   - arch/x86/kvm/vmx/vmx.c|1196| <<vmx_prepare_switch_to_guest>> vmx->req_immediate_exit = false;
+	 *   - arch/x86/kvm/vmx/vmx.c|5906| <<handle_fastpath_preemption_timer>> if (!vmx->req_immediate_exit &&
+	 *   - arch/x86/kvm/vmx/vmx.c|7146| <<vmx_update_hv_timer>> if (vmx->req_immediate_exit) {
+	 *   - arch/x86/kvm/vmx/vmx.c|7907| <<vmx_request_immediate_exit>> to_vmx(vcpu)->req_immediate_exit = true;
+	 */
 	bool req_immediate_exit;
 
 	/* Support for PML */
@@ -553,12 +601,30 @@ static inline unsigned long vmx_get_exit_qual(struct kvm_vcpu *vcpu)
 	return vmx->exit_qualification;
 }
 
+/*
+ * 在以下使用vmx_get_intr_info():
+ *   - arch/x86/kvm/vmx/nested.c|5790| <<handle_vmfunc>> vmx_get_intr_info(vcpu),
+ *   - arch/x86/kvm/vmx/nested.c|6031| <<nested_vmx_l0_wants_exit>> intr_info = vmx_get_intr_info(vcpu);
+ *   - arch/x86/kvm/vmx/nested.c|6103| <<nested_vmx_l1_wants_exit>> intr_info = vmx_get_intr_info(vcpu);
+ *   - arch/x86/kvm/vmx/nested.c|6257| <<nested_vmx_reflect_vmexit>> exit_intr_info = vmx_get_intr_info(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|5130| <<handle_exception_nmi>> intr_info = vmx_get_intr_info(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|6079| <<vmx_get_exit_info>> *intr_info = vmx_get_intr_info(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|6948| <<handle_exception_nmi_irqoff>> u32 intr_info = vmx_get_intr_info(&vmx->vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|6966| <<handle_external_interrupt_irqoff>> u32 intr_info = vmx_get_intr_info(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|7027| <<vmx_recover_nmi_blocking>> exit_intr_info = vmx_get_intr_info(&vmx->vcpu);
+ */
 static inline u32 vmx_get_intr_info(struct kvm_vcpu *vcpu)
 {
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
 
 	if (!kvm_register_is_available(vcpu, VCPU_EXREG_EXIT_INFO_2)) {
 		kvm_register_mark_available(vcpu, VCPU_EXREG_EXIT_INFO_2);
+		/*
+		 * 在以下使用vcpu_vmx->exit_intr_info:
+		 *   - arch/x86/kvm/vmx/vmx.c|7322| <<vmx_vcpu_run>> vmx->exit_intr_info = 0;
+		 *   - arch/x86/kvm/vmx/vmx.h|584| <<vmx_get_intr_info>> vmx->exit_intr_info = vmcs_read32(VM_EXIT_INTR_INFO);
+		 *   - arch/x86/kvm/vmx/vmx.h|586| <<vmx_get_intr_info>> return vmx->exit_intr_info;
+		 */
 		vmx->exit_intr_info = vmcs_read32(VM_EXIT_INTR_INFO);
 	}
 	return vmx->exit_intr_info;
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index 321af8f0e7ab..7202dc9e9973 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -146,22 +146,91 @@ EXPORT_SYMBOL_GPL(report_ignored_msrs);
 unsigned int min_timer_period_us = 200;
 module_param(min_timer_period_us, uint, S_IRUGO | S_IWUSR);
 
+/*
+ * 在以下使用kvmclock_periodic_sync:
+ *   - arch/x86/kvm/x86.c|149| <<global>> static bool __read_mostly kvmclock_periodic_sync = true;
+ *   - arch/x86/kvm/x86.c|3526| <<kvmclock_sync_fn>> if (!kvmclock_periodic_sync)
+ *   - arch/x86/kvm/x86.c|12996| <<kvm_arch_vcpu_postcreate>> if (kvmclock_periodic_sync && vcpu->vcpu_idx == 0)
+ */
 static bool __read_mostly kvmclock_periodic_sync = true;
 module_param(kvmclock_periodic_sync, bool, S_IRUGO);
 
+/*
+ * 在以下设置kvm_has_tsc_control:
+ *   - arch/x86/kvm/svm/svm.c|1115| <<svm_hardware_setup>> kvm_has_tsc_control = true;
+ *   - arch/x86/kvm/vmx/vmx.c|8787| <<hardware_setup>> kvm_has_tsc_control = true;
+ * 在以下使用kvm_has_tsc_control:
+ *   - arch/x86/kvm/debugfs.c|69| <<kvm_arch_create_vcpu_debugfs>> if (kvm_has_tsc_control) {
+ *   - arch/x86/kvm/vmx/nested.c|2581| <<prepare_vmcs02>> if (kvm_has_tsc_control)
+ *   - arch/x86/kvm/vmx/nested.c|4680| <<nested_vmx_vmexit>> if (kvm_has_tsc_control)
+ *   - arch/x86/kvm/x86.c|2579| <<set_tsc_khz>> if (!kvm_has_tsc_control) {
+ *   - arch/x86/kvm/x86.c|2843| <<kvm_vcpu_write_tsc_multiplier>> if (kvm_has_tsc_control)
+ *   - arch/x86/kvm/x86.c|3607| <<kvm_guest_time_update>> if (kvm_has_tsc_control)
+ *   - arch/x86/kvm/x86.c|4951| <<kvm_vm_ioctl_check_extension>> r = kvm_has_tsc_control;
+ *   - arch/x86/kvm/x86.c|6207| <<kvm_arch_vcpu_ioctl(KVM_SET_TSC_KHZ)>> if (kvm_has_tsc_control &&
+ *   - arch/x86/kvm/x86.c|13736| <<kvm_arch_hardware_setup>> if (kvm_has_tsc_control) {
+ */
 bool __read_mostly kvm_has_tsc_control;
 EXPORT_SYMBOL_GPL(kvm_has_tsc_control);
+/*
+ * 在以下使用kvm_max_guest_tsc_khz:
+ *   - arch/x86/kvm/x86.c|6255| <<kvm_arch_vcpu_ioctl(KVM_SET_TSC_KHZ)>> if(...user_tsc_khz >= kvm_max_guest_tsc_khz)
+ *   - arch/x86/kvm/x86.c|9511| <<kvm_hyperv_tsc_notifier>> kvm_max_guest_tsc_khz = tsc_khz;
+ *   - arch/x86/kvm/x86.c|13792| <<kvm_arch_hardware_setup>> kvm_max_guest_tsc_khz = max;
+ */
 u32  __read_mostly kvm_max_guest_tsc_khz;
 EXPORT_SYMBOL_GPL(kvm_max_guest_tsc_khz);
+/*
+ * 在以下使用kvm_tsc_scaling_ratio_frac_bits:
+ *   - arch/x86/kvm/debugfs.c|51| <<vcpu_get_tsc_scaling_frac_bits>> *val = kvm_tsc_scaling_ratio_frac_bits;
+ *   - arch/x86/kvm/svm/svm.c|1117| <<svm_hardware_setup>> kvm_tsc_scaling_ratio_frac_bits = 32;
+ *   - arch/x86/kvm/vmx/vmx.c|8358| <<vmx_set_hv_timer>> if (vcpu->arch.l1_tsc_scaling_ratio != kvm_default_tsc_scaling_ratio
+ *              && delta_tsc && u64_shl_div_u64(delta_tsc, kvm_tsc_scaling_ratio_frac_bits, vcpu->arch.l1_tsc_scaling_ratio, &delta_tsc))
+ *   - arch/x86/kvm/vmx/vmx.c|8789| <<hardware_setup>> kvm_tsc_scaling_ratio_frac_bits = 48;
+ *   - arch/x86/kvm/x86.c|2561| <<set_tsc_khz>> ratio = mul_u64_u32_div(1ULL << kvm_tsc_scaling_ratio_frac_bits, user_tsc_khz, tsc_khz);
+ *   - arch/x86/kvm/x86.c|2702| <<__scale_tsc>> return mul_u64_u64_shr(tsc, ratio, kvm_tsc_scaling_ratio_frac_bits);
+ *   - arch/x86/kvm/x86.c|2740| <<kvm_calc_nested_tsc_offset>> nested_offset = mul_s64_u64_shr((s64) l1_offset,
+ *              l2_multiplier, kvm_tsc_scaling_ratio_frac_bits);
+ *   - arch/x86/kvm/x86.c|2751| <<kvm_calc_nested_tsc_multiplier>> return mul_u64_u64_shr(l1_multiplier, l2_multiplier,
+ *              kvm_tsc_scaling_ratio_frac_bits);
+ *   - arch/x86/kvm/x86.c|13707| <<kvm_arch_hardware_setup>> kvm_default_tsc_scaling_ratio = 1ULL << kvm_tsc_scaling_ratio_frac_bits;
+ */
 u8   __read_mostly kvm_tsc_scaling_ratio_frac_bits;
 EXPORT_SYMBOL_GPL(kvm_tsc_scaling_ratio_frac_bits);
+/*
+ * 在以下使用kvm_max_tsc_scaling_ratio:
+ *   - rch/x86/kvm/svm/svm.c|1116| <<svm_hardware_setup>> kvm_max_tsc_scaling_ratio = TSC_RATIO_MAX;
+ *   - arch/x86/kvm/vmx/vmx.c|8803| <<hardware_setup>> kvm_max_tsc_scaling_ratio = KVM_VMX_TSC_MULTIPLIER_MAX;
+ *   - arch/x86/kvm/x86.c|2626| <<set_tsc_khz>> if (ratio == 0 || ratio >= kvm_max_tsc_scaling_ratio) {
+ *   - arch/x86/kvm/x86.c|13791| <<kvm_arch_hardware_setup>> __scale_tsc(kvm_max_tsc_scaling_ratio, tsc_khz));
+ */
 u64  __read_mostly kvm_max_tsc_scaling_ratio;
 EXPORT_SYMBOL_GPL(kvm_max_tsc_scaling_ratio);
+/*
+ * 在以下使用kvm_default_tsc_scaling_ratio:
+ *   - arch/x86/kvm/lapic.c|2838| <<__wait_lapic_expire>> if (vcpu->arch.tsc_scaling_ratio == kvm_default_tsc_scaling_ratio) {
+ *   - arch/x86/kvm/svm/svm.c|1253| <<svm_get_l2_tsc_multiplier>> return kvm_default_tsc_scaling_ratio;
+ *   - arch/x86/kvm/vmx/vmx.c|1892| <<vmx_get_l2_tsc_multiplier>> return kvm_default_tsc_scaling_ratio;
+ *   - arch/x86/kvm/vmx/vmx.c|8356| <<vmx_set_hv_timer>> if (vcpu->arch.l1_tsc_scaling_ratio != kvm_default_tsc_scaling_ratio &&
+ *   - arch/x86/kvm/x86.c|2544| <<set_tsc_khz>> kvm_vcpu_write_tsc_multiplier(vcpu, kvm_default_tsc_scaling_ratio);
+ *   - arch/x86/kvm/x86.c|2587| <<kvm_set_tsc_khz>> kvm_vcpu_write_tsc_multiplier(vcpu, kvm_default_tsc_scaling_ratio);
+ *   - arch/x86/kvm/x86.c|2709| <<kvm_scale_tsc>> if (ratio != kvm_default_tsc_scaling_ratio)
+ *   - arch/x86/kvm/x86.c|2736| <<kvm_calc_nested_tsc_offset>> if (l2_multiplier == kvm_default_tsc_scaling_ratio)
+ *   - arch/x86/kvm/x86.c|2749| <<kvm_calc_nested_tsc_multiplier>> if (l2_multiplier != kvm_default_tsc_scaling_ratio)
+ *   - arch/x86/kvm/x86.c|2959| <<adjust_tsc_offset_host>> if (vcpu->arch.l1_tsc_scaling_ratio != kvm_default_tsc_scaling_ratio)
+ *   - arch/x86/kvm/x86.c|13707| <<kvm_arch_hardware_setup>> kvm_default_tsc_scaling_ratio = 1ULL << kvm_tsc_scaling_ratio_frac_bits;
+ */
 u64 __read_mostly kvm_default_tsc_scaling_ratio;
 EXPORT_SYMBOL_GPL(kvm_default_tsc_scaling_ratio);
 bool __read_mostly kvm_has_bus_lock_exit;
 EXPORT_SYMBOL_GPL(kvm_has_bus_lock_exit);
 
+/*
+ * 在以下使用tsc_tolerance_ppm:
+ *   - arch/x86/kvm/x86.c|229| <<global>> static u32 __read_mostly tsc_tolerance_ppm = 250;
+ *   - arch/x86/kvm/x86.c|2694| <<kvm_set_tsc_khz>> thresh_lo = adjust_tsc_khz(tsc_khz, -tsc_tolerance_ppm);
+ *   - arch/x86/kvm/x86.c|2695| <<kvm_set_tsc_khz>> thresh_hi = adjust_tsc_khz(tsc_khz, tsc_tolerance_ppm);
+ */
 /* tsc tolerance in parts per million - default to 1/2 of the NTP threshold */
 static u32 __read_mostly tsc_tolerance_ppm = 250;
 module_param(tsc_tolerance_ppm, uint, S_IRUGO | S_IWUSR);
@@ -461,6 +530,13 @@ static void drop_user_return_notifiers(void)
 		kvm_on_user_return(&msrs->urn);
 }
 
+/*
+ * 在以下使用kvm_get_apic_base():
+ *   - arch/x86/kvm/x86.c|472| <<kvm_get_apic_mode>> return kvm_apic_mode(kvm_get_apic_base(vcpu));
+ *   - arch/x86/kvm/x86.c|4074| <<kvm_get_msr_common>> msr_info->data = kvm_get_apic_base(vcpu);
+ *   - arch/x86/kvm/x86.c|9617| <<post_kvm_run_save>> kvm_run->apic_base = kvm_get_apic_base(vcpu);
+ *   - arch/x86/kvm/x86.c|11932| <<__get_sregs_common>> sregs->apic_base = kvm_get_apic_base(vcpu);
+ */
 u64 kvm_get_apic_base(struct kvm_vcpu *vcpu)
 {
 	return vcpu->arch.apic_base;
@@ -469,10 +545,22 @@ EXPORT_SYMBOL_GPL(kvm_get_apic_base);
 
 enum lapic_mode kvm_get_apic_mode(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用kvm_get_apic_base():
+	 *   - arch/x86/kvm/x86.c|472| <<kvm_get_apic_mode>> return kvm_apic_mode(kvm_get_apic_base(vcpu));
+	 *   - arch/x86/kvm/x86.c|4074| <<kvm_get_msr_common>> msr_info->data = kvm_get_apic_base(vcpu);
+	 *   - arch/x86/kvm/x86.c|9617| <<post_kvm_run_save>> kvm_run->apic_base = kvm_get_apic_base(vcpu);
+	 *   - arch/x86/kvm/x86.c|11932| <<__get_sregs_common>> sregs->apic_base = kvm_get_apic_base(vcpu);
+	 */
 	return kvm_apic_mode(kvm_get_apic_base(vcpu));
 }
 EXPORT_SYMBOL_GPL(kvm_get_apic_mode);
 
+/*
+ * 在以下使用kvm_set_apic_base():
+ *   - arch/x86/kvm/x86.c|3471| <<kvm_set_msr_common(MSR_IA32_APICBASE)>> return kvm_set_apic_base(vcpu, msr_info);
+ *   - arch/x86/kvm/x86.c|11103| <<__set_sregs_common>> if (kvm_set_apic_base(vcpu, &apic_base_msr))
+ */
 int kvm_set_apic_base(struct kvm_vcpu *vcpu, struct msr_data *msr_info)
 {
 	enum lapic_mode old_mode = kvm_get_apic_mode(vcpu);
@@ -489,7 +577,21 @@ int kvm_set_apic_base(struct kvm_vcpu *vcpu, struct msr_data *msr_info)
 			return 1;
 	}
 
+	/*
+	 * 在以下使用kvm_lapic_set_base():
+	 *   - arch/x86/kvm/lapic.c|2661| <<kvm_lapic_reset>> kvm_lapic_set_base(vcpu, msr_val);
+	 *   - arch/x86/kvm/lapic.c|2989| <<kvm_apic_set_state>> kvm_lapic_set_base(vcpu, vcpu->arch.apic_base);
+	 *   - arch/x86/kvm/x86.c|492| <<kvm_set_apic_base>> kvm_lapic_set_base(vcpu, msr_info->data);
+	 */
 	kvm_lapic_set_base(vcpu, msr_info->data);
+	/*
+	 * 在以下调用kvm_recalculate_apic_map():
+	 *   - arch/x86/kvm/lapic.c|2441| <<kvm_lapic_reg_write>> kvm_recalculate_apic_map(apic->vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|2718| <<kvm_lapic_reset>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|2995| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/lapic.c|3001| <<kvm_apic_set_state>> kvm_recalculate_apic_map(vcpu->kvm);
+	 *   - arch/x86/kvm/x86.c|493| <<kvm_set_apic_base>> kvm_recalculate_apic_map(vcpu->kvm);
+	 */
 	kvm_recalculate_apic_map(vcpu->kvm);
 	return 0;
 }
@@ -564,6 +666,26 @@ static int exception_type(int vector)
 
 void kvm_deliver_exception_payload(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * struct kvm_vcpu *vcpu:
+	 * -> struct kvm_vcpu_arch arch;
+	 *        struct kvm_queued_exception {
+	 *            bool pending;
+	 *            bool injected;
+	 *            bool has_error_code;
+	 *            u8 nr;
+	 *            u32 error_code;
+	 *            unsigned long payload;
+	 *            bool has_payload;
+	 *            u8 nested_apf;
+	 *        } exception;
+	 *
+	 *        struct kvm_queued_interrupt {
+	 *            bool injected;
+	 *            bool soft;
+	 *            u8 nr;
+	 *        } interrupt;
+	 */
 	unsigned nr = vcpu->arch.exception.nr;
 	bool has_payload = vcpu->arch.exception.has_payload;
 	unsigned long payload = vcpu->arch.exception.payload;
@@ -623,6 +745,15 @@ static void kvm_leave_nested(struct kvm_vcpu *vcpu)
 	kvm_x86_ops.nested_ops->leave_nested(vcpu);
 }
 
+/*
+ * 在以下调用kvm_multiple_exception():
+ *   - arch/x86/kvm/x86.c|735| <<kvm_queue_exception>> kvm_multiple_exception(vcpu, nr, false, 0, false, 0, false);
+ *   - arch/x86/kvm/x86.c|741| <<kvm_requeue_exception>> kvm_multiple_exception(vcpu, nr, false, 0, false, 0, true);
+ *   - arch/x86/kvm/x86.c|748| <<kvm_queue_exception_p>> kvm_multiple_exception(vcpu, nr, false, 0, true, payload, false);
+ *   - arch/x86/kvm/x86.c|755| <<kvm_queue_exception_e_p>> kvm_multiple_exception(vcpu, nr, true, error_code,
+ *   - arch/x86/kvm/x86.c|817| <<kvm_queue_exception_e>> kvm_multiple_exception(vcpu, nr, true, error_code, false, 0, false);
+ *   - arch/x86/kvm/x86.c|823| <<kvm_requeue_exception_e>> kvm_multiple_exception(vcpu, nr, true, error_code, false, 0, true);
+ */
 static void kvm_multiple_exception(struct kvm_vcpu *vcpu,
 		unsigned nr, bool has_error, u32 error_code,
 	        bool has_payload, unsigned long payload, bool reinject)
@@ -697,18 +828,68 @@ static void kvm_multiple_exception(struct kvm_vcpu *vcpu,
 		goto queue;
 }
 
+/*
+ * 在以下使用kvm_queue_exception():
+ *   - arch/x86/kvm/hyperv.c|2220| <<kvm_hv_hypercall>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/hyperv.c|2258| <<kvm_hv_hypercall>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/svm/nested.c|748| <<nested_svm_vmrun>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/svm/nested.c|1026| <<nested_svm_vmexit>> kvm_queue_exception(&(svm->vcpu), DB_VECTOR);
+ *   - arch/x86/kvm/svm/nested.c|1226| <<nested_svm_check_permissions>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/svm/svm.c|2508| <<skinit_interception>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/svm/svm.c|2691| <<cr_interception>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/svm/svm.c|2713| <<cr_interception>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/svm/svm.c|2750| <<cr_trap>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/svm/svm.c|3234| <<invpcid_interception>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/svm/svm.c|4795| <<svm_can_emulate_instruction>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/nested.c|3360| <<nested_vmx_check_permission>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/nested.c|3575| <<nested_vmx_run>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/nested.c|4809| <<get_vmx_mem_address>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/nested.c|5050| <<handle_vmon>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/nested.c|5553| <<handle_invept>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/nested.c|5633| <<handle_invvpid>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/nested.c|5755| <<handle_vmfunc>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/nested.c|5766| <<handle_vmfunc>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/sgx.c|378| <<handle_encls>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/vmx.c|1574| <<vmx_can_emulate_instruction>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/vmx.c|5050| <<handle_rmode_exception>> kvm_queue_exception(vcpu, vec);
+ *   - arch/x86/kvm/vmx/vmx.c|5113| <<handle_exception_nmi>> kvm_queue_exception(vcpu, NM_VECTOR);
+ *   - arch/x86/kvm/vmx/vmx.c|5849| <<handle_invpcid>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/vmx.c|5927| <<handle_vmx_instruction>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/vmx/vmx.c|5939| <<handle_encls>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/x86.c|845| <<kvm_require_dr>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/x86.c|2111| <<kvm_handle_invalid_op>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/x86.c|4933| <<kvm_vcpu_ioctl_x86_set_mce>> kvm_queue_exception(vcpu, MC_VECTOR);
+ *   - arch/x86/kvm/x86.c|7934| <<inject_emulated_exception>> kvm_queue_exception(vcpu, ctxt->exception.vector);
+ *   - arch/x86/kvm/x86.c|8097| <<handle_emulation_failure>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/x86.c|8441| <<x86_emulate_instruction>> kvm_queue_exception(vcpu, UD_VECTOR);
+ *   - arch/x86/kvm/x86.c|11805| <<kvm_arch_vcpu_ioctl_set_guest_debug>> kvm_queue_exception(vcpu, DB_VECTOR);
+ *   - arch/x86/kvm/x86.c|11807| <<kvm_arch_vcpu_ioctl_set_guest_debug>> kvm_queue_exception(vcpu, BP_VECTOR);
+ */
 void kvm_queue_exception(struct kvm_vcpu *vcpu, unsigned nr)
 {
 	kvm_multiple_exception(vcpu, nr, false, 0, false, 0, false);
 }
 EXPORT_SYMBOL_GPL(kvm_queue_exception);
 
+/*
+ * 在以下使用kvm_requeue_exception():
+ *   - arch/x86/kvm/svm/svm.c|4042| <<svm_complete_interrupts>> kvm_requeue_exception(vcpu, vector);
+ *   - arch/x86/kvm/vmx/vmx.c|7042| <<__vmx_complete_interrupts>> kvm_requeue_exception(vcpu, vector);
+ */
 void kvm_requeue_exception(struct kvm_vcpu *vcpu, unsigned nr)
 {
 	kvm_multiple_exception(vcpu, nr, false, 0, false, 0, true);
 }
 EXPORT_SYMBOL_GPL(kvm_requeue_exception);
 
+/*
+ * 在以下使用kvm_queue_exception_p():
+ *   - arch/x86/kvm/svm/svm.c|2098| <<db_interception>> kvm_queue_exception_p(vcpu, DB_VECTOR, payload);
+ *   - arch/x86/kvm/vmx/vmx.c|5208| <<handle_exception_nmi>> kvm_queue_exception_p(vcpu, DB_VECTOR, dr6);
+ *   - arch/x86/kvm/vmx/vmx.c|5455| <<handle_dr>> kvm_queue_exception_p(vcpu, DB_VECTOR, DR6_BD);
+ *   - arch/x86/kvm/x86.c|8282| <<kvm_vcpu_do_singlestep>> kvm_queue_exception_p(vcpu, DB_VECTOR, DR6_BS);
+ *   - arch/x86/kvm/x86.c|8337| <<kvm_vcpu_check_code_breakpoint>> kvm_queue_exception_p(vcpu, DB_VECTOR, dr6);
+ */
 void kvm_queue_exception_p(struct kvm_vcpu *vcpu, unsigned nr,
 			   unsigned long payload)
 {
@@ -716,6 +897,11 @@ void kvm_queue_exception_p(struct kvm_vcpu *vcpu, unsigned nr,
 }
 EXPORT_SYMBOL_GPL(kvm_queue_exception_p);
 
+/*
+ * 在以下使用kvm_queue_exception_e_p():
+ *   - arch/x86/kvm/x86.c|779| <<kvm_inject_page_fault>> kvm_queue_exception_e_p(vcpu, PF_VECTOR,
+ *             fault->error_code, fault->address);
+ */
 static void kvm_queue_exception_e_p(struct kvm_vcpu *vcpu, unsigned nr,
 				    u32 error_code, unsigned long payload)
 {
@@ -774,6 +960,13 @@ EXPORT_SYMBOL_GPL(kvm_inject_emulated_page_fault);
 
 void kvm_inject_nmi(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用kvm_vcpu_arch->nmi_queued:
+	 *   - arch/x86/kvm/x86.c|874| <<kvm_inject_nmi>> atomic_inc(&vcpu->arch.nmi_queued);
+	 *   - arch/x86/kvm/x86.c|5158| <<kvm_vcpu_ioctl_x86_set_vcpu_events>> atomic_set(&vcpu->arch.nmi_queued, events->nmi.pending);
+	 *   - arch/x86/kvm/x86.c|9855| <<process_nmi>> vcpu->arch.nmi_pending += atomic_xchg(&vcpu->arch.nmi_queued, 0);
+	 *   - arch/x86/kvm/x86.c|12376| <<kvm_vcpu_reset>> atomic_set(&vcpu->arch.nmi_queued, 0);
+	 */
 	atomic_inc(&vcpu->arch.nmi_queued);
 	kvm_make_request(KVM_REQ_NMI, vcpu);
 }
@@ -1732,6 +1925,36 @@ bool kvm_msr_allowed(struct kvm_vcpu *vcpu, u32 index, u32 type)
 }
 EXPORT_SYMBOL_GPL(kvm_msr_allowed);
 
+/*
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_vcpu_reset
+ * kvm_apic_accept_events
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_lapic_reg_write
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ */
 /*
  * Write @data into the MSR specified by @index.  Select MSR specific fault
  * checks are bypassed if @host_initiated is %true.
@@ -1967,6 +2190,36 @@ int kvm_emulate_rdmsr(struct kvm_vcpu *vcpu)
 }
 EXPORT_SYMBOL_GPL(kvm_emulate_rdmsr);
 
+/*
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_vcpu_reset
+ * kvm_apic_accept_events
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_lapic_reg_write
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ */
 int kvm_emulate_wrmsr(struct kvm_vcpu *vcpu)
 {
 	u32 ecx = kvm_rcx_read(vcpu);
@@ -2020,6 +2273,11 @@ int kvm_handle_invalid_op(struct kvm_vcpu *vcpu)
 }
 EXPORT_SYMBOL_GPL(kvm_handle_invalid_op);
 
+/*
+ * 在以下使用kvm_emulate_monitor():
+ *   - arch/x86/kvm/svm/svm.c|3312| <<global>> [SVM_EXIT_MONITOR] = kvm_emulate_monitor,
+ *   - arch/x86/kvm/vmx/vmx.c|5788| <<global>> [EXIT_REASON_MONITOR_INSTRUCTION] = kvm_emulate_monitor,
+ */
 int kvm_emulate_monitor(struct kvm_vcpu *vcpu)
 {
 	pr_warn_once("kvm: MONITOR instruction emulated as NOP!\n");
@@ -2027,6 +2285,11 @@ int kvm_emulate_monitor(struct kvm_vcpu *vcpu)
 }
 EXPORT_SYMBOL_GPL(kvm_emulate_monitor);
 
+/*
+ * 在以下调用kvm_vcpu_exit_request():
+ *   - arch/x86/kvm/x86.c|10386| <<vcpu_enter_guest(关于cancel_injection)>> if (kvm_vcpu_exit_request(vcpu)) {
+ *   - arch/x86/kvm/x86.c|10443| <<vcpu_enter_guest(关于EXIT_FASTPATH_EXIT_HANDLED)>> if (unlikely(kvm_vcpu_exit_request(vcpu))) {
+ */
 static inline bool kvm_vcpu_exit_request(struct kvm_vcpu *vcpu)
 {
 	xfer_to_guest_mode_prepare();
@@ -2041,6 +2304,10 @@ static inline bool kvm_vcpu_exit_request(struct kvm_vcpu *vcpu)
  * from guest to host, e.g. reacquiring KVM's SRCU lock. In contrast to the
  * other cases which must be called after interrupts are enabled on the host.
  */
+/*
+ * 在以下调用handle_fastpath_set_x2apic_icr_irqoff():
+ *   - arch/x86/kvm/x86.c|2089| <<handle_fastpath_set_msr_irqoff>> if (!handle_fastpath_set_x2apic_icr_irqoff(vcpu, data)) {
+ */
 static int handle_fastpath_set_x2apic_icr_irqoff(struct kvm_vcpu *vcpu, u64 data)
 {
 	if (!lapic_in_kernel(vcpu) || !apic_x2apic_mode(vcpu->arch.apic))
@@ -2055,6 +2322,10 @@ static int handle_fastpath_set_x2apic_icr_irqoff(struct kvm_vcpu *vcpu, u64 data
 	return 1;
 }
 
+/*
+ * 在以下使用handle_fastpath_set_tscdeadline():
+ *   - arch/x86/kvm/x86.c|2096| <<handle_fastpath_set_msr_irqoff>> if (!handle_fastpath_set_tscdeadline(vcpu, data)) {
+ */
 static int handle_fastpath_set_tscdeadline(struct kvm_vcpu *vcpu, u64 data)
 {
 	if (!kvm_can_use_hv_timer(vcpu))
@@ -2064,6 +2335,11 @@ static int handle_fastpath_set_tscdeadline(struct kvm_vcpu *vcpu, u64 data)
 	return 0;
 }
 
+/*
+ * 在以下调用handle_fastpath_set_msr_irqoff():
+ *   - arch/x86/kvm/svm/svm.c|4077| <<svm_exit_handlers_fastpath>> return handle_fastpath_set_msr_irqoff(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|6873| <<vmx_exit_handlers_fastpath>> return handle_fastpath_set_msr_irqoff(vcpu);
+ */
 fastpath_t handle_fastpath_set_msr_irqoff(struct kvm_vcpu *vcpu)
 {
 	u32 msr = kvm_rcx_read(vcpu);
@@ -2130,10 +2406,42 @@ struct pvclock_gtod_data {
 	u64		wall_time_sec;
 };
 
+/*
+ * 在以下使用pvclock_gtod_data:
+ *   - arch/x86/kvm/x86.c|2417| <<update_pvclock_gtod>> struct pvclock_gtod_data *vdata = &pvclock_gtod_data;
+ *   - arch/x86/kvm/x86.c|2448| <<get_kvmclock_base_ns>> return ktime_to_ns(ktime_add(ktime_get_raw(), pvclock_gtod_data.offs_boot));
+ *   - arch/x86/kvm/x86.c|2828| <<kvm_track_tsc_matching>> struct pvclock_gtod_data *gtod = &pvclock_gtod_data;
+ *   - arch/x86/kvm/x86.c|3072| <<kvm_check_tsc_unstable>> if (pvclock_gtod_data.clock.vclock_mode == VDSO_CLOCKMODE_HVCLOCK)
+ *   - arch/x86/kvm/x86.c|3279| <<read_tsc>> u64 last = pvclock_gtod_data.clock.cycle_last;
+ *   - arch/x86/kvm/x86.c|3334| <<do_monotonic_raw>> struct pvclock_gtod_data *gtod = &pvclock_gtod_data;
+ *   - arch/x86/kvm/x86.c|3353| <<do_realtime>> struct pvclock_gtod_data *gtod = &pvclock_gtod_data;
+ *   - arch/x86/kvm/x86.c|3376| <<kvm_get_time_and_clockread>> if (!gtod_is_based_on_tsc(pvclock_gtod_data.clock.vclock_mode))
+ *   - arch/x86/kvm/x86.c|3388| <<kvm_get_walltime_and_clockread>> if (!gtod_is_based_on_tsc(pvclock_gtod_data.clock.vclock_mode))
+ *   - arch/x86/kvm/x86.c|3504| <<pvclock_update_vm_gtod_copy>> vclock_mode = pvclock_gtod_data.clock.vclock_mode;
+ *   - arch/x86/kvm/x86.c|10233| <<pvclock_gtod_notify>> struct pvclock_gtod_data *gtod = &pvclock_gtod_data;
+ */
 static struct pvclock_gtod_data pvclock_gtod_data;
 
+/*
+ * 在以下调用update_pvclock_gtod():
+ *   - arch/x86/kvm/x86.c|9587| <<pvclock_gtod_notify>> update_pvclock_gtod(tk);
+ */
 static void update_pvclock_gtod(struct timekeeper *tk)
 {
+	/*
+	 * 在以下使用pvclock_gtod_data:
+	 *   - arch/x86/kvm/x86.c|2417| <<update_pvclock_gtod>> struct pvclock_gtod_data *vdata = &pvclock_gtod_data;
+	 *   - arch/x86/kvm/x86.c|2448| <<get_kvmclock_base_ns>> return ktime_to_ns(ktime_add(ktime_get_raw(), pvclock_gtod_data.offs_boot));
+	 *   - arch/x86/kvm/x86.c|2828| <<kvm_track_tsc_matching>> struct pvclock_gtod_data *gtod = &pvclock_gtod_data;
+	 *   - arch/x86/kvm/x86.c|3072| <<kvm_check_tsc_unstable>> if (pvclock_gtod_data.clock.vclock_mode == VDSO_CLOCKMODE_HVCLOCK)
+	 *   - arch/x86/kvm/x86.c|3279| <<read_tsc>> u64 last = pvclock_gtod_data.clock.cycle_last;
+	 *   - arch/x86/kvm/x86.c|3334| <<do_monotonic_raw>> struct pvclock_gtod_data *gtod = &pvclock_gtod_data;
+	 *   - arch/x86/kvm/x86.c|3353| <<do_realtime>> struct pvclock_gtod_data *gtod = &pvclock_gtod_data;
+	 *   - arch/x86/kvm/x86.c|3376| <<kvm_get_time_and_clockread>> if (!gtod_is_based_on_tsc(pvclock_gtod_data.clock.vclock_mode))
+	 *   - arch/x86/kvm/x86.c|3388| <<kvm_get_walltime_and_clockread>> if (!gtod_is_based_on_tsc(pvclock_gtod_data.clock.vclock_mode))
+	 *   - arch/x86/kvm/x86.c|3504| <<pvclock_update_vm_gtod_copy>> vclock_mode = pvclock_gtod_data.clock.vclock_mode;
+	 *   - arch/x86/kvm/x86.c|10233| <<pvclock_gtod_notify>> struct pvclock_gtod_data *gtod = &pvclock_gtod_data;
+	 */
 	struct pvclock_gtod_data *vdata = &pvclock_gtod_data;
 
 	write_seqcount_begin(&vdata->seq);
@@ -2162,6 +2470,15 @@ static void update_pvclock_gtod(struct timekeeper *tk)
 	write_seqcount_end(&vdata->seq);
 }
 
+/*
+ * 在以下调用get_kvmclock_base_ns():
+ *   - arch/x86/kvm/x86.c|3101| <<kvm_synchronize_tsc>> ns = get_kvmclock_base_ns();
+ *   - arch/x86/kvm/x86.c|3660| <<get_kvmclock_ns>> return get_kvmclock_base_ns() + ka->kvmclock_offset;
+ *   - arch/x86/kvm/x86.c|3738| <<get_kvmclock_ns>> ret = get_kvmclock_base_ns() + ka->kvmclock_offset;
+ *   - arch/x86/kvm/x86.c|3918| <<kvm_guest_time_update>> kernel_ns = get_kvmclock_base_ns();
+ *   - arch/x86/kvm/x86.c|7705| <<kvm_arch_vm_ioctl>> now_ns = get_kvmclock_base_ns();
+ *   - arch/x86/kvm/x86.c|14426| <<kvm_arch_init_vm>> kvm->arch.kvmclock_offset = -get_kvmclock_base_ns();
+ */
 static s64 get_kvmclock_base_ns(void)
 {
 	/* Count up from boot time, but with the frequency of the raw clock.  */
@@ -2221,19 +2538,52 @@ void kvm_write_wall_clock(struct kvm *kvm, gpa_t wall_clock, int sec_hi_ofs)
 	kvm_write_guest(kvm, wall_clock, &version, sizeof(version));
 }
 
+/*
+ * 在以下使用kvm_write_system_time():
+ *   - arch/x86/kvm/x86.c|4612| <<kvm_set_msr_common(MSR_KVM_SYSTEM_TIME_NEW)>> kvm_write_system_time(vcpu, data, false, msr_info->host_initiated);
+ *   - arch/x86/kvm/x86.c|4618| <<kvm_set_msr_common(MSR_KVM_SYSTEM_TIME)>> kvm_write_system_time(vcpu, data, true, msr_info->host_initiated);
+ */
 static void kvm_write_system_time(struct kvm_vcpu *vcpu, gpa_t system_time,
 				  bool old_msr, bool host_initiated)
 {
 	struct kvm_arch *ka = &vcpu->kvm->arch;
 
 	if (vcpu->vcpu_id == 0 && !host_initiated) {
+		/*
+		 * 在以下使用KVM_REQ_MASTERCLOCK_UPDATE():
+		 *   - arch/x86/kvm/hyperv.c|1411| <<kvm_hv_set_msr_pw>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+		 *   - arch/x86/kvm/x86.c|2444| <<kvm_write_system_time>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+		 *   - arch/x86/kvm/x86.c|2647| <<kvm_track_tsc_matching>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+		 *   - arch/x86/kvm/x86.c|9496| <<pvclock_gtod_update_fn>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+		 *   - arch/x86/kvm/x86.c|11224| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu))
+		 *   - arch/x86/kvm/x86.c|13427| <<kvm_arch_hardware_enable>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+		 *   - arch/x86/kvm/xen.c|58| <<kvm_xen_shared_info_init>> kvm_make_all_cpus_request(kvm, KVM_REQ_MASTERCLOCK_UPDATE);
+		 *
+		 * 处理KVM_REQ_MASTERCLOCK_UPDATE的函数: kvm_gen_update_masterclock()
+		 */
 		if (ka->boot_vcpu_runs_old_kvmclock != old_msr)
 			kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
 
 		ka->boot_vcpu_runs_old_kvmclock = old_msr;
 	}
 
+	/*
+	 * struct kvm_vcpu *vcpu:
+	 * -> struct kvm_vcpu_arch arch;
+	 *    -> gpa_t time;
+	 *    -> struct pvclock_vcpu_time_info hv_clock;
+	 *    -> struct gfn_to_hva_cache pv_time;
+	 *    -> bool pv_time_enabled;
+	 */
 	vcpu->arch.time = system_time;
+	/*
+	 * 在以下使用KVM_REQ_GLOBAL_CLOCK_UPDATE:
+	 *   - arch/x86/kvm/x86.c|2529| <<kvm_write_system_time>> kvm_make_request(KVM_REQ_GLOBAL_CLOCK_UPDATE, vcpu);
+	 *   - arch/x86/kvm/x86.c|5532| <<kvm_arch_vcpu_load>> kvm_make_request(KVM_REQ_GLOBAL_CLOCK_UPDATE, vcpu);
+	 *   - arch/x86/kvm/x86.c|11816| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_GLOBAL_CLOCK_UPDATE, vcpu))
+	 *
+	 * 处理KVM_REQ_GLOBAL_CLOCK_UPDATE的函数: kvm_gen_kvmclock_update()
+	 */
 	kvm_make_request(KVM_REQ_GLOBAL_CLOCK_UPDATE, vcpu);
 
 	/* we verify if the enable bit is set... */
@@ -2249,12 +2599,25 @@ static void kvm_write_system_time(struct kvm_vcpu *vcpu, gpa_t system_time,
 	return;
 }
 
+/*
+ * 只在一个地方使用div_frac():
+ *   - arch/x86/kvm/x86.c|2584| <<kvm_get_time_scale>> *pmultiplier = div_frac(scaled64, tps32);
+ */
 static uint32_t div_frac(uint32_t dividend, uint32_t divisor)
 {
 	do_shl32_div32(dividend, divisor);
 	return dividend;
 }
 
+/*
+ * 在以下使用kvm_get_time_scale():
+ *   - arch/x86/kvm/x86.c|2704| <<kvm_set_tsc_khz>> kvm_get_time_scale(user_tsc_khz * 1000LL, NSEC_PER_SEC,
+ *          &vcpu->arch.virtual_tsc_shift, &vcpu->arch.virtual_tsc_mult);
+ *   - arch/x86/kvm/x86.c|3609| <<get_kvmclock_ns>> kvm_get_time_scale(NSEC_PER_SEC, __this_cpu_read(cpu_tsc_khz) * 1000LL,
+ *          &hv_clock.tsc_shift, &hv_clock.tsc_to_system_mul);
+ *   - arch/x86/kvm/x86.c|3826| <<kvm_guest_time_update>> kvm_get_time_scale(NSEC_PER_SEC, tgt_tsc_khz * 1000LL,
+ *          &vcpu->hv_clock.tsc_shift, &vcpu->hv_clock.tsc_to_system_mul);
+ */
 static void kvm_get_time_scale(uint64_t scaled_hz, uint64_t base_hz,
 			       s8 *pshift, u32 *pmultiplier)
 {
@@ -2284,14 +2647,47 @@ static void kvm_get_time_scale(uint64_t scaled_hz, uint64_t base_hz,
 }
 
 #ifdef CONFIG_X86_64
+/*
+ * 在以下使用kvm_guest_has_master_clock:
+ *    - arch/x86/kvm/x86.c|2500| <<global>> static atomic_t kvm_guest_has_master_clock = ATOMIC_INIT(0);
+ *    - arch/x86/kvm/x86.c|3144| <<pvclock_update_vm_gtod_copy>> atomic_set(&kvm_guest_has_master_clock, 1);
+ *    - arch/x86/kvm/x86.c|9560| <<pvclock_gtod_update_fn>> atomic_set(&kvm_guest_has_master_clock, 0);
+ *    - arch/x86/kvm/x86.c|9595| <<pvclock_gtod_notify>> atomic_read(&kvm_guest_has_master_clock) != 0)
+ */
 static atomic_t kvm_guest_has_master_clock = ATOMIC_INIT(0);
 #endif
 
+/*
+ * 在以下设置cpu_tsc_khz (percpu):
+ *   - arch/x86/kvm/x86.c|9664| <<kvmclock_cpu_down_prep>> __this_cpu_write(cpu_tsc_khz, 0);
+ *   - arch/x86/kvm/x86.c|9679| <<tsc_khz_changed>> __this_cpu_write(cpu_tsc_khz, khz);
+ *   - arch/x86/kvm/x86.c|9698| <<kvm_hyperv_tsc_notifier>> per_cpu(cpu_tsc_khz, cpu) = tsc_khz;
+ * 在以下使用cpu_tsc_khz (percpu):
+ *   - arch/x86/kvm/x86.c|2589| <<global>> static DEFINE_PER_CPU(unsigned long , cpu_tsc_khz);
+ *   - arch/x86/kvm/x86.c|3608| <<get_kvmclock_ns>> if (__this_cpu_read(cpu_tsc_khz)) {
+ *   - arch/x86/kvm/x86.c|3609| <<get_kvmclock_ns>> kvm_get_time_scale(NSEC_PER_SEC, __this_cpu_read(cpu_tsc_khz) * 1000LL,
+ *   - arch/x86/kvm/x86.c|3765| <<kvm_guest_time_update>> tgt_tsc_khz = __this_cpu_read(cpu_tsc_khz);
+ */
 static DEFINE_PER_CPU(unsigned long, cpu_tsc_khz);
+/*
+ * 在以下使用max_tsc_khz:
+ *   - arch/x86/kvm/x86.c|2610| <<global>> static unsigned long max_tsc_khz;
+ *   - arch/x86/kvm/x86.c|10083| <<kvm_timer_init>> max_tsc_khz = tsc_khz;
+ *   - arch/x86/kvm/x86.c|10094| <<kvm_timer_init>> max_tsc_khz = policy->cpuinfo.max_freq;
+ *   - arch/x86/kvm/x86.c|13801| <<kvm_arch_vcpu_create>> kvm_set_tsc_khz(vcpu, max_tsc_khz);
+ */
 static unsigned long max_tsc_khz;
 
+/*
+ * 在以下使用adjust_tsc_khz():
+ *   - arch/x86/kvm/x86.c|2767| <<kvm_set_tsc_khz>> thresh_lo = adjust_tsc_khz(tsc_khz, -tsc_tolerance_ppm);
+ *   - arch/x86/kvm/x86.c|2768| <<kvm_set_tsc_khz>> thresh_hi = adjust_tsc_khz(tsc_khz, tsc_tolerance_ppm);
+ */
 static u32 adjust_tsc_khz(u32 khz, s32 ppm)
 {
+	/*
+	 * 0.000250
+	 */
 	u64 v = (u64)khz * (1000000 + ppm);
 	do_div(v, 1000000);
 	return v;
@@ -2299,16 +2695,41 @@ static u32 adjust_tsc_khz(u32 khz, s32 ppm)
 
 static void kvm_vcpu_write_tsc_multiplier(struct kvm_vcpu *vcpu, u64 l1_multiplier);
 
+/*
+ * 在以下使用set_tsc_khz():
+ *   - arch/x86/kvm/x86.c|2609| <<kvm_set_tsc_khz>> return set_tsc_khz(vcpu, user_tsc_khz, use_scaling);
+ */
 static int set_tsc_khz(struct kvm_vcpu *vcpu, u32 user_tsc_khz, bool scale)
 {
 	u64 ratio;
 
 	/* Guest TSC same frequency as host TSC? */
 	if (!scale) {
+		/*
+		 * 在以下使用kvm_vcpu_write_tsc_multiplier():
+		 *   - arch/x86/kvm/x86.c|2544| <<set_tsc_khz>> kvm_vcpu_write_tsc_multiplier(vcpu, kvm_default_tsc_scaling_ratio);
+		 *   - arch/x86/kvm/x86.c|2570| <<set_tsc_khz>> kvm_vcpu_write_tsc_multiplier(vcpu, ratio);
+		 *   - arch/x86/kvm/x86.c|2587| <<kvm_set_tsc_khz>> kvm_vcpu_write_tsc_multiplier(vcpu, kvm_default_tsc_scaling_ratio);
+		 */
 		kvm_vcpu_write_tsc_multiplier(vcpu, kvm_default_tsc_scaling_ratio);
 		return 0;
 	}
 
+	/*
+	 * 在以下设置kvm_has_tsc_control:
+	 *   - arch/x86/kvm/svm/svm.c|1115| <<svm_hardware_setup>> kvm_has_tsc_control = true;
+	 *   - arch/x86/kvm/vmx/vmx.c|8787| <<hardware_setup>> kvm_has_tsc_control = true;
+	 * 在以下使用kvm_has_tsc_control:
+	 *   - arch/x86/kvm/debugfs.c|69| <<kvm_arch_create_vcpu_debugfs>> if (kvm_has_tsc_control) {
+	 *   - arch/x86/kvm/vmx/nested.c|2581| <<prepare_vmcs02>> if (kvm_has_tsc_control)
+	 *   - arch/x86/kvm/vmx/nested.c|4680| <<nested_vmx_vmexit>> if (kvm_has_tsc_control)
+	 *   - arch/x86/kvm/x86.c|2579| <<set_tsc_khz>> if (!kvm_has_tsc_control) {
+	 *   - arch/x86/kvm/x86.c|2843| <<kvm_vcpu_write_tsc_multiplier>> if (kvm_has_tsc_control)
+	 *   - arch/x86/kvm/x86.c|3607| <<kvm_guest_time_update>> if (kvm_has_tsc_control)
+	 *   - arch/x86/kvm/x86.c|4951| <<kvm_vm_ioctl_check_extension>> r = kvm_has_tsc_control;
+	 *   - arch/x86/kvm/x86.c|6207| <<kvm_arch_vcpu_ioctl(KVM_SET_TSC_KHZ)>> if (kvm_has_tsc_control &
+	 *   - arch/x86/kvm/x86.c|13736| <<kvm_arch_hardware_setup>> if (kvm_has_tsc_control) {
+	 */
 	/* TSC scaling supported? */
 	if (!kvm_has_tsc_control) {
 		if (user_tsc_khz > tsc_khz) {
@@ -2321,6 +2742,21 @@ static int set_tsc_khz(struct kvm_vcpu *vcpu, u32 user_tsc_khz, bool scale)
 		}
 	}
 
+	/*
+	 * 在以下使用kvm_tsc_scaling_ratio_frac_bits:
+	 *   - arch/x86/kvm/debugfs.c|51| <<vcpu_get_tsc_scaling_frac_bits>> *val = kvm_tsc_scaling_ratio_frac_bits;
+	 *   - arch/x86/kvm/svm/svm.c|1117| <<svm_hardware_setup>> kvm_tsc_scaling_ratio_frac_bits = 32;
+	 *   - arch/x86/kvm/vmx/vmx.c|8358| <<vmx_set_hv_timer>> if (vcpu->arch.l1_tsc_scaling_ratio != kvm_default_tsc_scaling_ratio
+	 *              && delta_tsc && u64_shl_div_u64(delta_tsc, kvm_tsc_scaling_ratio_frac_bits, vcpu->arch.l1_tsc_scaling_ratio, &delta_tsc))
+	 *   - arch/x86/kvm/vmx/vmx.c|8789| <<hardware_setup>> kvm_tsc_scaling_ratio_frac_bits = 48;
+	 *   - arch/x86/kvm/x86.c|2561| <<set_tsc_khz>> ratio = mul_u64_u32_div(1ULL << kvm_tsc_scaling_ratio_frac_bits, user_tsc_khz, tsc_khz);
+	 *   - arch/x86/kvm/x86.c|2702| <<__scale_tsc>> return mul_u64_u64_shr(tsc, ratio, kvm_tsc_scaling_ratio_frac_bits);
+	 *   - arch/x86/kvm/x86.c|2740| <<kvm_calc_nested_tsc_offset>> nested_offset = mul_s64_u64_shr((s64) l1_offset,
+	 *              l2_multiplier, kvm_tsc_scaling_ratio_frac_bits);
+	 *   - arch/x86/kvm/x86.c|2751| <<kvm_calc_nested_tsc_multiplier>> return mul_u64_u64_shr(l1_multiplier, l2_multiplier,
+	 *              kvm_tsc_scaling_ratio_frac_bits);
+	 *   - arch/x86/kvm/x86.c|13707| <<kvm_arch_hardware_setup>> kvm_default_tsc_scaling_ratio = 1ULL << kvm_tsc_scaling_ratio_frac_bits;
+	 */
 	/* TSC scaling required  - calculate ratio */
 	ratio = mul_u64_u32_div(1ULL << kvm_tsc_scaling_ratio_frac_bits,
 				user_tsc_khz, tsc_khz);
@@ -2331,10 +2767,21 @@ static int set_tsc_khz(struct kvm_vcpu *vcpu, u32 user_tsc_khz, bool scale)
 		return -1;
 	}
 
+	/*
+	 * 在以下使用kvm_vcpu_write_tsc_multiplier():
+	 *   - arch/x86/kvm/x86.c|2544| <<set_tsc_khz>> kvm_vcpu_write_tsc_multiplier(vcpu, kvm_default_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|2570| <<set_tsc_khz>> kvm_vcpu_write_tsc_multiplier(vcpu, ratio);
+	 *   - arch/x86/kvm/x86.c|2587| <<kvm_set_tsc_khz>> kvm_vcpu_write_tsc_multiplier(vcpu, kvm_default_tsc_scaling_ratio);
+	 */
 	kvm_vcpu_write_tsc_multiplier(vcpu, ratio);
 	return 0;
 }
 
+/*
+ * 在以下使用kvm_set_tsc_khz():
+ *   - arch/x86/kvm/x86.c|5780| <<kvm_arch_vcpu_ioctl(KVM_SET_TSC_KHZ)>> if (!kvm_set_tsc_khz(vcpu, user_tsc_khz))
+ *   - arch/x86/kvm/x86.c|12691| <<kvm_arch_vcpu_create>> kvm_set_tsc_khz(vcpu, max_tsc_khz);
+ */
 static int kvm_set_tsc_khz(struct kvm_vcpu *vcpu, u32 user_tsc_khz)
 {
 	u32 thresh_lo, thresh_hi;
@@ -2347,10 +2794,45 @@ static int kvm_set_tsc_khz(struct kvm_vcpu *vcpu, u32 user_tsc_khz)
 		return -1;
 	}
 
+	/*
+	 * 在以下使用kvm_vcpu_arch->virtual_tsc_shift:
+	 *   - arch/x86/kvm/x86.c|2684| <<kvm_set_tsc_khz>> kvm_get_time_scale(user_tsc_khz * 1000LL,
+	 *           NSEC_PER_SEC, &vcpu->arch.virtual_tsc_shift, &vcpu->arch.virtual_tsc_mult);
+	 *   - arch/x86/kvm/x86.c|2707| <<compute_guest_tsc>> u64 tsc = pvclock_scale_delta(kernel_ns-vcpu->arch.this_tsc_nsec,
+	 *           vcpu->arch.virtual_tsc_mult, vcpu->arch.virtual_tsc_shift);
+	 *   - arch/x86/kvm/x86.h|382| <<nsec_to_cycles>> return pvclock_scale_delta(nsec,
+	 *           vcpu->arch.virtual_tsc_mult, vcpu->arch.virtual_tsc_shift);
+	 *
+	 * 在以下使用kvm_get_time_scale():
+	 *   - arch/x86/kvm/x86.c|2704| <<kvm_set_tsc_khz>> kvm_get_time_scale(user_tsc_khz * 1000LL, NSEC_PER_SEC,
+	 *          &vcpu->arch.virtual_tsc_shift, &vcpu->arch.virtual_tsc_mult);
+	 *   - arch/x86/kvm/x86.c|3609| <<get_kvmclock_ns>> kvm_get_time_scale(NSEC_PER_SEC, __this_cpu_read(cpu_tsc_khz) * 1000LL,
+	 *          &hv_clock.tsc_shift, &hv_clock.tsc_to_system_mul);
+	 *   - arch/x86/kvm/x86.c|3826| <<kvm_guest_time_update>> kvm_get_time_scale(NSEC_PER_SEC, tgt_tsc_khz * 1000LL,
+	 *          &vcpu->hv_clock.tsc_shift, &vcpu->hv_clock.tsc_to_system_mul);
+	 */
 	/* Compute a scale to convert nanoseconds in TSC cycles */
 	kvm_get_time_scale(user_tsc_khz * 1000LL, NSEC_PER_SEC,
 			   &vcpu->arch.virtual_tsc_shift,
 			   &vcpu->arch.virtual_tsc_mult);
+	/*
+	 * 在以下设置kvm_vcpu_arch->virtual_tsc_khz:
+	 *   - arch/x86/kvm/x86.c|2561| <<kvm_set_tsc_khz>> vcpu->arch.virtual_tsc_khz = user_tsc_khz;
+	 * 在以下使用kvm_vcpu_arch->virtual_tsc_khz:
+	 *   - arch/x86/kvm/hyperv.c|1697| <<kvm_hv_get_msr>> data = (u64)vcpu->arch.virtual_tsc_khz * 1000;
+	 *   - arch/x86/kvm/lapic.c|2843| <<__wait_lapic_expire>> do_div(delay_ns, vcpu->arch.virtual_tsc_khz);
+	 *   - arch/x86/kvm/lapic.c|2863| <<adjust_lapic_timer_advance>> do_div(ns, vcpu->arch.virtual_tsc_khz);
+	 *   - arch/x86/kvm/lapic.c|2868| <<adjust_lapic_timer_advance>> do_div(ns, vcpu->arch.virtual_tsc_khz);
+	 *   - arch/x86/kvm/lapic.c|3002| <<start_sw_tscdeadline>> unsigned long this_tsc_khz = vcpu->arch.virtual_tsc_khz;
+	 *   - arch/x86/kvm/vmx/nested.c|2111| <<vmx_start_preemption_timer>> if (vcpu->arch.virtual_tsc_khz == 0)
+	 *   - arch/x86/kvm/vmx/nested.c|2116| <<vmx_start_preemption_timer>> do_div(preemption_timeout, vcpu->arch.virtual_tsc_khz);
+	 *   - arch/x86/kvm/vmx/nested.c|4059| <<vmx_get_preemption_timer_value>> value = ktime_to_ns(remaining) * vcpu->arch.virtual_tsc_khz;
+	 *   - arch/x86/kvm/x86.c|2775| <<kvm_synchronize_tsc>> if (vcpu->arch.virtual_tsc_khz) {
+	 *   - arch/x86/kvm/x86.c|2786| <<kvm_synchronize_tsc>> u64 tsc_hz = vcpu->arch.virtual_tsc_khz * 1000LL;
+	 *   - arch/x86/kvm/x86.c|2804| <<kvm_synchronize_tsc>> vcpu->arch.virtual_tsc_khz == kvm->arch.last_tsc_khz) {
+	 *   - arch/x86/kvm/x86.c|2837| <<kvm_synchronize_tsc>> kvm->arch.last_tsc_khz = vcpu->arch.virtual_tsc_khz;
+	 *   - arch/x86/kvm/x86.c|5786| <<kvm_arch_vcpu_ioctl(KVM_GET_TSC_KHZ)>> r = vcpu->arch.virtual_tsc_khz;
+	 */
 	vcpu->arch.virtual_tsc_khz = user_tsc_khz;
 
 	/*
@@ -2359,17 +2841,47 @@ static int kvm_set_tsc_khz(struct kvm_vcpu *vcpu, u32 user_tsc_khz)
 	 * rate being applied is within that bounds of the hardware
 	 * rate.  If so, no scaling or compensation need be done.
 	 */
+	/*
+	 * 在以下使用tsc_tolerance_ppm:
+	 *   - arch/x86/kvm/x86.c|229| <<global>> static u32 __read_mostly tsc_tolerance_ppm = 250;
+	 *   - arch/x86/kvm/x86.c|2694| <<kvm_set_tsc_khz>> thresh_lo = adjust_tsc_khz(tsc_khz, -tsc_tolerance_ppm);
+	 *   - arch/x86/kvm/x86.c|2695| <<kvm_set_tsc_khz>> thresh_hi = adjust_tsc_khz(tsc_khz, tsc_tolerance_ppm);
+	 */
 	thresh_lo = adjust_tsc_khz(tsc_khz, -tsc_tolerance_ppm);
 	thresh_hi = adjust_tsc_khz(tsc_khz, tsc_tolerance_ppm);
 	if (user_tsc_khz < thresh_lo || user_tsc_khz > thresh_hi) {
 		pr_debug("kvm: requested TSC rate %u falls outside tolerance [%u,%u]\n", user_tsc_khz, thresh_lo, thresh_hi);
 		use_scaling = 1;
 	}
+	/*
+	 * 只在这里调用set_tsc_khz()
+	 */
 	return set_tsc_khz(vcpu, user_tsc_khz, use_scaling);
 }
 
+/*
+ * 只在vcpu->tsc_catchup的时候使用:
+ *   - arch/x86/kvm/x86.c|3735| <<kvm_guest_time_update>> u64 tsc = compute_guest_tsc(v, kernel_ns);
+ */
 static u64 compute_guest_tsc(struct kvm_vcpu *vcpu, s64 kernel_ns)
 {
+	/*
+	 * 在以下使用kvm_vcpu_arch->arch.virtual_tsc_mult:
+	 *   - arch/x86/kvm/x86.c|2697| <<kvm_set_tsc_khz>> kvm_get_time_scale(user_tsc_khz * 1000LL,
+	 *           NSEC_PER_SEC, &vcpu->arch.virtual_tsc_shift, &vcpu->arch.virtual_tsc_mult);
+	 *   - arch/x86/kvm/x86.c|2754| <<compute_guest_tsc>> u64 tsc = pvclock_scale_delta(kernel_ns-vcpu->arch.this_tsc_nsec,
+	 *           vcpu->arch.virtual_tsc_mult, vcpu->arch.virtual_tsc_shift);
+	 *   - arch/x86/kvm/x86.h|390| <<nsec_to_cycles>> return pvclock_scale_delta(nsec,
+	 *           vcpu->arch.virtual_tsc_mult, vcpu->arch.virtual_tsc_shift);
+	 *
+	 * 在以下使用kvm_vcpu_arch->virtual_tsc_shift:
+	 *   - arch/x86/kvm/x86.c|2684| <<kvm_set_tsc_khz>> kvm_get_time_scale(user_tsc_khz * 1000LL,
+	 *           NSEC_PER_SEC, &vcpu->arch.virtual_tsc_shift, &vcpu->arch.virtual_tsc_mult);
+	 *   - arch/x86/kvm/x86.c|2707| <<compute_guest_tsc>> u64 tsc = pvclock_scale_delta(kernel_ns-vcpu->arch.this_tsc_nsec,
+	 *           vcpu->arch.virtual_tsc_mult, vcpu->arch.virtual_tsc_shift);
+	 *   - arch/x86/kvm/x86.h|382| <<nsec_to_cycles>> return pvclock_scale_delta(nsec,
+	 *           vcpu->arch.virtual_tsc_mult, vcpu->arch.virtual_tsc_shift);
+	 */
 	u64 tsc = pvclock_scale_delta(kernel_ns-vcpu->arch.this_tsc_nsec,
 				      vcpu->arch.virtual_tsc_mult,
 				      vcpu->arch.virtual_tsc_shift);
@@ -2384,12 +2896,42 @@ static inline int gtod_is_based_on_tsc(int mode)
 }
 #endif
 
+/*
+ * 在以下使用kvm_synchronize_tsc():
+ *   - arch/x86/kvm/x86.c|3718| <<kvm_set_msr_common(MSR_IA32_TSC)>> kvm_synchronize_tsc(vcpu, data);
+ *   - arch/x86/kvm/x86.c|12688| <<kvm_arch_vcpu_postcreate>> kvm_synchronize_tsc(vcpu, 0);
+ *
+ * 在以下使用kvm_track_tsc_matching():
+ *   - arch/x86/kvm/x86.c|2867| <<kvm_synchronize_tsc>> kvm_track_tsc_matching(vcpu, !matched);
+ */
 static void kvm_track_tsc_matching(struct kvm_vcpu *vcpu, bool new_generation)
 {
 #ifdef CONFIG_X86_64
 	struct kvm_arch *ka = &vcpu->kvm->arch;
 	struct pvclock_gtod_data *gtod = &pvclock_gtod_data;
 
+	/*
+	 * 在以下设置kvm_arch->use_master_clock:
+	 *   - arch/x86/kvm/x86.c|3073| <<pvclock_update_vm_gtod_copy>> ka->use_master_clock = host_tsc_clocksource && vcpus_matched
+	 * 在以下使用kvm_arch->use_master_clock:
+	 *   - arch/x86/kvm/x86.c|2620| <<kvm_track_tsc_matching>> if ((ka->use_master_clock && new_generation) ||
+	 *   - arch/x86/kvm/x86.c|2621| <<kvm_track_tsc_matching>> (ka->use_master_clock != use_master_clock))
+	 *   - arch/x86/kvm/x86.c|2626| <<kvm_track_tsc_matching>> ka->use_master_clock, gtod->clock.vclock_mode);
+	 *   - arch/x86/kvm/x86.c|3077| <<pvclock_update_vm_gtod_copy>> if (ka->use_master_clock)
+	 *   - arch/x86/kvm/x86.c|3081| <<pvclock_update_vm_gtod_copy>> trace_kvm_update_master_clock(ka->use_master_clock, vclock_mode,
+	 *   - arch/x86/kvm/x86.c|3130| <<get_kvmclock_ns>> if (!ka->use_master_clock) {
+	 *   - arch/x86/kvm/x86.c|3232| <<kvm_guest_time_update>> use_master_clock = ka->use_master_clock;
+	 *   - arch/x86/kvm/x86.c|4817| <<kvm_arch_vcpu_load>> if (!vcpu->kvm->arch.use_master_clock || vcpu->cpu == -1)
+	 *   - arch/x86/kvm/x86.c|6791| <<kvm_arch_vm_ioctl(KVM_SET_CLOCK)>> if (kvm->arch.use_master_clock)
+	 *   - arch/x86/kvm/x86.c|6807| <<kvm_arch_vm_ioctl(KVM_GET_CLOCK)>> user_ns.flags = kvm->arch.use_master_clock ? KVM_CLOCK_TSC_STABLE : 0;
+	 *
+	 * 在以下使用kvm_arch->nr_vcpus_matched_tsc:
+	 *   - arch/x86/kvm/x86.c|2850| <<kvm_track_tsc_matching>> bool use_master_clock = (ka->nr_vcpus_matched_tsc + 1 ==
+	 *   - arch/x86/kvm/x86.c|2876| <<kvm_track_tsc_matching>> trace_kvm_track_tsc(vcpu->vcpu_id, ka->nr_vcpus_matched_tsc,
+	 *   - arch/x86/kvm/x86.c|3190| <<kvm_synchronize_tsc>> kvm->arch.nr_vcpus_matched_tsc = 0;
+	 *   - arch/x86/kvm/x86.c|3192| <<kvm_synchronize_tsc>> kvm->arch.nr_vcpus_matched_tsc++;
+	 *   - arch/x86/kvm/x86.c|3399| <<pvclock_update_vm_gtod_copy>> vcpus_matched = (ka->nr_vcpus_matched_tsc + 1 ==
+	 */
 	/*
 	 * To use the masterclock, the host clocksource must be based on TSC
 	 * and all vCPUs must have matching TSCs.  Note, the count for matching
@@ -2405,6 +2947,18 @@ static void kvm_track_tsc_matching(struct kvm_vcpu *vcpu, bool new_generation)
 	 * enabled (compute_guest_tsc() requires the masterclock snapshot to be
 	 * taken _after_ the new generation is created).
 	 */
+	/*
+	 * 在以下使用KVM_REQ_MASTERCLOCK_UPDATE:
+	 *   - arch/x86/kvm/hyperv.c|1411| <<kvm_hv_set_msr_pw>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+	 *   - arch/x86/kvm/x86.c|2444| <<kvm_write_system_time>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+	 *   - arch/x86/kvm/x86.c|2647| <<kvm_track_tsc_matching>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+	 *   - arch/x86/kvm/x86.c|9496| <<pvclock_gtod_update_fn>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+	 *   - arch/x86/kvm/x86.c|11224| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu))
+	 *   - arch/x86/kvm/x86.c|13427| <<kvm_arch_hardware_enable>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+	 *   - arch/x86/kvm/xen.c|58| <<kvm_xen_shared_info_init>> kvm_make_all_cpus_request(kvm, KVM_REQ_MASTERCLOCK_UPDATE);
+	 *
+	 * 处理KVM_REQ_MASTERCLOCK_UPDATE的函数: kvm_gen_update_masterclock()
+	 */
 	if ((ka->use_master_clock && new_generation) ||
 	    (ka->use_master_clock != use_master_clock))
 		kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
@@ -2425,11 +2979,39 @@ static void kvm_track_tsc_matching(struct kvm_vcpu *vcpu, bool new_generation)
  *
  * N equals to kvm_tsc_scaling_ratio_frac_bits.
  */
+/*
+ * 在以下使用__scale_tsc():
+ *   - arch/x86/kvm/x86.c|2924| <<kvm_scale_tsc>> _tsc = __scale_tsc(ratio, tsc);
+ *   - arch/x86/kvm/x86.c|14275| <<kvm_arch_hardware_setup>> __scale_tsc(kvm_max_tsc_scaling_ratio, tsc_khz));
+ */
 static inline u64 __scale_tsc(u64 ratio, u64 tsc)
 {
+	/*
+	 * 在以下使用kvm_tsc_scaling_ratio_frac_bits:
+	 *   - arch/x86/kvm/debugfs.c|51| <<vcpu_get_tsc_scaling_frac_bits>> *val = kvm_tsc_scaling_ratio_frac_bits;
+	 *   - arch/x86/kvm/svm/svm.c|1117| <<svm_hardware_setup>> kvm_tsc_scaling_ratio_frac_bits = 32;
+	 *   - arch/x86/kvm/vmx/vmx.c|8358| <<vmx_set_hv_timer>> if (vcpu->arch.l1_tsc_scaling_ratio != kvm_default_tsc_scaling_ratio
+	 *              && delta_tsc && u64_shl_div_u64(delta_tsc, kvm_tsc_scaling_ratio_frac_bits, vcpu->arch.l1_tsc_scaling_ratio, &delta_tsc))
+	 *   - arch/x86/kvm/vmx/vmx.c|8789| <<hardware_setup>> kvm_tsc_scaling_ratio_frac_bits = 48;
+	 *   - arch/x86/kvm/x86.c|2561| <<set_tsc_khz>> ratio = mul_u64_u32_div(1ULL << kvm_tsc_scaling_ratio_frac_bits, user_tsc_khz, tsc_khz);
+	 *   - arch/x86/kvm/x86.c|2702| <<__scale_tsc>> return mul_u64_u64_shr(tsc, ratio, kvm_tsc_scaling_ratio_frac_bits);
+	 *   - arch/x86/kvm/x86.c|2740| <<kvm_calc_nested_tsc_offset>> nested_offset = mul_s64_u64_shr((s64) l1_offset,
+	 *              l2_multiplier, kvm_tsc_scaling_ratio_frac_bits);
+	 *   - arch/x86/kvm/x86.c|2751| <<kvm_calc_nested_tsc_multiplier>> return mul_u64_u64_shr(l1_multiplier, l2_multiplier,
+	 *              kvm_tsc_scaling_ratio_frac_bits);
+	 *   - arch/x86/kvm/x86.c|13707| <<kvm_arch_hardware_setup>> kvm_default_tsc_scaling_ratio = 1ULL << kvm_tsc_scaling_ratio_frac_bits;
+	 */
 	return mul_u64_u64_shr(tsc, ratio, kvm_tsc_scaling_ratio_frac_bits);
 }
 
+/*
+ * 在以下使用kvm_scale_tsc():
+ *   - arch/x86/kvm/x86.c|2941| <<kvm_compute_l1_tsc_offset>> tsc = kvm_scale_tsc(vcpu, rdtsc(), vcpu->arch.l1_tsc_scaling_ratio);
+ *   - arch/x86/kvm/x86.c|2964| <<kvm_read_l1_tsc>> kvm_scale_tsc(vcpu, host_tsc, vcpu->arch.l1_tsc_scaling_ratio);
+ *   - arch/x86/kvm/x86.c|3269| <<adjust_tsc_offset_host>> adjustment = kvm_scale_tsc(vcpu, (u64) adjustment, vcpu->arch.l1_tsc_scaling_ratio);
+ *   - arch/x86/kvm/x86.c|3979| <<kvm_guest_time_update>> tgt_tsc_khz = kvm_scale_tsc(v, tgt_tsc_khz, v->arch.l1_tsc_scaling_ratio);
+ *   - arch/x86/kvm/x86.c|4914| <<kvm_get_msr_common(MSR_IA32_TSC)>> msr_info->data = kvm_scale_tsc(vcpu, rdtsc(), ratio) + offset;
+ */
 u64 kvm_scale_tsc(struct kvm_vcpu *vcpu, u64 tsc, u64 ratio)
 {
 	u64 _tsc = tsc;
@@ -2441,17 +3023,71 @@ u64 kvm_scale_tsc(struct kvm_vcpu *vcpu, u64 tsc, u64 ratio)
 }
 EXPORT_SYMBOL_GPL(kvm_scale_tsc);
 
+/*
+ * 在以下使用kvm_compute_l1_tsc_offset():
+ *   - arch/x86/kvm/x86.c|3071| <<kvm_synchronize_tsc>> offset = kvm_compute_l1_tsc_offset(vcpu, data);
+ *   - arch/x86/kvm/x86.c|3140| <<kvm_synchronize_tsc>> offset = kvm_compute_l1_tsc_offset(vcpu, data);
+ *   - arch/x86/kvm/x86.c|4512| <<kvm_set_msr_common(MSR_IA32_TSC不是host)>> u64 adj = kvm_compute_l1_tsc_offset(vcpu, data) - vcpu->arch.l1_tsc_offset;
+ *   - arch/x86/kvm/x86.c|5556| <<kvm_arch_vcpu_load(tsc unstable)>> u64 offset = kvm_compute_l1_tsc_offset(vcpu, vcpu->arch.last_guest_tsc);
+ */
 static u64 kvm_compute_l1_tsc_offset(struct kvm_vcpu *vcpu, u64 target_tsc)
 {
 	u64 tsc;
 
+	/*
+	 * 在以下使用kvm_scale_tsc():
+	 *   - arch/x86/kvm/x86.c|2941| <<kvm_compute_l1_tsc_offset>> tsc = kvm_scale_tsc(vcpu, rdtsc(), vcpu->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|2964| <<kvm_read_l1_tsc>> kvm_scale_tsc(vcpu, host_tsc, vcpu->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|3269| <<adjust_tsc_offset_host>> adjustment = kvm_scale_tsc(vcpu, (u64) adjustment, vcpu->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|3979| <<kvm_guest_time_update>> tgt_tsc_khz = kvm_scale_tsc(v, tgt_tsc_khz, v->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|4914| <<kvm_get_msr_common(MSR_IA32_TSC)>> msr_info->data = kvm_scale_tsc(vcpu, rdtsc(), ratio) + offset;
+	 */
 	tsc = kvm_scale_tsc(vcpu, rdtsc(), vcpu->arch.l1_tsc_scaling_ratio);
 
 	return target_tsc - tsc;
 }
 
+/*
+ * 在以下使用kvm_read_l1_tsc():
+ *   - arch/x86/kvm/hyperv.c|591| <<get_time_ref_counter>> tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+ *   - arch/x86/kvm/lapic.c|2899| <<__kvm_wait_lapic_expire>> guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+ *   - arch/x86/kvm/lapic.c|2917| <<__kvm_wait_lapic_expire>> guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+ *   - arch/x86/kvm/lapic.c|3027| <<start_sw_tscdeadline>> guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+ *   - arch/x86/kvm/lapic.c|3141| <<set_target_expiration>> apic->lapic_timer.tscdeadline = kvm_read_l1_tsc(apic->vcpu, tscl) +
+ *   - arch/x86/kvm/lapic.c|3180| <<advance_periodic_target_expiration>> apic->lapic_timer.tscdeadline = kvm_read_l1_tsc(apic->vcpu, tscl) +
+ *   - arch/x86/kvm/vmx/nested.c|980| <<nested_vmx_get_vmexit_msr_value>> *data = kvm_read_l1_tsc(vcpu, val);
+ *   - arch/x86/kvm/vmx/nested.c|2086| <<vmx_calc_preemption_timer_value>> u64 l1_scaled_tsc = kvm_read_l1_tsc(vcpu, rdtsc()) >>
+ *   - arch/x86/kvm/vmx/vmx.c|8345| <<vmx_set_hv_timer>> guest_tscl = kvm_read_l1_tsc(vcpu, tscl);
+ *   - arch/x86/kvm/x86.c|3885| <<kvm_guest_time_update>> tsc_timestamp = kvm_read_l1_tsc(v, host_tsc);
+ *   - arch/x86/kvm/x86.c|10375| <<kvm_pv_clock_pairing>> clock_pairing.tsc = kvm_read_l1_tsc(vcpu, cycle);
+ *   - arch/x86/kvm/x86.c|12309| <<vcpu_enter_guest>> vcpu->arch.last_guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+ */
 u64 kvm_read_l1_tsc(struct kvm_vcpu *vcpu, u64 host_tsc)
 {
+	/*
+	 * 在以下使用kvm_vcpu_arch->l1_tsc_offset:
+	 *   - arch/x86/kvm/svm/nested.c|619| <<nested_vmcb02_prepare_control>> vcpu->arch.l1_tsc_offset + svm->nested.ctl.tsc_offset;
+	 *   - arch/x86/kvm/svm/nested.c|972| <<nested_svm_vmexit>> svm->vcpu.arch.tsc_offset = svm->vcpu.arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/svm/svm.c|1290| <<svm_write_tsc_offset>> svm->vmcb01.ptr->control.tsc_offset = vcpu->arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/vmx/nested.c|2602| <<prepare_vmcs02>> vcpu->arch.tsc_offset = kvm_calc_nested_tsc_offset(vcpu->arch.l1_tsc_offset,
+	 *          vmx_get_l2_tsc_offset(vcpu), vmx_get_l2_tsc_multiplier(vcpu));
+	 *   - arch/x86/kvm/vmx/nested.c|4648| <<nested_vmx_vmexit>> vcpu->arch.tsc_offset = vcpu->arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/x86.c|3066| <<kvm_read_l1_tsc>> return vcpu->arch.l1_tsc_offset + kvm_scale_tsc(vcpu, host_tsc,
+	 *          vcpu->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|3105| <<kvm_vcpu_write_tsc_offset>> trace_kvm_write_tsc_offset( ... vcpu->arch.l1_tsc_offset,
+	 *   - arch/x86/kvm/x86.c|3108| <<kvm_vcpu_write_tsc_offset>> vcpu->arch.l1_tsc_offset = l1_offset;
+	 *   - arch/x86/kvm/x86.c|3373| <<adjust_tsc_offset_guest>> u64 tsc_offset = vcpu->arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/x86.c|4746| <<kvm_set_msr_common(MSR_IA32_TSC)>> u64 adj = kvm_compute_l1_tsc_offset(vcpu, data) - vcpu->arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/x86.c|5090| <<kvm_get_msr_common(MSR_IA32_TSC)>> offset = vcpu->arch.l1_tsc_offset;
+	 *
+	 *
+	 * 在以下使用kvm_scale_tsc():
+	 *   - arch/x86/kvm/x86.c|2941| <<kvm_compute_l1_tsc_offset>> tsc = kvm_scale_tsc(vcpu, rdtsc(), vcpu->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|2964| <<kvm_read_l1_tsc>> kvm_scale_tsc(vcpu, host_tsc, vcpu->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|3269| <<adjust_tsc_offset_host>> adjustment = kvm_scale_tsc(vcpu, (u64) adjustment, vcpu->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|3979| <<kvm_guest_time_update>> tgt_tsc_khz = kvm_scale_tsc(v, tgt_tsc_khz, v->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|4914| <<kvm_get_msr_common(MSR_IA32_TSC)>> msr_info->data = kvm_scale_tsc(vcpu, rdtsc(), ratio) + offset;
+	 */
 	return vcpu->arch.l1_tsc_offset +
 		kvm_scale_tsc(vcpu, host_tsc, vcpu->arch.l1_tsc_scaling_ratio);
 }
@@ -2482,12 +3118,34 @@ u64 kvm_calc_nested_tsc_multiplier(u64 l1_multiplier, u64 l2_multiplier)
 }
 EXPORT_SYMBOL_GPL(kvm_calc_nested_tsc_multiplier);
 
+/*
+ * 在以下使用kvm_vcpu_write_tsc_offset():
+ *   - arch/x86/kvm/x86.c|2831| <<kvm_synchronize_tsc>> kvm_vcpu_write_tsc_offset(vcpu, offset);
+ *   - arch/x86/kvm/x86.c|2849| <<adjust_tsc_offset_guest>> kvm_vcpu_write_tsc_offset(vcpu, tsc_offset + adjustment);
+ *   - arch/x86/kvm/x86.c|4763| <<kvm_arch_vcpu_load>> kvm_vcpu_write_tsc_offset(vcpu, offset);
+ */
 static void kvm_vcpu_write_tsc_offset(struct kvm_vcpu *vcpu, u64 l1_offset)
 {
 	trace_kvm_write_tsc_offset(vcpu->vcpu_id,
 				   vcpu->arch.l1_tsc_offset,
 				   l1_offset);
 
+	/*
+	 * 在以下使用kvm_vcpu_arch->l1_tsc_offset:
+	 *   - arch/x86/kvm/svm/nested.c|619| <<nested_vmcb02_prepare_control>> vcpu->arch.l1_tsc_offset + svm->nested.ctl.tsc_offset;
+	 *   - arch/x86/kvm/svm/nested.c|972| <<nested_svm_vmexit>> svm->vcpu.arch.tsc_offset = svm->vcpu.arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/svm/svm.c|1290| <<svm_write_tsc_offset>> svm->vmcb01.ptr->control.tsc_offset = vcpu->arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/vmx/nested.c|2602| <<prepare_vmcs02>> vcpu->arch.tsc_offset = kvm_calc_nested_tsc_offset(vcpu->arch.l1_tsc_offset,
+	 *          vmx_get_l2_tsc_offset(vcpu), vmx_get_l2_tsc_multiplier(vcpu));
+	 *   - arch/x86/kvm/vmx/nested.c|4648| <<nested_vmx_vmexit>> vcpu->arch.tsc_offset = vcpu->arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/x86.c|3066| <<kvm_read_l1_tsc>> return vcpu->arch.l1_tsc_offset + kvm_scale_tsc(vcpu, host_tsc,
+	 *          vcpu->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|3105| <<kvm_vcpu_write_tsc_offset>> trace_kvm_write_tsc_offset( ... vcpu->arch.l1_tsc_offset,
+	 *   - arch/x86/kvm/x86.c|3108| <<kvm_vcpu_write_tsc_offset>> vcpu->arch.l1_tsc_offset = l1_offset;
+	 *   - arch/x86/kvm/x86.c|3373| <<adjust_tsc_offset_guest>> u64 tsc_offset = vcpu->arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/x86.c|4746| <<kvm_set_msr_common(MSR_IA32_TSC)>> u64 adj = kvm_compute_l1_tsc_offset(vcpu, data) - vcpu->arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/x86.c|5090| <<kvm_get_msr_common(MSR_IA32_TSC)>> offset = vcpu->arch.l1_tsc_offset;
+	 */
 	vcpu->arch.l1_tsc_offset = l1_offset;
 
 	/*
@@ -2503,9 +3161,19 @@ static void kvm_vcpu_write_tsc_offset(struct kvm_vcpu *vcpu, u64 l1_offset)
 	else
 		vcpu->arch.tsc_offset = l1_offset;
 
+	/*
+	 * vmx_write_tsc_offset()
+	 * svm_write_tsc_offset()
+	 */
 	static_call(kvm_x86_write_tsc_offset)(vcpu, vcpu->arch.tsc_offset);
 }
 
+/*
+ * 在以下使用kvm_vcpu_write_tsc_multiplier():
+ *   - arch/x86/kvm/x86.c|2544| <<set_tsc_khz>> kvm_vcpu_write_tsc_multiplier(vcpu, kvm_default_tsc_scaling_ratio);
+ *   - arch/x86/kvm/x86.c|2570| <<set_tsc_khz>> kvm_vcpu_write_tsc_multiplier(vcpu, ratio);
+ *   - arch/x86/kvm/x86.c|2587| <<kvm_set_tsc_khz>> kvm_vcpu_write_tsc_multiplier(vcpu, kvm_default_tsc_scaling_ratio);
+ */
 static void kvm_vcpu_write_tsc_multiplier(struct kvm_vcpu *vcpu, u64 l1_multiplier)
 {
 	vcpu->arch.l1_tsc_scaling_ratio = l1_multiplier;
@@ -2518,11 +3186,34 @@ static void kvm_vcpu_write_tsc_multiplier(struct kvm_vcpu *vcpu, u64 l1_multipli
 	else
 		vcpu->arch.tsc_scaling_ratio = l1_multiplier;
 
+	/*
+	 * 在以下设置kvm_has_tsc_control:
+	 *   - arch/x86/kvm/svm/svm.c|1115| <<svm_hardware_setup>> kvm_has_tsc_control = true;
+	 *   - arch/x86/kvm/vmx/vmx.c|8787| <<hardware_setup>> kvm_has_tsc_control = true;
+	 * 在以下使用kvm_has_tsc_control:
+	 *   - arch/x86/kvm/debugfs.c|69| <<kvm_arch_create_vcpu_debugfs>> if (kvm_has_tsc_control) {
+	 *   - arch/x86/kvm/vmx/nested.c|2581| <<prepare_vmcs02>> if (kvm_has_tsc_control)
+	 *   - arch/x86/kvm/vmx/nested.c|4680| <<nested_vmx_vmexit>> if (kvm_has_tsc_control)
+	 *   - arch/x86/kvm/x86.c|2579| <<set_tsc_khz>> if (!kvm_has_tsc_control) {
+	 *   - arch/x86/kvm/x86.c|2843| <<kvm_vcpu_write_tsc_multiplier>> if (kvm_has_tsc_control)
+	 *   - arch/x86/kvm/x86.c|3607| <<kvm_guest_time_update>> if (kvm_has_tsc_control)
+	 *   - arch/x86/kvm/x86.c|4951| <<kvm_vm_ioctl_check_extension>> r = kvm_has_tsc_control;
+	 *   - arch/x86/kvm/x86.c|6207| <<kvm_arch_vcpu_ioctl(KVM_SET_TSC_KHZ)>> if (kvm_has_tsc_control &
+	 *   - arch/x86/kvm/x86.c|13736| <<kvm_arch_hardware_setup>> if (kvm_has_tsc_control) {
+	 */
 	if (kvm_has_tsc_control)
 		static_call(kvm_x86_write_tsc_multiplier)(
 			vcpu, vcpu->arch.tsc_scaling_ratio);
 }
 
+/*
+ * 在以下使用kvm_check_tsc_unstable():
+ *   - arch/x86/kvm/x86.c|3236| <<kvm_synchronize_tsc>> if (!kvm_check_tsc_unstable()) {
+ *   - arch/x86/kvm/x86.c|5684| <<kvm_arch_vcpu_load>> if (unlikely(vcpu->cpu != cpu) || kvm_check_tsc_unstable()) {
+ *   - arch/x86/kvm/x86.c|5700| <<kvm_arch_vcpu_load>> if (kvm_check_tsc_unstable()) {
+ *   - arch/x86/kvm/x86.c|13780| <<kvm_arch_vcpu_precreate>> if (kvm_check_tsc_unstable() && atomic_read(&kvm->online_vcpus) != 0)
+ *   - arch/x86/kvm/x86.c|14215| <<kvm_arch_hardware_enable>> stable = !kvm_check_tsc_unstable();
+ */
 static inline bool kvm_check_tsc_unstable(void)
 {
 #ifdef CONFIG_X86_64
@@ -2536,6 +3227,11 @@ static inline bool kvm_check_tsc_unstable(void)
 	return check_tsc_unstable();
 }
 
+/*
+ * 在以下使用kvm_synchronize_tsc():
+ *   - arch/x86/kvm/x86.c|3718| <<kvm_set_msr_common(MSR_IA32_TSC)>> kvm_synchronize_tsc(vcpu, data);
+ *   - arch/x86/kvm/x86.c|12688| <<kvm_arch_vcpu_postcreate>> kvm_synchronize_tsc(vcpu, 0);
+ */
 static void kvm_synchronize_tsc(struct kvm_vcpu *vcpu, u64 data)
 {
 	struct kvm *kvm = vcpu->kvm;
@@ -2546,8 +3242,21 @@ static void kvm_synchronize_tsc(struct kvm_vcpu *vcpu, u64 data)
 	bool synchronizing = false;
 
 	raw_spin_lock_irqsave(&kvm->arch.tsc_write_lock, flags);
+	/*
+	 * 在以下使用kvm_compute_l1_tsc_offset():
+	 *   - arch/x86/kvm/x86.c|3071| <<kvm_synchronize_tsc>> offset = kvm_compute_l1_tsc_offset(vcpu, data);
+	 *   - arch/x86/kvm/x86.c|3140| <<kvm_synchronize_tsc>> offset = kvm_compute_l1_tsc_offset(vcpu, data);
+	 *   - arch/x86/kvm/x86.c|4512| <<kvm_set_msr_common(MSR_IA32_TSC不是host)>> u64 adj = kvm_compute_l1_tsc_offset(vcpu, data) - vcpu->arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/x86.c|5556| <<kvm_arch_vcpu_load(tsc unstable)>> u64 offset = kvm_compute_l1_tsc_offset(vcpu, vcpu->arch.last_guest_tsc);
+	 */
 	offset = kvm_compute_l1_tsc_offset(vcpu, data);
 	ns = get_kvmclock_base_ns();
+	/*
+	 * 在以下使用kvm_arch->last_tsc_nsec:
+	 *   - arch/x86/kvm/x86.c|3254| <<kvm_synchronize_tsc>> elapsed = ns - kvm->arch.last_tsc_nsec;
+	 *   - arch/x86/kvm/x86.c|3353| <<kvm_synchronize_tsc>> kvm->arch.last_tsc_nsec = ns;
+	 *   - arch/x86/kvm/x86.c|14529| <<kvm_arch_hardware_enable>> kvm->arch.last_tsc_nsec = 0;
+	 */
 	elapsed = ns - kvm->arch.last_tsc_nsec;
 
 	if (vcpu->arch.virtual_tsc_khz) {
@@ -2559,6 +3268,28 @@ static void kvm_synchronize_tsc(struct kvm_vcpu *vcpu, u64 data)
 			 */
 			synchronizing = true;
 		} else {
+			/*
+			 * 在以下使用nsec_to_cycles():
+			 *   - arch/x86/kvm/lapic.c|2840| <<__wait_lapic_expire>> __delay(min(guest_cycles,
+			 *          nsec_to_cycles(vcpu, timer_advance_ns)));
+			 *   - arch/x86/kvm/lapic.c|3052| <<update_target_expiration>> nsec_to_cycles(apic->vcpu, ns_remaining_new) -
+			 *                                                             nsec_to_cycles(apic->vcpu, ns_remaining_old);
+			 *   - arch/x86/kvm/lapic.c|3053| <<update_target_expiration>> nsec_to_cycles(apic->vcpu, ns_remaining_new) -
+			 *                                                             nsec_to_cycles(apic->vcpu, ns_remaining_old);
+			 *   - arch/x86/kvm/lapic.c|3097| <<set_target_expiration>> nsec_to_cycles(apic->vcpu, deadline);
+			 *   - arch/x86/kvm/lapic.c|3121| <<advance_periodic_target_expiration>> nsec_to_cycles(apic->vcpu, delta);
+			 *   - arch/x86/kvm/vmx/vmx.c|8347| <<vmx_set_hv_timer>> lapic_timer_advance_cycles = nsec_to_cycles(vcpu,
+			 *          ktimer->timer_advance_ns);
+			 *   - arch/x86/kvm/x86.c|3042| <<kvm_synchronize_tsc>> nsec_to_cycles(vcpu, elapsed);
+			 *   - arch/x86/kvm/x86.c|3065| <<kvm_synchronize_tsc>> u64 delta = nsec_to_cycles(vcpu, elapsed);
+			 *
+			 *
+			 * 在以下使用kvm_arch->last_tsc_write:
+			 *   - arch/x86/kvm/x86.c|3280| <<kvm_synchronize_tsc>> u64 tsc_exp = kvm->arch.last_tsc_write +
+			 *                                                              nsec_to_cycles(vcpu, elapsed);
+			 *   - arch/x86/kvm/x86.c|3354| <<kvm_synchronize_tsc>> kvm->arch.last_tsc_write = data;
+			 *   - arch/x86/kvm/x86.c|14530| <<kvm_arch_hardware_enable>> kvm->arch.last_tsc_write = 0;
+			 */
 			u64 tsc_exp = kvm->arch.last_tsc_write +
 						nsec_to_cycles(vcpu, elapsed);
 			u64 tsc_hz = vcpu->arch.virtual_tsc_khz * 1000LL;
@@ -2583,8 +3314,30 @@ static void kvm_synchronize_tsc(struct kvm_vcpu *vcpu, u64 data)
 		if (!kvm_check_tsc_unstable()) {
 			offset = kvm->arch.cur_tsc_offset;
 		} else {
+			/*
+			 * 在以下使用nsec_to_cycles():
+			 *   - arch/x86/kvm/lapic.c|2840| <<__wait_lapic_expire>> __delay(min(guest_cycles,
+			 *          nsec_to_cycles(vcpu, timer_advance_ns)));
+			 *   - arch/x86/kvm/lapic.c|3052| <<update_target_expiration>> nsec_to_cycles(apic->vcpu, ns_remaining_new) -
+			 *                                                             nsec_to_cycles(apic->vcpu, ns_remaining_old);
+			 *   - arch/x86/kvm/lapic.c|3053| <<update_target_expiration>> nsec_to_cycles(apic->vcpu, ns_remaining_new) -
+			 *                                                             nsec_to_cycles(apic->vcpu, ns_remaining_old);
+			 *   - arch/x86/kvm/lapic.c|3097| <<set_target_expiration>> nsec_to_cycles(apic->vcpu, deadline);
+			 *   - arch/x86/kvm/lapic.c|3121| <<advance_periodic_target_expiration>> nsec_to_cycles(apic->vcpu, delta);
+			 *   - arch/x86/kvm/vmx/vmx.c|8347| <<vmx_set_hv_timer>> lapic_timer_advance_cycles = nsec_to_cycles(vcpu,
+			 *          ktimer->timer_advance_ns);
+			 *   - arch/x86/kvm/x86.c|3042| <<kvm_synchronize_tsc>> nsec_to_cycles(vcpu, elapsed);
+			 *   - arch/x86/kvm/x86.c|3065| <<kvm_synchronize_tsc>> u64 delta = nsec_to_cycles(vcpu, elapsed);
+			 */
 			u64 delta = nsec_to_cycles(vcpu, elapsed);
 			data += delta;
+			/*
+			 * 在以下使用kvm_compute_l1_tsc_offset():
+			 *   - arch/x86/kvm/x86.c|3071| <<kvm_synchronize_tsc>> offset = kvm_compute_l1_tsc_offset(vcpu, data);
+			 *   - arch/x86/kvm/x86.c|3140| <<kvm_synchronize_tsc>> offset = kvm_compute_l1_tsc_offset(vcpu, data);
+			 *   - arch/x86/kvm/x86.c|4512| <<kvm_set_msr_common(MSR_IA32_TSC不是host)>> u64 adj = kvm_compute_l1_tsc_offset(vcpu, data) - vcpu->arch.l1_tsc_offset;
+			 *   - arch/x86/kvm/x86.c|5556| <<kvm_arch_vcpu_load(tsc unstable)>> u64 offset = kvm_compute_l1_tsc_offset(vcpu, vcpu->arch.last_guest_tsc);
+			 */
 			offset = kvm_compute_l1_tsc_offset(vcpu, data);
 		}
 		matched = true;
@@ -2610,7 +3363,20 @@ static void kvm_synchronize_tsc(struct kvm_vcpu *vcpu, u64 data)
 	 * We also track th most recent recorded KHZ, write and time to
 	 * allow the matching interval to be extended at each write.
 	 */
+	/*
+	 * 在以下使用kvm_arch->last_tsc_nsec:
+	 *   - arch/x86/kvm/x86.c|3254| <<kvm_synchronize_tsc>> elapsed = ns - kvm->arch.last_tsc_nsec;
+	 *   - arch/x86/kvm/x86.c|3353| <<kvm_synchronize_tsc>> kvm->arch.last_tsc_nsec = ns;
+	 *   - arch/x86/kvm/x86.c|14529| <<kvm_arch_hardware_enable>> kvm->arch.last_tsc_nsec = 0;
+	 */
 	kvm->arch.last_tsc_nsec = ns;
+	/*
+	 * 在以下使用kvm_arch->last_tsc_write:
+	 *   - arch/x86/kvm/x86.c|3280| <<kvm_synchronize_tsc>> u64 tsc_exp = kvm->arch.last_tsc_write +
+	 *                                                              nsec_to_cycles(vcpu, elapsed);
+	 *   - arch/x86/kvm/x86.c|3354| <<kvm_synchronize_tsc>> kvm->arch.last_tsc_write = data;
+	 *   - arch/x86/kvm/x86.c|14530| <<kvm_arch_hardware_enable>> kvm->arch.last_tsc_write = 0;
+	 */
 	kvm->arch.last_tsc_write = data;
 	kvm->arch.last_tsc_khz = vcpu->arch.virtual_tsc_khz;
 
@@ -2621,38 +3387,116 @@ static void kvm_synchronize_tsc(struct kvm_vcpu *vcpu, u64 data)
 	vcpu->arch.this_tsc_nsec = kvm->arch.cur_tsc_nsec;
 	vcpu->arch.this_tsc_write = kvm->arch.cur_tsc_write;
 
+	/*
+	 * 在以下使用kvm_vcpu_write_tsc_offset():
+	 *   - arch/x86/kvm/x86.c|2831| <<kvm_synchronize_tsc>> kvm_vcpu_write_tsc_offset(vcpu, offset);
+	 *   - arch/x86/kvm/x86.c|2849| <<adjust_tsc_offset_guest>> kvm_vcpu_write_tsc_offset(vcpu, tsc_offset + adjustment);
+	 *   - arch/x86/kvm/x86.c|4763| <<kvm_arch_vcpu_load>> kvm_vcpu_write_tsc_offset(vcpu, offset);
+	 */
 	kvm_vcpu_write_tsc_offset(vcpu, offset);
 	raw_spin_unlock_irqrestore(&kvm->arch.tsc_write_lock, flags);
 
+	/*
+	 * 使用kvm_arch->pvclock_gtod_sync_lock的函数:
+	 *   - kvm_synchronize_tsc()
+	 *   - kvm_gen_update_masterclock()
+	 *   - get_kvmclock_ns()
+	 *   - kvm_guest_time_update()
+	 *   - kvm_arch_vm_ioctl(KVM_SET_CLOCK)
+	 *   - kvm_hyperv_tsc_notifier()
+	 *   - kvm_arch_init_vm()
+	 */
 	raw_spin_lock_irqsave(&kvm->arch.pvclock_gtod_sync_lock, flags);
 	if (!matched) {
+		/*
+		 * 在以下使用kvm_arch->nr_vcpus_matched_tsc:*   - arch/x86/kvm/x86.c|2850| <<kvm_track_tsc_matching>> bool use_master_clock = (ka->nr_vcpus_matched_tsc + 1 ==
+		 *   - arch/x86/kvm/x86.c|2876| <<kvm_track_tsc_matching>> trace_kvm_track_tsc(vcpu->vcpu_id, ka->nr_vcpus_matched_tsc,
+		 *   - arch/x86/kvm/x86.c|3190| <<kvm_synchronize_tsc>> kvm->arch.nr_vcpus_matched_tsc = 0;
+		 *   - arch/x86/kvm/x86.c|3192| <<kvm_synchronize_tsc>> kvm->arch.nr_vcpus_matched_tsc++;
+		 *   - arch/x86/kvm/x86.c|3399| <<pvclock_update_vm_gtod_copy>> vcpus_matched = (ka->nr_vcpus_matched_tsc + 1 ==
+		 */
 		kvm->arch.nr_vcpus_matched_tsc = 0;
 	} else if (!already_matched) {
 		kvm->arch.nr_vcpus_matched_tsc++;
 	}
 
+	/*
+	 * 只在这里调用
+	 */
 	kvm_track_tsc_matching(vcpu, !matched);
 	raw_spin_unlock_irqrestore(&kvm->arch.pvclock_gtod_sync_lock, flags);
 }
 
+/*
+ * 在以下使用adjust_tsc_offset_guest():
+ *   - arch/x86/kvm/x86.c|3358| <<adjust_tsc_offset_host>> adjust_tsc_offset_guest(vcpu, adjustment);
+ *   - arch/x86/kvm/x86.c|4041| <<kvm_guest_time_update>> adjust_tsc_offset_guest(v, tsc - tsc_timestamp);
+ *   - arch/x86/kvm/x86.c|4618| <<kvm_set_msr_common(MSR_IA32_TSC_ADJUST)>> adjust_tsc_offset_guest(vcpu, adj);
+ *   - arch/x86/kvm/x86.c|4658| <<kvm_set_msr_common(MSR_IA32_TSC)>> adjust_tsc_offset_guest(vcpu, adj);
+ */
 static inline void adjust_tsc_offset_guest(struct kvm_vcpu *vcpu,
 					   s64 adjustment)
 {
+	/*
+	 * 在以下使用kvm_vcpu_arch->l1_tsc_offset:
+	 *   - arch/x86/kvm/svm/nested.c|619| <<nested_vmcb02_prepare_control>> vcpu->arch.l1_tsc_offset + svm->nested.ctl.tsc_offset;
+	 *   - arch/x86/kvm/svm/nested.c|972| <<nested_svm_vmexit>> svm->vcpu.arch.tsc_offset = svm->vcpu.arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/svm/svm.c|1290| <<svm_write_tsc_offset>> svm->vmcb01.ptr->control.tsc_offset = vcpu->arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/vmx/nested.c|2602| <<prepare_vmcs02>> vcpu->arch.tsc_offset = kvm_calc_nested_tsc_offset(vcpu->arch.l1_tsc_offset,
+	 *          vmx_get_l2_tsc_offset(vcpu), vmx_get_l2_tsc_multiplier(vcpu));
+	 *   - arch/x86/kvm/vmx/nested.c|4648| <<nested_vmx_vmexit>> vcpu->arch.tsc_offset = vcpu->arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/x86.c|3066| <<kvm_read_l1_tsc>> return vcpu->arch.l1_tsc_offset + kvm_scale_tsc(vcpu, host_tsc,
+	 *          vcpu->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|3105| <<kvm_vcpu_write_tsc_offset>> trace_kvm_write_tsc_offset( ... vcpu->arch.l1_tsc_offset,
+	 *   - arch/x86/kvm/x86.c|3108| <<kvm_vcpu_write_tsc_offset>> vcpu->arch.l1_tsc_offset = l1_offset;
+	 *   - arch/x86/kvm/x86.c|3373| <<adjust_tsc_offset_guest>> u64 tsc_offset = vcpu->arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/x86.c|4746| <<kvm_set_msr_common(MSR_IA32_TSC)>> u64 adj = kvm_compute_l1_tsc_offset(vcpu, data) - vcpu->arch.l1_tsc_offset;
+	 *   - arch/x86/kvm/x86.c|5090| <<kvm_get_msr_common(MSR_IA32_TSC)>> offset = vcpu->arch.l1_tsc_offset;
+	 */
 	u64 tsc_offset = vcpu->arch.l1_tsc_offset;
+	/*
+	 * 在以下使用kvm_vcpu_write_tsc_offset():
+	 *   - arch/x86/kvm/x86.c|2831| <<kvm_synchronize_tsc>> kvm_vcpu_write_tsc_offset(vcpu, offset);
+	 *   - arch/x86/kvm/x86.c|2849| <<adjust_tsc_offset_guest>> kvm_vcpu_write_tsc_offset(vcpu, tsc_offset + adjustment);
+	 *   - arch/x86/kvm/x86.c|4763| <<kvm_arch_vcpu_load>> kvm_vcpu_write_tsc_offset(vcpu, offset);
+	 */
 	kvm_vcpu_write_tsc_offset(vcpu, tsc_offset + adjustment);
 }
 
+/*
+ * 只在unlikely(vcpu->arch.tsc_offset_adjustment)的时候:
+ *   - arch/x86/kvm/x86.c|5676| <<kvm_arch_vcpu_load>> adjust_tsc_offset_host(vcpu, vcpu->arch.tsc_offset_adjustment);
+ */
 static inline void adjust_tsc_offset_host(struct kvm_vcpu *vcpu, s64 adjustment)
 {
 	if (vcpu->arch.l1_tsc_scaling_ratio != kvm_default_tsc_scaling_ratio)
 		WARN_ON(adjustment < 0);
+	/*
+	 * 在以下使用kvm_scale_tsc():
+	 *   - arch/x86/kvm/x86.c|2941| <<kvm_compute_l1_tsc_offset>> tsc = kvm_scale_tsc(vcpu, rdtsc(), vcpu->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|2964| <<kvm_read_l1_tsc>> kvm_scale_tsc(vcpu, host_tsc, vcpu->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|3269| <<adjust_tsc_offset_host>> adjustment = kvm_scale_tsc(vcpu, (u64) adjustment, vcpu->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|3979| <<kvm_guest_time_update>> tgt_tsc_khz = kvm_scale_tsc(v, tgt_tsc_khz, v->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|4914| <<kvm_get_msr_common(MSR_IA32_TSC)>> msr_info->data = kvm_scale_tsc(vcpu, rdtsc(), ratio) + offset;
+	 */
 	adjustment = kvm_scale_tsc(vcpu, (u64) adjustment,
 				   vcpu->arch.l1_tsc_scaling_ratio);
+	/*
+	 * 在以下使用adjust_tsc_offset_guest():
+	 *   - arch/x86/kvm/x86.c|3358| <<adjust_tsc_offset_host>> adjust_tsc_offset_guest(vcpu, adjustment);
+	 *   - arch/x86/kvm/x86.c|4041| <<kvm_guest_time_update>> adjust_tsc_offset_guest(v, tsc - tsc_timestamp);
+	 *   - arch/x86/kvm/x86.c|4618| <<kvm_set_msr_common(MSR_IA32_TSC_ADJUST)>> adjust_tsc_offset_guest(vcpu, adj);
+	 *   - arch/x86/kvm/x86.c|4658| <<kvm_set_msr_common(MSR_IA32_TSC)>> adjust_tsc_offset_guest(vcpu, adj);
+	 */
 	adjust_tsc_offset_guest(vcpu, adjustment);
 }
 
 #ifdef CONFIG_X86_64
 
+/*
+ * 在以下调用read_tsc():
+ *   - arch/x86/kvm/x86.c|3405| <<vgettsc>> *tsc_timestamp = read_tsc();
+ */
 static u64 read_tsc(void)
 {
 	u64 ret = (u64)rdtsc_ordered();
@@ -2673,6 +3517,11 @@ static u64 read_tsc(void)
 	return last;
 }
 
+/*
+ * 在以下使用vgettsc():
+ *   - arch/x86/kvm/x86.c|3429| <<do_monotonic_raw>> ns += vgettsc(&gtod->raw_clock, tsc_timestamp, &mode);
+ *   - arch/x86/kvm/x86.c|3449| <<do_realtime>> ns += vgettsc(&gtod->clock, tsc_timestamp, &mode);
+ */
 static inline u64 vgettsc(struct pvclock_clock *clock, u64 *tsc_timestamp,
 			  int *mode)
 {
@@ -2749,6 +3598,10 @@ static int do_realtime(struct timespec64 *ts, u64 *tsc_timestamp)
 	return mode;
 }
 
+/*
+ * 只在这里使用kvm_get_time_and_clockread():
+ *   - arch/x86/kvm/x86.c|3558| <<pvclock_update_vm_gtod_copy>> host_tsc_clocksource = kvm_get_time_and_clockread(
+ */
 /* returns true if host is using TSC based clocksource */
 static bool kvm_get_time_and_clockread(s64 *kernel_ns, u64 *tsc_timestamp)
 {
@@ -2760,6 +3613,10 @@ static bool kvm_get_time_and_clockread(s64 *kernel_ns, u64 *tsc_timestamp)
 						      tsc_timestamp));
 }
 
+/*
+ * 只在这里使用kvm_get_walltime_and_clockread():
+ *   - arch/x86/kvm/x86.c|10522| <<kvm_pv_clock_pairing>> if (!kvm_get_walltime_and_clockread(&ts, &cycle))
+ */
 /* returns true if host is using TSC based clocksource */
 static bool kvm_get_walltime_and_clockread(struct timespec64 *ts,
 					   u64 *tsc_timestamp)
@@ -2813,6 +3670,12 @@ static bool kvm_get_walltime_and_clockread(struct timespec64 *ts,
  *
  */
 
+/*
+ * 在以下使用pvclock_update_vm_gtod_copy():
+ *   - arch/x86/kvm/x86.c|3110| <<kvm_gen_update_masterclock>> pvclock_update_vm_gtod_copy(kvm);
+ *   - arch/x86/kvm/x86.c|8999| <<kvm_hyperv_tsc_notifier>> pvclock_update_vm_gtod_copy(kvm);
+ *   - arch/x86/kvm/x86.c|13281| <<kvm_arch_init_vm>> pvclock_update_vm_gtod_copy(kvm);
+ */
 static void pvclock_update_vm_gtod_copy(struct kvm *kvm)
 {
 #ifdef CONFIG_X86_64
@@ -2820,9 +3683,24 @@ static void pvclock_update_vm_gtod_copy(struct kvm *kvm)
 	int vclock_mode;
 	bool host_tsc_clocksource, vcpus_matched;
 
+	/*
+	 * 在以下使用kvm_arch->nr_vcpus_matched_tsc:
+	 *   - arch/x86/kvm/x86.c|2850| <<kvm_track_tsc_matching>> bool use_master_clock = (ka->nr_vcpus_matched_tsc + 1 ==
+	 *   - arch/x86/kvm/x86.c|2876| <<kvm_track_tsc_matching>> trace_kvm_track_tsc(vcpu->vcpu_id, ka->nr_vcpus_matched_tsc,
+	 *   - arch/x86/kvm/x86.c|3190| <<kvm_synchronize_tsc>> kvm->arch.nr_vcpus_matched_tsc = 0;
+	 *   - arch/x86/kvm/x86.c|3192| <<kvm_synchronize_tsc>> kvm->arch.nr_vcpus_matched_tsc++;
+	 *   - arch/x86/kvm/x86.c|3399| <<pvclock_update_vm_gtod_copy>> vcpus_matched = (ka->nr_vcpus_matched_tsc + 1 ==
+	 */
 	vcpus_matched = (ka->nr_vcpus_matched_tsc + 1 ==
 			atomic_read(&kvm->online_vcpus));
 
+	/*
+	 * 在以下使用kvm_arch->master_cycle_now:
+	 *   - arch/x86/kvm/x86.c|3071| <<pvclock_update_vm_gtod_copy>> host_tsc_clocksource =
+	 *               kvm_get_time_and_clockread(&ka->master_kernel_ns, &ka->master_cycle_now);
+	 *   - arch/x86/kvm/x86.c|3144| <<get_kvmclock_ns>> hv_clock.tsc_timestamp = ka->master_cycle_now;
+	 *   - arch/x86/kvm/x86.c|3253| <<kvm_guest_time_update>> host_tsc = ka->master_cycle_now;
+	 */
 	/*
 	 * If the host uses TSC clock, then passthrough TSC as stable
 	 * to the guest.
@@ -2831,10 +3709,32 @@ static void pvclock_update_vm_gtod_copy(struct kvm *kvm)
 					&ka->master_kernel_ns,
 					&ka->master_cycle_now);
 
+	/*
+	 * 在以下设置kvm_arch->use_master_clock:
+	 *   - arch/x86/kvm/x86.c|3073| <<pvclock_update_vm_gtod_copy>> ka->use_master_clock = host_tsc_clocksource && vcpus_matched
+	 * 在以下使用kvm_arch->use_master_clock:
+	 *   - arch/x86/kvm/x86.c|2620| <<kvm_track_tsc_matching>> if ((ka->use_master_clock && new_generation) ||
+	 *   - arch/x86/kvm/x86.c|2621| <<kvm_track_tsc_matching>> (ka->use_master_clock != use_master_clock))
+	 *   - arch/x86/kvm/x86.c|2626| <<kvm_track_tsc_matching>> ka->use_master_clock, gtod->clock.vclock_mode);
+	 *   - arch/x86/kvm/x86.c|3077| <<pvclock_update_vm_gtod_copy>> if (ka->use_master_clock)
+	 *   - arch/x86/kvm/x86.c|3081| <<pvclock_update_vm_gtod_copy>> trace_kvm_update_master_clock(ka->use_master_clock, vclock_mode,
+	 *   - arch/x86/kvm/x86.c|3130| <<get_kvmclock_ns>> if (!ka->use_master_clock) {
+	 *   - arch/x86/kvm/x86.c|3232| <<kvm_guest_time_update>> use_master_clock = ka->use_master_clock;
+	 *   - arch/x86/kvm/x86.c|4817| <<kvm_arch_vcpu_load>> if (!vcpu->kvm->arch.use_master_clock || vcpu->cpu == -1)
+	 *   - arch/x86/kvm/x86.c|6791| <<kvm_arch_vm_ioctl(KVM_SET_CLOCK)>> if (kvm->arch.use_master_clock)
+	 *   - arch/x86/kvm/x86.c|6807| <<kvm_arch_vm_ioctl(KVM_GET_CLOCK)>> user_ns.flags = kvm->arch.use_master_clock ? KVM_CLOCK_TSC_STABLE : 0;
+	 */
 	ka->use_master_clock = host_tsc_clocksource && vcpus_matched
 				&& !ka->backwards_tsc_observed
 				&& !ka->boot_vcpu_runs_old_kvmclock;
 
+	/*
+	 * 在以下使用kvm_guest_has_master_clock:
+	 *    - arch/x86/kvm/x86.c|2500| <<global>> static atomic_t kvm_guest_has_master_clock = ATOMIC_INIT(0);
+	 *    - arch/x86/kvm/x86.c|3144| <<pvclock_update_vm_gtod_copy>> atomic_set(&kvm_guest_has_master_clock, 1);
+	 *    - arch/x86/kvm/x86.c|9560| <<pvclock_gtod_update_fn>> atomic_set(&kvm_guest_has_master_clock, 0);
+	 *    - arch/x86/kvm/x86.c|9595| <<pvclock_gtod_notify>> atomic_read(&kvm_guest_has_master_clock) != 0)
+	 */
 	if (ka->use_master_clock)
 		atomic_set(&kvm_guest_has_master_clock, 1);
 
@@ -2844,11 +3744,33 @@ static void pvclock_update_vm_gtod_copy(struct kvm *kvm)
 #endif
 }
 
+/*
+ * 在以下使用kvm_make_mclock_inprogress_request():
+ *   - arch/x86/kvm/x86.c|3159| <<kvm_gen_update_masterclock>> kvm_make_mclock_inprogress_request(kvm);
+ *   - arch/x86/kvm/x86.c|9277| <<kvm_hyperv_tsc_notifier>> kvm_make_mclock_inprogress_request(kvm);
+ */
 void kvm_make_mclock_inprogress_request(struct kvm *kvm)
 {
 	kvm_make_all_cpus_request(kvm, KVM_REQ_MCLOCK_INPROGRESS);
 }
 
+/*
+ * 在以下使用KVM_REQ_MASTERCLOCK_UPDATE():
+ *   - arch/x86/kvm/hyperv.c|1411| <<kvm_hv_set_msr_pw>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|2444| <<kvm_write_system_time>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|2647| <<kvm_track_tsc_matching>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|9496| <<pvclock_gtod_update_fn>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|11224| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu))
+ *   - arch/x86/kvm/x86.c|13427| <<kvm_arch_hardware_enable>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/xen.c|58| <<kvm_xen_shared_info_init>> kvm_make_all_cpus_request(kvm, KVM_REQ_MASTERCLOCK_UPDATE);
+ *
+ * 处理KVM_REQ_MASTERCLOCK_UPDATE的函数: kvm_gen_update_masterclock()
+ *
+ *
+ * 在以下使用kvm_gen_update_masterclock():
+ *   - arch/x86/kvm/x86.c|6771| <<kvm_arch_vm_ioctl(KVM_SET_CLOCK)>> kvm_gen_update_masterclock(kvm);
+ *   - arch/x86/kvm/x86.c|10880| <<vcpu_enter_guest(KVM_REQ_MASTERCLOCK_UPDATE)>> kvm_gen_update_masterclock(vcpu->kvm);
+ */
 static void kvm_gen_update_masterclock(struct kvm *kvm)
 {
 #ifdef CONFIG_X86_64
@@ -2859,13 +3781,55 @@ static void kvm_gen_update_masterclock(struct kvm *kvm)
 
 	kvm_hv_invalidate_tsc_page(kvm);
 
+	/*
+	 * 在以下使用kvm_make_mclock_inprogress_request():
+	 *   - arch/x86/kvm/x86.c|3159| <<kvm_gen_update_masterclock>> kvm_make_mclock_inprogress_request(kvm);
+	 *   - arch/x86/kvm/x86.c|9277| <<kvm_hyperv_tsc_notifier>> kvm_make_mclock_inprogress_request(kvm);
+	 */
 	kvm_make_mclock_inprogress_request(kvm);
 
+	/*
+	 * 使用kvm_arch->pvclock_gtod_sync_lock的函数:
+	 *   - kvm_synchronize_tsc()
+	 *   - kvm_gen_update_masterclock()
+	 *   - get_kvmclock_ns()
+	 *   - kvm_guest_time_update()
+	 *   - kvm_arch_vm_ioctl(KVM_SET_CLOCK)
+	 *   - kvm_hyperv_tsc_notifier()
+	 *   - kvm_arch_init_vm()
+	 */
 	/* no guest entries from this point */
 	raw_spin_lock_irqsave(&ka->pvclock_gtod_sync_lock, flags);
+	/*
+	 * 在以下使用pvclock_update_vm_gtod_copy():
+	 *   - arch/x86/kvm/x86.c|3110| <<kvm_gen_update_masterclock>> pvclock_update_vm_gtod_copy(kvm);
+	 *   - arch/x86/kvm/x86.c|8999| <<kvm_hyperv_tsc_notifier>> pvclock_update_vm_gtod_copy(kvm);
+	 *   - arch/x86/kvm/x86.c|13281| <<kvm_arch_init_vm>> pvclock_update_vm_gtod_copy(kvm);
+	 */
 	pvclock_update_vm_gtod_copy(kvm);
 	raw_spin_unlock_irqrestore(&ka->pvclock_gtod_sync_lock, flags);
 
+	/*
+	 * 在以下使用KVM_REQ_CLOCK_UPDATE:
+	 *   - arch/x86/kvm/x86.c|3167| <<kvm_gen_update_masterclock>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+	 *   - arch/x86/kvm/x86.c|3395| <<kvm_guest_time_update>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, v);
+	 *   - arch/x86/kvm/x86.c|3498| <<kvmclock_update_fn>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+	 *   - arch/x86/kvm/x86.c|3507| <<kvm_gen_kvmclock_update>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, v);
+	 *   - arch/x86/kvm/x86.c|3901| <<kvm_set_msr_common(MSR_IA32_TSC_ADJUST)>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+	 *   - arch/x86/kvm/x86.c|4950| <<kvm_arch_vcpu_load>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+	 *   - arch/x86/kvm/x86.c|5618| <<kvm_set_guest_paused>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+	 *   - arch/x86/kvm/x86.c|7018| <<kvm_arch_vm_ioctl>> kvm_make_all_cpus_request(kvm, KVM_REQ_CLOCK_UPDATE);
+	 *   - arch/x86/kvm/x86.c|9225| <<kvm_hyperv_tsc_notifier>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+	 *   - arch/x86/kvm/x86.c|9286| <<__kvmclock_cpufreq_notifier>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+	 *   - arch/x86/kvm/x86.c|11150| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_CLOCK_UPDATE, vcpu)) {
+	 *   - arch/x86/kvm/x86.c|11643| <<vcpu_enter_guest>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+	 *   - arch/x86/kvm/x86.c|13274| <<kvm_arch_hardware_enable>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+	 *   - arch/x86/kvm/xen.c|371| <<kvm_xen_vcpu_set_attr>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+	 *   - arch/x86/kvm/xen.c|394| <<kvm_xen_vcpu_set_attr>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+	 *
+	 *
+	 * 处理KVM_REQ_CLOCK_UPDATE的函数: kvm_guest_time_update()
+	 */
 	kvm_for_each_vcpu(i, vcpu, kvm)
 		kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
 
@@ -2875,6 +3839,15 @@ static void kvm_gen_update_masterclock(struct kvm *kvm)
 #endif
 }
 
+/*
+ * 在以下使用get_kvmclock_ns():
+ *   - arch/x86/kvm/hyperv.c|588| <<get_time_ref_counter>> return div_u64(get_kvmclock_ns(kvm), 100);
+ *   - arch/x86/kvm/x86.c|2413| <<kvm_write_wall_clock>> wall_nsec = ktime_get_real_ns() - get_kvmclock_ns(kvm);
+ *   - arch/x86/kvm/x86.c|6805| <<kvm_arch_vm_ioctl(KVM_GET_CLOCK)>> now_ns = get_kvmclock_ns(kvm);
+ *   - arch/x86/kvm/xen.c|68| <<kvm_xen_update_runstate>> u64 now = get_kvmclock_ns(v->kvm);
+ *   - arch/x86/kvm/xen.c|455| <<kvm_xen_vcpu_set_attr>> if (get_kvmclock_ns(vcpu->kvm) <
+ *   - arch/x86/kvm/xen.c|496| <<kvm_xen_vcpu_set_attr>> if (get_kvmclock_ns(vcpu->kvm) <
+ */
 u64 get_kvmclock_ns(struct kvm *kvm)
 {
 	struct kvm_arch *ka = &kvm->arch;
@@ -2882,23 +3855,121 @@ u64 get_kvmclock_ns(struct kvm *kvm)
 	unsigned long flags;
 	u64 ret;
 
+	/*
+	 * 使用kvm_arch->pvclock_gtod_sync_lock的函数:
+	 *   - kvm_synchronize_tsc()
+	 *   - kvm_gen_update_masterclock()
+	 *   - get_kvmclock_ns()
+	 *   - kvm_guest_time_update()
+	 *   - kvm_arch_vm_ioctl(KVM_SET_CLOCK)
+	 *   - kvm_hyperv_tsc_notifier()
+	 *   - kvm_arch_init_vm()
+	 */
 	raw_spin_lock_irqsave(&ka->pvclock_gtod_sync_lock, flags);
+	/*
+	 * 在以下设置kvm_arch->use_master_clock:
+	 *   - arch/x86/kvm/x86.c|3073| <<pvclock_update_vm_gtod_copy>> ka->use_master_clock = host_tsc_clocksource && vcpus_matched
+	 * 在以下使用kvm_arch->use_master_clock:
+	 *   - arch/x86/kvm/x86.c|2620| <<kvm_track_tsc_matching>> if ((ka->use_master_clock && new_generation) ||
+	 *   - arch/x86/kvm/x86.c|2621| <<kvm_track_tsc_matching>> (ka->use_master_clock != use_master_clock))
+	 *   - arch/x86/kvm/x86.c|2626| <<kvm_track_tsc_matching>> ka->use_master_clock, gtod->clock.vclock_mode);
+	 *   - arch/x86/kvm/x86.c|3077| <<pvclock_update_vm_gtod_copy>> if (ka->use_master_clock)
+	 *   - arch/x86/kvm/x86.c|3081| <<pvclock_update_vm_gtod_copy>> trace_kvm_update_master_clock(ka->use_master_clock, vclock_mode,
+	 *   - arch/x86/kvm/x86.c|3130| <<get_kvmclock_ns>> if (!ka->use_master_clock) {
+	 *   - arch/x86/kvm/x86.c|3232| <<kvm_guest_time_update>> use_master_clock = ka->use_master_clock;
+	 *   - arch/x86/kvm/x86.c|4817| <<kvm_arch_vcpu_load>> if (!vcpu->kvm->arch.use_master_clock || vcpu->cpu == -1)
+	 *   - arch/x86/kvm/x86.c|6791| <<kvm_arch_vm_ioctl(KVM_SET_CLOCK)>> if (kvm->arch.use_master_clock)
+	 *   - arch/x86/kvm/x86.c|6807| <<kvm_arch_vm_ioctl(KVM_GET_CLOCK)>> user_ns.flags = kvm->arch.use_master_clock ? KVM_CLOCK_TSC_STABLE : 0;
+	 */
 	if (!ka->use_master_clock) {
 		raw_spin_unlock_irqrestore(&ka->pvclock_gtod_sync_lock, flags);
+		/*
+		 * 在以下设置kvm_arch->kvmclock_offset:
+		 *   - arch/x86/kvm/x86.c|6814| <<kvm_arch_vm_ioctl(KVM_SET_CLOCK)>> ka->kvmclock_offset = user_ns.clock - now_ns;
+		 *   - arch/x86/kvm/x86.c|13280| <<kvm_arch_init_vm>> kvm->arch.kvmclock_offset = -get_kvmclock_base_ns();
+		 * 在以下使用kvm_arch->kvmclock_offset:
+		 *   - arch/x86/kvm/pmu.c|342| <<kvm_pmu_rdpmc_vmware>> ctr_val = ktime_get_boottime_ns() + vcpu->kvm->arch.kvmclock_offset;
+		 *   - arch/x86/kvm/x86.c|3141| <<get_kvmclock_ns>> return get_kvmclock_base_ns() + ka->kvmclock_offset;
+		 *   - arch/x86/kvm/x86.c|3145| <<get_kvmclock_ns>> hv_clock.system_time = ka->master_kernel_ns + ka->kvmclock_offset;
+		 *   - arch/x86/kvm/x86.c|3167| <<get_kvmclock_ns>> ret = get_kvmclock_base_ns() + ka->kvmclock_offset;
+		 *   - arch/x86/kvm/x86.c|3307| <<kvm_guest_time_update>> vcpu->hv_clock.system_time = kernel_ns + v->kvm->arch.kvmclock_offset;
+		 */
 		return get_kvmclock_base_ns() + ka->kvmclock_offset;
 	}
 
+	/*
+	 * 关于cycles.
+	 * vcpu->arch.l1_tsc_offset +
+	 *     kvm_scale_tsc(vcpu, host_tsc, vcpu->arch.l1_tsc_scaling_ratio);
+	 *
+	 *
+	 * 在以下使用kvm_arch->master_cycle_now:
+	 *   - arch/x86/kvm/x86.c|3071| <<pvclock_update_vm_gtod_copy>> host_tsc_clocksource =
+	 *               kvm_get_time_and_clockread(&ka->master_kernel_ns, &ka->master_cycle_now);
+	 *   - arch/x86/kvm/x86.c|3144| <<get_kvmclock_ns>> hv_clock.tsc_timestamp = ka->master_cycle_now;
+	 *   - arch/x86/kvm/x86.c|3253| <<kvm_guest_time_update>> host_tsc = ka->master_cycle_now;
+	 *
+	 * host_tsc - ka->master_cycle_now
+	 * host_tsc + vcpu->arch.l1_tsc_offset - ka->master_cycle_now - vcpu->arch.l1_tsc_offset = host - ka->master_cycle_now
+	 */
 	hv_clock.tsc_timestamp = ka->master_cycle_now;
+	/*
+	 * 在以下设置kvm_arch->master_kernel_ns:
+	 *   - arch/x86/kvm/x86.c|3070| <<pvclock_update_vm_gtod_copy>> &ka->master_kernel_ns,
+	 *   - arch/x86/kvm/x86.c|3145| <<get_kvmclock_ns>> hv_clock.system_time = ka->master_kernel_ns + ka->kvmclock_offset;
+	 *   - arch/x86/kvm/x86.c|3254| <<kvm_guest_time_update>> kernel_ns = ka->master_kernel_ns;
+	 *   - arch/x86/kvm/x86.c|6811| <<kvm_arch_vm_ioctl>> now_ns = ka->master_kernel_ns;
+	 *
+	 * 在以下设置kvm_arch->kvmclock_offset:
+	 *   - arch/x86/kvm/x86.c|6814| <<kvm_arch_vm_ioctl(KVM_SET_CLOCK)>> ka->kvmclock_offset = user_ns.clock - now_ns;
+	 *   - arch/x86/kvm/x86.c|13280| <<kvm_arch_init_vm>> kvm->arch.kvmclock_offset = -get_kvmclock_base_ns();
+	 * 在以下使用kvm_arch->kvmclock_offset:
+	 *   - arch/x86/kvm/pmu.c|342| <<kvm_pmu_rdpmc_vmware>> ctr_val = ktime_get_boottime_ns() + vcpu->kvm->arch.kvmclock_offset;
+	 *   - arch/x86/kvm/x86.c|3141| <<get_kvmclock_ns>> return get_kvmclock_base_ns() + ka->kvmclock_offset;
+	 *   - arch/x86/kvm/x86.c|3145| <<get_kvmclock_ns>> hv_clock.system_time = ka->master_kernel_ns + ka->kvmclock_offset;
+	 *   - arch/x86/kvm/x86.c|3167| <<get_kvmclock_ns>> ret = get_kvmclock_base_ns() + ka->kvmclock_offset;
+	 *   - arch/x86/kvm/x86.c|3307| <<kvm_guest_time_update>> vcpu->hv_clock.system_time = kernel_ns + v->kvm->arch.kvmclock_offset;
+	 */
 	hv_clock.system_time = ka->master_kernel_ns + ka->kvmclock_offset;
 	raw_spin_unlock_irqrestore(&ka->pvclock_gtod_sync_lock, flags);
 
 	/* both __this_cpu_read() and rdtsc() should be on the same cpu */
 	get_cpu();
 
+	/*
+	 * 在以下设置cpu_tsc_khz (percpu):
+	 *   - arch/x86/kvm/x86.c|9664| <<kvmclock_cpu_down_prep>> __this_cpu_write(cpu_tsc_khz, 0);
+	 *   - arch/x86/kvm/x86.c|9679| <<tsc_khz_changed>> __this_cpu_write(cpu_tsc_khz, khz);
+	 *   - arch/x86/kvm/x86.c|9698| <<kvm_hyperv_tsc_notifier>> per_cpu(cpu_tsc_khz, cpu) = tsc_khz;
+	 * 在以下使用cpu_tsc_khz (percpu):
+	 *   - arch/x86/kvm/x86.c|2589| <<global>> static DEFINE_PER_CPU(unsigned long , cpu_tsc_khz);
+	 *   - arch/x86/kvm/x86.c|3608| <<get_kvmclock_ns>> if (__this_cpu_read(cpu_tsc_khz)) {
+	 *   - arch/x86/kvm/x86.c|3609| <<get_kvmclock_ns>> kvm_get_time_scale(NSEC_PER_SEC, __this_cpu_read(cpu_tsc_khz) * 1000LL,
+	 *   - arch/x86/kvm/x86.c|3765| <<kvm_guest_time_update>> tgt_tsc_khz = __this_cpu_read(cpu_tsc_khz);
+	 */
 	if (__this_cpu_read(cpu_tsc_khz)) {
+		/*
+		 * 在以下使用kvm_get_time_scale():
+		 *   - arch/x86/kvm/x86.c|2704| <<kvm_set_tsc_khz>> kvm_get_time_scale(user_tsc_khz * 1000LL, NSEC_PER_SEC,
+		 *          &vcpu->arch.virtual_tsc_shift, &vcpu->arch.virtual_tsc_mult);
+		 *   - arch/x86/kvm/x86.c|3609| <<get_kvmclock_ns>> kvm_get_time_scale(NSEC_PER_SEC, __this_cpu_read(cpu_tsc_khz) * 1000LL,
+		 *          &hv_clock.tsc_shift, &hv_clock.tsc_to_system_mul);
+		 *   - arch/x86/kvm/x86.c|3826| <<kvm_guest_time_update>> kvm_get_time_scale(NSEC_PER_SEC, tgt_tsc_khz * 1000LL,
+		 *          &vcpu->hv_clock.tsc_shift, &vcpu->hv_clock.tsc_to_system_mul);
+		 */
 		kvm_get_time_scale(NSEC_PER_SEC, __this_cpu_read(cpu_tsc_khz) * 1000LL,
 				   &hv_clock.tsc_shift,
 				   &hv_clock.tsc_to_system_mul);
+		/*
+		 * 在以下使用__pvclock_read_cycles():
+		 *   - arch/x86/include/asm/vdso/gettimeofday.h|231| <<vread_pvclock>> ret = __pvclock_read_cycles(pvti, rdtsc_ordered());
+		 *   - arch/x86/kernel/pvclock.c|76| <<pvclock_clocksource_read>> ret = __pvclock_read_cycles(src, rdtsc_ordered());
+		 *   - arch/x86/kvm/x86.c|3146| <<get_kvmclock_ns>> ret = __pvclock_read_cycles(&hv_clock, rdtsc());
+		 *   - drivers/ptp/ptp_kvm_x86.c|123| <<kvm_arch_ptp_get_crosststamp>> *cycle = __pvclock_read_cycles(src, clock_pair->tsc);
+		 *
+		 * 把host_tsc转成nanoseconds
+		 * 把当前host_tsc, 按照kvmclock(不是tsc2ns)的通用公式, 转化成nanoseconds
+		 */
 		ret = __pvclock_read_cycles(&hv_clock, rdtsc());
 	} else
 		ret = get_kvmclock_base_ns() + ka->kvmclock_offset;
@@ -2908,6 +3979,12 @@ u64 get_kvmclock_ns(struct kvm *kvm)
 	return ret;
 }
 
+/*
+ * 在以下使用kvm_setup_pvclock_page():
+ *   - arch/x86/kvm/x86.c|3849| <<kvm_guest_time_update>> kvm_setup_pvclock_page(v, &vcpu->pv_time, 0);
+ *   - arch/x86/kvm/x86.c|3851| <<kvm_guest_time_update>> kvm_setup_pvclock_page(v, &vcpu->xen.vcpu_info_cache,
+ *   - arch/x86/kvm/x86.c|3854| <<kvm_guest_time_update>> kvm_setup_pvclock_page(v, &vcpu->xen.vcpu_time_info_cache, 0);
+ */
 static void kvm_setup_pvclock_page(struct kvm_vcpu *v,
 				   struct gfn_to_hva_cache *cache,
 				   unsigned int offset)
@@ -2948,6 +4025,12 @@ static void kvm_setup_pvclock_page(struct kvm_vcpu *v,
 	/* retain PVCLOCK_GUEST_STOPPED if set in guest copy */
 	vcpu->hv_clock.flags |= (guest_hv_clock.flags & PVCLOCK_GUEST_STOPPED);
 
+	/*
+	 * 在以下使用kvm_vcpu_arch->pvclock_set_guest_stopped_request:
+	 *   - arch/x86/kvm/x86.c|3993| <<kvm_setup_pvclock_page>> if (vcpu->pvclock_set_guest_stopped_request) {
+	 *   - arch/x86/kvm/x86.c|3995| <<kvm_setup_pvclock_page>> vcpu->pvclock_set_guest_stopped_request = false;
+	 *   - arch/x86/kvm/x86.c|6539| <<kvm_set_guest_paused>> vcpu->arch.pvclock_set_guest_stopped_request = tr
+	 */
 	if (vcpu->pvclock_set_guest_stopped_request) {
 		vcpu->hv_clock.flags |= PVCLOCK_GUEST_STOPPED;
 		vcpu->pvclock_set_guest_stopped_request = false;
@@ -2967,6 +4050,26 @@ static void kvm_setup_pvclock_page(struct kvm_vcpu *v,
 				     sizeof(vcpu->hv_clock.version));
 }
 
+/*
+ * 在以下使用KVM_REQ_CLOCK_UPDATE:
+ *   - arch/x86/kvm/x86.c|3167| <<kvm_gen_update_masterclock>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|3395| <<kvm_guest_time_update>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, v);
+ *   - arch/x86/kvm/x86.c|3498| <<kvmclock_update_fn>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|3507| <<kvm_gen_kvmclock_update>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, v);
+ *   - arch/x86/kvm/x86.c|3901| <<kvm_set_msr_common(MSR_IA32_TSC_ADJUST)>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|4950| <<kvm_arch_vcpu_load>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|5618| <<kvm_set_guest_paused>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|7018| <<kvm_arch_vm_ioctl>> kvm_make_all_cpus_request(kvm, KVM_REQ_CLOCK_UPDATE);
+ *   - arch/x86/kvm/x86.c|9225| <<kvm_hyperv_tsc_notifier>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|9286| <<__kvmclock_cpufreq_notifier>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|11150| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_CLOCK_UPDATE, vcpu)) {
+ *   - arch/x86/kvm/x86.c|11643| <<vcpu_enter_guest>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|13274| <<kvm_arch_hardware_enable>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/xen.c|371| <<kvm_xen_vcpu_set_attr>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/xen.c|394| <<kvm_xen_vcpu_set_attr>> kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
+ *
+ * 处理KVM_REQ_CLOCK_UPDATE的函数: kvm_guest_time_update()
+ */
 static int kvm_guest_time_update(struct kvm_vcpu *v)
 {
 	unsigned long flags, tgt_tsc_khz;
@@ -2980,23 +4083,76 @@ static int kvm_guest_time_update(struct kvm_vcpu *v)
 	kernel_ns = 0;
 	host_tsc = 0;
 
+	/*
+	 * 使用kvm_arch->pvclock_gtod_sync_lock的函数:
+	 *   - kvm_synchronize_tsc()
+	 *   - kvm_gen_update_masterclock()
+	 *   - get_kvmclock_ns()
+	 *   - kvm_guest_time_update()
+	 *   - kvm_arch_vm_ioctl(KVM_SET_CLOCK)
+	 *   - kvm_hyperv_tsc_notifier()
+	 *   - kvm_arch_init_vm()
+	 */
 	/*
 	 * If the host uses TSC clock, then passthrough TSC as stable
 	 * to the guest.
 	 */
 	raw_spin_lock_irqsave(&ka->pvclock_gtod_sync_lock, flags);
-	use_master_clock = ka->use_master_clock;
+	/*
+	 * 在以下设置kvm_arch->use_master_clock:
+	 *   - arch/x86/kvm/x86.c|3073| <<pvclock_update_vm_gtod_copy>> ka->use_master_clock = host_tsc_clocksource && vcpus_matched
+	 * 在以下使用kvm_arch->use_master_clock:
+	 *   - arch/x86/kvm/x86.c|2620| <<kvm_track_tsc_matching>> if ((ka->use_master_clock && new_generation) ||
+	 *   - arch/x86/kvm/x86.c|2621| <<kvm_track_tsc_matching>> (ka->use_master_clock != use_master_clock))
+	 *   - arch/x86/kvm/x86.c|2626| <<kvm_track_tsc_matching>> ka->use_master_clock, gtod->clock.vclock_mode);
+	 *   - arch/x86/kvm/x86.c|3077| <<pvclock_update_vm_gtod_copy>> if (ka->use_master_clock)
+	 *   - arch/x86/kvm/x86.c|3081| <<pvclock_update_vm_gtod_copy>> trace_kvm_update_master_clock(ka->use_master_clock, vclock_mode,
+	 *   - arch/x86/kvm/x86.c|3130| <<get_kvmclock_ns>> if (!ka->use_master_clock) {
+	 *   - arch/x86/kvm/x86.c|3232| <<kvm_guest_time_update>> use_master_clock = ka->use_master_clock;
+	 *   - arch/x86/kvm/x86.c|4817| <<kvm_arch_vcpu_load>> if (!vcpu->kvm->arch.use_master_clock || vcpu->cpu == -1)
+	 *   - arch/x86/kvm/x86.c|6791| <<kvm_arch_vm_ioctl(KVM_SET_CLOCK)>> if (kvm->arch.use_master_clock)
+	 *   - arch/x86/kvm/x86.c|6807| <<kvm_arch_vm_ioctl(KVM_GET_CLOCK)>> user_ns.flags = kvm->arch.use_master_clock ? KVM_CLOCK_TSC_STABLE : 0;
+	 */
+	use_master_clock = ka->use_master_clock;
 	if (use_master_clock) {
+		/*
+		 * 在以下使用kvm_arch->master_cycle_now:
+		 *   - arch/x86/kvm/x86.c|3071| <<pvclock_update_vm_gtod_copy>> host_tsc_clocksource =
+		 *               kvm_get_time_and_clockread(&ka->master_kernel_ns, &ka->master_cycle_now);
+		 *   - arch/x86/kvm/x86.c|3144| <<get_kvmclock_ns>> hv_clock.tsc_timestamp = ka->master_cycle_now;
+		 *   - arch/x86/kvm/x86.c|3253| <<kvm_guest_time_update>> host_tsc = ka->master_cycle_now;
+		 */
 		host_tsc = ka->master_cycle_now;
+		/*
+		 * 在以下使用kvm_arch->master_cycle_now:
+		 *   - arch/x86/kvm/x86.c|3071| <<pvclock_update_vm_gtod_copy>> host_tsc_clocksource =
+		 *               kvm_get_time_and_clockread(&ka->master_kernel_ns, &ka->master_cycle_now);
+		 *   - arch/x86/kvm/x86.c|3144| <<get_kvmclock_ns>> hv_clock.tsc_timestamp = ka->master_cycle_now;
+		 *   - arch/x86/kvm/x86.c|3253| <<kvm_guest_time_update>> host_tsc = ka->master_cycle_now;
+		 */
 		kernel_ns = ka->master_kernel_ns;
 	}
 	raw_spin_unlock_irqrestore(&ka->pvclock_gtod_sync_lock, flags);
 
 	/* Keep irq disabled to prevent changes to the clock */
 	local_irq_save(flags);
+	/*
+	 * 在以下设置cpu_tsc_khz (percpu):
+	 *   - arch/x86/kvm/x86.c|9664| <<kvmclock_cpu_down_prep>> __this_cpu_write(cpu_tsc_khz, 0);
+	 *   - arch/x86/kvm/x86.c|9679| <<tsc_khz_changed>> __this_cpu_write(cpu_tsc_khz, khz);
+	 *   - arch/x86/kvm/x86.c|9698| <<kvm_hyperv_tsc_notifier>> per_cpu(cpu_tsc_khz, cpu) = tsc_khz;
+	 * 在以下使用cpu_tsc_khz (percpu):
+	 *   - arch/x86/kvm/x86.c|2589| <<global>> static DEFINE_PER_CPU(unsigned long , cpu_tsc_khz);
+	 *   - arch/x86/kvm/x86.c|3608| <<get_kvmclock_ns>> if (__this_cpu_read(cpu_tsc_khz)) {
+	 *   - arch/x86/kvm/x86.c|3609| <<get_kvmclock_ns>> kvm_get_time_scale(NSEC_PER_SEC, __this_cpu_read(cpu_tsc_khz) * 1000LL,
+	 *   - arch/x86/kvm/x86.c|3765| <<kvm_guest_time_update>> tgt_tsc_khz = __this_cpu_read(cpu_tsc_khz);
+	 */
 	tgt_tsc_khz = __this_cpu_read(cpu_tsc_khz);
 	if (unlikely(tgt_tsc_khz == 0)) {
 		local_irq_restore(flags);
+		/*
+		 * 处理KVM_REQ_CLOCK_UPDATE的函数: kvm_guest_time_update()
+		 */
 		kvm_make_request(KVM_REQ_CLOCK_UPDATE, v);
 		return 1;
 	}
@@ -3005,6 +4161,21 @@ static int kvm_guest_time_update(struct kvm_vcpu *v)
 		kernel_ns = get_kvmclock_base_ns();
 	}
 
+	/*
+	 * 在以下使用kvm_read_l1_tsc():
+	 *   - arch/x86/kvm/hyperv.c|591| <<get_time_ref_counter>> tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 *   - arch/x86/kvm/lapic.c|2899| <<__kvm_wait_lapic_expire>> guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 *   - arch/x86/kvm/lapic.c|2917| <<__kvm_wait_lapic_expire>> guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 *   - arch/x86/kvm/lapic.c|3027| <<start_sw_tscdeadline>> guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 *   - arch/x86/kvm/lapic.c|3141| <<set_target_expiration>> apic->lapic_timer.tscdeadline = kvm_read_l1_tsc(apic->vcpu, tscl) +
+	 *   - arch/x86/kvm/lapic.c|3180| <<advance_periodic_target_expiration>> apic->lapic_timer.tscdeadline = kvm_read_l1_tsc(apic->vcpu, tscl) +
+	 *   - arch/x86/kvm/vmx/nested.c|980| <<nested_vmx_get_vmexit_msr_value>> *data = kvm_read_l1_tsc(vcpu, val);
+	 *   - arch/x86/kvm/vmx/nested.c|2086| <<vmx_calc_preemption_timer_value>> u64 l1_scaled_tsc = kvm_read_l1_tsc(vcpu, rdtsc()) >>
+	 *   - arch/x86/kvm/vmx/vmx.c|8345| <<vmx_set_hv_timer>> guest_tscl = kvm_read_l1_tsc(vcpu, tscl);
+	 *   - arch/x86/kvm/x86.c|3885| <<kvm_guest_time_update>> tsc_timestamp = kvm_read_l1_tsc(v, host_tsc);
+	 *   - arch/x86/kvm/x86.c|10375| <<kvm_pv_clock_pairing>> clock_pairing.tsc = kvm_read_l1_tsc(vcpu, cycle);
+	 *   - arch/x86/kvm/x86.c|12309| <<vcpu_enter_guest>> vcpu->arch.last_guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 */
 	tsc_timestamp = kvm_read_l1_tsc(v, host_tsc);
 
 	/*
@@ -3018,8 +4189,18 @@ static int kvm_guest_time_update(struct kvm_vcpu *v)
 	 *	very slowly.
 	 */
 	if (vcpu->tsc_catchup) {
+		/*
+		 * 只在这里使用
+		 */
 		u64 tsc = compute_guest_tsc(v, kernel_ns);
 		if (tsc > tsc_timestamp) {
+			/*
+			 * 在以下使用adjust_tsc_offset_guest():
+			 *   - arch/x86/kvm/x86.c|3358| <<adjust_tsc_offset_host>> adjust_tsc_offset_guest(vcpu, adjustment);
+			 *   - arch/x86/kvm/x86.c|4041| <<kvm_guest_time_update>> adjust_tsc_offset_guest(v, tsc - tsc_timestamp);
+			 *   - arch/x86/kvm/x86.c|4618| <<kvm_set_msr_common(MSR_IA32_TSC_ADJUST)>> adjust_tsc_offset_guest(vcpu, adj);
+			 *   - arch/x86/kvm/x86.c|4658| <<kvm_set_msr_common(MSR_IA32_TSC)>> adjust_tsc_offset_guest(vcpu, adj);
+			 */
 			adjust_tsc_offset_guest(v, tsc - tsc_timestamp);
 			tsc_timestamp = tsc;
 		}
@@ -3029,11 +4210,48 @@ static int kvm_guest_time_update(struct kvm_vcpu *v)
 
 	/* With all the info we got, fill in the values */
 
+	/*
+	 * 在以下设置kvm_has_tsc_control:
+	 *   - arch/x86/kvm/svm/svm.c|1115| <<svm_hardware_setup>> kvm_has_tsc_control = true;
+	 *   - arch/x86/kvm/vmx/vmx.c|8787| <<hardware_setup>> kvm_has_tsc_control = true;
+	 * 在以下使用kvm_has_tsc_control:
+	 *   - arch/x86/kvm/debugfs.c|69| <<kvm_arch_create_vcpu_debugfs>> if (kvm_has_tsc_control) {
+	 *   - arch/x86/kvm/vmx/nested.c|2581| <<prepare_vmcs02>> if (kvm_has_tsc_control)
+	 *   - arch/x86/kvm/vmx/nested.c|4680| <<nested_vmx_vmexit>> if (kvm_has_tsc_control)
+	 *   - arch/x86/kvm/x86.c|2579| <<set_tsc_khz>> if (!kvm_has_tsc_control) {
+	 *   - arch/x86/kvm/x86.c|2843| <<kvm_vcpu_write_tsc_multiplier>> if (kvm_has_tsc_control)
+	 *   - arch/x86/kvm/x86.c|3607| <<kvm_guest_time_update>> if (kvm_has_tsc_control)
+	 *   - arch/x86/kvm/x86.c|4951| <<kvm_vm_ioctl_check_extension>> r = kvm_has_tsc_control;
+	 *   - arch/x86/kvm/x86.c|6207| <<kvm_arch_vcpu_ioctl(KVM_SET_TSC_KHZ)>> if (kvm_has_tsc_control &
+	 *   - arch/x86/kvm/x86.c|13736| <<kvm_arch_hardware_setup>> if (kvm_has_tsc_control) {
+	 *
+	 *
+	 * 在以下使用kvm_scale_tsc():
+	 *   - arch/x86/kvm/x86.c|2941| <<kvm_compute_l1_tsc_offset>> tsc = kvm_scale_tsc(vcpu, rdtsc(), vcpu->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|2964| <<kvm_read_l1_tsc>> kvm_scale_tsc(vcpu, host_tsc, vcpu->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|3269| <<adjust_tsc_offset_host>> adjustment = kvm_scale_tsc(vcpu, (u64) adjustment, vcpu->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|3979| <<kvm_guest_time_update>> tgt_tsc_khz = kvm_scale_tsc(v, tgt_tsc_khz, v->arch.l1_tsc_scaling_ratio);
+	 *   - arch/x86/kvm/x86.c|4914| <<kvm_get_msr_common(MSR_IA32_TSC)>> msr_info->data = kvm_scale_tsc(vcpu, rdtsc(), ratio) + offset;
+	 */
 	if (kvm_has_tsc_control)
 		tgt_tsc_khz = kvm_scale_tsc(v, tgt_tsc_khz,
 					    v->arch.l1_tsc_scaling_ratio);
 
+	/*
+	 * 在以下使用kvm_vcpu_arch->hw_tsc_khz:
+	 *   - arch/x86/kvm/x86.c|3825| <<kvm_guest_time_update>> if (unlikely(vcpu->hw_tsc_khz != tgt_tsc_khz)) {
+	 *   - arch/x86/kvm/x86.c|3829| <<kvm_guest_time_update>> vcpu->hw_tsc_khz = tgt_tsc_khz;
+	 */
 	if (unlikely(vcpu->hw_tsc_khz != tgt_tsc_khz)) {
+		/*
+		 * 在以下使用kvm_get_time_scale():
+		 *   - arch/x86/kvm/x86.c|2704| <<kvm_set_tsc_khz>> kvm_get_time_scale(user_tsc_khz * 1000LL, NSEC_PER_SEC,
+		 *          &vcpu->arch.virtual_tsc_shift, &vcpu->arch.virtual_tsc_mult);
+		 *   - arch/x86/kvm/x86.c|3609| <<get_kvmclock_ns>> kvm_get_time_scale(NSEC_PER_SEC, __this_cpu_read(cpu_tsc_khz) * 1000LL,
+		 *          &hv_clock.tsc_shift, &hv_clock.tsc_to_system_mul);
+		 *   - arch/x86/kvm/x86.c|3826| <<kvm_guest_time_update>> kvm_get_time_scale(NSEC_PER_SEC, tgt_tsc_khz * 1000LL,
+		 *          &vcpu->hv_clock.tsc_shift, &vcpu->hv_clock.tsc_to_system_mul);
+		 */
 		kvm_get_time_scale(NSEC_PER_SEC, tgt_tsc_khz * 1000LL,
 				   &vcpu->hv_clock.tsc_shift,
 				   &vcpu->hv_clock.tsc_to_system_mul);
@@ -3041,6 +4259,17 @@ static int kvm_guest_time_update(struct kvm_vcpu *v)
 	}
 
 	vcpu->hv_clock.tsc_timestamp = tsc_timestamp;
+	/*
+	 * 在以下设置kvm_arch->kvmclock_offset:
+	 *   - arch/x86/kvm/x86.c|6814| <<kvm_arch_vm_ioctl(KVM_SET_CLOCK)>> ka->kvmclock_offset = user_ns.clock - now_ns;
+	 *   - arch/x86/kvm/x86.c|13280| <<kvm_arch_init_vm>> kvm->arch.kvmclock_offset = -get_kvmclock_base_ns();
+	 * 在以下使用kvm_arch->kvmclock_offset:
+	 *   - arch/x86/kvm/pmu.c|342| <<kvm_pmu_rdpmc_vmware>> ctr_val = ktime_get_boottime_ns() + vcpu->kvm->arch.kvmclock_offset;
+	 *   - arch/x86/kvm/x86.c|3141| <<get_kvmclock_ns>> return get_kvmclock_base_ns() + ka->kvmclock_offset;
+	 *   - arch/x86/kvm/x86.c|3145| <<get_kvmclock_ns>> hv_clock.system_time = ka->master_kernel_ns + ka->kvmclock_offset;
+	 *   - arch/x86/kvm/x86.c|3167| <<get_kvmclock_ns>> ret = get_kvmclock_base_ns() + ka->kvmclock_offset;
+	 *   - arch/x86/kvm/x86.c|3307| <<kvm_guest_time_update>> vcpu->hv_clock.system_time = kernel_ns + v->kvm->arch.kvmclock_offset;
+	 */
 	vcpu->hv_clock.system_time = kernel_ns + v->kvm->arch.kvmclock_offset;
 	vcpu->last_guest_tsc = tsc_timestamp;
 
@@ -3051,6 +4280,12 @@ static int kvm_guest_time_update(struct kvm_vcpu *v)
 
 	vcpu->hv_clock.flags = pvclock_flags;
 
+	/*
+	 * 在以下使用kvm_setup_pvclock_page():
+	 *   - arch/x86/kvm/x86.c|3849| <<kvm_guest_time_update>> kvm_setup_pvclock_page(v, &vcpu->pv_time, 0);
+	 *   - arch/x86/kvm/x86.c|3851| <<kvm_guest_time_update>> kvm_setup_pvclock_page(v, &vcpu->xen.vcpu_info_cache,
+	 *   - arch/x86/kvm/x86.c|3854| <<kvm_guest_time_update>> kvm_setup_pvclock_page(v, &vcpu->xen.vcpu_time_info_cache, 0);
+	 */
 	if (vcpu->pv_time_enabled)
 		kvm_setup_pvclock_page(v, &vcpu->pv_time, 0);
 	if (vcpu->xen.vcpu_info_set)
@@ -3079,6 +4314,15 @@ static int kvm_guest_time_update(struct kvm_vcpu *v)
 
 #define KVMCLOCK_UPDATE_DELAY msecs_to_jiffies(100)
 
+/*
+ * 在以下使用kvm_arch->kvmclock_update_work:
+ *   - arch/x86/kvm/x86.c|3508| <<kvm_gen_kvmclock_update>> schedule_delayed_work(&kvm->arch.kvmclock_update_work, KVMCLOCK_UPDATE_DELAY);
+ *   - arch/x86/kvm/x86.c|3529| <<kvmclock_sync_fn>> schedule_delayed_work(&kvm->arch.kvmclock_update_work, 0);
+ *   - arch/x86/kvm/x86.c|13529| <<kvm_arch_init_vm>> INIT_DELAYED_WORK(&kvm->arch.kvmclock_update_work, kvmclock_update_fn);
+ *   - arch/x86/kvm/x86.c|13578| <<kvm_arch_sync_events>> cancel_delayed_work_sync(&kvm->arch.kvmclock_update_work);
+ *
+ * kvmclock_update_fn()
+ */
 static void kvmclock_update_fn(struct work_struct *work)
 {
 	int i;
@@ -3089,22 +4333,58 @@ static void kvmclock_update_fn(struct work_struct *work)
 	struct kvm_vcpu *vcpu;
 
 	kvm_for_each_vcpu(i, vcpu, kvm) {
+		/*
+		 * 处理KVM_REQ_CLOCK_UPDATE的函数: kvm_guest_time_update()
+		 */
 		kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
 		kvm_vcpu_kick(vcpu);
 	}
 }
 
+/*
+ * 在以下使用KVM_REQ_GLOBAL_CLOCK_UPDATE:
+ *   - arch/x86/kvm/x86.c|2529| <<kvm_write_system_time>> kvm_make_request(KVM_REQ_GLOBAL_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|5532| <<kvm_arch_vcpu_load>> kvm_make_request(KVM_REQ_GLOBAL_CLOCK_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|11816| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_GLOBAL_CLOCK_UPDATE, vcpu))
+ *
+ * 处理KVM_REQ_GLOBAL_CLOCK_UPDATE的函数: kvm_gen_kvmclock_update()
+ *
+ *
+ * 在以下使用kvm_gen_kvmclock_update():
+ *   - arch/x86/kvm/x86.c|11817| <<vcpu_enter_guest(KVM_REQ_GLOBAL_CLOCK_UPDATE)>> kvm_gen_kvmclock_update(vcpu);
+ */
 static void kvm_gen_kvmclock_update(struct kvm_vcpu *v)
 {
 	struct kvm *kvm = v->kvm;
 
+	/*
+	 * 处理KVM_REQ_CLOCK_UPDATE的函数: kvm_guest_time_update()
+	 */
 	kvm_make_request(KVM_REQ_CLOCK_UPDATE, v);
+	/*
+	 * 在以下使用kvm_arch->kvmclock_update_work:
+	 *   - arch/x86/kvm/x86.c|3508| <<kvm_gen_kvmclock_update>> schedule_delayed_work(&kvm->arch.kvmclock_update_work, KVMCLOCK_UPDATE_DELAY);
+	 *   - arch/x86/kvm/x86.c|3529| <<kvmclock_sync_fn>> schedule_delayed_work(&kvm->arch.kvmclock_update_work, 0);
+	 *   - arch/x86/kvm/x86.c|13529| <<kvm_arch_init_vm>> INIT_DELAYED_WORK(&kvm->arch.kvmclock_update_work, kvmclock_update_fn);
+	 *   - arch/x86/kvm/x86.c|13578| <<kvm_arch_sync_events>> cancel_delayed_work_sync(&kvm->arch.kvmclock_update_work);
+	 *
+	 * kvmclock_update_fn()
+	 */
 	schedule_delayed_work(&kvm->arch.kvmclock_update_work,
 					KVMCLOCK_UPDATE_DELAY);
 }
 
+/*
+ * 在以下使用KVMCLOCK_SYNC_PERIOD:
+ *   - arch/x86/kvm/x86.c|3383| <<kvmclock_sync_fn>> schedule_delayed_work(&kvm->arch.kvmclock_sync_work, KVMCLOCK_SYNC_PERIOD);
+ *   - arch/x86/kvm/x86.c|12776| <<kvm_arch_vcpu_postcreate>> schedule_delayed_work(&kvm->arch.kvmclock_sync_work, KVMCLOCK_SYNC_PERIOD);
+ */
 #define KVMCLOCK_SYNC_PERIOD (300 * HZ)
 
+/*
+ * 在以下使用kvmclock_sync_fn():
+ *   - arch/x86/kvm/x86.c|13530| <<kvm_arch_init_vm>> INIT_DELAYED_WORK(&kvm->arch.kvmclock_sync_work, kvmclock_sync_fn);
+ */
 static void kvmclock_sync_fn(struct work_struct *work)
 {
 	struct delayed_work *dwork = to_delayed_work(work);
@@ -3112,10 +4392,38 @@ static void kvmclock_sync_fn(struct work_struct *work)
 					   kvmclock_sync_work);
 	struct kvm *kvm = container_of(ka, struct kvm, arch);
 
+	/*
+	 * 在以下使用kvmclock_periodic_sync:
+	 *   - arch/x86/kvm/x86.c|149| <<global>> static bool __read_mostly kvmclock_periodic_sync = true;
+	 *   - arch/x86/kvm/x86.c|3526| <<kvmclock_sync_fn>> if (!kvmclock_periodic_sync)
+	 *   - arch/x86/kvm/x86.c|12996| <<kvm_arch_vcpu_postcreate>> if (kvmclock_periodic_sync && vcpu->vcpu_idx == 0)
+	 */
 	if (!kvmclock_periodic_sync)
 		return;
 
+	/*
+	 * 在以下使用kvm_arch->kvmclock_update_work:
+	 *   - arch/x86/kvm/x86.c|3508| <<kvm_gen_kvmclock_update>> schedule_delayed_work(&kvm->arch.kvmclock_update_work, KVMCLOCK_UPDATE_DELAY);
+	 *   - arch/x86/kvm/x86.c|3529| <<kvmclock_sync_fn>> schedule_delayed_work(&kvm->arch.kvmclock_update_work, 0);
+	 *   - arch/x86/kvm/x86.c|13529| <<kvm_arch_init_vm>> INIT_DELAYED_WORK(&kvm->arch.kvmclock_update_work, kvmclock_update_fn);
+	 *   - arch/x86/kvm/x86.c|13578| <<kvm_arch_sync_events>> cancel_delayed_work_sync(&kvm->arch.kvmclock_update_work);
+	 *
+	 * kvmclock_update_fn()
+	 */
 	schedule_delayed_work(&kvm->arch.kvmclock_update_work, 0);
+	/*
+	 * 在以下使用KVMCLOCK_SYNC_PERIOD:
+	 *   - arch/x86/kvm/x86.c|3383| <<kvmclock_sync_fn>> schedule_delayed_work(&kvm->arch.kvmclock_sync_work, KVMCLOCK_SYNC_PERIOD);
+	 *   - arch/x86/kvm/x86.c|12776| <<kvm_arch_vcpu_postcreate>> schedule_delayed_work(&kvm->arch.kvmclock_sync_work, KVMCLOCK_SYNC_PERIOD);
+	 *
+	 * 在以下使用kvm_arch->kvmclock_sync_work:
+	 *   - arch/x86/kvm/x86.c|3535| <<kvmclock_sync_fn>> schedule_delayed_work(&kvm->arch.kvmclock_sync_work, KVMCLOCK_SYNC_PERIOD);
+	 *   - arch/x86/kvm/x86.c|12997| <<kvm_arch_vcpu_postcreate>> schedule_delayed_work(&kvm->arch.kvmclock_sync_work, KVMCLOCK_SYNC_PERIOD);
+	 *   - arch/x86/kvm/x86.c|13530| <<kvm_arch_init_vm>> INIT_DELAYED_WORK(&kvm->arch.kvmclock_sync_work, kvmclock_sync_fn);
+	 *   - arch/x86/kvm/x86.c|13577| <<kvm_arch_sync_events>> cancel_delayed_work_sync(&kvm->arch.kvmclock_sync_work);
+	 *
+	 * kvmclock_sync_fn()
+	 */
 	schedule_delayed_work(&kvm->arch.kvmclock_sync_work,
 					KVMCLOCK_SYNC_PERIOD);
 }
@@ -3478,6 +4786,13 @@ int kvm_set_msr_common(struct kvm_vcpu *vcpu, struct msr_data *msr_info)
 		if (guest_cpuid_has(vcpu, X86_FEATURE_TSC_ADJUST)) {
 			if (!msr_info->host_initiated) {
 				s64 adj = data - vcpu->arch.ia32_tsc_adjust_msr;
+				/*
+				 * 在以下使用adjust_tsc_offset_guest():
+				 *   - arch/x86/kvm/x86.c|3358| <<adjust_tsc_offset_host>> adjust_tsc_offset_guest(vcpu, adjustment);
+				 *   - arch/x86/kvm/x86.c|4041| <<kvm_guest_time_update>> adjust_tsc_offset_guest(v, tsc - tsc_timestamp);
+				 *   - arch/x86/kvm/x86.c|4618| <<kvm_set_msr_common(MSR_IA32_TSC_ADJUST)>> adjust_tsc_offset_guest(vcpu, adj);
+				 *   - arch/x86/kvm/x86.c|4658| <<kvm_set_msr_common(MSR_IA32_TSC)>> adjust_tsc_offset_guest(vcpu, adj);
+				 */
 				adjust_tsc_offset_guest(vcpu, adj);
 				/* Before back to guest, tsc_timestamp must be adjusted
 				 * as well, otherwise guest's percpu pvclock time could jump.
@@ -3510,7 +4825,37 @@ int kvm_set_msr_common(struct kvm_vcpu *vcpu, struct msr_data *msr_info)
 		if (msr_info->host_initiated) {
 			kvm_synchronize_tsc(vcpu, data);
 		} else {
+			/*
+			 * 在以下使用kvm_vcpu_arch->l1_tsc_offset:
+			 *   - arch/x86/kvm/svm/nested.c|619| <<nested_vmcb02_prepare_control>> vcpu->arch.l1_tsc_offset + svm->nested.ctl.tsc_offset;
+			 *   - arch/x86/kvm/svm/nested.c|972| <<nested_svm_vmexit>> svm->vcpu.arch.tsc_offset = svm->vcpu.arch.l1_tsc_offset;
+			 *   - arch/x86/kvm/svm/svm.c|1290| <<svm_write_tsc_offset>> svm->vmcb01.ptr->control.tsc_offset = vcpu->arch.l1_tsc_offset;
+			 *   - arch/x86/kvm/vmx/nested.c|2602| <<prepare_vmcs02>> vcpu->arch.tsc_offset = kvm_calc_nested_tsc_offset(vcpu->arch.l1_tsc_offset,
+			 *          vmx_get_l2_tsc_offset(vcpu), vmx_get_l2_tsc_multiplier(vcpu));
+			 *   - arch/x86/kvm/vmx/nested.c|4648| <<nested_vmx_vmexit>> vcpu->arch.tsc_offset = vcpu->arch.l1_tsc_offset;
+			 *   - arch/x86/kvm/x86.c|3066| <<kvm_read_l1_tsc>> return vcpu->arch.l1_tsc_offset + kvm_scale_tsc(vcpu, host_tsc,
+			 *          vcpu->arch.l1_tsc_scaling_ratio);
+			 *   - arch/x86/kvm/x86.c|3105| <<kvm_vcpu_write_tsc_offset>> trace_kvm_write_tsc_offset( ... vcpu->arch.l1_tsc_offset,
+			 *   - arch/x86/kvm/x86.c|3108| <<kvm_vcpu_write_tsc_offset>> vcpu->arch.l1_tsc_offset = l1_offset;
+			 *   - arch/x86/kvm/x86.c|3373| <<adjust_tsc_offset_guest>> u64 tsc_offset = vcpu->arch.l1_tsc_offset;
+			 *   - arch/x86/kvm/x86.c|4746| <<kvm_set_msr_common(MSR_IA32_TSC)>> u64 adj = kvm_compute_l1_tsc_offset(vcpu, data) - vcpu->arch.l1_tsc_offset;
+			 *   - arch/x86/kvm/x86.c|5090| <<kvm_get_msr_common(MSR_IA32_TSC)>> offset = vcpu->arch.l1_tsc_offset;
+			 *
+			 *
+			 * 在以下使用kvm_compute_l1_tsc_offset():
+			 *   - arch/x86/kvm/x86.c|3071| <<kvm_synchronize_tsc>> offset = kvm_compute_l1_tsc_offset(vcpu, data);
+			 *   - arch/x86/kvm/x86.c|3140| <<kvm_synchronize_tsc>> offset = kvm_compute_l1_tsc_offset(vcpu, data);
+			 *   - arch/x86/kvm/x86.c|4512| <<kvm_set_msr_common(MSR_IA32_TSC不是host)>> u64 adj = kvm_compute_l1_tsc_offset(vcpu, data) - vcpu->arch.l1_tsc_offset;
+			 *   - arch/x86/kvm/x86.c|5556| <<kvm_arch_vcpu_load(tsc unstable)>> u64 offset = kvm_compute_l1_tsc_offset(vcpu, vcpu->arch.last_guest_tsc);
+			 */
 			u64 adj = kvm_compute_l1_tsc_offset(vcpu, data) - vcpu->arch.l1_tsc_offset;
+			/*
+			 * 在以下使用adjust_tsc_offset_guest():
+			 *   - arch/x86/kvm/x86.c|3358| <<adjust_tsc_offset_host>> adjust_tsc_offset_guest(vcpu, adjustment);
+			 *   - arch/x86/kvm/x86.c|4041| <<kvm_guest_time_update>> adjust_tsc_offset_guest(v, tsc - tsc_timestamp);
+			 *   - arch/x86/kvm/x86.c|4618| <<kvm_set_msr_common(MSR_IA32_TSC_ADJUST)>> adjust_tsc_offset_guest(vcpu, adj);
+			 *   - arch/x86/kvm/x86.c|4658| <<kvm_set_msr_common(MSR_IA32_TSC)>> adjust_tsc_offset_guest(vcpu, adj);
+			 */
 			adjust_tsc_offset_guest(vcpu, adj);
 			vcpu->arch.ia32_tsc_adjust_msr += adj;
 		}
@@ -3597,6 +4942,14 @@ int kvm_set_msr_common(struct kvm_vcpu *vcpu, struct msr_data *msr_info)
 		if (!(data & KVM_MSR_ENABLED))
 			break;
 
+		/*
+		 * 在以下使用KVM_REQ_STEAL_UPDATE:
+		 *   - arch/x86/kvm/x86.c|3787| <<kvm_set_msr_common(MSR_KVM_STEAL_TIME)>> kvm_make_request(KVM_REQ_STEAL_UPDATE, vcpu);
+		 *   - arch/x86/kvm/x86.c|4733| <<kvm_arch_vcpu_load>> kvm_make_request(KVM_REQ_STEAL_UPDATE, vcpu);
+		 *   - arch/x86/kvm/x86.c|10795| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_STEAL_UPDATE, vcpu))
+		 *
+		 * 处理函数是record_steal_time()
+		 */
 		kvm_make_request(KVM_REQ_STEAL_UPDATE, vcpu);
 
 		break;
@@ -3839,6 +5192,22 @@ int kvm_get_msr_common(struct kvm_vcpu *vcpu, struct msr_data *msr_info)
 		u64 offset, ratio;
 
 		if (msr_info->host_initiated) {
+			/*
+			 * 在以下使用kvm_vcpu_arch->l1_tsc_offset:
+			 *   - arch/x86/kvm/svm/nested.c|619| <<nested_vmcb02_prepare_control>> vcpu->arch.l1_tsc_offset + svm->nested.ctl.tsc_offset;
+			 *   - arch/x86/kvm/svm/nested.c|972| <<nested_svm_vmexit>> svm->vcpu.arch.tsc_offset = svm->vcpu.arch.l1_tsc_offset;
+			 *   - arch/x86/kvm/svm/svm.c|1290| <<svm_write_tsc_offset>> svm->vmcb01.ptr->control.tsc_offset = vcpu->arch.l1_tsc_offset;
+			 *   - arch/x86/kvm/vmx/nested.c|2602| <<prepare_vmcs02>> vcpu->arch.tsc_offset = kvm_calc_nested_tsc_offset(vcpu->arch.l1_tsc_offset,
+			 *          vmx_get_l2_tsc_offset(vcpu), vmx_get_l2_tsc_multiplier(vcpu));
+			 *   - arch/x86/kvm/vmx/nested.c|4648| <<nested_vmx_vmexit>> vcpu->arch.tsc_offset = vcpu->arch.l1_tsc_offset;
+			 *   - arch/x86/kvm/x86.c|3066| <<kvm_read_l1_tsc>> return vcpu->arch.l1_tsc_offset + kvm_scale_tsc(vcpu, host_tsc,
+			 *          vcpu->arch.l1_tsc_scaling_ratio);
+			 *   - arch/x86/kvm/x86.c|3105| <<kvm_vcpu_write_tsc_offset>> trace_kvm_write_tsc_offset( ... vcpu->arch.l1_tsc_offset,
+			 *   - arch/x86/kvm/x86.c|3108| <<kvm_vcpu_write_tsc_offset>> vcpu->arch.l1_tsc_offset = l1_offset;
+			 *   - arch/x86/kvm/x86.c|3373| <<adjust_tsc_offset_guest>> u64 tsc_offset = vcpu->arch.l1_tsc_offset;
+			 *   - arch/x86/kvm/x86.c|4746| <<kvm_set_msr_common(MSR_IA32_TSC)>> u64 adj = kvm_compute_l1_tsc_offset(vcpu, data) - vcpu->arch.l1_tsc_offset;
+			 *   - arch/x86/kvm/x86.c|5090| <<kvm_get_msr_common(MSR_IA32_TSC)>> offset = vcpu->arch.l1_tsc_offset;
+			 */
 			offset = vcpu->arch.l1_tsc_offset;
 			ratio = vcpu->arch.l1_tsc_scaling_ratio;
 		} else {
@@ -3846,6 +5215,14 @@ int kvm_get_msr_common(struct kvm_vcpu *vcpu, struct msr_data *msr_info)
 			ratio = vcpu->arch.tsc_scaling_ratio;
 		}
 
+		/*
+		 * 在以下使用kvm_scale_tsc():
+		 *   - arch/x86/kvm/x86.c|2941| <<kvm_compute_l1_tsc_offset>> tsc = kvm_scale_tsc(vcpu, rdtsc(), vcpu->arch.l1_tsc_scaling_ratio);
+		 *   - arch/x86/kvm/x86.c|2964| <<kvm_read_l1_tsc>> kvm_scale_tsc(vcpu, host_tsc, vcpu->arch.l1_tsc_scaling_ratio);
+		 *   - arch/x86/kvm/x86.c|3269| <<adjust_tsc_offset_host>> adjustment = kvm_scale_tsc(vcpu, (u64) adjustment, vcpu->arch.l1_tsc_scaling_ratio);
+		 *   - arch/x86/kvm/x86.c|3979| <<kvm_guest_time_update>> tgt_tsc_khz = kvm_scale_tsc(v, tgt_tsc_khz, v->arch.l1_tsc_scaling_ratio);
+		 *   - arch/x86/kvm/x86.c|4914| <<kvm_get_msr_common(MSR_IA32_TSC)>> msr_info->data = kvm_scale_tsc(vcpu, rdtsc(), ratio) + offset;
+		 */
 		msr_info->data = kvm_scale_tsc(vcpu, rdtsc(), ratio) + offset;
 		break;
 	}
@@ -3870,6 +5247,13 @@ int kvm_get_msr_common(struct kvm_vcpu *vcpu, struct msr_data *msr_info)
 		msr_info->data = 1 << 24;
 		break;
 	case MSR_IA32_APICBASE:
+		/*
+		 * 在以下使用kvm_get_apic_base():
+		 *   - arch/x86/kvm/x86.c|472| <<kvm_get_apic_mode>> return kvm_apic_mode(kvm_get_apic_base(vcpu));
+		 *   - arch/x86/kvm/x86.c|4074| <<kvm_get_msr_common>> msr_info->data = kvm_get_apic_base(vcpu);
+		 *   - arch/x86/kvm/x86.c|9617| <<post_kvm_run_save>> kvm_run->apic_base = kvm_get_apic_base(vcpu);
+		 *   - arch/x86/kvm/x86.c|11932| <<__get_sregs_common>> sregs->apic_base = kvm_get_apic_base(vcpu);
+		 */
 		msr_info->data = kvm_get_apic_base(vcpu);
 		break;
 	case APIC_BASE_MSR ... APIC_BASE_MSR + 0xff:
@@ -4504,6 +5888,9 @@ void kvm_arch_vcpu_load(struct kvm_vcpu *vcpu, int cpu)
 					wbinvd_ipi, NULL, 1);
 	}
 
+	/*
+	 * vmx_vcpu_load()
+	 */
 	static_call(kvm_x86_vcpu_load)(vcpu, cpu);
 
 	/* Save host pkru register if supported */
@@ -4513,18 +5900,44 @@ void kvm_arch_vcpu_load(struct kvm_vcpu *vcpu, int cpu)
 	if (unlikely(vcpu->arch.tsc_offset_adjustment)) {
 		adjust_tsc_offset_host(vcpu, vcpu->arch.tsc_offset_adjustment);
 		vcpu->arch.tsc_offset_adjustment = 0;
+		/*
+		 * 处理KVM_REQ_CLOCK_UPDATE的函数: kvm_guest_time_update()
+		 */
 		kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
 	}
 
 	if (unlikely(vcpu->cpu != cpu) || kvm_check_tsc_unstable()) {
+		/*
+		 * 在以下使用kvm_vcpu_arch->last_host_tsc:
+		 *   - arch/x86/kvm/x86.c|4745| <<kvm_arch_vcpu_load>> s64 tsc_delta = !vcpu->arch.last_host_tsc ? 0 :
+		 *   - arch/x86/kvm/x86.c|4746| <<kvm_arch_vcpu_load>> rdtsc() - vcpu->arch.last_host_tsc;
+		 *   - arch/x86/kvm/x86.c|4857| <<kvm_arch_vcpu_put>> vcpu->arch.last_host_tsc = rdtsc();
+		 *   - arch/x86/kvm/x86.c|12955| <<kvm_arch_hardware_enable>> if (stable && vcpu->arch.last_host_tsc > local_tsc) {
+		 *   - arch/x86/kvm/x86.c|12957| <<kvm_arch_hardware_enable>> if (vcpu->arch.last_host_tsc > max_tsc)
+		 *   - arch/x86/kvm/x86.c|12958| <<kvm_arch_hardware_enable>> max_tsc = vcpu->arch.last_host_tsc;
+		 *   - arch/x86/kvm/x86.c|13007| <<kvm_arch_hardware_enable>> vcpu->arch.last_host_tsc = local_tsc;
+		 */
 		s64 tsc_delta = !vcpu->arch.last_host_tsc ? 0 :
 				rdtsc() - vcpu->arch.last_host_tsc;
 		if (tsc_delta < 0)
 			mark_tsc_unstable("KVM discovered backwards TSC");
 
 		if (kvm_check_tsc_unstable()) {
+			/*
+			 * 在以下使用kvm_compute_l1_tsc_offset():
+			 *   - arch/x86/kvm/x86.c|3071| <<kvm_synchronize_tsc>> offset = kvm_compute_l1_tsc_offset(vcpu, data);
+			 *   - arch/x86/kvm/x86.c|3140| <<kvm_synchronize_tsc>> offset = kvm_compute_l1_tsc_offset(vcpu, data);
+			 *   - arch/x86/kvm/x86.c|4512| <<kvm_set_msr_common(MSR_IA32_TSC不是host)>> u64 adj = kvm_compute_l1_tsc_offset(vcpu, data) - vcpu->arch.l1_tsc_offset;
+			 *   - arch/x86/kvm/x86.c|5556| <<kvm_arch_vcpu_load(tsc unstable)>> u64 offset = kvm_compute_l1_tsc_offset(vcpu, vcpu->arch.last_guest_tsc);
+			 */
 			u64 offset = kvm_compute_l1_tsc_offset(vcpu,
 						vcpu->arch.last_guest_tsc);
+			/*
+			 * 在以下使用kvm_vcpu_write_tsc_offset():
+			 *   - arch/x86/kvm/x86.c|2831| <<kvm_synchronize_tsc>> kvm_vcpu_write_tsc_offset(vcpu, offset);
+			 *   - arch/x86/kvm/x86.c|2849| <<adjust_tsc_offset_guest>> kvm_vcpu_write_tsc_offset(vcpu, tsc_offset + adjustment);
+			 *   - arch/x86/kvm/x86.c|4763| <<kvm_arch_vcpu_load>> kvm_vcpu_write_tsc_offset(vcpu, offset);
+			 */
 			kvm_vcpu_write_tsc_offset(vcpu, offset);
 			vcpu->arch.tsc_catchup = 1;
 		}
@@ -4536,6 +5949,21 @@ void kvm_arch_vcpu_load(struct kvm_vcpu *vcpu, int cpu)
 		 * On a host with synchronized TSC, there is no need to update
 		 * kvmclock on vcpu->cpu migration
 		 */
+		/*
+		 *  在以下设置kvm_arch->use_master_clock:
+		 *   - arch/x86/kvm/x86.c|3073| <<pvclock_update_vm_gtod_copy>> ka->use_master_clock = host_tsc_clocksource && vcpus_matched
+		 * 在以下使用kvm_arch->use_master_clock:
+		 *   - arch/x86/kvm/x86.c|2620| <<kvm_track_tsc_matching>> if ((ka->use_master_clock && new_generation) ||
+		 *   - arch/x86/kvm/x86.c|2621| <<kvm_track_tsc_matching>> (ka->use_master_clock != use_master_clock))
+		 *   - arch/x86/kvm/x86.c|2626| <<kvm_track_tsc_matching>> ka->use_master_clock, gtod->clock.vclock_mode);
+		 *   - arch/x86/kvm/x86.c|3077| <<pvclock_update_vm_gtod_copy>> if (ka->use_master_clock)
+		 *   - arch/x86/kvm/x86.c|3081| <<pvclock_update_vm_gtod_copy>> trace_kvm_update_master_clock(ka->use_master_clock, vclock_mode,
+		 *   - arch/x86/kvm/x86.c|3130| <<get_kvmclock_ns>> if (!ka->use_master_clock) {
+		 *   - arch/x86/kvm/x86.c|3232| <<kvm_guest_time_update>> use_master_clock = ka->use_master_clock;
+		 *   - arch/x86/kvm/x86.c|4817| <<kvm_arch_vcpu_load>> if (!vcpu->kvm->arch.use_master_clock || vcpu->cpu == -1)
+		 *   - arch/x86/kvm/x86.c|6791| <<kvm_arch_vm_ioctl(KVM_SET_CLOCK)>> if (kvm->arch.use_master_clock)
+		 *   - arch/x86/kvm/x86.c|6807| <<kvm_arch_vm_ioctl(KVM_GET_CLOCK)>> user_ns.flags = kvm->arch.use_master_clock ? KVM_CLOCK_TSC_STABLE : 0;
+		 */
 		if (!vcpu->kvm->arch.use_master_clock || vcpu->cpu == -1)
 			kvm_make_request(KVM_REQ_GLOBAL_CLOCK_UPDATE, vcpu);
 		if (vcpu->cpu != cpu)
@@ -4543,6 +5971,14 @@ void kvm_arch_vcpu_load(struct kvm_vcpu *vcpu, int cpu)
 		vcpu->cpu = cpu;
 	}
 
+	/*
+	 * 在以下使用KVM_REQ_STEAL_UPDATE:
+	 *   - arch/x86/kvm/x86.c|3787| <<kvm_set_msr_common(MSR_KVM_STEAL_TIME)>> kvm_make_request(KVM_REQ_STEAL_UPDATE, vcpu);
+	 *   - arch/x86/kvm/x86.c|4733| <<kvm_arch_vcpu_load>> kvm_make_request(KVM_REQ_STEAL_UPDATE, vcpu);
+	 *   - arch/x86/kvm/x86.c|10795| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_STEAL_UPDATE, vcpu))
+	 *
+	 * 处理函数是record_steal_time()
+	 */
 	kvm_make_request(KVM_REQ_STEAL_UPDATE, vcpu);
 }
 
@@ -4561,6 +5997,13 @@ static void kvm_steal_time_set_preempted(struct kvm_vcpu *vcpu)
 	 * when this is true, for example allowing the vCPU to be marked
 	 * preempted if and only if the VM-Exit was due to a host interrupt.
 	 */
+	/*
+	 * 在以下使用kvm_vcpu_arch->at_instruction_boundary:
+	 *   - arch/x86/kvm/svm/svm.c|4585| <<svm_handle_exit_irqoff>> vcpu->arch.at_instruction_boundary = true;
+	 *   - arch/x86/kvm/vmx/vmx.c|6979| <<handle_external_interrupt_irqoff>> vcpu->arch.at_instruction_boundary = true;
+	 *   - arch/x86/kvm/x86.c|4744| <<kvm_steal_time_set_preempted>> if (!vcpu->arch.at_instruction_boundary) {
+	 *   - arch/x86/kvm/x86.c|11223| <<vcpu_run>> vcpu->arch.at_instruction_boundary = false;
+	 */
 	if (!vcpu->arch.at_instruction_boundary) {
 		vcpu->stat.preemption_other++;
 		return;
@@ -4614,22 +6057,53 @@ void kvm_arch_vcpu_put(struct kvm_vcpu *vcpu)
 	}
 
 	static_call(kvm_x86_vcpu_put)(vcpu);
+	/*
+	 * 在以下使用kvm_vcpu_arch->last_host_tsc:
+	 *   - arch/x86/kvm/x86.c|4745| <<kvm_arch_vcpu_load>> s64 tsc_delta = !vcpu->arch.last_host_tsc ? 0 :
+	 *   - arch/x86/kvm/x86.c|4746| <<kvm_arch_vcpu_load>> rdtsc() - vcpu->arch.last_host_tsc;
+	 *   - arch/x86/kvm/x86.c|4857| <<kvm_arch_vcpu_put>> vcpu->arch.last_host_tsc = rdtsc();
+	 *   - arch/x86/kvm/x86.c|12955| <<kvm_arch_hardware_enable>> if (stable && vcpu->arch.last_host_tsc > local_tsc) {
+	 *   - arch/x86/kvm/x86.c|12957| <<kvm_arch_hardware_enable>> if (vcpu->arch.last_host_tsc > max_tsc)
+	 *   - arch/x86/kvm/x86.c|12958| <<kvm_arch_hardware_enable>> max_tsc = vcpu->arch.last_host_tsc;
+	 *   - arch/x86/kvm/x86.c|13007| <<kvm_arch_hardware_enable>> vcpu->arch.last_host_tsc = local_tsc;
+	 */
 	vcpu->arch.last_host_tsc = rdtsc();
 }
 
 static int kvm_vcpu_ioctl_get_lapic(struct kvm_vcpu *vcpu,
 				    struct kvm_lapic_state *s)
 {
+	/*
+	 * 在以下调用kvm_x86_sync_pir_to_irr()
+	 *   - arch/x86/kvm/lapic.c|789| <<apic_has_interrupt_for_ppr>> highest_irr = static_call(kvm_x86_sync_pir_to_irr)(apic->vcpu);
+	 *   - arch/x86/kvm/x86.c|4623| <<kvm_vcpu_ioctl_get_lapic>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 *   - arch/x86/kvm/x86.c|9842| <<vcpu_scan_ioapic>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 *   - arch/x86/kvm/x86.c|10171| <<vcpu_enter_guest>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 *   - arch/x86/kvm/x86.c|10220| <<vcpu_enter_guest>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 */
 	static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
 
 	return kvm_apic_get_state(vcpu, s);
 }
 
+/*
+ * 在以下使用KVM_SET_LAPIC:
+ *   - arch/x86/kvm/x86.c|5200| <<kvm_arch_vcpu_ioctl(KVM_SET_LAPIC)>> r = kvm_vcpu_ioctl_set_lapic(vcpu, u.lapic);
+ *
+ * kvm_arch_vcpu_ioctl(KVM_SET_LAPIC)
+ * -> kvm_vcpu_ioctl_set_lapic()
+ *    -> kvm_apic_set_state()
+ *       -> kvm_recalculate_apic_map() -> 只有kvm_apic_state_fixup() > 0的时候
+ *       -> kvm_recalculate_apic_map()
+ */
 static int kvm_vcpu_ioctl_set_lapic(struct kvm_vcpu *vcpu,
 				    struct kvm_lapic_state *s)
 {
 	int r;
 
+	/*
+	 * 只在此处调用
+	 */
 	r = kvm_apic_set_state(vcpu, s);
 	if (r)
 		return r;
@@ -4640,6 +6114,16 @@ static int kvm_vcpu_ioctl_set_lapic(struct kvm_vcpu *vcpu,
 
 static int kvm_cpu_accept_dm_intr(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下调用kvm_cpu_has_extint():
+	 *   - arch/x86/kvm/irq.c|86| <<kvm_cpu_has_injectable_intr>> if (kvm_cpu_has_extint(v))
+	 *   - arch/x86/kvm/irq.c|115| <<kvm_cpu_has_interrupt>> if (kvm_cpu_has_extint(v))
+	 *   - arch/x86/kvm/irq.c|135| <<kvm_cpu_get_extint>> if (!kvm_cpu_has_extint(v)) {
+	 *   - arch/x86/kvm/x86.c|4850| <<kvm_cpu_accept_dm_intr>> if (kvm_cpu_has_extint(vcpu))
+	 *
+	 * check if there is pending interrupt from
+	 * non-APIC source without intack.
+	 */
 	/*
 	 * We can accept userspace's request for interrupt injection
 	 * as long as we have a place to store the interrupt number.
@@ -4654,6 +6138,11 @@ static int kvm_cpu_accept_dm_intr(struct kvm_vcpu *vcpu)
 		kvm_apic_accept_pic_intr(vcpu));
 }
 
+/*
+ * 在以下使用kvm_vcpu_ready_for_interrupt_injection():
+ *   - arch/x86/kvm/x86.c|9418| <<post_kvm_run_save>> kvm_vcpu_ready_for_interrupt_injection(vcpu);
+ *   - arch/x86/kvm/x86.c|11078| <<vcpu_run>> kvm_vcpu_ready_for_interrupt_injection(vcpu)) {
+ */
 static int kvm_vcpu_ready_for_interrupt_injection(struct kvm_vcpu *vcpu)
 {
 	/*
@@ -4676,6 +6165,15 @@ static int kvm_vcpu_ioctl_interrupt(struct kvm_vcpu *vcpu,
 		return -EINVAL;
 
 	if (!irqchip_in_kernel(vcpu->kvm)) {
+		/*
+		 * 在以下使用kvm_queue_interrupt():
+		 *   - arch/x86/kvm/svm/svm.c|4045| <<svm_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, false);
+		 *   - arch/x86/kvm/svm/svm.c|4048| <<svm_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, true);
+		 *   - arch/x86/kvm/vmx/vmx.c|6768| <<__vmx_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, type == INTR_TYPE_SOFT_INTR);
+		 *   - arch/x86/kvm/x86.c|4713| <<kvm_vcpu_ioctl_interrupt>> kvm_queue_interrupt(vcpu, irq->irq, false);
+		 *   - arch/x86/kvm/x86.c|9490| <<inject_pending_event>> kvm_queue_interrupt(vcpu, irq, false);
+		 *   - arch/x86/kvm/x86.c|11223| <<__set_sregs>> kvm_queue_interrupt(vcpu, pending_vec, false);
+		 */
 		kvm_queue_interrupt(vcpu, irq->irq, false);
 		kvm_make_request(KVM_REQ_EVENT, vcpu);
 		return 0;
@@ -4923,6 +6421,13 @@ static int kvm_vcpu_ioctl_x86_set_vcpu_events(struct kvm_vcpu *vcpu,
 	vcpu->arch.nmi_injected = events->nmi.injected;
 	if (events->flags & KVM_VCPUEVENT_VALID_NMI_PENDING) {
 		vcpu->arch.nmi_pending = 0;
+		/*
+		 * 在以下使用kvm_vcpu_arch->nmi_queued:
+		 *   - arch/x86/kvm/x86.c|874| <<kvm_inject_nmi>> atomic_inc(&vcpu->arch.nmi_queued);
+		 *   - arch/x86/kvm/x86.c|5158| <<kvm_vcpu_ioctl_x86_set_vcpu_events>> atomic_set(&vcpu->arch.nmi_queued, events->nmi.pending);
+		 *   - arch/x86/kvm/x86.c|9855| <<process_nmi>> vcpu->arch.nmi_pending += atomic_xchg(&vcpu->arch.nmi_queued, 0);
+		 *   - arch/x86/kvm/x86.c|12376| <<kvm_vcpu_reset>> atomic_set(&vcpu->arch.nmi_queued, 0);
+		 */
 		atomic_set(&vcpu->arch.nmi_queued, events->nmi.pending);
 		kvm_make_request(KVM_REQ_NMI, vcpu);
 	}
@@ -5068,11 +6573,25 @@ static int kvm_vcpu_ioctl_x86_set_xcrs(struct kvm_vcpu *vcpu,
  * EINVAL is returned when the host attempts to set the flag for a guest that
  * does not support pv clocks.
  */
+/*
+ * 在以下使用kvm_set_guest_paused():
+ *   - arch/x86/kvm/x86.c|6927| <<kvm_arch_vcpu_ioctl(KVM_KVMCLOCK_CTRL)>> r = kvm_set_guest_paused(vcpu);
+ *   - arch/x86/kvm/x86.c|7613| <<kvm_arch_suspend_notifier>> ret = kvm_set_guest_paused(vcpu);
+ */
 static int kvm_set_guest_paused(struct kvm_vcpu *vcpu)
 {
 	if (!vcpu->arch.pv_time_enabled)
 		return -EINVAL;
+	/*
+	 * 在以下使用kvm_vcpu_arch->pvclock_set_guest_stopped_request:
+	 *   - arch/x86/kvm/x86.c|3993| <<kvm_setup_pvclock_page>> if (vcpu->pvclock_set_guest_stopped_request) {
+	 *   - arch/x86/kvm/x86.c|3995| <<kvm_setup_pvclock_page>> vcpu->pvclock_set_guest_stopped_request = false;
+	 *   - arch/x86/kvm/x86.c|6539| <<kvm_set_guest_paused>> vcpu->arch.pvclock_set_guest_stopped_request = tr
+	 */
 	vcpu->arch.pvclock_set_guest_stopped_request = true;
+	/*
+	 * 处理KVM_REQ_CLOCK_UPDATE的函数: kvm_guest_time_update()
+	 */
 	kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
 	return 0;
 }
@@ -5176,6 +6695,13 @@ long kvm_arch_vcpu_ioctl(struct file *filp,
 			goto out_nofree;
 		}
 
+		/*
+		 * kvm_arch_vcpu_ioctl(KVM_SET_LAPIC)
+		 * -> kvm_vcpu_ioctl_set_lapic()
+		 *    -> kvm_apic_set_state()
+		 *       -> kvm_recalculate_apic_map() -> 只有kvm_apic_state_fixup() > 0的时候
+		 *       -> kvm_recalculate_apic_map()
+		 */
 		r = kvm_vcpu_ioctl_set_lapic(vcpu, u.lapic);
 		break;
 	}
@@ -5418,6 +6944,21 @@ long kvm_arch_vcpu_ioctl(struct file *filp,
 		r = -EINVAL;
 		user_tsc_khz = (u32)arg;
 
+		/*
+		 * 在以下设置kvm_has_tsc_control:
+		 *   - arch/x86/kvm/svm/svm.c|1115| <<svm_hardware_setup>> kvm_has_tsc_control = true;
+		 *   - arch/x86/kvm/vmx/vmx.c|8787| <<hardware_setup>> kvm_has_tsc_control = true;
+		 * 在以下使用kvm_has_tsc_control:
+		 *   - arch/x86/kvm/debugfs.c|69| <<kvm_arch_create_vcpu_debugfs>> if (kvm_has_tsc_control) {
+		 *   - arch/x86/kvm/vmx/nested.c|2581| <<prepare_vmcs02>> if (kvm_has_tsc_control)
+		 *   - arch/x86/kvm/vmx/nested.c|4680| <<nested_vmx_vmexit>> if (kvm_has_tsc_control)
+		 *   - arch/x86/kvm/x86.c|2579| <<set_tsc_khz>> if (!kvm_has_tsc_control) {
+		 *   - arch/x86/kvm/x86.c|2843| <<kvm_vcpu_write_tsc_multiplier>> if (kvm_has_tsc_control)
+		 *   - arch/x86/kvm/x86.c|3607| <<kvm_guest_time_update>> if (kvm_has_tsc_control)
+		 *   - arch/x86/kvm/x86.c|4951| <<kvm_vm_ioctl_check_extension>> r = kvm_has_tsc_control;
+		 *   - arch/x86/kvm/x86.c|6207| <<kvm_arch_vcpu_ioctl(KVM_SET_TSC_KHZ)>> if (kvm_has_tsc_control &
+		 *   - arch/x86/kvm/x86.c|13736| <<kvm_arch_hardware_setup>> if (kvm_has_tsc_control) {
+		 */
 		if (kvm_has_tsc_control &&
 		    user_tsc_khz >= kvm_max_guest_tsc_khz)
 			goto out;
@@ -5431,6 +6972,24 @@ long kvm_arch_vcpu_ioctl(struct file *filp,
 		goto out;
 	}
 	case KVM_GET_TSC_KHZ: {
+		/*
+		 * 在以下设置kvm_vcpu_arch->virtual_tsc_khz:
+		 *   - arch/x86/kvm/x86.c|2561| <<kvm_set_tsc_khz>> vcpu->arch.virtual_tsc_khz = user_tsc_khz;
+		 * 在以下使用kvm_vcpu_arch->virtual_tsc_khz:
+		 *   - arch/x86/kvm/hyperv.c|1697| <<kvm_hv_get_msr>> data = (u64)vcpu->arch.virtual_tsc_khz * 1000;
+		 *   - arch/x86/kvm/lapic.c|2843| <<__wait_lapic_expire>> do_div(delay_ns, vcpu->arch.virtual_tsc_khz);
+		 *   - arch/x86/kvm/lapic.c|2863| <<adjust_lapic_timer_advance>> do_div(ns, vcpu->arch.virtual_tsc_khz);
+		 *   - arch/x86/kvm/lapic.c|2868| <<adjust_lapic_timer_advance>> do_div(ns, vcpu->arch.virtual_tsc_khz);
+		 *   - arch/x86/kvm/lapic.c|3002| <<start_sw_tscdeadline>> unsigned long this_tsc_khz = vcpu->arch.virtual_tsc_khz;
+		 *   - arch/x86/kvm/vmx/nested.c|2111| <<vmx_start_preemption_timer>> if (vcpu->arch.virtual_tsc_khz == 0)
+		 *   - arch/x86/kvm/vmx/nested.c|2116| <<vmx_start_preemption_timer>> do_div(preemption_timeout, vcpu->arch.virtual_tsc_khz);
+		 *   - arch/x86/kvm/vmx/nested.c|4059| <<vmx_get_preemption_timer_value>> value = ktime_to_ns(remaining) * vcpu->arch.virtual_tsc_khz;
+		 *   - arch/x86/kvm/x86.c|2775| <<kvm_synchronize_tsc>> if (vcpu->arch.virtual_tsc_khz) {
+		 *   - arch/x86/kvm/x86.c|2786| <<kvm_synchronize_tsc>> u64 tsc_hz = vcpu->arch.virtual_tsc_khz * 1000LL;
+		 *   - arch/x86/kvm/x86.c|2804| <<kvm_synchronize_tsc>> vcpu->arch.virtual_tsc_khz == kvm->arch.last_tsc_khz) {
+		 *   - arch/x86/kvm/x86.c|2837| <<kvm_synchronize_tsc>> kvm->arch.last_tsc_khz = vcpu->arch.virtual_tsc_khz;
+		 *   - arch/x86/kvm/x86.c|5786| <<kvm_arch_vcpu_ioctl(KVM_GET_TSC_KHZ)>> r = vcpu->arch.virtual_tsc_khz;
+		 */
 		r = vcpu->arch.virtual_tsc_khz;
 		goto out;
 	}
@@ -5794,6 +7353,14 @@ int kvm_vm_ioctl_enable_cap(struct kvm *kvm,
 		smp_wmb();
 		kvm->arch.irqchip_mode = KVM_IRQCHIP_SPLIT;
 		kvm->arch.nr_reserved_ioapic_pins = cap->args[0];
+		/*
+		 * 在以下使用kvm_clear_apicv_inhibit():
+		 *   - arch/x86/kvm/i8254.c|314| <<kvm_pit_set_reinject>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_PIT_REINJ);
+		 *   - arch/x86/kvm/lapic.c|579| <<kvm_recalculate_apic_map>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_APIC_ID_MODIFIED);
+		 *   - arch/x86/kvm/svm/svm.c|3235| <<interrupt_window_interception>> kvm_clear_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+		 *   - arch/x86/kvm/x86.c|6050| <<kvm_vm_ioctl_enable_cap(KVM_CAP_SPLIT_IRQCHIP)>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
+		 *   - arch/x86/kvm/x86.c|6465| <<kvm_arch_vm_ioctl(KVM_CREATE_IRQCHIP)>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
+		 */
 		kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
 		r = 0;
 split_irqchip_unlock:
@@ -5805,8 +7372,28 @@ int kvm_vm_ioctl_enable_cap(struct kvm *kvm,
 		if (cap->args[0] & ~KVM_X2APIC_API_VALID_FLAGS)
 			break;
 
+		/*
+		 * 在以下使用kvm_arch->x2apic_format:
+		 *   - arch/x86/kvm/irq_comm.c|137| <<kvm_set_msi_irq>> trace_kvm_msi_set_irq(msg.address_lo | (kvm->arch.x2apic_format ?
+		 *   - arch/x86/kvm/irq_comm.c|140| <<kvm_set_msi_irq>> irq->dest_id = x86_msi_msg_get_destid(&msg, kvm->arch.x2apic_format);
+		 *   - arch/x86/kvm/irq_comm.c|154| <<kvm_msi_route_invalid>> return kvm->arch.x2apic_format && (e->msi.address_hi & 0xff);
+		 *   - arch/x86/kvm/lapic.c|3673| <<kvm_apic_state_fixup>> if (vcpu->kvm->arch.x2apic_format) {
+		 *   - arch/x86/kvm/x86.c|5933| <<kvm_vm_ioctl_enable_cap>> kvm->arch.x2apic_format = true;
+		 *
+		 *     x2apic_format = false,
+		 *     x2apic_broadcast_quirk_disabled = false,
+		 */
 		if (cap->args[0] & KVM_X2APIC_API_USE_32BIT_IDS)
 			kvm->arch.x2apic_format = true;
+		/*
+		 * 在以下使用kvm_arch->x2apic_broadcast_quirk_disabled:
+		 *   - arch/x86/kvm/lapic.c|1356| <<kvm_apic_mda>> if (!vcpu->kvm->arch.x2apic_broadcast_quirk_disabled &&
+		 *   - arch/x86/kvm/lapic.c|1435| <<kvm_apic_is_broadcast_dest>> if (kvm->arch.x2apic_broadcast_quirk_disabled) {
+		 *   - arch/x86/kvm/x86.c|5935| <<kvm_vm_ioctl_enable_cap>> kvm->arch.x2apic_broadcast_quirk_disabled = true;
+		 *
+		 *     x2apic_format = false,
+		 *     x2apic_broadcast_quirk_disabled = false,
+		 */
 		if (cap->args[0] & KVM_X2APIC_API_DISABLE_BROADCAST_QUIRK)
 			kvm->arch.x2apic_broadcast_quirk_disabled = true;
 
@@ -6189,6 +7776,14 @@ long kvm_arch_vm_ioctl(struct file *filp,
 		/* Write kvm->irq_routing before enabling irqchip_in_kernel. */
 		smp_wmb();
 		kvm->arch.irqchip_mode = KVM_IRQCHIP_KERNEL;
+		/*
+		 * 在以下使用kvm_clear_apicv_inhibit():
+		 *   - arch/x86/kvm/i8254.c|314| <<kvm_pit_set_reinject>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_PIT_REINJ);
+		 *   - arch/x86/kvm/lapic.c|579| <<kvm_recalculate_apic_map>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_APIC_ID_MODIFIED);
+		 *   - arch/x86/kvm/svm/svm.c|3235| <<interrupt_window_interception>> kvm_clear_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+		 *   - arch/x86/kvm/x86.c|6050| <<kvm_vm_ioctl_enable_cap(KVM_CAP_SPLIT_IRQCHIP)>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
+		 *   - arch/x86/kvm/x86.c|6465| <<kvm_arch_vm_ioctl(KVM_CREATE_IRQCHIP)>> kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
+		 */
 		kvm_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_ABSENT);
 	create_irqchip_unlock:
 		mutex_unlock(&kvm->lock);
@@ -6363,6 +7958,13 @@ long kvm_arch_vm_ioctl(struct file *filp,
 #endif
 	case KVM_SET_CLOCK: {
 		struct kvm_arch *ka = &kvm->arch;
+		/*
+		 * struct kvm_clock_data {
+		 *     __u64 clock;
+		 *     __u32 flags;
+		 *     __u32 pad[9];
+		 * };
+		 */
 		struct kvm_clock_data user_ns;
 		u64 now_ns;
 
@@ -6375,6 +7977,17 @@ long kvm_arch_vm_ioctl(struct file *filp,
 			goto out;
 
 		r = 0;
+		/*
+		 * 在以下使用pvclock_update_vm_gtod_copy()来重新计算master clock!
+		 *   - arch/x86/kvm/x86.c|3110| <<kvm_gen_update_masterclock>> pvclock_update_vm_gtod_copy(kvm);
+		 *   - arch/x86/kvm/x86.c|8999| <<kvm_hyperv_tsc_notifier>> pvclock_update_vm_gtod_copy(kvm);
+		 *   - arch/x86/kvm/x86.c|13281| <<kvm_arch_init_vm>> pvclock_update_vm_gtod_copy(kvm);
+		 *
+		 *
+		 * 在以下使用kvm_gen_update_masterclock():
+		 *   - arch/x86/kvm/x86.c|6771| <<kvm_arch_vm_ioctl(KVM_SET_CLOCK)>> kvm_gen_update_masterclock(kvm);
+		 *   - arch/x86/kvm/x86.c|10880| <<vcpu_enter_guest(KVM_REQ_MASTERCLOCK_UPDATE)>> kvm_gen_update_masterclock(vcpu->kvm);
+		 */
 		/*
 		 * TODO: userspace has to take care of races with VCPU_RUN, so
 		 * kvm_gen_update_masterclock() can be cut down to locked
@@ -6382,6 +7995,16 @@ long kvm_arch_vm_ioctl(struct file *filp,
 		 */
 		kvm_gen_update_masterclock(kvm);
 
+		/*
+		 * 使用kvm_arch->pvclock_gtod_sync_lock的函数:
+		 *   - kvm_synchronize_tsc()
+		 *   - kvm_gen_update_masterclock()
+		 *   - get_kvmclock_ns()
+		 *   - kvm_guest_time_update()
+		 *   - kvm_arch_vm_ioctl(KVM_SET_CLOCK)
+		 *   - kvm_hyperv_tsc_notifier()
+		 *   - kvm_arch_init_vm()
+		 */
 		/*
 		 * This pairs with kvm_guest_time_update(): when masterclock is
 		 * in use, we use master_kernel_ns + kvmclock_offset to set
@@ -6390,22 +8013,94 @@ long kvm_arch_vm_ioctl(struct file *filp,
 		 * 'system_time' when 'user_ns.clock' is very small.
 		 */
 		raw_spin_lock_irq(&ka->pvclock_gtod_sync_lock);
+		/*
+		 * 在以下设置kvm_arch->use_master_clock:
+		 *   - arch/x86/kvm/x86.c|3073| <<pvclock_update_vm_gtod_copy>> ka->use_master_clock = host_tsc_clocksource && vcpus_matched
+		 * 在以下使用kvm_arch->use_master_clock:
+		 *   - arch/x86/kvm/x86.c|2620| <<kvm_track_tsc_matching>> if ((ka->use_master_clock && new_generation) ||
+		 *   - arch/x86/kvm/x86.c|2621| <<kvm_track_tsc_matching>> (ka->use_master_clock != use_master_clock))
+		 *   - arch/x86/kvm/x86.c|2626| <<kvm_track_tsc_matching>> ka->use_master_clock, gtod->clock.vclock_mode);
+		 *   - arch/x86/kvm/x86.c|3077| <<pvclock_update_vm_gtod_copy>> if (ka->use_master_clock)
+		 *   - arch/x86/kvm/x86.c|3081| <<pvclock_update_vm_gtod_copy>> trace_kvm_update_master_clock(ka->use_master_clock, vclock_mode,
+		 *   - arch/x86/kvm/x86.c|3130| <<get_kvmclock_ns>> if (!ka->use_master_clock) {
+		 *   - arch/x86/kvm/x86.c|3232| <<kvm_guest_time_update>> use_master_clock = ka->use_master_clock;
+		 *   - arch/x86/kvm/x86.c|4817| <<kvm_arch_vcpu_load>> if (!vcpu->kvm->arch.use_master_clock || vcpu->cpu == -1)
+		 *   - arch/x86/kvm/x86.c|6791| <<kvm_arch_vm_ioctl(KVM_SET_CLOCK)>> if (kvm->arch.use_master_clock)
+		 *   - arch/x86/kvm/x86.c|6807| <<kvm_arch_vm_ioctl(KVM_GET_CLOCK)>> user_ns.flags = kvm->arch.use_master_clock ? KVM_CLOCK_TSC_STABLE : 0;
+		 *
+		 * 在以下设置kvm_arch->master_kernel_ns:
+		 *   - arch/x86/kvm/x86.c|3070| <<pvclock_update_vm_gtod_copy>> &ka->master_kernel_ns,
+		 *   - arch/x86/kvm/x86.c|3145| <<get_kvmclock_ns>> hv_clock.system_time = ka->master_kernel_ns + ka->kvmclock_offset;
+		 *   - arch/x86/kvm/x86.c|3254| <<kvm_guest_time_update>> kernel_ns = ka->master_kernel_ns;
+		 *   - arch/x86/kvm/x86.c|6811| <<kvm_arch_vm_ioctl>> now_ns = ka->master_kernel_ns;
+		 *
+		 * 在以下使用kvm_arch->master_cycle_now:
+		 *   - arch/x86/kvm/x86.c|3071| <<pvclock_update_vm_gtod_copy>> host_tsc_clocksource =
+		 *               kvm_get_time_and_clockread(&ka->master_kernel_ns, &ka->master_cycle_now);
+		 *   - arch/x86/kvm/x86.c|3144| <<get_kvmclock_ns>> hv_clock.tsc_timestamp = ka->master_cycle_now;
+		 *   - arch/x86/kvm/x86.c|3253| <<kvm_guest_time_update>> host_tsc = ka->master_cycle_now;
+		 */
 		if (kvm->arch.use_master_clock)
 			now_ns = ka->master_kernel_ns;
 		else
 			now_ns = get_kvmclock_base_ns();
+		/*
+		 * 在以下设置kvm_arch->kvmclock_offset:
+		 *   - arch/x86/kvm/x86.c|6814| <<kvm_arch_vm_ioctl(KVM_SET_CLOCK)>> ka->kvmclock_offset = user_ns.clock - now_ns;
+		 *   - arch/x86/kvm/x86.c|13280| <<kvm_arch_init_vm>> kvm->arch.kvmclock_offset = -get_kvmclock_base_ns();
+		 * 在以下使用kvm_arch->kvmclock_offset:
+		 *   - arch/x86/kvm/pmu.c|342| <<kvm_pmu_rdpmc_vmware>> ctr_val = ktime_get_boottime_ns() + vcpu->kvm->arch.kvmclock_offset;
+		 *   - arch/x86/kvm/x86.c|3141| <<get_kvmclock_ns>> return get_kvmclock_base_ns() + ka->kvmclock_offset;
+		 *   - arch/x86/kvm/x86.c|3145| <<get_kvmclock_ns>> hv_clock.system_time = ka->master_kernel_ns + ka->kvmclock_offset;
+		 *   - arch/x86/kvm/x86.c|3167| <<get_kvmclock_ns>> ret = get_kvmclock_base_ns() + ka->kvmclock_offset;
+		 *   - arch/x86/kvm/x86.c|3307| <<kvm_guest_time_update>> vcpu->hv_clock.system_time = kernel_ns + v->kvm->arch.kvmclock_offset;
+		 */
 		ka->kvmclock_offset = user_ns.clock - now_ns;
 		raw_spin_unlock_irq(&ka->pvclock_gtod_sync_lock);
 
+		/*
+		 * 处理KVM_REQ_CLOCK_UPDATE的函数: kvm_guest_time_update()
+		 */
 		kvm_make_all_cpus_request(kvm, KVM_REQ_CLOCK_UPDATE);
 		break;
 	}
 	case KVM_GET_CLOCK: {
+		/*
+		 * struct kvm_clock_data {
+		 *     __u64 clock;
+		 *     __u32 flags;
+		 *     __u32 pad[9];
+		 * };
+		 */
 		struct kvm_clock_data user_ns;
 		u64 now_ns;
 
+		/*
+		 * 在以下使用get_kvmclock_ns():
+		 *   - arch/x86/kvm/hyperv.c|588| <<get_time_ref_counter>> return div_u64(get_kvmclock_ns(kvm), 100);
+		 *   - arch/x86/kvm/x86.c|2413| <<kvm_write_wall_clock>> wall_nsec = ktime_get_real_ns() - get_kvmclock_ns(kvm);
+		 *   - arch/x86/kvm/x86.c|6805| <<kvm_arch_vm_ioctl(KVM_GET_CLOCK)>> now_ns = get_kvmclock_ns(kvm);
+		 *   - arch/x86/kvm/xen.c|68| <<kvm_xen_update_runstate>> u64 now = get_kvmclock_ns(v->kvm);
+		 *   - arch/x86/kvm/xen.c|455| <<kvm_xen_vcpu_set_attr>> if (get_kvmclock_ns(vcpu->kvm) <
+		 *   - arch/x86/kvm/xen.c|496| <<kvm_xen_vcpu_set_attr>> if (get_kvmclock_ns(vcpu->kvm) <
+		 */
 		now_ns = get_kvmclock_ns(kvm);
 		user_ns.clock = now_ns;
+		/*
+		 *  在以下设置kvm_arch->use_master_clock:
+		 *   - arch/x86/kvm/x86.c|3073| <<pvclock_update_vm_gtod_copy>> ka->use_master_clock = host_tsc_clocksource && vcpus_matched
+		 * 在以下使用kvm_arch->use_master_clock:
+		 *   - arch/x86/kvm/x86.c|2620| <<kvm_track_tsc_matching>> if ((ka->use_master_clock && new_generation) ||
+		 *   - arch/x86/kvm/x86.c|2621| <<kvm_track_tsc_matching>> (ka->use_master_clock != use_master_clock))
+		 *   - arch/x86/kvm/x86.c|2626| <<kvm_track_tsc_matching>> ka->use_master_clock, gtod->clock.vclock_mode);
+		 *   - arch/x86/kvm/x86.c|3077| <<pvclock_update_vm_gtod_copy>> if (ka->use_master_clock)
+		 *   - arch/x86/kvm/x86.c|3081| <<pvclock_update_vm_gtod_copy>> trace_kvm_update_master_clock(ka->use_master_clock, vclock_mode,
+		 *   - arch/x86/kvm/x86.c|3130| <<get_kvmclock_ns>> if (!ka->use_master_clock) {
+		 *   - arch/x86/kvm/x86.c|3232| <<kvm_guest_time_update>> use_master_clock = ka->use_master_clock;
+		 *   - arch/x86/kvm/x86.c|4817| <<kvm_arch_vcpu_load>> if (!vcpu->kvm->arch.use_master_clock || vcpu->cpu == -1)
+		 *   - arch/x86/kvm/x86.c|6791| <<kvm_arch_vm_ioctl(KVM_SET_CLOCK)>> if (kvm->arch.use_master_clock)
+		 *   - arch/x86/kvm/x86.c|6807| <<kvm_arch_vm_ioctl(KVM_GET_CLOCK)>> user_ns.flags = kvm->arch.use_master_clock ? KVM_CLOCK_TSC_STABLE : 0;
+		 */
 		user_ns.flags = kvm->arch.use_master_clock ? KVM_CLOCK_TSC_STABLE : 0;
 		memset(&user_ns.pad, 0, sizeof(user_ns.pad));
 
@@ -7137,6 +8832,18 @@ static int emulator_cmpxchg_emulated(struct x86_emulate_ctxt *ctxt,
 	    (gpa & PAGE_MASK) == APIC_DEFAULT_PHYS_BASE)
 		goto emul_write;
 
+	/*
+	 * 在以下使用X86_FEATURE_SPLIT_LOCK_DETECT:
+	 *   - arch/x86/kernel/cpu/intel.c|1149| <<sld_state_setup>> if (!boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) &&
+	 *   - arch/x86/kernel/cpu/intel.c|1221| <<__split_lock_setup>> setup_force_cpu_cap(X86_FEATURE_SPLIT_LOCK_DETECT);
+	 *   - arch/x86/kernel/cpu/intel.c|1475| <<bus_lock_init>> if ((boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) &&
+	 *   - arch/x86/kernel/cpu/intel.c|1621| <<sld_state_show>> !boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 *   - arch/x86/kernel/cpu/intel.c|1643| <<sld_state_show>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1653| <<sld_state_show>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT)) {
+	 *   - arch/x86/kernel/cpu/intel.c|1657| <<sld_state_show>> boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT) ?
+	 *   - arch/x86/kvm/vmx/vmx.c|4917| <<vmx_guest_inject_ac>> if (!boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 *   - arch/x86/kvm/x86.c|7297| <<emulator_cmpxchg_emulated>> if (boot_cpu_has(X86_FEATURE_SPLIT_LOCK_DETECT))
+	 */
 	/*
 	 * Emulate the atomic as a straight write to avoid #AC if SLD is
 	 * enabled in the host and the access splits a cache line.
@@ -8510,10 +10217,35 @@ EXPORT_SYMBOL_GPL(kvm_fast_pio);
 
 static int kvmclock_cpu_down_prep(unsigned int cpu)
 {
+	/*
+	 * 在以下设置cpu_tsc_khz (percpu):
+	 *   - arch/x86/kvm/x86.c|9664| <<kvmclock_cpu_down_prep>> __this_cpu_write(cpu_tsc_khz, 0);
+	 *   - arch/x86/kvm/x86.c|9679| <<tsc_khz_changed>> __this_cpu_write(cpu_tsc_khz, khz);
+	 *   - arch/x86/kvm/x86.c|9698| <<kvm_hyperv_tsc_notifier>> per_cpu(cpu_tsc_khz, cpu) = tsc_khz;
+	 * 在以下使用cpu_tsc_khz (percpu):
+	 *   - arch/x86/kvm/x86.c|2589| <<global>> static DEFINE_PER_CPU(unsigned long , cpu_tsc_khz);
+	 *   - arch/x86/kvm/x86.c|3608| <<get_kvmclock_ns>> if (__this_cpu_read(cpu_tsc_khz)) {
+	 *   - arch/x86/kvm/x86.c|3609| <<get_kvmclock_ns>> kvm_get_time_scale(NSEC_PER_SEC, __this_cpu_read(cpu_tsc_khz) * 1000LL,
+	 *   - arch/x86/kvm/x86.c|3765| <<kvm_guest_time_update>> tgt_tsc_khz = __this_cpu_read(cpu_tsc_khz);
+	 */
 	__this_cpu_write(cpu_tsc_khz, 0);
 	return 0;
 }
 
+/*
+ * [0] tsc_khz_changed
+ * [0] kvmclock_cpu_online
+ * [0] cpuhp_invoke_callback
+ * [0] cpuhp_thread_fun
+ * [0] smpboot_thread_fn
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * 在以下使用tsc_khz_changed():
+ *   - arch/x86/kvm/x86.c|9769| <<__kvmclock_cpufreq_notifier>> smp_call_function_single(cpu, tsc_khz_changed, freq, 1);
+ *   - arch/x86/kvm/x86.c|9799| <<__kvmclock_cpufreq_notifier>> smp_call_function_single(cpu, tsc_khz_changed, freq, 1);
+ *   - arch/x86/kvm/x86.c|9826| <<kvmclock_cpu_online>> tsc_khz_changed(NULL);
+ */
 static void tsc_khz_changed(void *data)
 {
 	struct cpufreq_freqs *freq = data;
@@ -8525,6 +10257,17 @@ static void tsc_khz_changed(void *data)
 		khz = cpufreq_quick_get(raw_smp_processor_id());
 	if (!khz)
 		khz = tsc_khz;
+	/*
+	 * 在以下设置cpu_tsc_khz (percpu):
+	 *   - arch/x86/kvm/x86.c|9664| <<kvmclock_cpu_down_prep>> __this_cpu_write(cpu_tsc_khz, 0);
+	 *   - arch/x86/kvm/x86.c|9679| <<tsc_khz_changed>> __this_cpu_write(cpu_tsc_khz, khz);
+	 *   - arch/x86/kvm/x86.c|9698| <<kvm_hyperv_tsc_notifier>> per_cpu(cpu_tsc_khz, cpu) = tsc_khz;
+	 * 在以下使用cpu_tsc_khz (percpu):
+	 *   - arch/x86/kvm/x86.c|2589| <<global>> static DEFINE_PER_CPU(unsigned long , cpu_tsc_khz);
+	 *   - arch/x86/kvm/x86.c|3608| <<get_kvmclock_ns>> if (__this_cpu_read(cpu_tsc_khz)) {
+	 *   - arch/x86/kvm/x86.c|3609| <<get_kvmclock_ns>> kvm_get_time_scale(NSEC_PER_SEC, __this_cpu_read(cpu_tsc_khz) * 1000LL,
+	 *   - arch/x86/kvm/x86.c|3765| <<kvm_guest_time_update>> tgt_tsc_khz = __this_cpu_read(cpu_tsc_khz);
+	 */
 	__this_cpu_write(cpu_tsc_khz, khz);
 }
 
@@ -8551,6 +10294,12 @@ static void kvm_hyperv_tsc_notifier(void)
 		struct kvm_arch *ka = &kvm->arch;
 
 		raw_spin_lock_irqsave(&ka->pvclock_gtod_sync_lock, flags);
+		/*
+		 * 在以下使用pvclock_update_vm_gtod_copy():
+		 *   - arch/x86/kvm/x86.c|3110| <<kvm_gen_update_masterclock>> pvclock_update_vm_gtod_copy(kvm);
+		 *   - arch/x86/kvm/x86.c|8999| <<kvm_hyperv_tsc_notifier>> pvclock_update_vm_gtod_copy(kvm);
+		 *   - arch/x86/kvm/x86.c|13281| <<kvm_arch_init_vm>> pvclock_update_vm_gtod_copy(kvm);
+		 */
 		pvclock_update_vm_gtod_copy(kvm);
 		raw_spin_unlock_irqrestore(&ka->pvclock_gtod_sync_lock, flags);
 
@@ -8616,6 +10365,9 @@ static void __kvmclock_cpufreq_notifier(struct cpufreq_freqs *freq, int cpu)
 		kvm_for_each_vcpu(i, vcpu, kvm) {
 			if (vcpu->cpu != cpu)
 				continue;
+			/*
+			 * 处理KVM_REQ_CLOCK_UPDATE的函数: kvm_guest_time_update()
+			 */
 			kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
 			if (vcpu->cpu != raw_smp_processor_id())
 				send_ipi = 1;
@@ -8738,6 +10490,15 @@ static struct perf_guest_info_callbacks kvm_guest_cbs = {
 };
 
 #ifdef CONFIG_X86_64
+/*
+ * 在以下使用pvclock_gtod_work:
+ *   - arch/x86/kvm/x86.c|9564| <<global>> static DECLARE_WORK(pvclock_gtod_work, pvclock_gtod_update_fn);
+ *   - arch/x86/kvm/x86.c|9573| <<pvclock_irq_work_fn>> queue_work(system_long_wq, &pvclock_gtod_work);
+ *   - arch/x86/kvm/x86.c|9698| <<kvm_arch_exit>> cancel_work_sync(&pvclock_gtod_work);
+ *
+ * 在以下使用pvclock_gtod_update_fn():
+ *   - arch/x86/kvm/x86.c|9564| <<global>> static DECLARE_WORK(pvclock_gtod_work, pvclock_gtod_update_fn);
+ */
 static void pvclock_gtod_update_fn(struct work_struct *work)
 {
 	struct kvm *kvm;
@@ -8746,13 +10507,38 @@ static void pvclock_gtod_update_fn(struct work_struct *work)
 	int i;
 
 	mutex_lock(&kvm_lock);
+	/*
+	 * 在以下使用KVM_REQ_MASTERCLOCK_UPDATE():
+	 *   - arch/x86/kvm/hyperv.c|1411| <<kvm_hv_set_msr_pw>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+	 *   - arch/x86/kvm/x86.c|2444| <<kvm_write_system_time>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+	 *   - arch/x86/kvm/x86.c|2647| <<kvm_track_tsc_matching>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+	 *   - arch/x86/kvm/x86.c|9496| <<pvclock_gtod_update_fn>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+	 *   - arch/x86/kvm/x86.c|11224| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu))
+	 *   - arch/x86/kvm/x86.c|13427| <<kvm_arch_hardware_enable>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+	 *   - arch/x86/kvm/xen.c|58| <<kvm_xen_shared_info_init>> kvm_make_all_cpus_request(kvm, KVM_REQ_MASTERCLOCK_UPDATE);
+	 *
+	 * 处理KVM_REQ_MASTERCLOCK_UPDATE的函数: kvm_gen_update_masterclock()
+	 */
 	list_for_each_entry(kvm, &vm_list, vm_list)
 		kvm_for_each_vcpu(i, vcpu, kvm)
 			kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+	/*
+	 * 在以下使用kvm_guest_has_master_clock:
+	 *    - arch/x86/kvm/x86.c|2500| <<global>> static atomic_t kvm_guest_has_master_clock = ATOMIC_INIT(0);
+	 *    - arch/x86/kvm/x86.c|3144| <<pvclock_update_vm_gtod_copy>> atomic_set(&kvm_guest_has_master_clock, 1);
+	 *    - arch/x86/kvm/x86.c|9560| <<pvclock_gtod_update_fn>> atomic_set(&kvm_guest_has_master_clock, 0);
+	 *    - arch/x86/kvm/x86.c|9595| <<pvclock_gtod_notify>> atomic_read(&kvm_guest_has_master_clock) != 0)
+	 */
 	atomic_set(&kvm_guest_has_master_clock, 0);
 	mutex_unlock(&kvm_lock);
 }
 
+/*
+ * 在以下使用pvclock_gtod_work:
+ *   - arch/x86/kvm/x86.c|9564| <<global>> static DECLARE_WORK(pvclock_gtod_work, pvclock_gtod_update_fn);
+ *   - arch/x86/kvm/x86.c|9573| <<pvclock_irq_work_fn>> queue_work(system_long_wq, &pvclock_gtod_work);
+ *   - arch/x86/kvm/x86.c|9698| <<kvm_arch_exit>> cancel_work_sync(&pvclock_gtod_work);
+ */
 static DECLARE_WORK(pvclock_gtod_work, pvclock_gtod_update_fn);
 
 /*
@@ -8762,9 +10548,21 @@ static DECLARE_WORK(pvclock_gtod_work, pvclock_gtod_update_fn);
  */
 static void pvclock_irq_work_fn(struct irq_work *w)
 {
+	/*
+	 * 在以下使用pvclock_gtod_work:
+	 *   - arch/x86/kvm/x86.c|9564| <<global>> static DECLARE_WORK(pvclock_gtod_work, pvclock_gtod_update_fn);
+	 *   - arch/x86/kvm/x86.c|9573| <<pvclock_irq_work_fn>> queue_work(system_long_wq, &pvclock_gtod_work);
+	 *   - arch/x86/kvm/x86.c|9698| <<kvm_arch_exit>> cancel_work_sync(&pvclock_gtod_work);
+	 */
 	queue_work(system_long_wq, &pvclock_gtod_work);
 }
 
+/*
+ * 在以下使用pvclock_irq_work:
+ *   - arch/x86/kvm/x86.c|9576| <<global>> static DEFINE_IRQ_WORK(pvclock_irq_work, pvclock_irq_work_fn);
+ *   - arch/x86/kvm/x86.c|9596| <<pvclock_gtod_notify>> irq_work_queue(&pvclock_irq_work);
+ *   - arch/x86/kvm/x86.c|9697| <<kvm_arch_exit>> irq_work_sync(&pvclock_irq_work);
+ */
 static DEFINE_IRQ_WORK(pvclock_irq_work, pvclock_irq_work_fn);
 
 /*
@@ -8776,6 +10574,9 @@ static int pvclock_gtod_notify(struct notifier_block *nb, unsigned long unused,
 	struct pvclock_gtod_data *gtod = &pvclock_gtod_data;
 	struct timekeeper *tk = priv;
 
+	/*
+	 * 只在以下调用
+	 */
 	update_pvclock_gtod(tk);
 
 	/*
@@ -8783,12 +10584,29 @@ static int pvclock_gtod_notify(struct notifier_block *nb, unsigned long unused,
 	 * TSC based clocksource. Delegate queue_work() to irq_work as
 	 * this is invoked with tk_core.seq write held.
 	 */
+	/*
+	 * 在以下使用kvm_guest_has_master_clock:
+	 *    - arch/x86/kvm/x86.c|2500| <<global>> static atomic_t kvm_guest_has_master_clock = ATOMIC_INIT(0);
+	 *    - arch/x86/kvm/x86.c|3144| <<pvclock_update_vm_gtod_copy>> atomic_set(&kvm_guest_has_master_clock, 1);
+	 *    - arch/x86/kvm/x86.c|9560| <<pvclock_gtod_update_fn>> atomic_set(&kvm_guest_has_master_clock, 0);
+	 *    - arch/x86/kvm/x86.c|9595| <<pvclock_gtod_notify>> atomic_read(&kvm_guest_has_master_clock) != 0)
+	 *
+	 * 在以下使用pvclock_irq_work:
+	 *   - arch/x86/kvm/x86.c|9576| <<global>> static DEFINE_IRQ_WORK(pvclock_irq_work, pvclock_irq_work_fn);
+	 *   - arch/x86/kvm/x86.c|9596| <<pvclock_gtod_notify>> irq_work_queue(&pvclock_irq_work);
+	 *   - arch/x86/kvm/x86.c|9697| <<kvm_arch_exit>> irq_work_sync(&pvclock_irq_work);
+	 */
 	if (!gtod_is_based_on_tsc(gtod->clock.vclock_mode) &&
 	    atomic_read(&kvm_guest_has_master_clock) != 0)
 		irq_work_queue(&pvclock_irq_work);
 	return 0;
 }
 
+/*
+ * 在以下使用pvclock_gtod_notifier:
+ *   - arch/x86/kvm/x86.c|9667| <<kvm_arch_init>> pvclock_gtod_register_notifier(&pvclock_gtod_notifier);
+ *   - arch/x86/kvm/x86.c|9696| <<kvm_arch_exit>> pvclock_gtod_unregister_notifier(&pvclock_gtod_notifier);
+ */
 static struct notifier_block pvclock_gtod_notifier = {
 	.notifier_call = pvclock_gtod_notify,
 };
@@ -8937,6 +10755,10 @@ int kvm_emulate_ap_reset_hold(struct kvm_vcpu *vcpu)
 EXPORT_SYMBOL_GPL(kvm_emulate_ap_reset_hold);
 
 #ifdef CONFIG_X86_64
+/*
+ * 模拟KVM_HC_CLOCK_PAIRING():
+ *   - arch/x86/kvm/x86.c|10794| <<kvm_emulate_hypercall>> ret = kvm_pv_clock_pairing(vcpu, a0, a1);
+ */
 static int kvm_pv_clock_pairing(struct kvm_vcpu *vcpu, gpa_t paddr,
 			        unsigned long clock_type)
 {
@@ -8960,6 +10782,21 @@ static int kvm_pv_clock_pairing(struct kvm_vcpu *vcpu, gpa_t paddr,
 
 	clock_pairing.sec = ts.tv_sec;
 	clock_pairing.nsec = ts.tv_nsec;
+	/*
+	 * 在以下使用kvm_read_l1_tsc():
+	 *   - arch/x86/kvm/hyperv.c|591| <<get_time_ref_counter>> tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 *   - arch/x86/kvm/lapic.c|2899| <<__kvm_wait_lapic_expire>> guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 *   - arch/x86/kvm/lapic.c|2917| <<__kvm_wait_lapic_expire>> guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 *   - arch/x86/kvm/lapic.c|3027| <<start_sw_tscdeadline>> guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 *   - arch/x86/kvm/lapic.c|3141| <<set_target_expiration>> apic->lapic_timer.tscdeadline = kvm_read_l1_tsc(apic->vcpu, tscl) +
+	 *   - arch/x86/kvm/lapic.c|3180| <<advance_periodic_target_expiration>> apic->lapic_timer.tscdeadline = kvm_read_l1_tsc(apic->vcpu, tscl) +
+	 *   - arch/x86/kvm/vmx/nested.c|980| <<nested_vmx_get_vmexit_msr_value>> *data = kvm_read_l1_tsc(vcpu, val);
+	 *   - arch/x86/kvm/vmx/nested.c|2086| <<vmx_calc_preemption_timer_value>> u64 l1_scaled_tsc = kvm_read_l1_tsc(vcpu, rdtsc()) >>
+	 *   - arch/x86/kvm/vmx/vmx.c|8345| <<vmx_set_hv_timer>> guest_tscl = kvm_read_l1_tsc(vcpu, tscl);
+	 *   - arch/x86/kvm/x86.c|3885| <<kvm_guest_time_update>> tsc_timestamp = kvm_read_l1_tsc(v, host_tsc);
+	 *   - arch/x86/kvm/x86.c|10375| <<kvm_pv_clock_pairing>> clock_pairing.tsc = kvm_read_l1_tsc(vcpu, cycle);
+	 *   - arch/x86/kvm/x86.c|12309| <<vcpu_enter_guest>> vcpu->arch.last_guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 */
 	clock_pairing.tsc = kvm_read_l1_tsc(vcpu, cycle);
 	clock_pairing.flags = 0;
 	memset(&clock_pairing.pad, 0, sizeof(clock_pairing.pad));
@@ -8991,24 +10828,67 @@ static void kvm_pv_kick_cpu_op(struct kvm *kvm, unsigned long flags, int apicid)
 		.dest_id = apicid,
 	};
 
+	/*
+	 * 在以下使用kvm_irq_delivery_to_apic():
+	 *   - arch/x86/kvm/hyperv.c|495| <<synic_set_irq>> ret = kvm_irq_delivery_to_apic(vcpu->kvm, vcpu->arch.apic, &irq, NULL);
+	 *   - arch/x86/kvm/ioapic.c|673| <<ioapic_service>> ret = kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe,
+	 *   - arch/x86/kvm/ioapic.c|677| <<ioapic_service>> ret = kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe, NULL);
+	 *   - arch/x86/kvm/irq_comm.c|214| <<kvm_set_msi>> return kvm_irq_delivery_to_apic(kvm, NULL, &irq, NULL);
+	 *   - arch/x86/kvm/lapic.c|2293| <<kvm_apic_send_ipi>> kvm_irq_delivery_to_apic(apic->vcpu->kvm, apic, &irq, NULL);
+	 *   - arch/x86/kvm/x86.c|9314| <<kvm_pv_kick_cpu_op>> kvm_irq_delivery_to_apic(kvm, NULL, &lapic_irq, NULL);
+	 */
 	kvm_irq_delivery_to_apic(kvm, NULL, &lapic_irq, NULL);
 }
 
 bool kvm_apicv_activated(struct kvm *kvm)
 {
+	/*
+	 * 在以下使用kvm_arch->apicv_inhibit_reasons:
+	 *   - arch/x86/kvm/x86.c|9007| <<kvm_apicv_activated>> return (READ_ONCE(kvm->arch.apicv_inhibit_reasons) == 0);
+	 *   - arch/x86/kvm/x86.c|9013| <<kvm_vcpu_apicv_activated>> ulong vm_reasons = READ_ONCE(vcpu->kvm->arch.apicv_inhibit_reasons);
+	 *   - arch/x86/kvm/x86.c|9033| <<kvm_apicv_init>> unsigned long *inhibits = &kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|9830| <<__kvm_set_or_clear_apicv_inhibit>> old = new = kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|9848| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 *   - arch/x86/kvm/x86.c|9857| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 */
 	return (READ_ONCE(kvm->arch.apicv_inhibit_reasons) == 0);
 }
 EXPORT_SYMBOL_GPL(kvm_apicv_activated);
 
+/*
+ * 在以下调用kvm_vcpu_apicv_activated():
+ *   - arch/x86/kvm/svm/svm.c|1688| <<svm_set_vintr>> WARN_ON(kvm_vcpu_apicv_activated(&svm->vcpu));
+ *   - arch/x86/kvm/x86.c|9794| <<kvm_vcpu_update_apicv>> activate = kvm_vcpu_apicv_activated(vcpu) &&
+ *   - arch/x86/kvm/x86.c|10318| <<vcpu_enter_guest>> WARN_ON_ONCE((kvm_vcpu_apicv_activated(vcpu) != kvm_vcpu_apicv_active(vcpu)) &&
+ */
 bool kvm_vcpu_apicv_activated(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用kvm_arch->apicv_inhibit_reasons:
+	 *   - arch/x86/kvm/x86.c|9007| <<kvm_apicv_activated>> return (READ_ONCE(kvm->arch.apicv_inhibit_reasons) == 0);
+	 *   - arch/x86/kvm/x86.c|9013| <<kvm_vcpu_apicv_activated>> ulong vm_reasons = READ_ONCE(vcpu->kvm->arch.apicv_inhibit_reasons);
+	 *   - arch/x86/kvm/x86.c|9033| <<kvm_apicv_init>> unsigned long *inhibits = &kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|9830| <<__kvm_set_or_clear_apicv_inhibit>> old = new = kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|9848| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 *   - arch/x86/kvm/x86.c|9857| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 */
 	ulong vm_reasons = READ_ONCE(vcpu->kvm->arch.apicv_inhibit_reasons);
+	/*
+	 * 只在这里调用
+	 * 只有amd有: avic_vcpu_get_apicv_inhibit_reasons()
+	 */
 	ulong vcpu_reasons = static_call(kvm_x86_vcpu_get_apicv_inhibit_reasons)(vcpu);
 
 	return (vm_reasons | vcpu_reasons) == 0;
 }
 EXPORT_SYMBOL_GPL(kvm_vcpu_apicv_activated);
 
+/*
+ * 在以下使用set_or_clear_apicv_inhibit():
+ *   - arch/x86/kvm/x86.c|9367| <<kvm_apicv_init>> set_or_clear_apicv_inhibit(inhibits, APICV_INHIBIT_REASON_ABSENT, true);
+ *   - arch/x86/kvm/x86.c|9370| <<kvm_apicv_init>> set_or_clear_apicv_inhibit(inhibits, APICV_INHIBIT_REASON_DISABLE, true);
+ *   - arch/x86/kvm/x86.c|10360| <<__kvm_set_or_clear_apicv_inhibit>> set_or_clear_apicv_inhibit(&new, reason, set);
+ */
 static void set_or_clear_apicv_inhibit(unsigned long *inhibits,
 				       enum kvm_apicv_inhibit reason, bool set)
 {
@@ -9020,12 +10900,31 @@ static void set_or_clear_apicv_inhibit(unsigned long *inhibits,
 	trace_kvm_apicv_inhibit_changed(reason, set, *inhibits);
 }
 
+/*
+ * 在以下使用kvm_apicv_init():
+ *    - arch/x86/kvm/x86.c|12910| <<kvm_arch_init_vm>> kvm_apicv_init(kvm);
+ */
 static void kvm_apicv_init(struct kvm *kvm)
 {
+	/*
+	 * 在以下使用kvm_arch->apicv_inhibit_reasons:
+	 *   - arch/x86/kvm/x86.c|9007| <<kvm_apicv_activated>> return (READ_ONCE(kvm->arch.apicv_inhibit_reasons) == 0);
+	 *   - arch/x86/kvm/x86.c|9013| <<kvm_vcpu_apicv_activated>> ulong vm_reasons = READ_ONCE(vcpu->kvm->arch.apicv_inhibit_reasons);
+	 *   - arch/x86/kvm/x86.c|9033| <<kvm_apicv_init>> unsigned long *inhibits = &kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|9830| <<__kvm_set_or_clear_apicv_inhibit>> old = new = kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|9848| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 *   - arch/x86/kvm/x86.c|9857| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 */
 	unsigned long *inhibits = &kvm->arch.apicv_inhibit_reasons;
 
 	init_rwsem(&kvm->arch.apicv_update_lock);
 
+	/*
+	 * 在以下使用set_or_clear_apicv_inhibit():
+	 *   - arch/x86/kvm/x86.c|9367| <<kvm_apicv_init>> set_or_clear_apicv_inhibit(inhibits, APICV_INHIBIT_REASON_ABSENT, true);
+	 *   - arch/x86/kvm/x86.c|9370| <<kvm_apicv_init>> set_or_clear_apicv_inhibit(inhibits, APICV_INHIBIT_REASON_DISABLE, true);
+	 *   - arch/x86/kvm/x86.c|10360| <<__kvm_set_or_clear_apicv_inhibit>> set_or_clear_apicv_inhibit(&new, reason, set);
+	 */
 	set_or_clear_apicv_inhibit(inhibits, APICV_INHIBIT_REASON_ABSENT, true);
 
 	if (!enable_apicv)
@@ -9044,8 +10943,31 @@ static void kvm_sched_yield(struct kvm_vcpu *vcpu, unsigned long dest_id)
 		goto no_yield;
 
 	rcu_read_lock();
+	/*
+	 * 在以下使用kvm_arch->apic_map:
+	 *   - arch/x86/kvm/lapic.c|581| <<kvm_recalculate_apic_map>> old = rcu_dereference_protected(kvm->arch.apic_map,
+	 *   - arch/x86/kvm/lapic.c|583| <<kvm_recalculate_apic_map>> rcu_assign_pointer(kvm->arch.apic_map, new);
+	 *   - arch/x86/kvm/lapic.c|1305| <<kvm_pv_send_ipi>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1772| <<kvm_irq_delivery_to_apic_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1825| <<kvm_intr_is_single_vcpu_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|2023| <<kvm_bitmap_or_dest_vcpus>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|9391| <<kvm_sched_yield>> map = rcu_dereference(vcpu->kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|13061| <<kvm_arch_destroy_vm>> kvfree(rcu_dereference_check(kvm->arch.apic_map, 1));
+	 */
 	map = rcu_dereference(vcpu->kvm->arch.apic_map);
 
+	/*
+	 * 在以下使用kvm_apic_map->phys_map[]:
+	 *   - arch/x86/kvm/lapic.c|289| <<kvm_apic_map_get_logical_dest>> *cluster = &map->phys_map[offset];
+	 *   - arch/x86/kvm/lapic.c|534| <<kvm_recalculate_apic_map>> new->phys_map[x2apic_id] = apic;
+	 *   - arch/x86/kvm/lapic.c|539| <<kvm_recalculate_apic_map>> if (!apic_x2apic_mode(apic) && !new->phys_map[xapic_id])
+	 *   - arch/x86/kvm/lapic.c|540| <<kvm_recalculate_apic_map>> new->phys_map[xapic_id] = apic;
+	 *   - arch/x86/kvm/lapic.c|1287| <<__pv_send_ipi>> if (map->phys_map[min + i]) {
+	 *   - arch/x86/kvm/lapic.c|1288| <<__pv_send_ipi>> vcpu = map->phys_map[min + i]->vcpu;
+	 *   - arch/x86/kvm/lapic.c|1738| <<kvm_apic_map_get_dest_lapic>> *dst = &map->phys_map[dest_id];
+	 *   - arch/x86/kvm/x86.c|9433| <<kvm_sched_yield>> if (likely(map) && dest_id <= map->max_apic_id && map->phys_map[dest_id])
+	 *   - arch/x86/kvm/x86.c|9434| <<kvm_sched_yield>> target = map->phys_map[dest_id]->vcpu;
+	 */
 	if (likely(map) && dest_id <= map->max_apic_id && map->phys_map[dest_id])
 		target = map->phys_map[dest_id]->vcpu;
 
@@ -9197,12 +11119,23 @@ static int dm_request_for_irq_injection(struct kvm_vcpu *vcpu)
 		likely(!pic_in_kernel(vcpu->kvm));
 }
 
+/*
+ * 在以下使用post_kvm_run_save():
+ *   - arch/x86/kvm/x86.c|11799| <<kvm_arch_vcpu_ioctl_run>> post_kvm_run_save(vcpu);
+ */
 static void post_kvm_run_save(struct kvm_vcpu *vcpu)
 {
 	struct kvm_run *kvm_run = vcpu->run;
 
 	kvm_run->if_flag = static_call(kvm_x86_get_if_flag)(vcpu);
 	kvm_run->cr8 = kvm_get_cr8(vcpu);
+	/*
+	 * 在以下使用kvm_get_apic_base():
+	 *   - arch/x86/kvm/x86.c|472| <<kvm_get_apic_mode>> return kvm_apic_mode(kvm_get_apic_base(vcpu));
+	 *   - arch/x86/kvm/x86.c|4074| <<kvm_get_msr_common>> msr_info->data = kvm_get_apic_base(vcpu);
+	 *   - arch/x86/kvm/x86.c|9617| <<post_kvm_run_save>> kvm_run->apic_base = kvm_get_apic_base(vcpu);
+	 *   - arch/x86/kvm/x86.c|11932| <<__get_sregs_common>> sregs->apic_base = kvm_get_apic_base(vcpu);
+	 */
 	kvm_run->apic_base = kvm_get_apic_base(vcpu);
 
 	/*
@@ -9257,6 +11190,11 @@ int kvm_check_nested_events(struct kvm_vcpu *vcpu)
 	return kvm_x86_ops.nested_ops->check_events(vcpu);
 }
 
+/*
+ * 在以下调用kvm_inject_exception():
+ *   - arch/x86/kvm/x86.c|9582| <<inject_pending_event>> kvm_inject_exception(vcpu);
+ *   - arch/x86/kvm/x86.c|9651| <<inject_pending_event>> kvm_inject_exception(vcpu);
+ */
 static void kvm_inject_exception(struct kvm_vcpu *vcpu)
 {
 	/*
@@ -9276,6 +11214,16 @@ static void kvm_inject_exception(struct kvm_vcpu *vcpu)
 	static_call(kvm_x86_inject_exception)(vcpu);
 }
 
+/*
+ * 在以下调用inject_pending_event():
+ *   - arch/x86/kvm/x86.c|10320| <<vcpu_enter_guest>> r = inject_pending_event(vcpu, &req_immediate_exit);
+ *
+ * vcpu_enter_guest()
+ * -> inject_pending_event()
+ *    -> kvm_cpu_get_interrupt()
+ *       -> kvm_get_apic_interrupt()
+ *          -> apic_set_isr()
+ */
 static int inject_pending_event(struct kvm_vcpu *vcpu, bool *req_immediate_exit)
 {
 	int r;
@@ -9284,6 +11232,11 @@ static int inject_pending_event(struct kvm_vcpu *vcpu, bool *req_immediate_exit)
 	/* try to reinject previous events if any */
 
 	if (vcpu->arch.exception.injected) {
+		/*
+		 * 在以下调用kvm_inject_exception():
+		 *   - arch/x86/kvm/x86.c|9582| <<inject_pending_event>> kvm_inject_exception(vcpu);
+		 *   - arch/x86/kvm/x86.c|9651| <<inject_pending_event>> kvm_inject_exception(vcpu);
+		 */
 		kvm_inject_exception(vcpu);
 		can_inject = false;
 	}
@@ -9303,9 +11256,16 @@ static int inject_pending_event(struct kvm_vcpu *vcpu, bool *req_immediate_exit)
 	 */
 	else if (!vcpu->arch.exception.pending) {
 		if (vcpu->arch.nmi_injected) {
+			/*
+			 * vmx_inject_nmi
+			 */
 			static_call(kvm_x86_inject_nmi)(vcpu);
 			can_inject = false;
 		} else if (vcpu->arch.interrupt.injected) {
+			/*
+			 * vmx_inject_irq()
+			 * svm_set_irq()
+			 */
 			static_call(kvm_x86_inject_irq)(vcpu, true);
 			can_inject = false;
 		}
@@ -9350,6 +11310,11 @@ static int inject_pending_event(struct kvm_vcpu *vcpu, bool *req_immediate_exit)
 			}
 		}
 
+		/*
+		 * 在以下调用kvm_inject_exception():
+		 *   - arch/x86/kvm/x86.c|9582| <<inject_pending_event>> kvm_inject_exception(vcpu);
+		 *   - arch/x86/kvm/x86.c|9651| <<inject_pending_event>> kvm_inject_exception(vcpu);
+		 */
 		kvm_inject_exception(vcpu);
 
 		vcpu->arch.exception.pending = false;
@@ -9387,34 +11352,119 @@ static int inject_pending_event(struct kvm_vcpu *vcpu, bool *req_immediate_exit)
 	}
 
 	if (vcpu->arch.nmi_pending) {
+		/*
+		 * 在以下使用kvm_x86_nmi_allowed():
+		 *   - arch/x86/kvm/x86.c|9727| <<inject_pending_event>> r = can_inject ? static_call(kvm_x86_nmi_allowed)(vcpu, true) : -EBUSY;
+		 *   - arch/x86/kvm/x86.c|9735| <<inject_pending_event>> WARN_ON(static_call(kvm_x86_nmi_allowed)(vcpu, true) < 0);
+		 *   - arch/x86/kvm/x86.c|13270| <<kvm_vcpu_has_events>> static_call(kvm_x86_nmi_allowed)(vcpu, false)))
+		 *
+		 * vmx_nmi_allowed
+		 */
 		r = can_inject ? static_call(kvm_x86_nmi_allowed)(vcpu, true) : -EBUSY;
 		if (r < 0)
 			goto out;
 		if (r) {
 			--vcpu->arch.nmi_pending;
 			vcpu->arch.nmi_injected = true;
+			/*
+			 * vmx_inject_nmi
+			 */
 			static_call(kvm_x86_inject_nmi)(vcpu);
 			can_inject = false;
+			/*
+			 * 在以下使用kvm_x86_nmi_allowed():
+			 *   - arch/x86/kvm/x86.c|9727| <<inject_pending_event>> r = can_inject ? static_call(kvm_x86_nmi_allowed)(vcpu, true) : -EBUSY;
+			 *   - arch/x86/kvm/x86.c|9735| <<inject_pending_event>> WARN_ON(static_call(kvm_x86_nmi_allowed)(vcpu, true) < 0);
+			 *   - arch/x86/kvm/x86.c|13270| <<kvm_vcpu_has_events>> static_call(kvm_x86_nmi_allowed)(vcpu, false)))
+			 */
 			WARN_ON(static_call(kvm_x86_nmi_allowed)(vcpu, true) < 0);
 		}
+		/*
+		 * vmx_enable_nmi_window
+		 */
 		if (vcpu->arch.nmi_pending)
 			static_call(kvm_x86_enable_nmi_window)(vcpu);
 	}
 
+	/*
+	 * 在以下使用kvm_cpu_has_injectable_intr():
+	 *   - arch/x86/kvm/svm/svm.c|2448| <<svm_set_gif>> kvm_cpu_has_injectable_intr(&svm->vcpu))
+	 *   - arch/x86/kvm/x86.c|9412| <<inject_pending_event>> if (kvm_cpu_has_injectable_intr(vcpu)) {
+	 *   - arch/x86/kvm/x86.c|9425| <<inject_pending_event>> if (kvm_cpu_has_injectable_intr(vcpu))
+	 *
+	 * 第一个地方
+	 */
 	if (kvm_cpu_has_injectable_intr(vcpu)) {
+		/*
+		 * 在以下调用kvm_x86_interrupt_allowed():
+		 *   - arch/x86/kvm/x86.c|9719| <<inject_pending_event>> r = can_inject ? static_call(kvm_x86_interrupt_allowed)(vcpu, true) : -EBUSY;
+		 *   - arch/x86/kvm/x86.c|9749| <<inject_pending_event>> WARN_ON(static_call(kvm_x86_interrupt_allowed)(vcpu, true) < 0);
+		 *   - arch/x86/kvm/x86.c|13272| <<kvm_arch_interrupt_allowed>> return static_call(kvm_x86_interrupt_allowed)(vcpu, false);
+		 *
+		 * vmx_interrupt_allowed()
+		 * svm_interrupt_allowed()
+		 */
 		r = can_inject ? static_call(kvm_x86_interrupt_allowed)(vcpu, true) : -EBUSY;
 		if (r < 0)
 			goto out;
 		if (r) {
+			/*
+			 * 在以下调用kvm_cpu_get_interrupt():
+			 *   - arch/x86/kvm/vmx/nested.c|4709| <<nested_vmx_vmexit>> int irq = kvm_cpu_get_interrupt(vcpu);
+			 *   - arch/x86/kvm/x86.c|9417| <<inject_pending_event>> int irq = kvm_cpu_get_interrupt(vcpu);
+			 *
+			 * vcpu_enter_guest()
+			 * -> inject_pending_event()
+			 *    -> kvm_cpu_get_interrupt()
+			 *       -> kvm_get_apic_interrupt()
+			 *          -> apic_set_isr()
+			 *
+			 * 这里很重要!
+			 * 这个函数有可能会把IRR的bit移动到ISR.
+			 */
 			int irq = kvm_cpu_get_interrupt(vcpu);
 
 			if (!WARN_ON_ONCE(irq == -1)) {
+				/*
+				 * 在以下使用kvm_queue_interrupt():
+				 *   - arch/x86/kvm/svm/svm.c|4045| <<svm_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, false);
+				 *   - arch/x86/kvm/svm/svm.c|4048| <<svm_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, true);
+				 *   - arch/x86/kvm/vmx/vmx.c|6768| <<__vmx_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, type == INTR_TYPE_SOFT_INTR);
+				 *   - arch/x86/kvm/x86.c|4713| <<kvm_vcpu_ioctl_interrupt>> kvm_queue_interrupt(vcpu, irq->irq, false);
+				 *   - arch/x86/kvm/x86.c|9490| <<inject_pending_event>> kvm_queue_interrupt(vcpu, irq, false);
+				 *   - arch/x86/kvm/x86.c|11223| <<__set_sregs>> kvm_queue_interrupt(vcpu, pending_vec, false);
+				 *
+				 * vcpu->arch.interrupt.injected = true;
+				 * vcpu->arch.interrupt.soft = soft;
+				 * vcpu->arch.interrupt.nr = vector;
+				 */
 				kvm_queue_interrupt(vcpu, irq, false);
+				/*
+				 * vmx_inject_irq()
+				 * svm_set_irq()
+				 */
 				static_call(kvm_x86_inject_irq)(vcpu, false);
+				/*
+				 * 在以下调用kvm_x86_interrupt_allowed():
+				 *   - arch/x86/kvm/x86.c|9719| <<inject_pending_event>> r = can_inject ? static_call(kvm_x86_interrupt_allowed)(vcpu, true) : -EBUSY;
+				 *   - arch/x86/kvm/x86.c|9749| <<inject_pending_event>> WARN_ON(static_call(kvm_x86_interrupt_allowed)(vcpu, true) < 0);
+				 *   - arch/x86/kvm/x86.c|13272| <<kvm_arch_interrupt_allowed>> return static_call(kvm_x86_interrupt_allowed)(vcpu, false);
+				 */
 				WARN_ON(static_call(kvm_x86_interrupt_allowed)(vcpu, true) < 0);
 			}
 		}
-		if (kvm_cpu_has_injectable_intr(vcpu))
+		/*
+		 * 在以下调用:
+		 *   - arch/x86/kvm/x86.c|9847| <<inject_pending_event>> static_call(kvm_x86_enable_irq_window)(vcpu);
+		 *   - arch/x86/kvm/x86.c|10871| <<vcpu_enter_guest>> static_call(kvm_x86_enable_irq_window)(vcpu);
+		 *
+		 * vmx_enable_irq_window()
+		 * "VM-Exit if INTRs are unblocked in guest"
+		 * svm_enable_irq_window()
+		 *
+		 * 第二个地方
+		 */
+		if (kvm_cpu_has_injectable_intr(vcpu))
 			static_call(kvm_x86_enable_irq_window)(vcpu);
 	}
 
@@ -9460,6 +11510,13 @@ static void process_nmi(struct kvm_vcpu *vcpu)
 	if (static_call(kvm_x86_is_vnmi_pending)(vcpu))
 		limit--;
 
+	/*
+	 * 在以下使用kvm_vcpu_arch->nmi_queued:
+	 *   - arch/x86/kvm/x86.c|874| <<kvm_inject_nmi>> atomic_inc(&vcpu->arch.nmi_queued);
+	 *   - arch/x86/kvm/x86.c|5158| <<kvm_vcpu_ioctl_x86_set_vcpu_events>> atomic_set(&vcpu->arch.nmi_queued, events->nmi.pending);
+	 *   - arch/x86/kvm/x86.c|9855| <<process_nmi>> vcpu->arch.nmi_pending += atomic_xchg(&vcpu->arch.nmi_queued, 0);
+	 *   - arch/x86/kvm/x86.c|12376| <<kvm_vcpu_reset>> atomic_set(&vcpu->arch.nmi_queued, 0);
+	 */
 	vcpu->arch.nmi_pending += atomic_xchg(&vcpu->arch.nmi_queued, 0);
 	vcpu->arch.nmi_pending = min(vcpu->arch.nmi_pending, limit);
 
@@ -9724,6 +11781,10 @@ static void process_smi(struct kvm_vcpu *vcpu)
 	kvm_make_request(KVM_REQ_EVENT, vcpu);
 }
 
+/*
+ * 在以下使用kvm_make_scan_ioapic_request_mask():
+ *   - arch/x86/kvm/ioapic.c|575| <<ioapic_write_indirect>> kvm_make_scan_ioapic_request_mask(ioapic->kvm, vcpu_bitmap);
+ */
 void kvm_make_scan_ioapic_request_mask(struct kvm *kvm,
 				       unsigned long *vcpu_bitmap)
 {
@@ -9731,17 +11792,60 @@ void kvm_make_scan_ioapic_request_mask(struct kvm *kvm,
 
 	zalloc_cpumask_var(&cpus, GFP_ATOMIC);
 
+	/*
+	 * 在以下使用KVM_REQ_SCAN_IOAPIC:
+	 *   - arch/x86/kvm/hyperv.c|171| <<synic_set_sint>> kvm_make_request(KVM_REQ_SCAN_IOAPIC, hv_synic_to_vcpu(synic));
+	 *   - arch/x86/kvm/x86.c|9742| <<kvm_make_scan_ioapic_request_mask>> kvm_make_vcpus_request_mask(kvm, KVM_REQ_SCAN_IOAPIC,
+	 *   - arch/x86/kvm/x86.c|9750| <<kvm_make_scan_ioapic_request>> kvm_make_all_cpus_request(kvm, KVM_REQ_SCAN_IOAPIC);
+	 *   - arch/x86/kvm/x86.c|10087| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_SCAN_IOAPIC, vcpu))
+	 *
+	 * 处理的函数vcpu_scan_ioapic()
+	 */
 	kvm_make_vcpus_request_mask(kvm, KVM_REQ_SCAN_IOAPIC,
 				    NULL, vcpu_bitmap, cpus);
 
 	free_cpumask_var(cpus);
 }
 
+/*
+ * 在以下使用kvm_make_scan_ioapic_request():
+ *   - arch/x86/kvm/ioapic.c|485| <<kvm_arch_post_irq_ack_notifier_list_update>> kvm_make_scan_ioapic_request(kvm);
+ *   - arch/x86/kvm/ioapic.c|578| <<ioapic_write_indirect>> kvm_make_scan_ioapic_request(ioapic->kvm);
+ *   - arch/x86/kvm/ioapic.c|1011| <<kvm_set_ioapic>> kvm_make_scan_ioapic_request(kvm);
+ *   - arch/x86/kvm/irq_comm.c|454| <<kvm_arch_post_irq_routing_update>> kvm_make_scan_ioapic_request(kvm);
+ *   - arch/x86/kvm/lapic.c|347| <<kvm_recalculate_apic_map>> kvm_make_scan_ioapic_request(kvm);
+ */
 void kvm_make_scan_ioapic_request(struct kvm *kvm)
 {
+	/*
+	 * 在以下使用KVM_REQ_SCAN_IOAPIC:
+	 *   - arch/x86/kvm/hyperv.c|171| <<synic_set_sint>> kvm_make_request(KVM_REQ_SCAN_IOAPIC, hv_synic_to_vcpu(synic));
+	 *   - arch/x86/kvm/x86.c|9742| <<kvm_make_scan_ioapic_request_mask>> kvm_make_vcpus_request_mask(kvm, KVM_REQ_SCAN_IOAPIC,
+	 *   - arch/x86/kvm/x86.c|9750| <<kvm_make_scan_ioapic_request>> kvm_make_all_cpus_request(kvm, KVM_REQ_SCAN_IOAPIC);
+	 *   - arch/x86/kvm/x86.c|10087| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_SCAN_IOAPIC, vcpu))
+	 *
+	 * 处理的函数vcpu_scan_ioapic()
+	 */
 	kvm_make_all_cpus_request(kvm, KVM_REQ_SCAN_IOAPIC);
 }
 
+/*
+ * 在以下使用KVM_REQ_APICV_UPDATE:
+ *   - arch/x86/kvm/svm/nested.c|729| <<enter_svm_guest_mode>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+ *   - arch/x86/kvm/svm/nested.c|1111| <<svm_leave_nested>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+ *   - arch/x86/kvm/vmx/nested.c|4696| <<nested_vmx_vmexit>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+ *   - arch/x86/kvm/x86.c|10189| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_APICV_UPDATE, vcpu))
+ *   - arch/x86/kvm/x86.c|11394| <<kvm_arch_vcpu_create>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+ *
+ * 处理的函数:
+ * kvm_vcpu_update_apicv(vcpu);
+ *
+ *
+ * 在以下使用kvm_vcpu_update_apicv():
+ *   - arch/x86/kvm/lapic.c|2595| <<kvm_lapic_set_base>> kvm_vcpu_update_apicv(vcpu);
+ *   - arch/x86/kvm/svm/nested.c|1033| <<nested_svm_vmexit>> kvm_vcpu_update_apicv(vcpu);
+ *   - arch/x86/kvm/x86.c|10190| <<vcpu_enter_guest(KVM_REQ_APICV_UPDATE)>> kvm_vcpu_update_apicv(vcpu);
+ */
 void kvm_vcpu_update_apicv(struct kvm_vcpu *vcpu)
 {
 	bool activate;
@@ -9760,7 +11864,17 @@ void kvm_vcpu_update_apicv(struct kvm_vcpu *vcpu)
 		goto out;
 
 	vcpu->arch.apicv_active = activate;
+	/*
+	 * 在以下使用kvm_apic_update_apicv():
+	 *   - arch/x86/kvm/lapic.c|2828| <<kvm_lapic_reset>> kvm_apic_update_apicv(vcpu);
+	 *   - arch/x86/kvm/lapic.c|3192| <<kvm_apic_set_state>> kvm_apic_update_apicv(vcpu);
+	 *   - arch/x86/kvm/x86.c|9877| <<kvm_vcpu_update_apicv>> kvm_apic_update_apicv(vcpu);
+	 */
 	kvm_apic_update_apicv(vcpu);
+	/*
+	 * vmx_refresh_apicv_exec_ctrl()
+	 * avic_refresh_apicv_exec_ctrl()
+	 */
 	static_call(kvm_x86_refresh_apicv_exec_ctrl)(vcpu);
 
 	/*
@@ -9778,6 +11892,44 @@ void kvm_vcpu_update_apicv(struct kvm_vcpu *vcpu)
 }
 EXPORT_SYMBOL_GPL(kvm_vcpu_update_apicv);
 
+/*
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_vcpu_reset
+ * kvm_apic_accept_events
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_lapic_reg_write
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ *
+ * 在以下调用__kvm_set_or_clear_apicv_inhibit():
+ *   - arch/x86/kvm/hyperv.c|132| <<synic_update_vector>> __kvm_set_or_clear_apicv_inhibit(vcpu->kvm,
+ *          APICV_INHIBIT_REASON_HYPERV, !!hv->synic_auto_eoi_used);
+ *   - arch/x86/kvm/x86.c|10434| <<kvm_set_or_clear_apicv_inhibit>> __kvm_set_or_clear_apicv_inhibit(kvm, reason, set);
+ *   - arch/x86/kvm/x86.c|12032| <<kvm_arch_vcpu_guestdbg_update_apicv_inhibit>> __kvm_set_or_clear_apicv_inhibit(kvm,
+ *          APICV_INHIBIT_REASON_BLOCKIRQ, set);
+ */
 void __kvm_set_or_clear_apicv_inhibit(struct kvm *kvm,
 				      enum kvm_apicv_inhibit reason, bool set)
 {
@@ -9785,10 +11937,23 @@ void __kvm_set_or_clear_apicv_inhibit(struct kvm *kvm,
 
 	lockdep_assert_held_write(&kvm->arch.apicv_update_lock);
 
+	/*
+	 * vmx_check_apicv_inhibit_reasons()
+	 * avic_check_apicv_inhibit_reasons()
+	 */
 	if (!kvm_x86_ops.check_apicv_inhibit_reasons ||
 	    !static_call(kvm_x86_check_apicv_inhibit_reasons)(reason))
 		return;
 
+	/*
+	 * 在以下使用kvm_arch->apicv_inhibit_reasons:
+	 *   - arch/x86/kvm/x86.c|9007| <<kvm_apicv_activated>> return (READ_ONCE(kvm->arch.apicv_inhibit_reasons) == 0);
+	 *   - arch/x86/kvm/x86.c|9013| <<kvm_vcpu_apicv_activated>> ulong vm_reasons = READ_ONCE(vcpu->kvm->arch.apicv_inhibit_reasons);
+	 *   - arch/x86/kvm/x86.c|9033| <<kvm_apicv_init>> unsigned long *inhibits = &kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|9830| <<__kvm_set_or_clear_apicv_inhibit>> old = new = kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|9848| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 *   - arch/x86/kvm/x86.c|9857| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 */
 	old = new = kvm->arch.apicv_inhibit_reasons;
 
 	set_or_clear_apicv_inhibit(&new, reason, set);
@@ -9806,6 +11971,17 @@ void __kvm_set_or_clear_apicv_inhibit(struct kvm *kvm,
 		 * side (handling the request) also prevents other vCPUs from
 		 * servicing the request with a stale apicv_inhibit_reasons.
 		 */
+		/*
+		 * 在以下使用KVM_REQ_APICV_UPDATE:
+		 *   - arch/x86/kvm/svm/nested.c|729| <<enter_svm_guest_mode>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+		 *   - arch/x86/kvm/svm/nested.c|1111| <<svm_leave_nested>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+		 *   - arch/x86/kvm/vmx/nested.c|4696| <<nested_vmx_vmexit>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+		 *   - arch/x86/kvm/x86.c|10189| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_APICV_UPDATE, vcpu))
+		 *   - arch/x86/kvm/x86.c|11394| <<kvm_arch_vcpu_create>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+		 *
+		 * 处理的函数:
+		 * kvm_vcpu_update_apicv(vcpu);
+		 */
 		kvm_make_all_cpus_request(kvm, KVM_REQ_APICV_UPDATE);
 		kvm->arch.apicv_inhibit_reasons = new;
 		if (new) {
@@ -9820,6 +11996,41 @@ void __kvm_set_or_clear_apicv_inhibit(struct kvm *kvm,
 	}
 }
 
+/*
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_vcpu_reset
+ * kvm_apic_accept_events
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_lapic_reg_write
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ *
+ * 在以下调用kvm_set_or_clear_apicv_inhibit():
+ *   - arch/x86/include/asm/kvm_host.h|2021| <<kvm_set_apicv_inhibit>> kvm_set_or_clear_apicv_inhibit(kvm, reason, true);
+ *   - arch/x86/include/asm/kvm_host.h|2027| <<kvm_clear_apicv_inhibit>> kvm_set_or_clear_apicv_inhibit(kvm, reason, false);
+ */
 void kvm_set_or_clear_apicv_inhibit(struct kvm *kvm,
 				    enum kvm_apicv_inhibit reason, bool set)
 {
@@ -9827,11 +12038,30 @@ void kvm_set_or_clear_apicv_inhibit(struct kvm *kvm,
 		return;
 
 	down_write(&kvm->arch.apicv_update_lock);
+	/*
+	 * 在以下调用__kvm_set_or_clear_apicv_inhibit():
+	 *   - arch/x86/kvm/hyperv.c|132| <<synic_update_vector>> __kvm_set_or_clear_apicv_inhibit(vcpu->kvm,
+	 *          APICV_INHIBIT_REASON_HYPERV, !!hv->synic_auto_eoi_used);
+	 *   - arch/x86/kvm/x86.c|10434| <<kvm_set_or_clear_apicv_inhibit>> __kvm_set_or_clear_apicv_inhibit(kvm, reason, set);
+	 *   - arch/x86/kvm/x86.c|12032| <<kvm_arch_vcpu_guestdbg_update_apicv_inhibit>> __kvm_set_or_clear_apicv_inhibit(kvm,
+	 *          APICV_INHIBIT_REASON_BLOCKIRQ, set);
+	 */
 	__kvm_set_or_clear_apicv_inhibit(kvm, reason, set);
 	up_write(&kvm->arch.apicv_update_lock);
 }
 EXPORT_SYMBOL_GPL(kvm_set_or_clear_apicv_inhibit);
 
+/*
+ * 在以下使用KVM_REQ_SCAN_IOAPIC:
+ *   - arch/x86/kvm/hyperv.c|171| <<synic_set_sint>> kvm_make_request(KVM_REQ_SCAN_IOAPIC, hv_synic_to_vcpu(synic));
+ *   - arch/x86/kvm/x86.c|9742| <<kvm_make_scan_ioapic_request_mask>> kvm_make_vcpus_request_mask(kvm, KVM_REQ_SCAN_IOAPIC,
+ *   - arch/x86/kvm/x86.c|9750| <<kvm_make_scan_ioapic_request>> kvm_make_all_cpus_request(kvm, KVM_REQ_SCAN_IOAPIC);
+ *   - arch/x86/kvm/x86.c|10087| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_SCAN_IOAPIC, vcpu)) 
+ *
+ *
+ * 处理KVM_REQ_SCAN_IOAPIC:
+ *   - arch/x86/kvm/x86.c|10058| <<vcpu_enter_guest>> vcpu_scan_ioapic(vcpu);
+ */
 static void vcpu_scan_ioapic(struct kvm_vcpu *vcpu)
 {
 	if (!kvm_apic_present(vcpu))
@@ -9839,34 +12069,118 @@ static void vcpu_scan_ioapic(struct kvm_vcpu *vcpu)
 
 	bitmap_zero(vcpu->arch.ioapic_handled_vectors, 256);
 
+	/*
+	 * 在以下调用kvm_x86_sync_pir_to_irr()
+	 *   - arch/x86/kvm/lapic.c|789| <<apic_has_interrupt_for_ppr>> highest_irr = static_call(kvm_x86_sync_pir_to_irr)(apic->vcpu);
+	 *   - arch/x86/kvm/x86.c|4623| <<kvm_vcpu_ioctl_get_lapic>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 *   - arch/x86/kvm/x86.c|9842| <<vcpu_scan_ioapic>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 *   - arch/x86/kvm/x86.c|10171| <<vcpu_enter_guest>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 *   - arch/x86/kvm/x86.c|10220| <<vcpu_enter_guest>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 *
+	 * vmx_sync_pir_to_irr()
+	 */
 	static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
 
+	/*
+	 * 在以下使用kvm_vcpu_arch->ioapic_handled_vectors:
+	 *   - arch/x86/kvm/lapic.c|1273| <<kvm_ioapic_handles_vector>> return test_bit(vector, apic->vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|9840| <<vcpu_scan_ioapic>> bitmap_zero(vcpu->arch.ioapic_handled_vectors, 256);
+	 *   - arch/x86/kvm/x86.c|9845| <<vcpu_scan_ioapic>> kvm_scan_ioapic_routes(vcpu, vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|9847| <<vcpu_scan_ioapic>> kvm_ioapic_scan_entry(vcpu, vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|9864| <<vcpu_load_eoi_exitmap>> bitmap_or((ulong *)eoi_exit_bitmap, vcpu->arch.ioapic_handled_vectors,
+	 *              to_hv_synic(vcpu)->vec_bitmap, 256);
+	 *   - arch/x86/kvm/x86.c|9871| <<vcpu_load_eoi_exitmap>> static_call(kvm_x86_load_eoi_exitmap)(vcpu, (u64 *)vcpu->arch.ioapic_handled_vectors);
+	 *   - arch/x86/kvm/x86.c|10004| <<vcpu_enter_guest>> if (test_bit(vcpu->arch.pending_ioapic_eoi, vcpu->arch.ioapic_handled_vectors)) {
+	 *
+	 *
+	 * on: KVM模拟全部
+	 * split: QEMU模拟IOAPIC和PIC,KVM模拟LAPIC
+	 * off:QEMU 模拟全部
+	 */
 	if (irqchip_split(vcpu->kvm))
 		kvm_scan_ioapic_routes(vcpu, vcpu->arch.ioapic_handled_vectors);
 	else if (ioapic_in_kernel(vcpu->kvm))
 		kvm_ioapic_scan_entry(vcpu, vcpu->arch.ioapic_handled_vectors);
 
+	/*
+	 * 在以下使用kvm_vcpu_arch->load_eoi_exitmap_pending:
+	 *   - arch/x86/kvm/kvm_cache_regs.h|184| <<leave_guest_mode>> if (vcpu->arch.load_eoi_exitmap_pending) {
+	 *   - arch/x86/kvm/kvm_cache_regs.h|185| <<leave_guest_mode>> vcpu->arch.load_eoi_exitmap_pending = false;
+	 *   - arch/x86/kvm/x86.c|9850| <<vcpu_scan_ioapic>> vcpu->arch.load_eoi_exitmap_pending = true;
+	 */
 	if (is_guest_mode(vcpu))
 		vcpu->arch.load_eoi_exitmap_pending = true;
 	else
 		kvm_make_request(KVM_REQ_LOAD_EOI_EXITMAP, vcpu);
+	/*
+	 * 在以下使用KVM_REQ_LOAD_EOI_EXITMAP:
+	 *   - arch/x86/kvm/kvm_cache_regs.h|186| <<leave_guest_mode>> kvm_make_request(KVM_REQ_LOAD_EOI_EXITMAP, vcpu);
+	 *   - arch/x86/kvm/x86.c|9889| <<vcpu_scan_ioapic>> kvm_make_request(KVM_REQ_LOAD_EOI_EXITMAP, vcpu);
+	 *   - arch/x86/kvm/x86.c|10089| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_LOAD_EOI_EXITMAP, vcpu))
+	 *
+	 * 处理的函数vcpu_load_eoi_exitmap()
+	 */
 }
 
+/*
+ * 在以下使用KVM_REQ_LOAD_EOI_EXITMAP:
+ *   - arch/x86/kvm/kvm_cache_regs.h|186| <<leave_guest_mode>> kvm_make_request(KVM_REQ_LOAD_EOI_EXITMAP, vcpu);
+ *   - arch/x86/kvm/x86.c|9889| <<vcpu_scan_ioapic>> kvm_make_request(KVM_REQ_LOAD_EOI_EXITMAP, vcpu);
+ *   - arch/x86/kvm/x86.c|10089| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_LOAD_EOI_EXITMAP, vcpu))
+ *
+ * 处理的函数vcpu_load_eoi_exitmap()
+ *
+ *
+ * 处理KVM_REQ_IOAPIC_EOI_EXIT:
+ *   - arch/x86/kvm/x86.c|10060| <<vcpu_enter_guest>> vcpu_load_eoi_exitmap(vcpu);
+ */
 static void vcpu_load_eoi_exitmap(struct kvm_vcpu *vcpu)
 {
 	u64 eoi_exit_bitmap[4];
 
+	/*
+	 * 在以下调用kvm_apic_hw_enabled():
+	 *   - arch/x86/kvm/lapic.c|177| <<apic_enabled>> return kvm_apic_sw_enabled(apic) && kvm_apic_hw_enabled(apic);
+	 *   - arch/x86/kvm/lapic.c|2040| <<apic_mmio_read>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2125| <<lapic_timer_int_injected>> if (kvm_apic_hw_enabled(apic)) {
+	 *   - arch/x86/kvm/lapic.c|2809| <<apic_mmio_write>> if (!kvm_apic_hw_enabled(apic) || apic_x2apic_mode(apic)) {
+	 *   - arch/x86/kvm/lapic.c|3330| <<kvm_apic_local_deliver>> if (kvm_apic_hw_enabled(apic) && !(reg & APIC_LVT_MASKED)) {
+	 *   - arch/x86/kvm/lapic.c|3443| <<kvm_apic_accept_pic_intr>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 *   - arch/x86/kvm/lapic.h|246| <<kvm_apic_present>> return lapic_in_kernel(vcpu) && kvm_apic_hw_enabled(vcpu->arch.apic);
+	 *   - arch/x86/kvm/x86.c|10218| <<vcpu_load_eoi_exitmap>> if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+	 */
 	if (!kvm_apic_hw_enabled(vcpu->arch.apic))
 		return;
 
 	if (to_hv_vcpu(vcpu)) {
+		/*
+		 * 在以下使用kvm_vcpu_arch->ioapic_handled_vectors:
+		 *   - arch/x86/kvm/lapic.c|1273| <<kvm_ioapic_handles_vector>> return test_bit(vector, apic->vcpu->arch.ioapic_handled_vectors);
+		 *   - arch/x86/kvm/x86.c|9840| <<vcpu_scan_ioapic>> bitmap_zero(vcpu->arch.ioapic_handled_vectors, 256);
+		 *   - arch/x86/kvm/x86.c|9845| <<vcpu_scan_ioapic>> kvm_scan_ioapic_routes(vcpu, vcpu->arch.ioapic_handled_vectors);
+		 *   - arch/x86/kvm/x86.c|9847| <<vcpu_scan_ioapic>> kvm_ioapic_scan_entry(vcpu, vcpu->arch.ioapic_handled_vectors);
+		 *   - arch/x86/kvm/x86.c|9864| <<vcpu_load_eoi_exitmap>> bitmap_or((ulong *)eoi_exit_bitmap, vcpu->arch.ioapic_handled_vectors,
+		 *              to_hv_synic(vcpu)->vec_bitmap, 256);
+		 *   - arch/x86/kvm/x86.c|9871| <<vcpu_load_eoi_exitmap>> static_call(kvm_x86_load_eoi_exitmap)(vcpu, (u64 *)vcpu->arch.ioapic_handled_vectors);
+		 *   - arch/x86/kvm/x86.c|10004| <<vcpu_enter_guest>> if (test_bit(vcpu->arch.pending_ioapic_eoi, vcpu->arch.ioapic_handled_vectors)) {
+		 */
 		bitmap_or((ulong *)eoi_exit_bitmap,
 			  vcpu->arch.ioapic_handled_vectors,
 			  to_hv_synic(vcpu)->vec_bitmap, 256);
+		/*
+		 * vmx_load_eoi_exitmap()
+		 */
 		static_call(kvm_x86_load_eoi_exitmap)(vcpu, eoi_exit_bitmap);
 		return;
 	}
 
+	/*
+	 * 在以下调用kvm_x86_load_eoi_exitmap():
+	 *   - arch/x86/kvm/x86.c|9921| <<vcpu_load_eoi_exitmap>> static_call(kvm_x86_load_eoi_exitmap)(vcpu, eoi_exit_bitmap);
+	 *   - arch/x86/kvm/x86.c|9928| <<vcpu_load_eoi_exitmap>> static_call(kvm_x86_load_eoi_exitmap)(
+	 *
+	 * vmx_load_eoi_exitmap()
+	 */
 	static_call(kvm_x86_load_eoi_exitmap)(
 		vcpu, (u64 *)vcpu->arch.ioapic_handled_vectors);
 }
@@ -9881,6 +12195,15 @@ void kvm_arch_mmu_notifier_invalidate_range(struct kvm *kvm,
 	 * Update it when it becomes invalid.
 	 */
 	apic_address = gfn_to_hva(kvm, APIC_DEFAULT_PHYS_BASE >> PAGE_SHIFT);
+	/*
+	 * 在以下使用KVM_REQ_APIC_PAGE_RELOAD:
+	 *   - arch/x86/kvm/vmx/nested.c|4691| <<nested_vmx_vmexit>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|4645| <<vmx_vcpu_reset>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|6462| <<vmx_set_virtual_apic_mode>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+	 *   - arch/x86/kvm/x86.c|10340| <<kvm_arch_mmu_notifier_invalidate_range>> kvm_make_all_cpus_request(kvm, KVM_REQ_APIC_PAGE_RELOAD);
+	 *
+	 * 处理的函数kvm_vcpu_reload_apic_access_page()
+	 */
 	if (start <= apic_address && apic_address < end)
 		kvm_make_all_cpus_request(kvm, KVM_REQ_APIC_PAGE_RELOAD);
 }
@@ -9890,6 +12213,15 @@ void kvm_arch_guest_memory_reclaimed(struct kvm *kvm)
 	static_call_cond(kvm_x86_guest_memory_reclaimed)(kvm);
 }
 
+/*
+ * 在以下使用KVM_REQ_APIC_PAGE_RELOAD:
+ *   - arch/x86/kvm/vmx/nested.c|4691| <<nested_vmx_vmexit>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|4645| <<vmx_vcpu_reset>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|6462| <<vmx_set_virtual_apic_mode>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+ *   - arch/x86/kvm/x86.c|10340| <<kvm_arch_mmu_notifier_invalidate_range>> kvm_make_all_cpus_request(kvm, KVM_REQ_APIC_PAGE_RELOAD);
+ *
+ * 处理的函数kvm_vcpu_reload_apic_access_page()
+ */
 void kvm_vcpu_reload_apic_access_page(struct kvm_vcpu *vcpu)
 {
 	if (!lapic_in_kernel(vcpu))
@@ -9912,6 +12244,10 @@ EXPORT_SYMBOL_GPL(__kvm_request_immediate_exit);
  * exiting to the userspace.  Otherwise, the value will be returned to the
  * userspace.
  */
+/*
+ * 在以下调用vcpu_enter_guest():
+ *   - arch/x86/kvm/x86.c|11174| <<vcpu_run>> r = vcpu_enter_guest(vcpu);
+ */
 static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 {
 	int r;
@@ -9922,6 +12258,23 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 
 	bool req_immediate_exit = false;
 
+	/*
+	 * 在以下使用kvm->dirty_ring_size:
+	 *   - arch/x86/kvm/x86.c|10381| <<vcpu_enter_guest>> if (unlikely(vcpu->kvm->dirty_ring_size &&
+	 *   - virt/kvm/kvm_main.c|1563| <<kvm_prepare_memory_region>> else if (!kvm->dirty_ring_size) {
+	 *   - virt/kvm/kvm_main.c|2007| <<kvm_get_dirty_log>> if (kvm->dirty_ring_size)
+	 *   - virt/kvm/kvm_main.c|2072| <<kvm_get_dirty_log_protect>> if (kvm->dirty_ring_size)
+	 *   - virt/kvm/kvm_main.c|2184| <<kvm_clear_dirty_log_protect>> if (kvm->dirty_ring_size)
+	 *   - virt/kvm/kvm_main.c|3302| <<mark_page_dirty_in_slot>> if (kvm->dirty_ring_size)
+	 *   - virt/kvm/kvm_main.c|3706| <<kvm_page_in_dirty_ring>> return (pgoff >= KVM_DIRTY_LOG_PAGE_OFFSET)
+	 *           && (pgoff < KVM_DIRTY_LOG_PAGE_OFFSET + kvm->dirty_ring_size / PAGE_SIZE);
+	 *   - virt/kvm/kvm_main.c|3849| <<kvm_vm_ioctl_create_vcpu>> if (kvm->dirty_ring_size) {
+	 *   - virt/kvm/kvm_main.c|3851| <<kvm_vm_ioctl_create_vcpu>> r = kvm_dirty_ring_alloc(&vcpu->dirty_ring,
+	 *           id, kvm->dirty_ring_size);
+	 *   - virt/kvm/kvm_main.c|4459| <<kvm_vm_ioctl_enable_dirty_log_ring>> if (kvm->dirty_ring_size)
+	 *   - virt/kvm/kvm_main.c|4468| <<kvm_vm_ioctl_enable_dirty_log_ring>> kvm->dirty_ring_size = size;
+	 *   - virt/kvm/kvm_main.c|4482| <<kvm_vm_ioctl_reset_dirty_pages>> if (!kvm->dirty_ring_size)
+	 */
 	/* Forbid vmenter if vcpu dirty ring is soft-full */
 	if (unlikely(vcpu->kvm->dirty_ring_size &&
 		     kvm_dirty_ring_soft_full(&vcpu->dirty_ring))) {
@@ -9931,7 +12284,15 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 		goto out;
 	}
 
+	/*
+	 * 一直到kvm_mmu_reload()之前
+	 */
 	if (kvm_request_pending(vcpu)) {
+		/*
+		 * 在以下使用KVM_REQ_VM_DEAD:
+		 *   - arch/x86/kvm/x86.c|10390| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_VM_DEAD, vcpu)) {
+		 *   - include/linux/kvm_host.h|795| <<kvm_vm_dead>> kvm_make_all_cpus_request(kvm, KVM_REQ_VM_DEAD);
+		 */
 		if (kvm_check_request(KVM_REQ_VM_DEAD, vcpu)) {
 			r = -EIO;
 			goto out;
@@ -9942,6 +12303,12 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 				goto out;
 			}
 		}
+		/*
+		 * x86在以下使用KVM_REQ_MMU_RELOAD:
+		 *   - arch/x86/kvm/mmu/mmu.c|3940| <<is_page_fault_stale>> if (!sp && kvm_test_request(KVM_REQ_MMU_RELOAD, vcpu))
+		 *   - arch/x86/kvm/x86.c|10400| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_MMU_RELOAD, vcpu))
+		 *   - virt/kvm/kvm_main.c|377| <<kvm_reload_remote_mmus>> kvm_make_all_cpus_request(kvm, KVM_REQ_MMU_RELOAD);
+		 */
 		if (kvm_check_request(KVM_REQ_MMU_RELOAD, vcpu))
 			kvm_mmu_unload(vcpu);
 		if (kvm_check_request(KVM_REQ_MIGRATE_TIMER, vcpu))
@@ -9967,6 +12334,11 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 		}
 		kvm_service_local_tlb_flush_requests(vcpu);
 
+		/*
+		 * 在以下使用KVM_REQ_REPORT_TPR_ACCESS:
+		 *   - arch/x86/kvm/lapic.c|2056| <<__report_tpr_access>> kvm_make_request(KVM_REQ_REPORT_TPR_ACCESS, vcpu);
+		 *   - arch/x86/kvm/x86.c|10425| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_REPORT_TPR_ACCESS, vcpu)) {
+		 */
 		if (kvm_check_request(KVM_REQ_REPORT_TPR_ACCESS, vcpu)) {
 			vcpu->run->exit_reason = KVM_EXIT_TPR_ACCESS;
 			r = 0;
@@ -9988,6 +12360,14 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 			r = 1;
 			goto out;
 		}
+		/*
+		 * 在以下使用KVM_REQ_STEAL_UPDATE:
+		 *   - arch/x86/kvm/x86.c|3787| <<kvm_set_msr_common(MSR_KVM_STEAL_TIME)>> kvm_make_request(KVM_REQ_STEAL_UPDATE, vcpu);
+		 *   - arch/x86/kvm/x86.c|4733| <<kvm_arch_vcpu_load>> kvm_make_request(KVM_REQ_STEAL_UPDATE, vcpu);
+		 *   - arch/x86/kvm/x86.c|10795| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_STEAL_UPDATE, vcpu))
+		 *
+		 * 处理函数是record_steal_time()
+		 */
 		if (kvm_check_request(KVM_REQ_STEAL_UPDATE, vcpu))
 			record_steal_time(vcpu);
 		if (kvm_check_request(KVM_REQ_SMI, vcpu))
@@ -10000,6 +12380,23 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 			kvm_pmu_deliver_pmi(vcpu);
 		if (kvm_check_request(KVM_REQ_IOAPIC_EOI_EXIT, vcpu)) {
 			BUG_ON(vcpu->arch.pending_ioapic_eoi > 255);
+			/*
+			 * 在以下使用kvm_vcpu_arch->pending_ioapic_eoi:
+			 *   - arch/x86/kvm/lapic.c|1286| <<kvm_ioapic_send_eoi>> apic->vcpu->arch.pending_ioapic_eoi = vector;
+			 *   - arch/x86/kvm/x86.c|10008| <<vcpu_enter_guest(KVM_REQ_IOAPIC_EOI_EXIT)>> BUG_ON(vcpu->arch.pending_ioapic_eoi > 255);
+			 *   - arch/x86/kvm/x86.c|10009| <<vcpu_enter_guest(KVM_REQ_IOAPIC_EOI_EXIT)>> if (test_bit(vcpu->arch.pending_ioapic_eoi,
+			 *   - arch/x86/kvm/x86.c|10013| <<vcpu_enter_guest(KVM_REQ_IOAPIC_EOI_EXIT)>> vcpu->arch.pending_ioapic_eoi;
+			 *
+			 * 在以下使用kvm_vcpu_arch->ioapic_handled_vectors:
+			 *   - arch/x86/kvm/lapic.c|1273| <<kvm_ioapic_handles_vector>> return test_bit(vector, apic->vcpu->arch.ioapic_handled_vectors);
+			 *   - arch/x86/kvm/x86.c|9840| <<vcpu_scan_ioapic>> bitmap_zero(vcpu->arch.ioapic_handled_vectors, 256);
+			 *   - arch/x86/kvm/x86.c|9845| <<vcpu_scan_ioapic>> kvm_scan_ioapic_routes(vcpu, vcpu->arch.ioapic_handled_vectors);
+			 *   - arch/x86/kvm/x86.c|9847| <<vcpu_scan_ioapic>> kvm_ioapic_scan_entry(vcpu, vcpu->arch.ioapic_handled_vectors);
+			 *   - arch/x86/kvm/x86.c|9864| <<vcpu_load_eoi_exitmap>> bitmap_or((ulong *)eoi_exit_bitmap, vcpu->arch.ioapic_handled_vectors,
+			 *              to_hv_synic(vcpu)->vec_bitmap, 256);
+			 *   - arch/x86/kvm/x86.c|9871| <<vcpu_load_eoi_exitmap>> static_call(kvm_x86_load_eoi_exitmap)(vcpu, (u64 *)vcpu->arch.ioapic_handled_vectors);
+			 *   - arch/x86/kvm/x86.c|10004| <<vcpu_enter_guest>> if (test_bit(vcpu->arch.pending_ioapic_eoi, vcpu->arch.ioapic_handled_vectors)) {
+			 */
 			if (test_bit(vcpu->arch.pending_ioapic_eoi,
 				     vcpu->arch.ioapic_handled_vectors)) {
 				vcpu->run->exit_reason = KVM_EXIT_IOAPIC_EOI;
@@ -10009,10 +12406,28 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 				goto out;
 			}
 		}
+		/*
+		 * 在以下使用KVM_REQ_SCAN_IOAPIC:
+		 *   - arch/x86/kvm/hyperv.c|171| <<synic_set_sint>> kvm_make_request(KVM_REQ_SCAN_IOAPIC, hv_synic_to_vcpu(synic));
+		 *   - arch/x86/kvm/x86.c|9742| <<kvm_make_scan_ioapic_request_mask>> kvm_make_vcpus_request_mask(kvm, KVM_REQ_SCAN_IOAPIC,
+		 *   - arch/x86/kvm/x86.c|9750| <<kvm_make_scan_ioapic_request>> kvm_make_all_cpus_request(kvm, KVM_REQ_SCAN_IOAPIC);
+		 *   - arch/x86/kvm/x86.c|10087| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_SCAN_IOAPIC, vcpu)) 
+		 *
+		 * 处理的函数vcpu_scan_ioapic()
+		 */
 		if (kvm_check_request(KVM_REQ_SCAN_IOAPIC, vcpu))
 			vcpu_scan_ioapic(vcpu);
 		if (kvm_check_request(KVM_REQ_LOAD_EOI_EXITMAP, vcpu))
 			vcpu_load_eoi_exitmap(vcpu);
+		/*
+		 * 在以下使用KVM_REQ_APIC_PAGE_RELOAD:
+		 *   - arch/x86/kvm/vmx/nested.c|4691| <<nested_vmx_vmexit>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+		 *   - arch/x86/kvm/vmx/vmx.c|4645| <<vmx_vcpu_reset>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+		 *   - arch/x86/kvm/vmx/vmx.c|6462| <<vmx_set_virtual_apic_mode>> kvm_make_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu);
+		 *   - arch/x86/kvm/x86.c|10340| <<kvm_arch_mmu_notifier_invalidate_range>> kvm_make_all_cpus_request(kvm, KVM_REQ_APIC_PAGE_RELOAD);
+		 *
+		 * 处理的函数kvm_vcpu_reload_apic_access_page()
+		 */
 		if (kvm_check_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu))
 			kvm_vcpu_reload_apic_access_page(vcpu);
 		if (kvm_check_request(KVM_REQ_HV_CRASH, vcpu)) {
@@ -10043,8 +12458,27 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 		 */
 		if (kvm_check_request(KVM_REQ_HV_STIMER, vcpu))
 			kvm_hv_process_stimers(vcpu);
+		/*
+		 * 在以下使用KVM_REQ_APICV_UPDATE:
+		 *   - arch/x86/kvm/svm/nested.c|729| <<enter_svm_guest_mode>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+		 *   - arch/x86/kvm/svm/nested.c|1111| <<svm_leave_nested>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+		 *   - arch/x86/kvm/vmx/nested.c|4696| <<nested_vmx_vmexit>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+		 *   - arch/x86/kvm/x86.c|10189| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_APICV_UPDATE, vcpu))
+		 *   - arch/x86/kvm/x86.c|11394| <<kvm_arch_vcpu_create>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+		 *
+		 * 处理的函数:
+		 * kvm_vcpu_update_apicv(vcpu);
+		 */
 		if (kvm_check_request(KVM_REQ_APICV_UPDATE, vcpu))
 			kvm_vcpu_update_apicv(vcpu);
+		/*
+		 * 在以下使用KVM_REQ_APF_READY:
+		 *   - arch/x86/kvm/lapic.c|621| <<apic_set_spiv>> kvm_make_request(KVM_REQ_APF_READY, apic->vcpu);
+		 *   - arch/x86/kvm/lapic.c|3303| <<kvm_lapic_set_base>> kvm_make_request(KVM_REQ_APF_READY, vcpu);
+		 *   - arch/x86/kvm/x86.c|13246| <<kvm_arch_async_page_present_queued>> kvm_make_request(KVM_REQ_APF_READY, vcpu);
+		 *
+		 * 处理的函数kvm_check_async_pf_completion()
+		 */
 		if (kvm_check_request(KVM_REQ_APF_READY, vcpu))
 			kvm_check_async_pf_completion(vcpu);
 		if (kvm_check_request(KVM_REQ_MSR_FILTER_CHANGED, vcpu))
@@ -10057,6 +12491,15 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 	if (kvm_check_request(KVM_REQ_EVENT, vcpu) || req_int_win ||
 	    kvm_xen_has_interrupt(vcpu)) {
 		++vcpu->stat.req_event;
+		/*
+		 * 在以下使用kvm_apic_accept_events():
+		 *   - arch/x86/kvm/x86.c|10552| <<vcpu_enter_guest>> r = kvm_apic_accept_events(vcpu);
+		 *   - arch/x86/kvm/x86.c|10877| <<vcpu_block>> if (kvm_apic_accept_events(vcpu) < 0)
+		 *   - arch/x86/kvm/x86.c|11077| <<kvm_arch_vcpu_ioctl_run>> if (kvm_apic_accept_events(vcpu) < 0) {
+		 *   - arch/x86/kvm/x86.c|11313| <<kvm_arch_vcpu_ioctl_get_mpstate>> r = kvm_apic_accept_events(vcpu);
+		 *
+		 * 就关心KVM_APIC_INIT和KVM_APIC_SIPI
+		 */
 		r = kvm_apic_accept_events(vcpu);
 		if (r < 0) {
 			r = 0;
@@ -10067,11 +12510,22 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 			goto out;
 		}
 
+		/*
+		 * 只在此处调用
+		 */
 		r = inject_pending_event(vcpu, &req_immediate_exit);
 		if (r < 0) {
 			r = 0;
 			goto out;
 		}
+		/*
+		 * 在以下调用:
+		 *   - arch/x86/kvm/x86.c|9847| <<inject_pending_event>> static_call(kvm_x86_enable_irq_window)(vcpu);
+		 *   - arch/x86/kvm/x86.c|10871| <<vcpu_enter_guest>> static_call(kvm_x86_enable_irq_window)(vcpu);
+		 *
+		 * vmx_enable_irq_window()
+		 * svm_enable_irq_window()
+		 */
 		if (req_int_win)
 			static_call(kvm_x86_enable_irq_window)(vcpu);
 
@@ -10081,6 +12535,11 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 		}
 	}
 
+	/*
+	 * 在以下使用kvm_mmu_reload():
+	 *   - arch/x86/kvm/x86.c|10576| <<vcpu_enter_guest>> r = kvm_mmu_reload(vcpu);
+	 *   - arch/x86/kvm/x86.c|13052| <<kvm_arch_async_page_ready>> r = kvm_mmu_reload(vcpu);
+	 */
 	r = kvm_mmu_reload(vcpu);
 	if (unlikely(r)) {
 		goto cancel_injection;
@@ -10088,6 +12547,11 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 
 	preempt_disable();
 
+	/*
+	 * 只在此处调用kvm_x86_prepare_switch_to_guest
+	 *
+	 * vmx_prepare_switch_to_guest()
+	 */
 	static_call(kvm_x86_prepare_switch_to_guest)(vcpu);
 
 	/*
@@ -10122,9 +12586,24 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 	 * use the POSTED_INTR_VECTOR even if APICv is disabled,
 	 * so do it even if APICv is disabled on this vCPU.
 	 */
+	/*
+	 * 在以下调用kvm_x86_sync_pir_to_irr()
+	 *   - arch/x86/kvm/lapic.c|789| <<apic_has_interrupt_for_ppr>> highest_irr = static_call(kvm_x86_sync_pir_to_irr)(apic->vcpu);
+	 *   - arch/x86/kvm/x86.c|4623| <<kvm_vcpu_ioctl_get_lapic>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 *   - arch/x86/kvm/x86.c|9842| <<vcpu_scan_ioapic>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 *   - arch/x86/kvm/x86.c|10171| <<vcpu_enter_guest>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 *   - arch/x86/kvm/x86.c|10220| <<vcpu_enter_guest>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+	 *
+	 * vmx_sync_pir_to_irr()
+	 */
 	if (kvm_lapic_enabled(vcpu))
 		static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
 
+	/*
+	 * 在以下调用kvm_vcpu_exit_request():
+	 *   - arch/x86/kvm/x86.c|10386| <<vcpu_enter_guest(关于cancel_injection)>> if (kvm_vcpu_exit_request(vcpu)) {
+	 *   - arch/x86/kvm/x86.c|10443| <<vcpu_enter_guest(关于EXIT_FASTPATH_EXIT_HANDLED)>> if (unlikely(kvm_vcpu_exit_request(vcpu))) {
+	 */
 	if (kvm_vcpu_exit_request(vcpu)) {
 		vcpu->mode = OUTSIDE_GUEST_MODE;
 		smp_wmb();
@@ -10137,6 +12616,9 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 
 	if (req_immediate_exit) {
 		kvm_make_request(KVM_REQ_EVENT, vcpu);
+		/*
+		 * vmx_request_immediate_exit()
+		 */
 		static_call(kvm_x86_request_immediate_exit)(vcpu);
 	}
 
@@ -10167,13 +12649,36 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 		WARN_ON_ONCE((kvm_vcpu_apicv_activated(vcpu) != kvm_vcpu_apicv_active(vcpu)) &&
 			     (kvm_get_apic_mode(vcpu) != LAPIC_MODE_DISABLED));
 
+		/*
+		 * vmx_vcpu_run()
+		 * svm_vcpu_run()
+		 */
 		exit_fastpath = static_call(kvm_x86_vcpu_run)(vcpu);
+		/*
+		 * 很可能是EXIT_FASTPATH_NONE
+		 * 除非ICR或者HW timer
+		 */
 		if (likely(exit_fastpath != EXIT_FASTPATH_REENTER_GUEST))
 			break;
 
+		/*
+		 * 在以下调用kvm_x86_sync_pir_to_irr()
+		 *   - arch/x86/kvm/lapic.c|789| <<apic_has_interrupt_for_ppr>> highest_irr = static_call(kvm_x86_sync_pir_to_irr)(apic->vcpu);
+		 *   - arch/x86/kvm/x86.c|4623| <<kvm_vcpu_ioctl_get_lapic>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+		 *   - arch/x86/kvm/x86.c|9842| <<vcpu_scan_ioapic>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+		 *   - arch/x86/kvm/x86.c|10171| <<vcpu_enter_guest>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+		 *   - arch/x86/kvm/x86.c|10220| <<vcpu_enter_guest>> static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
+		 *
+		 * vmx_sync_pir_to_irr();
+		 */
 		if (kvm_lapic_enabled(vcpu))
 			static_call_cond(kvm_x86_sync_pir_to_irr)(vcpu);
 
+		/*
+		 * 在以下调用kvm_vcpu_exit_request():
+		 *   - arch/x86/kvm/x86.c|10386| <<vcpu_enter_guest(关于cancel_injection)>> if (kvm_vcpu_exit_request(vcpu)) {
+		 *   - arch/x86/kvm/x86.c|10443| <<vcpu_enter_guest(关于EXIT_FASTPATH_EXIT_HANDLED)>> if (unlikely(kvm_vcpu_exit_request(vcpu))) {
+		 */
 		if (unlikely(kvm_vcpu_exit_request(vcpu))) {
 			exit_fastpath = EXIT_FASTPATH_EXIT_HANDLED;
 			break;
@@ -10206,7 +12711,41 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 	if (hw_breakpoint_active())
 		hw_breakpoint_restore();
 
+	/*
+	 * 在以下使用kvm_vcpu_arch->last_vmentry_cpu:
+	 *   - arch/x86/kvm/cpuid.c|349| <<kvm_set_cpuid>> if (vcpu->arch.last_vmentry_cpu != -1)
+	 *   - arch/x86/kvm/mmu/mmu.c|5018| <<kvm_mmu_after_set_cpuid>> if (vcpu->arch.last_vmentry_cpu != -1) {
+	 *   - arch/x86/kvm/svm/sev.c|2607| <<pre_sev_run>> if (sd->sev_vmcbs[asid] == svm->vmcb && svm->vcpu.arch.last_vmentry_cpu == cpu)
+	 *   - arch/x86/kvm/svm/svm.c|3341| <<dump_vmcb>> pr_err("VMCB %p, last attempted VMRUN on CPU %d\n",
+	 *                                    svm->current_vmcb->ptr, vcpu->arch.last_vmentry_cpu);
+	 *   - arch/x86/kvm/svm/svm.c|3465| <<svm_handle_invalid_exit>> vcpu->run->internal.data[1] = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/svm/svm.c|3540| <<handle_exit>> kvm_run->fail_entry.cpu = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/vmx/vmx.c|4996| <<handle_exception_nmi>> vcpu->run->internal.data[3] = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/vmx/vmx.c|5971| <<dump_vmcs>> pr_err("VMCS %p, last attempted VM-entry on CPU %d\n",
+	 *                                    vmx->loaded_vmcs->vmcs, vcpu->arch.last_vmentry_cpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|6195| <<__vmx_handle_exit>> vcpu->run->fail_entry.cpu = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/vmx/vmx.c|6204| <<__vmx_handle_exit>> vcpu->run->fail_entry.cpu = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/vmx/vmx.c|6232| <<__vmx_handle_exit>> vcpu->run->internal.data[ndata++] = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/vmx/vmx.c|6292| <<__vmx_handle_exit>> vcpu->run->internal.data[1] = vcpu->arch.last_vmentry_cpu;
+	 *   - arch/x86/kvm/x86.c|10741| <<vcpu_enter_guest>> vcpu->arch.last_vmentry_cpu = vcpu->cpu;
+	 *   - arch/x86/kvm/x86.c|11799| <<kvm_arch_vcpu_create>> vcpu->arch.last_vmentry_cpu = -1;
+	 */
 	vcpu->arch.last_vmentry_cpu = vcpu->cpu;
+	/*
+	 * 在以下使用kvm_read_l1_tsc():
+	 *   - arch/x86/kvm/hyperv.c|591| <<get_time_ref_counter>> tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 *   - arch/x86/kvm/lapic.c|2899| <<__kvm_wait_lapic_expire>> guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 *   - arch/x86/kvm/lapic.c|2917| <<__kvm_wait_lapic_expire>> guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 *   - arch/x86/kvm/lapic.c|3027| <<start_sw_tscdeadline>> guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 *   - arch/x86/kvm/lapic.c|3141| <<set_target_expiration>> apic->lapic_timer.tscdeadline = kvm_read_l1_tsc(apic->vcpu, tscl) +
+	 *   - arch/x86/kvm/lapic.c|3180| <<advance_periodic_target_expiration>> apic->lapic_timer.tscdeadline = kvm_read_l1_tsc(apic->vcpu, tscl) +
+	 *   - arch/x86/kvm/vmx/nested.c|980| <<nested_vmx_get_vmexit_msr_value>> *data = kvm_read_l1_tsc(vcpu, val);
+	 *   - arch/x86/kvm/vmx/nested.c|2086| <<vmx_calc_preemption_timer_value>> u64 l1_scaled_tsc = kvm_read_l1_tsc(vcpu, rdtsc()) >>
+	 *   - arch/x86/kvm/vmx/vmx.c|8345| <<vmx_set_hv_timer>> guest_tscl = kvm_read_l1_tsc(vcpu, tscl);
+	 *   - arch/x86/kvm/x86.c|3885| <<kvm_guest_time_update>> tsc_timestamp = kvm_read_l1_tsc(v, host_tsc);
+	 *   - arch/x86/kvm/x86.c|10375| <<kvm_pv_clock_pairing>> clock_pairing.tsc = kvm_read_l1_tsc(vcpu, cycle);
+	 *   - arch/x86/kvm/x86.c|12309| <<vcpu_enter_guest>> vcpu->arch.last_guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
+	 */
 	vcpu->arch.last_guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
 
 	vcpu->mode = OUTSIDE_GUEST_MODE;
@@ -10220,6 +12759,10 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 	if (vcpu->arch.xfd_no_write_intercept)
 		fpu_sync_guest_vmexit_xfd_state();
 
+	/*
+	 * vmx_handle_exit_irqoff
+	 * svm_handle_exit_irqoff
+	 */
 	static_call(kvm_x86_handle_exit_irqoff)(vcpu);
 
 	if (vcpu->arch.guest_fpu.xfd_err)
@@ -10232,6 +12775,12 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 	 * interrupts on processors that implement an interrupt shadow, the
 	 * stat.exits increment will do nicely.
 	 */
+	/*
+	 * 在以下使用kvm_before_interrupt():
+	 *   - arch/x86/kvm/svm/svm.c|4206| <<svm_vcpu_run>> kvm_before_interrupt(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|6920| <<handle_interrupt_nmi_irqoff>> kvm_before_interrupt(vcpu);
+	 *   - arch/x86/kvm/x86.c|11036| <<vcpu_enter_guest>> kvm_before_interrupt(vcpu);
+	 */
 	kvm_before_interrupt(vcpu);
 	local_irq_enable();
 	++vcpu->stat.exits;
@@ -10248,6 +12797,13 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 	vtime_account_guest_exit();
 
 	if (lapic_in_kernel(vcpu)) {
+		/*
+		 * 在以下使用kvm_timer->advance_expire_delta:
+		 *   - arch/x86/kvm/lapic.c|2382| <<__kvm_wait_lapic_expire>> apic->lapic_timer.advance_expire_delta = guest_tsc - tsc_deadline;
+		 *   - arch/x86/kvm/lapic.c|2385| <<__kvm_wait_lapic_expire>> adjust_lapic_timer_advance(vcpu, apic->lapic_timer.advance_expire_delta);
+		 *   - arch/x86/kvm/x86.c|10872| <<vcpu_enter_guest>> s64 delta = vcpu->arch.apic->lapic_timer.advance_expire_delta;
+		 *   - arch/x86/kvm/x86.c|10875| <<vcpu_enter_guest>> vcpu->arch.apic->lapic_timer.advance_expire_delta = S64_MIN;
+		 */
 		s64 delta = vcpu->arch.apic->lapic_timer.advance_expire_delta;
 		if (delta != S64_MIN) {
 			trace_kvm_wait_lapic_expire(vcpu->vcpu_id, delta);
@@ -10268,29 +12824,93 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 		profile_hit(KVM_PROFILING, (void *)rip);
 	}
 
+	/*
+	 * 处理KVM_REQ_CLOCK_UPDATE的函数: kvm_guest_time_update()
+	 */
 	if (unlikely(vcpu->arch.tsc_always_catchup))
 		kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
 
+	/*
+	 * 在以下使用kvm_vcpu_arch->apic_attention:
+	 *   - arch/x86/kvm/lapic.c|1283| <<pv_eoi_set_pending>> __set_bit(KVM_APIC_PV_EOI_PENDING, &vcpu->arch.apic_attention);
+	 *   - arch/x86/kvm/lapic.c|1291| <<pv_eoi_clr_pending>> __clear_bit(KVM_APIC_PV_EOI_PENDING, &vcpu->arch.apic_attention);
+	 *   - arch/x86/kvm/lapic.c|3541| <<kvm_lapic_reset>> vcpu->arch.apic_attention = 0;
+	 *   - arch/x86/kvm/lapic.c|4066| <<kvm_lapic_sync_from_vapic>> if (test_bit(KVM_APIC_PV_EOI_PENDING, &vcpu->arch.apic_attention))
+	 *   - arch/x86/kvm/lapic.c|4069| <<kvm_lapic_sync_from_vapic>> if (!test_bit(KVM_APIC_CHECK_VAPIC, &vcpu->arch.apic_attention))
+	 *   - arch/x86/kvm/lapic.c|4128| <<kvm_lapic_sync_to_vapic>> if (!test_bit(KVM_APIC_CHECK_VAPIC, &vcpu->arch.apic_attention))
+	 *   - arch/x86/kvm/lapic.c|4151| <<kvm_lapic_set_vapic_addr>> __set_bit(KVM_APIC_CHECK_VAPIC, &vcpu->arch.apic_attention);
+	 *   - arch/x86/kvm/lapic.c|4153| <<kvm_lapic_set_vapic_addr>> __clear_bit(KVM_APIC_CHECK_VAPIC, &vcpu->arch.apic_attention);
+	 *   - arch/x86/kvm/x86.c|10895| <<vcpu_enter_guest>> if (vcpu->arch.apic_attention)
+	 *   - arch/x86/kvm/x86.c|10926| <<vcpu_enter_guest>> if (unlikely(vcpu->arch.apic_attention))
+	 *
+	 * 在以下调用kvm_lapic_sync_from_vapic():
+	 *   - arch/x86/kvm/x86.c|10896| <<vcpu_enter_guest>> kvm_lapic_sync_from_vapic(vcpu);
+	 *   - arch/x86/kvm/x86.c|10927| <<vcpu_enter_guest>> kvm_lapic_sync_from_vapic(vcpu);
+	 */
 	if (vcpu->arch.apic_attention)
 		kvm_lapic_sync_from_vapic(vcpu);
 
+	/*
+	 * apic_set_eoi
+	 * kvm_lapic_reg_write
+	 * vmx_set_msr
+	 * __kvm_set_msr
+	 * kvm_emulate_wrmsr
+	 * vmx_handle_exit
+	 * vcpu_enter_guest
+	 * vcpu_run
+	 * kvm_arch_vcpu_ioctl_run
+	 * kvm_vcpu_ioctl
+	 * __x64_sys_ioctl
+	 * do_syscall_64
+	 * entry_SYSCALL_64_after_hwframe
+	 *
+	 * vmx_handle_exit
+	 */
 	r = static_call(kvm_x86_handle_exit)(vcpu, exit_fastpath);
 	return r;
 
 cancel_injection:
 	if (req_immediate_exit)
 		kvm_make_request(KVM_REQ_EVENT, vcpu);
+	/*
+	 * vmx_cancel_injection
+	 * svm_cancel_injection
+	 */
 	static_call(kvm_x86_cancel_injection)(vcpu);
+	/*
+	 * 在以下调用kvm_lapic_sync_from_vapic():
+	 *   - arch/x86/kvm/x86.c|10896| <<vcpu_enter_guest>> kvm_lapic_sync_from_vapic(vcpu);
+	 *   - arch/x86/kvm/x86.c|10927| <<vcpu_enter_guest>> kvm_lapic_sync_from_vapic(vcpu);
+	 */
 	if (unlikely(vcpu->arch.apic_attention))
 		kvm_lapic_sync_from_vapic(vcpu);
 out:
 	return r;
 }
 
+/*
+ * 在以下使用vcpu_block():
+ *   - arch/x86/kvm/x86.c|11384| <<vcpu_run>> r = vcpu_block(kvm, vcpu);
+ */
 static inline int vcpu_block(struct kvm *kvm, struct kvm_vcpu *vcpu)
 {
 	bool hv_timer;
 
+	/*
+	 * 在以下使用x86的kvm_arch_vcpu_runnable():
+	 *   - arch/x86/kvm/x86.c|11309| <<vcpu_block>> if (!kvm_arch_vcpu_runnable(vcpu) &&
+	 *   - virt/kvm/kvm_main.c|3398| <<kvm_vcpu_check_block>> if (kvm_arch_vcpu_runnable(vcpu)) {
+	 *   - virt/kvm/kvm_main.c|3630| <<kvm_arch_dy_runnable>> return kvm_arch_vcpu_runnable(vcpu);
+	 *
+	 * 对于普通正在运行的vCPU, 满足二者之一就行:
+	 * 1. KVM_MP_STATE_RUNNABLE, 并且没有halted
+	 * 2. 对于已经存在的vCPU, 更多是检查vCPU有没有开中断
+	 * 和有没有pending的IRR
+	 *
+	 *
+	 * vmx_pre_block()
+	 */
 	if (!kvm_arch_vcpu_runnable(vcpu) &&
 	    (!kvm_x86_ops.pre_block || static_call(kvm_x86_pre_block)(vcpu) == 0)) {
 		/*
@@ -10305,29 +12925,75 @@ static inline int vcpu_block(struct kvm *kvm, struct kvm_vcpu *vcpu)
 			kvm_lapic_switch_to_sw_timer(vcpu);
 
 		srcu_read_unlock(&kvm->srcu, vcpu->srcu_idx);
+		/*
+		 * x86和arm在以下使用kvm_vcpu_block():
+		 *   - arch/arm64/kvm/handle_exit.c|98| <<kvm_handle_wfx>> kvm_vcpu_block(vcpu);
+		 *   - arch/arm64/kvm/psci.c|49| <<kvm_psci_vcpu_suspend>> kvm_vcpu_block(vcpu);
+		 *   - arch/x86/kvm/x86.c|11226| <<vcpu_block>> kvm_vcpu_block(vcpu);
+		 *   - arch/x86/kvm/x86.c|11445| <<kvm_arch_vcpu_ioctl_run>> kvm_vcpu_block(vcpu);
+		 *
+		 * The vCPU has executed a HLT instruction with in-kernel mode enabled.
+		 * 对于普通的x86的vCPU,只考虑vcpu_block()就行
+		 */
 		kvm_vcpu_block(vcpu);
 		vcpu->srcu_idx = srcu_read_lock(&kvm->srcu);
 
 		if (hv_timer)
 			kvm_lapic_switch_to_hv_timer(vcpu);
 
+		/*
+		 * vmx_post_block()
+		 */
 		if (kvm_x86_ops.post_block)
 			static_call(kvm_x86_post_block)(vcpu);
 
+		/*
+		 * x86和arm64在以下使用KVM_REQ_UNHALT:
+		 *   - arch/arm64/kvm/handle_exit.c|99| <<kvm_handle_wfx>> kvm_clear_request(KVM_REQ_UNHALT, vcpu);
+		 *   - arch/arm64/kvm/psci.c|50| <<kvm_psci_vcpu_suspend>> kvm_clear_request(KVM_REQ_UNHALT, vcpu);
+		 *   - arch/x86/kvm/x86.c|11370| <<vcpu_block>> if (!kvm_check_request(KVM_REQ_UNHALT, vcpu))
+		 *   - arch/x86/kvm/x86.c|11658| <<kvm_arch_vcpu_ioctl_run>> kvm_clear_request(KVM_REQ_UNHALT, vcpu);
+		 *   - virt/kvm/kvm_main.c|3458| <<kvm_vcpu_check_block>> kvm_make_request(KVM_REQ_UNHALT, vcpu);
+		 */
 		if (!kvm_check_request(KVM_REQ_UNHALT, vcpu))
 			return 1;
 	}
 
+	/*
+	 * 在以下使用kvm_apic_accept_events():
+	 *   - arch/x86/kvm/x86.c|10552| <<vcpu_enter_guest>> r = kvm_apic_accept_events(vcpu);
+	 *   - arch/x86/kvm/x86.c|10877| <<vcpu_block>> if (kvm_apic_accept_events(vcpu) < 0)
+	 *   - arch/x86/kvm/x86.c|11077| <<kvm_arch_vcpu_ioctl_run>> if (kvm_apic_accept_events(vcpu) < 0) {
+	 *   - arch/x86/kvm/x86.c|11313| <<kvm_arch_vcpu_ioctl_get_mpstate>> r = kvm_apic_accept_events(vcpu);
+	 *
+	 * 主要INIT和SIPI
+	 */
 	if (kvm_apic_accept_events(vcpu) < 0)
 		return 0;
 	switch(vcpu->arch.mp_state) {
 	case KVM_MP_STATE_HALTED:
 	case KVM_MP_STATE_AP_RESET_HOLD:
+		/*
+		 * 在以下使用kvm_vcpu_arch的pv_unhalted:
+		 *   - arch/x86/kvm/lapic.c|2005| <<__apic_accept_irq>> vcpu->arch.pv.pv_unhalted = 1;
+		 *   - arch/x86/kvm/x86.c|11341| <<vcpu_block>> vcpu->arch.pv.pv_unhalted = false;
+		 *   - arch/x86/kvm/x86.c|11793| <<kvm_arch_vcpu_ioctl_get_mpstate>> vcpu->arch.pv.pv_unhalted)
+		 *   - arch/x86/kvm/x86.c|13430| <<kvm_vcpu_has_events>> if (vcpu->arch.pv.pv_unhalted)
+		 *   - arch/x86/kvm/x86.c|13483| <<kvm_arch_dy_runnable>> if (READ_ONCE(vcpu->arch.pv.pv_unhalted))
+		 */
 		vcpu->arch.pv.pv_unhalted = false;
 		vcpu->arch.mp_state =
 			KVM_MP_STATE_RUNNABLE;
 		fallthrough;
 	case KVM_MP_STATE_RUNNABLE:
+		/*
+		 * 在以下使用kvm的halted:
+		 *   - arch/x86/kvm/x86.c|10791| <<vcpu_enter_guest>> vcpu->arch.apf.halted = true;
+		 *   - arch/x86/kvm/x86.c|11346| <<vcpu_block>> vcpu->arch.apf.halted = false;
+		 *   - arch/x86/kvm/x86.c|11362| <<kvm_vcpu_running>> !vcpu->arch.apf.halted);
+		 *   - arch/x86/kvm/x86.c|12566| <<kvm_vcpu_reset>> vcpu->arch.apf.halted = false;
+		 *   - arch/x86/kvm/x86.c|13776| <<kvm_arch_async_page_present>> vcpu->arch.apf.halted = false;
+		 */
 		vcpu->arch.apf.halted = false;
 		break;
 	case KVM_MP_STATE_INIT_RECEIVED:
@@ -10338,15 +13004,48 @@ static inline int vcpu_block(struct kvm *kvm, struct kvm_vcpu *vcpu)
 	return 1;
 }
 
+/*
+ * 在以下使用kvm_vcpu_running():
+ *   - arch/x86/kvm/x86.c|11381| <<vcpu_run>> if (kvm_vcpu_running(vcpu)) {
+ *   - arch/x86/kvm/x86.c|13470| <<kvm_arch_vcpu_runnable>> return kvm_vcpu_running(vcpu) || kvm_vcpu_has_events(vcpu);
+ */
 static inline bool kvm_vcpu_running(struct kvm_vcpu *vcpu)
 {
 	if (is_guest_mode(vcpu))
 		kvm_check_nested_events(vcpu);
 
+	/*
+	 * 在以下设置KVM_MP_STATE_HALTED:
+	 *   - arch/x86/kvm/x86.c|9217| <<kvm_vcpu_halt>> return __kvm_vcpu_halt(vcpu, KVM_MP_STATE_HALTED, KVM_EXIT_HLT); 
+	 *
+	 *
+	 * 在以下设置KVM_MP_STATE_RUNNABLE:
+	 *   - arch/x86/kvm/lapic.c|4712| <<kvm_apic_accept_events>> vcpu->arch.mp_state = KVM_MP_STATE_RUNNABLE;
+	 *   - arch/x86/kvm/lapic.c|4723| <<kvm_apic_accept_events>> vcpu->arch.mp_state = KVM_MP_STATE_RUNNABLE;
+	 *   - arch/x86/kvm/svm/nested.c|880| <<nested_svm_vmexit>> svm->vcpu.arch.mp_state = KVM_MP_STATE_RUNNABLE;
+	 *   - arch/x86/kvm/vmx/nested.c|4729| <<nested_vmx_vmexit>> vcpu->arch.mp_state = KVM_MP_STATE_RUNNABLE;
+	 *   - arch/x86/kvm/x86.c|11794| <<kvm_arch_vcpu_ioctl_get_mpstate>> mp_state->mp_state = KVM_MP_STATE_RUNNABLE;
+	 *   - arch/x86/kvm/x86.c|11966| <<__set_sregs_common>> vcpu->arch.mp_state = KVM_MP_STATE_RUNNABLE;
+	 *   - arch/x86/kvm/x86.c|12293| <<kvm_arch_vcpu_create>> vcpu->arch.mp_state = KVM_MP_STATE_RUNNABLE;
+	 *   - arch/x86/kvm/x86.c|13777| <<kvm_arch_async_page_present>> vcpu->arch.mp_state = KVM_MP_STATE_RUNNABLE;
+	 *
+	 * 在以下使用kvm的halted:
+	 *   - arch/x86/kvm/x86.c|10791| <<vcpu_enter_guest>> vcpu->arch.apf.halted = true;
+	 *   - arch/x86/kvm/x86.c|11346| <<vcpu_block>> vcpu->arch.apf.halted = false;
+	 *   - arch/x86/kvm/x86.c|11362| <<kvm_vcpu_running>> !vcpu->arch.apf.halted);
+	 *   - arch/x86/kvm/x86.c|12566| <<kvm_vcpu_reset>> vcpu->arch.apf.halted = false;
+	 *   - arch/x86/kvm/x86.c|13776| <<kvm_arch_async_page_present>> vcpu->arch.apf.halted = false;
+	 */
 	return (vcpu->arch.mp_state == KVM_MP_STATE_RUNNABLE &&
 		!vcpu->arch.apf.halted);
 }
 
+/*
+ * 在以下调用vcpu_run():
+ *   - arch/x86/kvm/x86.c|11591| <<kvm_arch_vcpu_ioctl_run>> r = vcpu_run(vcpu);
+ *
+ * caller什么循环也没有
+ */
 static int vcpu_run(struct kvm_vcpu *vcpu)
 {
 	int r;
@@ -10355,6 +13054,9 @@ static int vcpu_run(struct kvm_vcpu *vcpu)
 	vcpu->srcu_idx = srcu_read_lock(&kvm->srcu);
 	vcpu->arch.l1tf_flush_l1d = true;
 
+	/*
+	 * 这里应该是KVM的第一个循环
+	 */
 	for (;;) {
 		/*
 		 * If another guest vCPU requests a PV TLB flush in the middle
@@ -10363,6 +13065,11 @@ static int vcpu_run(struct kvm_vcpu *vcpu)
 		 * this point can start executing an instruction.
 		 */
 		vcpu->arch.at_instruction_boundary = false;
+		/*
+		 * 在以下使用kvm_vcpu_running():
+		 *   - arch/x86/kvm/x86.c|11381| <<vcpu_run>> if (kvm_vcpu_running(vcpu)) {
+		 *   - arch/x86/kvm/x86.c|13470| <<kvm_arch_vcpu_runnable>> return kvm_vcpu_running(vcpu) || kvm_vcpu_has_events(vcpu);
+		 */
 		if (kvm_vcpu_running(vcpu)) {
 			r = vcpu_enter_guest(vcpu);
 		} else {
@@ -10372,10 +13079,30 @@ static int vcpu_run(struct kvm_vcpu *vcpu)
 		if (r <= 0)
 			break;
 
+		/*
+		 * 在以下使用KVM_REQ_UNBLOCK:
+		 *   - arch/x86/kvm/lapic.c|2735| <<apic_timer_expired>> kvm_make_request(KVM_REQ_UNBLOCK, vcpu);
+		 *   - arch/x86/kvm/vmx/posted_intr.c|256| <<vmx_pi_start_assignment>> kvm_make_all_cpus_request(kvm, KVM_REQ_UNBLOCK);
+		 *   - arch/x86/kvm/x86.c|11444| <<vcpu_run>> kvm_clear_request(KVM_REQ_UNBLOCK, vcpu);
+		 *   - virt/kvm/kvm_main.c|3406| <<kvm_vcpu_check_block>> if (kvm_check_request(KVM_REQ_UNBLOCK, vcpu))
+		 */
 		kvm_clear_request(KVM_REQ_UNBLOCK, vcpu);
+		/*
+		 * 在以下使用kvm_cpu_has_pending_timer():
+		 *   - arch/x86/kvm/x86.c|11445| <<vcpu_run>> if (kvm_cpu_has_pending_timer(vcpu))
+		 *   - virt/kvm/kvm_main.c|3402| <<kvm_vcpu_check_block>> if (kvm_cpu_has_pending_timer(vcpu))
+		 *
+		 * 检查APIC的Timer寄存器是不是开了
+		 * 并且是不是有pending的
+		 */
 		if (kvm_cpu_has_pending_timer(vcpu))
 			kvm_inject_pending_timer_irqs(vcpu);
 
+		/*
+		 * 在以下使用kvm_vcpu_ready_for_interrupt_injection():
+		 *   - arch/x86/kvm/x86.c|9418| <<post_kvm_run_save>> kvm_vcpu_ready_for_interrupt_injection(vcpu);
+		 *   - arch/x86/kvm/x86.c|11078| <<vcpu_run>> kvm_vcpu_ready_for_interrupt_injection(vcpu)) {
+		 */
 		if (dm_request_for_irq_injection(vcpu) &&
 			kvm_vcpu_ready_for_interrupt_injection(vcpu)) {
 			r = 0;
@@ -10497,6 +13224,10 @@ static void kvm_put_guest_fpu(struct kvm_vcpu *vcpu)
 	trace_kvm_fpu(0);
 }
 
+/*
+ * 处理KVM_RUN:
+ *   - virt/kvm/kvm_main.c|4021| <<kvm_vcpu_ioctl(KVM_RUN)>> r = kvm_arch_vcpu_ioctl_run(vcpu);
+ */
 int kvm_arch_vcpu_ioctl_run(struct kvm_vcpu *vcpu)
 {
 	struct kvm_run *kvm_run = vcpu->run;
@@ -10517,12 +13248,39 @@ int kvm_arch_vcpu_ioctl_run(struct kvm_vcpu *vcpu)
 		 * use before KVM has ever run the vCPU.
 		 */
 		WARN_ON_ONCE(kvm_lapic_hv_timer_in_use(vcpu));
+		/*
+		 * x86和arm在以下使用kvm_vcpu_block():
+		 *   - arch/arm64/kvm/handle_exit.c|98| <<kvm_handle_wfx>> kvm_vcpu_block(vcpu);
+		 *   - arch/arm64/kvm/psci.c|49| <<kvm_psci_vcpu_suspend>> kvm_vcpu_block(vcpu);
+		 *   - arch/x86/kvm/x86.c|11226| <<vcpu_block>> kvm_vcpu_block(vcpu);
+		 *   - arch/x86/kvm/x86.c|11445| <<kvm_arch_vcpu_ioctl_run>> kvm_vcpu_block(vcpu);
+		 */
 		kvm_vcpu_block(vcpu);
+		/*
+		 * 在以下使用kvm_apic_accept_events():
+		 *   - arch/x86/kvm/x86.c|10552| <<vcpu_enter_guest>> r = kvm_apic_accept_events(vcpu);
+		 *   - arch/x86/kvm/x86.c|10877| <<vcpu_block>> if (kvm_apic_accept_events(vcpu) < 0)
+		 *   - arch/x86/kvm/x86.c|11077| <<kvm_arch_vcpu_ioctl_run>> if (kvm_apic_accept_events(vcpu) < 0) {
+		 *   - arch/x86/kvm/x86.c|11313| <<kvm_arch_vcpu_ioctl_get_mpstate>> r = kvm_apic_accept_events(vcpu);
+		 *
+		 * 主要SIPI和INIT
+		 */
 		if (kvm_apic_accept_events(vcpu) < 0) {
 			r = 0;
 			goto out;
 		}
+		/*
+		 * x86和arm64在以下使用KVM_REQ_UNHALT:
+		 *   - arch/arm64/kvm/handle_exit.c|99| <<kvm_handle_wfx>> kvm_clear_request(KVM_REQ_UNHALT, vcpu);
+		 *   - arch/arm64/kvm/psci.c|50| <<kvm_psci_vcpu_suspend>> kvm_clear_request(KVM_REQ_UNHALT, vcpu);
+		 *   - arch/x86/kvm/x86.c|11370| <<vcpu_block>> if (!kvm_check_request(KVM_REQ_UNHALT, vcpu))
+		 *   - arch/x86/kvm/x86.c|11658| <<kvm_arch_vcpu_ioctl_run>> kvm_clear_request(KVM_REQ_UNHALT, vcpu);
+		 *   - virt/kvm/kvm_main.c|3458| <<kvm_vcpu_check_block>> kvm_make_request(KVM_REQ_UNHALT, vcpu);
+		 */
 		kvm_clear_request(KVM_REQ_UNHALT, vcpu);
+		/*
+		 * 再来一次, 可能vCPU已经启动了
+		 */
 		r = -EAGAIN;
 		if (signal_pending(current)) {
 			r = -EINTR;
@@ -10539,6 +13297,9 @@ int kvm_arch_vcpu_ioctl_run(struct kvm_vcpu *vcpu)
 	}
 
 	if (kvm_run->kvm_dirty_regs) {
+		/*
+		 * 只在这里调用
+		 */
 		r = sync_regs(vcpu);
 		if (r != 0)
 			goto out;
@@ -10563,6 +13324,9 @@ int kvm_arch_vcpu_ioctl_run(struct kvm_vcpu *vcpu)
 		WARN_ON_ONCE(vcpu->mmio_needed);
 	}
 
+	/*
+	 * 只在这里一个地方用到vcpu_run()
+	 */
 	if (kvm_run->immediate_exit)
 		r = -EINTR;
 	else
@@ -10705,6 +13469,13 @@ static void __get_sregs_common(struct kvm_vcpu *vcpu, struct kvm_sregs *sregs)
 	sregs->cr4 = kvm_read_cr4(vcpu);
 	sregs->cr8 = kvm_get_cr8(vcpu);
 	sregs->efer = vcpu->arch.efer;
+	/*
+	 * 在以下使用kvm_get_apic_base():
+	 *   - arch/x86/kvm/x86.c|472| <<kvm_get_apic_mode>> return kvm_apic_mode(kvm_get_apic_base(vcpu));
+	 *   - arch/x86/kvm/x86.c|4074| <<kvm_get_msr_common>> msr_info->data = kvm_get_apic_base(vcpu);
+	 *   - arch/x86/kvm/x86.c|9617| <<post_kvm_run_save>> kvm_run->apic_base = kvm_get_apic_base(vcpu);
+	 *   - arch/x86/kvm/x86.c|11932| <<__get_sregs_common>> sregs->apic_base = kvm_get_apic_base(vcpu);
+	 */
 	sregs->apic_base = kvm_get_apic_base(vcpu);
 }
 
@@ -10754,11 +13525,26 @@ int kvm_arch_vcpu_ioctl_get_mpstate(struct kvm_vcpu *vcpu,
 	if (kvm_mpx_supported())
 		kvm_load_guest_fpu(vcpu);
 
+	/*
+	 * 在以下使用kvm_apic_accept_events():
+	 *   - arch/x86/kvm/x86.c|10552| <<vcpu_enter_guest>> r = kvm_apic_accept_events(vcpu);
+	 *   - arch/x86/kvm/x86.c|10877| <<vcpu_block>> if (kvm_apic_accept_events(vcpu) < 0)
+	 *   - arch/x86/kvm/x86.c|11077| <<kvm_arch_vcpu_ioctl_run>> if (kvm_apic_accept_events(vcpu) < 0) {
+	 *   - arch/x86/kvm/x86.c|11313| <<kvm_arch_vcpu_ioctl_get_mpstate>> r = kvm_apic_accept_events(vcpu);
+	 */
 	r = kvm_apic_accept_events(vcpu);
 	if (r < 0)
 		goto out;
 	r = 0;
 
+	/*
+	 * 在以下使用kvm_vcpu_arch的pv_unhalted:
+	 *   - arch/x86/kvm/lapic.c|2005| <<__apic_accept_irq>> vcpu->arch.pv.pv_unhalted = 1;
+	 *   - arch/x86/kvm/x86.c|11341| <<vcpu_block>> vcpu->arch.pv.pv_unhalted = false;
+	 *   - arch/x86/kvm/x86.c|11793| <<kvm_arch_vcpu_ioctl_get_mpstate>> vcpu->arch.pv.pv_unhalted)
+	 *   - arch/x86/kvm/x86.c|13430| <<kvm_vcpu_has_events>> if (vcpu->arch.pv.pv_unhalted)
+	 *   - arch/x86/kvm/x86.c|13483| <<kvm_arch_dy_runnable>> if (READ_ONCE(vcpu->arch.pv.pv_unhalted))
+	 */
 	if ((vcpu->arch.mp_state == KVM_MP_STATE_HALTED ||
 	     vcpu->arch.mp_state == KVM_MP_STATE_AP_RESET_HOLD) &&
 	    vcpu->arch.pv.pv_unhalted)
@@ -10807,6 +13593,13 @@ int kvm_arch_vcpu_ioctl_set_mpstate(struct kvm_vcpu *vcpu,
 	return ret;
 }
 
+/*
+ * 在以下使用kvm_task_switch():
+ *   - arch/x86/kvm/svm/svm.c|2574| <<task_switch_interception>> return kvm_task_switch(vcpu,
+ *                  tss_selector, int_vec, reason, has_error_code, error_code);
+ *   - arch/x86/kvm/vmx/vmx.c|5468| <<handle_task_switch>> return kvm_task_switch(vcpu,
+ *                  tss_selector, type == INTR_TYPE_SOFT_INTR ? idt_index : -1, reason, has_error_code, error_code);
+ */
 int kvm_task_switch(struct kvm_vcpu *vcpu, u16 tss_selector, int idt_index,
 		    int reason, bool has_error_code, u32 error_code)
 {
@@ -10855,6 +13648,11 @@ static bool kvm_is_valid_sregs(struct kvm_vcpu *vcpu, struct kvm_sregs *sregs)
 	       kvm_is_valid_cr0(vcpu, sregs->cr0);
 }
 
+/*
+ * 在以下调用__set_sregs_common():
+ *   - arch/x86/kvm/x86.c|11200| <<__set_sregs>> int ret = __set_sregs_common(vcpu, sregs, &mmu_reset_needed, true);
+ *   - arch/x86/kvm/x86.c|11234| <<__set_sregs2>> ret = __set_sregs_common(vcpu, (struct kvm_sregs *)sregs2,
+ */
 static int __set_sregs_common(struct kvm_vcpu *vcpu, struct kvm_sregs *sregs,
 		int *mmu_reset_needed, bool update_pdptrs)
 {
@@ -10867,6 +13665,11 @@ static int __set_sregs_common(struct kvm_vcpu *vcpu, struct kvm_sregs *sregs,
 
 	apic_base_msr.data = sregs->apic_base;
 	apic_base_msr.host_initiated = true;
+	/*
+	 * 在以下使用kvm_set_apic_base():
+	 *   - arch/x86/kvm/x86.c|3471| <<kvm_set_msr_common(MSR_IA32_APICBASE)>> return kvm_set_apic_base(vcpu, msr_info);
+	 *   - arch/x86/kvm/x86.c|11103| <<__set_sregs_common>> if (kvm_set_apic_base(vcpu, &apic_base_msr))
+	 */
 	if (kvm_set_apic_base(vcpu, &apic_base_msr))
 		return -EINVAL;
 
@@ -10927,6 +13730,11 @@ static int __set_sregs_common(struct kvm_vcpu *vcpu, struct kvm_sregs *sregs,
 	return 0;
 }
 
+/*
+ * 在以下调用__set_sregs():
+ *   - arch/x86/kvm/x86.c|11258| <<kvm_arch_vcpu_ioctl_set_sregs>> ret = __set_sregs(vcpu, sregs);
+ *   - arch/x86/kvm/x86.c|11438| <<sync_regs>> if (__set_sregs(vcpu, &vcpu->run->s.regs.sregs))
+ */
 static int __set_sregs(struct kvm_vcpu *vcpu, struct kvm_sregs *sregs)
 {
 	int pending_vec, max_bits;
@@ -10944,6 +13752,15 @@ static int __set_sregs(struct kvm_vcpu *vcpu, struct kvm_sregs *sregs)
 		(const unsigned long *)sregs->interrupt_bitmap, max_bits);
 
 	if (pending_vec < max_bits) {
+		/*
+		 * 在以下使用kvm_queue_interrupt():
+		 *   - arch/x86/kvm/svm/svm.c|4045| <<svm_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, false);
+		 *   - arch/x86/kvm/svm/svm.c|4048| <<svm_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, true);
+		 *   - arch/x86/kvm/vmx/vmx.c|6768| <<__vmx_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, type == INTR_TYPE_SOFT_INTR);
+		 *   - arch/x86/kvm/x86.c|4713| <<kvm_vcpu_ioctl_interrupt>> kvm_queue_interrupt(vcpu, irq->irq, false);
+		 *   - arch/x86/kvm/x86.c|9490| <<inject_pending_event>> kvm_queue_interrupt(vcpu, irq, false);
+		 *   - arch/x86/kvm/x86.c|11223| <<__set_sregs>> kvm_queue_interrupt(vcpu, pending_vec, false);
+		 */
 		kvm_queue_interrupt(vcpu, pending_vec, false);
 		pr_debug("Set back pending irq %d\n", pending_vec);
 		kvm_make_request(KVM_REQ_EVENT, vcpu);
@@ -10951,6 +13768,10 @@ static int __set_sregs(struct kvm_vcpu *vcpu, struct kvm_sregs *sregs)
 	return 0;
 }
 
+/*
+ * 在以下调用__set_sregs2():
+ *   - arch/x86/kvm/x86.c|5597| <<kvm_arch_vcpu_ioctl(KVM_SET_SREGS2)>> r = __set_sregs2(vcpu, u.sregs2);
+ */
 static int __set_sregs2(struct kvm_vcpu *vcpu, struct kvm_sregs2 *sregs2)
 {
 	int mmu_reset_needed = 0;
@@ -10983,6 +13804,10 @@ static int __set_sregs2(struct kvm_vcpu *vcpu, struct kvm_sregs2 *sregs2)
 	return 0;
 }
 
+/*
+ * 处理KVM_SET_SREGS:
+ *   - virt/kvm/kvm_main.c|4062| <<kvm_vcpu_ioctl(KVM_SET_SREGS)>> r = kvm_arch_vcpu_ioctl_set_sregs(vcpu, kvm_sregs);
+ */
 int kvm_arch_vcpu_ioctl_set_sregs(struct kvm_vcpu *vcpu,
 				  struct kvm_sregs *sregs)
 {
@@ -10994,6 +13819,10 @@ int kvm_arch_vcpu_ioctl_set_sregs(struct kvm_vcpu *vcpu,
 	return ret;
 }
 
+/*
+ * 在以下使用kvm_arch_vcpu_guestdbg_update_apicv_inhibit():
+ *   - arch/x86/kvm/x86.c|12068| <<kvm_arch_vcpu_ioctl_set_guest_debug>> kvm_arch_vcpu_guestdbg_update_apicv_inhibit(vcpu->kvm);
+ */
 static void kvm_arch_vcpu_guestdbg_update_apicv_inhibit(struct kvm *kvm)
 {
 	bool set = false;
@@ -11011,10 +13840,22 @@ static void kvm_arch_vcpu_guestdbg_update_apicv_inhibit(struct kvm *kvm)
 			break;
 		}
 	}
+	/*
+	 * 在以下调用__kvm_set_or_clear_apicv_inhibit():
+	 *   - arch/x86/kvm/hyperv.c|132| <<synic_update_vector>> __kvm_set_or_clear_apicv_inhibit(vcpu->kvm,
+	 *          APICV_INHIBIT_REASON_HYPERV, !!hv->synic_auto_eoi_used);
+	 *   - arch/x86/kvm/x86.c|10434| <<kvm_set_or_clear_apicv_inhibit>> __kvm_set_or_clear_apicv_inhibit(kvm, reason, set);
+	 *   - arch/x86/kvm/x86.c|12032| <<kvm_arch_vcpu_guestdbg_update_apicv_inhibit>> __kvm_set_or_clear_apicv_inhibit(kvm,
+	 *          APICV_INHIBIT_REASON_BLOCKIRQ, set);
+	 */
 	__kvm_set_or_clear_apicv_inhibit(kvm, APICV_INHIBIT_REASON_BLOCKIRQ, set);
 	up_write(&kvm->arch.apicv_update_lock);
 }
 
+/*
+ * 在以下使用kvm_arch_vcpu_ioctl_set_guest_debug():
+ *   - virt/kvm/kvm_main.c|4122| <<kvm_vcpu_ioctl(KVM_SET_GUEST_DEBUG)>> r = kvm_arch_vcpu_ioctl_set_guest_debug(vcpu, &dbg);
+ */
 int kvm_arch_vcpu_ioctl_set_guest_debug(struct kvm_vcpu *vcpu,
 					struct kvm_guest_debug *dbg)
 {
@@ -11162,6 +14003,10 @@ static void store_regs(struct kvm_vcpu *vcpu)
 				vcpu, &vcpu->run->s.regs.events);
 }
 
+/*
+ * 在以下调用sync_regs():
+ *   - arch/x86/kvm/x86.c|10808| <<kvm_arch_vcpu_ioctl_run>> r = sync_regs(vcpu); 
+ */
 static int sync_regs(struct kvm_vcpu *vcpu)
 {
 	if (vcpu->run->kvm_dirty_regs & KVM_SYNC_X86_REGS) {
@@ -11232,6 +14077,17 @@ int kvm_arch_vcpu_create(struct kvm_vcpu *vcpu)
 		 */
 		if (enable_apicv) {
 			vcpu->arch.apicv_active = true;
+			/*
+			 * 在以下使用KVM_REQ_APICV_UPDATE:
+			 *   - arch/x86/kvm/svm/nested.c|729| <<enter_svm_guest_mode>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+			 *   - arch/x86/kvm/svm/nested.c|1111| <<svm_leave_nested>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+			 *   - arch/x86/kvm/vmx/nested.c|4696| <<nested_vmx_vmexit>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+			 *   - arch/x86/kvm/x86.c|10189| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_APICV_UPDATE, vcpu))
+			 *   - arch/x86/kvm/x86.c|11394| <<kvm_arch_vcpu_create>> kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
+			 *
+			 * 处理的函数:
+			 * kvm_vcpu_update_apicv(vcpu);
+			 */
 			kvm_make_request(KVM_REQ_APICV_UPDATE, vcpu);
 		}
 	} else
@@ -11325,6 +14181,21 @@ void kvm_arch_vcpu_postcreate(struct kvm_vcpu *vcpu)
 
 	mutex_unlock(&vcpu->mutex);
 
+	/*
+	 * 在以下使用kvmclock_periodic_sync:
+	 *   - arch/x86/kvm/x86.c|149| <<global>> static bool __read_mostly kvmclock_periodic_sync = true;
+	 *   - arch/x86/kvm/x86.c|3526| <<kvmclock_sync_fn>> if (!kvmclock_periodic_sync)
+	 *   - arch/x86/kvm/x86.c|12996| <<kvm_arch_vcpu_postcreate>> if (kvmclock_periodic_sync && vcpu->vcpu_idx == 0)
+	 *
+	 *
+	 * 在以下使用kvm_arch->kvmclock_sync_work:
+	 *   - arch/x86/kvm/x86.c|3535| <<kvmclock_sync_fn>> schedule_delayed_work(&kvm->arch.kvmclock_sync_work, KVMCLOCK_SYNC_PERIOD);
+	 *   - arch/x86/kvm/x86.c|12997| <<kvm_arch_vcpu_postcreate>> schedule_delayed_work(&kvm->arch.kvmclock_sync_work, KVMCLOCK_SYNC_PERIOD);
+	 *   - arch/x86/kvm/x86.c|13530| <<kvm_arch_init_vm>> INIT_DELAYED_WORK(&kvm->arch.kvmclock_sync_work, kvmclock_sync_fn);
+	 *   - arch/x86/kvm/x86.c|13577| <<kvm_arch_sync_events>> cancel_delayed_work_sync(&kvm->arch.kvmclock_sync_work);
+	 *
+	 * kvmclock_sync_fn()
+	 */
 	if (kvmclock_periodic_sync && vcpu->vcpu_idx == 0)
 		schedule_delayed_work(&kvm->arch.kvmclock_sync_work,
 						KVMCLOCK_SYNC_PERIOD);
@@ -11355,6 +14226,45 @@ void kvm_arch_vcpu_destroy(struct kvm_vcpu *vcpu)
 		static_branch_dec(&kvm_has_noapic_vcpu);
 }
 
+/*
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_vcpu_reset
+ * kvm_apic_accept_events
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * __kvm_set_or_clear_apicv_inhibit
+ * __kvm_set_or_clear_apicv_inhibit
+ * kvm_set_or_clear_apicv_inhibit
+ * kvm_recalculate_apic_map
+ * kvm_lapic_reg_write
+ * vmx_set_msr
+ * __kvm_set_msr
+ * kvm_emulate_wrmsr
+ * vmx_handle_exit
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ *
+ * 在以下使用:
+ *   - arch/x86/kvm/lapic.c|3537| <<kvm_apic_accept_events>> kvm_vcpu_reset(vcpu, true);
+ *   - arch/x86/kvm/svm/svm.c|2230| <<shutdown_interception>> kvm_vcpu_reset(vcpu, true);
+ *   - arch/x86/kvm/x86.c|11655| <<kvm_arch_vcpu_create>> kvm_vcpu_reset(vcpu, false);
+ *
+ * 只在VM里面online/offline也会调用kvm_vcpu_reset()
+ * online的时候调用
+ */
 void kvm_vcpu_reset(struct kvm_vcpu *vcpu, bool init_event)
 {
 	unsigned long old_cr0 = kvm_read_cr0(vcpu);
@@ -11370,6 +14280,19 @@ void kvm_vcpu_reset(struct kvm_vcpu *vcpu, bool init_event)
 	if (is_guest_mode(vcpu))
 		kvm_leave_nested(vcpu);
 
+	/*
+	 * __kvm_set_or_clear_apicv_inhibit
+	 * __kvm_set_or_clear_apicv_inhibit
+	 * kvm_set_or_clear_apicv_inhibit
+	 * kvm_recalculate_apic_map
+	 * kvm_vcpu_reset
+	 * kvm_apic_accept_events
+	 * kvm_arch_vcpu_ioctl_run
+	 * kvm_vcpu_ioctl
+	 * __x64_sys_ioctl
+	 * do_syscall_64
+	 * entry_SYSCALL_64_after_hwframe
+	 */
 	kvm_lapic_reset(vcpu, init_event);
 
 	WARN_ON_ONCE(is_guest_mode(vcpu) || is_smm(vcpu));
@@ -11377,9 +14300,26 @@ void kvm_vcpu_reset(struct kvm_vcpu *vcpu, bool init_event)
 
 	vcpu->arch.smi_pending = 0;
 	vcpu->arch.smi_count = 0;
+	/*
+	 * 在以下使用kvm_vcpu_arch->nmi_queued:
+	 *   - arch/x86/kvm/x86.c|874| <<kvm_inject_nmi>> atomic_inc(&vcpu->arch.nmi_queued);
+	 *   - arch/x86/kvm/x86.c|5158| <<kvm_vcpu_ioctl_x86_set_vcpu_events>> atomic_set(&vcpu->arch.nmi_queued, events->nmi.pending);
+	 *   - arch/x86/kvm/x86.c|9855| <<process_nmi>> vcpu->arch.nmi_pending += atomic_xchg(&vcpu->arch.nmi_queued, 0);
+	 *   - arch/x86/kvm/x86.c|12376| <<kvm_vcpu_reset>> atomic_set(&vcpu->arch.nmi_queued, 0);
+	 */
 	atomic_set(&vcpu->arch.nmi_queued, 0);
 	vcpu->arch.nmi_pending = 0;
 	vcpu->arch.nmi_injected = false;
+	/*
+	 * 在以下调用kvm_clear_interrupt_queue():
+	 *   - arch/x86/kvm/svm/nested.c|1017| <<nested_svm_vmexit>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/svm/svm.c|2556| <<task_switch_interception>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/svm/svm.c|4012| <<svm_complete_interrupts>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/vmx/nested.c|4645| <<nested_vmx_vmexit>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|5440| <<handle_task_switch>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/vmx/vmx.c|6799| <<__vmx_complete_interrupts>> kvm_clear_interrupt_queue(vcpu);
+	 *   - arch/x86/kvm/x86.c|11947| <<kvm_vcpu_reset>> kvm_clear_interrupt_queue(vcpu);
+	 */
 	kvm_clear_interrupt_queue(vcpu);
 	kvm_clear_exception_queue(vcpu);
 
@@ -11400,6 +14340,14 @@ void kvm_vcpu_reset(struct kvm_vcpu *vcpu, bool init_event)
 
 	kvm_clear_async_pf_completion_queue(vcpu);
 	kvm_async_pf_hash_reset(vcpu);
+	/*
+	 * 在以下使用kvm的halted:
+	 *   - arch/x86/kvm/x86.c|10791| <<vcpu_enter_guest>> vcpu->arch.apf.halted = true;
+	 *   - arch/x86/kvm/x86.c|11346| <<vcpu_block>> vcpu->arch.apf.halted = false;
+	 *   - arch/x86/kvm/x86.c|11362| <<kvm_vcpu_running>> !vcpu->arch.apf.halted);
+	 *   - arch/x86/kvm/x86.c|12566| <<kvm_vcpu_reset>> vcpu->arch.apf.halted = false;
+	 *   - arch/x86/kvm/x86.c|13776| <<kvm_arch_async_page_present>> vcpu->arch.apf.halted = false;
+	 */
 	vcpu->arch.apf.halted = false;
 
 	if (vcpu->arch.guest_fpu.fpstate && kvm_mpx_supported()) {
@@ -11525,6 +14473,9 @@ int kvm_arch_hardware_enable(void)
 	stable = !kvm_check_tsc_unstable();
 	list_for_each_entry(kvm, &vm_list, vm_list) {
 		kvm_for_each_vcpu(i, vcpu, kvm) {
+			/*
+			 * 处理KVM_REQ_CLOCK_UPDATE的函数: kvm_guest_time_update()
+			 */
 			if (!stable && vcpu->cpu == smp_processor_id())
 				kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
 			if (stable && vcpu->arch.last_host_tsc > local_tsc) {
@@ -11580,6 +14531,18 @@ int kvm_arch_hardware_enable(void)
 			kvm_for_each_vcpu(i, vcpu, kvm) {
 				vcpu->arch.tsc_offset_adjustment += delta_cyc;
 				vcpu->arch.last_host_tsc = local_tsc;
+				/*
+				 * 在以下使用KVM_REQ_MASTERCLOCK_UPDATE():
+				 *   - arch/x86/kvm/hyperv.c|1411| <<kvm_hv_set_msr_pw>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+				 *   - arch/x86/kvm/x86.c|2444| <<kvm_write_system_time>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+				 *   - arch/x86/kvm/x86.c|2647| <<kvm_track_tsc_matching>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+				 *   - arch/x86/kvm/x86.c|9496| <<pvclock_gtod_update_fn>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+				 *   - arch/x86/kvm/x86.c|11224| <<vcpu_enter_guest>> if (kvm_check_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu))
+				 *   - arch/x86/kvm/x86.c|13427| <<kvm_arch_hardware_enable>> kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
+				 *   - arch/x86/kvm/xen.c|58| <<kvm_xen_shared_info_init>> kvm_make_all_cpus_request(kvm, KVM_REQ_MASTERCLOCK_UPDATE);
+				 *
+				 * 处理KVM_REQ_MASTERCLOCK_UPDATE的函数: kvm_gen_update_masterclock()
+				 */
 				kvm_make_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu);
 			}
 
@@ -11631,6 +14594,21 @@ int kvm_arch_hardware_setup(void *opaque)
 	cr4_reserved_bits = __cr4_reserved_bits(__kvm_cpu_cap_has, UNUSED_);
 #undef __kvm_cpu_cap_has
 
+	/*
+	 * 在以下设置kvm_has_tsc_control:
+	 *   - arch/x86/kvm/svm/svm.c|1115| <<svm_hardware_setup>> kvm_has_tsc_control = true;
+	 *   - arch/x86/kvm/vmx/vmx.c|8787| <<hardware_setup>> kvm_has_tsc_control = true;
+	 * 在以下使用kvm_has_tsc_control:
+	 *   - arch/x86/kvm/debugfs.c|69| <<kvm_arch_create_vcpu_debugfs>> if (kvm_has_tsc_control) {
+	 *   - arch/x86/kvm/vmx/nested.c|2581| <<prepare_vmcs02>> if (kvm_has_tsc_control)
+	 *   - arch/x86/kvm/vmx/nested.c|4680| <<nested_vmx_vmexit>> if (kvm_has_tsc_control)
+	 *   - arch/x86/kvm/x86.c|2579| <<set_tsc_khz>> if (!kvm_has_tsc_control) {
+	 *   - arch/x86/kvm/x86.c|2843| <<kvm_vcpu_write_tsc_multiplier>> if (kvm_has_tsc_control)
+	 *   - arch/x86/kvm/x86.c|3607| <<kvm_guest_time_update>> if (kvm_has_tsc_control)
+	 *   - arch/x86/kvm/x86.c|4951| <<kvm_vm_ioctl_check_extension>> r = kvm_has_tsc_control;
+	 *   - arch/x86/kvm/x86.c|6207| <<kvm_arch_vcpu_ioctl(KVM_SET_TSC_KHZ)>> if (kvm_has_tsc_control &
+	 *   - arch/x86/kvm/x86.c|13736| <<kvm_arch_hardware_setup>> if (kvm_has_tsc_control) {
+	 */
 	if (kvm_has_tsc_control) {
 		/*
 		 * Make sure the user can only configure tsc_khz values that
@@ -11642,6 +14620,21 @@ int kvm_arch_hardware_setup(void *opaque)
 			      __scale_tsc(kvm_max_tsc_scaling_ratio, tsc_khz));
 		kvm_max_guest_tsc_khz = max;
 
+		/*
+		 * 在以下使用kvm_tsc_scaling_ratio_frac_bits:
+		 *   - arch/x86/kvm/debugfs.c|51| <<vcpu_get_tsc_scaling_frac_bits>> *val = kvm_tsc_scaling_ratio_frac_bits;
+		 *   - arch/x86/kvm/svm/svm.c|1117| <<svm_hardware_setup>> kvm_tsc_scaling_ratio_frac_bits = 32;
+		 *   - arch/x86/kvm/vmx/vmx.c|8358| <<vmx_set_hv_timer>> if (vcpu->arch.l1_tsc_scaling_ratio != kvm_default_tsc_scaling_ratio
+		 *              && delta_tsc && u64_shl_div_u64(delta_tsc, kvm_tsc_scaling_ratio_frac_bits, vcpu->arch.l1_tsc_scaling_ratio, &delta_tsc))
+		 *   - arch/x86/kvm/vmx/vmx.c|8789| <<hardware_setup>> kvm_tsc_scaling_ratio_frac_bits = 48;
+		 *   - arch/x86/kvm/x86.c|2561| <<set_tsc_khz>> ratio = mul_u64_u32_div(1ULL << kvm_tsc_scaling_ratio_frac_bits, user_tsc_khz, tsc_khz);
+		 *   - arch/x86/kvm/x86.c|2702| <<__scale_tsc>> return mul_u64_u64_shr(tsc, ratio, kvm_tsc_scaling_ratio_frac_bits);
+		 *   - arch/x86/kvm/x86.c|2740| <<kvm_calc_nested_tsc_offset>> nested_offset = mul_s64_u64_shr((s64) l1_offset,
+		 *              l2_multiplier, kvm_tsc_scaling_ratio_frac_bits);
+		 *   - arch/x86/kvm/x86.c|2751| <<kvm_calc_nested_tsc_multiplier>> return mul_u64_u64_shr(l1_multiplier, l2_multiplier,
+		 *              kvm_tsc_scaling_ratio_frac_bits);
+		 *   - arch/x86/kvm/x86.c|13707| <<kvm_arch_hardware_setup>> kvm_default_tsc_scaling_ratio = 1ULL << kvm_tsc_scaling_ratio_frac_bits;
+		 */
 		kvm_default_tsc_scaling_ratio = 1ULL << kvm_tsc_scaling_ratio_frac_bits;
 	}
 
@@ -11715,6 +14708,12 @@ int kvm_arch_init_vm(struct kvm *kvm, unsigned long type)
 	if (ret)
 		return ret;
 
+	/*
+	 * 在以下使用kvm_arch->mask_notifier_list:
+	 *   - arch/x86/kvm/irq_comm.c|234| <<kvm_register_irq_mask_notifier>> hlist_add_head_rcu(&kimn->link, &kvm->arch.mask_notifier_list);
+	 *   - arch/x86/kvm/irq_comm.c|256| <<kvm_fire_mask_notifiers>> hlist_for_each_entry_rcu(kimn, &kvm->arch.mask_notifier_list, link)
+	 *   - arch/x86/kvm/x86.c|11763| <<kvm_arch_init_vm>> INIT_HLIST_HEAD(&kvm->arch.mask_notifier_list);
+	 */
 	INIT_HLIST_HEAD(&kvm->arch.mask_notifier_list);
 	INIT_LIST_HEAD(&kvm->arch.active_mmu_pages);
 	INIT_LIST_HEAD(&kvm->arch.zapped_obsolete_pages);
@@ -11722,6 +14721,13 @@ int kvm_arch_init_vm(struct kvm *kvm, unsigned long type)
 	INIT_LIST_HEAD(&kvm->arch.assigned_dev_head);
 	atomic_set(&kvm->arch.noncoherent_dma_count, 0);
 
+	/*
+	 * 在以下使用kvm_arch->irq_sources_bitmap:
+	 *   - arch/x86/kvm/irq_comm.c|187| <<kvm_request_irq_source_id>> unsigned long *bitmap = &kvm->arch.irq_sources_bitmap;
+	 *   - arch/x86/kvm/irq_comm.c|219| <<kvm_free_irq_source_id>> clear_bit(irq_source_id, &kvm->arch.irq_sources_bitmap);
+	 *   - arch/x86/kvm/x86.c|11732| <<kvm_arch_init_vm>> set_bit(KVM_USERSPACE_IRQ_SOURCE_ID, &kvm->arch.irq_sources_bitmap);
+	 *   - arch/x86/kvm/x86.c|11735| <<kvm_arch_init_vm>> set_bit(KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID, &kvm->arch.irq_sources_bitmap);
+	 */
 	/* Reserve bit 0 of irq_sources_bitmap for userspace irq source */
 	set_bit(KVM_USERSPACE_IRQ_SOURCE_ID, &kvm->arch.irq_sources_bitmap);
 	/* Reserve bit 1 of irq_sources_bitmap for irqfd-resampler */
@@ -11729,10 +14735,46 @@ int kvm_arch_init_vm(struct kvm *kvm, unsigned long type)
 		&kvm->arch.irq_sources_bitmap);
 
 	raw_spin_lock_init(&kvm->arch.tsc_write_lock);
+	/*
+	 * 在以下使用kvm_arch->apic_map_lock:
+	 *   - arch/x86/kvm/lapic.c|375| <<kvm_recalculate_apic_map>> mutex_lock(&kvm->arch.apic_map_lock);
+	 *   - arch/x86/kvm/lapic.c|383| <<kvm_recalculate_apic_map>> mutex_unlock(&kvm->arch.apic_map_lock);
+	 *   - arch/x86/kvm/lapic.c|506| <<kvm_recalculate_apic_map>> old = rcu_dereference_protected(kvm->arch.apic_map,
+	 *                                     lockdep_is_held(&kvm->arch.apic_map_lock));
+	 *   - arch/x86/kvm/lapic.c|514| <<kvm_recalculate_apic_map>> mutex_unlock(&kvm->arch.apic_map_lock);
+	 *   - arch/x86/kvm/x86.c|12397| <<kvm_arch_init_vm>> mutex_init(&kvm->arch.apic_map_lock);
+	 */
 	mutex_init(&kvm->arch.apic_map_lock);
+	/*
+	 * 使用kvm_arch->pvclock_gtod_sync_lock的函数:
+	 *   - kvm_synchronize_tsc()
+	 *   - kvm_gen_update_masterclock()
+	 *   - get_kvmclock_ns()
+	 *   - kvm_guest_time_update()
+	 *   - kvm_arch_vm_ioctl(KVM_SET_CLOCK)
+	 *   - kvm_hyperv_tsc_notifier()
+	 *   - kvm_arch_init_vm()
+	 */
 	raw_spin_lock_init(&kvm->arch.pvclock_gtod_sync_lock);
 
+	/*
+	 * 在以下设置kvm_arch->kvmclock_offset:
+	 *   - arch/x86/kvm/x86.c|6814| <<kvm_arch_vm_ioctl(KVM_SET_CLOCK)>> ka->kvmclock_offset = user_ns.clock - now_ns;
+	 *   - arch/x86/kvm/x86.c|13280| <<kvm_arch_init_vm>> kvm->arch.kvmclock_offset = -get_kvmclock_base_ns();
+	 * 在以下使用kvm_arch->kvmclock_offset:
+	 *   - arch/x86/kvm/pmu.c|342| <<kvm_pmu_rdpmc_vmware>> ctr_val = ktime_get_boottime_ns() + vcpu->kvm->arch.kvmclock_offset;
+	 *   - arch/x86/kvm/x86.c|3141| <<get_kvmclock_ns>> return get_kvmclock_base_ns() + ka->kvmclock_offset;
+	 *   - arch/x86/kvm/x86.c|3145| <<get_kvmclock_ns>> hv_clock.system_time = ka->master_kernel_ns + ka->kvmclock_offset;
+	 *   - arch/x86/kvm/x86.c|3167| <<get_kvmclock_ns>> ret = get_kvmclock_base_ns() + ka->kvmclock_offset;
+	 *   - arch/x86/kvm/x86.c|3307| <<kvm_guest_time_update>> vcpu->hv_clock.system_time = kernel_ns + v->kvm->arch.kvmclock_offset;
+	 */
 	kvm->arch.kvmclock_offset = -get_kvmclock_base_ns();
+	/*
+	 * 在以下使用pvclock_update_vm_gtod_copy():
+	 *   - arch/x86/kvm/x86.c|3110| <<kvm_gen_update_masterclock>> pvclock_update_vm_gtod_copy(kvm);
+	 *   - arch/x86/kvm/x86.c|8999| <<kvm_hyperv_tsc_notifier>> pvclock_update_vm_gtod_copy(kvm);
+	 *   - arch/x86/kvm/x86.c|13281| <<kvm_arch_init_vm>> pvclock_update_vm_gtod_copy(kvm);
+	 */
 	pvclock_update_vm_gtod_copy(kvm);
 
 	kvm->arch.guest_can_read_msr_platform_info = true;
@@ -11742,7 +14784,25 @@ int kvm_arch_init_vm(struct kvm *kvm, unsigned long type)
 	kvm->arch.hv_root_tdp = INVALID_PAGE;
 #endif
 
+	/*
+	 * 在以下使用kvm_arch->kvmclock_update_work:
+	 *   - arch/x86/kvm/x86.c|3508| <<kvm_gen_kvmclock_update>> schedule_delayed_work(&kvm->arch.kvmclock_update_work, KVMCLOCK_UPDATE_DELAY);
+	 *   - arch/x86/kvm/x86.c|3529| <<kvmclock_sync_fn>> schedule_delayed_work(&kvm->arch.kvmclock_update_work, 0);
+	 *   - arch/x86/kvm/x86.c|13529| <<kvm_arch_init_vm>> INIT_DELAYED_WORK(&kvm->arch.kvmclock_update_work, kvmclock_update_fn);
+	 *   - arch/x86/kvm/x86.c|13578| <<kvm_arch_sync_events>> cancel_delayed_work_sync(&kvm->arch.kvmclock_update_work);
+	 *
+	 * kvmclock_update_fn()
+	 */
 	INIT_DELAYED_WORK(&kvm->arch.kvmclock_update_work, kvmclock_update_fn);
+	/*
+	 * 在以下使用kvm_arch->kvmclock_sync_work:
+	 *   - arch/x86/kvm/x86.c|3535| <<kvmclock_sync_fn>> schedule_delayed_work(&kvm->arch.kvmclock_sync_work, KVMCLOCK_SYNC_PERIOD);
+	 *   - arch/x86/kvm/x86.c|12997| <<kvm_arch_vcpu_postcreate>> schedule_delayed_work(&kvm->arch.kvmclock_sync_work, KVMCLOCK_SYNC_PERIOD);
+	 *   - arch/x86/kvm/x86.c|13530| <<kvm_arch_init_vm>> INIT_DELAYED_WORK(&kvm->arch.kvmclock_sync_work, kvmclock_sync_fn);
+	 *   - arch/x86/kvm/x86.c|13577| <<kvm_arch_sync_events>> cancel_delayed_work_sync(&kvm->arch.kvmclock_sync_work);
+	 *
+	 * kvmclock_sync_fn()
+	 */
 	INIT_DELAYED_WORK(&kvm->arch.kvmclock_sync_work, kvmclock_sync_fn);
 
 	kvm_apicv_init(kvm);
@@ -11790,7 +14850,25 @@ static void kvm_free_vcpus(struct kvm *kvm)
 
 void kvm_arch_sync_events(struct kvm *kvm)
 {
+	/*
+	 * 在以下使用kvm_arch->kvmclock_sync_work:
+	 *   - arch/x86/kvm/x86.c|3535| <<kvmclock_sync_fn>> schedule_delayed_work(&kvm->arch.kvmclock_sync_work, KVMCLOCK_SYNC_PERIOD);
+	 *   - arch/x86/kvm/x86.c|12997| <<kvm_arch_vcpu_postcreate>> schedule_delayed_work(&kvm->arch.kvmclock_sync_work, KVMCLOCK_SYNC_PERIOD);
+	 *   - arch/x86/kvm/x86.c|13530| <<kvm_arch_init_vm>> INIT_DELAYED_WORK(&kvm->arch.kvmclock_sync_work, kvmclock_sync_fn);
+	 *   - arch/x86/kvm/x86.c|13577| <<kvm_arch_sync_events>> cancel_delayed_work_sync(&kvm->arch.kvmclock_sync_work);
+	 *
+	 * kvmclock_sync_fn()
+	 */
 	cancel_delayed_work_sync(&kvm->arch.kvmclock_sync_work);
+	/*
+	 * 在以下使用kvm_arch->kvmclock_update_work:
+	 *   - arch/x86/kvm/x86.c|3508| <<kvm_gen_kvmclock_update>> schedule_delayed_work(&kvm->arch.kvmclock_update_work, KVMCLOCK_UPDATE_DELAY);
+	 *   - arch/x86/kvm/x86.c|3529| <<kvmclock_sync_fn>> schedule_delayed_work(&kvm->arch.kvmclock_update_work, 0);
+	 *   - arch/x86/kvm/x86.c|13529| <<kvm_arch_init_vm>> INIT_DELAYED_WORK(&kvm->arch.kvmclock_update_work, kvmclock_update_fn);
+	 *   - arch/x86/kvm/x86.c|13578| <<kvm_arch_sync_events>> cancel_delayed_work_sync(&kvm->arch.kvmclock_update_work);
+	 *
+	 * kvmclock_update_fn()
+	 */
 	cancel_delayed_work_sync(&kvm->arch.kvmclock_update_work);
 	kvm_free_pit(kvm);
 }
@@ -11896,6 +14974,17 @@ void kvm_arch_destroy_vm(struct kvm *kvm)
 	kvm_pic_destroy(kvm);
 	kvm_ioapic_destroy(kvm);
 	kvm_free_vcpus(kvm);
+	/*
+	 * 在以下使用kvm_arch->apic_map:
+	 *   - arch/x86/kvm/lapic.c|581| <<kvm_recalculate_apic_map>> old = rcu_dereference_protected(kvm->arch.apic_map,
+	 *   - arch/x86/kvm/lapic.c|583| <<kvm_recalculate_apic_map>> rcu_assign_pointer(kvm->arch.apic_map, new);
+	 *   - arch/x86/kvm/lapic.c|1305| <<kvm_pv_send_ipi>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1772| <<kvm_irq_delivery_to_apic_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|1825| <<kvm_intr_is_single_vcpu_fast>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/lapic.c|2023| <<kvm_bitmap_or_dest_vcpus>> map = rcu_dereference(kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|9391| <<kvm_sched_yield>> map = rcu_dereference(vcpu->kvm->arch.apic_map);
+	 *   - arch/x86/kvm/x86.c|13061| <<kvm_arch_destroy_vm>> kvfree(rcu_dereference_check(kvm->arch.apic_map, 1));
+	 */
 	kvfree(rcu_dereference_check(kvm->arch.apic_map, 1));
 	kfree(srcu_dereference_check(kvm->arch.pmu_event_filter, &kvm->srcu, 1));
 	kvm_mmu_uninit_vm(kvm);
@@ -12219,20 +15308,45 @@ static inline bool kvm_guest_apic_has_interrupt(struct kvm_vcpu *vcpu)
 		static_call(kvm_x86_guest_apic_has_interrupt)(vcpu));
 }
 
+/*
+ * 在以下使用kvm_vcpu_has_events():
+ *   - arch/x86/kvm/x86.c|12810| <<kvm_arch_vcpu_runnable>> return kvm_vcpu_running(vcpu) || kvm_vcpu_has_events(vcpu);
+ *
+ * 对于已经存在的vCPU, 更多是检查vCPU有没有开中断
+ * 和有没有pending的IRR
+ */
 static inline bool kvm_vcpu_has_events(struct kvm_vcpu *vcpu)
 {
 	if (!list_empty_careful(&vcpu->async_pf.done))
 		return true;
 
+	/*
+	 * 只在这里调用
+	 * 主要是KVM_APIC_INIT和KVM_APIC_SIPI
+	 */
 	if (kvm_apic_has_events(vcpu))
 		return true;
 
+	/*
+	 * 在以下使用kvm_vcpu_arch的pv_unhalted:
+	 *   - arch/x86/kvm/lapic.c|2005| <<__apic_accept_irq(APIC_DM_REMRD)>> vcpu->arch.pv.pv_unhalted = 1;
+	 *   - arch/x86/kvm/x86.c|11341| <<vcpu_block>> vcpu->arch.pv.pv_unhalted = false;
+	 *   - arch/x86/kvm/x86.c|11793| <<kvm_arch_vcpu_ioctl_get_mpstate>> vcpu->arch.pv.pv_unhalted)
+	 *   - arch/x86/kvm/x86.c|13430| <<kvm_vcpu_has_events>> if (vcpu->arch.pv.pv_unhalted)
+	 *   - arch/x86/kvm/x86.c|13483| <<kvm_arch_dy_runnable>> if (READ_ONCE(vcpu->arch.pv.pv_unhalted))
+	 */
 	if (vcpu->arch.pv.pv_unhalted)
 		return true;
 
 	if (vcpu->arch.exception.pending)
 		return true;
 
+	/*
+	 * 在以下使用kvm_x86_nmi_allowed():
+	 *   - arch/x86/kvm/x86.c|9727| <<inject_pending_event>> r = can_inject ? static_call(kvm_x86_nmi_allowed)(vcpu, true) : -EBUSY;
+	 *   - arch/x86/kvm/x86.c|9735| <<inject_pending_event>> WARN_ON(static_call(kvm_x86_nmi_allowed)(vcpu, true) < 0);
+	 *   - arch/x86/kvm/x86.c|13270| <<kvm_vcpu_has_events>> static_call(kvm_x86_nmi_allowed)(vcpu, false)))
+	 */
 	if (kvm_test_request(KVM_REQ_NMI, vcpu) ||
 	    (vcpu->arch.nmi_pending &&
 	     static_call(kvm_x86_nmi_allowed)(vcpu, false)))
@@ -12243,6 +15357,11 @@ static inline bool kvm_vcpu_has_events(struct kvm_vcpu *vcpu)
 	     static_call(kvm_x86_smi_allowed)(vcpu, false)))
 		return true;
 
+	/*
+	 * kvm_guest_apic_has_interrupt()只在这里调用, 主要为了nested
+	 *
+	 * vmx_interrupt_allowed()
+	 */
 	if (kvm_arch_interrupt_allowed(vcpu) &&
 	    (kvm_cpu_has_interrupt(vcpu) ||
 	    kvm_guest_apic_has_interrupt(vcpu)))
@@ -12259,8 +15378,28 @@ static inline bool kvm_vcpu_has_events(struct kvm_vcpu *vcpu)
 	return false;
 }
 
+/*
+ * 在以下使用x86的kvm_arch_vcpu_runnable():
+ *   - arch/x86/kvm/x86.c|11309| <<vcpu_block>> if (!kvm_arch_vcpu_runnable(vcpu) &&
+ *   - virt/kvm/kvm_main.c|3398| <<kvm_vcpu_check_block>> if (kvm_arch_vcpu_runnable(vcpu)) {
+ *   - virt/kvm/kvm_main.c|3630| <<kvm_arch_dy_runnable>> return kvm_arch_vcpu_runnable(vcpu);
+ *
+ * 对于普通正在运行的vCPU, 满足二者之一就行:
+ * 1. KVM_MP_STATE_RUNNABLE, 并且没有halted
+ * 2. 对于已经存在的vCPU, 更多是检查vCPU有没有开中断
+ * 和有没有pending的IRR
+ */
 int kvm_arch_vcpu_runnable(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用kvm_vcpu_running():
+	 *   - arch/x86/kvm/x86.c|11381| <<vcpu_run>> if (kvm_vcpu_running(vcpu)) {
+	 *   - arch/x86/kvm/x86.c|13470| <<kvm_arch_vcpu_runnable>> return kvm_vcpu_running(vcpu) || kvm_vcpu_has_events(vcpu);
+	 *
+	 * 此外, 只在这里调用kvm_vcpu_has_events()
+	 * 对于已经存在的vCPU, 更多是检查vCPU有没有开中断
+	 * 和有没有pending的IRR
+	 */
 	return kvm_vcpu_running(vcpu) || kvm_vcpu_has_events(vcpu);
 }
 
@@ -12274,6 +15413,14 @@ bool kvm_arch_dy_has_pending_interrupt(struct kvm_vcpu *vcpu)
 
 bool kvm_arch_dy_runnable(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用kvm_vcpu_arch的pv_unhalted:
+	 *   - arch/x86/kvm/lapic.c|2005| <<__apic_accept_irq>> vcpu->arch.pv.pv_unhalted = 1;
+	 *   - arch/x86/kvm/x86.c|11341| <<vcpu_block>> vcpu->arch.pv.pv_unhalted = false;
+	 *   - arch/x86/kvm/x86.c|11793| <<kvm_arch_vcpu_ioctl_get_mpstate>> vcpu->arch.pv.pv_unhalted)
+	 *   - arch/x86/kvm/x86.c|13430| <<kvm_vcpu_has_events>> if (vcpu->arch.pv.pv_unhalted)
+	 *   - arch/x86/kvm/x86.c|13483| <<kvm_arch_dy_runnable>> if (READ_ONCE(vcpu->arch.pv.pv_unhalted))
+	 */
 	if (READ_ONCE(vcpu->arch.pv.pv_unhalted))
 		return true;
 
@@ -12298,8 +15445,20 @@ int kvm_arch_vcpu_should_kick(struct kvm_vcpu *vcpu)
 	return kvm_vcpu_exiting_guest_mode(vcpu) == IN_GUEST_MODE;
 }
 
+/*
+ * 在以下使用kvm_arch_interrupt_allowed():
+ *   - arch/x86/kvm/x86.c|4896| <<kvm_vcpu_ready_for_interrupt_injection>> return (kvm_arch_interrupt_allowed(vcpu) &&
+ *   - arch/x86/kvm/x86.c|13450| <<kvm_vcpu_has_events>> if (kvm_arch_interrupt_allowed(vcpu) &&
+ *   - arch/x86/kvm/x86.c|13701| <<kvm_can_do_async_pf>> return kvm_arch_interrupt_allowed(vcpu);
+ */
 int kvm_arch_interrupt_allowed(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下调用kvm_x86_interrupt_allowed():
+	 *   - arch/x86/kvm/x86.c|9719| <<inject_pending_event>> r = can_inject ? static_call(kvm_x86_interrupt_allowed)(vcpu, true) : -EBUSY;
+	 *   - arch/x86/kvm/x86.c|9749| <<inject_pending_event>> WARN_ON(static_call(kvm_x86_interrupt_allowed)(vcpu, true) < 0);
+	 *   - arch/x86/kvm/x86.c|13272| <<kvm_arch_interrupt_allowed>> return static_call(kvm_x86_interrupt_allowed)(vcpu, false);
+	 */
 	return static_call(kvm_x86_interrupt_allowed)(vcpu, false);
 }
 
@@ -12541,15 +15700,42 @@ void kvm_arch_async_page_present(struct kvm_vcpu *vcpu,
 	    kvm_pv_async_pf_enabled(vcpu) &&
 	    !apf_put_user_ready(vcpu, work->arch.token)) {
 		vcpu->arch.apf.pageready_pending = true;
+		/*
+		 * 在以下使用kvm_apic_set_irq():
+		 *   - arch/x86/kvm/hyperv.c|828| <<stimer_notify_direct>> return !kvm_apic_set_irq(vcpu, &irq, NULL);
+		 *   - arch/x86/kvm/hyperv.c|1899| <<kvm_send_ipi_to_many>> kvm_apic_set_irq(vcpu, &irq, NULL);
+		 *   - arch/x86/kvm/irq_comm.c|94| <<kvm_irq_delivery_to_apic>> r += kvm_apic_set_irq(vcpu, irq, dest_map);
+		 *   - arch/x86/kvm/irq_comm.c|125| <<kvm_irq_delivery_to_apic>> r = kvm_apic_set_irq(lowest, irq, dest_map);
+		 *   - arch/x86/kvm/lapic.c|1218| <<__pv_send_ipi>> count += kvm_apic_set_irq(vcpu, irq, NULL);
+		 *   - arch/x86/kvm/lapic.c|1699| <<kvm_irq_delivery_to_apic_fast>> *r = kvm_apic_set_irq(src->vcpu, irq, dest_map);
+		 *   - arch/x86/kvm/lapic.c|1712| <<kvm_irq_delivery_to_apic_fast>> *r += kvm_apic_set_irq(dst[i]->vcpu, irq, dest_map);
+		 *   - arch/x86/kvm/x86.c|13639| <<kvm_arch_async_page_present>> kvm_apic_set_irq(vcpu, &irq, NULL);
+		 */
 		kvm_apic_set_irq(vcpu, &irq, NULL);
 	}
 
+	/*
+	 * 在以下使用kvm的halted:
+	 *   - arch/x86/kvm/x86.c|10791| <<vcpu_enter_guest>> vcpu->arch.apf.halted = true;
+	 *   - arch/x86/kvm/x86.c|11346| <<vcpu_block>> vcpu->arch.apf.halted = false;
+	 *   - arch/x86/kvm/x86.c|11362| <<kvm_vcpu_running>> !vcpu->arch.apf.halted);
+	 *   - arch/x86/kvm/x86.c|12566| <<kvm_vcpu_reset>> vcpu->arch.apf.halted = false;
+	 *   - arch/x86/kvm/x86.c|13776| <<kvm_arch_async_page_present>> vcpu->arch.apf.halted = false;
+	 */
 	vcpu->arch.apf.halted = false;
 	vcpu->arch.mp_state = KVM_MP_STATE_RUNNABLE;
 }
 
 void kvm_arch_async_page_present_queued(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用KVM_REQ_APF_READY:
+	 *   - arch/x86/kvm/lapic.c|621| <<apic_set_spiv>> kvm_make_request(KVM_REQ_APF_READY, apic->vcpu);
+	 *   - arch/x86/kvm/lapic.c|3303| <<kvm_lapic_set_base>> kvm_make_request(KVM_REQ_APF_READY, vcpu);
+	 *   - arch/x86/kvm/x86.c|13246| <<kvm_arch_async_page_present_queued>> kvm_make_request(KVM_REQ_APF_READY, vcpu);
+	 *
+	 * 处理的函数kvm_check_async_pf_completion()
+	 */
 	kvm_make_request(KVM_REQ_APF_READY, vcpu);
 	if (!vcpu->arch.apf.pageready_pending)
 		kvm_vcpu_kick(vcpu);
@@ -12600,6 +15786,10 @@ bool kvm_arch_has_noncoherent_dma(struct kvm *kvm)
 }
 EXPORT_SYMBOL_GPL(kvm_arch_has_noncoherent_dma);
 
+/*
+ * 在以下使用kvm_arch_has_irq_bypass():
+ *   - virt/kvm/eventfd.c|444| <<kvm_irqfd_assign>> if (kvm_arch_has_irq_bypass()) {
+ */
 bool kvm_arch_has_irq_bypass(void)
 {
 	return true;
@@ -12614,6 +15804,15 @@ int kvm_arch_irq_bypass_add_producer(struct irq_bypass_consumer *cons,
 
 	irqfd->producer = prod;
 	kvm_arch_start_assignment(irqfd->kvm);
+	/*
+	 * 在以下调用kvm_x86_pi_update_irte:
+	 *   - arch/x86/kvm/x86.c|14122| <<kvm_arch_irq_bypass_add_producer>> ret = static_call(kvm_x86_pi_update_irte)(irqfd->kvm,
+	 *   - arch/x86/kvm/x86.c|14147| <<kvm_arch_irq_bypass_del_producer>> ret = static_call(kvm_x86_pi_update_irte)(irqfd->kvm, prod->irq, irqfd->gsi, 0);
+	 *   - arch/x86/kvm/x86.c|14158| <<kvm_arch_update_irqfd_routing>> return static_call(kvm_x86_pi_update_irte)(kvm, host_irq, guest_irq, set);
+	 *
+	 * vmx_pi_update_irte()
+	 * avic_pi_update_irte()
+	 */
 	ret = static_call(kvm_x86_pi_update_irte)(irqfd->kvm,
 					 prod->irq, irqfd->gsi, 1);
 
@@ -12639,6 +15838,12 @@ void kvm_arch_irq_bypass_del_producer(struct irq_bypass_consumer *cons,
 	 * when the irq is masked/disabled or the consumer side (KVM
 	 * int this case doesn't want to receive the interrupts.
 	*/
+	/*
+	 * 在以下调用kvm_x86_pi_update_irte:
+	 *   - arch/x86/kvm/x86.c|14122| <<kvm_arch_irq_bypass_add_producer>> ret = static_call(kvm_x86_pi_update_irte)(irqfd->kvm,
+	 *   - arch/x86/kvm/x86.c|14147| <<kvm_arch_irq_bypass_del_producer>> ret = static_call(kvm_x86_pi_update_irte)(irqfd->kvm, prod->irq, irqfd->gsi, 0);
+	 *   - arch/x86/kvm/x86.c|14158| <<kvm_arch_update_irqfd_routing>> return static_call(kvm_x86_pi_update_irte)(kvm, host_irq, guest_irq, set);
+	 */
 	ret = static_call(kvm_x86_pi_update_irte)(irqfd->kvm, prod->irq, irqfd->gsi, 0);
 	if (ret)
 		printk(KERN_INFO "irq bypass consumer (token %p) unregistration"
@@ -12650,6 +15855,12 @@ void kvm_arch_irq_bypass_del_producer(struct irq_bypass_consumer *cons,
 int kvm_arch_update_irqfd_routing(struct kvm *kvm, unsigned int host_irq,
 				   uint32_t guest_irq, bool set)
 {
+	/*
+	 * 在以下调用kvm_x86_pi_update_irte:
+	 *   - arch/x86/kvm/x86.c|14122| <<kvm_arch_irq_bypass_add_producer>> ret = static_call(kvm_x86_pi_update_irte)(irqfd->kvm,
+	 *   - arch/x86/kvm/x86.c|14147| <<kvm_arch_irq_bypass_del_producer>> ret = static_call(kvm_x86_pi_update_irte)(irqfd->kvm, prod->irq, irqfd->gsi, 0);
+	 *   - arch/x86/kvm/x86.c|14158| <<kvm_arch_update_irqfd_routing>> return static_call(kvm_x86_pi_update_irte)(kvm, host_irq, guest_irq, set);
+	 */
 	return static_call(kvm_x86_pi_update_irte)(kvm, host_irq, guest_irq, set);
 }
 
diff --git a/arch/x86/kvm/x86.h b/arch/x86/kvm/x86.h
index f7854e742e8c..5240b9adc2eb 100644
--- a/arch/x86/kvm/x86.h
+++ b/arch/x86/kvm/x86.h
@@ -112,6 +112,15 @@ static inline void kvm_clear_exception_queue(struct kvm_vcpu *vcpu)
 	vcpu->arch.exception.injected = false;
 }
 
+/*
+ * 在以下使用kvm_queue_interrupt():
+ *   - arch/x86/kvm/svm/svm.c|4045| <<svm_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, false);
+ *   - arch/x86/kvm/svm/svm.c|4048| <<svm_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, true);
+ *   - arch/x86/kvm/vmx/vmx.c|6768| <<__vmx_complete_interrupts>> kvm_queue_interrupt(vcpu, vector, type == INTR_TYPE_SOFT_INTR);
+ *   - arch/x86/kvm/x86.c|4713| <<kvm_vcpu_ioctl_interrupt>> kvm_queue_interrupt(vcpu, irq->irq, false);
+ *   - arch/x86/kvm/x86.c|9490| <<inject_pending_event>> kvm_queue_interrupt(vcpu, irq, false);
+ *   - arch/x86/kvm/x86.c|11223| <<__set_sregs>> kvm_queue_interrupt(vcpu, pending_vec, false);
+ */
 static inline void kvm_queue_interrupt(struct kvm_vcpu *vcpu, u8 vector,
 	bool soft)
 {
@@ -120,11 +129,29 @@ static inline void kvm_queue_interrupt(struct kvm_vcpu *vcpu, u8 vector,
 	vcpu->arch.interrupt.nr = vector;
 }
 
+/*
+ * 在以下调用kvm_clear_interrupt_queue():
+ *   - arch/x86/kvm/svm/nested.c|1017| <<nested_svm_vmexit>> kvm_clear_interrupt_queue(vcpu);
+ *   - arch/x86/kvm/svm/svm.c|2556| <<task_switch_interception>> kvm_clear_interrupt_queue(vcpu);
+ *   - arch/x86/kvm/svm/svm.c|4012| <<svm_complete_interrupts>> kvm_clear_interrupt_queue(vcpu);
+ *   - arch/x86/kvm/vmx/nested.c|4645| <<nested_vmx_vmexit>> kvm_clear_interrupt_queue(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|5440| <<handle_task_switch>> kvm_clear_interrupt_queue(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|6799| <<__vmx_complete_interrupts>> kvm_clear_interrupt_queue(vcpu);
+ *   - arch/x86/kvm/x86.c|11947| <<kvm_vcpu_reset>> kvm_clear_interrupt_queue(vcpu);
+ */
 static inline void kvm_clear_interrupt_queue(struct kvm_vcpu *vcpu)
 {
 	vcpu->arch.interrupt.injected = false;
 }
 
+/*
+ * 在以下使用kvm_event_needs_reinjection():
+ *   - arch/x86/kvm/mmu/mmu.c|4031| <<kvm_handle_page_fault>> if (kvm_event_needs_reinjection(vcpu))
+ *   - arch/x86/kvm/svm/nested.c|1288| <<svm_check_nested_events>> kvm_event_needs_reinjection(vcpu) || svm->nested.nested_run_pending;
+ *   - arch/x86/kvm/vmx/nested.c|3921| <<vmx_check_nested_events>> vmx->nested.nested_run_pending || kvm_event_needs_reinjection(vcpu);
+ *   - arch/x86/kvm/x86.c|4785| <<kvm_vcpu_ready_for_interrupt_injection>> !kvm_event_needs_reinjection(vcpu) &&
+ *   - arch/x86/kvm/x86.c|13061| <<kvm_can_do_async_pf>> kvm_event_needs_reinjection(vcpu) ||
+ */
 static inline bool kvm_event_needs_reinjection(struct kvm_vcpu *vcpu)
 {
 	return vcpu->arch.exception.injected || vcpu->arch.interrupt.injected ||
@@ -349,8 +376,40 @@ extern struct static_key kvm_no_apic_vcpu;
 
 extern bool report_ignored_msrs;
 
+/*
+ * 在以下使用nsec_to_cycles():
+ *   - arch/x86/kvm/lapic.c|2840| <<__wait_lapic_expire>> __delay(min(guest_cycles,
+ *          nsec_to_cycles(vcpu, timer_advance_ns)));
+ *   - arch/x86/kvm/lapic.c|3052| <<update_target_expiration>> nsec_to_cycles(apic->vcpu, ns_remaining_new) -
+ *                                                             nsec_to_cycles(apic->vcpu, ns_remaining_old);
+ *   - arch/x86/kvm/lapic.c|3053| <<update_target_expiration>> nsec_to_cycles(apic->vcpu, ns_remaining_new) -
+ *                                                             nsec_to_cycles(apic->vcpu, ns_remaining_old);
+ *   - arch/x86/kvm/lapic.c|3097| <<set_target_expiration>> nsec_to_cycles(apic->vcpu, deadline);
+ *   - arch/x86/kvm/lapic.c|3121| <<advance_periodic_target_expiration>> nsec_to_cycles(apic->vcpu, delta);
+ *   - arch/x86/kvm/vmx/vmx.c|8347| <<vmx_set_hv_timer>> lapic_timer_advance_cycles = nsec_to_cycles(vcpu,
+ *          ktimer->timer_advance_ns);
+ *   - arch/x86/kvm/x86.c|3042| <<kvm_synchronize_tsc>> nsec_to_cycles(vcpu, elapsed);
+ *   - arch/x86/kvm/x86.c|3065| <<kvm_synchronize_tsc>> u64 delta = nsec_to_cycles(vcpu, elapsed);
+ */
 static inline u64 nsec_to_cycles(struct kvm_vcpu *vcpu, u64 nsec)
 {
+	/*
+	 * 在以下使用kvm_vcpu_arch->arch.virtual_tsc_mult:
+	 *   - arch/x86/kvm/x86.c|2697| <<kvm_set_tsc_khz>> kvm_get_time_scale(user_tsc_khz * 1000LL,
+	 *           NSEC_PER_SEC, &vcpu->arch.virtual_tsc_shift, &vcpu->arch.virtual_tsc_mult);
+	 *   - arch/x86/kvm/x86.c|2754| <<compute_guest_tsc>> u64 tsc = pvclock_scale_delta(kernel_ns-vcpu->arch.this_tsc_nsec,
+	 *           vcpu->arch.virtual_tsc_mult, vcpu->arch.virtual_tsc_shift);
+	 *   - arch/x86/kvm/x86.h|390| <<nsec_to_cycles>> return pvclock_scale_delta(nsec,
+	 *           vcpu->arch.virtual_tsc_mult, vcpu->arch.virtual_tsc_shift);
+	 *
+	 * 在以下使用kvm_vcpu_arch->virtual_tsc_shift:
+	 *   - arch/x86/kvm/x86.c|2684| <<kvm_set_tsc_khz>> kvm_get_time_scale(user_tsc_khz * 1000LL,
+	 *           NSEC_PER_SEC, &vcpu->arch.virtual_tsc_shift, &vcpu->arch.virtual_tsc_mult);
+	 *   - arch/x86/kvm/x86.c|2707| <<compute_guest_tsc>> u64 tsc = pvclock_scale_delta(kernel_ns-vcpu->arch.this_tsc_nsec,
+	 *           vcpu->arch.virtual_tsc_mult, vcpu->arch.virtual_tsc_shift);
+	 *   - arch/x86/kvm/x86.h|382| <<nsec_to_cycles>> return pvclock_scale_delta(nsec,
+	 *           vcpu->arch.virtual_tsc_mult, vcpu->arch.virtual_tsc_shift);
+	 */
 	return pvclock_scale_delta(nsec, vcpu->arch.virtual_tsc_mult,
 				   vcpu->arch.virtual_tsc_shift);
 }
@@ -391,6 +450,12 @@ static inline bool kvm_cstate_in_guest(struct kvm *kvm)
 
 DECLARE_PER_CPU(struct kvm_vcpu *, current_vcpu);
 
+/*
+ * 在以下使用kvm_before_interrupt():
+ *   - arch/x86/kvm/svm/svm.c|4206| <<svm_vcpu_run>> kvm_before_interrupt(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|6920| <<handle_interrupt_nmi_irqoff>> kvm_before_interrupt(vcpu);
+ *   - arch/x86/kvm/x86.c|11036| <<vcpu_enter_guest>> kvm_before_interrupt(vcpu);
+ */
 static inline void kvm_before_interrupt(struct kvm_vcpu *vcpu)
 {
 	__this_cpu_write(current_vcpu, vcpu);
diff --git a/drivers/acpi/acpica/dbexec.c b/drivers/acpi/acpica/dbexec.c
index d3a9521e2dc8..78134e2119ff 100644
--- a/drivers/acpi/acpica/dbexec.c
+++ b/drivers/acpi/acpica/dbexec.c
@@ -692,6 +692,26 @@ acpi_db_create_execution_thread(char *method_name_arg,
 		return;
 	}
 
+	/*
+	 * 在以下调用acpi_os_execute():
+	 *   - drivers/acpi/acpica/dbexec.c|695| <<acpi_db_create_execution_thread>> status = acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+	 *            acpi_db_single_execution_thread, &acpi_gbl_db_method_info);
+	 *   - drivers/acpi/acpica/dbexec.c|849| <<acpi_db_create_execution_threads>> acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+	 *            acpi_db_method_thread, &acpi_gbl_db_method_info);
+	 *   - drivers/acpi/acpica/dbxface.c|448| <<acpi_initialize_debugger>> status = acpi_os_execute(OSL_DEBUGGER_MAIN_THREAD,
+	 *            acpi_db_execute_thread, NULL);
+	 *   - drivers/acpi/acpica/evgpe.c|526| <<acpi_ev_asynch_execute_gpe_method>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_ev_asynch_enable_gpe, gpe_event_info);
+	 *   - drivers/acpi/acpica/evgpe.c|823| <<acpi_ev_gpe_dispatch>> status = acpi_os_execute(OSL_GPE_HANDLER,
+	 *            acpi_ev_asynch_execute_gpe_method, gpe_event_info);
+	 *   - drivers/acpi/acpica/evmisc.c|139| <<acpi_ev_queue_notify_request>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_ev_notify_dispatch, info);
+	 *   - drivers/acpi/bus.c|539| <<acpi_device_fixed_event>> acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_notify_device_fixed, data);
+	 *   - drivers/acpi/sbshc.c|232| <<smbus_alarm>> acpi_os_execute(OSL_NOTIFY_HANDLER, acpi_smbus_callback, hc);
+	 *   - drivers/platform/x86/dell/dell-rbtn.c|278| <<rbtn_resume>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            rbtn_clear_suspended_flag, rbtn_data);
+	 */
 	status = acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
 				 acpi_db_single_execution_thread,
 				 &acpi_gbl_db_method_info);
@@ -845,6 +865,26 @@ acpi_db_create_execution_threads(char *num_threads_arg,
 		       num_threads, num_loops);
 
 	for (i = 0; i < (num_threads); i++) {
+		/*
+		 * 在以下调用acpi_os_execute():
+		 *   - drivers/acpi/acpica/dbexec.c|695| <<acpi_db_create_execution_thread>> status = acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+		 *            acpi_db_single_execution_thread, &acpi_gbl_db_method_info);
+		 *   - drivers/acpi/acpica/dbexec.c|849| <<acpi_db_create_execution_threads>> acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+		 *            acpi_db_method_thread, &acpi_gbl_db_method_info);
+		 *   - drivers/acpi/acpica/dbxface.c|448| <<acpi_initialize_debugger>> status = acpi_os_execute(OSL_DEBUGGER_MAIN_THREAD,
+		 *            acpi_db_execute_thread, NULL);
+		 *   - drivers/acpi/acpica/evgpe.c|526| <<acpi_ev_asynch_execute_gpe_method>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            acpi_ev_asynch_enable_gpe, gpe_event_info);
+		 *   - drivers/acpi/acpica/evgpe.c|823| <<acpi_ev_gpe_dispatch>> status = acpi_os_execute(OSL_GPE_HANDLER,
+		 *            acpi_ev_asynch_execute_gpe_method, gpe_event_info);
+		 *   - drivers/acpi/acpica/evmisc.c|139| <<acpi_ev_queue_notify_request>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            acpi_ev_notify_dispatch, info);
+		 *   - drivers/acpi/bus.c|539| <<acpi_device_fixed_event>> acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            acpi_notify_device_fixed, data);
+		 *   - drivers/acpi/sbshc.c|232| <<smbus_alarm>> acpi_os_execute(OSL_NOTIFY_HANDLER, acpi_smbus_callback, hc);
+		 *   - drivers/platform/x86/dell/dell-rbtn.c|278| <<rbtn_resume>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            rbtn_clear_suspended_flag, rbtn_data);
+		 */
 		status =
 		    acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
 				    acpi_db_method_thread,
diff --git a/drivers/acpi/acpica/dbxface.c b/drivers/acpi/acpica/dbxface.c
index 9dfd693cda3e..ac899207a957 100644
--- a/drivers/acpi/acpica/dbxface.c
+++ b/drivers/acpi/acpica/dbxface.c
@@ -445,6 +445,26 @@ acpi_status acpi_initialize_debugger(void)
 		/* Create the debug execution thread to execute commands */
 
 		acpi_gbl_db_threads_terminated = FALSE;
+		/*
+		 * 在以下调用acpi_os_execute():
+		 *   - drivers/acpi/acpica/dbexec.c|695| <<acpi_db_create_execution_thread>> status = acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+		 *            acpi_db_single_execution_thread, &acpi_gbl_db_method_info);
+		 *   - drivers/acpi/acpica/dbexec.c|849| <<acpi_db_create_execution_threads>> acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+		 *            acpi_db_method_thread, &acpi_gbl_db_method_info);
+		 *   - drivers/acpi/acpica/dbxface.c|448| <<acpi_initialize_debugger>> status = acpi_os_execute(OSL_DEBUGGER_MAIN_THREAD,
+		 *            acpi_db_execute_thread, NULL);
+		 *   - drivers/acpi/acpica/evgpe.c|526| <<acpi_ev_asynch_execute_gpe_method>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            acpi_ev_asynch_enable_gpe, gpe_event_info);
+		 *   - drivers/acpi/acpica/evgpe.c|823| <<acpi_ev_gpe_dispatch>> status = acpi_os_execute(OSL_GPE_HANDLER,
+		 *            acpi_ev_asynch_execute_gpe_method, gpe_event_info);
+		 *   - drivers/acpi/acpica/evmisc.c|139| <<acpi_ev_queue_notify_request>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            acpi_ev_notify_dispatch, info);
+		 *   - drivers/acpi/bus.c|539| <<acpi_device_fixed_event>> acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            acpi_notify_device_fixed, data);
+		 *   - drivers/acpi/sbshc.c|232| <<smbus_alarm>> acpi_os_execute(OSL_NOTIFY_HANDLER, acpi_smbus_callback, hc);
+		 *   - drivers/platform/x86/dell/dell-rbtn.c|278| <<rbtn_resume>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            rbtn_clear_suspended_flag, rbtn_data);
+		 */
 		status = acpi_os_execute(OSL_DEBUGGER_MAIN_THREAD,
 					 acpi_db_execute_thread, NULL);
 		if (ACPI_FAILURE(status)) {
diff --git a/drivers/acpi/acpica/dswexec.c b/drivers/acpi/acpica/dswexec.c
index f2d2267054af..793d3c1a9c15 100644
--- a/drivers/acpi/acpica/dswexec.c
+++ b/drivers/acpi/acpica/dswexec.c
@@ -26,6 +26,10 @@ ACPI_MODULE_NAME("dswexec")
 /*
  * Dispatch table for opcode classes
  */
+/*
+ * 在以下使用acpi_gbl_op_type_dispatch[]:
+ *   - drivers/acpi/acpica/dswexec.c|453| <<acpi_ds_exec_end_op>> acpi_gbl_op_type_dispatch[op_type] (walk_state);
+ */
 static acpi_execute_op acpi_gbl_op_type_dispatch[] = {
 	acpi_ex_opcode_0A_0T_1R,
 	acpi_ex_opcode_1A_0T_0R,
@@ -324,6 +328,48 @@ acpi_ds_exec_begin_op(struct acpi_walk_state *walk_state,
  *
  ****************************************************************************/
 
+/*
+ * hotplug pci的时候调用三次.
+ *                      
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq         
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt     
+ *                            
+ * [0] acpi_os_execute       
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op  
+ * [0] acpi_ps_parse_loop   
+ * [0] acpi_ps_parse_aml        
+ * [0] acpi_ps_execute_method   
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work         
+ * [0] worker_thread            
+ * [0] kthread                      
+ * [0] ret_from_fork                                            
+ *                                                              
+ * [0] acpi_os_execute          
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred         
+ * [0] process_one_work                         
+ * [0] worker_thread                                            
+ * [0] kthread                          
+ * [0] ret_from_fork 
+ *
+ * 在以下使用acpi_ds_exec_end_op():
+ *   - drivers/acpi/acpica/dswload.c|78| <<acpi_ds_init_callbacks>> walk_state->ascending_callback = acpi_ds_exec_end_op;
+ *
+ * acpi_ex_opcode_2A_0T_0R()
+ */
 acpi_status acpi_ds_exec_end_op(struct acpi_walk_state *walk_state)
 {
 	union acpi_parse_object *op;
@@ -409,6 +455,10 @@ acpi_status acpi_ds_exec_end_op(struct acpi_walk_state *walk_state)
 			 * routine. There is one routine per opcode "type" based upon the
 			 * number of opcode arguments and return type.
 			 */
+			/*
+			 * 这里!!!!
+			 * acpi_ex_opcode_2A_0T_0R()
+			 */
 			status =
 			    acpi_gbl_op_type_dispatch[op_type] (walk_state);
 		} else {
diff --git a/drivers/acpi/acpica/evgpe.c b/drivers/acpi/acpica/evgpe.c
index c5a06882bdf6..c29c04c4bfb8 100644
--- a/drivers/acpi/acpica/evgpe.c
+++ b/drivers/acpi/acpica/evgpe.c
@@ -330,6 +330,43 @@ struct acpi_gpe_event_info *acpi_ev_get_gpe_event_info(acpi_handle gpe_device,
 		(gpe_number, obj_desc->device.gpe_block));
 }
 
+/*
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ */
 /*******************************************************************************
  *
  * FUNCTION:    acpi_ev_gpe_detect
@@ -373,14 +410,26 @@ u32 acpi_ev_gpe_detect(struct acpi_gpe_xrupt_info *gpe_xrupt_list)
 
 	/* Examine all GPE blocks attached to this interrupt level */
 
+	/*
+	 * struct acpi_gpe_block_info *gpe_block;
+	 */
 	gpe_block = gpe_xrupt_list->gpe_block_list_head;
 	while (gpe_block) {
+		/*
+		 * 这个while循环就一个block,
+		 * gpe_device->name.ascii = "_GPE".
+		 *
+		 * struct acpi_namespace_node *gpe_device;
+		 */
 		gpe_device = gpe_block->node;
 
 		/*
 		 * Read all of the 8-bit GPE status and enable registers in this GPE
 		 * block, saving all of them. Find all currently active GP events.
 		 */
+		/*
+		 * hot-add测试register_count也是8个
+		 */
 		for (i = 0; i < gpe_block->register_count; i++) {
 
 			/* Get the next status/enable pair */
@@ -391,6 +440,9 @@ u32 acpi_ev_gpe_detect(struct acpi_gpe_xrupt_info *gpe_xrupt_list)
 			 * Optimization: If there are no GPEs enabled within this
 			 * register, we can safely ignore the entire register.
 			 */
+			/*
+			 * 只有0的能跳过这里
+			 */
 			if (!(gpe_register_info->enable_for_run |
 			      gpe_register_info->enable_for_wake)) {
 				ACPI_DEBUG_PRINT((ACPI_DB_INTERRUPTS,
@@ -410,10 +462,24 @@ u32 acpi_ev_gpe_detect(struct acpi_gpe_xrupt_info *gpe_xrupt_list)
 
 			/* Now look at the individual GPEs in this byte register */
 
+			/*
+			 * 8个
+			 */
 			for (j = 0; j < ACPI_GPE_REGISTER_WIDTH; j++) {
 
 				/* Detect and dispatch one GPE bit */
 
+				/*
+				 * gpe_block都链接在gpe_block_list_head
+				 *
+				 * struct acpi_gpe_block_info *gpe_block;
+				 * -> struct acpi_namespace_node *node; (gpe_device->name.ascii = "_GPE".)
+				 * -> struct acpi_gpe_register_info *register_info;
+				 * -> struct acpi_gpe_event_info *event_info;
+				 *
+				 *
+				 * struct acpi_gpe_event_info *gpe_event_info;
+				 */
 				gpe_event_info =
 				    &gpe_block->
 				    event_info[((acpi_size)i *
@@ -421,6 +487,13 @@ u32 acpi_ev_gpe_detect(struct acpi_gpe_xrupt_info *gpe_xrupt_list)
 				gpe_number =
 				    j + gpe_register_info->base_gpe_number;
 				acpi_os_release_lock(acpi_gbl_gpe_lock, flags);
+				/*
+				 * 在以下调用acpi_ev_detect_gpe():
+				 *   - drivers/acpi/acpica/evgpe.c|471| <<acpi_ev_gpe_detect>> acpi_ev_detect_gpe(gpe_device, gpe_event_info, gpe_number);
+				 *   - drivers/acpi/acpica/evxface.c|980| <<acpi_remove_gpe_handler>> (void )acpi_ev_detect_gpe(gpe_device, gpe_event_info, gpe_number);
+				 *   - drivers/acpi/acpica/evxfgpe.c|118| <<acpi_enable_gpe>> (void )acpi_ev_detect_gpe(gpe_device, gpe_event_info, gpe_number);
+				 *   - drivers/acpi/acpica/evxfgpe.c|657| <<acpi_dispatch_gpe>> return acpi_ev_detect_gpe(gpe_device, NULL, gpe_number);
+				 */
 				int_status |=
 				    acpi_ev_detect_gpe(gpe_device,
 						       gpe_event_info,
@@ -429,6 +502,9 @@ u32 acpi_ev_gpe_detect(struct acpi_gpe_xrupt_info *gpe_xrupt_list)
 			}
 		}
 
+		/*
+		 * 选择下一个
+		 */
 		gpe_block = gpe_block->next;
 	}
 
@@ -452,6 +528,64 @@ u32 acpi_ev_gpe_detect(struct acpi_gpe_xrupt_info *gpe_xrupt_list)
  *
  ******************************************************************************/
 
+/*
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request ==> acpi_ev_notify_dispatch
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ *
+ * [0] acpi_hotplug_schedule
+ * [0] acpi_bus_notify
+ * [0] acpi_ev_notify_dispatch
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ *
+ * struct acpi_gpe_block_info *gpe_block;
+ * -> struct acpi_namespace_node *node; (gpe_device->name.ascii = "_GPE".)
+ * -> struct acpi_gpe_register_info *register_info;
+ * -> struct acpi_gpe_event_info *event_info;
+ *
+ * debug测试的时候只有i=0, j=1执行了这里
+ * gpe_number=1
+ * (插入第二个第三个还是这样)
+ * 应该是ACPI_GPE_DISPATCH_METHOD
+ */
 static void ACPI_SYSTEM_XFACE acpi_ev_asynch_execute_gpe_method(void *context)
 {
 	struct acpi_gpe_event_info *gpe_event_info = context;
@@ -478,6 +612,9 @@ static void ACPI_SYSTEM_XFACE acpi_ev_asynch_execute_gpe_method(void *context)
 		 */
 		notify = gpe_event_info->dispatch.notify_list;
 		while (ACPI_SUCCESS(status) && notify) {
+			/*
+			 * 似乎这里非常重要!!! 也不一定, 好吧不是!!!
+			 */
 			status =
 			    acpi_ev_queue_notify_request(notify->device_node,
 							 ACPI_NOTIFY_DEVICE_WAKE);
@@ -495,6 +632,20 @@ static void ACPI_SYSTEM_XFACE acpi_ev_asynch_execute_gpe_method(void *context)
 		if (!info) {
 			status = AE_NO_MEMORY;
 		} else {
+			/*
+			 * struct acpi_gpe_block_info *gpe_block;
+			 * -> struct acpi_namespace_node *node; (gpe_device->name.ascii = "_GPE".)
+			 * -> struct acpi_gpe_register_info *register_info;
+			 * -> struct acpi_gpe_event_info *event_info;
+			 *
+			 * debug测试的时候只有i=0, j=1执行了这里
+			 * gpe_number=1
+			 * (插入第二个第三个还是这样)
+			 * 应该是ACPI_GPE_DISPATCH_METHOD
+			 *
+			 * 这里测试的
+			 * acpi_ut_get_node_name(gpe_event_info->dispatch.method_node)是"_E01"
+			 */
 			/*
 			 * Invoke the GPE Method (_Lxx, _Exx) i.e., evaluate the
 			 * _Lxx/_Exx control method that corresponds to this GPE
@@ -503,6 +654,11 @@ static void ACPI_SYSTEM_XFACE acpi_ev_asynch_execute_gpe_method(void *context)
 			    gpe_event_info->dispatch.method_node;
 			info->flags = ACPI_IGNORE_RETURN_VALUE;
 
+			/*
+			 * 先执行这里!!!!!
+			 *
+			 * struct acpi_evaluate_info *info;
+			 */
 			status = acpi_ns_evaluate(info);
 			ACPI_FREE(info);
 		}
@@ -523,6 +679,28 @@ static void ACPI_SYSTEM_XFACE acpi_ev_asynch_execute_gpe_method(void *context)
 
 	/* Defer enabling of GPE until all notify handlers are done */
 
+	/*
+	 * 在以下调用acpi_os_execute():
+	 *   - drivers/acpi/acpica/dbexec.c|695| <<acpi_db_create_execution_thread>> status = acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+	 *            acpi_db_single_execution_thread, &acpi_gbl_db_method_info);
+	 *   - drivers/acpi/acpica/dbexec.c|849| <<acpi_db_create_execution_threads>> acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+	 *            acpi_db_method_thread, &acpi_gbl_db_method_info);
+	 *   - drivers/acpi/acpica/dbxface.c|448| <<acpi_initialize_debugger>> status = acpi_os_execute(OSL_DEBUGGER_MAIN_THREAD,
+	 *            acpi_db_execute_thread, NULL);
+	 *   - drivers/acpi/acpica/evgpe.c|526| <<acpi_ev_asynch_execute_gpe_method>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_ev_asynch_enable_gpe, gpe_event_info);
+	 *   - drivers/acpi/acpica/evgpe.c|823| <<acpi_ev_gpe_dispatch>> status = acpi_os_execute(OSL_GPE_HANDLER,
+	 *            acpi_ev_asynch_execute_gpe_method, gpe_event_info);
+	 *   - drivers/acpi/acpica/evmisc.c|139| <<acpi_ev_queue_notify_request>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_ev_notify_dispatch, info);
+	 *   - drivers/acpi/bus.c|539| <<acpi_device_fixed_event>> acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_notify_device_fixed, data);
+	 *   - drivers/acpi/sbshc.c|232| <<smbus_alarm>> acpi_os_execute(OSL_NOTIFY_HANDLER, acpi_smbus_callback, hc);
+	 *   - drivers/platform/x86/dell/dell-rbtn.c|278| <<rbtn_resume>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            rbtn_clear_suspended_flag, rbtn_data);
+	 *
+	 * struct acpi_gpe_event_info *gpe_event_info = context;
+	 */
 	status = acpi_os_execute(OSL_NOTIFY_HANDLER,
 				 acpi_ev_asynch_enable_gpe, gpe_event_info);
 	if (ACPI_SUCCESS(status)) {
@@ -549,6 +727,11 @@ static void ACPI_SYSTEM_XFACE acpi_ev_asynch_execute_gpe_method(void *context)
  *
  ******************************************************************************/
 
+/*
+ * 在以下使用acpi_ev_asynch_enable_gpe():
+ *   - drivers/acpi/acpica/evgpe.c|630| <<acpi_ev_asynch_execute_gpe_method>> status = acpi_os_execute(OSL_NOTIFY_HANDLER, acpi_ev_asynch_enable_gpe, gpe_event_info);
+ *   - drivers/acpi/acpica/evgpe.c|636| <<acpi_ev_asynch_execute_gpe_method>> acpi_ev_asynch_enable_gpe(gpe_event_info);
+ */
 static void ACPI_SYSTEM_XFACE acpi_ev_asynch_enable_gpe(void *context)
 {
 	struct acpi_gpe_event_info *gpe_event_info = context;
@@ -622,6 +805,56 @@ acpi_status acpi_ev_finish_gpe(struct acpi_gpe_event_info *gpe_event_info)
  *
  ******************************************************************************/
 
+/*
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * 在以下调用acpi_ev_detect_gpe():
+ *   - drivers/acpi/acpica/evgpe.c|471| <<acpi_ev_gpe_detect>> acpi_ev_detect_gpe(gpe_device, gpe_event_info, gpe_number);
+ *   - drivers/acpi/acpica/evxface.c|980| <<acpi_remove_gpe_handler>> (void )acpi_ev_detect_gpe(gpe_device, gpe_event_info, gpe_number);
+ *   - drivers/acpi/acpica/evxfgpe.c|118| <<acpi_enable_gpe>> (void )acpi_ev_detect_gpe(gpe_device, gpe_event_info, gpe_number);
+ *   - drivers/acpi/acpica/evxfgpe.c|657| <<acpi_dispatch_gpe>> return acpi_ev_detect_gpe(gpe_device, NULL, gpe_number);
+ *
+ * gpe_block都链接在gpe_block_list_head
+ *
+ * struct acpi_gpe_block_info *gpe_block;
+ * -> struct acpi_namespace_node *node; (gpe_device->name.ascii = "_GPE".)
+ * -> struct acpi_gpe_register_info *register_info;
+ * -> struct acpi_gpe_event_info *event_info;
+ */
 u32
 acpi_ev_detect_gpe(struct acpi_namespace_node *gpe_device,
 		   struct acpi_gpe_event_info *gpe_event_info, u32 gpe_number)
@@ -720,6 +953,18 @@ acpi_ev_detect_gpe(struct acpi_namespace_node *gpe_device,
 	} else {
 		/* Dispatch the event to a standard handler or method. */
 
+		/*
+		 * struct acpi_gpe_block_info *gpe_block;
+		 * -> struct acpi_namespace_node *node; (gpe_device->name.ascii = "_GPE".)
+		 * -> struct acpi_gpe_register_info *register_info;
+		 * -> struct acpi_gpe_event_info *event_info;
+		 *
+		 * debug测试的时候只有i=0, j=1执行了这里
+		 * gpe_number=1
+		 * (插入第二个第三个还是这样)
+		 *
+		 * 这里???
+		 */
 		int_status |= acpi_ev_gpe_dispatch(gpe_device,
 						   gpe_event_info, gpe_number);
 	}
@@ -744,6 +989,57 @@ acpi_ev_detect_gpe(struct acpi_namespace_node *gpe_device,
  *
  ******************************************************************************/
 
+/*
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * 在以下使用acpi_ev_gpe_dispatch():
+ *   - drivers/acpi/acpica/dbcmds.c|1055| <<acpi_db_generate_gpe>> (void )acpi_ev_gpe_dispatch(NULL, gpe_event_info, gpe_number);
+ *   - drivers/acpi/acpica/evgpe.c|866| <<acpi_ev_detect_gpe>> int_status |= acpi_ev_gpe_dispatch(gpe_device, gpe_event_info, gpe_number);
+ *
+ * struct acpi_gpe_block_info *gpe_block;
+ * -> struct acpi_namespace_node *node; (gpe_device->name.ascii = "_GPE".)
+ * -> struct acpi_gpe_register_info *register_info;
+ * -> struct acpi_gpe_event_info *event_info;
+ *
+ * debug测试的时候只有i=0, j=1执行了这里
+ * gpe_number=1
+ * (插入第二个第三个还是这样)
+ * 应该是ACPI_GPE_DISPATCH_METHOD
+ */
 u32
 acpi_ev_gpe_dispatch(struct acpi_namespace_node *gpe_device,
 		     struct acpi_gpe_event_info *gpe_event_info, u32 gpe_number)
@@ -795,6 +1091,9 @@ acpi_ev_gpe_dispatch(struct acpi_namespace_node *gpe_device,
 	 * If there is neither a handler nor a method, leave the GPE
 	 * disabled.
 	 */
+	/*
+	 * hot-add应该是ACPI_GPE_DISPATCH_METHOD
+	 */
 	switch (ACPI_GPE_DISPATCH_TYPE(gpe_event_info->flags)) {
 	case ACPI_GPE_DISPATCH_HANDLER:
 
@@ -816,6 +1115,37 @@ acpi_ev_gpe_dispatch(struct acpi_namespace_node *gpe_device,
 
 	case ACPI_GPE_DISPATCH_METHOD:
 	case ACPI_GPE_DISPATCH_NOTIFY:
+		/*
+		 * 在以下调用acpi_os_execute():
+		 *   - drivers/acpi/acpica/dbexec.c|695| <<acpi_db_create_execution_thread>> status = acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+		 *            acpi_db_single_execution_thread, &acpi_gbl_db_method_info);
+		 *   - drivers/acpi/acpica/dbexec.c|849| <<acpi_db_create_execution_threads>> acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+		 *            acpi_db_method_thread, &acpi_gbl_db_method_info);
+		 *   - drivers/acpi/acpica/dbxface.c|448| <<acpi_initialize_debugger>> status = acpi_os_execute(OSL_DEBUGGER_MAIN_THREAD,
+		 *            acpi_db_execute_thread, NULL);
+		 *   - drivers/acpi/acpica/evgpe.c|526| <<acpi_ev_asynch_execute_gpe_method>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            acpi_ev_asynch_enable_gpe, gpe_event_info);
+		 *   - drivers/acpi/acpica/evgpe.c|823| <<acpi_ev_gpe_dispatch>> status = acpi_os_execute(OSL_GPE_HANDLER,
+		 *            acpi_ev_asynch_execute_gpe_method, gpe_event_info);
+		 *   - drivers/acpi/acpica/evmisc.c|139| <<acpi_ev_queue_notify_request>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            acpi_ev_notify_dispatch, info);
+		 *   - drivers/acpi/bus.c|539| <<acpi_device_fixed_event>> acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            acpi_notify_device_fixed, data);
+		 *   - drivers/acpi/sbshc.c|232| <<smbus_alarm>> acpi_os_execute(OSL_NOTIFY_HANDLER, acpi_smbus_callback, hc);
+		 *   - drivers/platform/x86/dell/dell-rbtn.c|278| <<rbtn_resume>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+		 *            rbtn_clear_suspended_flag, rbtn_data);
+		 *
+		 *
+		 * struct acpi_gpe_block_info *gpe_block;
+		 * -> struct acpi_namespace_node *node; (gpe_device->name.ascii = "_GPE".)
+		 * -> struct acpi_gpe_register_info *register_info;
+		 * -> struct acpi_gpe_event_info *event_info;
+		 *
+		 * debug测试的时候只有i=0, j=1执行了这里
+		 * gpe_number=1
+		 * (插入第二个第三个还是这样)
+		 * 应该是ACPI_GPE_DISPATCH_METHOD
+		 */
 		/*
 		 * Execute the method associated with the GPE
 		 * NOTE: Level-triggered GPEs are cleared after the method completes.
diff --git a/drivers/acpi/acpica/evmisc.c b/drivers/acpi/acpica/evmisc.c
index f14ebcd610ab..8e5f031301d7 100644
--- a/drivers/acpi/acpica/evmisc.c
+++ b/drivers/acpi/acpica/evmisc.c
@@ -64,11 +64,92 @@ u8 acpi_ev_is_notify_object(struct acpi_namespace_node *node)
  *
  ******************************************************************************/
 
+/*
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ *
+ * [0] acpi_hotplug_schedule
+ * [0] acpi_bus_notify
+ * [0] acpi_ev_notify_dispatch
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * static acpi_execute_op acpi_gbl_op_type_dispatch[] = {
+ *     acpi_ex_opcode_0A_0T_1R,
+ *     acpi_ex_opcode_1A_0T_0R,
+ *     acpi_ex_opcode_1A_0T_1R,
+ *     acpi_ex_opcode_1A_1T_0R,
+ *     acpi_ex_opcode_1A_1T_1R,
+ *     acpi_ex_opcode_2A_0T_0R,
+ *     acpi_ex_opcode_2A_0T_1R,
+ *     acpi_ex_opcode_2A_1T_1R,
+ *     acpi_ex_opcode_2A_2T_1R,
+ *     acpi_ex_opcode_3A_0T_0R,
+ *     acpi_ex_opcode_3A_1T_1R,
+ *     acpi_ex_opcode_6A_0T_1R
+ *
+ * 在以下使用acpi_ev_queue_notify_request():
+ *   - drivers/acpi/acpica/dbcmds.c|386| <<acpi_db_send_notify>> status = acpi_ev_queue_notify_request(node, value);
+ *   - drivers/acpi/acpica/evgpe.c|482| <<acpi_ev_asynch_execute_gpe_method>> acpi_ev_queue_notify_request(notify->device_node, ACPI_NOTIFY_DEVICE_WAKE);
+ *   - drivers/acpi/acpica/exoparg2.c|96| <<acpi_ex_opcode_2A_0T_0R>> status = acpi_ev_queue_notify_request(node, value);
+ *
+ * 要看acpi_ex_opcode_2A_0T_0R()!!!
+ */
 acpi_status
 acpi_ev_queue_notify_request(struct acpi_namespace_node *node, u32 notify_value)
 {
 	union acpi_operand_object *obj_desc;
 	union acpi_operand_object *handler_list_head = NULL;
+	/*
+	 * union acpi_generic_state {
+	 *     struct acpi_common_state common;
+	 *     struct acpi_control_state control;
+	 *     struct acpi_update_state update;
+	 *     struct acpi_scope_state scope;
+	 *     struct acpi_pscope_state parse_scope;
+	 *     struct acpi_pkg_state pkg;
+	 *     struct acpi_thread_state thread;
+	 *     struct acpi_result_values results;
+	 *     struct acpi_notify_info notify;
+	 * };
+	 */
 	union acpi_generic_state *info;
 	u8 handler_list_id = 0;
 	acpi_status status = AE_OK;
@@ -116,6 +197,18 @@ acpi_ev_queue_notify_request(struct acpi_namespace_node *node, u32 notify_value)
 
 	/* Setup notify info and schedule the notify dispatcher */
 
+	/*
+	 * 在以下调用acpi_ut_create_generic_state():
+	 *   - drivers/acpi/acpica/dswscope.c|92| <<acpi_ds_scope_stack_push>> scope_info = acpi_ut_create_generic_state();
+	 *   - drivers/acpi/acpica/dswstate.c|198| <<acpi_ds_result_stack_push>> state = acpi_ut_create_generic_state();
+	 *   - drivers/acpi/acpica/evmisc.c|184| <<acpi_ev_queue_notify_request>> info = acpi_ut_create_generic_state();
+	 *   - drivers/acpi/acpica/psscope.c|78| <<acpi_ps_init_scope>> scope = acpi_ut_create_generic_state();
+	 *   - drivers/acpi/acpica/psscope.c|119| <<acpi_ps_push_scope>> scope = acpi_ut_create_generic_state();
+	 *   - drivers/acpi/acpica/utstate.c|121| <<acpi_ut_create_thread_state>> state = acpi_ut_create_generic_state();
+	 *   - drivers/acpi/acpica/utstate.c|165| <<acpi_ut_create_update_state>> state = acpi_ut_create_generic_state();
+	 *   - drivers/acpi/acpica/utstate.c|201| <<acpi_ut_create_pkg_state>> state = acpi_ut_create_generic_state();
+	 *   - drivers/acpi/acpica/utstate.c|238| <<acpi_ut_create_control_state>> state = acpi_ut_create_generic_state();
+	 */
 	info = acpi_ut_create_generic_state();
 	if (!info) {
 		return (AE_NO_MEMORY);
@@ -123,12 +216,40 @@ acpi_ev_queue_notify_request(struct acpi_namespace_node *node, u32 notify_value)
 
 	info->common.descriptor_type = ACPI_DESC_TYPE_STATE_NOTIFY;
 
+	/*
+	 * union acpi_generic_state *info;
+	 * -> struct acpi_notify_info notify;
+	 *    -> struct acpi_namespace_node *node;
+	 */
 	info->notify.node = node;
 	info->notify.value = (u16)notify_value;
 	info->notify.handler_list_id = handler_list_id;
 	info->notify.handler_list_head = handler_list_head;
 	info->notify.global = &acpi_gbl_global_notify[handler_list_id];
 
+	/*
+	 * Add第一个PCI.
+	 * acpi_ut_get_node_name(node) = "S00_"
+	 * acpi_ut_get_type_name(node->type) = "Device"
+	 * notify_value = 0x01
+	 * acpi_ut_get_notify_name(notify_value, ACPI_TYPE_ANY) = "Device Check"
+	 * node = "0000000000dc4999"
+	 *
+	 * Add第二个PCI.
+	 * acpi_ut_get_node_name(node) = "S00_"
+	 * acpi_ut_get_type_name(node->type) = "Device"
+	 * notify_value = 0x01
+	 * acpi_ut_get_notify_name(notify_value, ACPI_TYPE_ANY) = "Device Check"
+	 * node = "00000000864355e2"
+	 *
+	 * 然后删除:
+	 * Dispatching Notify on [S00_] (Device) Value 0x03 (Eject Request) Node 00000000864355e2
+	 *
+	 * 再Add一次第二个.
+	 * Dispatching Notify on [S00_] (Device) Value 0x01 (Device Check) Node 00000000864355e2
+	 *
+	 * acpi_ut_get_notify_name()竟然编译不过???
+	 */
 	ACPI_DEBUG_PRINT((ACPI_DB_INFO,
 			  "Dispatching Notify on [%4.4s] (%s) Value 0x%2.2X (%s) Node %p\n",
 			  acpi_ut_get_node_name(node),
@@ -136,6 +257,35 @@ acpi_ev_queue_notify_request(struct acpi_namespace_node *node, u32 notify_value)
 			  acpi_ut_get_notify_name(notify_value, ACPI_TYPE_ANY),
 			  node));
 
+	/*
+	 * 在以下调用acpi_os_execute():
+	 *   - drivers/acpi/acpica/dbexec.c|695| <<acpi_db_create_execution_thread>> status = acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+	 *            acpi_db_single_execution_thread, &acpi_gbl_db_method_info);
+	 *   - drivers/acpi/acpica/dbexec.c|849| <<acpi_db_create_execution_threads>> acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+	 *            acpi_db_method_thread, &acpi_gbl_db_method_info);
+	 *   - drivers/acpi/acpica/dbxface.c|448| <<acpi_initialize_debugger>> status = acpi_os_execute(OSL_DEBUGGER_MAIN_THREAD,
+	 *            acpi_db_execute_thread, NULL);
+	 *   - drivers/acpi/acpica/evgpe.c|526| <<acpi_ev_asynch_execute_gpe_method>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_ev_asynch_enable_gpe, gpe_event_info);
+	 *   - drivers/acpi/acpica/evgpe.c|823| <<acpi_ev_gpe_dispatch>> status = acpi_os_execute(OSL_GPE_HANDLER,
+	 *            acpi_ev_asynch_execute_gpe_method, gpe_event_info);
+	 *   - drivers/acpi/acpica/evmisc.c|139| <<acpi_ev_queue_notify_request>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_ev_notify_dispatch, info);
+	 *   - drivers/acpi/bus.c|539| <<acpi_device_fixed_event>> acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_notify_device_fixed, data);
+	 *   - drivers/acpi/sbshc.c|232| <<smbus_alarm>> acpi_os_execute(OSL_NOTIFY_HANDLER, acpi_smbus_callback, hc);
+	 *   - drivers/platform/x86/dell/dell-rbtn.c|278| <<rbtn_resume>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            rbtn_clear_suspended_flag, rbtn_data);
+	 *
+	 * [0] acpi_hotplug_schedule
+	 * [0] acpi_bus_notify
+	 * [0] acpi_ev_notify_dispatch
+	 * [0] acpi_os_execute_deferred
+	 * [0] process_one_work
+	 * [0] worker_thread
+	 * [0] kthread
+	 * [0] ret_from_fork
+	 */
 	status = acpi_os_execute(OSL_NOTIFY_HANDLER,
 				 acpi_ev_notify_dispatch, info);
 	if (ACPI_FAILURE(status)) {
@@ -158,6 +308,57 @@ acpi_ev_queue_notify_request(struct acpi_namespace_node *node, u32 notify_value)
  *
  ******************************************************************************/
 
+/*
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ *
+ *
+ * [0] acpi_hotplug_schedule
+ * [0] acpi_bus_notify
+ * [0] acpi_ev_notify_dispatch
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * 在以下使用acpi_ev_notify_dispatch():
+ *   - drivers/acpi/acpica/evmisc.c|160| <<acpi_ev_queue_notify_request>> status = acpi_os_execute(OSL_NOTIFY_HANDLER, acpi_ev_notify_dispatch, info);
+ */
 static void ACPI_SYSTEM_XFACE acpi_ev_notify_dispatch(void *context)
 {
 	union acpi_generic_state *info = (union acpi_generic_state *)context;
@@ -165,6 +366,20 @@ static void ACPI_SYSTEM_XFACE acpi_ev_notify_dispatch(void *context)
 
 	ACPI_FUNCTION_ENTRY();
 
+	/*
+	 * union acpi_generic_state *info:
+	 * -> struct acpi_notify_info notify;
+	 *    -> struct acpi_namespace_node *node;
+	 *
+	 * 在以下使用acpi_bus_notify():
+	 *   -  drivers/acpi/bus.c|1335| <<acpi_bus_init>> status =
+	 *                  acpi_install_notify_handler(ACPI_ROOT_OBJECT, ACPI_SYSTEM_NOTIFY,
+	 *                                              &acpi_bus_notify, NULL);
+	 *
+	 * 定义是:
+	 * static void acpi_bus_notify(acpi_handle handle, u32 type, void *data)
+	 */
+
 	/* Invoke a global notify handler if installed */
 
 	if (info->notify.global->handler) {
diff --git a/drivers/acpi/acpica/evsci.c b/drivers/acpi/acpica/evsci.c
index 3915ff61412b..3213f53c03b3 100644
--- a/drivers/acpi/acpica/evsci.c
+++ b/drivers/acpi/acpica/evsci.c
@@ -73,6 +73,51 @@ u32 acpi_ev_sci_dispatch(void)
  *
  ******************************************************************************/
 
+/*
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * 在以下使用acpi_ev_sci_xrupt_handler():
+ *   - drivers/acpi/acpica/evsci.c|171| <<acpi_ev_install_sci_handler>> status =
+ *                 acpi_os_install_interrupt_handler((u32) acpi_gbl_FADT.sci_interrupt,
+ *                 cpi_ev_sci_xrupt_handler, acpi_gbl_gpe_xrupt_list_head);
+ *   - drivers/acpi/acpica/evsci.c|207| <<acpi_ev_remove_all_sci_handlers>> status =
+ *                 acpi_os_remove_interrupt_handler((u32) acpi_gbl_FADT.sci_interrupt,
+ *                 acpi_ev_sci_xrupt_handler);
+ */
 static u32 ACPI_SYSTEM_XFACE acpi_ev_sci_xrupt_handler(void *context)
 {
 	struct acpi_gpe_xrupt_info *gpe_xrupt_list = context;
@@ -91,6 +136,19 @@ static u32 ACPI_SYSTEM_XFACE acpi_ev_sci_xrupt_handler(void *context)
 	 */
 	interrupt_handled |= acpi_ev_fixed_event_detect();
 
+	/*
+	 * [0] acpi_os_execute
+	 * [0] acpi_ev_gpe_dispatch
+	 * [0] acpi_ev_detect_gpe
+	 * [0] acpi_ev_gpe_detect
+	 * [0] acpi_ev_sci_xrupt_handler
+	 * [0] acpi_irq
+	 * [0] __handle_irq_event_percpu
+	 * [0] handle_irq_event
+	 * [0] handle_fasteoi_irq
+	 * [0] __common_interrupt
+	 * [0] common_interrupt
+	 */
 	/*
 	 * General Purpose Events:
 	 * Check for and dispatch any GPEs that have occurred
diff --git a/drivers/acpi/acpica/exoparg2.c b/drivers/acpi/acpica/exoparg2.c
index 10323ab186da..f448ed795277 100644
--- a/drivers/acpi/acpica/exoparg2.c
+++ b/drivers/acpi/acpica/exoparg2.c
@@ -52,8 +52,66 @@ ACPI_MODULE_NAME("exoparg2")
  * ALLOCATION:  Deletes both operands
  *
  ******************************************************************************/
+/*
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq         
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt     
+ *                            
+ * [0] acpi_os_execute       
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op  
+ * [0] acpi_ps_parse_loop   
+ * [0] acpi_ps_parse_aml        
+ * [0] acpi_ps_execute_method   
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work         
+ * [0] worker_thread            
+ * [0] kthread                      
+ * [0] ret_from_fork                                            
+ *                                                              
+ * [0] acpi_os_execute          
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred         
+ * [0] process_one_work                         
+ * [0] worker_thread                                            
+ * [0] kthread                          
+ * [0] ret_from_fork
+ *
+ *
+ * static acpi_execute_op acpi_gbl_op_type_dispatch[] = {
+ *     acpi_ex_opcode_0A_0T_1R,
+ *     acpi_ex_opcode_1A_0T_0R,
+ *     acpi_ex_opcode_1A_0T_1R,
+ *     acpi_ex_opcode_1A_1T_0R,
+ *     acpi_ex_opcode_1A_1T_1R,
+ *     acpi_ex_opcode_2A_0T_0R,
+ *     acpi_ex_opcode_2A_0T_1R,
+ *     acpi_ex_opcode_2A_1T_1R,
+ *     acpi_ex_opcode_2A_2T_1R,
+ *     acpi_ex_opcode_3A_0T_0R,
+ *     acpi_ex_opcode_3A_1T_1R,
+ *     acpi_ex_opcode_6A_0T_1R
+ * };
+ *
+ * 在以下使用acpi_gbl_op_type_dispatch[]:
+ *   - drivers/acpi/acpica/dswexec.c|453| <<acpi_ds_exec_end_op>> acpi_gbl_op_type_dispatch[op_type] (walk_state);
+ */
 acpi_status acpi_ex_opcode_2A_0T_0R(struct acpi_walk_state *walk_state)
 {
+	/*
+	 * struct acpi_walk_state *walk_state;
+	 * -> union acpi_operand_object *operands[ACPI_OBJ_NUM_OPERANDS + 1];
+	 */
 	union acpi_operand_object **operand = &walk_state->operands[0];
 	struct acpi_namespace_node *node;
 	u32 value;
@@ -93,6 +151,9 @@ acpi_status acpi_ex_opcode_2A_0T_0R(struct acpi_walk_state *walk_state)
 		 * from this thread -- because handlers may in turn run other
 		 * control methods.
 		 */
+		/*
+		 * 执行这里!!!
+		 */
 		status = acpi_ev_queue_notify_request(node, value);
 		break;
 
diff --git a/drivers/acpi/acpica/nseval.c b/drivers/acpi/acpica/nseval.c
index 63748ac699f7..a10aa62022ed 100644
--- a/drivers/acpi/acpica/nseval.c
+++ b/drivers/acpi/acpica/nseval.c
@@ -39,6 +39,127 @@ ACPI_MODULE_NAME("nseval")
  * MUTEX:       Locks interpreter
  *
  ******************************************************************************/
+/*
+ * _SB.PCI0.S29.S00._ADR (Integer)
+ *
+ * [0] acpi_ns_evaluate+0xe7/0x2ae
+ * [0] acpi_evaluate_object
+ * [0] acpi_evaluate_integer
+ * [0] acpi_find_child_device
+ * [0] acpi_pci_find_companion
+ * [0] pci_set_acpi_fwnode
+ * [0] pci_setup_device
+ * [0] pci_scan_single_device
+ * [0] pci_scan_slot
+ * [0] acpiphp_hotplug_notify
+ * [0] acpi_device_hotplug
+ * [0] acpi_hotplug_work_fn
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ *
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ *
+ * struct acpi_gpe_block_info *gpe_block;
+ * -> struct acpi_namespace_node *node; (gpe_device->name.ascii = "_GPE".)
+ * -> struct acpi_gpe_register_info *register_info;
+ * -> struct acpi_gpe_event_info *event_info;
+ *
+ * debug测试的时候只有i=0, j=1执行了这里
+ * gpe_number=1
+ * (插入第二个第三个还是这样)
+ * 应该是ACPI_GPE_DISPATCH_METHOD
+ *
+ * 这里测试的
+ * acpi_ut_get_node_name(gpe_event_info->dispatch.method_node)是"_E01"
+ *
+ *     Scope (_GPE)
+ *     {
+ *         Method (_E01, 0, NotSerialized)  // _Exx: Edge-Triggered GPE, xx=0x00-0xFF
+ *         {
+ *             Acquire (\_SB.PCI0.BLCK, 0xFFFF)
+ *             \_SB.PCI0.PCNT ()
+ *             Release (\_SB.PCI0.BLCK)
+ *         }
+ *     }
+ *
+ *         Method (PCNT, 0, NotSerialized)
+ *         {
+ *             ^S2C.PCNT ()
+ *             ^S2A.PCNT ()
+ *             ^S29.PCNT ()
+ *             ^S28.PCNT ()
+ *             ^S27.PCNT ()
+ *         }
+ *
+ * 其中一个例子
+ *        Scope (S29)
+ *         {
+ *             Method (PCNT, 0, NotSerialized)
+ *             {
+ *                 BNUM = 0x02
+ *                 DVNT (PCIU, One)
+ *                 DVNT (PCID, 0x03)
+ *             }
+ *         }
+ *
+ *
+ *                 Method (DVNT, 2, NotSerialized)
+ *                 {
+ *                     If ((Arg0 & One))
+ *                     {
+ *                         Notify (S00, Arg1)
+ *                     }
+ *                }
+ *
+ * 在以下调用acpi_ns_evaluate():
+ *   - drivers/acpi/acpica/evgpe.c|598| <<acpi_ev_asynch_execute_gpe_method>> status = acpi_ns_evaluate(info);
+ *   - drivers/acpi/acpica/evregion.c|630| <<acpi_ev_execute_reg_method>> status = acpi_ns_evaluate(info);
+ *   - drivers/acpi/acpica/hwxface.c|362| <<acpi_get_sleep_type_data>> status = acpi_ns_evaluate(info);
+ *   - drivers/acpi/acpica/nsinit.c|156| <<acpi_ns_initialize_devices>> status = acpi_ns_evaluate(info.evaluate_info);
+ *   - drivers/acpi/acpica/nsinit.c|176| <<acpi_ns_initialize_devices>> status = acpi_ns_evaluate(info.evaluate_info);
+ *   - drivers/acpi/acpica/nsinit.c|645| <<acpi_ns_init_one_device>> status = acpi_ns_evaluate(info);
+ *   - drivers/acpi/acpica/nsxfeval.c|354| <<acpi_evaluate_object>> status = acpi_ns_evaluate(info);
+ *   - drivers/acpi/acpica/rsutils.c|746| <<acpi_rs_set_srs_method_data>> status = acpi_ns_evaluate(info);
+ *   - drivers/acpi/acpica/uteval.c|60| <<acpi_ut_evaluate_object>> status = acpi_ns_evaluate(info);
+ */
 acpi_status acpi_ns_evaluate(struct acpi_evaluate_info *info)
 {
 	acpi_status status;
@@ -49,6 +170,10 @@ acpi_status acpi_ns_evaluate(struct acpi_evaluate_info *info)
 		return_ACPI_STATUS(AE_BAD_PARAMETER);
 	}
 
+	/*
+	 * 从acpi_ev_asynch_execute_gpe_method()过来的话
+	 * 感觉就设置了prefix_node和flags
+	 */
 	if (!info->node) {
 		/*
 		 * Get the actual namespace node for the target object if we
@@ -100,6 +225,15 @@ acpi_status acpi_ns_evaluate(struct acpi_evaluate_info *info)
 
 	/* Optional object evaluation log */
 
+	/*
+	 * 从acpi_ev_asynch_execute_gpe_method()进来
+	 * 这里"%s (%s)\n"显示的是:
+	 * "_GPE._E01 (Method)"
+	 *
+	 * 从这里接着往下走, 怎么变成了ACPI的handle的呢???
+	 *
+	 * BTW, 稍后来到这里的时候是"_SB.PCI0.S2A.S00._DSM (Method)"
+	 */
 	ACPI_DEBUG_PRINT_RAW((ACPI_DB_EVALUATION,
 			      "%-26s:  %s (%s)\n", "   Enter evaluation",
 			      &info->full_pathname[1],
@@ -202,6 +336,10 @@ acpi_status acpi_ns_evaluate(struct acpi_evaluate_info *info)
 		 * here before calling into the AML parser
 		 */
 		acpi_ex_enter_interpreter();
+		/*
+		 * 这里吧
+		 * 只在这里调用
+		 */
 		status = acpi_ps_execute_method(info);
 		acpi_ex_exit_interpreter();
 		break;
diff --git a/drivers/acpi/acpica/nsnames.c b/drivers/acpi/acpica/nsnames.c
index d91153f65700..00adf10529ea 100644
--- a/drivers/acpi/acpica/nsnames.c
+++ b/drivers/acpi/acpica/nsnames.c
@@ -137,6 +137,9 @@ acpi_ns_handle_to_pathname(acpi_handle target_handle,
 
 	ACPI_FUNCTION_TRACE_PTR(ns_handle_to_pathname, target_handle);
 
+	/*
+	 * struct acpi_namespace_node *node;
+	 */
 	node = acpi_ns_validate_handle(target_handle);
 	if (!node) {
 		return_ACPI_STATUS(AE_BAD_PARAMETER);
diff --git a/drivers/acpi/acpica/nsxfeval.c b/drivers/acpi/acpica/nsxfeval.c
index f9d059647cc5..9c8a396ee144 100644
--- a/drivers/acpi/acpica/nsxfeval.c
+++ b/drivers/acpi/acpica/nsxfeval.c
@@ -922,6 +922,13 @@ ACPI_EXPORT_SYMBOL(acpi_detach_data)
  *              and execute a callback before returning.
  *
  ******************************************************************************/
+/*
+ * 在以下调用acpi_get_data_full():
+ *   - drivers/acpi/acpica/nsxfeval.c|979| <<acpi_get_data>> return acpi_get_data_full(obj_handle, handler, data, NULL);
+ *   - drivers/acpi/scan.c|576| <<acpi_get_data>> status = acpi_get_data_full(handle, acpi_scan_drop_device, (void **)&adev, callback);
+ *
+ * callback的一个例子是get_acpi_device()
+ */
 acpi_status
 acpi_get_data_full(acpi_handle obj_handle, acpi_object_handler handler,
 		   void **data, void (*callback)(void *))
@@ -950,6 +957,9 @@ acpi_get_data_full(acpi_handle obj_handle, acpi_object_handler handler,
 
 	status = acpi_ns_get_attached_data(node, handler, data);
 	if (ACPI_SUCCESS(status) && callback) {
+		/*
+		 * 比如get_acpi_device()
+		 */
 		callback(*data);
 	}
 
diff --git a/drivers/acpi/acpica/nsxfname.c b/drivers/acpi/acpica/nsxfname.c
index 03487546da5a..76caa414d8a2 100644
--- a/drivers/acpi/acpica/nsxfname.c
+++ b/drivers/acpi/acpica/nsxfname.c
@@ -145,6 +145,9 @@ acpi_get_name(acpi_handle handle, u32 name_type, struct acpi_buffer *buffer)
 		return (status);
 	}
 
+	/*
+	 * 应该是ACPI_FULL_PATHNAME
+	 */
 	if (name_type == ACPI_FULL_PATHNAME ||
 	    name_type == ACPI_FULL_PATHNAME_NO_TRAILING) {
 
diff --git a/drivers/acpi/acpica/psloop.c b/drivers/acpi/acpica/psloop.c
index 4b51dd939f29..7b4f74ecdb73 100644
--- a/drivers/acpi/acpica/psloop.c
+++ b/drivers/acpi/acpica/psloop.c
@@ -218,6 +218,43 @@ acpi_ps_get_arguments(struct acpi_walk_state *walk_state,
  *
  ******************************************************************************/
 
+/*
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ */
 acpi_status acpi_ps_parse_loop(struct acpi_walk_state *walk_state)
 {
 	acpi_status status = AE_OK;
@@ -522,6 +559,10 @@ acpi_status acpi_ps_parse_loop(struct acpi_walk_state *walk_state)
 			walk_state->op = op;
 			walk_state->opcode = op->common.aml_opcode;
 
+			/*
+			 * 这里很重要
+			 * acpi_ds_exec_end_op()
+			 */
 			status = walk_state->ascending_callback(walk_state);
 			status =
 			    acpi_ps_next_parse_state(walk_state, op, status);
diff --git a/drivers/acpi/acpica/psparse.c b/drivers/acpi/acpica/psparse.c
index 7eb7a81619a3..6155b1a12690 100644
--- a/drivers/acpi/acpica/psparse.c
+++ b/drivers/acpi/acpica/psparse.c
@@ -405,6 +405,43 @@ acpi_ps_next_parse_state(struct acpi_walk_state *walk_state,
  *
  ******************************************************************************/
 
+/*
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ */
 acpi_status acpi_ps_parse_aml(struct acpi_walk_state *walk_state)
 {
 	acpi_status status;
@@ -472,6 +509,9 @@ acpi_status acpi_ps_parse_aml(struct acpi_walk_state *walk_state)
 			 * The parse_loop executes AML until the method terminates
 			 * or calls another method.
 			 */
+			/*
+			 * 在这里????
+			 */
 			status = acpi_ps_parse_loop(walk_state);
 		}
 
diff --git a/drivers/acpi/acpica/psxface.c b/drivers/acpi/acpica/psxface.c
index fd0f28c7af1e..f5ebc868ac0b 100644
--- a/drivers/acpi/acpica/psxface.c
+++ b/drivers/acpi/acpica/psxface.c
@@ -81,6 +81,47 @@ acpi_debug_trace(const char *name, u32 debug_level, u32 debug_layer, u32 flags)
  *
  ******************************************************************************/
 
+/*
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ *
+ * 在以下使用acpi_ps_execute_method():
+ *   - drivers/acpi/acpica/nseval.c|313| <<acpi_ns_evaluate>> status = acpi_ps_execute_method(info);
+ */
 acpi_status acpi_ps_execute_method(struct acpi_evaluate_info *info)
 {
 	acpi_status status;
@@ -187,6 +228,9 @@ acpi_status acpi_ps_execute_method(struct acpi_evaluate_info *info)
 
 	/* Parse the AML */
 
+	/*
+	 * 在这里??
+	 */
 	status = acpi_ps_parse_aml(walk_state);
 
 	/* walk_state was deleted by parse_aml */
diff --git a/drivers/acpi/acpica/utstate.c b/drivers/acpi/acpica/utstate.c
index a2484556a6b5..512c874c95c0 100644
--- a/drivers/acpi/acpica/utstate.c
+++ b/drivers/acpi/acpica/utstate.c
@@ -81,6 +81,18 @@ union acpi_generic_state *acpi_ut_pop_generic_state(union acpi_generic_state
  *
  ******************************************************************************/
 
+/*
+ * 在以下调用acpi_ut_create_generic_state():
+ *   - drivers/acpi/acpica/dswscope.c|92| <<acpi_ds_scope_stack_push>> scope_info = acpi_ut_create_generic_state();
+ *   - drivers/acpi/acpica/dswstate.c|198| <<acpi_ds_result_stack_push>> state = acpi_ut_create_generic_state();
+ *   - drivers/acpi/acpica/evmisc.c|184| <<acpi_ev_queue_notify_request>> info = acpi_ut_create_generic_state();
+ *   - drivers/acpi/acpica/psscope.c|78| <<acpi_ps_init_scope>> scope = acpi_ut_create_generic_state();
+ *   - drivers/acpi/acpica/psscope.c|119| <<acpi_ps_push_scope>> scope = acpi_ut_create_generic_state();
+ *   - drivers/acpi/acpica/utstate.c|121| <<acpi_ut_create_thread_state>> state = acpi_ut_create_generic_state();
+ *   - drivers/acpi/acpica/utstate.c|165| <<acpi_ut_create_update_state>> state = acpi_ut_create_generic_state();
+ *   - drivers/acpi/acpica/utstate.c|201| <<acpi_ut_create_pkg_state>> state = acpi_ut_create_generic_state();
+ *   - drivers/acpi/acpica/utstate.c|238| <<acpi_ut_create_control_state>> state = acpi_ut_create_generic_state();
+ */
 union acpi_generic_state *acpi_ut_create_generic_state(void)
 {
 	union acpi_generic_state *state;
diff --git a/drivers/acpi/bus.c b/drivers/acpi/bus.c
index 30938e61d54b..952e4f397ed8 100644
--- a/drivers/acpi/bus.c
+++ b/drivers/acpi/bus.c
@@ -445,6 +445,22 @@ static void acpi_bus_osc_negotiate_usb_control(void)
  * ---------------
  * Callback for all 'system-level' device notifications (values 0x00-0x7F).
  */
+/*
+ * [0] acpi_hotplug_schedule
+ * [0] acpi_bus_notify
+ * [0] acpi_ev_notify_dispatch
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ *
+ * 在以下使用acpi_bus_notify():
+ *   -  drivers/acpi/bus.c|1335| <<acpi_bus_init>> status =
+ *                  acpi_install_notify_handler(ACPI_ROOT_OBJECT, ACPI_SYSTEM_NOTIFY,
+ *                                              &acpi_bus_notify, NULL);
+ */
 static void acpi_bus_notify(acpi_handle handle, u32 type, void *data)
 {
 	struct acpi_device *adev;
@@ -496,6 +512,14 @@ static void acpi_bus_notify(acpi_handle handle, u32 type, void *data)
 		break;
 	}
 
+	/*
+	 * 在以下调用acpi_bus_get_acpi_device():
+	 *   - drivers/acpi/bus.c|508| <<acpi_bus_notify>> adev = acpi_bus_get_acpi_device(handle);
+	 *   - drivers/acpi/device_pm.c|447| <<acpi_pm_notify_handler>> adev = acpi_bus_get_acpi_device(handle);
+	 *   - drivers/acpi/irq.c|127| <<acpi_get_irq_source_fwhandle>> device = acpi_bus_get_acpi_device(handle);
+	 *   - drivers/acpi/scan.c|2223| <<acpi_dev_get_first_consumer_dev_cb>> adev = acpi_bus_get_acpi_device(dep->consumer);
+	 *   - drivers/acpi/scan.c|2276| <<acpi_scan_clear_dep>> struct acpi_device *adev = acpi_bus_get_acpi_device(dep->consumer);
+	 */
 	adev = acpi_bus_get_acpi_device(handle);
 	if (!adev)
 		goto err;
@@ -536,6 +560,26 @@ static void acpi_notify_device_fixed(void *data)
 
 static u32 acpi_device_fixed_event(void *data)
 {
+	/*
+	 * 在以下调用acpi_os_execute():
+	 *   - drivers/acpi/acpica/dbexec.c|695| <<acpi_db_create_execution_thread>> status = acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+	 *            acpi_db_single_execution_thread, &acpi_gbl_db_method_info);
+	 *   - drivers/acpi/acpica/dbexec.c|849| <<acpi_db_create_execution_threads>> acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+	 *            acpi_db_method_thread, &acpi_gbl_db_method_info);
+	 *   - drivers/acpi/acpica/dbxface.c|448| <<acpi_initialize_debugger>> status = acpi_os_execute(OSL_DEBUGGER_MAIN_THREAD,
+	 *            acpi_db_execute_thread, NULL);
+	 *   - drivers/acpi/acpica/evgpe.c|526| <<acpi_ev_asynch_execute_gpe_method>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_ev_asynch_enable_gpe, gpe_event_info);
+	 *   - drivers/acpi/acpica/evgpe.c|823| <<acpi_ev_gpe_dispatch>> status = acpi_os_execute(OSL_GPE_HANDLER,
+	 *            acpi_ev_asynch_execute_gpe_method, gpe_event_info);
+	 *   - drivers/acpi/acpica/evmisc.c|139| <<acpi_ev_queue_notify_request>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_ev_notify_dispatch, info);
+	 *   - drivers/acpi/bus.c|539| <<acpi_device_fixed_event>> acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            acpi_notify_device_fixed, data);
+	 *   - drivers/acpi/sbshc.c|232| <<smbus_alarm>> acpi_os_execute(OSL_NOTIFY_HANDLER, acpi_smbus_callback, hc);
+	 *   - drivers/platform/x86/dell/dell-rbtn.c|278| <<rbtn_resume>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+	 *            rbtn_clear_suspended_flag, rbtn_data);
+	 */
 	acpi_os_execute(OSL_NOTIFY_HANDLER, acpi_notify_device_fixed, data);
 	return ACPI_INTERRUPT_HANDLED;
 }
diff --git a/drivers/acpi/osl.c b/drivers/acpi/osl.c
index 45c5c0e45e33..11d816d0f3ba 100644
--- a/drivers/acpi/osl.c
+++ b/drivers/acpi/osl.c
@@ -63,6 +63,12 @@ static int (*__acpi_os_prepare_extended_sleep)(u8 sleep_state, u32 val_a,
 				      u32 val_b);
 
 static acpi_osd_handler acpi_irq_handler;
+/*
+ * 在以下使用acpi_irq_context:
+ *   - drivers/acpi/osl.c|66| <<global>> static void *acpi_irq_context;
+ *   - drivers/acpi/osl.c|550| <<acpi_irq>> handled = (*acpi_irq_handler) (acpi_irq_context);
+ *   - drivers/acpi/osl.c|585| <<acpi_os_install_interrupt_handler>> acpi_irq_context = context;
+ */
 static void *acpi_irq_context;
 static struct workqueue_struct *kacpid_wq;
 static struct workqueue_struct *kacpi_notify_wq;
@@ -547,6 +553,12 @@ static irqreturn_t acpi_irq(int irq, void *dev_id)
 {
 	u32 handled;
 
+	/*
+	 * 在以下使用acpi_irq_context:
+	 *   - drivers/acpi/osl.c|66| <<global>> static void *acpi_irq_context;
+	 *   - drivers/acpi/osl.c|550| <<acpi_irq>> handled = (*acpi_irq_handler) (acpi_irq_context);
+	 *   - drivers/acpi/osl.c|585| <<acpi_os_install_interrupt_handler>> acpi_irq_context = context;
+	 */
 	handled = (*acpi_irq_handler) (acpi_irq_context);
 
 	if (handled) {
@@ -582,6 +594,12 @@ acpi_os_install_interrupt_handler(u32 gsi, acpi_osd_handler handler,
 	}
 
 	acpi_irq_handler = handler;
+	/*
+	 * 在以下使用acpi_irq_context:
+	 *   - drivers/acpi/osl.c|66| <<global>> static void *acpi_irq_context;
+	 *   - drivers/acpi/osl.c|550| <<acpi_irq>> handled = (*acpi_irq_handler) (acpi_irq_context);
+	 *   - drivers/acpi/osl.c|585| <<acpi_os_install_interrupt_handler>> acpi_irq_context = context;
+	 */
 	acpi_irq_context = context;
 	if (request_irq(irq, acpi_irq, IRQF_SHARED, "acpi", acpi_irq)) {
 		pr_err("SCI (IRQ%d) allocation failed\n", irq);
@@ -841,8 +859,20 @@ acpi_os_write_pci_configuration(struct acpi_pci_id * pci_id, u32 reg,
 }
 #endif
 
+/*
+ * 在以下使用acpi_os_execute_deferred():
+ *   - drivers/acpi/osl.c|1104| <<acpi_os_execute>> INIT_WORK(&dpc->work, acpi_os_execute_deferred);
+ *   - drivers/acpi/osl.c|1107| <<acpi_os_execute>> INIT_WORK(&dpc->work, acpi_os_execute_deferred);
+ */
 static void acpi_os_execute_deferred(struct work_struct *work)
 {
+	/*
+	 * struct acpi_os_dpc {
+	 *     acpi_osd_exec_callback function;
+	 *     void *context;
+	 *     struct work_struct work;
+	 * };
+	 */
 	struct acpi_os_dpc *dpc = container_of(work, struct acpi_os_dpc, work);
 
 	dpc->function(dpc->context);
@@ -1058,6 +1088,65 @@ int __init acpi_debugger_init(void)
  *
  ******************************************************************************/
 
+/*
+ * hotplug pci的时候调用三次.
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_gpe_dispatch
+ * [0] acpi_ev_detect_gpe
+ * [0] acpi_ev_gpe_detect
+ * [0] acpi_ev_sci_xrupt_handler
+ * [0] acpi_irq
+ * [0] __handle_irq_event_percpu
+ * [0] handle_irq_event
+ * [0] handle_fasteoi_irq
+ * [0] __common_interrupt
+ * [0] common_interrupt
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_queue_notify_request
+ * [0] acpi_ds_exec_end_op
+ * [0] acpi_ps_parse_loop
+ * [0] acpi_ps_parse_aml
+ * [0] acpi_ps_execute_method
+ * [0] acpi_ns_evaluate
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * [0] acpi_os_execute
+ * [0] acpi_ev_asynch_execute_gpe_method
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ *
+ * 在以下调用acpi_os_execute():
+ *   - drivers/acpi/acpica/dbexec.c|695| <<acpi_db_create_execution_thread>> status = acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+ *            acpi_db_single_execution_thread, &acpi_gbl_db_method_info);
+ *   - drivers/acpi/acpica/dbexec.c|849| <<acpi_db_create_execution_threads>> acpi_os_execute(OSL_DEBUGGER_EXEC_THREAD,
+ *            acpi_db_method_thread, &acpi_gbl_db_method_info);
+ *   - drivers/acpi/acpica/dbxface.c|448| <<acpi_initialize_debugger>> status = acpi_os_execute(OSL_DEBUGGER_MAIN_THREAD,
+ *            acpi_db_execute_thread, NULL);
+ *   - drivers/acpi/acpica/evgpe.c|526| <<acpi_ev_asynch_execute_gpe_method>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+ *            acpi_ev_asynch_enable_gpe, gpe_event_info);
+ *   - drivers/acpi/acpica/evgpe.c|823| <<acpi_ev_gpe_dispatch>> status = acpi_os_execute(OSL_GPE_HANDLER,
+ *            acpi_ev_asynch_execute_gpe_method, gpe_event_info);
+ *   - drivers/acpi/acpica/evmisc.c|139| <<acpi_ev_queue_notify_request>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+ *            acpi_ev_notify_dispatch, info);
+ *   - drivers/acpi/bus.c|539| <<acpi_device_fixed_event>> acpi_os_execute(OSL_NOTIFY_HANDLER,
+ *            acpi_notify_device_fixed, data);
+ *   - drivers/acpi/sbshc.c|232| <<smbus_alarm>> acpi_os_execute(OSL_NOTIFY_HANDLER, acpi_smbus_callback, hc);
+ *   - drivers/platform/x86/dell/dell-rbtn.c|278| <<rbtn_resume>> status = acpi_os_execute(OSL_NOTIFY_HANDLER,
+ *            rbtn_clear_suspended_flag, rbtn_data);
+ *
+ * hotplug的时候type好像是2, 1, 1
+ */
 acpi_status acpi_os_execute(acpi_execute_type type,
 			    acpi_osd_exec_callback function, void *context)
 {
@@ -1087,6 +1176,13 @@ acpi_status acpi_os_execute(acpi_execute_type type,
 	 * having a static work_struct.
 	 */
 
+	/*
+	 * struct acpi_os_dpc {
+	 *     acpi_osd_exec_callback function;
+	 *     void *context;
+	 *     struct work_struct work;
+	 * };
+	 */
 	dpc = kzalloc(sizeof(struct acpi_os_dpc), GFP_ATOMIC);
 	if (!dpc)
 		return AE_NO_MEMORY;
@@ -1152,6 +1248,18 @@ struct acpi_hp_work {
 	u32 src;
 };
 
+/*
+ * [0] acpiphp_hotplug_notify
+ * [0] acpi_device_hotplug
+ * [0] acpi_hotplug_work_fn
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * 在以下使用acpi_hotplug_work_fn():
+ *   - drivers/acpi/osl.c|1210| <<acpi_hotplug_schedule>> INIT_WORK(&hpw->work, acpi_hotplug_work_fn);
+ */
 static void acpi_hotplug_work_fn(struct work_struct *work)
 {
 	struct acpi_hp_work *hpw = container_of(work, struct acpi_hp_work, work);
@@ -1161,6 +1269,20 @@ static void acpi_hotplug_work_fn(struct work_struct *work)
 	kfree(hpw);
 }
 
+/*
+ * [0] acpi_hotplug_schedule
+ * [0] acpi_bus_notify
+ * [0] acpi_ev_notify_dispatch
+ * [0] acpi_os_execute_deferred
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * 在以下调用acpi_hotplug_schedule():
+ *   - drivers/acpi/bus.c|522| <<acpi_bus_notify>> if (ACPI_SUCCESS(acpi_hotplug_schedule(adev, type)))
+ *   - drivers/acpi/device_sysfs.c|388| <<eject_store>> status = acpi_hotplug_schedule(acpi_device, ACPI_OST_EC_OSPM_EJECT);
+ */
 acpi_status acpi_hotplug_schedule(struct acpi_device *adev, u32 src)
 {
 	struct acpi_hp_work *hpw;
diff --git a/drivers/acpi/scan.c b/drivers/acpi/scan.c
index e7d4a39e539f..77178c61b551 100644
--- a/drivers/acpi/scan.c
+++ b/drivers/acpi/scan.c
@@ -376,6 +376,83 @@ static int acpi_generic_hotplug_event(struct acpi_device *adev, u32 type)
 	return -EINVAL;
 }
 
+/*
+ * [  433.553792] <intr> acpi:624: ACPI: GPE event 0x01
+ * [  433.554104] [426] acpi:462: ACPI: \_SB_.PCI0.S29_.S00_: ACPI: ACPI_NOTIFY_DEVICE_CHECK event
+ * [  433.554110] [426] acpi:1168: ACPI: \_SB_.PCI0.S29_.S00_: ACPI: OSL: Scheduling hotplug event 1 for deferred handling
+ * [  433.554178] [97] acpiphp:803: ACPI: \_SB_.PCI0.S29_.S00_: acpiphp_glue: Device check in hotplug_event()
+ * [  433.554184] [97] acpi:579: ACPI: \_SB_.PCI0.S29_.S00_._ADR: ACPI: No context!
+ * [  433.554186] [97] acpi:579: ACPI: \_SB_.PCI0.S29_.S00_.ASUN: ACPI: No context!
+ * [  433.554188] [97] acpi:579: ACPI: \_SB_.PCI0.S29_.S00_._DSM: ACPI: No context!
+ * [  433.554190] [97] acpi:579: ACPI: \_SB_.PCI0.S29_.S00_._SUN: ACPI: No context!
+ * [  433.554191] [97] acpi:579: ACPI: \_SB_.PCI0.S29_.S00_._EJ0: ACPI: No context!
+ * [  433.554197] [97] acpi:28: ACPI: \_SB_.PCI0.S29_.S00_: ACPI: utils: Evaluate [_STA]: AE_NOT_FOUND
+ * [  433.554199] [97] acpi:125: ACPI: Device [S00] status [0000000f]
+ * [  433.554356] [97] acpi:273: ACPI: \_SB_.PCI0.S29_.S00_: ACPI: utils: Return value [0]
+ * [  433.554359] [97] acpi:273: ACPI: \_SB_.PCI0.S29_.S00_: ACPI: utils: Return value [0]
+ * [  433.554419] pci 0000:02:00.0: [1af4:1048] type 00 class 0x010000
+ * [  433.555885] pci 0000:02:00.0: reg 0x14: [mem 0x00000000-0x00000fff]
+ * [  433.557122] pci 0000:02:00.0: reg 0x20: [mem 0x00000000-0x00003fff 64bit pref]
+ * [  433.559748] [97] edr:233: pci 0000:02:00.0: EDR: Notify handler installed
+ * [  433.559766] [97] acpi:324: wakeup wakeup15: No ACPI support
+ * [  433.559838] [97] acpi:318: ACPI: \_SB_.PCI0.S29_.S00_: ACPI: Bound to device 0000:02:00.0
+ * [  433.560376] [97] acpi:28: ACPI: \_SB_.PCI0.S29_.S00_: ACPI: utils: Evaluate [_STA]: AE_NOT_FOUND
+ * [  433.560402] [97] acpi:579: ACPI: \_SB_.PCI0.S29_.S00_._ADR: ACPI: No context!
+ * [  433.560404] [97] acpi:579: ACPI: \_SB_.PCI0.S29_.S00_.ASUN: ACPI: No context!
+ * [  433.560405] [97] acpi:579: ACPI: \_SB_.PCI0.S29_.S00_._DSM: ACPI: No context!
+ * [  433.560407] [97] acpi:579: ACPI: \_SB_.PCI0.S29_.S00_._SUN: ACPI: No context!
+ * [  433.560409] [97] acpi:579: ACPI: \_SB_.PCI0.S29_.S00_._EJ0: ACPI: No context!
+ * [  433.560411] [97] acpi:28: ACPI: \_SB_.PCI0.S29_.S00_: ACPI: utils: Evaluate [_STA]: AE_NOT_FOUND
+ * [  433.560412] [97] acpi:125: ACPI: Device [S00] status [0000000f]
+ * [  433.560430] pci 0000:02:00.0: BAR 4: assigned [mem 0x802000000-0x802003fff 64bit pref]
+ * [  433.561843] pci 0000:02:00.0: BAR 1: assigned [mem 0x81200000-0x81200fff]
+ * [  433.563130] [97] acpi:1591: pciback 0000:02:00.0: Adding to IOMMU failed: -19
+ * [  433.563136] [97] setup_irq:27: pciback 0000:02:00.0: runtime IRQ mapping not provided by arch
+ * [  433.563161] [97] acpi:1591: virtio-pci 0000:02:00.0: Adding to IOMMU failed: -19
+ * [  433.563164] [97] setup_irq:27: virtio-pci 0000:02:00.0: runtime IRQ mapping not provided by arch
+ * [  433.563197] virtio-pci 0000:02:00.0: enabling device (0000 -> 0002)
+ * [  433.565778] [97] acpi:190: ACPI: PCI: 0000:00:05[A] -> \_SB_.GSIF[0]
+ * [  433.565782] [97] acpi:327: virtio-pci 0000:02:00.0: Derived GSI INT A from 0000:00:05.1
+ * [  433.565786] [97] acpi:649: ACPI: \_SB_.GSIF: ACPI: PCI: Link is referenced
+ * [  433.565791] [97] acpi:466: virtio-pci 0000:02:00.0: PCI INT A -> Link[GSIF] -> GSI 21 (level, high) -> IRQ 21
+ * [  433.566517] [97] pci:4371: virtio-pci 0000:02:00.0: enabling bus mastering
+ * [  433.567195] [97] acpi:324: virtio virtio1: No ACPI support
+ * [  433.567502] [97] acpi:324: workqueue scsi_tmf_7: No ACPI support
+ * [  433.568580] scsi host7: Virtio SCSI HBA
+ * [  433.569371] [97] acpi:324: scsi host7: No ACPI support
+ * [  433.569420] [97] acpi:324: scsi_host host7: No ACPI support
+ * [  433.574553] scsi 7:0:1:0: Direct-Access     LIO-ORG  storage02        4.0  PQ: 0 ANSI: 6
+ * [  433.589101] [1935] acpi:324: scsi target7:0:1: No ACPI support
+ * [  433.589137] scsi 7:0:1:0: alua: supports implicit and explicit TPGS
+ * [  433.590341] scsi 7:0:1:0: alua: device naa.6001405428c34d0d8a342cdbb4597c72 port group 0 rel port 1
+ * [  433.591927] [1935] acpi:324: scsi 7:0:1:0: No ACPI support
+ * [  433.591985] [1935] acpi:324: scsi_device 7:0:1:0: No ACPI support
+ * [  433.592021] [1935] acpi:324: scsi_generic sg3: No ACPI support
+ * [  433.592093] [105] acpi:324: scsi_disk 7:0:1:0: No ACPI support
+ * [  433.592302] sd 7:0:1:0: Attached scsi generic sg3 type 0
+ * [  433.592332] sd 7:0:1:0: [sdc] 262144 512-byte logical blocks: (134 MB/128 MiB)
+ * [  433.593213] [1935] acpi:324: bsg 7:0:1:0: No ACPI support
+ * [  433.594767] sd 7:0:1:0: [sdc] Write Protect is off
+ * [  433.595651] sd 7:0:1:0: [sdc] Mode Sense: 43 00 10 08
+ * [  433.595722] sd 7:0:1:0: [sdc] Write cache: enabled, read cache: enabled, supports DPO and FUA
+ * [  433.597263] sd 7:0:1:0: alua: transition timeout set to 60 seconds
+ * [  433.597270] sd 7:0:1:0: alua: port group 00 state A non-preferred supports TOlUSNA
+ * [  433.703687] sd 7:0:1:0: [sdc] Optimal transfer size 8388608 bytes
+ * [  433.705139] [105] acpi:324: block sdc: No ACPI support
+ * [  433.705660] [105] acpi:324: bdi 8:32: No ACPI support
+ * [  433.706272] sd 7:0:1:0: [sdc] Attached SCSI disk
+ *
+ * [0] acpiphp_hotplug_notify
+ * [0] acpi_device_hotplug
+ * [0] acpi_hotplug_work_fn
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * 在以下调用acpi_device_hotplug():
+ *   - drivers/acpi/osl.c|1250| <<acpi_hotplug_work_fn>> acpi_device_hotplug(hpw->adev, hpw->src);
+ */
 void acpi_device_hotplug(struct acpi_device *adev, u32 src)
 {
 	u32 ost_code = ACPI_OST_SC_NON_SPECIFIC_FAILURE;
@@ -406,6 +483,9 @@ void acpi_device_hotplug(struct acpi_device *adev, u32 src)
 		 * There may be additional notify handlers for device objects
 		 * without the .event() callback, so ignore them here.
 		 */
+		/*
+		 * 应该是acpiphp_hotplug_notify()
+		 */
 		if (notify)
 			error = notify(adev, src);
 		else
@@ -567,12 +647,23 @@ static void acpi_scan_drop_device(acpi_handle handle, void *context)
 	mutex_unlock(&acpi_device_del_lock);
 }
 
+/*
+ * 在以下使用handle_to_device():
+ *   - drivers/acpi/scan.c|590| <<acpi_bus_get_device>> *device = handle_to_device(handle, NULL);
+ *   - drivers/acpi/scan.c|607| <<acpi_fetch_acpi_dev>> return handle_to_device(handle, NULL);
+ *   - drivers/acpi/scan.c|618| <<acpi_bus_get_acpi_device>> return handle_to_device(handle, get_acpi_device);
+ */
 static struct acpi_device *handle_to_device(acpi_handle handle,
 					    void (*callback)(void *))
 {
 	struct acpi_device *adev = NULL;
 	acpi_status status;
 
+	/*
+	 * 在以下调用acpi_get_data_full():
+	 *   - drivers/acpi/acpica/nsxfeval.c|979| <<acpi_get_data>> return acpi_get_data_full(obj_handle, handler, data, NULL);
+	 *   - drivers/acpi/scan.c|576| <<acpi_get_data>> status = acpi_get_data_full(handle, acpi_scan_drop_device, (void **)&adev, callback);
+	 */
 	status = acpi_get_data_full(handle, acpi_scan_drop_device,
 				    (void **)&adev, callback);
 	if (ACPI_FAILURE(status) || !adev) {
@@ -587,6 +678,12 @@ int acpi_bus_get_device(acpi_handle handle, struct acpi_device **device)
 	if (!device)
 		return -EINVAL;
 
+	/*
+	 * 在以下使用handle_to_device():
+	 *   - drivers/acpi/scan.c|590| <<acpi_bus_get_device>> *device = handle_to_device(handle, NULL);
+	 *   - drivers/acpi/scan.c|607| <<acpi_fetch_acpi_dev>> return handle_to_device(handle, NULL);
+	 *   - drivers/acpi/scan.c|618| <<acpi_bus_get_acpi_device>> return handle_to_device(handle, get_acpi_device);
+	 */
 	*device = handle_to_device(handle, NULL);
 	if (!*device)
 		return -ENODEV;
@@ -604,6 +701,12 @@ EXPORT_SYMBOL(acpi_bus_get_device);
  */
 struct acpi_device *acpi_fetch_acpi_dev(acpi_handle handle)
 {
+	/*
+	 * 在以下使用handle_to_device():
+	 *   - drivers/acpi/scan.c|590| <<acpi_bus_get_device>> *device = handle_to_device(handle, NULL);
+	 *   - drivers/acpi/scan.c|607| <<acpi_fetch_acpi_dev>> return handle_to_device(handle, NULL);
+	 *   - drivers/acpi/scan.c|618| <<acpi_bus_get_acpi_device>> return handle_to_device(handle, get_acpi_device);
+	 */
 	return handle_to_device(handle, NULL);
 }
 EXPORT_SYMBOL_GPL(acpi_fetch_acpi_dev);
@@ -613,8 +716,22 @@ static void get_acpi_device(void *dev)
 	acpi_dev_get(dev);
 }
 
+/*
+ * 在以下调用acpi_bus_get_acpi_device():
+ *   - drivers/acpi/bus.c|508| <<acpi_bus_notify>> adev = acpi_bus_get_acpi_device(handle);
+ *   - drivers/acpi/device_pm.c|447| <<acpi_pm_notify_handler>> adev = acpi_bus_get_acpi_device(handle);
+ *   - drivers/acpi/irq.c|127| <<acpi_get_irq_source_fwhandle>> device = acpi_bus_get_acpi_device(handle);
+ *   - drivers/acpi/scan.c|2223| <<acpi_dev_get_first_consumer_dev_cb>> adev = acpi_bus_get_acpi_device(dep->consumer);
+ *   - drivers/acpi/scan.c|2276| <<acpi_scan_clear_dep>> struct acpi_device *adev = acpi_bus_get_acpi_device(dep->consumer);
+ */
 struct acpi_device *acpi_bus_get_acpi_device(acpi_handle handle)
 {
+	/*
+	 * 在以下使用handle_to_device():
+	 *   - drivers/acpi/scan.c|590| <<acpi_bus_get_device>> *device = handle_to_device(handle, NULL);
+	 *   - drivers/acpi/scan.c|607| <<acpi_fetch_acpi_dev>> return handle_to_device(handle, NULL);
+	 *   - drivers/acpi/scan.c|618| <<acpi_bus_get_acpi_device>> return handle_to_device(handle, get_acpi_device);
+	 */
 	return handle_to_device(handle, get_acpi_device);
 }
 
@@ -1793,6 +1910,25 @@ static void acpi_scan_init_status(struct acpi_device *adev)
 		acpi_set_device_status(adev, 0);
 }
 
+/*
+ * [0] acpi_add_single_object
+ * [0] acpi_bus_check_add
+ * [0] acpi_ns_walk_namespace
+ * [0] acpi_walk_namespace
+ * [0] acpi_bus_scan
+ * [0] acpi_scan_init
+ * [0] acpi_init
+ * [0] do_one_initcall
+ * [0] kernel_init_freeable
+ * [0] kernel_init
+ * [0] ret_from_fork
+ *
+ * 在以下使用acpi_add_single_object():
+ *   - drivers/acpi/scan.c|2182| <<acpi_bus_check_add>> acpi_add_single_object(&device, handle, type, !check_dep);
+ *   - drivers/acpi/scan.c|2560| <<acpi_bus_register_early_device>> result = acpi_add_single_object(&device, NULL, type, false);
+ *   - drivers/acpi/scan.c|2579| <<acpi_bus_scan_fixed>> result = acpi_add_single_object(&device, NULL, ACPI_BUS_TYPE_POWER_BUTTON, false);
+ *   - drivers/acpi/scan.c|2595| <<acpi_bus_scan_fixed>> result = acpi_add_single_object(&device, NULL, ACPI_BUS_TYPE_SLEEP_BUTTON, false);
+ */
 static int acpi_add_single_object(struct acpi_device **child,
 				  acpi_handle handle, int type, bool dep_init)
 {
@@ -2014,6 +2150,13 @@ static u32 acpi_scan_check_dep(acpi_handle handle, bool check_dep)
 
 static bool acpi_bus_scan_second_pass;
 
+/*
+ * 在以下使用acpi_bus_check_add():
+ *   - drivers/acpi/scan.c|2198| <<acpi_bus_check_add_1>> return acpi_bus_check_add(handle, true, (struct acpi_device **)ret_p);
+ *   - drivers/acpi/scan.c|2204| <<acpi_bus_check_add_2>> return acpi_bus_check_add(handle, false, (struct acpi_device **)ret_p);
+ *   - drivers/acpi/scan.c|2494| <<acpi_bus_scan>> if (ACPI_SUCCESS(acpi_bus_check_add(handle, true, &device)))
+ *   - drivers/acpi/scan.c|2511| <<acpi_bus_scan>> if (ACPI_SUCCESS(acpi_bus_check_add(handle, false, &device)))
+ */
 static acpi_status acpi_bus_check_add(acpi_handle handle, bool check_dep,
 				      struct acpi_device **adev_p)
 {
@@ -2062,6 +2205,13 @@ static acpi_status acpi_bus_check_add(acpi_handle handle, bool check_dep,
 	 * If check_dep is true at this point, the device has no dependencies,
 	 * or the creation of the device object would have been postponed above.
 	 */
+	/*
+	 * 在以下使用acpi_add_single_object():
+	 *   - drivers/acpi/scan.c|2182| <<acpi_bus_check_add>> acpi_add_single_object(&device, handle, type, !check_dep);
+	 *   - drivers/acpi/scan.c|2560| <<acpi_bus_register_early_device>> result = acpi_add_single_object(&device, NULL, type, false);
+	 *   - drivers/acpi/scan.c|2579| <<acpi_bus_scan_fixed>> result = acpi_add_single_object(&device, NULL, ACPI_BUS_TYPE_POWER_BUTTON, false);
+	 *   - drivers/acpi/scan.c|2595| <<acpi_bus_scan_fixed>> result = acpi_add_single_object(&device, NULL, ACPI_BUS_TYPE_SLEEP_BUTTON, false);
+	 */
 	acpi_add_single_object(&device, handle, type, !check_dep);
 	if (!device)
 		return AE_CTRL_DEPTH;
@@ -2078,12 +2228,26 @@ static acpi_status acpi_bus_check_add(acpi_handle handle, bool check_dep,
 static acpi_status acpi_bus_check_add_1(acpi_handle handle, u32 lvl_not_used,
 					void *not_used, void **ret_p)
 {
+	/*
+	 * 在以下使用acpi_bus_check_add():
+	 *   - drivers/acpi/scan.c|2198| <<acpi_bus_check_add_1>> return acpi_bus_check_add(handle, true, (struct acpi_device **)ret_p);
+	 *   - drivers/acpi/scan.c|2204| <<acpi_bus_check_add_2>> return acpi_bus_check_add(handle, false, (struct acpi_device **)ret_p);
+	 *   - drivers/acpi/scan.c|2494| <<acpi_bus_scan>> if (ACPI_SUCCESS(acpi_bus_check_add(handle, true, &device)))
+	 *   - drivers/acpi/scan.c|2511| <<acpi_bus_scan>> if (ACPI_SUCCESS(acpi_bus_check_add(handle, false, &device)))
+	 */
 	return acpi_bus_check_add(handle, true, (struct acpi_device **)ret_p);
 }
 
 static acpi_status acpi_bus_check_add_2(acpi_handle handle, u32 lvl_not_used,
 					void *not_used, void **ret_p)
 {
+	/*
+	 * 在以下使用acpi_bus_check_add():
+	 *   - drivers/acpi/scan.c|2198| <<acpi_bus_check_add_1>> return acpi_bus_check_add(handle, true, (struct acpi_device **)ret_p);
+	 *   - drivers/acpi/scan.c|2204| <<acpi_bus_check_add_2>> return acpi_bus_check_add(handle, false, (struct acpi_device **)ret_p);
+	 *   - drivers/acpi/scan.c|2494| <<acpi_bus_scan>> if (ACPI_SUCCESS(acpi_bus_check_add(handle, true, &device)))
+	 *   - drivers/acpi/scan.c|2511| <<acpi_bus_scan>> if (ACPI_SUCCESS(acpi_bus_check_add(handle, false, &device)))
+	 */
 	return acpi_bus_check_add(handle, false, (struct acpi_device **)ret_p);
 }
 
@@ -2374,6 +2538,13 @@ int acpi_bus_scan(acpi_handle handle)
 
 	/* Pass 1: Avoid enumerating devices with missing dependencies. */
 
+	/*
+	 * 在以下使用acpi_bus_check_add():
+	 *   - drivers/acpi/scan.c|2198| <<acpi_bus_check_add_1>> return acpi_bus_check_add(handle, true, (struct acpi_device **)ret_p);
+	 *   - drivers/acpi/scan.c|2204| <<acpi_bus_check_add_2>> return acpi_bus_check_add(handle, false, (struct acpi_device **)ret_p);
+	 *   - drivers/acpi/scan.c|2494| <<acpi_bus_scan>> if (ACPI_SUCCESS(acpi_bus_check_add(handle, true, &device)))
+	 *   - drivers/acpi/scan.c|2511| <<acpi_bus_scan>> if (ACPI_SUCCESS(acpi_bus_check_add(handle, false, &device)))
+	 */
 	if (ACPI_SUCCESS(acpi_bus_check_add(handle, true, &device)))
 		acpi_walk_namespace(ACPI_TYPE_ANY, handle, ACPI_UINT32_MAX,
 				    acpi_bus_check_add_1, NULL, NULL,
@@ -2391,6 +2562,13 @@ int acpi_bus_scan(acpi_handle handle)
 
 	device = NULL;
 
+	/*
+	 * 在以下使用acpi_bus_check_add():
+	 *   - drivers/acpi/scan.c|2198| <<acpi_bus_check_add_1>> return acpi_bus_check_add(handle, true, (struct acpi_device **)ret_p);
+	 *   - drivers/acpi/scan.c|2204| <<acpi_bus_check_add_2>> return acpi_bus_check_add(handle, false, (struct acpi_device **)ret_p);
+	 *   - drivers/acpi/scan.c|2494| <<acpi_bus_scan>> if (ACPI_SUCCESS(acpi_bus_check_add(handle, true, &device)))
+	 *   - drivers/acpi/scan.c|2511| <<acpi_bus_scan>> if (ACPI_SUCCESS(acpi_bus_check_add(handle, false, &device)))
+	 */
 	if (ACPI_SUCCESS(acpi_bus_check_add(handle, false, &device)))
 		acpi_walk_namespace(ACPI_TYPE_ANY, handle, ACPI_UINT32_MAX,
 				    acpi_bus_check_add_2, NULL, NULL,
@@ -2435,11 +2613,22 @@ void acpi_bus_trim(struct acpi_device *adev)
 }
 EXPORT_SYMBOL_GPL(acpi_bus_trim);
 
+/*
+ * 在以下调用acpi_bus_register_early_device():
+ *   - drivers/acpi/ec.c|1835| <<acpi_ec_ecdt_start>> acpi_bus_register_early_device(ACPI_BUS_TYPE_ECDT_EC);
+ */
 int acpi_bus_register_early_device(int type)
 {
 	struct acpi_device *device = NULL;
 	int result;
 
+	/*
+	 * 在以下使用acpi_add_single_object():
+	 *   - drivers/acpi/scan.c|2182| <<acpi_bus_check_add>> acpi_add_single_object(&device, handle, type, !check_dep);
+	 *   - drivers/acpi/scan.c|2560| <<acpi_bus_register_early_device>> result = acpi_add_single_object(&device, NULL, type, false);
+	 *   - drivers/acpi/scan.c|2579| <<acpi_bus_scan_fixed>> result = acpi_add_single_object(&device, NULL, ACPI_BUS_TYPE_POWER_BUTTON, false);
+	 *   - drivers/acpi/scan.c|2595| <<acpi_bus_scan_fixed>> result = acpi_add_single_object(&device, NULL, ACPI_BUS_TYPE_SLEEP_BUTTON, false);
+	 */
 	result = acpi_add_single_object(&device, NULL, type, false);
 	if (result)
 		return result;
@@ -2459,6 +2648,13 @@ static int acpi_bus_scan_fixed(void)
 	if (!(acpi_gbl_FADT.flags & ACPI_FADT_POWER_BUTTON)) {
 		struct acpi_device *device = NULL;
 
+		/*
+		 * 在以下使用acpi_add_single_object():
+		 *   - drivers/acpi/scan.c|2182| <<acpi_bus_check_add>> acpi_add_single_object(&device, handle, type, !check_dep);
+		 *   - drivers/acpi/scan.c|2560| <<acpi_bus_register_early_device>> result = acpi_add_single_object(&device, NULL, type, false);
+		 *   - drivers/acpi/scan.c|2579| <<acpi_bus_scan_fixed>> result = acpi_add_single_object(&device, NULL, ACPI_BUS_TYPE_POWER_BUTTON, false);
+		 *   - drivers/acpi/scan.c|2595| <<acpi_bus_scan_fixed>> result = acpi_add_single_object(&device, NULL, ACPI_BUS_TYPE_SLEEP_BUTTON, false);
+		 */
 		result = acpi_add_single_object(&device, NULL,
 						ACPI_BUS_TYPE_POWER_BUTTON, false);
 		if (result)
@@ -2475,6 +2671,13 @@ static int acpi_bus_scan_fixed(void)
 	if (!(acpi_gbl_FADT.flags & ACPI_FADT_SLEEP_BUTTON)) {
 		struct acpi_device *device = NULL;
 
+		/*
+		 * 在以下使用acpi_add_single_object():
+		 *   - drivers/acpi/scan.c|2182| <<acpi_bus_check_add>> acpi_add_single_object(&device, handle, type, !check_dep);
+		 *   - drivers/acpi/scan.c|2560| <<acpi_bus_register_early_device>> result = acpi_add_single_object(&device, NULL, type, false);
+		 *   - drivers/acpi/scan.c|2579| <<acpi_bus_scan_fixed>> result = acpi_add_single_object(&device, NULL, ACPI_BUS_TYPE_POWER_BUTTON, false);
+		 *   - drivers/acpi/scan.c|2595| <<acpi_bus_scan_fixed>> result = acpi_add_single_object(&device, NULL, ACPI_BUS_TYPE_SLEEP_BUTTON, false);
+		 */
 		result = acpi_add_single_object(&device, NULL,
 						ACPI_BUS_TYPE_SLEEP_BUTTON, false);
 		if (result)
diff --git a/drivers/clocksource/hyperv_timer.c b/drivers/clocksource/hyperv_timer.c
index 66cf3d7468e5..85eb95cfdd9a 100644
--- a/drivers/clocksource/hyperv_timer.c
+++ b/drivers/clocksource/hyperv_timer.c
@@ -373,6 +373,12 @@ struct ms_hyperv_tsc_page *hv_get_tsc_page(void)
 }
 EXPORT_SYMBOL_GPL(hv_get_tsc_page);
 
+/*
+ * 在以下使用read_hv_clock_tsc():
+ *   - drivers/clocksource/hyperv_timer.c|388| <<read_hv_clock_tsc_cs>> return read_hv_clock_tsc();
+ *   - drivers/clocksource/hyperv_timer.c|393| <<read_hv_sched_clock_tsc>> return (read_hv_clock_tsc() - hv_sched_clock_offset) *
+ *   - drivers/clocksource/hyperv_timer.c|535| <<hv_init_tsc_clocksource>> hv_read_reference_counter = read_hv_clock_tsc;
+ */
 static u64 notrace read_hv_clock_tsc(void)
 {
 	u64 current_tick = hv_read_tsc_page(hv_get_tsc_page());
diff --git a/drivers/iommu/intel/irq_remapping.c b/drivers/iommu/intel/irq_remapping.c
index 59981119655d..74f81abe8dd0 100644
--- a/drivers/iommu/intel/irq_remapping.c
+++ b/drivers/iommu/intel/irq_remapping.c
@@ -1218,6 +1218,15 @@ static int intel_ir_set_vcpu_affinity(struct irq_data *data, void *info)
 		irte_pi.p_pst = 1;
 		irte_pi.p_urgent = 0;
 		irte_pi.p_vector = vcpu_pi_info->vector;
+		/*
+		 * 在以下使用vcpu_data->pi_desc_addr:
+		 *   - arch/x86/kvm/svm/avic.c|928| <<get_pi_vcpu_info>> vcpu_info->pi_desc_addr = __sme_set(page_to_phys((*svm)->avic_backing_page));
+		 *   - arch/x86/kvm/svm/avic.c|1035| <<avic_pi_update_irte>> trace_kvm_pi_irte_update(host_irq,... vcpu_info.pi_desc_addr, set);
+		 *   - arch/x86/kvm/vmx/posted_intr.c|337| <<vmx_pi_update_irte>> vcpu_info.pi_desc_addr = __pa(&to_vmx(vcpu)->pi_desc);
+		 *   - arch/x86/kvm/vmx/posted_intr.c|341| <<vmx_pi_update_irte>> trace_kvm_pi_irte_update(host_irq,... vcpu_info.vector, vcpu_info.pi_desc_addr, set);
+		 *   - drivers/iommu/intel/irq_remapping.c|1221| <<intel_ir_set_vcpu_affinity>> irte_pi.pda_l = (vcpu_pi_info->pi_desc_addr >>
+		 *   - drivers/iommu/intel/irq_remapping.c|1223| <<intel_ir_set_vcpu_affinity>> irte_pi.pda_h = (vcpu_pi_info->pi_desc_addr >> 32) &
+		 */
 		irte_pi.pda_l = (vcpu_pi_info->pi_desc_addr >>
 				(32 - PDA_LOW_BIT)) & ~(-1UL << PDA_LOW_BIT);
 		irte_pi.pda_h = (vcpu_pi_info->pi_desc_addr >> 32) &
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/eq.c b/drivers/net/ethernet/mellanox/mlx5/core/eq.c
index 6e3a51046560..8df7db2d768c 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/eq.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eq.c
@@ -1210,6 +1210,12 @@ mlx5_comp_irq_get_affinity_mask(struct mlx5_core_dev *dev, int vector)
 	return NULL;
 }
 
+/*
+ * 在以下调用mlx5_comp_vector_get_cpu():
+ *   - drivers/net/ethernet/mellanox/mlx5/core/en/trap.c|133| <<mlx5e_open_trap>> int cpu = mlx5_comp_vector_get_cpu(priv->mdev, 0);
+ *   - drivers/net/ethernet/mellanox/mlx5/core/en_main.c|2532| <<mlx5e_open_channel>> int cpu = mlx5_comp_vector_get_cpu(priv->mdev, ix);
+ *   - drivers/net/ethernet/mellanox/mlx5/core/en_main.c|2950| <<mlx5e_set_default_xps_cpumasks>> int cpu = mlx5_comp_vector_get_cpu(mdev, irq);
+ */
 int mlx5_comp_vector_get_cpu(struct mlx5_core_dev *dev, int vector)
 {
 	struct cpumask *mask;
diff --git a/drivers/nvme/target/rdma.c b/drivers/nvme/target/rdma.c
index 96d75b2b9fbc..c5eaebc66c66 100644
--- a/drivers/nvme/target/rdma.c
+++ b/drivers/nvme/target/rdma.c
@@ -940,6 +940,16 @@ static u16 nvmet_rdma_map_sgl(struct nvmet_rdma_rsp *rsp)
 	}
 }
 
+/*
+ * nvmet_rdma_execute_command
+ * nvmet_rdma_handle_command
+ * __ib_process_cq
+ * ib_cq_poll_work
+ * process_one_work
+ * worker_thread
+ * kthread
+ * ret_from_fork
+ */
 static bool nvmet_rdma_execute_command(struct nvmet_rdma_rsp *rsp)
 {
 	struct nvmet_rdma_queue *queue = rsp->queue;
@@ -964,6 +974,11 @@ static bool nvmet_rdma_execute_command(struct nvmet_rdma_rsp *rsp)
 	return true;
 }
 
+/*
+ * 在以下使用nvmet_rdma_handle_command():
+ *   - drivers/nvme/target/rdma.c|1052| <<nvmet_rdma_recv_done>> nvmet_rdma_handle_command(queue, rsp);
+ *   - drivers/nvme/target/rdma.c|1624| <<nvmet_rdma_queue_established>> nvmet_rdma_handle_command(queue, cmd);
+ */
 static void nvmet_rdma_handle_command(struct nvmet_rdma_queue *queue,
 		struct nvmet_rdma_rsp *cmd)
 {
diff --git a/drivers/pci/hotplug/acpiphp_glue.c b/drivers/pci/hotplug/acpiphp_glue.c
index f031302ad401..142b19e133c9 100644
--- a/drivers/pci/hotplug/acpiphp_glue.c
+++ b/drivers/pci/hotplug/acpiphp_glue.c
@@ -56,6 +56,10 @@ static void free_bridge(struct kref *kref);
  *
  * Call under acpi_hp_context_lock.
  */
+/*
+ * 在以下使用acpiphp_init_context():
+ *   - drivers/pci/hotplug/acpiphp_glue.c|255| <<acpiphp_add_context>> context = acpiphp_init_context(adev);
+ */
 static struct acpiphp_context *acpiphp_init_context(struct acpi_device *adev)
 {
 	struct acpiphp_context *context;
@@ -117,12 +121,28 @@ static inline void put_bridge(struct acpiphp_bridge *bridge)
 	kref_put(&bridge->ref, free_bridge);
 }
 
+/*
+ * 在以下调用acpiphp_grab_context():
+ *   - drivers/pci/hotplug/acpiphp_glue.c|195| <<acpiphp_post_dock_fixup>> struct acpiphp_context *context = acpiphp_grab_context(adev);
+ *   - drivers/pci/hotplug/acpiphp_glue.c|861| <<acpiphp_hotplug_notify>> context = acpiphp_grab_context(adev);
+ */
 static struct acpiphp_context *acpiphp_grab_context(struct acpi_device *adev)
 {
 	struct acpiphp_context *context;
 
 	acpi_lock_hp_context();
 
+	/*
+	 * struct acpi_device *adev:
+	 * -> struct acpi_hotplug_context *hp;
+	 *
+	 * struct acpiphp_context {
+	 *     struct acpi_hotplug_context hp;
+	 *     struct acpiphp_func func;
+	 *     struct acpiphp_bridge *bridge;
+	 *     unsigned int refcount;
+	 * };
+	 */
 	context = acpiphp_get_context(adev);
 	if (!context)
 		goto unlock;
@@ -223,6 +243,10 @@ static void acpiphp_post_dock_fixup(struct acpi_device *adev)
  * @data: The object's parent ACPIPHP bridge.
  * @rv: Not used.
  */
+/*
+ * 在以下使用acpiphp_add_context():
+ *   - drivers/pci/hotplug/acpiphp_glue.c|916| <<acpiphp_enumerate_slots>> acpiphp_add_context, NULL, bridge, NULL);
+ */
 static acpi_status acpiphp_add_context(acpi_handle handle, u32 lvl, void *data,
 				       void **rv)
 {
@@ -771,10 +795,31 @@ void acpiphp_check_host_bridge(struct acpi_device *adev)
 
 static int acpiphp_disable_and_eject_slot(struct acpiphp_slot *slot);
 
+/*
+ * 在以下调用hotplug_event():
+ *   - drivers/pci/hotplug/acpiphp_glue.c|836| <<acpiphp_hotplug_notify>> hotplug_event(type, context);
+ */
 static void hotplug_event(u32 type, struct acpiphp_context *context)
 {
+	/*
+	 * struct acpiphp_context *context:
+	 * -> struct acpi_hotplug_context hp;
+	 *    -> struct acpi_device *self;
+	 */
 	acpi_handle handle = context->hp.self->handle;
 	struct acpiphp_func *func = &context->func;
+	/*
+	 * struct acpiphp_slot {
+	 *     struct list_head node;
+	 *     struct pci_bus *bus;
+	 *     struct list_head funcs;          one slot may have different
+         *                                      objects (i.e. for each function)
+	 *     struct slot *slot;
+	 *
+	 *     u8              device;         // pci device# 
+	 *     u32             flags;          // see below 
+	 * };
+	 */
 	struct acpiphp_slot *slot = func->slot;
 	struct acpiphp_bridge *bridge;
 
@@ -825,14 +870,34 @@ static void hotplug_event(u32 type, struct acpiphp_context *context)
 		put_bridge(bridge);
 }
 
+/*
+ * [0] acpiphp_hotplug_notify
+ * [0] acpi_device_hotplug
+ * [0] acpi_hotplug_work_fn
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ *
+ * 在以下使用acpiphp_hotplug_notify():
+ *   - drivers/pci/hotplug/acpiphp_glue.c|72| <<acpiphp_init_context>> context->hp.notify = acpiphp_hotplug_notify;
+ */
 static int acpiphp_hotplug_notify(struct acpi_device *adev, u32 type)
 {
 	struct acpiphp_context *context;
 
+	/*
+	 * 在以下调用acpiphp_grab_context():
+	 *   - drivers/pci/hotplug/acpiphp_glue.c|195| <<acpiphp_post_dock_fixup>> struct acpiphp_context *context = acpiphp_grab_context(adev);
+	 *   - drivers/pci/hotplug/acpiphp_glue.c|861| <<acpiphp_hotplug_notify>> context = acpiphp_grab_context(adev);
+	 */
 	context = acpiphp_grab_context(adev);
 	if (!context)
 		return -ENODATA;
 
+	/*
+	 * 只在此处调用
+	 */
 	hotplug_event(type, context);
 	acpiphp_let_context_go(context);
 	return 0;
@@ -845,6 +910,35 @@ static int acpiphp_hotplug_notify(struct acpi_device *adev, u32 type)
  * A "slot" is an object associated with a PCI device number.  All functions
  * (PCI devices) with the same bus and device number belong to the same slot.
  */
+/*
+ * [0] acpiphp_init_context
+ * [0] acpiphp_add_context
+ * [0] acpi_ns_walk_namespace
+ * [0] acpi_walk_namespace
+ * [0] acpiphp_enumerate_slots
+ * [0] acpi_pci_add_bus
+ * [0] pci_alloc_child_bus
+ * [0] pci_scan_bridge_extend
+ * [0] pci_scan_child_bus_extend
+ * [0] acpi_pci_root_create
+ * [0] pci_acpi_scan_root
+ * [0] acpi_pci_root_add
+ * [0] acpi_bus_attach
+ * [0] acpi_bus_attach
+ * [0] acpi_bus_attach
+ * [0] acpi_bus_scan
+ * [0] acpi_scan_init
+ * [0] acpi_init
+ * [0] do_one_initcall
+ * [0] kernel_init_freeable
+ * [0] kernel_init
+ * [0] ret_from_fork
+ *
+ * 在以下调用acpiphp_enumerate_slots():
+ *   - drivers/pci/pci-acpi.c|1170| <<acpi_pci_add_bus>> acpiphp_enumerate_slots(bus);
+ *
+ * acpiphp_enumerate_slots()针对每一个bus调用一次
+ */
 void acpiphp_enumerate_slots(struct pci_bus *bus)
 {
 	struct acpiphp_bridge *bridge;
diff --git a/drivers/pci/pci-acpi.c b/drivers/pci/pci-acpi.c
index 8f4a4fc48efa..3210cfa3389a 100644
--- a/drivers/pci/pci-acpi.c
+++ b/drivers/pci/pci-acpi.c
@@ -935,6 +935,10 @@ static pci_power_t acpi_pci_choose_state(struct pci_dev *pdev)
 
 static struct acpi_device *acpi_pci_find_companion(struct device *dev);
 
+/*
+ * 在以下使用pci_set_acpi_fwnode():
+ *   - drivers/pci/probe.c|1855| <<pci_setup_device>> pci_set_acpi_fwnode(dev);
+ */
 void pci_set_acpi_fwnode(struct pci_dev *dev)
 {
 	if (!dev_fwnode(&dev->dev) && !pci_dev_is_added(dev))
diff --git a/drivers/target/target_core_spc.c b/drivers/target/target_core_spc.c
index 55b3d73c7f59..4000aa49564b 100644
--- a/drivers/target/target_core_spc.c
+++ b/drivers/target/target_core_spc.c
@@ -979,6 +979,10 @@ static void spc_modesense_write_protect(unsigned char *buf, int type)
 	}
 }
 
+/*
+ * 在以下使用spc_modesense_dpofua():
+ *   - drivers/target/target_core_spc.c|1051| <<spc_emulate_modesense>> spc_modesense_dpofua(&buf[length], type);
+ */
 static void spc_modesense_dpofua(unsigned char *buf, int type)
 {
 	switch (type) {
@@ -1014,6 +1018,11 @@ static int spc_modesense_long_blockdesc(unsigned char *buf, u64 blocks, u32 bloc
 	return 17;
 }
 
+/*
+ * 在以下使用spc_emulate_modesense():
+ *   - drivers/target/target_core_spc.c|1336| <<spc_parse_cdb(MODE_SENSE)>> cmd->execute_cmd = spc_emulate_modesense;
+ *   - drivers/target/target_core_spc.c|1340| <<spc_parse_cdb(MODE_SENSE_10)>> cmd->execute_cmd = spc_emulate_modesense;
+ */
 static sense_reason_t spc_emulate_modesense(struct se_cmd *cmd)
 {
 	struct se_device *dev = cmd->se_dev;
diff --git a/drivers/target/target_core_transport.c b/drivers/target/target_core_transport.c
index 65411f57cfd2..1883fe642fa7 100644
--- a/drivers/target/target_core_transport.c
+++ b/drivers/target/target_core_transport.c
@@ -3652,6 +3652,12 @@ int transport_generic_handle_tmr(
 }
 EXPORT_SYMBOL(transport_generic_handle_tmr);
 
+/*
+ * 在以下使用target_check_wce():
+ *   - drivers/target/target_core_spc.c|499| <<spc_emulate_evpd_86>> if (target_check_wce(dev))
+ *   - drivers/target/target_core_spc.c|935| <<spc_modesense_caching>> if (target_check_wce(dev))
+ *   - drivers/target/target_core_transport.c|3671| <<target_check_fua>> return target_check_wce(dev) && dev->dev_attrib.emulate_fua_write > 0;
+ */
 bool
 target_check_wce(struct se_device *dev)
 {
@@ -3665,8 +3671,22 @@ target_check_wce(struct se_device *dev)
 	return wce;
 }
 
+/*
+ * 在以下使用target_check_fua():
+ *   - drivers/target/target_core_sbc.c|808| <<sbc_check_dpofua>> if (!target_check_fua(dev)) {
+ *   - drivers/target/target_core_sbc.c|815| <<sbc_check_dpofua>> if (!target_check_fua(dev)) {
+ *   - drivers/target/target_core_spc.c|1050| <<spc_emulate_modesense>> if (target_check_fua(dev))
+ */
 bool
 target_check_fua(struct se_device *dev)
 {
+	/*
+	 * 在以下使用se_dev_attrib->emulate_fua_write:
+	 *   - drivers/target/target_core_configfs.c|520| <<global>> DEF_CONFIGFS_ATTRIB_SHOW(emulate_fua_write);
+	 *   - drivers/target/target_core_configfs.c|586| <<global>> DEF_CONFIGFS_ATTRIB_STORE_BOOL(emulate_fua_write);
+	 *   - drivers/target/target_core_configfs.c|1179| <<global>> CONFIGFS_ATTR(, emulate_fua_write);
+	 *   - drivers/target/target_core_device.c|784| <<target_alloc_device>> dev->dev_attrib.emulate_fua_write = 1;
+	 *   - drivers/target/target_core_transport.c|3671| <<target_check_fua>> return target_check_wce(dev) && dev->dev_attrib.emulate_fua_write > 0;
+	 */
 	return target_check_wce(dev) && dev->dev_attrib.emulate_fua_write > 0;
 }
diff --git a/drivers/vfio/pci/vfio_pci_intrs.c b/drivers/vfio/pci/vfio_pci_intrs.c
index f20512c413f7..bc0305a03534 100644
--- a/drivers/vfio/pci/vfio_pci_intrs.c
+++ b/drivers/vfio/pci/vfio_pci_intrs.c
@@ -398,6 +398,12 @@ static int vfio_msi_set_vector_signal(struct vfio_pci_core_device *vdev,
 	return 0;
 }
 
+/*
+ * 在以下使用vfio_msi_set_block():
+ *   - drivers/vfio/pci/vfio_pci_intrs.c|433| <<vfio_msi_disable>> vfio_msi_set_block(vdev, 0, vdev->num_ctx, NULL, msix);
+ *   - drivers/vfio/pci/vfio_pci_intrs.c|568| <<vfio_pci_set_msi_trigger>> return vfio_msi_set_block(vdev, start, count, fds, msix);
+ *   - drivers/vfio/pci/vfio_pci_intrs.c|575| <<vfio_pci_set_msi_trigger>> ret = vfio_msi_set_block(vdev, start, count, fds, msix);
+ */
 static int vfio_msi_set_block(struct vfio_pci_core_device *vdev, unsigned start,
 			      unsigned count, int32_t *fds, bool msix)
 {
@@ -545,6 +551,10 @@ static int vfio_pci_set_intx_trigger(struct vfio_pci_core_device *vdev,
 	return 0;
 }
 
+/*
+ * 处理VFIO_PCI_MSI_IRQ_INDEX和VFIO_PCI_MSIX_IRQ_INDEX:
+ *   - drivers/vfio/pci/vfio_pci_intrs.c|706| <<vfio_pci_set_irqs_ioctl>> func = vfio_pci_set_msi_trigger;
+ */
 static int vfio_pci_set_msi_trigger(struct vfio_pci_core_device *vdev,
 				    unsigned index, unsigned start,
 				    unsigned count, uint32_t flags, void *data)
diff --git a/include/clocksource/hyperv_timer.h b/include/clocksource/hyperv_timer.h
index 80fdfb89de7f..73cb3060b716 100644
--- a/include/clocksource/hyperv_timer.h
+++ b/include/clocksource/hyperv_timer.h
@@ -38,6 +38,11 @@ extern struct ms_hyperv_tsc_page *hv_get_tsc_page(void);
 
 extern void hv_adj_sched_clock_offset(u64 offset);
 
+/*
+ * 在以下使用hv_read_tsc_page_tsc():
+ *   - arch/x86/kvm/x86.c|3507| <<vgettsc>> tsc_pg_val = hv_read_tsc_page_tsc(hv_get_tsc_page(),
+ *   - include/clocksource/hyperv_timer.h|93| <<hv_read_tsc_page>> return hv_read_tsc_page_tsc(tsc_pg, &cur_tsc);
+ */
 static inline notrace u64
 hv_read_tsc_page_tsc(const struct ms_hyperv_tsc_page *tsc_pg, u64 *cur_tsc)
 {
@@ -72,6 +77,9 @@ hv_read_tsc_page_tsc(const struct ms_hyperv_tsc_page *tsc_pg, u64 *cur_tsc)
 
 		scale = READ_ONCE(tsc_pg->tsc_scale);
 		offset = READ_ONCE(tsc_pg->tsc_offset);
+		/*
+		 * rdtsc_ordered()
+		 */
 		*cur_tsc = hv_get_raw_timer();
 
 		/*
@@ -85,6 +93,10 @@ hv_read_tsc_page_tsc(const struct ms_hyperv_tsc_page *tsc_pg, u64 *cur_tsc)
 	return mul_u64_u64_shr(*cur_tsc, scale, 64) + offset;
 }
 
+/*
+ * 在以下使用hv_read_tsc_page():
+ *   - drivers/clocksource/hyperv_timer.c|378| <<read_hv_clock_tsc>> u64 current_tick = hv_read_tsc_page(hv_get_tsc_page());
+ */
 static inline notrace u64
 hv_read_tsc_page(const struct ms_hyperv_tsc_page *tsc_pg)
 {
diff --git a/include/linux/kvm_host.h b/include/linux/kvm_host.h
index d6b37eef1b32..68799f66f3ec 100644
--- a/include/linux/kvm_host.h
+++ b/include/linux/kvm_host.h
@@ -300,6 +300,12 @@ struct kvm_mmio_fragment {
 struct kvm_vcpu {
 	struct kvm *kvm;
 #ifdef CONFIG_PREEMPT_NOTIFIERS
+	/*
+	 * 在以下使用kvm_vcpu->preempt_notifier:
+	 *   - virt/kvm/kvm_main.c|208| <<vcpu_load>> preempt_notifier_register(&vcpu->preempt_notifier);
+	 *   - virt/kvm/kvm_main.c|218| <<vcpu_put>> preempt_notifier_unregister(&vcpu->preempt_notifier);
+	 *   - virt/kvm/kvm_main.c|462| <<kvm_vcpu_init>> preempt_notifier_init(&vcpu->preempt_notifier, &kvm_preempt_ops);
+	 */
 	struct preempt_notifier preempt_notifier;
 #endif
 	int cpu;
@@ -732,6 +738,18 @@ struct kvm {
 	/*
 	 * Update side is protected by irq_lock.
 	 */
+	/*
+	 * 在以下使用kvm->irq_routing:
+	 *   - arch/x86/kvm/hyperv.c|544| <<kvm_hv_irq_routing_update>> irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
+	 *   - arch/x86/kvm/irq_comm.c|538| <<kvm_scan_ioapic_routes>> table = srcu_dereference(kvm->irq_routing, &kvm->irq_srcu);
+	 *   - arch/x86/kvm/svm/avic.c|958| <<avic_pi_update_irte>> irq_rt = srcu_dereference(kvm->irq_routing, &kvm->irq_srcu);
+	 *   - arch/x86/kvm/vmx/posted_intr.c|282| <<vmx_pi_update_irte>> irq_rt = srcu_dereference(kvm->irq_routing, &kvm->irq_srcu);
+	 *   - virt/kvm/irqchip.c|29| <<kvm_irq_map_gsi>> irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
+	 *   - virt/kvm/irqchip.c|49| <<kvm_irq_map_chip_pin>> irq_rt = srcu_dereference(kvm->irq_routing, &kvm->irq_srcu);
+	 *   - virt/kvm/irqchip.c|145| <<kvm_free_irq_routing>> struct kvm_irq_routing_table *rt = rcu_access_pointer(kvm->irq_routing);
+	 *   - virt/kvm/irqchip.c|276| <<kvm_set_irq_routing>> old = rcu_dereference_protected(kvm->irq_routing, 1);
+	 *   - virt/kvm/irqchip.c|277| <<kvm_set_irq_routing>> rcu_assign_pointer(kvm->irq_routing, new);
+	 */
 	struct kvm_irq_routing_table __rcu *irq_routing;
 #endif
 #ifdef CONFIG_HAVE_KVM_IRQFD
@@ -753,6 +771,23 @@ struct kvm {
 	struct srcu_struct irq_srcu;
 	pid_t userspace_pid;
 	unsigned int max_halt_poll_ns;
+	/*
+	 * 在以下使用kvm->dirty_ring_size:
+	 *   - arch/x86/kvm/x86.c|10381| <<vcpu_enter_guest>> if (unlikely(vcpu->kvm->dirty_ring_size &&
+	 *   - virt/kvm/kvm_main.c|1563| <<kvm_prepare_memory_region>> else if (!kvm->dirty_ring_size) {
+	 *   - virt/kvm/kvm_main.c|2007| <<kvm_get_dirty_log>> if (kvm->dirty_ring_size)
+	 *   - virt/kvm/kvm_main.c|2072| <<kvm_get_dirty_log_protect>> if (kvm->dirty_ring_size)
+	 *   - virt/kvm/kvm_main.c|2184| <<kvm_clear_dirty_log_protect>> if (kvm->dirty_ring_size)
+	 *   - virt/kvm/kvm_main.c|3302| <<mark_page_dirty_in_slot>> if (kvm->dirty_ring_size)
+	 *   - virt/kvm/kvm_main.c|3706| <<kvm_page_in_dirty_ring>> return (pgoff >= KVM_DIRTY_LOG_PAGE_OFFSET)
+	 *           && (pgoff < KVM_DIRTY_LOG_PAGE_OFFSET + kvm->dirty_ring_size / PAGE_SIZE);
+	 *   - virt/kvm/kvm_main.c|3849| <<kvm_vm_ioctl_create_vcpu>> if (kvm->dirty_ring_size) {
+	 *   - virt/kvm/kvm_main.c|3851| <<kvm_vm_ioctl_create_vcpu>> r = kvm_dirty_ring_alloc(&vcpu->dirty_ring, 
+	 *           id, kvm->dirty_ring_size);
+	 *   - virt/kvm/kvm_main.c|4459| <<kvm_vm_ioctl_enable_dirty_log_ring>> if (kvm->dirty_ring_size)
+	 *   - virt/kvm/kvm_main.c|4468| <<kvm_vm_ioctl_enable_dirty_log_ring>> kvm->dirty_ring_size = size;
+	 *   - virt/kvm/kvm_main.c|4482| <<kvm_vm_ioctl_reset_dirty_pages>> if (!kvm->dirty_ring_size)
+	 */
 	u32 dirty_ring_size;
 	bool vm_bugged;
 	bool vm_dead;
@@ -842,6 +877,9 @@ static inline struct kvm_vcpu *kvm_get_vcpu(struct kvm *kvm, int i)
 	return kvm->vcpus[i];
 }
 
+/*
+ * 在kvm_vm_ioctl_create_vcpu()增加kvm->online_vcpus.
+ */
 #define kvm_for_each_vcpu(idx, vcpup, kvm) \
 	for (idx = 0; \
 	     idx < atomic_read(&kvm->online_vcpus) && \
@@ -1877,6 +1915,18 @@ static inline void kvm_make_request(int req, struct kvm_vcpu *vcpu)
 	set_bit(req & KVM_REQUEST_MASK, (void *)&vcpu->requests);
 }
 
+/*
+ * 在以下调用kvm_request_pending():
+ *   - arch/arm64/kvm/arm.c|682| <<check_vcpu_requests>> if (kvm_request_pending(vcpu)) {
+ *   - arch/arm64/kvm/arm.c|754| <<kvm_vcpu_exit_request>> return kvm_request_pending(vcpu) ||
+ *   - arch/mips/kvm/vz.c|2433| <<kvm_vz_check_requests>> if (!kvm_request_pending(vcpu))
+ *   - arch/powerpc/kvm/booke.c|714| <<kvmppc_core_prepare_to_enter>> if (kvm_request_pending(vcpu)) {
+ *   - arch/powerpc/kvm/powerpc.c|51| <<kvm_arch_vcpu_runnable>> return !!(v->arch.pending_exceptions) || kvm_request_pending(v);
+ *   - arch/powerpc/kvm/powerpc.c|113| <<kvmppc_prepare_to_enter>> if (kvm_request_pending(vcpu)) {
+ *   - arch/s390/kvm/kvm-s390.c|3824| <<kvm_s390_handle_requests>> if (!kvm_request_pending(vcpu))
+ *   - arch/x86/kvm/x86.c|2116| <<kvm_vcpu_exit_request>> return vcpu->mode == EXITING_GUEST_MODE || kvm_request_pending(vcpu) ||
+ *   - arch/x86/kvm/x86.c|10389| <<vcpu_enter_guest>> if (kvm_request_pending(vcpu)) {
+ */
 static inline bool kvm_request_pending(struct kvm_vcpu *vcpu)
 {
 	return READ_ONCE(vcpu->requests);
diff --git a/include/linux/sched.h b/include/linux/sched.h
index 7a9e7c52d323..b1e80c66ebf6 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -938,6 +938,12 @@ struct task_struct {
 	UEK_KABI_RENAME(unsigned in_eventfd_signal, unsigned in_eventfd):1;
 #endif
 #ifdef	CONFIG_CPU_SUP_INTEL
+	/*
+	 * 在以下使用task_struct->reported_split_lock:
+	 *   - arch/x86/kernel/cpu/intel.c|1373| <<split_lock_warn>> if (!current->reported_split_lock)
+	 *   - arch/x86/kernel/cpu/intel.c|1376| <<split_lock_warn>> current->reported_split_lock = 1;
+	 *   - kernel/fork.c|989| <<dup_task_struct>> tsk->reported_split_lock = 0;
+	 */
 	UEK_KABI_FILL_HOLE(unsigned reported_split_lock:1)
 #endif
 
diff --git a/include/target/target_core_base.h b/include/target/target_core_base.h
index a4e8a6393716..ad7c3a039fac 100644
--- a/include/target/target_core_base.h
+++ b/include/target/target_core_base.h
@@ -685,6 +685,14 @@ struct se_dev_entry {
 struct se_dev_attrib {
 	bool		emulate_model_alias;
 	bool		emulate_dpo;		/* deprecated */
+	/*
+	 * 在以下使用se_dev_attrib->emulate_fua_write:
+	 *   - drivers/target/target_core_configfs.c|520| <<global>> DEF_CONFIGFS_ATTRIB_SHOW(emulate_fua_write);
+	 *   - drivers/target/target_core_configfs.c|586| <<global>> DEF_CONFIGFS_ATTRIB_STORE_BOOL(emulate_fua_write);
+	 *   - drivers/target/target_core_configfs.c|1179| <<global>> CONFIGFS_ATTR(, emulate_fua_write);
+	 *   - drivers/target/target_core_device.c|784| <<target_alloc_device>> dev->dev_attrib.emulate_fua_write = 1;
+	 *   - drivers/target/target_core_transport.c|3671| <<target_check_fua>> return target_check_wce(dev) && dev->dev_attrib.emulate_fua_write > 0;
+	 */
 	bool		emulate_fua_write;
 	bool		emulate_fua_read;	/* deprecated */
 	bool		emulate_write_cache;
diff --git a/virt/kvm/eventfd.c b/virt/kvm/eventfd.c
index 37e3a49f4e76..c79a011a4cce 100644
--- a/virt/kvm/eventfd.c
+++ b/virt/kvm/eventfd.c
@@ -181,12 +181,41 @@ int __attribute__((weak)) kvm_arch_set_irq_inatomic(
 /*
  * Called with wqh->lock held and interrupts disabled
  */
+/*
+ * 在以下使用irqfd_wakeup():
+ *   - virt/kvm/eventfd.c|383| <<kvm_irqfd_assign>> init_waitqueue_func_entry(&irqfd->wait, irqfd_wakeup);
+ */
 static int
 irqfd_wakeup(wait_queue_entry_t *wait, unsigned mode, int sync, void *key)
 {
 	struct kvm_kernel_irqfd *irqfd =
 		container_of(wait, struct kvm_kernel_irqfd, wait);
 	__poll_t flags = key_to_poll(key);
+	/*
+	 * 609 struct kvm_kernel_irq_routing_entry {
+	 * 610         u32 gsi;
+	 * 611         u32 type;
+	 * 612         int (*set)(struct kvm_kernel_irq_routing_entry *e,
+	 * 613                    struct kvm *kvm, int irq_source_id, int level,
+	 * 614                    bool line_status);
+	 * 615         union {
+	 * 616                 struct {
+	 * 617                         unsigned irqchip;
+	 * 618                         unsigned pin;
+	 * 619                 } irqchip;
+	 * 620                 struct {
+	 * 621                         u32 address_lo;
+	 * 622                         u32 address_hi;
+	 * 623                         u32 data;
+	 * 624                         u32 flags;
+	 * 625                         u32 devid;
+	 * 626                 } msi;
+	 * 627                 struct kvm_s390_adapter_int adapter;
+	 * 628                 struct kvm_hv_sint hv_sint;
+	 * 629         };
+	 * 630         struct hlist_node link;
+	 * 631 };
+	 */
 	struct kvm_kernel_irq_routing_entry irq;
 	struct kvm *kvm = irqfd->kvm;
 	unsigned seq;
@@ -338,6 +367,9 @@ kvm_irqfd_assign(struct kvm *kvm, struct kvm_irqfd *args)
 
 		mutex_lock(&kvm->irqfds.resampler_lock);
 
+		/*
+		 * 似乎resampler_list也基本不怎么用
+		 */
 		list_for_each_entry(resampler,
 				    &kvm->irqfds.resampler_list, link) {
 			if (resampler->notifier.gsi == irqfd->gsi) {
@@ -409,6 +441,9 @@ kvm_irqfd_assign(struct kvm *kvm, struct kvm_irqfd *args)
 		schedule_work(&irqfd->inject);
 
 #ifdef CONFIG_HAVE_KVM_IRQ_BYPASS
+	/*
+	 * 只在这里调用kvm_arch_has_irq_bypass()
+	 */
 	if (kvm_arch_has_irq_bypass()) {
 		irqfd->consumer.token = (void *)irqfd->eventfd;
 		irqfd->consumer.add_producer = kvm_arch_irq_bypass_add_producer;
@@ -448,6 +483,10 @@ kvm_irqfd_assign(struct kvm *kvm, struct kvm_irqfd *args)
 	return ret;
 }
 
+/*
+ * 在以下使用kvm_irq_has_notifier():
+ *   - arch/x86/kvm/ioapic.c|448| <<kvm_ioapic_scan_entry>> kvm_irq_has_notifier(ioapic->kvm, KVM_IRQCHIP_IOAPIC, index) ||
+ */
 bool kvm_irq_has_notifier(struct kvm *kvm, unsigned irqchip, unsigned pin)
 {
 	struct kvm_irq_ack_notifier *kian;
@@ -455,6 +494,9 @@ bool kvm_irq_has_notifier(struct kvm *kvm, unsigned irqchip, unsigned pin)
 
 	idx = srcu_read_lock(&kvm->irq_srcu);
 	gsi = kvm_irq_map_chip_pin(kvm, irqchip, pin);
+	/*
+	 * 似乎irq_ack_notifier_list不怎么用
+	 */
 	if (gsi != -1)
 		hlist_for_each_entry_srcu(kian, &kvm->irq_ack_notifier_list,
 					  link, srcu_read_lock_held(&kvm->irq_srcu))
@@ -828,6 +870,30 @@ static int kvm_assign_ioeventfd_idx(struct kvm *kvm,
 
 	kvm_iodevice_init(&p->dev, &ioeventfd_ops);
 
+	/*
+	 * 在以下使用kvm_io_bus_register_dev():
+	 *   - arch/arm64/kvm/vgic/vgic-its.c|1840| <<vgic_register_its_iodev>> ret = kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS,
+	 *                    iodev->base_addr, KVM_VGIC_V3_ITS_SIZE, &iodev->dev);
+	 *   - arch/arm64/kvm/vgic/vgic-mmio-v3.c|743| <<vgic_register_redist_iodev>> ret = kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS,
+	 *                    rd_base, 2 * SZ_64K, &rd_dev->dev);
+	 *   - arch/arm64/kvm/vgic/vgic-mmio.c|1096| <<vgic_register_dist_iodev>> ret = kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS,
+	 *                    dist_base_address, len, &io_device->dev);
+	 *   - arch/mips/kvm/loongson_ipi.c|209| <<kvm_init_loongson_ipi>> kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS, addr, 0x400, device);
+	 *   - arch/powerpc/kvm/mpic.c|1449| <<map_mmio>> kvm_io_bus_register_dev(opp->kvm, KVM_MMIO_BUS,
+	 *                    opp->reg_base, OPENPIC_REG_SIZE, &opp->mmio);
+	 *   - arch/x86/kvm/i8254.c|705| <<kvm_create_pit>> ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS,
+	 *                    KVM_PIT_BASE_ADDRESS, KVM_PIT_MEM_LENGTH, &pit->dev);
+	 *   - arch/x86/kvm/i8254.c|712| <<kvm_create_pit>> ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS,
+	 *                    KVM_SPEAKER_BASE_ADDRESS, 4, &pit->speaker_dev);
+	 *   - arch/x86/kvm/i8259.c|607| <<kvm_pic_init>> ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS, 0x20, 2, &s->dev_master);
+	 *   - arch/x86/kvm/i8259.c|612| <<kvm_pic_init>> ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS, 0xa0, 2, &s->dev_slave);
+	 *   - arch/x86/kvm/i8259.c|616| <<kvm_pic_init>> ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS, 0x4d0, 2, &s->dev_elcr);
+	 *   - arch/x86/kvm/ioapic.c|1014| <<kvm_ioapic_init>> ret = kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS,
+	 *                    ioapic->base_address, IOAPIC_MEM_LENGTH, &ioapic->dev);
+	 *   - virt/kvm/coalesced_mmio.c|156| <<kvm_vm_ioctl_register_coalesced_mmio>> ret = kvm_io_bus_register_dev(kvm,
+	 *                    zone->pio ? KVM_PIO_BUS : KVM_MMIO_BUS, zone->addr, zone->size, &dev->dev);
+	 *   - virt/kvm/eventfd.c|841| <<kvm_assign_ioeventfd_idx>> ret = kvm_io_bus_register_dev(kvm, bus_idx, p->addr, p->length, &p->dev);
+	 */
 	ret = kvm_io_bus_register_dev(kvm, bus_idx, p->addr, p->length,
 				      &p->dev);
 	if (ret < 0)
diff --git a/virt/kvm/irqchip.c b/virt/kvm/irqchip.c
index 79dcd4cd5c60..ba8261c4d898 100644
--- a/virt/kvm/irqchip.c
+++ b/virt/kvm/irqchip.c
@@ -50,6 +50,10 @@ int kvm_irq_map_chip_pin(struct kvm *kvm, unsigned irqchip, unsigned pin)
 	return irq_rt->chip[irqchip][pin];
 }
 
+/*
+ * 在以下使用kvm_send_userspace_msi():
+ *   - virt/kvm/kvm_main.c|4828| <<kvm_vm_ioctl(KVM_SIGNAL_MSI)>> r = kvm_send_userspace_msi(kvm, &msi);
+ */
 int kvm_send_userspace_msi(struct kvm *kvm, struct kvm_msi *msi)
 {
 	struct kvm_kernel_irq_routing_entry route;
@@ -66,6 +70,17 @@ int kvm_send_userspace_msi(struct kvm *kvm, struct kvm_msi *msi)
 	return kvm_set_msi(&route, kvm, KVM_USERSPACE_IRQ_SOURCE_ID, 1, false);
 }
 
+/*
+ * 在以下调用kvm_set_irq():
+ *   - arch/x86/kvm/i8254.c|251| <<pit_do_work>> kvm_set_irq(kvm, pit->irq_source_id, 0, 1, false);
+ *   - arch/x86/kvm/i8254.c|252| <<pit_do_work>> kvm_set_irq(kvm, pit->irq_source_id, 0, 0, false);
+ *   - arch/x86/kvm/x86.c|6014| <<kvm_vm_ioctl_irq_line>> irq_event->status = kvm_set_irq(kvm, KVM_USERSPACE_IRQ_SOURCE_ID, irq_event->irq, irq_event->level, line_status);
+ *   - virt/kvm/eventfd.c|49| <<irqfd_inject>> kvm_set_irq(kvm, KVM_USERSPACE_IRQ_SOURCE_ID, irqfd->gsi, 1, false);
+ *   - virt/kvm/eventfd.c|51| <<irqfd_inject>> kvm_set_irq(kvm, KVM_USERSPACE_IRQ_SOURCE_ID, irqfd->gsi, 0, false);
+ *   - virt/kvm/eventfd.c|54| <<irqfd_inject>> kvm_set_irq(kvm, KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID, irqfd->gsi, 1, false);
+ *   - virt/kvm/eventfd.c|75| <<irqfd_resampler_ack>> kvm_set_irq(kvm, KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID, resampler->notifier.gsi, 0, false);
+ *   - virt/kvm/eventfd.c|100| <<irqfd_resampler_shutdown>> kvm_set_irq(kvm, KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID, resampler->notifier.gsi, 0, false);
+ */
 /*
  * Return value:
  *  < 0   Interrupt was ignored (masked or not delivered for other reasons)
@@ -75,6 +90,12 @@ int kvm_send_userspace_msi(struct kvm *kvm, struct kvm_msi *msi)
 int kvm_set_irq(struct kvm *kvm, int irq_source_id, u32 irq, int level,
 		bool line_status)
 {
+	/*
+	 * #define KVM_IRQCHIP_PIC_MASTER   0
+	 * #define KVM_IRQCHIP_PIC_SLAVE    1
+	 * #define KVM_IRQCHIP_IOAPIC       2
+	 * #define KVM_NR_IRQCHIPS          3
+	 */
 	struct kvm_kernel_irq_routing_entry irq_set[KVM_NR_IRQCHIPS];
 	int ret = -1, i, idx;
 
@@ -170,6 +191,41 @@ bool __weak kvm_arch_can_set_irq_routing(struct kvm *kvm)
 	return true;
 }
 
+/*
+ * 265 把irq从CPU=5换到CPU=6上.
+ * 266
+ * 267        CPU 5/KVM-51857   [011] ..... 435912.873065: vfio_pci_set_msi_trigger <-vfio_pci_core_ioctl
+ * 268        CPU 5/KVM-51857   [011] ..... 435912.873068: vfio_msi_set_vector_signal <-vfio_msi_set_block
+ * 269        CPU 5/KVM-51857   [011] ..... 435912.873069: irq_bypass_unregister_producer <-vfio_msi_set_vector_signal
+ * 270        CPU 5/KVM-51857   [011] ..... 435912.873070: kvm_arch_irq_bypass_del_producer <-__disconnect
+ * 271        CPU 5/KVM-51857   [011] ..... 435912.873070: vmx_pi_update_irte <-kvm_arch_irq_bypass_del_producer
+ * 272        CPU 5/KVM-51857   [011] ..... 435912.873102: irq_bypass_register_producer <-vfio_msi_set_vector_signal
+ * 273
+ * 274        CPU 5/KVM-51857   [011] ..... 435912.873255: kvm_set_irq_routing <-kvm_vm_ioctl
+ * 275        CPU 5/KVM-51857   [011] ..... 435912.873263: kvm_irq_routing_update <-kvm_set_irq_routing
+ * 276        CPU 5/KVM-51857   [011] d.... 435912.873263: irqfd_update <-kvm_irq_routing_update
+ * 277        CPU 5/KVM-51857   [011] d.... 435912.873264: kvm_arch_update_irqfd_routing <-kvm_irq_routing_update
+ * 278        CPU 5/KVM-51857   [011] d.... 435912.873264: vmx_pi_update_irte <-kvm_irq_routing_update
+ * 279        CPU 5/KVM-51857   [011] d.... 435912.873266: irqfd_update <-kvm_irq_routing_update
+ * 280        CPU 5/KVM-51857   [011] d.... 435912.873266: irqfd_update <-kvm_irq_routing_update
+ * 281        CPU 5/KVM-51857   [011] d.... 435912.873266: kvm_arch_update_irqfd_routing <-kvm_irq_routing_update
+ * 282        CPU 5/KVM-51857   [011] d.... 435912.873266: vmx_pi_update_irte <-kvm_irq_routing_update
+ * 283
+ * 284        CPU 5/KVM-51857   [011] ..... 435912.873290: vfio_pci_set_msi_trigger <-vfio_pci_core_ioctl
+ * 285        CPU 5/KVM-51857   [011] ..... 435912.873291: vfio_msi_set_vector_signal <-vfio_msi_set_block
+ * 286        CPU 5/KVM-51857   [011] ..... 435912.873291: irq_bypass_unregister_producer <-vfio_msi_set_vector_signal
+ * 287        CPU 5/KVM-51857   [011] ..... 435912.873311: irq_bypass_register_producer <-vfio_msi_set_vector_signal
+ * 288        CPU 5/KVM-51857   [011] ..... 435912.873312: kvm_arch_irq_bypass_add_producer <-__connect
+ * 289        CPU 5/KVM-51857   [011] ..... 435912.873312: vmx_pi_update_irte <-kvm_arch_irq_bypass_add_producer
+ *
+ * Add或者Del vCPU会调用:
+ *
+ * kvm_set_irq_routing
+ * kvm_vm_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ */
 int kvm_set_irq_routing(struct kvm *kvm,
 			const struct kvm_irq_routing_entry *ue,
 			unsigned nr,
diff --git a/virt/kvm/kvm_main.c b/virt/kvm/kvm_main.c
index 36896443375a..7cbf367dcd08 100644
--- a/virt/kvm/kvm_main.c
+++ b/virt/kvm/kvm_main.c
@@ -109,6 +109,13 @@ static atomic_t hardware_enable_failed;
 
 static struct kmem_cache *kvm_vcpu_cache;
 
+/*
+ * 在以下使用kvm_preempt_ops:
+ *   - virt/kvm/kvm_main.c|112| <<global>> static __read_mostly struct preempt_ops kvm_preempt_ops;
+ *   - virt/kvm/kvm_main.c|462| <<kvm_vcpu_init>> preempt_notifier_init(&vcpu->preempt_notifier, &kvm_preempt_ops);
+ *   - virt/kvm/kvm_main.c|5854| <<kvm_init>> kvm_preempt_ops.sched_in = kvm_sched_in;
+ *   - virt/kvm/kvm_main.c|5855| <<kvm_init>> kvm_preempt_ops.sched_out = kvm_sched_out;
+ */
 static __read_mostly struct preempt_ops kvm_preempt_ops;
 static DEFINE_PER_CPU(struct kvm_vcpu *, kvm_running_vcpu);
 
@@ -205,6 +212,18 @@ void vcpu_load(struct kvm_vcpu *vcpu)
 	int cpu = get_cpu();
 
 	__this_cpu_write(kvm_running_vcpu, vcpu);
+	/*
+	 * 在以下使用kvm_preempt_ops:
+	 *   - virt/kvm/kvm_main.c|112| <<global>> static __read_mostly struct preempt_ops kvm_preempt_ops;
+	 *   - virt/kvm/kvm_main.c|462| <<kvm_vcpu_init>> preempt_notifier_init(&vcpu->preempt_notifier, &kvm_preempt_ops);
+	 *   - virt/kvm/kvm_main.c|5854| <<kvm_init>> kvm_preempt_ops.sched_in = kvm_sched_in;
+	 *   - virt/kvm/kvm_main.c|5855| <<kvm_init>> kvm_preempt_ops.sched_out = kvm_sched_out;
+	 *
+	 * 在以下使用kvm_vcpu->preempt_notifier:
+	 *   - virt/kvm/kvm_main.c|208| <<vcpu_load>> preempt_notifier_register(&vcpu->preempt_notifier);
+	 *   - virt/kvm/kvm_main.c|218| <<vcpu_put>> preempt_notifier_unregister(&vcpu->preempt_notifier);
+	 *   - virt/kvm/kvm_main.c|462| <<kvm_vcpu_init>> preempt_notifier_init(&vcpu->preempt_notifier, &kvm_preempt_ops);
+	 */
 	preempt_notifier_register(&vcpu->preempt_notifier);
 	kvm_arch_vcpu_load(vcpu, cpu);
 	put_cpu();
@@ -215,6 +234,18 @@ void vcpu_put(struct kvm_vcpu *vcpu)
 {
 	preempt_disable();
 	kvm_arch_vcpu_put(vcpu);
+	/*
+	 * 在以下使用kvm_preempt_ops:
+	 *   - virt/kvm/kvm_main.c|112| <<global>> static __read_mostly struct preempt_ops kvm_preempt_ops;
+	 *   - virt/kvm/kvm_main.c|462| <<kvm_vcpu_init>> preempt_notifier_init(&vcpu->preempt_notifier, &kvm_preempt_ops);
+	 *   - virt/kvm/kvm_main.c|5854| <<kvm_init>> kvm_preempt_ops.sched_in = kvm_sched_in;
+	 *   - virt/kvm/kvm_main.c|5855| <<kvm_init>> kvm_preempt_ops.sched_out = kvm_sched_out;
+	 *
+	 * 在以下使用kvm_vcpu->preempt_notifier:
+	 *   - virt/kvm/kvm_main.c|208| <<vcpu_load>> preempt_notifier_register(&vcpu->preempt_notifier);
+	 *   - virt/kvm/kvm_main.c|218| <<vcpu_put>> preempt_notifier_unregister(&vcpu->preempt_notifier);
+	 *   - virt/kvm/kvm_main.c|462| <<kvm_vcpu_init>> preempt_notifier_init(&vcpu->preempt_notifier, &kvm_preempt_ops);
+	 */
 	preempt_notifier_unregister(&vcpu->preempt_notifier);
 	__this_cpu_write(kvm_running_vcpu, NULL);
 	preempt_enable();
@@ -438,6 +469,10 @@ void *kvm_mmu_memory_cache_alloc(struct kvm_mmu_memory_cache *mc)
 }
 #endif
 
+/*
+ * 在以下调用kvm_vcpu_init():
+ *   - virt/kvm/kvm_main.c|3835| <<kvm_vm_ioctl_create_vcpu>> kvm_vcpu_init(vcpu, kvm, id);
+ */
 static void kvm_vcpu_init(struct kvm_vcpu *vcpu, struct kvm *kvm, unsigned id)
 {
 	mutex_init(&vcpu->mutex);
@@ -455,6 +490,18 @@ static void kvm_vcpu_init(struct kvm_vcpu *vcpu, struct kvm *kvm, unsigned id)
 	kvm_vcpu_set_dy_eligible(vcpu, false);
 	vcpu->preempted = false;
 	vcpu->ready = false;
+	/*
+	 * 在以下使用kvm_preempt_ops:
+	 *   - virt/kvm/kvm_main.c|112| <<global>> static __read_mostly struct preempt_ops kvm_preempt_ops;
+	 *   - virt/kvm/kvm_main.c|462| <<kvm_vcpu_init>> preempt_notifier_init(&vcpu->preempt_notifier, &kvm_preempt_ops);
+	 *   - virt/kvm/kvm_main.c|5854| <<kvm_init>> kvm_preempt_ops.sched_in = kvm_sched_in;
+	 *   - virt/kvm/kvm_main.c|5855| <<kvm_init>> kvm_preempt_ops.sched_out = kvm_sched_out;
+	 *
+	 * 在以下使用kvm_vcpu->preempt_notifier:
+	 *   - virt/kvm/kvm_main.c|208| <<vcpu_load>> preempt_notifier_register(&vcpu->preempt_notifier);
+	 *   - virt/kvm/kvm_main.c|218| <<vcpu_put>> preempt_notifier_unregister(&vcpu->preempt_notifier);
+	 *   - virt/kvm/kvm_main.c|462| <<kvm_vcpu_init>> preempt_notifier_init(&vcpu->preempt_notifier, &kvm_preempt_ops);
+	 */
 	preempt_notifier_init(&vcpu->preempt_notifier, &kvm_preempt_ops);
 	vcpu->last_used_slot = NULL;
 }
@@ -3386,19 +3433,73 @@ static void shrink_halt_poll_ns(struct kvm_vcpu *vcpu)
 	trace_kvm_halt_poll_ns_shrink(vcpu->vcpu_id, val, old);
 }
 
+/*
+ * 在以下调用kvm_vcpu_check_block():
+ *   - virt/kvm/kvm_main.c|3453| <<kvm_vcpu_block>> if (kvm_vcpu_check_block(vcpu) < 0) {
+ *   - virt/kvm/kvm_main.c|3478| <<kvm_vcpu_block>> if (kvm_vcpu_check_block(vcpu) < 0)
+ *
+ * 主要做4组检查,决定是否返回<0.
+ *
+ * 第一组.
+ * 对于普通正在运行的vCPU, 满足二者之一就行:
+ * 1. KVM_MP_STATE_RUNNABLE, 并且没有halted
+ * 2. 对于已经存在的vCPU, 更多是检查vCPU有没有开中断
+ * 和有没有pending的IRR
+ * 第二组.
+ * 检查APIC的Timer寄存器是不是开了
+ * 并且是不是有pending的
+ * 第三组.
+ * 有没有pending的signal
+ * 第四组.
+ * 有没有KVM_REQ_UNBLOCK.
+ */
 static int kvm_vcpu_check_block(struct kvm_vcpu *vcpu)
 {
 	int ret = -EINTR;
 	int idx = srcu_read_lock(&vcpu->kvm->srcu);
 
+	/*
+	 * 在以下使用x86的kvm_arch_vcpu_runnable():
+	 *   - arch/x86/kvm/x86.c|11309| <<vcpu_block>> if (!kvm_arch_vcpu_runnable(vcpu) &&
+	 *   - virt/kvm/kvm_main.c|3398| <<kvm_vcpu_check_block>> if (kvm_arch_vcpu_runnable(vcpu)) {
+	 *   - virt/kvm/kvm_main.c|3630| <<kvm_arch_dy_runnable>> return kvm_arch_vcpu_runnable(vcpu);
+	 *
+	 * 对于普通正在运行的vCPU, 满足二者之一就行:
+	 * 1. KVM_MP_STATE_RUNNABLE, 并且没有halted
+	 * 2. 对于已经存在的vCPU, 更多是检查vCPU有没有开中断
+	 * 和有没有pending的IRR
+	 */
 	if (kvm_arch_vcpu_runnable(vcpu)) {
+		/*
+		 * x86和arm64在以下使用KVM_REQ_UNHALT:
+		 *   - arch/arm64/kvm/handle_exit.c|99| <<kvm_handle_wfx>> kvm_clear_request(KVM_REQ_UNHALT, vcpu);
+		 *   - arch/arm64/kvm/psci.c|50| <<kvm_psci_vcpu_suspend>> kvm_clear_request(KVM_REQ_UNHALT, vcpu);
+		 *   - arch/x86/kvm/x86.c|11370| <<vcpu_block>> if (!kvm_check_request(KVM_REQ_UNHALT, vcpu))
+		 *   - arch/x86/kvm/x86.c|11658| <<kvm_arch_vcpu_ioctl_run>> kvm_clear_request(KVM_REQ_UNHALT, vcpu);
+		 *   - virt/kvm/kvm_main.c|3458| <<kvm_vcpu_check_block>> kvm_make_request(KVM_REQ_UNHALT, vcpu);
+		 */
 		kvm_make_request(KVM_REQ_UNHALT, vcpu);
 		goto out;
 	}
+	/*
+	 * 在以下使用kvm_cpu_has_pending_timer():
+	 *   - arch/x86/kvm/x86.c|11445| <<vcpu_run>> if (kvm_cpu_has_pending_timer(vcpu))
+	 *   - virt/kvm/kvm_main.c|3402| <<kvm_vcpu_check_block>> if (kvm_cpu_has_pending_timer(vcpu))
+	 *
+	 * 检查APIC的Timer寄存器是不是开了
+	 * 并且是不是有pending的
+	 */
 	if (kvm_cpu_has_pending_timer(vcpu))
 		goto out;
 	if (signal_pending(current))
 		goto out;
+	/*
+	 * 在以下使用KVM_REQ_UNBLOCK:
+	 *   - arch/x86/kvm/lapic.c|2735| <<apic_timer_expired>> kvm_make_request(KVM_REQ_UNBLOCK, vcpu);
+	 *   - arch/x86/kvm/vmx/posted_intr.c|256| <<vmx_pi_start_assignment>> kvm_make_all_cpus_request(kvm, KVM_REQ_UNBLOCK);
+	 *   - arch/x86/kvm/x86.c|11444| <<vcpu_run>> kvm_clear_request(KVM_REQ_UNBLOCK, vcpu);
+	 *   - virt/kvm/kvm_main.c|3406| <<kvm_vcpu_check_block>> if (kvm_check_request(KVM_REQ_UNBLOCK, vcpu))
+	 */
 	if (kvm_check_request(KVM_REQ_UNBLOCK, vcpu))
 		goto out;
 
@@ -3420,6 +3521,16 @@ update_halt_poll_stats(struct kvm_vcpu *vcpu, u64 poll_ns, bool waited)
 /*
  * The vCPU has executed a HLT instruction with in-kernel mode enabled.
  */
+/*
+ * x86和arm在以下使用kvm_vcpu_block():
+ *   - arch/arm64/kvm/handle_exit.c|98| <<kvm_handle_wfx>> kvm_vcpu_block(vcpu);
+ *   - arch/arm64/kvm/psci.c|49| <<kvm_psci_vcpu_suspend>> kvm_vcpu_block(vcpu);
+ *   - arch/x86/kvm/x86.c|11226| <<vcpu_block>> kvm_vcpu_block(vcpu);
+ *   - arch/x86/kvm/x86.c|11445| <<kvm_arch_vcpu_ioctl_run>> kvm_vcpu_block(vcpu);
+ *
+ * The vCPU has executed a HLT instruction with in-kernel mode enabled.
+ * 对于普通的x86的vCPU,只考虑vcpu_block()就行
+ */
 void kvm_vcpu_block(struct kvm_vcpu *vcpu)
 {
 	bool halt_poll_allowed = !kvm_arch_no_poll(vcpu);
@@ -3435,6 +3546,11 @@ void kvm_vcpu_block(struct kvm_vcpu *vcpu)
 
 		++vcpu->stat.generic.halt_attempted_poll;
 		do {
+			/*
+			 * 在以下调用kvm_vcpu_check_block():
+			 *   - virt/kvm/kvm_main.c|3453| <<kvm_vcpu_block>> if (kvm_vcpu_check_block(vcpu) < 0) {
+			 *   - virt/kvm/kvm_main.c|3478| <<kvm_vcpu_block>> if (kvm_vcpu_check_block(vcpu) < 0)
+			 */
 			/*
 			 * This sets KVM_REQ_UNHALT if an interrupt
 			 * arrives.
@@ -3464,10 +3580,36 @@ void kvm_vcpu_block(struct kvm_vcpu *vcpu)
 	for (;;) {
 		set_current_state(TASK_INTERRUPTIBLE);
 
+		/*
+		 * 在以下调用kvm_vcpu_check_block():
+		 *   - virt/kvm/kvm_main.c|3453| <<kvm_vcpu_block>> if (kvm_vcpu_check_block(vcpu) < 0) {
+		 *   - virt/kvm/kvm_main.c|3478| <<kvm_vcpu_block>> if (kvm_vcpu_check_block(vcpu) < 0)
+		 *
+		 * 这里要小于0才break
+		 *
+		 * 主要做4组检查,决定是否返回<0.
+		 *
+		 * 第一组.
+		 * 对于普通正在运行的vCPU, 满足二者之一就行:
+		 * 1. KVM_MP_STATE_RUNNABLE, 并且没有halted
+		 * 2. 对于已经存在的vCPU, 更多是检查vCPU有没有开中断
+		 * 和有没有pending的IRR
+		 * 第二组.
+		 * 检查APIC的Timer寄存器是不是开了
+		 * 并且是不是有pending的
+		 * 第三组.
+		 * 有没有pending的signal
+		 * 第四组.
+		 * 有没有KVM_REQ_UNBLOCK.
+		 */
 		if (kvm_vcpu_check_block(vcpu) < 0)
 			break;
 
 		waited = true;
+		/*
+		 * 唤醒也没用.
+		 * 还是在循环内检查
+		 */
 		schedule();
 	}
 	finish_rcuwait(&vcpu->wait);
@@ -3509,6 +3651,15 @@ void kvm_vcpu_block(struct kvm_vcpu *vcpu)
 }
 EXPORT_SYMBOL_GPL(kvm_vcpu_block);
 
+/*
+ * 在以下使用kvm_vcpu_wake_up():
+ *   - arch/arm64/kvm/arch_timer.c|312| <<kvm_bg_timer_expire>> kvm_vcpu_wake_up(vcpu);
+ *   - arch/arm64/kvm/psci.c|117| <<kvm_psci_vcpu_on>> kvm_vcpu_wake_up(vcpu);
+ *   - arch/s390/kvm/interrupt.c|1353| <<kvm_s390_vcpu_wakeup>> kvm_vcpu_wake_up(vcpu);
+ *   - arch/x86/kvm/svm/avic.c|142| <<avic_ga_log_notifier>> kvm_vcpu_wake_up(vcpu);
+ *   - arch/x86/kvm/svm/svm.c|3729| <<svm_complete_interrupt_delivery>> kvm_vcpu_wake_up(vcpu);
+ *   - virt/kvm/kvm_main.c|301| <<kvm_make_vcpu_request>> if (!(req & KVM_REQUEST_NO_WAKEUP) && kvm_vcpu_wake_up(vcpu))
+ */
 bool kvm_vcpu_wake_up(struct kvm_vcpu *vcpu)
 {
 	if (__kvm_vcpu_wake_up(vcpu)) {
@@ -3796,6 +3947,10 @@ static void kvm_create_vcpu_debugfs(struct kvm_vcpu *vcpu)
 /*
  * Creates some virtual cpus.  Good luck creating more than one.
  */
+/*
+ * 在以下调用kvm_vm_ioctl_create_vcpu():
+ *   - virt/kvm/kvm_main.c|4593| <<kvm_vm_ioctl(KVM_CREATE_VCPU)>> r = kvm_vm_ioctl_create_vcpu(kvm, arg);
+ */
 static int kvm_vm_ioctl_create_vcpu(struct kvm *kvm, u32 id)
 {
 	int r;
@@ -3832,8 +3987,14 @@ static int kvm_vm_ioctl_create_vcpu(struct kvm *kvm, u32 id)
 	}
 	vcpu->run = page_address(page);
 
+	/*
+	 * 只在这里调用
+	 */
 	kvm_vcpu_init(vcpu, kvm, id);
 
+	/*
+	 * 会调用kvm_vcpu_reset()去初始化lapic
+	 */
 	r = kvm_arch_vcpu_create(vcpu);
 	if (r)
 		goto vcpu_free_run_page;
@@ -4670,6 +4831,9 @@ static long kvm_vm_ioctl(struct file *filp,
 		r = -EFAULT;
 		if (copy_from_user(&msi, argp, sizeof(msi)))
 			goto out;
+                /*
+		 * 只在此处调用kvm_send_userspace_msi()
+		 */
 		r = kvm_send_userspace_msi(kvm, &msi);
 		break;
 	}
@@ -5240,6 +5404,30 @@ int kvm_io_bus_read(struct kvm_vcpu *vcpu, enum kvm_bus bus_idx, gpa_t addr,
 	return r < 0 ? r : 0;
 }
 
+/*
+ * 在以下使用kvm_io_bus_register_dev():
+ *   - arch/arm64/kvm/vgic/vgic-its.c|1840| <<vgic_register_its_iodev>> ret = kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS,
+ *                    iodev->base_addr, KVM_VGIC_V3_ITS_SIZE, &iodev->dev);
+ *   - arch/arm64/kvm/vgic/vgic-mmio-v3.c|743| <<vgic_register_redist_iodev>> ret = kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS,
+ *                    rd_base, 2 * SZ_64K, &rd_dev->dev);
+ *   - arch/arm64/kvm/vgic/vgic-mmio.c|1096| <<vgic_register_dist_iodev>> ret = kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS,
+ *                    dist_base_address, len, &io_device->dev);
+ *   - arch/mips/kvm/loongson_ipi.c|209| <<kvm_init_loongson_ipi>> kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS, addr, 0x400, device);
+ *   - arch/powerpc/kvm/mpic.c|1449| <<map_mmio>> kvm_io_bus_register_dev(opp->kvm, KVM_MMIO_BUS,
+ *                    opp->reg_base, OPENPIC_REG_SIZE, &opp->mmio);
+ *   - arch/x86/kvm/i8254.c|705| <<kvm_create_pit>> ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS,
+ *                    KVM_PIT_BASE_ADDRESS, KVM_PIT_MEM_LENGTH, &pit->dev);
+ *   - arch/x86/kvm/i8254.c|712| <<kvm_create_pit>> ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS,
+ *                    KVM_SPEAKER_BASE_ADDRESS, 4, &pit->speaker_dev);
+ *   - arch/x86/kvm/i8259.c|607| <<kvm_pic_init>> ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS, 0x20, 2, &s->dev_master);
+ *   - arch/x86/kvm/i8259.c|612| <<kvm_pic_init>> ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS, 0xa0, 2, &s->dev_slave);
+ *   - arch/x86/kvm/i8259.c|616| <<kvm_pic_init>> ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS, 0x4d0, 2, &s->dev_elcr);
+ *   - arch/x86/kvm/ioapic.c|1014| <<kvm_ioapic_init>> ret = kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS,
+ *                    ioapic->base_address, IOAPIC_MEM_LENGTH, &ioapic->dev);
+ *   - virt/kvm/coalesced_mmio.c|156| <<kvm_vm_ioctl_register_coalesced_mmio>> ret = kvm_io_bus_register_dev(kvm,
+ *                    zone->pio ? KVM_PIO_BUS : KVM_MMIO_BUS, zone->addr, zone->size, &dev->dev);
+ *   - virt/kvm/eventfd.c|841| <<kvm_assign_ioeventfd_idx>> ret = kvm_io_bus_register_dev(kvm, bus_idx, p->addr, p->length, &p->dev);
+ */
 /* Caller must hold slots_lock. */
 int kvm_io_bus_register_dev(struct kvm *kvm, enum kvm_bus bus_idx, gpa_t addr,
 			    int len, struct kvm_io_device *dev)
-- 
2.39.5 (Apple Git-154)

