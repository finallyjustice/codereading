From 2caf951fc39bb77a8cf987d2d7a9f8b2532f631d Mon Sep 17 00:00:00 2001
From: Dongli Zhang <dongli.zhang0129@gmail.com>
Date: Fri, 8 Mar 2019 16:10:03 +0800
Subject: [PATCH 1/1] block comment for block and drivers for
 linux-block:for-5.1/block-20190302

This is for linux-block: for-5.1/block-20190302

Signed-off-by: Dongli Zhang <dongli.zhang0129@gmail.com>
---
 block/blk-merge.c       |   4 ++
 block/blk-mq-pci.c      |   7 ++
 block/blk-mq-sched.c    |   9 +++
 block/blk-mq-tag.c      |  14 ++++
 block/blk-mq-tag.h      |  43 ++++++++++++
 block/blk-mq.c          |  51 ++++++++++++++
 block/blk-mq.h          |  14 ++++
 block/blk-settings.c    |  35 ++++++++++
 block/blk-softirq.c     |  10 +++
 drivers/nvme/host/pci.c |  25 +++++++
 include/linux/blk-mq.h  | 178 ++++++++++++++++++++++++++++++++++++++++++++++++
 include/linux/blkdev.h  |  69 +++++++++++++++++++
 12 files changed, 459 insertions(+)

diff --git a/block/blk-merge.c b/block/blk-merge.c
index 22467f4..9fcb5d5 100644
--- a/block/blk-merge.c
+++ b/block/blk-merge.c
@@ -318,6 +318,10 @@ static struct bio *blk_bio_segment_split(struct request_queue *q,
 	return do_split ? new : NULL;
 }
 
+/*
+ * 根据块设备请求队列的limits.max_sectors和limits.max_segmetns
+ * 来拆分bio,适应设备缓存.会在函数blk_set_default_limits中设置
+ */
 void blk_queue_split(struct request_queue *q, struct bio **bio)
 {
 	struct bio *split, *res;
diff --git a/block/blk-mq-pci.c b/block/blk-mq-pci.c
index 1dce185..de49b40 100644
--- a/block/blk-mq-pci.c
+++ b/block/blk-mq-pci.c
@@ -31,6 +31,12 @@
  * that maps a queue to the CPUs that have irq affinity for the corresponding
  * vector.
  */
+/*
+ * called by:
+ *   - drivers/nvme/host/pci.c|504| <<nvme_pci_map_queues>> blk_mq_pci_map_queues(map, to_pci_dev(dev->dev), offset);
+ *   - drivers/scsi/qla2xxx/qla_os.c|6942| <<qla2xxx_map_queues>> rc = blk_mq_pci_map_queues(qmap, vha->hw->pdev, vha->irq_offset);
+ *   - drivers/scsi/smartpqi/smartpqi_init.c|5792| <<pqi_map_queues>> return blk_mq_pci_map_queues(&shost->tag_set.map[0],
+ */
 int blk_mq_pci_map_queues(struct blk_mq_queue_map *qmap, struct pci_dev *pdev,
 			    int offset)
 {
@@ -42,6 +48,7 @@ int blk_mq_pci_map_queues(struct blk_mq_queue_map *qmap, struct pci_dev *pdev,
 		if (!mask)
 			goto fallback;
 
+		/* 猜测是每一个sw queue对应的hw queue??? */
 		for_each_cpu(cpu, mask)
 			qmap->mq_map[cpu] = qmap->queue_offset + queue;
 	}
diff --git a/block/blk-mq-sched.c b/block/blk-mq-sched.c
index 4090553..dae14b5 100644
--- a/block/blk-mq-sched.c
+++ b/block/blk-mq-sched.c
@@ -443,6 +443,10 @@ static void blk_mq_sched_free_tags(struct blk_mq_tag_set *set,
 	}
 }
 
+/*
+ * called by:
+ *   - block/blk-mq-sched.c|497| <<blk_mq_init_sched>> ret = blk_mq_sched_alloc_tags(q, hctx, i);
+ */
 static int blk_mq_sched_alloc_tags(struct request_queue *q,
 				   struct blk_mq_hw_ctx *hctx,
 				   unsigned int hctx_idx)
@@ -472,6 +476,11 @@ static void blk_mq_sched_tags_teardown(struct request_queue *q)
 		blk_mq_sched_free_tags(set, hctx, i);
 }
 
+/*
+ * called by:
+ *   - block/elevator.c|577| <<elevator_switch_mq>> ret = blk_mq_init_sched(q, new_e);
+ *   - block/elevator.c|623| <<elevator_init_mq>> err = blk_mq_init_sched(q, e);
+ */
 int blk_mq_init_sched(struct request_queue *q, struct elevator_type *e)
 {
 	struct blk_mq_hw_ctx *hctx;
diff --git a/block/blk-mq-tag.c b/block/blk-mq-tag.c
index a4931fc..b84d0f2 100644
--- a/block/blk-mq-tag.c
+++ b/block/blk-mq-tag.c
@@ -27,8 +27,13 @@ bool blk_mq_has_free_tags(struct blk_mq_tags *tags)
  * to get tag when first time, the other shared-tag users could reserve
  * budget for it.
  */
+/*
+ * called by:
+ *   - block/blk-mq-tag.h|72| <<blk_mq_tag_busy>> return __blk_mq_tag_busy(hctx);
+ */
 bool __blk_mq_tag_busy(struct blk_mq_hw_ctx *hctx)
 {
+	/* test_and_set_bit(): Set a bit and return its old value */
 	if (!test_bit(BLK_MQ_S_TAG_ACTIVE, &hctx->state) &&
 	    !test_and_set_bit(BLK_MQ_S_TAG_ACTIVE, &hctx->state))
 		atomic_inc(&hctx->tags->active_queues);
@@ -107,6 +112,11 @@ static int __blk_mq_get_tag(struct blk_mq_alloc_data *data,
 
 unsigned int blk_mq_get_tag(struct blk_mq_alloc_data *data)
 {
+	/*
+	 * 如果参数的blk_mq_alloc_data->flags设置了BLK_MQ_REQ_INTERNAL,
+	 * 则返回使用data->hctx->sched_tags
+	 * 否则返回data->hctx->tags
+	 */
 	struct blk_mq_tags *tags = blk_mq_tags_from_data(data);
 	struct sbitmap_queue *bt;
 	struct sbq_wait_state *ws;
@@ -435,6 +445,10 @@ static struct blk_mq_tags *blk_mq_init_bitmap_tags(struct blk_mq_tags *tags,
 	return NULL;
 }
 
+/*
+ * called by:
+ *   - block/blk-mq.c|2068| <<blk_mq_alloc_rq_map>> tags = blk_mq_init_tags(nr_tags, reserved_tags, node,
+ */
 struct blk_mq_tags *blk_mq_init_tags(unsigned int total_tags,
 				     unsigned int reserved_tags,
 				     int node, int alloc_policy)
diff --git a/block/blk-mq-tag.h b/block/blk-mq-tag.h
index 61deab0..7f34423 100644
--- a/block/blk-mq-tag.h
+++ b/block/blk-mq-tag.h
@@ -8,15 +8,45 @@
  * Tag address space map.
  */
 struct blk_mq_tags {
+	/*
+	 * 只在一处设置:
+	 */
 	unsigned int nr_tags;
+	/*
+	 * 只在一处设置:
+	 *   - block/blk-mq-tag.c|454| <<blk_mq_init_tags>> tags->nr_reserved_tags = reserved_tags;
+	 */
 	unsigned int nr_reserved_tags;
 
+	/*
+	 * active_queues使用的地方:
+	 *   - block/blk-mq-debugfs.c|477| <<blk_mq_debugfs_tags_show>> atomic_read(&tags->active_queues));
+	 *   - block/blk-mq-tag.c|34| <<__blk_mq_tag_busy>> atomic_inc(&hctx->tags->active_queues);
+	 *   - block/blk-mq-tag.c|60| <<__blk_mq_tag_idle>> atomic_dec(&tags->active_queues);
+	 *   - block/blk-mq-tag.c|85| <<hctx_may_queue>> users = atomic_read(&hctx->tags->active_queues);
+	 */
 	atomic_t active_queues;
 
 	struct sbitmap_queue bitmap_tags;
 	struct sbitmap_queue breserved_tags;
 
+	/*
+	 * 分配指针数组的地方:
+	 *   - block/blk-mq.c|2073| <<blk_mq_alloc_rq_map>> tags->rqs = kcalloc_node(nr_tags, sizeof(struct request *),
+	 *
+	 * 设置指针内容的地方:
+	 *   - block/blk-mq-tag.h|92| <<blk_mq_tag_set_rq>> hctx->tags->rqs[tag] = rq;
+	 *   - block/blk-mq.c|307| <<blk_mq_rq_ctx_init>> data->hctx->tags->rqs[rq->tag] = rq;
+	 *   - block/blk-mq.c|1056| <<blk_mq_get_driver_tag>> data.hctx->tags->rqs[rq->tag] = rq;
+	 */
 	struct request **rqs;
+	/*
+	 * 分配指针数组的地方:
+	 *   - block/blk-mq.c|2081| <<blk_mq_alloc_rq_map>> tags->static_rqs = kcalloc_node(nr_tags, sizeof(struct request *),
+	 *
+	 * 设置指针内容的地方 (指向的都是下面page_list的内容):
+	 *   - block/blk-mq.c|2173| <<blk_mq_alloc_rqs>> tags->static_rqs[i] = rq;
+	 */
 	struct request **static_rqs;
 	struct list_head page_list;
 };
@@ -53,6 +83,14 @@ enum {
 extern bool __blk_mq_tag_busy(struct blk_mq_hw_ctx *);
 extern void __blk_mq_tag_idle(struct blk_mq_hw_ctx *);
 
+/*
+ * called by:
+ *   - block/blk-mq.c|394| <<blk_mq_get_request>> blk_mq_tag_busy(data->hctx);
+ *   - block/blk-mq.c|1078| <<blk_mq_get_driver_tag>> shared = blk_mq_tag_busy(data.hctx);
+ *
+ * 如果blk_mq_hw_ctx->flags没有设置BLK_MQ_F_TAG_SHARED
+ * 则不会调用__blk_mq_tag_busy()
+ */
 static inline bool blk_mq_tag_busy(struct blk_mq_hw_ctx *hctx)
 {
 	if (!(hctx->flags & BLK_MQ_F_TAG_SHARED))
@@ -75,6 +113,11 @@ static inline void blk_mq_tag_idle(struct blk_mq_hw_ctx *hctx)
  * in flight at the same time. The caller has to make sure the tag
  * can't be freed.
  */
+/*
+ * called by:
+ *   - block/blk-flush.c|220| <<flush_end_io>> blk_mq_tag_set_rq(hctx, flush_rq->tag, fq->orig_rq);
+ *   - block/blk-flush.c|303| <<blk_kick_flush>> blk_mq_tag_set_rq(flush_rq->mq_hctx, first_rq->tag, flush_rq);
+ */
 static inline void blk_mq_tag_set_rq(struct blk_mq_hw_ctx *hctx,
 		unsigned int tag, struct request *rq)
 {
diff --git a/block/blk-mq.c b/block/blk-mq.c
index fa024bc..785240e 100644
--- a/block/blk-mq.c
+++ b/block/blk-mq.c
@@ -38,6 +38,28 @@
 #include "blk-mq-sched.h"
 #include "blk-rq-qos.h"
 
+/*
+ * 一共两处对queue_rq()的调用:
+ *   - blk_mq_try_issue_directly()-->__blk_mq_issue_directly()
+ *   - blk_mq_dispatch_rq_list()
+ *
+ *
+ *
+ * BLK_MQ_F_xxx只被blk_mq_tag_set->flags和blk_mq_hw_hctx->flags使用
+ * blk_mq_init_hctx()中把blk_mq_tag_set->flags拷贝到blk_mq_hw_hctx->flags:
+ *   - block/blk-mq.c|2402| <<blk_mq_init_hctx>> hctx->flags = set->flags & ~BLK_MQ_F_TAG_SHARED;
+ *
+ * BLK_MQ_S_xxx只用在blk_mq_hw_ctx->state
+ *
+ * BLK_MQ_REQ_xxx只被blk_mq_alloc_data->flags使用
+ *
+ * RQF_xxx用在request->rq_flags
+ *
+ * MQ_RQ_xxx用在request->state
+ *
+ * QUEUE_FLAG_xxx在request_queue->queue_flags中使用
+ */
+
 static void blk_mq_poll_stats_start(struct request_queue *q);
 static void blk_mq_poll_stats_fn(struct blk_stat_callback *cb);
 
@@ -287,6 +309,10 @@ static inline bool blk_mq_need_time_stamp(struct request *rq)
 	return (rq->rq_flags & RQF_IO_STAT) || rq->q->elevator;
 }
 
+/*
+ * called by:
+ *   - block/blk-mq.c|397| <<blk_mq_get_request>> rq = blk_mq_rq_ctx_init(data, tag, data->cmd_flags);
+ */
 static struct request *blk_mq_rq_ctx_init(struct blk_mq_alloc_data *data,
 		unsigned int tag, unsigned int op)
 {
@@ -347,6 +373,12 @@ static struct request *blk_mq_rq_ctx_init(struct blk_mq_alloc_data *data,
 	return rq;
 }
 
+/*
+ * called by:
+ *   - block/blk-mq.c|423| <<blk_mq_alloc_request>> rq = blk_mq_get_request(q, NULL, &alloc_data);
+ *   - block/blk-mq.c|474| <<blk_mq_alloc_request_hctx>> rq = blk_mq_get_request(q, NULL, &alloc_data);
+ *   - block/blk-mq.c|1932| <<blk_mq_make_request>> rq = blk_mq_get_request(q, bio, &data);
+ */
 static struct request *blk_mq_get_request(struct request_queue *q,
 					  struct bio *bio,
 					  struct blk_mq_alloc_data *data)
@@ -657,8 +689,19 @@ bool blk_mq_complete_request(struct request *rq)
 }
 EXPORT_SYMBOL(blk_mq_complete_request);
 
+/*
+ * called by:
+ *   - block/blk-mq-tag.c|296| <<bt_tags_iter>> if (rq && blk_mq_request_started(rq))
+ *   - block/blk-mq.c|718| <<__blk_mq_requeue_request>> if (blk_mq_request_started(rq)) {
+ *   - drivers/block/nbd.c|648| <<nbd_read_stat>> if (!req || !blk_mq_request_started(req)) {
+ */
 int blk_mq_request_started(struct request *rq)
 {
+	/*
+	 * MQ_RQ_IDLE
+	 * MQ_RQ_IN_FLIGHT
+	 * MQ_RQ_COMPLETE
+	 */
 	return blk_mq_rq_state(rq) != MQ_RQ_IDLE;
 }
 EXPORT_SYMBOL_GPL(blk_mq_request_started);
@@ -1030,6 +1073,14 @@ static inline unsigned int queued_to_index(unsigned int queued)
 	return min(BLK_MQ_MAX_DISPATCH_ORDER - 1, ilog2(queued) + 1);
 }
 
+/*
+ * called by:
+ *   - block/blk-mq.c|1103| <<blk_mq_mark_tag_wait>> return blk_mq_get_driver_tag(rq);
+ *   - block/blk-mq.c|1128| <<blk_mq_mark_tag_wait>> ret = blk_mq_get_driver_tag(rq);
+ *   - block/blk-mq.c|1207| <<blk_mq_dispatch_rq_list>> if (!blk_mq_get_driver_tag(rq)) {
+ *   - block/blk-mq.c|1239| <<blk_mq_dispatch_rq_list>> bd.last = !blk_mq_get_driver_tag(nxt);
+ *   - block/blk-mq.c|1822| <<blk_mq_try_issue_directly>> if (!blk_mq_get_driver_tag(rq)) {
+ */
 bool blk_mq_get_driver_tag(struct request *rq)
 {
 	struct blk_mq_alloc_data data = {
diff --git a/block/blk-mq.h b/block/blk-mq.h
index c11353a..b1fec5c 100644
--- a/block/blk-mq.h
+++ b/block/blk-mq.h
@@ -171,8 +171,22 @@ struct blk_mq_alloc_data {
 	struct blk_mq_hw_ctx *hctx;
 };
 
+/*
+ * called by:
+ *   - block/blk-mq-tag.c|115| <<blk_mq_get_tag>> struct blk_mq_tags *tags = blk_mq_tags_from_data(data);
+ *   - block/blk-mq-tag.c|179| <<blk_mq_get_tag>> tags = blk_mq_tags_from_data(data);
+ *   - block/blk-mq.c|297| <<blk_mq_rq_ctx_init>> struct blk_mq_tags *tags = blk_mq_tags_from_data(data);
+ *
+ * 如果参数的blk_mq_alloc_data->flags设置了BLK_MQ_REQ_INTERNAL,
+ * 则返回使用data->hctx->sched_tags
+ * 否则返回data->hctx->tags
+ */
 static inline struct blk_mq_tags *blk_mq_tags_from_data(struct blk_mq_alloc_data *data)
 {
+	/*
+	 * BLK_MQ_REQ_INTERNAL在以下被设置:
+	 *   - block/blk-mq.c|372| <<blk_mq_get_request>> data->flags |= BLK_MQ_REQ_INTERNAL;
+	 */
 	if (data->flags & BLK_MQ_REQ_INTERNAL)
 		return data->hctx->sched_tags;
 
diff --git a/block/blk-settings.c b/block/blk-settings.c
index 6375afa..a2c02d8 100644
--- a/block/blk-settings.c
+++ b/block/blk-settings.c
@@ -20,6 +20,10 @@ EXPORT_SYMBOL(blk_max_low_pfn);
 
 unsigned long blk_max_pfn;
 
+/*
+ * 被很多地方调用, 其中一个例子
+ *   - block/blk-mq.c|2849| <<blk_mq_init_allocated_queue>> blk_queue_rq_timeout(q, set->timeout ? set->timeout : 30 * HZ);
+ */
 void blk_queue_rq_timeout(struct request_queue *q, unsigned int timeout)
 {
 	q->rq_timeout = timeout;
@@ -33,6 +37,11 @@ EXPORT_SYMBOL_GPL(blk_queue_rq_timeout);
  * Description:
  *   Returns a queue_limit struct to its default state.
  */
+/*
+ * called by:
+ *   - block/blk-settings.c|73| <<blk_set_stacking_limits>> blk_set_default_limits(lim);
+ *   - block/blk-settings.c|119| <<blk_queue_make_request>> blk_set_default_limits(&q->limits);
+ */
 void blk_set_default_limits(struct queue_limits *lim)
 {
 	lim->max_segments = BLK_MAX_SEGMENTS;
@@ -178,6 +187,13 @@ EXPORT_SYMBOL(blk_queue_bounce_limit);
  *    per-device basis in /sys/block/<device>/queue/max_sectors_kb.
  *    The soft limit can not exceed max_hw_sectors.
  **/
+/*
+ * 被很多调用, 这里是几个调用的例子:
+ *   - drivers/block/xen-blkfront.c|947| <<blkif_set_queue_limits>> blk_queue_max_hw_sectors(rq, (segments * XEN_PAGE_SIZE) / 512);
+ *   - drivers/block/virtio_blk.c|827| <<virtblk_probe>> blk_queue_max_hw_sectors(q, -1U);
+ *   - drivers/nvme/host/core.c|1972| <<nvme_set_queue_limits>> blk_queue_max_hw_sectors(q, ctrl->max_hw_sectors);
+ *   - drivers/block/loop.c|1968| <<loop_add>> blk_queue_max_hw_sectors(lo->lo_queue, BLK_DEF_MAX_SECTORS);
+ */
 void blk_queue_max_hw_sectors(struct request_queue *q, unsigned int max_hw_sectors)
 {
 	struct queue_limits *limits = &q->limits;
@@ -264,6 +280,14 @@ EXPORT_SYMBOL(blk_queue_max_write_zeroes_sectors);
  *    Enables a low level driver to set an upper limit on the number of
  *    hw data segments in a request.
  **/
+/*
+ * 选择的一些地方:
+ *   - drivers/block/virtio_blk.c|824| <<virtblk_probe>> blk_queue_max_segments(q, vblk->sg_elems-2);
+ *   - drivers/block/xen-blkfront.c|954| <<blkif_set_queue_limits>> blk_queue_max_segments(rq, segments / GRANTS_PER_PSEG);
+ *   - drivers/block/xen-blkfront.c|2027| <<blkif_recover>> blk_queue_max_segments(info->rq, segs / GRANTS_PER_PSEG);
+ *   - drivers/nvme/host/core.c|1973| <<nvme_set_queue_limits>> blk_queue_max_segments(q, min_t(u32, max_segments, USHRT_MAX));
+ *   - drivers/scsi/scsi_lib.c|1828| <<__scsi_init_queue>> blk_queue_max_segments(q, min_t(unsigned short , shost->sg_tablesize,
+ */
 void blk_queue_max_segments(struct request_queue *q, unsigned short max_segments)
 {
 	if (!max_segments) {
@@ -462,6 +486,11 @@ EXPORT_SYMBOL(blk_queue_io_opt);
  * @t:	the stacking driver (top)
  * @b:  the underlying device (bottom)
  **/
+/*
+ * called by:
+ *   - drivers/block/drbd/drbd_nl.c|1377| <<drbd_setup_queue_param>> blk_queue_stack_limits(q, b);
+ *   - drivers/nvme/host/core.c|1649| <<__nvme_revalidate_disk>> blk_queue_stack_limits(ns->head->disk->queue, ns->queue)
+ */
 void blk_queue_stack_limits(struct request_queue *t, struct request_queue *b)
 {
 	blk_stack_limits(&t->limits, &b->limits, 0);
@@ -489,6 +518,12 @@ EXPORT_SYMBOL(blk_queue_stack_limits);
  *    queue_limits will have the misaligned flag set to indicate that
  *    the alignment_offset is undefined.
  */
+/*
+ * called by:
+ *   - block/blk-settings.c|483| <<blk_queue_stack_limits>> blk_stack_limits(&t->limits, &b->limits, 0);
+ *   - block/blk-settings.c|650| <<bdev_stack_limits>> return blk_stack_limits(t, &bq->limits, start);
+ *   - drivers/md/dm-table.c|1541| <<dm_calculate_queue_limits>> if (blk_stack_limits(limits, &ti_limits, 0) < 0)
+ */
 int blk_stack_limits(struct queue_limits *t, struct queue_limits *b,
 		     sector_t start)
 {
diff --git a/block/blk-softirq.c b/block/blk-softirq.c
index 457d9ba..78878a1 100644
--- a/block/blk-softirq.c
+++ b/block/blk-softirq.c
@@ -95,6 +95,10 @@ static int blk_softirq_cpu_dead(unsigned int cpu)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - block/blk-mq.c|604| <<__blk_mq_complete_request>> __blk_complete_request(rq);
+ */
 void __blk_complete_request(struct request *req)
 {
 	struct request_queue *q = req->q;
@@ -136,6 +140,12 @@ void __blk_complete_request(struct request *req)
 		 * entries there, someone already raised the irq but it
 		 * hasn't run yet.
 		 */
+		/*
+		 * block/blk-softirq.c|154| <<blk_softirq_init>> open_softirq(BLOCK_SOFTIRQ, blk_done_softirq);
+		 *
+		 * 对于blk_cpu_done链表上的每一个request调用rq->q->mq_ops->complete(rq)
+		 * 并且删除这个request
+		 */
 		if (list->next == &req->ipi_list)
 			raise_softirq_irqoff(BLOCK_SOFTIRQ);
 	} else if (raise_blk_irq(ccpu, req))
diff --git a/drivers/nvme/host/pci.c b/drivers/nvme/host/pci.c
index f54718b..86bcf34 100644
--- a/drivers/nvme/host/pci.c
+++ b/drivers/nvme/host/pci.c
@@ -2435,6 +2435,20 @@ static void nvme_pci_disable(struct nvme_dev *dev)
 	}
 }
 
+/*
+ * called by:
+ *   - drivers/nvme/host/pci.c|1288| <<nvme_timeout>> nvme_dev_disable(dev, false);
+ *   - drivers/nvme/host/pci.c|1315| <<nvme_timeout>> nvme_dev_disable(dev, false);
+ *   - drivers/nvme/host/pci.c|1331| <<nvme_timeout>> nvme_dev_disable(dev, false);
+ *   - drivers/nvme/host/pci.c|2530| <<nvme_remove_dead_ctrl>> nvme_dev_disable(dev, false);
+ *   - drivers/nvme/host/pci.c|2552| <<nvme_reset_work>> nvme_dev_disable(dev, false);
+ *   - drivers/nvme/host/pci.c|2839| <<nvme_reset_prepare>> nvme_dev_disable(dev, false);
+ *   - drivers/nvme/host/pci.c|2851| <<nvme_shutdown>> nvme_dev_disable(dev, true);
+ *   - drivers/nvme/host/pci.c|2868| <<nvme_remove>> nvme_dev_disable(dev, true);
+ *   - drivers/nvme/host/pci.c|2875| <<nvme_remove>> nvme_dev_disable(dev, true);
+ *   - drivers/nvme/host/pci.c|2892| <<nvme_suspend>> nvme_dev_disable(ndev, true);
+ *   - drivers/nvme/host/pci.c|2924| <<nvme_error_detected>> nvme_dev_disable(dev, false);
+ */
 static void nvme_dev_disable(struct nvme_dev *dev, bool shutdown)
 {
 	bool dead = true;
@@ -2856,6 +2870,17 @@ static void nvme_shutdown(struct pci_dev *pdev)
  * state. This function must not have any dependencies on the device state in
  * order to proceed.
  */
+/*
+ * 调用的一个例子:
+ * [0] nvme_remove
+ * [0] pci_device_remove
+ * [0] device_release_driver_internal
+ * [0] nvme_remove_dead_ctrl_work
+ * [0] process_one_work
+ * [0] worker_thread
+ * [0] kthread
+ * [0] ret_from_fork
+ */
 static void nvme_remove(struct pci_dev *pdev)
 {
 	struct nvme_dev *dev = pci_get_drvdata(pdev);
diff --git a/include/linux/blk-mq.h b/include/linux/blk-mq.h
index b0c814b..71bb250 100644
--- a/include/linux/blk-mq.h
+++ b/include/linux/blk-mq.h
@@ -15,6 +15,14 @@ struct blk_flush_queue;
 struct blk_mq_hw_ctx {
 	struct {
 		spinlock_t		lock;
+		/*
+		 * 在以下插入新元素:
+		 *   - block/blk-mq-sched.c|189| <<blk_mq_sched_dispatch_requests>> list_splice_init(&hctx->dispatch, &rq_list);
+		 *   - block/blk-mq-sched.c|365| <<blk_mq_sched_bypass_insert>> list_add(&rq->queuelist, &hctx->dispatch);
+		 *   - block/blk-mq.c|1303| <<blk_mq_dispatch_rq_list>> list_splice_init(list, &hctx->dispatch);
+		 *   - block/blk-mq.c|1663| <<blk_mq_request_bypass_insert>> list_add_tail(&rq->queuelist, &hctx->dispatch);
+		 *   - block/blk-mq.c|2235| <<blk_mq_hctx_notify_dead>> list_splice_tail_init(&tmp, &hctx->dispatch);
+		 */
 		struct list_head	dispatch;
 		unsigned long		state;		/* BLK_MQ_S_* flags */
 	} ____cacheline_aligned_in_smp;
@@ -26,28 +34,83 @@ struct blk_mq_hw_ctx {
 
 	unsigned long		flags;		/* BLK_MQ_F_* flags */
 
+	/*
+	 * 设置sched_data的地方:
+	 *   - block/kyber-iosched.c|515| <<kyber_init_hctx>> hctx->sched_data = khd;
+	 */
 	void			*sched_data;
 	struct request_queue	*queue;
 	struct blk_flush_queue	*fq;
 
 	void			*driver_data;
 
+	/*
+	 * 在以下被使用:
+	 *   - block/blk-mq-debugfs.c|467| <<hctx_ctx_map_show>> sbitmap_bitmap_show(&hctx->ctx_map, m);
+	 *   - block/blk-mq-sched.c|142| <<blk_mq_do_dispatch_ctx>> if (!sbitmap_any_bit_set(&hctx->ctx_map))
+	 *   - block/blk-mq.c|67| <<blk_mq_hctx_has_pending>> sbitmap_any_bit_set(&hctx->ctx_map) ||
+	 *   - block/blk-mq.c|79| <<blk_mq_hctx_mark_pending>> if (!sbitmap_test_bit(&hctx->ctx_map, bit))
+	 *   - block/blk-mq.c|80| <<blk_mq_hctx_mark_pending>> sbitmap_set_bit(&hctx->ctx_map, bit);
+	 *   - block/blk-mq.c|88| <<blk_mq_hctx_clear_pending>> sbitmap_clear_bit(&hctx->ctx_map, bit);
+	 *   - block/blk-mq.c|991| <<blk_mq_flush_busy_ctxs>> sbitmap_for_each_set(&hctx->ctx_map, flush_busy_ctx, &data);
+	 *   - block/blk-mq.c|1029| <<blk_mq_dequeue_from_ctx>> __sbitmap_for_each_set(&hctx->ctx_map, off,
+	 *   - block/blk-mq.c|2267| <<blk_mq_exit_hctx>> sbitmap_free(&hctx->ctx_map);
+	 *   - block/blk-mq.c|2313| <<blk_mq_init_hctx>> if (sbitmap_init_node(&hctx->ctx_map, nr_cpu_ids, ilog2(8),
+	 *   - block/blk-mq.c|2346| <<blk_mq_init_hctx>> sbitmap_free(&hctx->ctx_map);
+	 *   - block/blk-mq.c|2512| <<blk_mq_map_swqueue>> sbitmap_resize(&hctx->ctx_map, hctx->nr_ctx);
+	 */
 	struct sbitmap		ctx_map;
 
+	/*
+	 * 用到dispatch_from的地方:
+	 *   - block/blk-mq-sched.c|137| <<blk_mq_do_dispatch_ctx>> struct blk_mq_ctx *ctx = READ_ONCE(hctx->dispatch_from);
+	 *   - block/blk-mq-sched.c|166| <<blk_mq_do_dispatch_ctx>> WRITE_ONCE(hctx->dispatch_from, ctx);
+	 *   - block/blk-mq.c|2428| <<blk_mq_map_swqueue>> hctx->dispatch_from = NULL;
+	 */
 	struct blk_mq_ctx	*dispatch_from;
+	/*
+	 * 修改dispatch_busy的地方:
+	 *   - block/blk-mq.c|1190| <<blk_mq_update_dispatch_busy>> hctx->dispatch_busy = ewma;
+	 */
 	unsigned int		dispatch_busy;
 
 	unsigned short		type;
+	/*
+	 * 在以下被修改:
+	 *   - block/blk-mq.c|2471| <<blk_mq_map_swqueue>> hctx->ctxs[hctx->nr_ctx++] = ctx;
+	 */
 	unsigned short		nr_ctx;
+	/*
+	 * 分配ctxs数组指针的地方:
+	 *   - block/blk-mq.c|2308| <<blk_mq_init_hctx>> hctx->ctxs = kmalloc_array_node(nr_cpu_ids, sizeof(void *),
+	 *
+	 * 设置每个指针元素的地方:
+	 *   - block/blk-mq.c|2471| <<blk_mq_map_swqueue>> hctx->ctxs[hctx->nr_ctx++] = ctx;
+	 */
 	struct blk_mq_ctx	**ctxs;
 
 	spinlock_t		dispatch_wait_lock;
 	wait_queue_entry_t	dispatch_wait;
 	atomic_t		wait_index;
 
+	/*
+	 * 在以下设置了tags:
+	 *   - block/blk-mq.c|2302| <<blk_mq_init_hctx>> hctx->tags = set->tags[hctx_idx];
+	 *   - block/blk-mq.c|2504| <<blk_mq_map_swqueue>> hctx->tags = set->tags[i];
+	 */
 	struct blk_mq_tags	*tags;
+	/*
+	 * 在以下分配:
+	 *   - block/blk-mq-sched.c|453| <<blk_mq_sched_alloc_tags>> hctx->sched_tags = blk_mq_alloc_rq_map(set, hctx_idx, q->nr_requests,
+	 */
 	struct blk_mq_tags	*sched_tags;
 
+	/*
+	 * 在以下进行使用:
+	 *   - block/blk-mq-debugfs.c|607| <<hctx_queued_show>> seq_printf(m, "%lu\n", hctx->queued);
+	 *   - block/blk-mq-debugfs.c|616| <<hctx_queued_write>> hctx->queued = 0;
+	 *   - block/blk-mq.c|418| <<blk_mq_get_request>> data->hctx->queued++;
+	 */
 	unsigned long		queued;
 	unsigned long		run;
 #define BLK_MQ_MAX_DISPATCH_ORDER	7
@@ -76,6 +139,9 @@ struct blk_mq_hw_ctx {
 };
 
 struct blk_mq_queue_map {
+	/*
+	 * 猜测是每一个sw queue对应的hw queue???
+	 */
 	unsigned int *mq_map;
 	unsigned int nr_queues;
 	unsigned int queue_offset;
@@ -216,15 +282,118 @@ struct blk_mq_ops {
 };
 
 enum {
+	/*
+	 * 下面的BLK_MQ_F_xxx只被blk_mq_tag_set->flags和blk_mq_hw_hctx->flags使用
+	 * blk_mq_init_hctx()中把blk_mq_tag_set->flags拷贝到blk_mq_hw_hctx->flags:
+	 *   - block/blk-mq.c|2402| <<blk_mq_init_hctx>> hctx->flags = set->flags & ~BLK_MQ_F_TAG_SHARED;
+	 */
+	/*
+	 * 主要使用的地方: 只被blk_mq_tag_set->flags和blk_mq_hw_hctx->flags使用 (0x1)
+	 *   - block/blk-mq-sched.c|334| <<__blk_mq_sched_bio_merge>> if ((hctx->flags & BLK_MQ_F_SHOULD_MERGE) &&
+	 *
+	 * 某些设置的地方: 只被blk_mq_tag_set->flags和blk_mq_hw_hctx->flags使用 (0x1)
+	 *   - drivers/block/loop.c|1954| <<loop_add>> lo->tag_set.flags = BLK_MQ_F_SHOULD_MERGE;
+	 *   - drivers/block/null_blk_main.c|1553| <<null_init_tag_set>> set->flags = BLK_MQ_F_SHOULD_MERGE;
+	 *   - drivers/block/virtio_blk.c|787| <<virtblk_probe>> vblk->tag_set.flags = BLK_MQ_F_SHOULD_MERGE;
+	 *   - drivers/block/xen-blkfront.c|980| <<xlvbd_init_blk_queue>> info->tag_set.flags = BLK_MQ_F_SHOULD_MERGE;
+	 *   - drivers/nvme/host/pci.c|2334| <<nvme_dev_add>> dev->tagset.flags = BLK_MQ_F_SHOULD_MERGE;
+	 *   - drivers/scsi/scsi_lib.c|1902| <<scsi_mq_setup_tags>> shost->tag_set.flags = BLK_MQ_F_SHOULD_MERGE;
+	 */
 	BLK_MQ_F_SHOULD_MERGE	= 1 << 0,
+	/*
+	 * 只被blk_mq_tag_set->flags和blk_mq_hw_hctx->flags使用 (0x2):
+	 *   - block/blk-mq-tag.c|79| <<hctx_may_queue>> if (!hctx || !(hctx->flags & BLK_MQ_F_TAG_SHARED))
+	 *   - block/blk-mq-tag.h|88| <<blk_mq_tag_busy>> if (!(hctx->flags & BLK_MQ_F_TAG_SHARED))
+	 *   - block/blk-mq-tag.h|96| <<blk_mq_tag_idle>> if (!(hctx->flags & BLK_MQ_F_TAG_SHARED))
+	 *   - block/blk-mq.c|305| <<blk_mq_rq_ctx_init>> if (data->hctx->flags & BLK_MQ_F_TAG_SHARED) {
+	 *   - block/blk-mq.c|1109| <<blk_mq_mark_tag_wait>> if (!(hctx->flags & BLK_MQ_F_TAG_SHARED)) {
+	 *   - block/blk-mq.c|1239| <<blk_mq_dispatch_rq_list>> if (hctx->flags & BLK_MQ_F_TAG_SHARED)
+	 *   - block/blk-mq.c|2298| <<blk_mq_init_hctx>> hctx->flags = set->flags & ~BLK_MQ_F_TAG_SHARED;
+	 *   - block/blk-mq.c|2533| <<queue_set_hctx_shared>> hctx->flags |= BLK_MQ_F_TAG_SHARED;
+	 *   - block/blk-mq.c|2535| <<queue_set_hctx_shared>> hctx->flags &= ~BLK_MQ_F_TAG_SHARED;
+	 *   - block/blk-mq.c|2561| <<blk_mq_del_queue_tag_set>> set->flags &= ~BLK_MQ_F_TAG_SHARED;
+	 *   - block/blk-mq.c|2578| <<blk_mq_add_queue_tag_set>> !(set->flags & BLK_MQ_F_TAG_SHARED)) {
+	 *   - block/blk-mq.c|2579| <<blk_mq_add_queue_tag_set>> set->flags |= BLK_MQ_F_TAG_SHARED;
+	 *   - block/blk-mq.c|2583| <<blk_mq_add_queue_tag_set>> if (set->flags & BLK_MQ_F_TAG_SHARED)
+	 *
+	 * 设置和删除的地方: 只被blk_mq_tag_set->flags和blk_mq_hw_hctx->flags使用 (0x1)
+	 *   - block/blk-mq.c|2544| <<queue_set_hctx_shared>> hctx->flags |= BLK_MQ_F_TAG_SHARED;
+	 *   - block/blk-mq.c|2590| <<blk_mq_add_queue_tag_set>> set->flags |= BLK_MQ_F_TAG_SHARED;
+	 *   - block/blk-mq.c|2309| <<blk_mq_init_hctx>> hctx->flags = set->flags & ~BLK_MQ_F_TAG_SHARED;
+	 *   - block/blk-mq.c|2546| <<queue_set_hctx_shared>> hctx->flags &= ~BLK_MQ_F_TAG_SHARED;
+	 *   - block/blk-mq.c|2572| <<blk_mq_del_queue_tag_set>> set->flags &= ~BLK_MQ_F_TAG_SHARED;
+	 */
 	BLK_MQ_F_TAG_SHARED	= 1 << 1,
+	/*
+	 * 会设置到BLK_MQ_F_BLOCKING的地方, 非常少: 只被blk_mq_tag_set->flags和blk_mq_hw_hctx->flags使用 (0x20)
+	 *   - block/bsg-lib.c|361| <<bsg_setup_queue>> set->flags = BLK_MQ_F_NO_SCHED | BLK_MQ_F_BLOCKING;
+	 *   - drivers/block/null_blk_main.c|1559| <<null_init_tag_set>> set->flags |= BLK_MQ_F_BLOCKING;
+	 *   - drivers/block/paride/pd.c|910| <<pd_probe_drive>> disk->tag_set.flags = BLK_MQ_F_SHOULD_MERGE | BLK_MQ_F_BLOCKING;
+	 *   - drivers/cdrom/gdrom.c|795| <<probe_gdrom>> BLK_MQ_F_SHOULD_MERGE | BLK_MQ_F_BLOCKING);
+	 *   - drivers/ide/ide-probe.c|785| <<ide_init_queue>> set->flags = BLK_MQ_F_SHOULD_MERGE | BLK_MQ_F_BLOCKING;
+	 *   - drivers/mmc/core/queue.c|413| <<mmc_init_queue>> mq->tag_set.flags = BLK_MQ_F_SHOULD_MERGE | BLK_MQ_F_BLOCKING;
+	 *   - drivers/mtd/mtd_blkdevs.c|448| <<add_mtd_blktrans_dev>> BLK_MQ_F_SHOULD_MERGE | BLK_MQ_F_BLOCKING);
+	 */
 	BLK_MQ_F_BLOCKING	= 1 << 5,
+	/*
+	 * 使用BLK_MQ_F_NO_SCHED的地方, 主要是第一个: 只被blk_mq_tag_set->flags和blk_mq_hw_hctx->flags使用 (0x40)
+	 *   - block/blk-mq.c|2891| <<blk_mq_init_allocated_queue>> if (!(set->flags & BLK_MQ_F_NO_SCHED)) {
+	 *   - block/elevator.c|691| <<elv_support_iosched>> if (q->tag_set && (q->tag_set->flags & BLK_MQ_F_NO_SCHED))
+	 *
+	 * 设置BLK_MQ_F_NO_SCHED的地方: 只被blk_mq_tag_set->flags和blk_mq_hw_hctx->flags使用 (0x40)
+	 *   - block/bsg-lib.c|361| <<bsg_setup_queue>> set->flags = BLK_MQ_F_NO_SCHED | BLK_MQ_F_BLOCKING;
+	 *   - drivers/block/null_blk_main.c|1555| <<null_init_tag_set>> set->flags |= BLK_MQ_F_NO_SCHED;
+	 *   - drivers/nvme/host/fc.c|3057| <<nvme_fc_init_ctrl>> ctrl->admin_tag_set.flags = BLK_MQ_F_NO_SCHED;
+	 *   - drivers/nvme/host/pci.c|1643| <<nvme_alloc_admin_tags>> dev->admin_tagset.flags = BLK_MQ_F_NO_SCHED;
+	 *   - drivers/nvme/host/rdma.c|728| <<nvme_rdma_alloc_tagset>> set->flags = BLK_MQ_F_NO_SCHED;
+	 *   - drivers/nvme/target/loop.c|363| <<nvme_loop_configure_admin_queue>> ctrl->admin_tag_set.flags = BLK_MQ_F_NO_SCHED;
+	 */
 	BLK_MQ_F_NO_SCHED	= 1 << 6,
+	/*
+	 * 只在下面使用:
+	 *   - include/linux/blk-mq.h|394| <<BLK_MQ_FLAG_TO_ALLOC_POLICY>> ((flags >> BLK_MQ_F_ALLOC_POLICY_START_BIT) & \
+	 *   - include/linux/blk-mq.h|398| <<BLK_ALLOC_POLICY_TO_MQ_FLAG>> << BLK_MQ_F_ALLOC_POLICY_START_BIT)
+	 */
 	BLK_MQ_F_ALLOC_POLICY_START_BIT = 8,
+	/*
+	 * 只在下面使用:
+	 *   - include/linux/blk-mq.h|395| <<BLK_MQ_FLAG_TO_ALLOC_POLICY>> ((1 << BLK_MQ_F_ALLOC_POLICY_BITS) - 1))
+	 *   - include/linux/blk-mq.h|397| <<BLK_ALLOC_POLICY_TO_MQ_FLAG>> ((policy & ((1 << BLK_MQ_F_ALLOC_POLICY_BITS) - 1)) \
+	 */
 	BLK_MQ_F_ALLOC_POLICY_BITS = 1,
 
+	/*
+	 * BLK_MQ_S_xxx只用在blk_mq_hw_ctx->state
+	 */
+	/*
+	 * 在以下被使用:
+	 *   - block/blk-mq.c|1550| <<blk_mq_stop_hw_queue>> set_bit(BLK_MQ_S_STOPPED, &hctx->state);
+	 *   - block/blk-mq.c|1575| <<blk_mq_start_hw_queue>> clear_bit(BLK_MQ_S_STOPPED, &hctx->state);
+	 *   - block/blk-mq.c|1596| <<blk_mq_start_stopped_hw_queue>> clear_bit(BLK_MQ_S_STOPPED, &hctx->state);
+	 *   - block/blk-mq.c|1620| <<blk_mq_run_work_fn>> if (test_bit(BLK_MQ_S_STOPPED, &hctx->state))
+	 *   - block/blk-mq.h|184| <<blk_mq_hctx_stopped>> return test_bit(BLK_MQ_S_STOPPED, &hctx->state);
+	 */
 	BLK_MQ_S_STOPPED	= 0,
+	/*
+	 * 在以下被使用:
+	 *   - block/blk-mq-tag.c|32| <<__blk_mq_tag_busy>> if (!test_bit(BLK_MQ_S_TAG_ACTIVE, &hctx->state) &&
+	 *   - block/blk-mq-tag.c|33| <<__blk_mq_tag_busy>> !test_and_set_bit(BLK_MQ_S_TAG_ACTIVE, &hctx->state))
+	 *   - block/blk-mq-tag.c|57| <<__blk_mq_tag_idle>> if (!test_and_clear_bit(BLK_MQ_S_TAG_ACTIVE, &hctx->state))
+	 *   - block/blk-mq-tag.c|76| <<hctx_may_queue>> if (!test_bit(BLK_MQ_S_TAG_ACTIVE, &hctx->state))
+	 */
 	BLK_MQ_S_TAG_ACTIVE	= 1,
+	/*
+	 * 在以下使用:
+	 *   - block/blk-mq-sched.c|66| <<blk_mq_sched_mark_restart_hctx>> if (test_bit(BLK_MQ_S_SCHED_RESTART, &hctx->state))
+	 *   - block/blk-mq-sched.c|69| <<blk_mq_sched_mark_restart_hctx>> set_bit(BLK_MQ_S_SCHED_RESTART, &hctx->state);
+	 *   - block/blk-mq-sched.c|75| <<blk_mq_sched_restart>> if (!test_bit(BLK_MQ_S_SCHED_RESTART, &hctx->state))
+	 *   - block/blk-mq-sched.c|77| <<blk_mq_sched_restart>> clear_bit(BLK_MQ_S_SCHED_RESTART, &hctx->state);
+	 *   - block/blk-mq-sched.h|91| <<blk_mq_sched_needs_restart>> return test_bit(BLK_MQ_S_SCHED_RESTART, &hctx->state);
+	 *   - block/blk-mq.c|1110| <<blk_mq_mark_tag_wait>> if (!test_bit(BLK_MQ_S_SCHED_RESTART, &hctx->state))
+	 *   - block/blk-mq.c|1111| <<blk_mq_mark_tag_wait>> set_bit(BLK_MQ_S_SCHED_RESTART, &hctx->state);
+	 *
+	 * 用来触发blk_mq_run_hw_queue()
+	 */
 	BLK_MQ_S_SCHED_RESTART	= 2,
 
 	BLK_MQ_MAX_DEPTH	= 10240,
@@ -264,6 +433,15 @@ enum {
 	/* allocate from reserved pool */
 	BLK_MQ_REQ_RESERVED	= (__force blk_mq_req_flags_t)(1 << 1),
 	/* allocate internal/sched tag */
+	/*
+	 * 在以下被设置:
+	 *   - block/blk-mq.c|372| <<blk_mq_get_request>> data->flags |= BLK_MQ_REQ_INTERNAL;
+	 *
+	 * 在以下被使用:
+	 *   - block/blk-mq-tag.c|104| <<__blk_mq_get_tag>> if (!(data->flags & BLK_MQ_REQ_INTERNAL) &&
+	 *   - block/blk-mq.c|297| <<blk_mq_rq_ctx_init>> if (data->flags & BLK_MQ_REQ_INTERNAL) {
+	 *   - block/blk-mq.h|176| <<blk_mq_tags_from_data>> if (data->flags & BLK_MQ_REQ_INTERNAL)
+	 */
 	BLK_MQ_REQ_INTERNAL	= (__force blk_mq_req_flags_t)(1 << 2),
 	/* set RQF_PREEMPT */
 	BLK_MQ_REQ_PREEMPT	= (__force blk_mq_req_flags_t)(1 << 3),
diff --git a/include/linux/blkdev.h b/include/linux/blkdev.h
index faed9d9..62b2f4e 100644
--- a/include/linux/blkdev.h
+++ b/include/linux/blkdev.h
@@ -115,8 +115,33 @@ typedef __u32 __bitwise req_flags_t;
  * Request state for blk-mq.
  */
 enum mq_rq_state {
+	/*
+	 * 设置的地方:
+	 *   - block/blk-mq.c|536| <<blk_mq_free_request>> WRITE_ONCE(rq->state, MQ_RQ_IDLE);
+	 *   - block/blk-mq.c|719| <<__blk_mq_requeue_request>> WRITE_ONCE(rq->state, MQ_RQ_IDLE);
+	 *   - block/blk-mq.c|2127| <<blk_mq_init_request>> WRITE_ONCE(rq->state, MQ_RQ_IDLE);
+	 *
+	 * 使用的地方:
+	 *   - block/blk-mq.c|672| <<blk_mq_request_started>> return blk_mq_rq_state(rq) != MQ_RQ_IDLE;
+	 *   - block/blk-mq.c|693| <<blk_mq_start_request>> WARN_ON_ONCE(blk_mq_rq_state(rq) != MQ_RQ_IDLE);
+	 */
 	MQ_RQ_IDLE		= 0,
+	/*
+	 * 设置的地方:
+	 *   - block/blk-mq.c|696| <<blk_mq_start_request>> WRITE_ONCE(rq->state, MQ_RQ_IN_FLIGHT);
+	 *
+	 * 使用的地方:
+	 *   - block/blk-mq.c|825| <<blk_mq_rq_inflight>> if (rq->state == MQ_RQ_IN_FLIGHT && rq->q == hctx->queue) {
+	 *   - block/blk-mq.c|863| <<blk_mq_req_expired>> if (blk_mq_rq_state(rq) != MQ_RQ_IN_FLIGHT)
+	 */
 	MQ_RQ_IN_FLIGHT		= 1,
+	/*
+	 * 设置的地方:
+	 *   - block/blk-mq.c|593| <<__blk_mq_complete_request>> WRITE_ONCE(rq->state, MQ_RQ_COMPLETE);
+	 *
+	 * 使用的地方:
+	 *   - block/blk-mq.c|3389| <<blk_mq_poll_hybrid_sleep>> if (blk_mq_rq_state(rq) == MQ_RQ_COMPLETE)
+	 */
 	MQ_RQ_COMPLETE		= 2,
 };
 
@@ -128,12 +153,31 @@ enum mq_rq_state {
  */
 struct request {
 	struct request_queue *q;
+	/*
+	 * 在以下设置:
+	 *   - block/blk-flush.c|297| <<blk_kick_flush>> flush_rq->mq_ctx = first_rq->mq_ctx;
+	 *   - block/blk-mq.c|316| <<blk_mq_rq_ctx_init>> rq->mq_ctx = data->ctx;
+	 */
 	struct blk_mq_ctx *mq_ctx;
+	/*
+	 * 在以下设置:
+	 *   - block/blk-flush.c|298| <<blk_kick_flush>> flush_rq->mq_hctx = first_rq->mq_hctx;
+	 *   - block/blk-mq.c|317| <<blk_mq_rq_ctx_init>> rq->mq_hctx = data->hctx;
+	 *   - block/blk-mq.c|502| <<__blk_mq_free_request>> rq->mq_hctx = NULL;
+	 */
 	struct blk_mq_hw_ctx *mq_hctx;
 
 	unsigned int cmd_flags;		/* op and common flags */
 	req_flags_t rq_flags;
 
+	/*
+	 * 在以下修改:
+	 *   - block/blk-core.c|116| <<blk_rq_init>> rq->internal_tag = -1;
+	 *   - block/blk-flush.c|224| <<flush_end_io>> flush_rq->internal_tag = -1;
+	 *   - block/blk-flush.c|305| <<blk_kick_flush>> flush_rq->internal_tag = first_rq->internal_tag;
+	 *   - block/blk-mq.c|303| <<blk_mq_rq_ctx_init>> rq->internal_tag = tag;
+	 *   - block/blk-mq.c|310| <<blk_mq_rq_ctx_init>> rq->internal_tag = -1;
+	 */
 	int internal_tag;
 
 	/* the following two fields are internal, NEVER access directly */
@@ -317,9 +361,34 @@ struct queue_limits {
 	unsigned long		seg_boundary_mask;
 	unsigned long		virt_boundary_mask;
 
+	/*
+	 * max_hw_sectors和max_sectors设置的地方主要是blk_queue_max_hw_sectors()
+	 *
+	 * 调用blk_queue_max_hw_sectors()的地方很多, 例子是:
+	 *   - drivers/block/xen-blkfront.c|947| <<blkif_set_queue_limits>> blk_queue_max_hw_sectors(rq, (segments * XEN_PAGE_SIZE) / 512);
+	 *   - drivers/block/virtio_blk.c|827| <<virtblk_probe>> blk_queue_max_hw_sectors(q, -1U);
+	 *   - drivers/nvme/host/core.c|1972| <<nvme_set_queue_limits>> blk_queue_max_hw_sectors(q, ctrl->max_hw_sectors);
+	 *   - drivers/block/loop.c|1968| <<loop_add>> blk_queue_max_hw_sectors(lo->lo_queue, BLK_DEF_MAX_SECTORS);
+	 */
 	unsigned int		max_hw_sectors;
+	/*
+	 * max_dev_sectors在以下被修改:
+	 *   - block/blk-settings.c|54| <<blk_set_default_limits>> lim->max_dev_sectors = 0;
+	 *   - block/blk-settings.c|90| <<blk_set_stacking_limits>> lim->max_dev_sectors = UINT_MAX;
+	 *   - block/blk-settings.c|526| <<blk_stack_limits>> t->max_dev_sectors = min_not_zero(t->max_dev_sectors, b->max_dev_sectors);
+	 *   - drivers/s390/block/dasd.c|3155| <<dasd_setup_queue>> q->limits.max_dev_sectors = max;
+	 *   - drivers/scsi/sd.c|3120| <<sd_revalidate_disk>> q->limits.max_dev_sectors = logical_to_sectors(sdp, dev_max);
+	 */
 	unsigned int		max_dev_sectors;
 	unsigned int		chunk_sectors;
+	/*
+	 * 设置max_sectors的地方:
+	 *   - block/blk-settings.c|53| <<blk_set_default_limits>> lim->max_sectors = lim->max_hw_sectors = BLK_SAFE_MAX_SECTORS;
+	 *   - block/blk-settings.c|89| <<blk_set_stacking_limits>> lim->max_sectors = UINT_MAX;
+	 *   - block/blk-settings.c|211| <<blk_queue_max_hw_sectors>> limits->max_sectors = max_sectors;
+	 *   - block/blk-settings.c|524| <<blk_stack_limits>> t->max_sectors = min_not_zero(t->max_sectors, b->max_sectors);
+	 *   - block/blk-sysfs.c|239| <<queue_max_sectors_store>> q->limits.max_sectors = max_sectors_kb << 1;
+	 */
 	unsigned int		max_sectors;
 	unsigned int		max_segment_size;
 	unsigned int		physical_block_size;
-- 
2.7.4

