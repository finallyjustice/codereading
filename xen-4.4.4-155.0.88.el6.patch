From b5e8e304f5275060e046e62e9d196c4625a6885c Mon Sep 17 00:00:00 2001
From: Dongli Zhang <dongli.zhang0129@gmail.com>
Date: Tue, 22 Dec 2020 10:18:19 -0800
Subject: [PATCH 1/1] xen-4.4.4-155.0.88.el6-kdump

xen-4.4.4-155.0.88

Signed-off-by: Dongli Zhang <dongli.zhang0129@gmail.com>
---
 xen/arch/x86/cpu/mcheck/mcaction.c    |   4 +
 xen/arch/x86/cpu/mcheck/mce.c         |  59 ++++++
 xen/arch/x86/cpu/mcheck/mce_intel.c   |  13 ++
 xen/arch/x86/cpu/mcheck/mctelem.c     |   9 +
 xen/arch/x86/cpu/mcheck/vmce.c        |   4 +
 xen/arch/x86/domain.c                 |   7 +
 xen/arch/x86/mm/p2m.c                 |  15 ++
 xen/common/page_alloc.c               | 246 ++++++++++++++++++++++++++
 xen/include/asm-x86/mm.h              |  56 ++++++
 xen/include/asm-x86/p2m.h             |  10 ++
 xen/include/public/arch-x86/xen-mca.h |   9 +
 xen/include/xen/mm.h                  |  28 +++
 12 files changed, 460 insertions(+)

diff --git a/xen/arch/x86/cpu/mcheck/mcaction.c b/xen/arch/x86/cpu/mcheck/mcaction.c
index 9cf2499b3b..2572a8e276 100644
--- a/xen/arch/x86/cpu/mcheck/mcaction.c
+++ b/xen/arch/x86/cpu/mcheck/mcaction.c
@@ -35,6 +35,10 @@ void mce_register_addrcheck(mce_check_addr_t cbfunc)
     mc_check_addr = cbfunc;
 }
 
+/*
+ * called by:
+ *   - arch/x86/cpu/mcheck/mce_intel.c|272| <<intel_memerr_dhandler>> mc_memerr_dhandler(binfo, result, regs);
+ */
 void
 mc_memerr_dhandler(struct mca_binfo *binfo,
                    enum mce_result *result,
diff --git a/xen/arch/x86/cpu/mcheck/mce.c b/xen/arch/x86/cpu/mcheck/mce.c
index 741a5d6742..e4b415127a 100644
--- a/xen/arch/x86/cpu/mcheck/mce.c
+++ b/xen/arch/x86/cpu/mcheck/mce.c
@@ -58,6 +58,11 @@ static int x86_mcerr(const char *msg, int err)
 #define x86_mcerr(msg, err) (err)
 #endif
 
+/*
+ * 在以下使用mce_verbosity:
+ *   - arch/x86/cpu/mcheck/mce.c|65| <<mce_set_verbosity>> mce_verbosity = MCE_VERBOSE;
+ *   - arch/x86/cpu/mcheck/mce.h|28| <<mce_printk>> if ((v) <= mce_verbosity) \
+ */
 int mce_verbosity;
 static void __init mce_set_verbosity(char *str)
 {
@@ -182,6 +187,14 @@ static struct mce_softirq_barrier mce_trap_bar;
  */
 static DEFINE_SPINLOCK(mce_logout_lock);
 
+/*
+ * 在以下使用severity_cpu:
+ *   - arch/x86/cpu/mcheck/mce.c|508| <<mcheck_cmn_handler>> atomic_set(&severity_cpu, smp_processor_id());
+ *   - arch/x86/cpu/mcheck/mce.c|529| <<mcheck_cmn_handler>> if (atomic_read(&severity_cpu) == smp_processor_id())
+ *   - arch/x86/cpu/mcheck/mce.c|1706| <<mce_softirq>> atomic_set(&severity_cpu, cpu);
+ *   - arch/x86/cpu/mcheck/mce.c|1710| <<mce_softirq>> atomic_set(&severity_cpu, cpu);
+ *   - arch/x86/cpu/mcheck/mce.c|1714| <<mce_softirq>> if (atomic_read(&severity_cpu) == cpu) {
+ */
 static atomic_t severity_cpu = ATOMIC_INIT(-1);
 static atomic_t found_error = ATOMIC_INIT(0);
 static cpumask_t mce_fatal_cpus;
@@ -431,6 +444,10 @@ static enum mce_result mce_action(const struct cpu_user_regs *regs,
  * -1: if system can't be recovered
  * 0: Continue to next step
  */
+/*
+ * called by:
+ *   - arch/x86/cpu/mcheck/mce.c|529| <<mcheck_cmn_handler>> if ( mctc != NULL && mce_urgent_action(regs, mctc))
+ */
 static int mce_urgent_action(const struct cpu_user_regs *regs,
                               mctelem_cookie_t mctc)
 {
@@ -458,6 +475,11 @@ static int mce_urgent_action(const struct cpu_user_regs *regs,
 }
 
 /* Shared #MC handler. */
+/*
+ * called by:
+ *   - arch/x86/cpu/mcheck/amd_k8.c|75| <<k8_machine_check>> mcheck_cmn_handler(regs, error_code, mca_allbanks,
+ *   - arch/x86/cpu/mcheck/mce_intel.c|402| <<intel_machine_check>> mcheck_cmn_handler(regs, error_code, mca_allbanks,
+ */
 void mcheck_cmn_handler(const struct cpu_user_regs *regs, long error_code,
     struct mca_banks *bankmask, struct mca_banks *clear_bank)
 {
@@ -544,6 +566,10 @@ void mcheck_cmn_handler(const struct cpu_user_regs *regs, long error_code,
     }
     mce_barrier_exit(&mce_trap_bar);
 
+    /*
+     * 在以下定义MACHINE_CHECK_SOFTIRQ:
+     *   - arch/x86/cpu/mcheck/mce.c|1760| <<mce_handler_init>> open_softirq(MACHINE_CHECK_SOFTIRQ, mce_softirq);
+     */
     raise_softirq(MACHINE_CHECK_SOFTIRQ);
 }
 
@@ -1567,6 +1593,11 @@ void mc_panic(char *s)
  */
 
 /* Maybe called in MCE context, no lock, no printk */
+/*
+ * called by:
+ *   - arch/x86/cpu/mcheck/mce.c|470| <<mce_urgent_action>> return mce_action(regs, mctc) == MCER_RESET ? -1 : 0;
+ *   - arch/x86/cpu/mcheck/mce.c|1665| <<mce_delayed_action>> result = mce_action(NULL, mctc);
+ */
 static enum mce_result mce_action(const struct cpu_user_regs *regs,
                       mctelem_cookie_t mctc)
 {
@@ -1631,6 +1662,10 @@ static enum mce_result mce_action(const struct cpu_user_regs *regs,
  * should be committed for dom0 consumption, 0 if it should be
  * dismissed.
  */
+/*
+ * called by:
+ *   - arch/x86/cpu/mcheck/mce.c|1718| <<mce_softirq>> mctelem_process_deferred(workcpu, mce_delayed_action);
+ */
 static int mce_delayed_action(mctelem_cookie_t mctc)
 {
     enum mce_result result;
@@ -1664,6 +1699,13 @@ static int mce_delayed_action(mctelem_cookie_t mctc)
 }
 
 /* Softirq Handler for this MCE# processing */
+/*
+ * 在以下调用MACHINE_CHECK_SOFTIRQ:
+ *   - arch/x86/cpu/mcheck/mce.c|552| <<mcheck_cmn_handler>> raise_softirq(MACHINE_CHECK_SOFTIRQ);
+ *
+ * 在以下使用mce_softirq():
+ *   - arch/x86/cpu/mcheck/mce.c|1744| <<mce_handler_init>> open_softirq(MACHINE_CHECK_SOFTIRQ, mce_softirq);
+ */
 static void mce_softirq(void)
 {
     int cpu = smp_processor_id();
@@ -1682,6 +1724,14 @@ static void mce_softirq(void)
      * will overwrite the value and become the default.
      */
 
+    /*
+     * 在以下使用severity_cpu:
+     *   - arch/x86/cpu/mcheck/mce.c|508| <<mcheck_cmn_handler>> atomic_set(&severity_cpu, smp_processor_id());
+     *   - arch/x86/cpu/mcheck/mce.c|529| <<mcheck_cmn_handler>> if (atomic_read(&severity_cpu) == smp_processor_id())
+     *   - arch/x86/cpu/mcheck/mce.c|1706| <<mce_softirq>> atomic_set(&severity_cpu, cpu);
+     *   - arch/x86/cpu/mcheck/mce.c|1710| <<mce_softirq>> atomic_set(&severity_cpu, cpu);
+     *   - arch/x86/cpu/mcheck/mce.c|1714| <<mce_softirq>> if (atomic_read(&severity_cpu) == cpu) {
+     */
     atomic_set(&severity_cpu, cpu);
 
     mce_barrier_enter(&mce_severity_bar);
@@ -1704,6 +1754,15 @@ static void mce_softirq(void)
         /* Step2: Send Log to DOM0 through vIRQ */
         if (dom0_vmce_enabled()) {
             mce_printk(MCE_VERBOSE, "MCE: send MCE# to DOM0 through virq\n");
+	    /*
+	     * 在以下使用VIRQ_MCA:
+	     *   - arch/x86/cpu/mcheck/amd_nonfatal.c|104| <<mce_amd_checkregs>> send_global_virq(VIRQ_MCA);
+	     *   - arch/x86/cpu/mcheck/mce.c|1712| <<mce_softirq>> send_global_virq(VIRQ_MCA);
+	     *   - arch/x86/cpu/mcheck/mce_intel.c|558| <<cmci_discover>> send_global_virq(VIRQ_MCA);
+	     *   - arch/x86/cpu/mcheck/mce_intel.c|646| <<cmci_interrupt>> send_global_virq(VIRQ_MCA);
+	     *   - arch/x86/cpu/mcheck/non-fatal.c|58| <<mce_checkregs>> send_global_virq(VIRQ_MCA);
+	     *   - arch/x86/cpu/mcheck/vmce.h|9| <<dom0_vmce_enabled>> && guest_enabled_event(dom0->vcpu[0], VIRQ_MCA))
+	     */
             send_global_virq(VIRQ_MCA);
         }
     }
diff --git a/xen/arch/x86/cpu/mcheck/mce_intel.c b/xen/arch/x86/cpu/mcheck/mce_intel.c
index bb4ce47ef9..fca2efda0c 100644
--- a/xen/arch/x86/cpu/mcheck/mce_intel.c
+++ b/xen/arch/x86/cpu/mcheck/mce_intel.c
@@ -263,6 +263,11 @@ static enum intel_mce_type intel_check_mce_type(uint64_t status)
     return intel_mce_fatal;
 }
 
+/*
+ * called by:
+ *   - arch/x86/cpu/mcheck/mce_intel.c|307| <<intel_srar_dhandler>> intel_memerr_dhandler(binfo, result, regs);
+ *   - arch/x86/cpu/mcheck/mce_intel.c|335| <<intel_srao_dhandler>> intel_memerr_dhandler(binfo, result, regs);
+ */
 static void intel_memerr_dhandler(
              struct mca_binfo *binfo,
              enum mce_result *result,
@@ -392,6 +397,10 @@ static const struct mca_error_handler intel_mce_uhandlers[] = {
     {intel_default_check, intel_default_mce_uhandler}
 };
 
+/*
+ * called by:
+ *   - arch/x86/cpu/mcheck/mce_intel.c|788| <<intel_init_mce>> x86_mce_vector_register(intel_machine_check);
+ */
 static void intel_machine_check(const struct cpu_user_regs * regs, long error_code)
 {
     mcheck_cmn_handler(regs, error_code, mca_allbanks,
@@ -756,6 +765,10 @@ static void intel_mce_post_reset(void)
     return;
 }
 
+/*
+ * called by:
+ *   - arch/x86/cpu/mcheck/mce_intel.c|873| <<intel_mcheck_init>> intel_init_mce();
+ */
 static void intel_init_mce(void)
 {
     uint64_t msr_content;
diff --git a/xen/arch/x86/cpu/mcheck/mctelem.c b/xen/arch/x86/cpu/mcheck/mctelem.c
index ed8e8d20b7..d68fa38689 100644
--- a/xen/arch/x86/cpu/mcheck/mctelem.c
+++ b/xen/arch/x86/cpu/mcheck/mctelem.c
@@ -142,6 +142,11 @@ void mctelem_defer(mctelem_cookie_t cookie)
 	mctelem_xchg_head(&this_cpu(mctctl.pending), &tep->mcte_next, tep);
 }
 
+/*
+ * called by:
+ *   - arch/x86/cpu/mcheck/mce.c|1545| <<mc_panic_dump>> mctelem_process_deferred(cpu, x86_mcinfo_dump_panic);
+ *   - arch/x86/cpu/mcheck/mce.c|1722| <<mce_softirq>> mctelem_process_deferred(workcpu, mce_delayed_action);
+ */
 void mctelem_process_deferred(unsigned int cpu,
 			      int (*fn)(mctelem_cookie_t))
 {
@@ -179,6 +184,10 @@ void mctelem_process_deferred(unsigned int cpu,
 		prev = tep->mcte_prev;
 		tep->mcte_next = tep->mcte_prev = NULL;
 
+		/*
+		 * !!!! 这里调用 fn() !!!!
+		 * x86_mcinfo_dump_panic() 或者 mce_delayed_action()
+		 */
 		ret = fn(MCTE2COOKIE(tep));
 		if (prev != NULL)
 			prev->mcte_next = NULL;
diff --git a/xen/arch/x86/cpu/mcheck/vmce.c b/xen/arch/x86/cpu/mcheck/vmce.c
index dcfe97ed7e..91cae6a24c 100644
--- a/xen/arch/x86/cpu/mcheck/vmce.c
+++ b/xen/arch/x86/cpu/mcheck/vmce.c
@@ -430,6 +430,10 @@ int fill_vmsr_data(struct mcinfo_bank *mc_bank, struct domain *d,
  * XXX following situation missed:
  * PoD, Foreign mapped, Granted, Shared
  */
+/*
+ * called by:
+ *   - arch/x86/cpu/mcheck/mcaction.c|90| <<mc_memerr_dhandler>> if ( unmmap_broken_page(d, _mfn(mfn), gfn) )
+ */
 int unmmap_broken_page(struct domain *d, mfn_t mfn, unsigned long gfn)
 {
     mfn_t r_mfn;
diff --git a/xen/arch/x86/domain.c b/xen/arch/x86/domain.c
index 8acc0c7d0c..abb69b3eb7 100644
--- a/xen/arch/x86/domain.c
+++ b/xen/arch/x86/domain.c
@@ -1983,6 +1983,13 @@ int hypercall_xlat_continuation(unsigned int *id, unsigned int nr,
     return rc;
 }
 
+/*
+ * called by:
+ *   - arch/x86/domain.c|2168| <<domain_relinquish_resources>> ret = relinquish_memory(d, &d->xenpage_list, ~0UL);
+ *   - arch/x86/domain.c|2175| <<domain_relinquish_resources>> ret = relinquish_memory(d, &d->page_list, PGT_l4_page_table);
+ *   - arch/x86/domain.c|2182| <<domain_relinquish_resources>> ret = relinquish_memory(d, &d->page_list, PGT_l3_page_table);
+ *   - arch/x86/domain.c|2189| <<domain_relinquish_resources>> ret = relinquish_memory(d, &d->page_list, PGT_l2_page_table);
+ */
 static int relinquish_memory(
     struct domain *d, struct page_list_head *list, unsigned long type)
 {
diff --git a/xen/arch/x86/mm/p2m.c b/xen/arch/x86/mm/p2m.c
index b2d1e42abe..c7ce9e11c0 100644
--- a/xen/arch/x86/mm/p2m.c
+++ b/xen/arch/x86/mm/p2m.c
@@ -206,6 +206,14 @@ void p2m_change_entry_type_global(struct domain *d,
     p2m_unlock(p2m);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/svm/svm.c|1385| <<svm_do_nested_pgfault>> mfn = __get_gfn_type_access(p2m, gfn, &_d.p2mt, &p2ma, 0, NULL, 0);
+ *   - arch/x86/hvm/svm/svm.c|1406| <<svm_do_nested_pgfault>> mfn = __get_gfn_type_access(p2m, gfn, &p2mt, &p2ma, 0, NULL, 0);
+ *   - arch/x86/mm/p2m.c|283| <<get_page_from_gfn_p2m>> mfn = __get_gfn_type_access(p2m, gfn, t, a, 0, NULL, 0);
+ *   - include/asm-x86/p2m.h|345| <<get_gfn_type_access>> __get_gfn_type_access((p), (g), (t), (a), (q), (o), 1)
+ *   - include/asm-x86/p2m.h|389| <<get_gfn_query_unlocked>> return __get_gfn_type_access(p2m_get_hostp2m(d), gfn, t, &a, 0, NULL, 0);
+ */
 mfn_t __get_gfn_type_access(struct p2m_domain *p2m, unsigned long gfn,
                     p2m_type_t *t, p2m_access_t *a, p2m_query_t q,
                     unsigned int *page_order, bool_t locked)
@@ -263,6 +271,13 @@ void __put_gfn(struct p2m_domain *p2m, unsigned long gfn)
 }
 
 /* Atomically look up a GFN and take a reference count on the backing page. */
+/*
+ * called by:
+ *   - arch/x86/mm/guest_walk.c|107| <<map_domain_gfn>> page = get_page_from_gfn_p2m(p2m->domain, p2m, gfn_x(gfn), p2mt, NULL,
+ *   - arch/x86/mm/hap/guest_walk.c|65| <<hap_p2m_ga_to_gfn>> top_page = get_page_from_gfn_p2m(p2m->domain, p2m, top_gfn,
+ *   - arch/x86/mm/hap/guest_walk.c|105| <<hap_p2m_ga_to_gfn>> page = get_page_from_gfn_p2m(p2m->domain, p2m, gfn_x(gfn), &p2mt,
+ *   - include/asm-x86/p2m.h|409| <<get_page_from_gfn>> return get_page_from_gfn_p2m(d, p2m_get_hostp2m(d), gfn, t, NULL, q);
+ */
 struct page_info *get_page_from_gfn_p2m(
     struct domain *d, struct p2m_domain *p2m, unsigned long gfn,
     p2m_type_t *t, p2m_access_t *a, p2m_query_t q)
diff --git a/xen/common/page_alloc.c b/xen/common/page_alloc.c
index 95db602e7c..80c1c6eb22 100644
--- a/xen/common/page_alloc.c
+++ b/xen/common/page_alloc.c
@@ -83,8 +83,17 @@ integer_param("dma_bits", dma_bitsize);
 
 static DEFINE_SPINLOCK(pglist_lock);
 /* Offlined page list, protected by pglist_lock. */
+/*
+ * 在以下使用page_offlined_list:
+ *   - common/page_alloc.c|949| <<reserve_offlined_page>> &page_broken_list : &page_offlined_list);
+ *   - common/page_alloc.c|1318| <<online_page>> page_list_del(pg, &page_offlined_list);
+ */
 static PAGE_LIST_HEAD(page_offlined_list);
 /* Broken page list, protected by pglist_lock. */
+/*
+ * 在以下使用page_broken_list:
+ *   - common/page_alloc.c|949| <<reserve_offlined_page>> &page_broken_list : &page_offlined_list);
+ */
 static PAGE_LIST_HEAD(page_broken_list);
 
 /* A rough flag to indicate whether a node have need_scrub pages */
@@ -287,11 +296,40 @@ unsigned long __init alloc_boot_pages(
 #define page_to_zone(pg) (is_xen_heap_page(pg) ? MEMZONE_XEN :  \
                           (flsl(page_to_mfn(pg)) ? : 1))
 
+/*
+ * struct page_list_head
+ * {
+ *     struct page_info *next, *tail;
+ * };
+ */
 typedef struct page_list_head heap_by_zone_and_order_t[NR_ZONES][MAX_ORDER+1];
+/*
+ * 这是一个数组, 每个数组是一个指针
+ * 指向typedef struct page_list_head heap_by_zone_and_order_t[NR_ZONES][MAX_ORDER+1];
+ */
 static heap_by_zone_and_order_t *_heap[MAX_NUMNODES];
+/*
+ * 返回的是struct page_list_head(不是指针)
+ */
 #define heap(node, zone, order) ((*_heap[node])[zone][order])
 
 static unsigned long *avail[MAX_NUMNODES];
+/*
+ * 在以下修改total_avail_pages:
+ *   - common/page_alloc.c|724| <<alloc_heap_pages>> total_avail_pages -= request;
+ *   - common/page_alloc.c|701| <<alloc_heap_pages>> total_avail_pages + tmem_freeable_pages()) &&
+ *   - common/page_alloc.c|793| <<alloc_heap_pages>> total_avail_pages += request;
+ *   - common/page_alloc.c|951| <<reserve_offlined_page>> total_avail_pages--;
+ *   - common/page_alloc.c|1111| <<free_heap_pages>> total_avail_pages += 1 << order;
+ * 在以下使用total_avail_pages:
+ *   - common/page_alloc.c|424| <<domain_set_outstanding_pages>> avail_pages = total_avail_pages;
+ *   - common/page_alloc.c|591| <<setup_low_mem_virq>> ((paddr_t) total_avail_pages) << PAGE_SHIFT);
+ *   - common/page_alloc.c|599| <<setup_low_mem_virq>> (threshold == (((paddr_t) total_avail_pages) << PAGE_SHIFT)) )
+ *   - common/page_alloc.c|716| <<alloc_heap_pages>> (total_avail_pages <= midsize_alloc_zone_pages) &&
+ *   - common/page_alloc.c|727| <<alloc_heap_pages>> avail_pages = total_avail_pages +
+ *   - common/page_alloc.c|1115| <<free_heap_pages>> midsize_alloc_zone_pages, total_avail_pages / MIDSIZE_ALLOC_FRAC);
+ *   - common/page_alloc.c|1478| <<total_free_pages>> ret = total_avail_pages - midsize_alloc_zone_pages;
+ */
 static long total_avail_pages;
 
 /* TMEM: Reserve a fraction of memory for mid-size (0<order<9) allocations.*/
@@ -299,6 +337,32 @@ static long midsize_alloc_zone_pages;
 #define MIDSIZE_ALLOC_FRAC 128
 
 static DEFINE_SPINLOCK(heap_lock_globals);
+/*
+ * called by:
+ *   - common/page_alloc.c|421| <<get_dirty_pages>> spin_lock(&heap_lock[node]);
+ *   - common/page_alloc.c|423| <<get_dirty_pages>> spin_unlock(&heap_lock[node]);
+ *   - common/page_alloc.c|691| <<alloc_heap_pages>> spin_lock(&heap_lock[node]);
+ *   - common/page_alloc.c|705| <<alloc_heap_pages>> spin_unlock(&heap_lock[node]);
+ *   - common/page_alloc.c|792| <<alloc_heap_pages>> spin_unlock(&heap_lock[node]);
+ *   - common/page_alloc.c|819| <<reserve_offlined_page>> ASSERT(spin_is_locked(&heap_lock[node]));
+ *   - common/page_alloc.c|925| <<merge_free_trunks>> ASSERT(spin_is_locked(&heap_lock[node]));
+ *   - common/page_alloc.c|1005| <<free_heap_pages>> spin_lock(&heap_lock[node]);
+ *   - common/page_alloc.c|1060| <<free_heap_pages>> spin_unlock(&heap_lock[node]);
+ *   - common/page_alloc.c|1075| <<mark_page_offline>> ASSERT(spin_is_locked(&heap_lock[phys_to_nid(page_to_maddr(pg))]));
+ *   - common/page_alloc.c|1171| <<offline_page>> spin_lock(&heap_lock[node]);
+ *   - common/page_alloc.c|1179| <<offline_page>> spin_unlock(&heap_lock[node]);
+ *   - common/page_alloc.c|1186| <<offline_page>> spin_unlock(&heap_lock[node]);
+ *   - common/page_alloc.c|1250| <<online_page>> spin_lock(&heap_lock[node]);
+ *   - common/page_alloc.c|1283| <<online_page>> spin_unlock(&heap_lock[node]);
+ *   - common/page_alloc.c|1306| <<query_page_offline>> spin_lock(&heap_lock[node]);
+ *   - common/page_alloc.c|1315| <<query_page_offline>> spin_unlock(&heap_lock[node]);
+ *   - common/page_alloc.c|1673| <<__scrub_free_pages>> spin_lock(&heap_lock[node]);
+ *   - common/page_alloc.c|1686| <<__scrub_free_pages>> spin_unlock(&heap_lock[node]);
+ *   - common/page_alloc.c|1726| <<scrub_free_pages>> spin_lock(&heap_lock[node]);
+ *   - common/page_alloc.c|1757| <<scrub_free_pages>> spin_unlock(&heap_lock[node]);
+ *   - common/page_alloc.c|1761| <<scrub_free_pages>> spin_unlock(&heap_lock[node]);
+ *   - common/page_alloc.c|2181| <<early_heap_init>> spin_lock_init(&heap_lock[i]);
+ */
 static spinlock_t heap_lock[MAX_NUMNODES];
 
 static long outstanding_claims; /* total outstanding claims by all domains */
@@ -804,9 +868,24 @@ static struct page_info *alloc_heap_pages(
 }
 
 /* Remove any offlined page in the buddy pointed to by head. */
+/*
+ * called by:
+ *   - common/page_alloc.c|1017| <<free_heap_pages>> reserve_offlined_page(pg);
+ *   - common/page_alloc.c|1074| <<reserve_heap_page>> return reserve_offlined_page(head);
+ */
 static int reserve_offlined_page(struct page_info *head)
 {
     unsigned int node = phys_to_nid(page_to_maddr(head));
+    /*
+     * 返回((_pfn)->v.free.order)
+     *
+     * struct page_info:
+     * -> union v:
+     *    -> struct {
+     *           // Order-size of the free chunk this page is the head of.
+     *           unsigned int order;
+     *       } free;
+     */
     int zone = page_to_zone(head), i, head_order = PFN_ORDER(head), count = 0;
     struct page_info *cur_head;
     int cur_order;
@@ -815,13 +894,51 @@ static int reserve_offlined_page(struct page_info *head)
 
     cur_head = head;
 
+    /*
+     * 在以下调用page_list_del():
+     *   - arch/x86/mm.c|4480| <<steal_page>> page_list_del(page, &d->page_list);
+     *   - arch/x86/mm/mem_sharing.c|660| <<page_make_sharable>> page_list_del(page, &d->page_list);
+     *   - arch/x86/mm/p2m-pod.c|122| <<p2m_pod_cache_add>> page_list_del(p, &d->page_list);
+     *   - arch/x86/mm/p2m-pod.c|442| <<p2m_pod_offline_or_broken_hit>> page_list_del(q, &p2m->pod.super);
+     *   - arch/x86/mm/p2m-pod.c|448| <<p2m_pod_offline_or_broken_hit>> page_list_del(p, &p2m->pod.single);
+     *   - arch/x86/mm/p2m-pod.c|459| <<p2m_pod_offline_or_broken_hit>> page_list_del(p, &p2m->pod.single);
+     *   - arch/x86/mm/p2m.c|373| <<p2m_free_ptp>> page_list_del(pg, &p2m->pages);
+     *   - common/kimage.c|283| <<kimage_free_page_list>> page_list_del(page, list);
+     *   - common/kimage.c|607| <<kimage_alloc_page>> page_list_del(page, &image->dest_pages);
+     *   - common/page_alloc.c|818| <<reserve_offlined_page>> page_list_del(head, &heap(node, zone, head_order));
+     *   - common/page_alloc.c|923| <<merge_free_trunks>> page_list_del(pg, &heap(node, zone, order));
+     *   - common/page_alloc.c|943| <<merge_free_trunks>> page_list_del(pg + mask, &heap(node, zone, order));
+     *   - common/page_alloc.c|1225| <<online_page>> page_list_del(pg, &page_offlined_list);
+     *   - common/page_alloc.c|1636| <<__scrub_free_pages>> page_list_del(pg, local_free_list);
+     *   - common/page_alloc.c|1691| <<scrub_free_pages>> page_list_del( pg, &heap(node, zone, order) );
+     *   - drivers/passthrough/iommu.c|424| <<iommu_populate_page_table>> page_list_del(page, &d->page_list);
+     *   - include/xen/mm.h|314| <<page_list_remove_head>> page_list_del(page, head);
+     *
+     *
+     * static heap_by_zone_and_order_t *_heap[MAX_NUMNODES];
+     * #define heap(node, zone, order) ((*_heap[node])[zone][order])
+     *
+     * 把page_info从对应的none/zone的heap上拿走
+     * head()返回的是struct page_list_head(不是指针)
+     */
     page_list_del(head, &heap(node, zone, head_order));
 
+    /*
+     * 一直处理到这组page_info[]的最后一个
+     */
     while ( cur_head < (head + (1 << head_order)) )
     {
         struct page_info *pg;
         int next_order;
 
+	/*
+	 * 在以下使用PGC_state_offlined:
+	 *   - common/page_alloc.c|1091| <<free_heap_pages>> ? PGC_state_offlined : PGC_state_free));
+	 *   - common/page_alloc.c|1155| <<mark_page_offline>> if ( ((x & PGC_state) != PGC_state_offlined) &&
+	 *   - common/page_alloc.c|1160| <<mark_page_offline>> ? PGC_state_offlined : PGC_state_offlining);
+	 *   - common/page_alloc.c|1355| <<online_page>> if ( (y & PGC_state) == PGC_state_offlined )
+	 *   - common/page_alloc.c|1376| <<online_page>> if ( (y & PGC_state) == PGC_state_offlined )
+	 */
         if ( page_state_is(cur_head, offlined) )
         {
             cur_head++;
@@ -851,7 +968,20 @@ static int reserve_offlined_page(struct page_info *head)
             {
             merge:
                 /* We don't consider merging outside the head_order. */
+                /*
+		 * 返回的是struct page_list_head(不是指针)
+		 */
                 page_list_add_tail(cur_head, &heap(node, zone, cur_order));
+		/*
+		 * 返回((_pfn)->v.free.order)
+		 *
+		 * struct page_info:
+		 * -> union v:
+		 *    -> struct {
+		 *           // Order-size of the free chunk this page is the head of.
+		 *           unsigned int order;
+		 *       } free;
+		 */
                 PFN_ORDER(cur_head) = cur_order;
                 cur_head += (1 << cur_order);
                 break;
@@ -861,6 +991,16 @@ static int reserve_offlined_page(struct page_info *head)
 
     for ( cur_head = head; cur_head < head + ( 1UL << head_order); cur_head++ )
     {
+        /*
+	 * 在以下使用PGC_state_offlined:
+	 *   - common/page_alloc.c|1091| <<free_heap_pages>> ? PGC_state_offlined : PGC_state_free));
+	 *   - common/page_alloc.c|1155| <<mark_page_offline>> if ( ((x & PGC_state) != PGC_state_offlined) &&
+	 *   - common/page_alloc.c|1160| <<mark_page_offline>> ? PGC_state_offlined : PGC_state_offlining);
+	 *   - common/page_alloc.c|1355| <<online_page>> if ( (y & PGC_state) == PGC_state_offlined )
+	 *   - common/page_alloc.c|1376| <<online_page>> if ( (y & PGC_state) == PGC_state_offlined )
+	 *
+	 * 没有offlined的直接跳过
+	 */
         if ( !page_state_is(cur_head, offlined) )
             continue;
 
@@ -876,6 +1016,14 @@ static int reserve_offlined_page(struct page_info *head)
 
         spin_lock(&pglist_lock);
 
+	/*
+	 * 只在此处使用page_broken_list:
+	 *   - common/page_alloc.c|949| <<reserve_offlined_page>> &page_broken_list : &page_offlined_list);
+	 *
+	 * 在以下使用page_offlined_list:
+	 *   - common/page_alloc.c|949| <<reserve_offlined_page>> &page_broken_list : &page_offlined_list);
+	 *   - common/page_alloc.c|1318| <<online_page>> page_list_del(pg, &page_offlined_list);
+	 */
         page_list_add_tail(cur_head,
                            test_bit(_PGC_broken, &cur_head->count_info) ?
                            &page_broken_list : &page_offlined_list);
@@ -888,6 +1036,11 @@ static int reserve_offlined_page(struct page_info *head)
     return count;
 }
 
+/*
+ * called by:
+ *   - common/page_alloc.c|1188| <<free_heap_pages>> merge_free_trunks(pg, order, node, zone, need_scrub);
+ *   - common/page_alloc.c|1841| <<__scrub_free_pages>> merge_free_trunks(pg, order, node, page_to_zone(pg), 0);
+ */
 static void merge_free_trunks(struct page_info *pg, unsigned int order,
     unsigned int node, unsigned int zone, bool_t need_scrub)
 {
@@ -951,6 +1104,18 @@ static void merge_free_trunks(struct page_info *pg, unsigned int order,
 }
 
 /* Free 2^@order set of pages. */
+/*
+ * called by:
+ *   - common/page_alloc.c|1274| <<online_page>> free_heap_pages(pg, 0, 0);
+ *   - common/page_alloc.c|1345| <<init_heap_pages>> free_heap_pages(pg+i, 0, 0);
+ *   - common/page_alloc.c|1821| <<free_xenheap_pages>> free_heap_pages(virt_to_page(v), order, 0);
+ *   - common/page_alloc.c|1879| <<free_xenheap_pages>> free_heap_pages(pg, order, 1);
+ *   - common/page_alloc.c|1995| <<alloc_domheap_pages>> free_heap_pages(pg, order, 0);
+ *   - common/page_alloc.c|2044| <<free_domheap_pages>> free_heap_pages(pg, order, 1);
+ *   - common/page_alloc.c|2046| <<free_domheap_pages>> free_heap_pages(pg, order, 0);
+ *   - common/page_alloc.c|2051| <<free_domheap_pages>> free_heap_pages(pg, 0, 1);
+ *   - common/page_alloc.c|2057| <<free_domheap_pages>> free_heap_pages(pg, order, 1);
+ */
 static void free_heap_pages(
     struct page_info *pg, unsigned int order, bool_t need_scrub)
 {
@@ -976,11 +1141,40 @@ static void free_heap_pages(
          *     in its pseudophysical address space).
          * In all the above cases there can be no guest mappings of this page.
          */
+        /*
+	 * 在以下使用PGC_state_offlined:
+	 *   - common/page_alloc.c|1091| <<free_heap_pages>> ? PGC_state_offlined : PGC_state_free));
+	 *   - common/page_alloc.c|1155| <<mark_page_offline>> if ( ((x & PGC_state) != PGC_state_offlined) &&
+	 *   - common/page_alloc.c|1160| <<mark_page_offline>> ? PGC_state_offlined : PGC_state_offlining);
+	 *   - common/page_alloc.c|1355| <<online_page>> if ( (y & PGC_state) == PGC_state_offlined )
+	 *   - common/page_alloc.c|1376| <<online_page>> if ( (y & PGC_state) == PGC_state_offlined )
+	 */
         ASSERT(!page_state_is(&pg[i], offlined));
+	/*
+	 * 在以下使用PGC_broken:
+	 *   - arch/x86/domctl.c|270| <<XEN_GUEST_HANDLE_PARAM>> if ( page->count_info & PGC_broken )
+	 *   - common/page_alloc.c|1061| <<free_heap_pages>> ((pg[i].count_info & PGC_broken) |
+	 *   - common/page_alloc.c|1136| <<mark_page_offline>> nx |= PGC_broken;
+	 *   - common/page_alloc.c|1215| <<offline_page>> if ( (pg->count_info & PGC_broken) && (owner = page_get_owner(pg)) )
+	 *   - common/page_alloc.c|1309| <<online_page>> if ( y & PGC_broken )
+	 *   - common/page_alloc.c|1362| <<query_page_offline>> if ( pg->count_info & PGC_broken )
+	 *   - common/page_alloc.c|2212| <<scrub_one_page>> if ( unlikely(pg->count_info & PGC_broken) )
+	 *   - drivers/passthrough/iommu.c|422| <<iommu_populate_page_table>> (page->count_info & (PGC_state|PGC_broken)) )
+	 */
         pg[i].count_info =
             ((pg[i].count_info & PGC_broken) |
              (page_state_is(&pg[i], offlining)
               ? PGC_state_offlined : PGC_state_free));
+	/*
+	 * 在以下使用PGC_state_offlined:
+	 *   - common/page_alloc.c|1091| <<free_heap_pages>> ? PGC_state_offlined : PGC_state_free));
+	 *   - common/page_alloc.c|1155| <<mark_page_offline>> if ( ((x & PGC_state) != PGC_state_offlined) &&
+	 *   - common/page_alloc.c|1160| <<mark_page_offline>> ? PGC_state_offlined : PGC_state_offlining);
+	 *   - common/page_alloc.c|1355| <<online_page>> if ( (y & PGC_state) == PGC_state_offlined )
+	 *   - common/page_alloc.c|1376| <<online_page>> if ( (y & PGC_state) == PGC_state_offlined )
+	 *
+	 * 返回的是(pg)->count_info&PGC_state是否等于PGC_state_offlined
+	 */
         if ( page_state_is(&pg[i], offlined) )
             tainted = 1;
 
@@ -1011,6 +1205,11 @@ static void free_heap_pages(
         node_need_scrub[node] += (1 << order);
     }
 
+    /*
+     * called by:
+     *   - common/page_alloc.c|1188| <<free_heap_pages>> merge_free_trunks(pg, order, node, zone, need_scrub);
+     *   - common/page_alloc.c|1841| <<__scrub_free_pages>> merge_free_trunks(pg, order, node, page_to_zone(pg), 0);
+     */
     merge_free_trunks(pg, order, node, zone, need_scrub);
 
     if ( tainted )
@@ -1026,6 +1225,11 @@ static void free_heap_pages(
  * A page will be offlined only if it is free
  * return original count_info
  */
+/*
+ * called by:
+ *   - common/page_alloc.c|1215| <<offline_page>> old_info = mark_page_offline(pg, broken);
+ *   - common/page_alloc.c|1792| <<scrub_free_pages>> mark_page_offline(&pg[i], 0);
+ */
 static unsigned long mark_page_offline(struct page_info *pg, int broken)
 {
     unsigned long nx, x, y = pg->count_info;
@@ -1054,6 +1258,10 @@ static unsigned long mark_page_offline(struct page_info *pg, int broken)
     return y;
 }
 
+/*
+ * called by:
+ *   - common/page_alloc.c|1305| <<offline_page>> reserve_heap_page(pg);
+ */
 static int reserve_heap_page(struct page_info *pg)
 {
     struct page_info *head = NULL;
@@ -1079,6 +1287,11 @@ static int reserve_heap_page(struct page_info *pg)
 
 }
 
+/*
+ * called by:
+ *   - arch/x86/cpu/mcheck/mcaction.c|57| <<mc_memerr_dhandler>> if (offline_page(mfn, 1, &status))
+ *   - common/sysctl.c|218| <<do_sysctl(XEN_SYSCTL_page_offline_op)>> ret = offline_page(pfn, 0, ptr++)
+ */
 int offline_page(unsigned long mfn, int broken, uint32_t *status)
 {
     unsigned long old_info = 0;
@@ -1129,6 +1342,10 @@ int offline_page(unsigned long mfn, int broken, uint32_t *status)
     node = phys_to_nid(page_to_maddr(pg));
     spin_lock(&heap_lock[node]);
 
+    /*
+     * 如果page正在被使用设置为PGC_state_offlining
+     * 否则设置为PGC_state_offlined
+     */
     old_info = mark_page_offline(pg, broken);
 
     if ( page_state_is(pg, offlined) )
@@ -1179,6 +1396,17 @@ int offline_page(unsigned long mfn, int broken, uint32_t *status)
                   (DOMID_INVALID << PG_OFFLINE_OWNER_SHIFT );
     }
 
+    /*
+     * 在以下使用PGC_broken:
+     *   - arch/x86/domctl.c|270| <<XEN_GUEST_HANDLE_PARAM>> if ( page->count_info & PGC_broken )
+     *   - common/page_alloc.c|1061| <<free_heap_pages>> ((pg[i].count_info & PGC_broken) |
+     *   - common/page_alloc.c|1136| <<mark_page_offline>> nx |= PGC_broken;
+     *   - common/page_alloc.c|1215| <<offline_page>> if ( (pg->count_info & PGC_broken) && (owner = page_get_owner(pg)) )
+     *   - common/page_alloc.c|1309| <<online_page>> if ( y & PGC_broken )
+     *   - common/page_alloc.c|1362| <<query_page_offline>> if ( pg->count_info & PGC_broken )
+     *   - common/page_alloc.c|2212| <<scrub_one_page>> if ( unlikely(pg->count_info & PGC_broken) )
+     *   - drivers/passthrough/iommu.c|422| <<iommu_populate_page_table>> (page->count_info & (PGC_state|PGC_broken)) )
+     */
     if ( broken )
         *status |= PG_OFFLINE_BROKEN;
 
@@ -1874,6 +2102,13 @@ void init_domheap_pages(paddr_t ps, paddr_t pe)
 }
 
 
+/*
+ * called by:
+ *   - arch/x86/domain_build.c|683| <<construct_dom0>> if ( assign_pages(d, mfn_to_page(mfn++), 0, 0) )
+ *   - common/memory.c|621| <<memory_exchange>> if ( assign_pages(d, page, exch.out.extent_order,
+ *   - common/memory.c|686| <<memory_exchange>> if ( assign_pages(d, page, 0, MEMF_no_refcount) )
+ *   - common/page_alloc.c|1957| <<alloc_domheap_pages>> assign_pages(d, pg, order, memflags) )
+ */
 int assign_pages(
     struct domain *d,
     struct page_info *pg,
@@ -1963,6 +2198,17 @@ struct page_info *alloc_domheap_pages(
     return pg;
 }
 
+/*
+ * called by:
+ *   - arch/arm/p2m.c|619| <<p2m_teardown>> free_domheap_pages(p2m->first_level, P2M_FIRST_ORDER);
+ *   - arch/x86/domain_build.c|297| <<alloc_chunk>> free_domheap_pages(page, free_order);
+ *   - arch/x86/domain_build.c|302| <<alloc_chunk>> free_domheap_pages(pg2, order);
+ *   - arch/x86/domain_build.c|670| <<construct_dom0>> free_domheap_pages(page, order);
+ *   - common/memory.c|646| <<memory_exchange>> free_domheap_pages(page, exch.out.extent_order);
+ *   - common/memory.c|697| <<memory_exchange>> free_domheap_pages(page, exch.out.extent_order);
+ *   - include/xen/mm.h|107| <<free_domheap_page>> #define free_domheap_page(p) (free_domheap_pages(p,0))
+ *   - include/xen/tmem_xen.h|140| <<__tmem_free_page_thispool>> free_domheap_pages(pi,0);
+ */
 void free_domheap_pages(struct page_info *pg, unsigned int order)
 {
     struct domain *d = page_get_owner(pg);
diff --git a/xen/include/asm-x86/mm.h b/xen/include/asm-x86/mm.h
index e1bce92d0c..4a1e80853d 100644
--- a/xen/include/asm-x86/mm.h
+++ b/xen/include/asm-x86/mm.h
@@ -15,6 +15,16 @@
  *  1. 'struct page_info' contains a 'struct page_list_entry list'.
  *  2. Provide a PFN_ORDER() macro for accessing the order of a free page.
  */
+/*
+ * 返回((_pfn)->v.free.order)
+ *
+ * struct page_info:
+ * -> union v:
+ *    -> struct {
+ *           // Order-size of the free chunk this page is the head of.
+ *           unsigned int order;
+ *       } free;
+ */
 #define PFN_ORDER(_pfn) ((_pfn)->v.free.order)
 
 /*
@@ -233,14 +243,60 @@ struct page_info
 #define PGC_cacheattr_base PG_shift(6)
 #define PGC_cacheattr_mask PG_mask(7, 6)
  /* Page is broken? */
+/*
+ * 在以下使用_PGC_broken:
+ *   - common/page_alloc.c|948| <<reserve_offlined_page>> test_bit(_PGC_broken, &cur_head->count_info) ?
+ *   - common/page_alloc.c|1801| <<scrub_free_pages>> ASSERT( !test_bit(_PGC_broken, &pg[i].count_info) );
+ */
 #define _PGC_broken       PG_shift(7)
+/*
+ * 在以下使用PGC_broken:
+ *   - arch/x86/domctl.c|270| <<XEN_GUEST_HANDLE_PARAM>> if ( page->count_info & PGC_broken )
+ *   - common/page_alloc.c|1061| <<free_heap_pages>> ((pg[i].count_info & PGC_broken) |
+ *   - common/page_alloc.c|1136| <<mark_page_offline>> nx |= PGC_broken;
+ *   - common/page_alloc.c|1215| <<offline_page>> if ( (pg->count_info & PGC_broken) && (owner = page_get_owner(pg)) )
+ *   - common/page_alloc.c|1309| <<online_page>> if ( y & PGC_broken )
+ *   - common/page_alloc.c|1362| <<query_page_offline>> if ( pg->count_info & PGC_broken )
+ *   - common/page_alloc.c|2212| <<scrub_one_page>> if ( unlikely(pg->count_info & PGC_broken) )
+ *   - drivers/passthrough/iommu.c|422| <<iommu_populate_page_table>> (page->count_info & (PGC_state|PGC_broken)) )
+ */
 #define PGC_broken        PG_mask(1, 7)
  /* Mutually-exclusive page states: { inuse, offlining, offlined, free }. */
 #define PGC_state         PG_mask(3, 9)
+/*
+ * 在以下使用PGC_state_inuse:
+ *   - arch/x86/x86_64/mm.c|1309| <<transfer_pages_to_heap>> pg->count_info = PGC_state_inuse;
+ *   - common/page_alloc.c|837| <<alloc_heap_pages>> pg[i].count_info = PGC_state_inuse;
+ *   - common/page_alloc.c|1462| <<online_page>> nx = (x & ~PGC_state) | PGC_state_inuse;
+ */
 #define PGC_state_inuse   PG_mask(0, 9)
+/*
+ * 在以下使用PGC_state_offlining:
+ *   - common/page_alloc.c|1219| <<mark_page_offline>> ((x & PGC_state) != PGC_state_offlining) )
+ *   - common/page_alloc.c|1223| <<mark_page_offline>> ? PGC_state_offlined : PGC_state_offlining);
+ *   - common/page_alloc.c|1427| <<online_page>> else if ( (y & PGC_state) == PGC_state_offlining )
+ */
 #define PGC_state_offlining PG_mask(1, 9)
+/*
+ * 在以下使用PGC_state_offlined:
+ *   - common/page_alloc.c|1091| <<free_heap_pages>> ? PGC_state_offlined : PGC_state_free));
+ *   - common/page_alloc.c|1155| <<mark_page_offline>> if ( ((x & PGC_state) != PGC_state_offlined) &&
+ *   - common/page_alloc.c|1160| <<mark_page_offline>> ? PGC_state_offlined : PGC_state_offlining);
+ *   - common/page_alloc.c|1355| <<online_page>> if ( (y & PGC_state) == PGC_state_offlined )
+ *   - common/page_alloc.c|1376| <<online_page>> if ( (y & PGC_state) == PGC_state_offlined )
+ */
 #define PGC_state_offlined PG_mask(2, 9)
+/*
+ * 在以下使用PGC_state_free:
+ *   - common/page_alloc.c|836| <<alloc_heap_pages>> BUG_ON(pg[i].count_info != PGC_state_free);
+ *   - common/page_alloc.c|1154| <<free_heap_pages>> ? PGC_state_offlined : PGC_state_free));
+ *   - common/page_alloc.c|1222| <<mark_page_offline>> nx |= (((x & PGC_state) == PGC_state_free)
+ *   - common/page_alloc.c|1838| <<__scrub_free_pages>> pg[i].count_info |= PGC_state_free;
+ */
 #define PGC_state_free    PG_mask(3, 9)
+/*
+ * 返回的是(pg)->count_info&PGC_state是否等于PGC_state_##st
+ */
 #define page_state_is(pg, st) (((pg)->count_info&PGC_state) == PGC_state_##st)
 /* Page need to be scrubbed */
 #define _PGC_need_scrub   PG_shift(10)
diff --git a/xen/include/asm-x86/p2m.h b/xen/include/asm-x86/p2m.h
index 72878406f8..588c5bd2b3 100644
--- a/xen/include/asm-x86/p2m.h
+++ b/xen/include/asm-x86/p2m.h
@@ -69,6 +69,12 @@ typedef enum {
     p2m_ram_paged = 10,           /* Memory that has been paged out */
     p2m_ram_paging_in = 11,       /* Memory that is being paged in */
     p2m_ram_shared = 12,          /* Shared or sharable memory */
+    /*
+     * 在以下使用p2m_ram_broken:
+     *   - arch/x86/cpu/mcheck/vmce.c|454| <<unmmap_broken_page>> p2m_change_type(d, gfn, pt, p2m_ram_broken);
+     *   - arch/x86/domctl.c|1414| <<arch_do_domctl(XEN_DOMCTL_set_broken_page_p2m)>> (p2m_change_type(d, pfn, pt, p2m_ram_broken) != pt)) )
+     *   - include/asm-x86/p2m.h|168| <<P2M_BROKEN_TYPES>> #define P2M_BROKEN_TYPES (p2m_to_mask(p2m_ram_broken))
+     */
     p2m_ram_broken = 13,          /* Broken page, access cause domain crash */
     p2m_map_foreign  = 14,        /* ram pages from foreign domain */
 } p2m_type_t;
@@ -161,6 +167,10 @@ typedef unsigned int p2m_query_t;
 
 /* Broken type: the frame backing this pfn has failed in hardware
  * and must not be touched. */
+/*
+ * 只在以下被使用P2M_BROKEN_TYPES:
+ *   - include/asm-x86/p2m.h|183| <<p2m_is_broken>> #define p2m_is_broken(_t) (p2m_to_mask(_t) & P2M_BROKEN_TYPES)
+ */
 #define P2M_BROKEN_TYPES (p2m_to_mask(p2m_ram_broken))
 
 /* Useful predicates */
diff --git a/xen/include/public/arch-x86/xen-mca.h b/xen/include/public/arch-x86/xen-mca.h
index 04382edeee..990f297fbe 100644
--- a/xen/include/public/arch-x86/xen-mca.h
+++ b/xen/include/public/arch-x86/xen-mca.h
@@ -91,6 +91,15 @@
 
 #ifndef __ASSEMBLY__
 
+/*
+ * 在以下使用VIRQ_MCA:
+ *   - arch/x86/cpu/mcheck/amd_nonfatal.c|104| <<mce_amd_checkregs>> send_global_virq(VIRQ_MCA);
+ *   - arch/x86/cpu/mcheck/mce.c|1712| <<mce_softirq>> send_global_virq(VIRQ_MCA);
+ *   - arch/x86/cpu/mcheck/mce_intel.c|558| <<cmci_discover>> send_global_virq(VIRQ_MCA);
+ *   - arch/x86/cpu/mcheck/mce_intel.c|646| <<cmci_interrupt>> send_global_virq(VIRQ_MCA);
+ *   - arch/x86/cpu/mcheck/non-fatal.c|58| <<mce_checkregs>> send_global_virq(VIRQ_MCA);
+ *   - arch/x86/cpu/mcheck/vmce.h|9| <<dom0_vmce_enabled>> && guest_enabled_event(dom0->vcpu[0], VIRQ_MCA))
+ */
 #define VIRQ_MCA VIRQ_ARCH_0 /* G. (DOM0) Machine Check Architecture */
 
 /*
diff --git a/xen/include/xen/mm.h b/xen/include/xen/mm.h
index 2a90f97d84..3a330f99fd 100644
--- a/xen/include/xen/mm.h
+++ b/xen/include/xen/mm.h
@@ -254,6 +254,13 @@ page_list_add_tail(struct page_info *page, struct page_list_head *head)
     }
     head->tail = page;
 }
+
+/*
+ * called by:
+ *   - include/xen/mm.h|288| <<page_list_del>> if ( !__page_list_del_head(page, head, next, prev) )
+ *   - include/xen/mm.h|301| <<page_list_del2>> if ( !__page_list_del_head(page, head1, next, prev) &&
+ *   - include/xen/mm.h|302| <<page_list_del2>> !__page_list_del_head(page, head2, next, prev) )
+ */
 static inline bool_t
 __page_list_del_head(struct page_info *page, struct page_list_head *head,
                      struct page_info *next, struct page_info *prev)
@@ -279,6 +286,27 @@ __page_list_del_head(struct page_info *page, struct page_list_head *head,
 
     return 0;
 }
+
+/*
+ * called by:
+ *   - arch/x86/mm.c|4480| <<steal_page>> page_list_del(page, &d->page_list);
+ *   - arch/x86/mm/mem_sharing.c|660| <<page_make_sharable>> page_list_del(page, &d->page_list);
+ *   - arch/x86/mm/p2m-pod.c|122| <<p2m_pod_cache_add>> page_list_del(p, &d->page_list);
+ *   - arch/x86/mm/p2m-pod.c|442| <<p2m_pod_offline_or_broken_hit>> page_list_del(q, &p2m->pod.super);
+ *   - arch/x86/mm/p2m-pod.c|448| <<p2m_pod_offline_or_broken_hit>> page_list_del(p, &p2m->pod.single);
+ *   - arch/x86/mm/p2m-pod.c|459| <<p2m_pod_offline_or_broken_hit>> page_list_del(p, &p2m->pod.single);
+ *   - arch/x86/mm/p2m.c|373| <<p2m_free_ptp>> page_list_del(pg, &p2m->pages);
+ *   - common/kimage.c|283| <<kimage_free_page_list>> page_list_del(page, list);
+ *   - common/kimage.c|607| <<kimage_alloc_page>> page_list_del(page, &image->dest_pages);
+ *   - common/page_alloc.c|818| <<reserve_offlined_page>> page_list_del(head, &heap(node, zone, head_order));
+ *   - common/page_alloc.c|923| <<merge_free_trunks>> page_list_del(pg, &heap(node, zone, order));
+ *   - common/page_alloc.c|943| <<merge_free_trunks>> page_list_del(pg + mask, &heap(node, zone, order));
+ *   - common/page_alloc.c|1225| <<online_page>> page_list_del(pg, &page_offlined_list);
+ *   - common/page_alloc.c|1636| <<__scrub_free_pages>> page_list_del(pg, local_free_list);
+ *   - common/page_alloc.c|1691| <<scrub_free_pages>> page_list_del( pg, &heap(node, zone, order) );
+ *   - drivers/passthrough/iommu.c|424| <<iommu_populate_page_table>> page_list_del(page, &d->page_list);
+ *   - include/xen/mm.h|314| <<page_list_remove_head>> page_list_del(page, head);
+ */
 static inline void
 page_list_del(struct page_info *page, struct page_list_head *head)
 {
-- 
2.17.1

