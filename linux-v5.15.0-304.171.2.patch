From dbdbc976cb29e2850b08ec15fef5852f1ac2a199 Mon Sep 17 00:00:00 2001
From: Dongli Zhang <dongli.zhang0129@gmail.com>
Date: Mon, 23 Dec 2024 10:53:38 -0800
Subject: [PATCH 1/1] linux v5.15.0-304.171.2

Signed-off-by: Dongli Zhang <dongli.zhang0129@gmail.com>
---
 drivers/vhost/net.c   |   4 +
 drivers/vhost/scsi.c  | 140 +++++++++++
 drivers/vhost/vhost.c | 534 ++++++++++++++++++++++++++++++++++++++++++
 drivers/vhost/vhost.h |  45 ++++
 4 files changed, 723 insertions(+)

diff --git a/drivers/vhost/net.c b/drivers/vhost/net.c
index 51498f97a7d0..9dc839937069 100644
--- a/drivers/vhost/net.c
+++ b/drivers/vhost/net.c
@@ -854,6 +854,10 @@ static void handle_tx_copy(struct vhost_net *net, struct socket *sock)
 	vhost_tx_batch(net, nvq, sock, &msg);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|984| <<handle_tx>> handle_tx_zerocopy(net, sock);
+ */
 static void handle_tx_zerocopy(struct vhost_net *net, struct socket *sock)
 {
 	struct vhost_net_virtqueue *nvq = &net->vqs[VHOST_NET_VQ_TX];
diff --git a/drivers/vhost/scsi.c b/drivers/vhost/scsi.c
index 58af67d1ce35..580a05b02615 100644
--- a/drivers/vhost/scsi.c
+++ b/drivers/vhost/scsi.c
@@ -39,6 +39,57 @@
 
 #include "vhost.h"
 
+/*
+ * 5.15
+ *
+ * root       10740  0.0  0.0      0     0 ?        S    20:34   0:00 [vhost-10719]
+ *
+ * vhost_poll_wakeup
+ * __wake_up_common
+ * eventfd_signal_mask
+ * ioeventfd_write
+ * __kvm_io_bus_write
+ * kvm_io_bus_write
+ * write_mmio
+ * emulator_read_write_onepage
+ * emulator_read_write
+ * x86_emulate_insn
+ * x86_emulate_instruction
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ * __GI___ioctl
+ * b'CPU 9/KVM' [10719]
+ *
+ *
+ * vhost_scsi_handle_vq
+ * vhost_worker
+ * kthread
+ * ret_from_fork
+ * b'vhost-10719' [10740]
+ *
+ *
+ * vhost_scsi_release_cmd
+ * target_release_cmd_kref
+ * target_put_sess_cmd
+ * process_one_work
+ * worker_thread
+ * kthread
+ * ret_from_fork
+ * b'kworker/53:0' [7266]
+ *
+ *
+ * vhost_scsi_complete_cmd_work
+ * vhost_worker
+ * kthread
+ * ret_from_fork
+ * b'vhost-10719' [10740]
+ */
+
 #define VHOST_SCSI_VERSION  "v0.1"
 #define VHOST_SCSI_NAMELEN 256
 #define VHOST_SCSI_MAX_CDB_SIZE 32
@@ -243,6 +294,11 @@ static void vhost_scsi_done_inflight(struct kref *kref)
 	complete(&inflight->comp);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1625| <<vhost_scsi_flush>> vhost_scsi_init_inflight(vs, old_inflight);
+ *   - drivers/vhost/scsi.c|2017| <<vhost_scsi_open>> vhost_scsi_init_inflight(vs, NULL);
+ */
 static void vhost_scsi_init_inflight(struct vhost_scsi *vs,
 				    struct vhost_scsi_inflight *old_inflight[])
 {
@@ -270,6 +326,11 @@ static void vhost_scsi_init_inflight(struct vhost_scsi *vs,
 	}
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|710| <<vhost_scsi_get_cmd>> cmd->inflight = vhost_scsi_get_inflight(vq);
+ *   - drivers/vhost/scsi.c|1398| <<vhost_scsi_handle_tmf>> tmf->inflight = vhost_scsi_get_inflight(vq);
+ */
 static struct vhost_scsi_inflight *
 vhost_scsi_get_inflight(struct vhost_virtqueue *vq)
 {
@@ -283,6 +344,11 @@ vhost_scsi_get_inflight(struct vhost_virtqueue *vq)
 	return inflight;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|405| <<vhost_scsi_release_cmd_res>> vhost_scsi_put_inflight(inflight);
+ *   - drivers/vhost/scsi.c|416| <<vhost_scsi_release_tmf_res>> vhost_scsi_put_inflight(inflight);
+ */
 static void vhost_scsi_put_inflight(struct vhost_scsi_inflight *inflight)
 {
 	kref_put(&inflight->kref, vhost_scsi_done_inflight);
@@ -467,6 +533,10 @@ static int vhost_scsi_check_stop_free(struct se_cmd *se_cmd)
 	return target_put_sess_cmd(se_cmd);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|597| <<vhost_scsi_evt_work>> vhost_scsi_do_evt_work(vs, evt);
+ */
 static void
 vhost_scsi_do_evt_work(struct vhost_scsi *vs, struct vhost_scsi_evt *evt)
 {
@@ -616,6 +686,10 @@ static void vhost_scsi_complete_cmd_work(struct vhost_work *work)
 		vhost_signal(&vs->dev, &vs->vqs[vq].vq);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1272| <<vhost_scsi_handle_vq>> cmd = vhost_scsi_get_cmd(vq, tpg, cdb, tag, lun, task_attr,
+ */
 static struct vhost_scsi_cmd *
 vhost_scsi_get_cmd(struct vhost_virtqueue *vq, struct vhost_scsi_tpg *tpg,
 		   unsigned char *cdb, u64 scsi_tag, u16 lun, u8 task_attr,
@@ -935,6 +1009,11 @@ static void vhost_scsi_target_queue_cmd(struct vhost_scsi_cmd *cmd)
 	target_queue_submission(se_cmd);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1340| <<vhost_scsi_handle_vq>> vhost_scsi_send_bad_target(vs, vq, vc.head, vc.out);
+ *   - drivers/vhost/scsi.c|1572| <<vhost_scsi_ctl_handle_vq>> vhost_scsi_send_bad_target(vs, vq, vc.head, vc.out);
+ */
 static void
 vhost_scsi_send_bad_target(struct vhost_scsi *vs,
 			   struct vhost_virtqueue *vq,
@@ -1269,6 +1348,11 @@ vhost_scsi_handle_vq(struct vhost_scsi *vs, struct vhost_virtqueue *vq)
 	mutex_unlock(&vq->mutex);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1375| <<vhost_scsi_tmf_resp_work>> vhost_scsi_send_tmf_resp(tmf->vhost, &tmf->svq->vq, tmf->in_iovs,
+ *   - drivers/vhost/scsi.c|1430| <<vhost_scsi_handle_tmf>> vhost_scsi_send_tmf_resp(vs, vq, vc->in, vc->head, &vq->iov[vc->out],
+ */
 static void
 vhost_scsi_send_tmf_resp(struct vhost_scsi *vs, struct vhost_virtqueue *vq,
 			 int in_iovs, int vq_desc, struct iovec *resp_iov,
@@ -1285,12 +1369,25 @@ vhost_scsi_send_tmf_resp(struct vhost_scsi *vs, struct vhost_virtqueue *vq,
 	iov_iter_init(&iov_iter, READ, resp_iov, in_iovs, sizeof(rsp));
 
 	ret = copy_to_iter(&rsp, sizeof(rsp), &iov_iter);
+	/*
+	 * called by:
+	 *   - drivers/vhost/net.c|957| <<handle_tx_zerocopy>> vhost_add_used_and_signal(&net->dev, vq, head, 0);
+	 *   - drivers/vhost/scsi.c|581| <<vhost_scsi_do_evt_work>> vhost_add_used_and_signal(&vs->dev, vq, head, 0);
+	 *   - drivers/vhost/scsi.c|1022| <<vhost_scsi_send_bad_target>> vhost_add_used_and_signal(&vs->dev, vq, head, 0);
+	 *   - drivers/vhost/scsi.c|1359| <<vhost_scsi_send_tmf_resp>> vhost_add_used_and_signal(&vs->dev, vq, vq_desc, 0);
+	 *   - drivers/vhost/scsi.c|1451| <<vhost_scsi_send_an_resp>> vhost_add_used_and_signal(&vs->dev, vq, vc->head, 0);
+	 *   - drivers/vhost/test.c|87| <<handle_vq>> vhost_add_used_and_signal(&n->dev, vq, head, 0);
+	 */
 	if (likely(ret == sizeof(rsp)))
 		vhost_add_used_and_signal(&vs->dev, vq, vq_desc, 0);
 	else
 		pr_err("Faulted on virtio_scsi_ctrl_tmf_resp\n");
 }
 
+/*
+ * 在以下使用vhost_scsi_tmf_resp_work():
+ *   - drivers/vhost/scsi.c|2244| <<vhost_scsi_port_link>> vhost_work_init(&tmf->vwork, vhost_scsi_tmf_resp_work);
+ */
 static void vhost_scsi_tmf_resp_work(struct vhost_work *work)
 {
 	struct vhost_scsi_tmf *tmf = container_of(work, struct vhost_scsi_tmf,
@@ -1307,6 +1404,18 @@ static void vhost_scsi_tmf_resp_work(struct vhost_work *work)
 	vhost_scsi_release_tmf_res(tmf);
 }
 
+/*
+ * "sg_reset -d /dev/sda"
+ *
+ * vhost-9091-9149    [197] .... 10935.501792: vhost_scsi_handle_tmf <-vhost_scsi_ctl_handle_vq
+ * vhost-9091-9149    [198] .... 10935.501896: vhost_scsi_tmf_resp_work <-vhost_worker
+ * vhost-9091-9149    [198] .... 10935.501898: vhost_scsi_send_tmf_resp <-vhost_scsi_tmf_resp_work
+ * vhost-9091-9149    [198] .... 10935.501903: vhost_scsi_release_tmf_res <-vhost_scsi_tmf_resp_work
+ *
+ *
+ * called by:
+ *   - drivers/vhost/scsi.c|1555| <<vhost_scsi_ctl_handle_vq>> vhost_scsi_handle_tmf(vs, tpg, vq, &v_req.tmf, &vc);
+ */
 static void
 vhost_scsi_handle_tmf(struct vhost_scsi *vs, struct vhost_scsi_tpg *tpg,
 		      struct vhost_virtqueue *vq,
@@ -1361,6 +1470,10 @@ vhost_scsi_handle_tmf(struct vhost_scsi *vs, struct vhost_scsi_tpg *tpg,
 				 VIRTIO_SCSI_S_FUNCTION_REJECTED);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1561| <<vhost_scsi_ctl_handle_vq>> vhost_scsi_send_an_resp(vs, vq, &vc);
+ */
 static void
 vhost_scsi_send_an_resp(struct vhost_scsi *vs,
 			struct vhost_virtqueue *vq,
@@ -1557,9 +1670,24 @@ static void vhost_scsi_handle_kick(struct vhost_work *work)
 	vhost_scsi_handle_vq(vs, vq);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1822| <<vhost_scsi_set_endpoint>> vhost_scsi_flush(vs);
+ *   - drivers/vhost/scsi.c|1915| <<vhost_scsi_clear_endpoint>> vhost_scsi_flush(vs);
+ *   - drivers/vhost/scsi.c|1926| <<vhost_scsi_clear_endpoint>> vhost_scsi_flush(vs);
+ *   - drivers/vhost/scsi.c|2021| <<vhost_scsi_release>> vhost_scsi_flush(vs);
+ */
 /* Callers must hold dev mutex */
 static void vhost_scsi_flush(struct vhost_scsi *vs)
 {
+	/*
+	 * struct vhost_scsi_inflight {
+	 *     // Wait for the flush operation to finish
+	 *     struct completion comp;
+	 *     // Refcount for the inflight reqs
+	 *     struct kref kref;
+	 * };
+	 */
 	struct vhost_scsi_inflight *old_inflight[VHOST_SCSI_MAX_VQ];
 	int i;
 
@@ -1574,6 +1702,14 @@ static void vhost_scsi_flush(struct vhost_scsi *vs)
 	for (i = 0; i < VHOST_SCSI_MAX_VQ; i++)
 		kref_put(&old_inflight[i]->kref, vhost_scsi_done_inflight);
 
+	/*
+	 * called by:
+	 *   - drivers/vhost/scsi.c|1629| <<vhost_scsi_flush>> vhost_work_dev_flush(&vs->dev);
+	 *   - drivers/vhost/vhost.c|308| <<vhost_poll_flush>> vhost_work_dev_flush(poll->dev);
+	 *   - drivers/vhost/vhost.c|597| <<vhost_attach_cgroups>> vhost_work_dev_flush(dev);
+	 *   - drivers/vhost/vhost.h|49| <<vhost_attach_cgroups>> void vhost_work_dev_flush(struct vhost_dev *dev);
+	 *   - drivers/vhost/vsock.c|718| <<vhost_vsock_flush>> vhost_work_dev_flush(&vsock->dev);
+	 */
 	/* Flush both the vhost poll and vhost work */
 	vhost_work_dev_flush(&vs->dev);
 
@@ -1666,6 +1802,10 @@ static int vhost_scsi_setup_vq_cmds(struct vhost_virtqueue *vq, int max_cmds)
  *  The lock nesting rule is:
  *    vhost_scsi_mutex -> vs->dev.mutex -> tpg->tv_tpg_mutex -> vq->mutex
  */
+/*
+ * 处理:
+ *   - drivers/vhost/scsi.c|2049| <<vhost_scsi_ioctl(VHOST_SCSI_SET_ENDPOINT)>> return vhost_scsi_set_endpoint(vs, &backend);
+ */
 static int
 vhost_scsi_set_endpoint(struct vhost_scsi *vs,
 			struct vhost_scsi_target *t)
diff --git a/drivers/vhost/vhost.c b/drivers/vhost/vhost.c
index e5565227aa91..2156d9700b21 100644
--- a/drivers/vhost/vhost.c
+++ b/drivers/vhost/vhost.c
@@ -33,6 +33,57 @@
 
 #include "vhost.h"
 
+/*
+ * 5.15的
+ *
+ * root       10740  0.0  0.0      0     0 ?        S    20:34   0:00 [vhost-10719]
+ *
+ * vhost_poll_wakeup
+ * __wake_up_common
+ * eventfd_signal_mask
+ * ioeventfd_write
+ * __kvm_io_bus_write
+ * kvm_io_bus_write
+ * write_mmio
+ * emulator_read_write_onepage
+ * emulator_read_write
+ * x86_emulate_insn
+ * x86_emulate_instruction
+ * vcpu_enter_guest
+ * vcpu_run
+ * kvm_arch_vcpu_ioctl_run
+ * kvm_vcpu_ioctl
+ * __x64_sys_ioctl
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ * __GI___ioctl
+ * b'CPU 9/KVM' [10719]
+ *
+ *
+ * vhost_scsi_handle_vq
+ * vhost_worker
+ * kthread
+ * ret_from_fork
+ * b'vhost-10719' [10740]
+ *
+ *
+ * vhost_scsi_release_cmd
+ * target_release_cmd_kref
+ * target_put_sess_cmd
+ * process_one_work
+ * worker_thread
+ * kthread
+ * ret_from_fork
+ * b'kworker/53:0' [7266]
+ *
+ *
+ * vhost_scsi_complete_cmd_work
+ * vhost_worker
+ * kthread
+ * ret_from_fork
+ * b'vhost-10719' [10740]
+ */
+
 static ushort max_mem_regions = 64;
 module_param(max_mem_regions, ushort, 0444);
 MODULE_PARM_DESC(max_mem_regions,
@@ -183,6 +234,17 @@ static int vhost_poll_wakeup(wait_queue_entry_t *wait, unsigned mode, int sync,
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1981| <<vhost_scsi_open>> vhost_work_init(&vs->vs_completion_work, vhost_scsi_complete_cmd_work);
+ *   - drivers/vhost/scsi.c|1982| <<vhost_scsi_open>> vhost_work_init(&vs->vs_event_work, vhost_scsi_evt_work);
+ *   - drivers/vhost/scsi.c|2185| <<vhost_scsi_port_link>> vhost_work_init(&tmf->vwork, vhost_scsi_tmf_resp_work);
+ *   - drivers/vhost/vhost.c|254| <<vhost_poll_init>> vhost_work_init(&poll->work, fn);
+ *   - drivers/vhost/vhost.c|296| <<vhost_work_dev_flush>> vhost_work_init(&flush.work, vhost_flush_work);
+ *   - drivers/vhost/vhost.c|595| <<vhost_attach_cgroups>> vhost_work_init(&attach.work, vhost_attach_cgroups_work);
+ *   - drivers/vhost/vhost.h|39| <<vhost_attach_cgroups>> void vhost_work_init(struct vhost_work *work, vhost_work_fn_t fn);
+ *   - drivers/vhost/vsock.c|703| <<vhost_vsock_dev_open>> vhost_work_init(&vsock->send_pkt_work, vhost_transport_send_pkt_work);
+ */
 void vhost_work_init(struct vhost_work *work, vhost_work_fn_t fn)
 {
 	clear_bit(VHOST_WORK_QUEUED, &work->flags);
@@ -190,6 +252,12 @@ void vhost_work_init(struct vhost_work *work, vhost_work_fn_t fn)
 }
 EXPORT_SYMBOL_GPL(vhost_work_init);
 
+/*
+ * 在以下使用vhost_poll_init():
+ *   - drivers/vhost/vhost.c|562| <<vhost_dev_init>> vhost_poll_init(&vq->poll, vq->handle_kick, EPOLLIN, dev);
+ *   - drivers/vhost/net.c|1348| <<vhost_net_open>> vhost_poll_init(n->poll + VHOST_NET_VQ_TX, handle_tx_net, EPOLLOUT, dev);
+ *   - drivers/vhost/net.c|1349| <<vhost_net_open>> vhost_poll_init(n->poll + VHOST_NET_VQ_RX, handle_rx_net, EPOLLIN, dev);
+ */
 /* Init poll structure */
 void vhost_poll_init(struct vhost_poll *poll, vhost_work_fn_t fn,
 		     __poll_t mask, struct vhost_dev *dev)
@@ -225,6 +293,14 @@ int vhost_poll_start(struct vhost_poll *poll, struct file *file)
 }
 EXPORT_SYMBOL_GPL(vhost_poll_start);
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|430| <<vhost_net_disable_vq>> vhost_poll_stop(poll);
+ *   - drivers/vhost/test.c|292| <<vhost_test_set_backend>> vhost_poll_stop(&vq->poll);
+ *   - drivers/vhost/vhost.c|288| <<vhost_poll_start>> vhost_poll_stop(poll);
+ *   - drivers/vhost/vhost.c|802| <<vhost_dev_stop>> vhost_poll_stop(&dev->vqs[i]->poll);
+ *   - drivers/vhost/vhost.c|1931| <<vhost_vring_ioctl>> vhost_poll_stop(&vq->poll);
+ */
 /* Stop polling a file. After this function returns, it becomes safe to drop the
  * file reference. You must also flush afterwards. */
 void vhost_poll_stop(struct vhost_poll *poll)
@@ -236,6 +312,13 @@ void vhost_poll_stop(struct vhost_poll *poll)
 }
 EXPORT_SYMBOL_GPL(vhost_poll_stop);
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1629| <<vhost_scsi_flush>> vhost_work_dev_flush(&vs->dev);
+ *   - drivers/vhost/vhost.c|308| <<vhost_poll_flush>> vhost_work_dev_flush(poll->dev);
+ *   - drivers/vhost/vhost.c|597| <<vhost_attach_cgroups>> vhost_work_dev_flush(dev);
+ *   - drivers/vhost/vsock.c|718| <<vhost_vsock_flush>> vhost_work_dev_flush(&vsock->dev);
+ */
 void vhost_work_dev_flush(struct vhost_dev *dev)
 {
 	struct vhost_flush_struct flush;
@@ -252,12 +335,40 @@ EXPORT_SYMBOL_GPL(vhost_work_dev_flush);
 
 /* Flush any work that has been scheduled. When calling this, don't hold any
  * locks that are also used by the callback. */
+/*
+ * called by:
+ *   - drivers/vhost/net.c|1384| <<vhost_net_flush_vq>> vhost_poll_flush(n->poll + index);
+ *   - drivers/vhost/net.c|1385| <<vhost_net_flush_vq>> vhost_poll_flush(&n->vqs[index].vq.poll);
+ *   - drivers/vhost/test.c|149| <<vhost_test_flush_vq>> vhost_poll_flush(&n->vqs[index].poll);
+ *   - drivers/vhost/vhost.c|725| <<vhost_dev_stop>> vhost_poll_flush(&dev->vqs[i]->poll);
+ *   - drivers/vhost/vhost.c|1809| <<vhost_vring_ioctl>> vhost_poll_flush(&vq->poll);
+ *   - drivers/vhost/vsock.c|717| <<vhost_vsock_flush>> vhost_poll_flush(&vsock->vqs[i].poll);
+ */
 void vhost_poll_flush(struct vhost_poll *poll)
 {
+	/*
+	 * called by:
+	 *   - drivers/vhost/scsi.c|1629| <<vhost_scsi_flush>> vhost_work_dev_flush(&vs->dev);
+	 *   - drivers/vhost/vhost.c|308| <<vhost_poll_flush>> vhost_work_dev_flush(poll->dev);
+	 *   - drivers/vhost/vhost.c|597| <<vhost_attach_cgroups>> vhost_work_dev_flush(dev);
+	 *   - drivers/vhost/vsock.c|718| <<vhost_vsock_flush>> vhost_work_dev_flush(&vsock->dev);
+	 */
 	vhost_work_dev_flush(poll->dev);
 }
 EXPORT_SYMBOL_GPL(vhost_poll_flush);
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|440| <<vhost_scsi_release_cmd>> vhost_work_queue(&tmf->vhost->dev, &tmf->vwork);
+ *   - drivers/vhost/scsi.c|447| <<vhost_scsi_release_cmd>> vhost_work_queue(&vs->dev, &vs->vs_completion_work);
+ *   - drivers/vhost/scsi.c|1602| <<vhost_scsi_send_evt>> vhost_work_queue(&vs->dev, &vs->vs_event_work);
+ *   - drivers/vhost/vhost.c|323| <<vhost_work_dev_flush>> vhost_work_queue(dev, &flush.work);
+ *   - drivers/vhost/vhost.c|395| <<vhost_poll_queue>> vhost_work_queue(poll->dev, &poll->work);
+ *   - drivers/vhost/vhost.c|674| <<vhost_attach_cgroups>> vhost_work_queue(dev, &attach.work);
+ *   - drivers/vhost/vhost.h|40| <<vhost_attach_cgroups>> void vhost_work_queue(struct vhost_dev *dev, struct vhost_work *work);
+ *   - drivers/vhost/vsock.c|303| <<vhost_transport_send_pkt>> vhost_work_queue(&vsock->dev, &vsock->send_pkt_work);
+ *   - drivers/vhost/vsock.c|615| <<vhost_vsock_start>> vhost_work_queue(&vsock->dev, &vsock->send_pkt_work);
+ */
 void vhost_work_queue(struct vhost_dev *dev, struct vhost_work *work)
 {
 	if (!dev->worker)
@@ -268,21 +379,72 @@ void vhost_work_queue(struct vhost_dev *dev, struct vhost_work *work)
 		 * sure it was not in the list.
 		 * test_and_set_bit() implies a memory barrier.
 		 */
+		/*
+		 * 在以下使用vhost_dev->work_list:
+		 *   - drivers/vhost/vhost.c|495| <<vhost_dev_init>> init_llist_head(&dev->work_list);
+		 *   - drivers/vhost/vhost.c|271| <<vhost_work_queue>> llist_add(&work->node, &dev->work_list);
+		 *   - drivers/vhost/vhost.c|280| <<vhost_has_work>> return !llist_empty(&dev->work_list);
+		 *   - drivers/vhost/vhost.c|366| <<vhost_worker>> node = llist_del_all(&dev->work_list);
+		 *   - drivers/vhost/vhost.c|724| <<vhost_dev_cleanup>> WARN_ON(!llist_empty(&dev->work_list));
+		 *
+		 * 注意是Lock-less NULL terminated single linked list
+		 */
 		llist_add(&work->node, &dev->work_list);
 		wake_up_process(dev->worker);
 	}
 }
 EXPORT_SYMBOL_GPL(vhost_work_queue);
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|547| <<vhost_net_busy_poll>> if (vhost_has_work(&net->dev)) {
+ */
 /* A lockless hint for busy polling code to exit the loop */
 bool vhost_has_work(struct vhost_dev *dev)
 {
+	/*
+	 * 在以下使用vhost_dev->work_list:
+	 *   - drivers/vhost/vhost.c|495| <<vhost_dev_init>> init_llist_head(&dev->work_list);
+	 *   - drivers/vhost/vhost.c|271| <<vhost_work_queue>> llist_add(&work->node, &dev->work_list);
+	 *   - drivers/vhost/vhost.c|280| <<vhost_has_work>> return !llist_empty(&dev->work_list);
+	 *   - drivers/vhost/vhost.c|366| <<vhost_worker>> node = llist_del_all(&dev->work_list);
+	 *   - drivers/vhost/vhost.c|724| <<vhost_dev_cleanup>> WARN_ON(!llist_empty(&dev->work_list));
+	 *
+	 * 注意是Lock-less NULL terminated single linked list
+	 */
 	return !llist_empty(&dev->work_list);
 }
 EXPORT_SYMBOL_GPL(vhost_has_work);
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|406| <<vhost_zerocopy_callback>> vhost_poll_queue(&vq->poll);
+ *   - drivers/vhost/net.c|512| <<vhost_net_busy_poll_try_queue>> vhost_poll_queue(&vq->poll);
+ *   - drivers/vhost/net.c|515| <<vhost_net_busy_poll_try_queue>> vhost_poll_queue(&vq->poll);
+ *   - drivers/vhost/net.c|799| <<handle_tx_copy>> vhost_poll_queue(&vq->poll);
+ *   - drivers/vhost/net.c|893| <<handle_tx_zerocopy>> vhost_poll_queue(&vq->poll);
+ *   - drivers/vhost/net.c|1175| <<handle_rx>> vhost_poll_queue(&vq->poll);
+ *   - drivers/vhost/net.c|1251| <<handle_rx>> vhost_poll_queue(&vq->poll);
+ *   - drivers/vhost/vhost.c|232| <<vhost_poll_wakeup>> vhost_poll_queue(poll);
+ *   - drivers/vhost/vhost.c|557| <<vhost_exceeds_weight>> vhost_poll_queue(&vq->poll);
+ *   - drivers/vhost/vhost.c|1230| <<vhost_iotlb_notify_vq>> vhost_poll_queue(&node->vq->poll);
+ *   - drivers/vhost/vsock.c|266| <<vhost_transport_do_send_pkt>> vhost_poll_queue(&tx_vq->poll);
+ *   - drivers/vhost/vsock.c|346| <<vhost_transport_cancel_pkt>> vhost_poll_queue(&tx_vq->poll);
+ */
 void vhost_poll_queue(struct vhost_poll *poll)
 {
+	/*
+	 * called by:
+	 *   - drivers/vhost/scsi.c|440| <<vhost_scsi_release_cmd>> vhost_work_queue(&tmf->vhost->dev, &tmf->vwork);
+	 *   - drivers/vhost/scsi.c|447| <<vhost_scsi_release_cmd>> vhost_work_queue(&vs->dev, &vs->vs_completion_work);
+	 *   - drivers/vhost/scsi.c|1602| <<vhost_scsi_send_evt>> vhost_work_queue(&vs->dev, &vs->vs_event_work);
+	 *   - drivers/vhost/vhost.c|323| <<vhost_work_dev_flush>> vhost_work_queue(dev, &flush.work);
+	 *   - drivers/vhost/vhost.c|395| <<vhost_poll_queue>> vhost_work_queue(poll->dev, &poll->work);
+	 *   - drivers/vhost/vhost.c|674| <<vhost_attach_cgroups>> vhost_work_queue(dev, &attach.work);
+	 *   - drivers/vhost/vhost.h|40| <<vhost_attach_cgroups>> void vhost_work_queue(struct vhost_dev *dev, struct vhost_work *work);
+	 *   - drivers/vhost/vsock.c|303| <<vhost_transport_send_pkt>> vhost_work_queue(&vsock->dev, &vsock->send_pkt_work);
+	 *   - drivers/vhost/vsock.c|615| <<vhost_vsock_start>> vhost_work_queue(&vsock->dev, &vsock->send_pkt_work);
+	 */
 	vhost_work_queue(poll->dev, &poll->work);
 }
 EXPORT_SYMBOL_GPL(vhost_poll_queue);
@@ -363,6 +525,16 @@ static int vhost_worker(void *data)
 			break;
 		}
 
+		/*
+		 * 在以下使用vhost_dev->work_list:
+		 *   - drivers/vhost/vhost.c|495| <<vhost_dev_init>> init_llist_head(&dev->work_list);
+		 *   - drivers/vhost/vhost.c|271| <<vhost_work_queue>> llist_add(&work->node, &dev->work_list);
+		 *   - drivers/vhost/vhost.c|280| <<vhost_has_work>> return !llist_empty(&dev->work_list);
+		 *   - drivers/vhost/vhost.c|366| <<vhost_worker>> node = llist_del_all(&dev->work_list);
+		 *   - drivers/vhost/vhost.c|724| <<vhost_dev_cleanup>> WARN_ON(!llist_empty(&dev->work_list));
+		 *
+		 * 注意是Lock-less NULL terminated single linked list
+		 */
 		node = llist_del_all(&dev->work_list);
 		if (!node)
 			schedule();
@@ -394,6 +566,10 @@ static void vhost_vq_free_iovecs(struct vhost_virtqueue *vq)
 	vq->heads = NULL;
 }
 
+/*
+ * called by:
+ *   - ddrivers/vhost/vhost.c|803| <<vhost_dev_set_owner>> err = vhost_dev_alloc_iovecs(dev);
+ */
 /* Helper to allocate iovec buffers for all vqs. */
 static long vhost_dev_alloc_iovecs(struct vhost_dev *dev)
 {
@@ -492,6 +668,16 @@ void vhost_dev_init(struct vhost_dev *dev,
 	dev->byte_weight = byte_weight;
 	dev->use_worker = use_worker;
 	dev->msg_handler = msg_handler;
+	/*
+	 * 在以下使用vhost_dev->work_list:
+	 *   - drivers/vhost/vhost.c|495| <<vhost_dev_init>> init_llist_head(&dev->work_list);
+	 *   - drivers/vhost/vhost.c|271| <<vhost_work_queue>> llist_add(&work->node, &dev->work_list);
+	 *   - drivers/vhost/vhost.c|280| <<vhost_has_work>> return !llist_empty(&dev->work_list);
+	 *   - drivers/vhost/vhost.c|366| <<vhost_worker>> node = llist_del_all(&dev->work_list);
+	 *   - drivers/vhost/vhost.c|724| <<vhost_dev_cleanup>> WARN_ON(!llist_empty(&dev->work_list));
+	 *
+	 * 注意是Lock-less NULL terminated single linked list
+	 */
 	init_llist_head(&dev->work_list);
 	init_waitqueue_head(&dev->wait);
 	INIT_LIST_HEAD(&dev->read_list);
@@ -721,6 +907,16 @@ void vhost_dev_cleanup(struct vhost_dev *dev)
 	dev->iotlb = NULL;
 	vhost_clear_msg(dev);
 	wake_up_interruptible_poll(&dev->wait, EPOLLIN | EPOLLRDNORM);
+	/*
+	 * 在以下使用vhost_dev->work_list:
+	 *   - drivers/vhost/vhost.c|495| <<vhost_dev_init>> init_llist_head(&dev->work_list);
+	 *   - drivers/vhost/vhost.c|271| <<vhost_work_queue>> llist_add(&work->node, &dev->work_list);
+	 *   - drivers/vhost/vhost.c|280| <<vhost_has_work>> return !llist_empty(&dev->work_list);
+	 *   - drivers/vhost/vhost.c|366| <<vhost_worker>> node = llist_del_all(&dev->work_list);
+	 *   - drivers/vhost/vhost.c|724| <<vhost_dev_cleanup>> WARN_ON(!llist_empty(&dev->work_list));
+	 *
+	 * 注意是Lock-less NULL terminated single linked list
+	 */
 	WARN_ON(!llist_empty(&dev->work_list));
 	if (dev->worker) {
 		kthread_stop(dev->worker);
@@ -744,6 +940,11 @@ static bool log_access_ok(void __user *log_base, u64 addr, unsigned long sz)
 			 (sz + VHOST_PAGE_SIZE * 8 - 1) / VHOST_PAGE_SIZE / 8);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|910| <<vq_memory_access_ok>> if (vhost_overflow(map->addr, map->size))
+ *   - drivers/vhost/vhost.c|1229| <<umem_access_ok>> if (vhost_overflow(uaddr, size))
+ */
 /* Make sure 64 bit math will not overflow. */
 static bool vhost_overflow(u64 uaddr, u64 size)
 {
@@ -756,6 +957,11 @@ static bool vhost_overflow(u64 uaddr, u64 size)
 	return uaddr > ULONG_MAX - size + 1;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|951| <<memory_access_ok>> ok = vq_memory_access_ok(d->vqs[i]->log_base,
+ *   - drivers/vhost/vhost.c|1574| <<vq_log_access_ok>> return vq_memory_access_ok(log_base, vq->umem,
+ */
 /* Caller should have vq mutex and device mutex. */
 static bool vq_memory_access_ok(void __user *log_base, struct vhost_iotlb *umem,
 				int log_all)
@@ -796,6 +1002,11 @@ static inline void __user *vhost_vq_meta_fetch(struct vhost_virtqueue *vq,
 
 /* Can we switch to this memory table? */
 /* Caller should have device mutex but not vq mutex */
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|1546| <<vhost_log_access_ok>> return memory_access_ok(dev, dev->umem, 1);
+ *   - drivers/vhost/vhost.c|1644| <<vhost_set_memory>> if (!memory_access_ok(d, newumem, 0))
+ */
 static bool memory_access_ok(struct vhost_dev *d, struct vhost_iotlb *umem,
 			     int log_all)
 {
@@ -844,6 +1055,23 @@ static int vhost_copy_to_user(struct vhost_virtqueue *vq, void __user *to,
 		if (uaddr)
 			return __copy_to_user(uaddr, from, size);
 
+		/*
+		 * called by:
+		 *   - drivers/vhost/vhost.c|1054| <<vhost_copy_to_user>> ret = translate_desc(vq, (u64)(uintptr_t)to, size,
+		 *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_WO);
+		 *   - drivers/vhost/vhost.c|1089| <<vhost_copy_from_user>> ret = translate_desc(vq, (u64)(uintptr_t)from, size,
+		 *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|1114| <<__vhost_get_user_slow>> ret = translate_desc(vq, (u64)(uintptr_t)addr, size,
+		 *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|2214| <<log_used>> ret = translate_desc(vq, (uintptr_t)vq->used + used_offset, len,
+		 *                  iov, 64, VHOST_ACCESS_WO);
+		 *   - drivers/vhost/vhost.c|2442| <<get_indirect>> ret = translate_desc(vq, vhost64_to_cpu(vq, indirect->addr), len,
+		 *                  vq->indirect, UIO_MAXIOV, VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|2483| <<get_indirect>> ret = translate_desc(vq, vhost64_to_cpu(vq, desc.addr),
+		 *                  vhost32_to_cpu(vq, desc.len), iov + iov_count, iov_size - iov_count, access);
+		 *   - drivers/vhost/vhost.c|2623| <<vhost_get_vq_desc>> ret = translate_desc(vq, vhost64_to_cpu(vq, desc.addr),
+		 *                  vhost32_to_cpu(vq, desc.len), iov + iov_count, iov_size - iov_count, access);
+		 */
 		ret = translate_desc(vq, (u64)(uintptr_t)to, size, vq->iotlb_iov,
 				     ARRAY_SIZE(vq->iotlb_iov),
 				     VHOST_ACCESS_WO);
@@ -879,6 +1107,23 @@ static int vhost_copy_from_user(struct vhost_virtqueue *vq, void *to,
 		if (uaddr)
 			return __copy_from_user(to, uaddr, size);
 
+		/*
+		 * called by:
+		 *   - drivers/vhost/vhost.c|1054| <<vhost_copy_to_user>> ret = translate_desc(vq, (u64)(uintptr_t)to, size,
+		 *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_WO);
+		 *   - drivers/vhost/vhost.c|1089| <<vhost_copy_from_user>> ret = translate_desc(vq, (u64)(uintptr_t)from, size,
+		 *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|1114| <<__vhost_get_user_slow>> ret = translate_desc(vq, (u64)(uintptr_t)addr, size,
+		 *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|2214| <<log_used>> ret = translate_desc(vq, (uintptr_t)vq->used + used_offset, len,
+		 *                  iov, 64, VHOST_ACCESS_WO);
+		 *   - drivers/vhost/vhost.c|2442| <<get_indirect>> ret = translate_desc(vq, vhost64_to_cpu(vq, indirect->addr), len,
+		 *                  vq->indirect, UIO_MAXIOV, VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|2483| <<get_indirect>> ret = translate_desc(vq, vhost64_to_cpu(vq, desc.addr),
+		 *                  vhost32_to_cpu(vq, desc.len), iov + iov_count, iov_size - iov_count, access);
+		 *   - drivers/vhost/vhost.c|2623| <<vhost_get_vq_desc>> ret = translate_desc(vq, vhost64_to_cpu(vq, desc.addr),
+		 *                  vhost32_to_cpu(vq, desc.len), iov + iov_count, iov_size - iov_count, access);
+		 */
 		ret = translate_desc(vq, (u64)(uintptr_t)from, size, vq->iotlb_iov,
 				     ARRAY_SIZE(vq->iotlb_iov),
 				     VHOST_ACCESS_RO);
@@ -904,6 +1149,23 @@ static void __user *__vhost_get_user_slow(struct vhost_virtqueue *vq,
 {
 	int ret;
 
+	/*
+	 * called by:
+	 *   - drivers/vhost/vhost.c|1054| <<vhost_copy_to_user>> ret = translate_desc(vq, (u64)(uintptr_t)to, size,
+	 *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_WO);
+	 *   - drivers/vhost/vhost.c|1089| <<vhost_copy_from_user>> ret = translate_desc(vq, (u64)(uintptr_t)from, size,
+	 *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_RO);
+	 *   - drivers/vhost/vhost.c|1114| <<__vhost_get_user_slow>> ret = translate_desc(vq, (u64)(uintptr_t)addr, size,
+	 *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_RO);
+	 *   - drivers/vhost/vhost.c|2214| <<log_used>> ret = translate_desc(vq, (uintptr_t)vq->used + used_offset, len,
+	 *                  iov, 64, VHOST_ACCESS_WO);
+	 *   - drivers/vhost/vhost.c|2442| <<get_indirect>> ret = translate_desc(vq, vhost64_to_cpu(vq, indirect->addr), len,
+	 *                  vq->indirect, UIO_MAXIOV, VHOST_ACCESS_RO);
+	 *   - drivers/vhost/vhost.c|2483| <<get_indirect>> ret = translate_desc(vq, vhost64_to_cpu(vq, desc.addr),
+	 *                  vhost32_to_cpu(vq, desc.len), iov + iov_count, iov_size - iov_count, access);
+	 *   - drivers/vhost/vhost.c|2623| <<vhost_get_vq_desc>> ret = translate_desc(vq, vhost64_to_cpu(vq, desc.addr),
+	 *                  vhost32_to_cpu(vq, desc.len), iov + iov_count, iov_size - iov_count, access);
+	 */
 	ret = translate_desc(vq, (u64)(uintptr_t)addr, size, vq->iotlb_iov,
 			     ARRAY_SIZE(vq->iotlb_iov),
 			     VHOST_ACCESS_RO);
@@ -1400,6 +1662,13 @@ int vq_meta_prefetch(struct vhost_virtqueue *vq)
 }
 EXPORT_SYMBOL_GPL(vq_meta_prefetch);
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|1655| <<vhost_net_set_features>> !vhost_log_access_ok(&n->dev))
+ *   - drivers/vhost/scsi.c|1963| <<vhost_scsi_set_features>> !vhost_log_access_ok(&vs->dev)) {
+ *   - drivers/vhost/test.c|254| <<vhost_test_set_features>> !vhost_log_access_ok(&n->dev)) {
+ *   - drivers/vhost/vsock.c|837| <<vhost_vsock_set_features>> !vhost_log_access_ok(&vsock->dev)) {
+ */
 /* Can we log writes? */
 /* Caller should have device mutex but not vq mutex */
 bool vhost_log_access_ok(struct vhost_dev *dev)
@@ -1408,6 +1677,12 @@ bool vhost_log_access_ok(struct vhost_dev *dev)
 }
 EXPORT_SYMBOL_GPL(vhost_log_access_ok);
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|1576| <<vq_log_access_ok>> vq_log_used_access_ok(vq, log_base, vq->log_used, vq->log_addr);
+ *   - drivers/vhost/vhost.c|1729| <<vhost_vring_set_addr>> if (!vq_log_used_access_ok(vq, vq->log_base,
+ *                                    a.flags & (0x1 << VHOST_VRING_F_LOG), a.log_guest_addr))
+ */
 static bool vq_log_used_access_ok(struct vhost_virtqueue *vq,
 				  void __user *log_base,
 				  bool log_used,
@@ -1424,6 +1699,11 @@ static bool vq_log_used_access_ok(struct vhost_virtqueue *vq,
 
 /* Verify access for write logging. */
 /* Caller should have vq mutex and device mutex */
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|1490| <<vhost_vq_access_ok>> if (!vq_log_access_ok(vq, vq->log_base))
+ *   - drivers/vhost/vhost.c|1879| <<vhost_dev_ioctl(VHOST_SET_LOG_BASE)>> if (vq->private_data && !vq_log_access_ok(vq, base))
+ */
 static bool vq_log_access_ok(struct vhost_virtqueue *vq,
 			     void __user *log_base)
 {
@@ -1432,6 +1712,16 @@ static bool vq_log_access_ok(struct vhost_virtqueue *vq,
 		vq_log_used_access_ok(vq, log_base, vq->log_used, vq->log_addr);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|1529| <<vhost_net_set_backend>> if (!vhost_vq_access_ok(vq)) {
+ *   - drivers/vhost/scsi.c|1749| <<vhost_scsi_set_endpoint>> if (!vhost_vq_access_ok(&vs->vqs[index].vq)) {
+ *   - drivers/vhost/scsi.c|1874| <<vhost_scsi_clear_endpoint>> if (!vhost_vq_access_ok(&vs->vqs[index].vq)) {
+ *   - drivers/vhost/test.c|189| <<vhost_test_run>> if (!vhost_vq_access_ok(&n->vqs[index])) {
+ *   - drivers/vhost/test.c|287| <<vhost_test_set_backend>> if (!vhost_vq_access_ok(vq)) {
+ *   - drivers/vhost/vhost.c|423| <<vhost_vq_is_setup>> return vq->avail && vq->desc && vq->used && vhost_vq_access_ok(vq);
+ *   - drivers/vhost/vsock.c|597| <<vhost_vsock_start>> if (!vhost_vq_access_ok(vq)) {
+ */
 /* Can we start vq? */
 /* Caller should have vq mutex and device mutex */
 bool vhost_vq_access_ok(struct vhost_virtqueue *vq)
@@ -1443,6 +1733,10 @@ bool vhost_vq_access_ok(struct vhost_virtqueue *vq)
 }
 EXPORT_SYMBOL_GPL(vhost_vq_access_ok);
 
+/*
+ * 处理VHOST_SET_MEM_TABLE:
+ *   - drivers/vhost/vhost.c|1965| <<vhost_dev_ioctl>> r = vhost_set_memory(d, argp);
+ */
 static long vhost_set_memory(struct vhost_dev *d, struct vhost_memory __user *m)
 {
 	struct vhost_memory mem, *newmem;
@@ -1531,6 +1825,10 @@ static long vhost_vring_set_num(struct vhost_dev *d,
 	return 0;
 }
 
+/*
+ * 处理VHOST_SET_VRING_ADDR:
+ *   - drivers/vhost/vhost.c|1600| <<vhost_vring_set_num_addr>> r = vhost_vring_set_addr(d, vq, argp);
+ */
 static long vhost_vring_set_addr(struct vhost_dev *d,
 				 struct vhost_virtqueue *vq,
 				 void __user *argp)
@@ -1583,6 +1881,10 @@ static long vhost_vring_set_addr(struct vhost_dev *d,
 	return 0;
 }
 
+/*
+ * 处理VHOST_SET_VRING_NUM或VHOST_SET_VRING_ADDR:
+ *   - drivers/vhost/vhost.c|1633| <<vhost_vring_ioctl>> return vhost_vring_set_num_addr(d, vq, ioctl, argp);
+ */
 static long vhost_vring_set_num_addr(struct vhost_dev *d,
 				     struct vhost_virtqueue *vq,
 				     unsigned int ioctl,
@@ -1607,6 +1909,14 @@ static long vhost_vring_set_num_addr(struct vhost_dev *d,
 
 	return r;
 }
+/*
+ * called by:
+ *   - drivers/vhost/net.c|1745| <<vhost_net_ioctl>> r = vhost_vring_ioctl(&n->dev, ioctl, argp);
+ *   - drivers/vhost/scsi.c|2135| <<vhost_scsi_ioctl>> r = vhost_vring_ioctl(&vs->dev, ioctl, argp);
+ *   - drivers/vhost/test.c|354| <<vhost_test_ioctl>> r = vhost_vring_ioctl(&n->dev, ioctl, argp);
+ *   - drivers/vhost/vdpa.c|691| <<vhost_vdpa_vring_ioctl>> r = vhost_vring_ioctl(&v->vdev, cmd, argp);
+ *   - drivers/vhost/vsock.c|909| <<vhost_vsock_dev_ioctl>> r = vhost_vring_ioctl(&vsock->dev, ioctl, argp);
+ */
 long vhost_vring_ioctl(struct vhost_dev *d, unsigned int ioctl, void __user *argp)
 {
 	struct file *eventfp, *filep = NULL;
@@ -1746,6 +2056,15 @@ long vhost_vring_ioctl(struct vhost_dev *d, unsigned int ioctl, void __user *arg
 
 	mutex_unlock(&vq->mutex);
 
+	/*
+	 * called by:
+	 *   - drivers/vhost/net.c|1384| <<vhost_net_flush_vq>> vhost_poll_flush(n->poll + index);
+	 *   - drivers/vhost/net.c|1385| <<vhost_net_flush_vq>> vhost_poll_flush(&n->vqs[index].vq.poll);
+	 *   - drivers/vhost/test.c|149| <<vhost_test_flush_vq>> vhost_poll_flush(&n->vqs[index].poll);
+	 *   - drivers/vhost/vhost.c|725| <<vhost_dev_stop>> vhost_poll_flush(&dev->vqs[i]->poll);
+	 *   - drivers/vhost/vhost.c|1809| <<vhost_vring_ioctl>> vhost_poll_flush(&vq->poll);
+	 *   - drivers/vhost/vsock.c|717| <<vhost_vsock_flush>> vhost_poll_flush(&vsock->vqs[i].poll);
+	 */
 	if (pollstop && vq->handle_kick)
 		vhost_poll_flush(&vq->poll);
 	return r;
@@ -1947,6 +2266,23 @@ static int log_used(struct vhost_virtqueue *vq, u64 used_offset, u64 len)
 	if (!vq->iotlb)
 		return log_write(vq->log_base, vq->log_addr + used_offset, len);
 
+	/*
+	 * called by:
+	 *   - drivers/vhost/vhost.c|1054| <<vhost_copy_to_user>> ret = translate_desc(vq, (u64)(uintptr_t)to, size,
+	 *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_WO);
+	 *   - drivers/vhost/vhost.c|1089| <<vhost_copy_from_user>> ret = translate_desc(vq, (u64)(uintptr_t)from, size,
+	 *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_RO);
+	 *   - drivers/vhost/vhost.c|1114| <<__vhost_get_user_slow>> ret = translate_desc(vq, (u64)(uintptr_t)addr, size,
+	 *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_RO);
+	 *   - drivers/vhost/vhost.c|2214| <<log_used>> ret = translate_desc(vq, (uintptr_t)vq->used + used_offset, len,
+	 *                  iov, 64, VHOST_ACCESS_WO);
+	 *   - drivers/vhost/vhost.c|2442| <<get_indirect>> ret = translate_desc(vq, vhost64_to_cpu(vq, indirect->addr), len,
+	 *                  vq->indirect, UIO_MAXIOV, VHOST_ACCESS_RO);
+	 *   - drivers/vhost/vhost.c|2483| <<get_indirect>> ret = translate_desc(vq, vhost64_to_cpu(vq, desc.addr),
+	 *                  vhost32_to_cpu(vq, desc.len), iov + iov_count, iov_size - iov_count, access);
+	 *   - drivers/vhost/vhost.c|2623| <<vhost_get_vq_desc>> ret = translate_desc(vq, vhost64_to_cpu(vq, desc.addr),
+	 *                  vhost32_to_cpu(vq, desc.len), iov + iov_count, iov_size - iov_count, access);
+	 */
 	ret = translate_desc(vq, (uintptr_t)vq->used + used_offset,
 			     len, iov, 64, VHOST_ACCESS_WO);
 	if (ret < 0)
@@ -1987,6 +2323,30 @@ int vhost_log_write(struct vhost_virtqueue *vq, struct vhost_log *log,
 			return r;
 		len -= l;
 		if (!len) {
+			/*
+			 * 在以下设置vhost_dev->log_ctx:
+			 *   - drivers/vhost/vhost.c|657| <<vhost_dev_init>> dev->log_ctx = NULL;
+			 *   - drivers/vhost/vhost.c|898| <<vhost_dev_cleanup>> dev->log_ctx = NULL;
+			 *   - drivers/vhost/vhost.c|2100| <<vhost_dev_ioctl(VHOST_SET_LOG_FD)>> swap(ctx, d->log_ctx);
+			 * 在以下使用vhost_dev->log_ctx:
+			 *   - drivers/vhost/vhost.c|896| <<vhost_dev_cleanup>> if (dev->log_ctx)
+			 *   - drivers/vhost/vhost.c|897| <<vhost_dev_cleanup>> eventfd_ctx_put(dev->log_ctx);
+			 *   - drivers/vhost/vhost.c|2103| <<vhost_dev_ioctl(VHOST_SET_LOG_FD)>> d->vqs[i]->log_ctx = d->log_ctx;
+			 * 在以下设置vhost_virtqueue->log_ctx:
+			 *   - drivers/vhost/vhost.c|501| <<vhost_vq_reset>> vq->log_ctx = NULL;
+			 *   - drivers/vhost/vhost.c|2103| <<vhost_dev_ioctl(VHOST_SET_LOG_FD)>> d->vqs[i]->log_ctx = d->log_ctx;
+			 * 在以下使用vhost_virtqueue->log_ctx:
+			 *   - drivers/vhost/vhost.c|2254| <<vhost_log_write>> if (vq->log_ctx)
+			 *   - drivers/vhost/vhost.c|2255| <<vhost_log_write>> eventfd_signal(vq->log_ctx, 1);
+			 *   - drivers/vhost/vhost.c|2277| <<vhost_update_used_flags>> if (vq->log_ctx)
+			 *   - drivers/vhost/vhost.c|2278| <<vhost_update_used_flags>> eventfd_signal(vq->log_ctx, 1);
+			 *   - drivers/vhost/vhost.c|2295| <<vhost_update_avail_event>> if (vq->log_ctx)
+			 *   - drivers/vhost/vhost.c|2296| <<vhost_update_avail_event>> eventfd_signal(vq->log_ctx, 1);
+			 *   - drivers/vhost/vhost.c|2721| <<vhost_add_used_n>> if (vq->log_ctx)
+			 *   - drivers/vhost/vhost.c|2722| <<vhost_add_used_n>> eventfd_signal(vq->log_ctx, 1);
+			 *
+			 * 目前在QEMU没有见到使用VHOST_SET_LOG_FD
+			 */
 			if (vq->log_ctx)
 				eventfd_signal(vq->log_ctx, 1);
 			return 0;
@@ -1998,6 +2358,12 @@ int vhost_log_write(struct vhost_virtqueue *vq, struct vhost_log *log,
 }
 EXPORT_SYMBOL_GPL(vhost_log_write);
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2408| <<vhost_vq_init_access>> r = vhost_update_used_flags(vq);
+ *   - drivers/vhost/vhost.c|3077| <<vhost_enable_notify>> r = vhost_update_used_flags(vq);
+ *   - drivers/vhost/vhost.c|3114| <<vhost_disable_notify>> r = vhost_update_used_flags(vq);
+ */
 static int vhost_update_used_flags(struct vhost_virtqueue *vq)
 {
 	void __user *used;
@@ -2016,6 +2382,10 @@ static int vhost_update_used_flags(struct vhost_virtqueue *vq)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|3084| <<vhost_enable_notify>> r = vhost_update_avail_event(vq, vq->avail_idx);
+ */
 static int vhost_update_avail_event(struct vhost_virtqueue *vq, u16 avail_event)
 {
 	if (vhost_put_avail_event(vq))
@@ -2069,9 +2439,43 @@ int vhost_vq_init_access(struct vhost_virtqueue *vq)
 }
 EXPORT_SYMBOL_GPL(vhost_vq_init_access);
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|1054| <<vhost_copy_to_user>> ret = translate_desc(vq, (u64)(uintptr_t)to, size,
+ *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_WO);
+ *   - drivers/vhost/vhost.c|1089| <<vhost_copy_from_user>> ret = translate_desc(vq, (u64)(uintptr_t)from, size,
+ *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_RO);
+ *   - drivers/vhost/vhost.c|1114| <<__vhost_get_user_slow>> ret = translate_desc(vq, (u64)(uintptr_t)addr, size,
+ *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_RO);
+ *   - drivers/vhost/vhost.c|2214| <<log_used>> ret = translate_desc(vq, (uintptr_t)vq->used + used_offset, len,
+ *                  iov, 64, VHOST_ACCESS_WO);
+ *   - drivers/vhost/vhost.c|2442| <<get_indirect>> ret = translate_desc(vq, vhost64_to_cpu(vq, indirect->addr), len,
+ *                  vq->indirect, UIO_MAXIOV, VHOST_ACCESS_RO);
+ *   - drivers/vhost/vhost.c|2483| <<get_indirect>> ret = translate_desc(vq, vhost64_to_cpu(vq, desc.addr),
+ *                  vhost32_to_cpu(vq, desc.len), iov + iov_count, iov_size - iov_count, access);
+ *   - drivers/vhost/vhost.c|2623| <<vhost_get_vq_desc>> ret = translate_desc(vq, vhost64_to_cpu(vq, desc.addr),
+ *                  vhost32_to_cpu(vq, desc.len), iov + iov_count, iov_size - iov_count, access);
+ */
 static int translate_desc(struct vhost_virtqueue *vq, u64 addr, u32 len,
 			  struct iovec iov[], int iov_size, int access)
 {
+	/*
+	 * struct vhost_iotlb_map {
+	 *     struct rb_node rb;
+	 *     struct list_head link;
+	 *     u64 start;
+	 *     u64 last;
+	 *     u64 size;
+	 *     u64 addr;
+	 * #define VHOST_MAP_RO 0x1
+	 * #define VHOST_MAP_WO 0x2
+	 * #define VHOST_MAP_RW 0x3
+	 *     u32 perm;
+	 *     u32 flags_padding;
+	 *     u64 __subtree_last;
+	 *     void *opaque;
+	 * };
+	 */
 	const struct vhost_iotlb_map *map;
 	struct vhost_dev *dev = vq->dev;
 	struct vhost_iotlb *umem = dev->iotlb ? dev->iotlb : dev->umem;
@@ -2151,6 +2555,23 @@ static int get_indirect(struct vhost_virtqueue *vq,
 		return -EINVAL;
 	}
 
+	/*
+	 * called by:
+	 *   - drivers/vhost/vhost.c|1054| <<vhost_copy_to_user>> ret = translate_desc(vq, (u64)(uintptr_t)to, size,
+	 *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_WO);
+	 *   - drivers/vhost/vhost.c|1089| <<vhost_copy_from_user>> ret = translate_desc(vq, (u64)(uintptr_t)from, size,
+	 *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_RO);
+	 *   - drivers/vhost/vhost.c|1114| <<__vhost_get_user_slow>> ret = translate_desc(vq, (u64)(uintptr_t)addr, size,
+	 *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_RO);
+	 *   - drivers/vhost/vhost.c|2214| <<log_used>> ret = translate_desc(vq, (uintptr_t)vq->used + used_offset, len,
+	 *                  iov, 64, VHOST_ACCESS_WO);
+	 *   - drivers/vhost/vhost.c|2442| <<get_indirect>> ret = translate_desc(vq, vhost64_to_cpu(vq, indirect->addr), len,
+	 *                  vq->indirect, UIO_MAXIOV, VHOST_ACCESS_RO);
+	 *   - drivers/vhost/vhost.c|2483| <<get_indirect>> ret = translate_desc(vq, vhost64_to_cpu(vq, desc.addr),
+	 *                  vhost32_to_cpu(vq, desc.len), iov + iov_count, iov_size - iov_count, access);
+	 *   - drivers/vhost/vhost.c|2623| <<vhost_get_vq_desc>> ret = translate_desc(vq, vhost64_to_cpu(vq, desc.addr),
+	 *                  vhost32_to_cpu(vq, desc.len), iov + iov_count, iov_size - iov_count, access);
+	 */
 	ret = translate_desc(vq, vhost64_to_cpu(vq, indirect->addr), len, vq->indirect,
 			     UIO_MAXIOV, VHOST_ACCESS_RO);
 	if (unlikely(ret < 0)) {
@@ -2192,6 +2613,23 @@ static int get_indirect(struct vhost_virtqueue *vq,
 		else
 			access = VHOST_ACCESS_RO;
 
+		/*
+		 * called by:
+		 *   - drivers/vhost/vhost.c|1054| <<vhost_copy_to_user>> ret = translate_desc(vq, (u64)(uintptr_t)to, size,
+		 *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_WO);
+		 *   - drivers/vhost/vhost.c|1089| <<vhost_copy_from_user>> ret = translate_desc(vq, (u64)(uintptr_t)from, size,
+		 *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|1114| <<__vhost_get_user_slow>> ret = translate_desc(vq, (u64)(uintptr_t)addr, size,
+		 *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|2214| <<log_used>> ret = translate_desc(vq, (uintptr_t)vq->used + used_offset, len,
+		 *                  iov, 64, VHOST_ACCESS_WO);
+		 *   - drivers/vhost/vhost.c|2442| <<get_indirect>> ret = translate_desc(vq, vhost64_to_cpu(vq, indirect->addr), len,
+		 *                  vq->indirect, UIO_MAXIOV, VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|2483| <<get_indirect>> ret = translate_desc(vq, vhost64_to_cpu(vq, desc.addr),
+		 *                  vhost32_to_cpu(vq, desc.len), iov + iov_count, iov_size - iov_count, access);
+		 *   - drivers/vhost/vhost.c|2623| <<vhost_get_vq_desc>> ret = translate_desc(vq, vhost64_to_cpu(vq, desc.addr),
+		 *                  vhost32_to_cpu(vq, desc.len), iov + iov_count, iov_size - iov_count, access);
+		 */
 		ret = translate_desc(vq, vhost64_to_cpu(vq, desc.addr),
 				     vhost32_to_cpu(vq, desc.len), iov + iov_count,
 				     iov_size - iov_count, access);
@@ -2332,6 +2770,23 @@ int vhost_get_vq_desc(struct vhost_virtqueue *vq,
 			access = VHOST_ACCESS_WO;
 		else
 			access = VHOST_ACCESS_RO;
+		/*
+		 * called by:
+		 *   - drivers/vhost/vhost.c|1054| <<vhost_copy_to_user>> ret = translate_desc(vq, (u64)(uintptr_t)to, size,
+		 *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_WO);
+		 *   - drivers/vhost/vhost.c|1089| <<vhost_copy_from_user>> ret = translate_desc(vq, (u64)(uintptr_t)from, size,
+		 *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|1114| <<__vhost_get_user_slow>> ret = translate_desc(vq, (u64)(uintptr_t)addr, size,
+		 *                  vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov), VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|2214| <<log_used>> ret = translate_desc(vq, (uintptr_t)vq->used + used_offset, len,
+		 *                  iov, 64, VHOST_ACCESS_WO);
+		 *   - drivers/vhost/vhost.c|2442| <<get_indirect>> ret = translate_desc(vq, vhost64_to_cpu(vq, indirect->addr), len,
+		 *                  vq->indirect, UIO_MAXIOV, VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|2483| <<get_indirect>> ret = translate_desc(vq, vhost64_to_cpu(vq, desc.addr),
+		 *                  vhost32_to_cpu(vq, desc.len), iov + iov_count, iov_size - iov_count, access);
+		 *   - drivers/vhost/vhost.c|2623| <<vhost_get_vq_desc>> ret = translate_desc(vq, vhost64_to_cpu(vq, desc.addr),
+		 *                  vhost32_to_cpu(vq, desc.len), iov + iov_count, iov_size - iov_count, access);
+		 */
 		ret = translate_desc(vq, vhost64_to_cpu(vq, desc.addr),
 				     vhost32_to_cpu(vq, desc.len), iov + iov_count,
 				     iov_size - iov_count, access);
@@ -2372,6 +2827,15 @@ int vhost_get_vq_desc(struct vhost_virtqueue *vq,
 }
 EXPORT_SYMBOL_GPL(vhost_get_vq_desc);
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|819| <<handle_tx_copy>> vhost_discard_vq_desc(vq, 1);
+ *   - drivers/vhost/net.c|840| <<handle_tx_copy>> vhost_discard_vq_desc(vq, 1);
+ *   - drivers/vhost/net.c|948| <<handle_tx_zerocopy>> vhost_discard_vq_desc(vq, 1);
+ *   - drivers/vhost/net.c|1107| <<get_rx_bufs>> vhost_discard_vq_desc(vq, headcount);
+ *   - drivers/vhost/net.c|1214| <<handle_rx>> vhost_discard_vq_desc(vq, headcount);
+ *   - drivers/vhost/net.c|1238| <<handle_rx>> vhost_discard_vq_desc(vq, headcount);
+ */
 /* Reverse the effect of vhost_get_vq_desc. Useful for error handling. */
 void vhost_discard_vq_desc(struct vhost_virtqueue *vq, int n)
 {
@@ -2379,6 +2843,13 @@ void vhost_discard_vq_desc(struct vhost_virtqueue *vq, int n)
 }
 EXPORT_SYMBOL_GPL(vhost_discard_vq_desc);
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|673| <<vhost_scsi_complete_cmd_work>> vhost_add_used(cmd->tvc_vq, cmd->tvc_vq_desc, 0);
+ *   - drivers/vhost/vhost.c|2969| <<vhost_add_used_and_signal>> vhost_add_used(vq, head, len);
+ *   - drivers/vhost/vsock.c|222| <<vhost_transport_do_send_pkt>> vhost_add_used(vq, head, sizeof(pkt->hdr) + payload_len);
+ *   - drivers/vhost/vsock.c|557| <<vhost_vsock_handle_tx_kick>> vhost_add_used(vq, head, 0);
+ */
 /* After we've used one of their buffers, we tell them about it.  We'll then
  * want to notify the guest, using eventfd. */
 int vhost_add_used(struct vhost_virtqueue *vq, unsigned int head, int len)
@@ -2388,10 +2859,20 @@ int vhost_add_used(struct vhost_virtqueue *vq, unsigned int head, int len)
 		cpu_to_vhost32(vq, len)
 	};
 
+	/*
+	 * called by:
+	 *   - drivers/vhost/vhost.c|2843| <<vhost_add_used>> return vhost_add_used_n(vq, &heads, 1);
+	 *   - drivers/vhost/vhost.c|2991| <<vhost_add_used_and_signal_n>> vhost_add_used_n(vq, heads, count);
+	 */
 	return vhost_add_used_n(vq, &heads, 1);
 }
 EXPORT_SYMBOL_GPL(vhost_add_used);
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2894| <<vhost_add_used_n>> r = __vhost_add_used_n(vq, heads, n);
+ *   - drivers/vhost/vhost.c|2900| <<vhost_add_used_n>> r = __vhost_add_used_n(vq, heads, count);
+ */
 static int __vhost_add_used_n(struct vhost_virtqueue *vq,
 			    struct vring_used_elem *heads,
 			    unsigned count)
@@ -2424,8 +2905,18 @@ static int __vhost_add_used_n(struct vhost_virtqueue *vq,
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2836| <<vhost_add_used>> return vhost_add_used_n(vq, &heads, 1);
+ *   - drivers/vhost/vhost.c|2979| <<vhost_add_used_and_signal_n>> vhost_add_used_n(vq, heads, count);
+ */
 /* After we've used one of their buffers, we tell them about it.  We'll then
  * want to notify the guest, using eventfd. */
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2843| <<vhost_add_used>> return vhost_add_used_n(vq, &heads, 1);
+ *   - drivers/vhost/vhost.c|2991| <<vhost_add_used_and_signal_n>> vhost_add_used_n(vq, heads, count);
+ */
 int vhost_add_used_n(struct vhost_virtqueue *vq, struct vring_used_elem *heads,
 		     unsigned count)
 {
@@ -2440,6 +2931,11 @@ int vhost_add_used_n(struct vhost_virtqueue *vq, struct vring_used_elem *heads,
 		heads += n;
 		count -= n;
 	}
+	/*
+	 * called by:
+	 *   - drivers/vhost/vhost.c|2894| <<vhost_add_used_n>> r = __vhost_add_used_n(vq, heads, n);
+	 *   - drivers/vhost/vhost.c|2900| <<vhost_add_used_n>> r = __vhost_add_used_n(vq, heads, count);
+	 */
 	r = __vhost_add_used_n(vq, heads, count);
 
 	/* Make sure buffer is written before we update index. */
@@ -2461,6 +2957,10 @@ int vhost_add_used_n(struct vhost_virtqueue *vq, struct vring_used_elem *heads,
 }
 EXPORT_SYMBOL_GPL(vhost_add_used_n);
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2962| <<vhost_signal>> if (vq->call_ctx.ctx && vhost_notify(dev, vq))
+ */
 static bool vhost_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 {
 	__u16 old, new;
@@ -2498,6 +2998,14 @@ static bool vhost_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 	return vring_need_event(vhost16_to_cpu(vq, event), new, old);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|686| <<vhost_scsi_complete_cmd_work>> vhost_signal(&vs->dev, &vs->vqs[vq].vq);
+ *   - drivers/vhost/vhost.c|2982| <<vhost_add_used_and_signal>> vhost_signal(dev, vq);
+ *   - drivers/vhost/vhost.c|2992| <<vhost_add_used_and_signal_n>> vhost_signal(dev, vq);
+ *   - drivers/vhost/vsock.c|260| <<vhost_transport_do_send_pkt>> vhost_signal(&vsock->dev, vq);
+ *   - drivers/vhost/vsock.c|564| <<vhost_vsock_handle_tx_kick>> vhost_signal(&vsock->dev, vq);
+ */
 /* This actually signals the guest, using eventfd. */
 void vhost_signal(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 {
@@ -2507,21 +3015,47 @@ void vhost_signal(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 }
 EXPORT_SYMBOL_GPL(vhost_signal);
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|957| <<handle_tx_zerocopy>> vhost_add_used_and_signal(&net->dev, vq, head, 0);
+ *   - drivers/vhost/scsi.c|581| <<vhost_scsi_do_evt_work>> vhost_add_used_and_signal(&vs->dev, vq, head, 0);
+ *   - drivers/vhost/scsi.c|1022| <<vhost_scsi_send_bad_target>> vhost_add_used_and_signal(&vs->dev, vq, head, 0);
+ *   - drivers/vhost/scsi.c|1359| <<vhost_scsi_send_tmf_resp>> vhost_add_used_and_signal(&vs->dev, vq, vq_desc, 0);
+ *   - drivers/vhost/scsi.c|1451| <<vhost_scsi_send_an_resp>> vhost_add_used_and_signal(&vs->dev, vq, vc->head, 0);
+ *   - drivers/vhost/test.c|87| <<handle_vq>> vhost_add_used_and_signal(&n->dev, vq, head, 0);
+ */
 /* And here's the combo meal deal.  Supersize me! */
 void vhost_add_used_and_signal(struct vhost_dev *dev,
 			       struct vhost_virtqueue *vq,
 			       unsigned int head, int len)
 {
+	/*
+	 * called by:
+	 *   - drivers/vhost/scsi.c|673| <<vhost_scsi_complete_cmd_work>> vhost_add_used(cmd->tvc_vq, cmd->tvc_vq_desc, 0);
+	 *   - drivers/vhost/vhost.c|2969| <<vhost_add_used_and_signal>> vhost_add_used(vq, head, len);
+	 *   - drivers/vhost/vsock.c|222| <<vhost_transport_do_send_pkt>> vhost_add_used(vq, head, sizeof(pkt->hdr) + payload_len);
+	 *   - drivers/vhost/vsock.c|557| <<vhost_vsock_handle_tx_kick>> vhost_add_used(vq, head, 0);
+	 */
 	vhost_add_used(vq, head, len);
 	vhost_signal(dev, vq);
 }
 EXPORT_SYMBOL_GPL(vhost_add_used_and_signal);
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|377| <<vhost_zerocopy_signal_used>> vhost_add_used_and_signal_n(vq->dev, vq,
+ *   - drivers/vhost/net.c|456| <<vhost_net_signal_used>> vhost_add_used_and_signal_n(dev, vq, vq->heads, nvq->done_idx);
+ */
 /* multi-buffer version of vhost_add_used_and_signal */
 void vhost_add_used_and_signal_n(struct vhost_dev *dev,
 				 struct vhost_virtqueue *vq,
 				 struct vring_used_elem *heads, unsigned count)
 {
+	/*
+	 * called by:
+	 *   - drivers/vhost/vhost.c|2843| <<vhost_add_used>> return vhost_add_used_n(vq, &heads, 1);
+	 *   - drivers/vhost/vhost.c|2991| <<vhost_add_used_and_signal_n>> vhost_add_used_n(vq, heads, count);
+	 */
 	vhost_add_used_n(vq, heads, count);
 	vhost_signal(dev, vq);
 }
diff --git a/drivers/vhost/vhost.h b/drivers/vhost/vhost.h
index 50b909feeb8c..d3dd98c1aa32 100644
--- a/drivers/vhost/vhost.h
+++ b/drivers/vhost/vhost.h
@@ -123,6 +123,17 @@ struct vhost_virtqueue {
 	u64 acked_features;
 	u64 acked_backend_features;
 	/* Log write descriptors */
+	/*
+	 * 在以下使用vhost_virtqueue->log_base:
+	 *   - drivers/vhost/vhost.c|387| <<vhost_vq_reset>> vq->log_base = NULL;
+	 *   - drivers/vhost/vhost.c|863| <<memory_access_ok>> ok = vq_memory_access_ok(d->vqs[i]->log_base,
+	 *   - drivers/vhost/vhost.c|1490| <<vhost_vq_access_ok>> if (!vq_log_access_ok(vq, vq->log_base))
+	 *   - drivers/vhost/vhost.c|1626| <<vhost_vring_set_addr>> if (!vq_log_used_access_ok(vq, vq->log_base,
+	 *   - drivers/vhost/vhost.c|1882| <<vhost_dev_ioctl(VHOST_SET_LOG_BASE)>> vq->log_base = base;
+	 *   - drivers/vhost/vhost.c|1982| <<log_write_hva>> r = log_write(vq->log_base,
+	 *   - drivers/vhost/vhost.c|2007| <<log_used>> return log_write(vq->log_base, vq->log_addr + used_offset, len);
+	 *   - drivers/vhost/vhost.c|2044| <<vhost_log_write>> r = log_write(vq->log_base, log[i].addr, l);
+	 */
 	void __user *log_base;
 	struct vhost_log *log;
 	struct iovec log_iov[64];
@@ -151,7 +162,41 @@ struct vhost_dev {
 	struct mutex mutex;
 	struct vhost_virtqueue **vqs;
 	int nvqs;
+	/*
+	 * 在以下设置vhost_dev->log_ctx:
+	 *   - drivers/vhost/vhost.c|657| <<vhost_dev_init>> dev->log_ctx = NULL;
+	 *   - drivers/vhost/vhost.c|898| <<vhost_dev_cleanup>> dev->log_ctx = NULL;
+	 *   - drivers/vhost/vhost.c|2100| <<vhost_dev_ioctl(VHOST_SET_LOG_FD)>> swap(ctx, d->log_ctx);
+	 * 在以下使用vhost_dev->log_ctx:
+	 *   - drivers/vhost/vhost.c|896| <<vhost_dev_cleanup>> if (dev->log_ctx)
+	 *   - drivers/vhost/vhost.c|897| <<vhost_dev_cleanup>> eventfd_ctx_put(dev->log_ctx);
+	 *   - drivers/vhost/vhost.c|2103| <<vhost_dev_ioctl(VHOST_SET_LOG_FD)>> d->vqs[i]->log_ctx = d->log_ctx;
+	 * 在以下设置vhost_virtqueue->log_ctx:
+	 *   - drivers/vhost/vhost.c|501| <<vhost_vq_reset>> vq->log_ctx = NULL;
+	 *   - drivers/vhost/vhost.c|2103| <<vhost_dev_ioctl(VHOST_SET_LOG_FD)>> d->vqs[i]->log_ctx = d->log_ctx;
+	 * 在以下使用vhost_virtqueue->log_ctx:
+	 *   - drivers/vhost/vhost.c|2254| <<vhost_log_write>> if (vq->log_ctx)
+	 *   - drivers/vhost/vhost.c|2255| <<vhost_log_write>> eventfd_signal(vq->log_ctx, 1);
+	 *   - drivers/vhost/vhost.c|2277| <<vhost_update_used_flags>> if (vq->log_ctx)
+	 *   - drivers/vhost/vhost.c|2278| <<vhost_update_used_flags>> eventfd_signal(vq->log_ctx, 1);
+	 *   - drivers/vhost/vhost.c|2295| <<vhost_update_avail_event>> if (vq->log_ctx)
+	 *   - drivers/vhost/vhost.c|2296| <<vhost_update_avail_event>> eventfd_signal(vq->log_ctx, 1);
+	 *   - drivers/vhost/vhost.c|2721| <<vhost_add_used_n>> if (vq->log_ctx)
+	 *   - drivers/vhost/vhost.c|2722| <<vhost_add_used_n>> eventfd_signal(vq->log_ctx, 1);
+	 *
+	 * 目前在QEMU没有见到使用VHOST_SET_LOG_FD
+	 */
 	struct eventfd_ctx *log_ctx;
+	/*
+	 * 在以下使用vhost_dev->work_list:
+	 *   - drivers/vhost/vhost.c|495| <<vhost_dev_init>> init_llist_head(&dev->work_list);
+	 *   - drivers/vhost/vhost.c|271| <<vhost_work_queue>> llist_add(&work->node, &dev->work_list);
+	 *   - drivers/vhost/vhost.c|280| <<vhost_has_work>> return !llist_empty(&dev->work_list);
+	 *   - drivers/vhost/vhost.c|366| <<vhost_worker>> node = llist_del_all(&dev->work_list);
+	 *   - drivers/vhost/vhost.c|724| <<vhost_dev_cleanup>> WARN_ON(!llist_empty(&dev->work_list));
+	 *
+	 * 注意是Lock-less NULL terminated single linked list
+	 */
 	struct llist_head work_list;
 	struct task_struct *worker;
 	struct vhost_iotlb *umem;
-- 
2.39.5 (Apple Git-154)

