From 4eeb659965da8fa0ea7513d1188f68368de48f09 Mon Sep 17 00:00:00 2001
From: Dongli Zhang <dongli.zhang0129@gmail.com>
Date: Tue, 1 Nov 2022 23:37:01 -0700
Subject: [PATCH 1/1] kvm-unit-tests-8b2603854231

Signed-off-by: Dongli Zhang <dongli.zhang0129@gmail.com>
---
 x86/pmu.c | 159 +++++++++++++++++++++++++++++++++++++++++++++++++++++-
 1 file changed, 158 insertions(+), 1 deletion(-)

diff --git a/x86/pmu.c b/x86/pmu.c
index d59baf1..e720b60 100644
--- a/x86/pmu.c
+++ b/x86/pmu.c
@@ -10,6 +10,10 @@
 #include "libcflat.h"
 #include <stdint.h>
 
+/*
+ * 在以下使用FIXED_CNT_INDEX:
+ *   - x86/pmu.c|127| <<event_to_global_idx>> return cnt->ctr - (is_gp(cnt) ? gp_counter_base : (MSR_CORE_PERF_FIXED_CTR0 - FIXED_CNT_INDEX));
+ */
 #define FIXED_CNT_INDEX 32
 #define PC_VECTOR	32
 
@@ -35,9 +39,23 @@
 
 // These values match the number of instructions and branches in the
 // assembly block in check_emulated_instr().
+/*
+ * 在以下使用EXPECTED_INSTR:
+ *   - x86/pmu.c|502| <<check_emulated_instr>> instr_start = -EXPECTED_INSTR;
+ *   - x86/pmu.c|537| <<check_emulated_instr>> report(instr_cnt.count - instr_start >= EXPECTED_INSTR,
+ */
 #define EXPECTED_INSTR 17
+/*
+ * 在以下使用EXPECTED_BRNCH:
+ *   - x86/pmu.c|501| <<check_emulated_instr>> brnch_start = -EXPECTED_BRNCH;
+ *   - x86/pmu.c|539| <<check_emulated_instr>> report(brnch_cnt.count - brnch_start >= EXPECTED_BRNCH,
+ */
 #define EXPECTED_BRNCH 5
 
+/*
+ * ctr是counter (不是sel)
+ * config是要写入sel的数值
+ */
 typedef struct {
 	uint32_t ctr;
 	uint32_t config;
@@ -67,25 +85,58 @@ struct pmu_event {
 #define PMU_CAP_FW_WRITES	(1ULL << 13)
 static u64 gp_counter_base = MSR_IA32_PERFCTR0;
 
+/*
+ * 在main中 buf = malloc(N*64);
+ */
 char *buf;
 
+/*
+ * 一共loop N次
+ * 每次10 instructions, 都会触发high level cache miss
+ */
 static inline void loop(void)
 {
 	unsigned long tmp, tmp2, tmp3;
 
+	/*
+	 * 0: tmp -> rcx -> N
+	 * 1: tmp2 -> 任何reg -> buf base address
+	 * 2: tmp3 -> 任何reg
+	 *
+	 *
+	 * loop N times
+	 *
+	 * 10 instructions each loop
+	 * 所以{"instructions", 0x00c0, 10*N, 10.2*N},
+	 */
 	asm volatile("1: mov (%1), %2; add $64, %1; nop; nop; nop; nop; nop; nop; nop; loop 1b"
 			: "=c"(tmp), "=r"(tmp2), "=r"(tmp3): "0"(N), "1"(buf));
 
 }
 
+/*
+ * 在以下使用irq_received:
+ *   - x86/pmu.c|121| <<cnt_overflow>> irq_received++;
+ *   - x86/pmu.c|132| <<check_irq>> irq_received = 0;
+ *   - x86/pmu.c|134| <<check_irq>> for (i = 0; i < 100000 && !irq_received; i++)
+ *   - x86/pmu.c|137| <<check_irq>> return irq_received;
+ */
 volatile uint64_t irq_received;
 
+/*
+ * called by:
+ *   - x86/pmu.c|688| <<main>> handle_irq(PC_VECTOR, cnt_overflow);
+ */
 static void cnt_overflow(isr_regs_t *regs)
 {
 	irq_received++;
 	apic_write(APIC_EOI, 0);
 }
 
+/*
+ * called by:
+ *   - x86/pmu.c|344| <<check_counter_overflow>> report(check_irq() == (i % 2), "irq-%d", i);
+ */
 static bool check_irq(void)
 {
 	int i;
@@ -97,18 +148,37 @@ static bool check_irq(void)
 	return irq_received;
 }
 
+/*
+ * called by:
+ *   - x86/pmu.c|159| <<event_to_global_idx>> return cnt->ctr - (is_gp(cnt) ? gp_counter_base :
+ *   - x86/pmu.c|165| <<get_counter_event>> if (is_gp(cnt)) {
+ *   - x86/pmu.c|199| <<start_event>> if (is_gp(evt))
+ *   - x86/pmu.c|223| <<stop_event>> if (is_gp(evt))
+ *   - x86/pmu.c|405| <<do_rdpmc_fast>> if (!is_gp(cnt))
+ */
 static bool is_gp(pmu_counter_t *evt)
 {
 	return evt->ctr < MSR_CORE_PERF_FIXED_CTR0 ||
 		evt->ctr >= MSR_IA32_PMC0;
 }
 
+/*
+ * called by:
+ *   - x86/pmu.c|183| <<global_enable>> cnt->idx = event_to_global_idx(cnt);
+ *   - x86/pmu.c|200| <<start_event>> wrmsr(MSR_P6_EVNTSEL0 + event_to_global_idx(evt),
+ *   - x86/pmu.c|224| <<stop_event>> wrmsr(MSR_P6_EVNTSEL0 + event_to_global_idx(evt),
+ *   - x86/pmu.c|374| <<check_counter_overflow>> idx = event_to_global_idx(&cnt);
+ */
 static int event_to_global_idx(pmu_counter_t *cnt)
 {
 	return cnt->ctr - (is_gp(cnt) ? gp_counter_base :
 		(MSR_CORE_PERF_FIXED_CTR0 - FIXED_CNT_INDEX));
 }
 
+/*
+ * called by:
+ *   - x86/pmu.c|259| <<verify_counter>> return verify_event(cnt->count, get_counter_event(cnt));
+ */
 static struct pmu_event* get_counter_event(pmu_counter_t *cnt)
 {
 	if (is_gp(cnt)) {
@@ -123,6 +193,10 @@ static struct pmu_event* get_counter_event(pmu_counter_t *cnt)
 	return (void*)0;
 }
 
+/*
+ * called by:
+ *   - x86/pmu.c|161| <<start_event>> global_enable(evt);
+ */
 static void global_enable(pmu_counter_t *cnt)
 {
 	cnt->idx = event_to_global_idx(cnt);
@@ -131,13 +205,25 @@ static void global_enable(pmu_counter_t *cnt)
 			(1ull << cnt->idx));
 }
 
+/*
+ * called by:
+ *   - x86/pmu.c|222| <<stop_event>> global_disable(evt);
+ */
 static void global_disable(pmu_counter_t *cnt)
 {
 	wrmsr(MSR_CORE_PERF_GLOBAL_CTRL, rdmsr(MSR_CORE_PERF_GLOBAL_CTRL) &
 			~(1ull << cnt->idx));
 }
 
-
+/*
+ * called by:
+ *   - x86/pmu.c|238| <<measure>> start_event(&evt[i]);
+ *   - x86/pmu.c|484| <<check_running_counter_wrmsr>> start_event(&evt);
+ *   - x86/pmu.c|495| <<check_running_counter_wrmsr>> start_event(&evt);
+ *   - x86/pmu.c|531| <<check_emulated_instr>> start_event(&brnch_cnt);
+ *   - x86/pmu.c|532| <<check_emulated_instr>> start_event(&instr_cnt);
+ *   - x86/pmu.c|669| <<set_ref_cycle_expectations>> start_event(&cnt);
+ */
 static void start_event(pmu_counter_t *evt)
 {
     wrmsr(evt->ctr, evt->count);
@@ -162,6 +248,15 @@ static void start_event(pmu_counter_t *evt)
     apic_write(APIC_LVTPC, PC_VECTOR);
 }
 
+/*
+ * called by:
+ *   - x86/pmu.c|241| <<measure>> stop_event(&evt[i]);
+ *   - x86/pmu.c|487| <<check_running_counter_wrmsr>> stop_event(&evt);
+ *   - x86/pmu.c|504| <<check_running_counter_wrmsr>> stop_event(&evt);
+ *   - x86/pmu.c|565| <<check_emulated_instr>> stop_event(&brnch_cnt);
+ *   - x86/pmu.c|566| <<check_emulated_instr>> stop_event(&instr_cnt);
+ *   - x86/pmu.c|684| <<set_ref_cycle_expectations>> stop_event(&cnt);
+ */
 static void stop_event(pmu_counter_t *evt)
 {
 	global_disable(evt);
@@ -176,16 +271,35 @@ static void stop_event(pmu_counter_t *evt)
 	evt->count = rdmsr(evt->ctr);
 }
 
+/*
+ * called by:
+ *   - x86/pmu.c|273| <<check_gp_counter>> measure(&cnt, 1);
+ *   - x86/pmu.c|301| <<check_fixed_counters>> measure(&cnt, 1);
+ *   - x86/pmu.c|330| <<check_counters_many>> measure(cnt, n);
+ *   - x86/pmu.c|349| <<check_counter_overflow>> measure(&cnt, 1);
+ *   - x86/pmu.c|375| <<check_counter_overflow>> measure(&cnt, 1);
+ *   - x86/pmu.c|396| <<check_gp_counter_cmask>> measure(&cnt, 1);
+ */
 static void measure(pmu_counter_t *evt, int count)
 {
 	int i;
 	for (i = 0; i < count; i++)
 		start_event(&evt[i]);
+	/*
+	 * 一共loop N次
+	 * 每次10 instructions, 都会触发high level cache miss
+	 */
 	loop();
 	for (i = 0; i < count; i++)
 		stop_event(&evt[i]);
 }
 
+/*
+ * called by:
+ *   - x86/pmu.c|198| <<verify_counter>> return verify_event(cnt->count, get_counter_event(cnt));
+ *   - x86/pmu.c|213| <<check_gp_counter>> report(verify_event(cnt.count, evt), "%s-%d", evt->name, i);
+ *   - x86/pmu.c|241| <<check_fixed_counters>> report(verify_event(cnt.count, &fixed_events[i]), "fixed-%d", i);
+ */
 static bool verify_event(uint64_t count, struct pmu_event *e)
 {
 	// printf("%d <= %ld <= %d\n", e->min, count, e->max);
@@ -193,11 +307,19 @@ static bool verify_event(uint64_t count, struct pmu_event *e)
 
 }
 
+/*
+ * called by:
+ *   - x86/pmu.c|333| <<check_counters_many>> if (!verify_counter(&cnt[i]))
+ */
 static bool verify_counter(pmu_counter_t *cnt)
 {
 	return verify_event(cnt->count, get_counter_event(cnt));
 }
 
+/*
+ * called by:
+ *   - x86/pmu.c|341| <<check_gp_counters>> check_gp_counter(&gp_events[i]);
+ */
 static void check_gp_counter(struct pmu_event *evt)
 {
 	int nr_gp_counters = pmu_nr_gp_counters();
@@ -214,6 +336,10 @@ static void check_gp_counter(struct pmu_event *evt)
 	}
 }
 
+/*
+ * called by:
+ *   - x86/pmu.c|649| <<check_counters>> check_gp_counters();
+ */
 static void check_gp_counters(void)
 {
 	int i;
@@ -226,6 +352,10 @@ static void check_gp_counters(void)
 					gp_events[i].name);
 }
 
+/*
+ * called by:
+ *   - x86/pmu.c|658| <<check_counters>> check_fixed_counters();
+ */
 static void check_fixed_counters(void)
 {
 	int nr_fixed_counters = pmu_nr_fixed_counters();
@@ -242,6 +372,10 @@ static void check_fixed_counters(void)
 	}
 }
 
+/*
+ * called by:
+ *   - x86/pmu.c|664| <<check_counters>> check_counters_many();
+ */
 static void check_counters_many(void)
 {
 	int nr_fixed_counters = pmu_nr_fixed_counters();
@@ -275,6 +409,10 @@ static void check_counters_many(void)
 	report(i == n, "all counters");
 }
 
+/*
+ * called by:
+ *   - x86/pmu.c|669| <<check_counters>> check_counter_overflow();
+ */
 static void check_counter_overflow(void)
 {
 	int nr_gp_counters = pmu_nr_gp_counters();
@@ -324,6 +462,10 @@ static void check_counter_overflow(void)
 	report_prefix_pop();
 }
 
+/*
+ * called by:
+ *   - x86/pmu.c|670| <<check_counters>> check_gp_counter_cmask();
+ */
 static void check_gp_counter_cmask(void)
 {
 	pmu_counter_t cnt = {
@@ -421,6 +563,10 @@ static void check_running_counter_wrmsr(void)
 	report_prefix_push("running counter wrmsr");
 
 	start_event(&evt);
+	/*
+	 * 一共loop N次
+	 * 每次10 instructions, 都会触发high level cache miss
+	 */
 	loop();
 	wrmsr(gp_counter_base, 0);
 	stop_event(&evt);
@@ -439,6 +585,10 @@ static void check_running_counter_wrmsr(void)
 
 	wrmsr(gp_counter_base, count);
 
+	/*
+	 * 一共loop N次
+	 * 每次10 instructions, 都会触发high level cache miss
+	 */
 	loop();
 	stop_event(&evt);
 	status = rdmsr(MSR_CORE_PERF_GLOBAL_STATUS);
@@ -586,6 +736,10 @@ static void check_gp_counters_write_width(void)
  */
 static void set_ref_cycle_expectations(void)
 {
+	/*
+	 * ctr = MSR_IA32_PERFCTR0是读counter的地方,
+	 * 不是selector
+	 */
 	pmu_counter_t cnt = {
 		.ctr = MSR_IA32_PERFCTR0,
 		.config = EVNTSEL_OS | EVNTSEL_USR | gp_events[2].unit_sel,
@@ -624,6 +778,9 @@ static void set_ref_cycle_expectations(void)
 	if (!tsc_delta)
 		return;
 
+	/*
+	 * cnt.count / tsc_delta 是每一个tsc的cycle执行的instruction的数目
+	 */
 	gp_events[2].min = (gp_events[2].min * cnt.count) / tsc_delta;
 	gp_events[2].max = (gp_events[2].max * cnt.count) / tsc_delta;
 }
-- 
2.34.1

