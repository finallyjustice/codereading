通过procfs修改virtio-net中断的smp_affinity_list

通过smp_affinity_list修改中断的affinity.

# echo 2,3 > /proc/irq/40/smp_affinity_list

但是这个不会立刻在effective_affinity_list体现出来.

是通过下面的函数实现的.

write_irq_affinity()
-> irq_set_affinity()
   -> __irq_set_affinity()
      -> irq_set_affinity_locked()

参数的mask是"2,3", force=false.

352 int irq_set_affinity_locked(struct irq_data *data, const struct cpumask *mask,
353                             bool force)
354 {
355         struct irq_chip *chip = irq_data_get_irq_chip(data);
356         struct irq_desc *desc = irq_data_to_desc(data);
357         int ret = 0;
358 
359         if (!chip || !chip->irq_set_affinity)
360                 return -EINVAL;
361 
362         if (irq_set_affinity_deactivated(data, mask))
363                 return 0;
364 
365         if (irq_can_move_pcntxt(data) && !irqd_is_setaffinity_pending(data)) {
366                 ret = irq_try_set_affinity(data, mask, force);
367         } else {
368                 irqd_set_move_pending(data);
369                 irq_copy_pending(desc, mask);
370         }
371 
372         if (desc->affinity_notify) {
373                 kref_get(&desc->affinity_notify->kref);
374                 if (!schedule_work(&desc->affinity_notify->work)) {
375                         /* Work was already scheduled, drop our extra ref */
376                         kref_put(&desc->affinity_notify->kref,
377                                  desc->affinity_notify->release);
378                 }
379         }
380         irqd_set(data, IRQD_AFFINITY_SET);
381 
382         return ret;
383 }

在line365会通过irq_can_move_pcntxt(data)和!irqd_is_setaffinity_pending(data)判断.
根据IRQD_MOVE_PCNTXT和IRQD_SETAFFINITY_PENDING的情况判断.

414 #ifdef CONFIG_GENERIC_PENDING_IRQ
415 static inline bool irq_can_move_pcntxt(struct irq_data *data)
416 {
417         return irqd_can_move_in_process_context(data);
418 }

341 static inline bool irqd_can_move_in_process_context(struct irq_data *d)
342 {
343         return __irqd_to_state(d) & IRQD_MOVE_PCNTXT;
344 }

256 static inline bool irqd_is_setaffinity_pending(struct irq_data *d)
257 {
258         return __irqd_to_state(d) & IRQD_SETAFFINITY_PENDING;
259 }

最终irq_set_affinity_locked()实际调用了line 368-369, 只是用IRQD_SETAFFINITY_PENDING进行了标记.
并且把affinity拷贝到了irq_desc->pending_mask.

IRQD_SETAFFINITY_PENDING     - Affinity setting is pending
IRQD_MOVE_PCNTXT             - Interrupt can be moved in process context

367         } else {
368                 irqd_set_move_pending(data);
369                 irq_copy_pending(desc, mask);
370         }


最终affinity在中断被触发和处理的时候重新配置.
并且写入irq_data->common->effective_affinity.

[0] apic_set_affinity
[0] msi_set_affinity
[0] irq_do_set_affinity
[0] irq_move_masked_irq
[0] __irq_move_irq
[0] apic_ack_edge
[0] handle_edge_irq
[0] __common_interrupt
[0] common_interrupt

分配完vector后同步到effective_affinity: line 137.

128 static void apic_update_irq_cfg(struct irq_data *irqd, unsigned int vector,
129                                 unsigned int cpu)
130 {
131         struct apic_chip_data *apicd = apic_chip_data(irqd);
132 
133         lockdep_assert_held(&vector_lock);
134 
135         apicd->hw_irq_cfg.vector = vector;
136         apicd->hw_irq_cfg.dest_apicid = apic->calc_dest_apicid(cpu);
137         irq_data_update_effective_affinity(irqd, cpumask_of(cpu));
138         trace_vector_config(irqd->irq, vector, cpu,   
139                             apicd->hw_irq_cfg.dest_apicid);
140 }

[0] apic_update_irq_cfg
[0] assign_vector_locked
[0] apic_set_affinity
[0] msi_set_affinity
[0] irq_do_set_affinity
[0] irq_move_masked_irq
[0] __irq_move_irq
[0] apic_ack_edge
[0] handle_edge_irq
[0] __common_interrupt
[0] common_interrupt






tasks progress


	
Improve the diagnostic
To improve the diagnostic by either: (1) creating new tools, (2) summarizing new diagnostic methods/docs, or (3) creating new patchset prototype to facilitate diagnostic.
Status
Not started
Priority
Medium
Last Update
6/20/23
	
Work closely with OCI, Exadata and customers
Work closely with OCI, Exadata and customers. Do a great job to fix/enhance the issue reported by customer or internal products (e.g., OVM, OLVM, Exadata or OCI) on a variety of topics, including Intel/AMD/ARM, Xen hypervisor, Xen/Xend toolstack, Xen PV driver, KVM hypervisor, QEMU, virtio/vhost driver, Xen/KVM specific kernel components, PCI/IOMMU and IOMMU. Since PV/virtio/vhost drivers are primarily for networking/IO, we need to have knowledge about blk-mq/NVMe/networking layer.
Status
Not started
Priority
Medium
Last Update
6/20/23
	
Do an internal talk
Do an internal talk (e.g., during virtualization and generic meeting) on a software component related to KVM virtualization.
Status
Not started
Priority
Medium
Last Update
6/20/23
	
Create a blog post for Oracle Linux.
Create a blog post for Oracle Linux.
Status
Not started
Priority
Medium
