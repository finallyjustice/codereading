From 94a2c6315942369a6d44f61fe3bddee31c8cd848 Mon Sep 17 00:00:00 2001
From: Dongli Zhang <dongli.zhang0129@gmail.com>
Date: Mon, 19 Oct 2020 09:00:48 -0700
Subject: [PATCH 1/1] linux v5.9

Signed-off-by: Dongli Zhang <dongli.zhang0129@gmail.com>
---
 block/bfq-iosched.c       |  14 +++
 block/blk-cgroup-rwstat.c |  11 ++
 block/blk-cgroup.c        |  79 ++++++++++++
 block/blk-iocost.c        |  47 ++++++++
 block/blk-iolatency.c     |  59 +++++++++
 block/blk-throttle.c      |  94 +++++++++++++++
 block/elevator.c          |   6 +
 drivers/vhost/net.c       |  62 ++++++++++
 drivers/vhost/vhost.c     | 246 ++++++++++++++++++++++++++++++++++++++
 drivers/vhost/vhost.h     |  30 +++++
 fs/eventfd.c              |  11 ++
 include/linux/kvm_host.h  |  11 ++
 include/linux/poll.h      |   7 ++
 virt/kvm/kvm_main.c       |  50 ++++++++
 14 files changed, 727 insertions(+)

diff --git a/block/bfq-iosched.c b/block/bfq-iosched.c
index fa98470df3f0..750660c538ee 100644
--- a/block/bfq-iosched.c
+++ b/block/bfq-iosched.c
@@ -132,6 +132,13 @@
 #include "bfq-iosched.h"
 #include "blk-wbt.h"
 
+/*
+ * 从block/bfq-iosched.c又分裂出了如下三个文件:
+ * create mode 100644 block/bfq-cgroup.c
+ * create mode 100644 block/bfq-iosched.h
+ * create mode 100644 block/bfq-wf2q.c
+ */
+
 #define BFQ_BFQQ_FNS(name)						\
 void bfq_mark_bfqq_##name(struct bfq_queue *bfqq)			\
 {									\
@@ -6809,6 +6816,13 @@ static int __init bfq_init(void)
 	int ret;
 
 #ifdef CONFIG_BFQ_GROUP_IOSCHED
+	/*
+	 * 在以下调用blkcg_policy_register():
+	 *   - block/bfq-iosched.c|6812| <<bfq_init>> ret = blkcg_policy_register(&blkcg_policy_bfq);
+	 *   - block/blk-iocost.c|2528| <<ioc_init>> return blkcg_policy_register(&blkcg_policy_iocost);
+	 *   - block/blk-iolatency.c|1044| <<iolatency_init>> return blkcg_policy_register(&blkcg_policy_iolatency);
+	 *   - block/blk-throttle.c|2477| <<throtl_init>> return blkcg_policy_register(&blkcg_policy_throtl);
+	 */
 	ret = blkcg_policy_register(&blkcg_policy_bfq);
 	if (ret)
 		return ret;
diff --git a/block/blk-cgroup-rwstat.c b/block/blk-cgroup-rwstat.c
index 85d5790ac49b..8468dacc5982 100644
--- a/block/blk-cgroup-rwstat.c
+++ b/block/blk-cgroup-rwstat.c
@@ -5,6 +5,17 @@
  */
 #include "blk-cgroup-rwstat.h"
 
+/*
+ * called by:
+ *   - block/bfq-cgroup.c|464| <<bfqg_stats_init>> if (blkg_rwstat_init(&stats->bytes, gfp) ||
+ *   - block/bfq-cgroup.c|465| <<bfqg_stats_init>> blkg_rwstat_init(&stats->ios, gfp))
+ *   - block/bfq-cgroup.c|469| <<bfqg_stats_init>> if (blkg_rwstat_init(&stats->merged, gfp) ||
+ *   - block/bfq-cgroup.c|470| <<bfqg_stats_init>> blkg_rwstat_init(&stats->service_time, gfp) ||
+ *   - block/bfq-cgroup.c|471| <<bfqg_stats_init>> blkg_rwstat_init(&stats->wait_time, gfp) ||
+ *   - block/bfq-cgroup.c|472| <<bfqg_stats_init>> blkg_rwstat_init(&stats->queued, gfp) ||
+ *   - block/blk-throttle.c|496| <<throtl_pd_alloc>> if (blkg_rwstat_init(&tg->stat_bytes, gfp))
+ *   - block/blk-throttle.c|499| <<throtl_pd_alloc>> if (blkg_rwstat_init(&tg->stat_ios, gfp))
+ */
 int blkg_rwstat_init(struct blkg_rwstat *rwstat, gfp_t gfp)
 {
 	int i, ret;
diff --git a/block/blk-cgroup.c b/block/blk-cgroup.c
index c195365c9817..464738113f36 100644
--- a/block/blk-cgroup.c
+++ b/block/blk-cgroup.c
@@ -34,6 +34,14 @@
 
 #define MAX_KEY_LEN 100
 
+/*
+ * 在以下调用blkcg_policy_register():
+ *   - block/bfq-iosched.c|6812| <<bfq_init>> ret = blkcg_policy_register(&blkcg_policy_bfq);
+ *   - block/blk-iocost.c|2528| <<ioc_init>> return blkcg_policy_register(&blkcg_policy_iocost);
+ *   - block/blk-iolatency.c|1044| <<iolatency_init>> return blkcg_policy_register(&blkcg_policy_iolatency);
+ *   - block/blk-throttle.c|2477| <<throtl_init>> return blkcg_policy_register(&blkcg_policy_throtl);
+ */
+
 /*
  * blkcg_pol_mutex protects blkcg_policy[] and policy [de]activation.
  * blkcg_pol_register_mutex nests outside of it and synchronizes entire
@@ -219,6 +227,12 @@ EXPORT_SYMBOL_GPL(blkg_lookup_slowpath);
  * If @new_blkg is %NULL, this function tries to allocate a new one as
  * necessary using %GFP_NOWAIT.  @new_blkg is always consumed on return.
  */
+/*
+ * called by:
+ *   - block/blk-cgroup.c|354| <<blkg_lookup_create>> blkg = blkg_create(pos, q, NULL);
+ *   - block/blk-cgroup.c|663| <<__acquires>> blkg = blkg_create(pos, q, new_blkg);
+ *   - block/blk-cgroup.c|1145| <<blkcg_init_queue>> blkg = blkg_create(&blkcg_root, q, new_blkg);
+ */
 static struct blkcg_gq *blkg_create(struct blkcg *blkcg,
 				    struct request_queue *q,
 				    struct blkcg_gq *new_blkg)
@@ -935,6 +949,9 @@ static struct cftype blkcg_files[] = {
 	{ }	/* terminate */
 };
 
+/*
+ * struct cgroup_subsys io_cgrp_subsys.legacy_cftypes = blkcg_legacy_files[]
+ */
 static struct cftype blkcg_legacy_files[] = {
 	{
 		.name = "reset_stats",
@@ -1127,6 +1144,10 @@ static int blkcg_css_online(struct cgroup_subsys_state *css)
  * RETURNS:
  * 0 on success, -errno on failure.
  */
+/*
+ * called by:
+ *   - block/blk-core.c|574| <<blk_alloc_queue>> if (blkcg_init_queue(q))
+ */
 int blkcg_init_queue(struct request_queue *q)
 {
 	struct blkcg_gq *new_blkg, *blkg;
@@ -1142,6 +1163,12 @@ int blkcg_init_queue(struct request_queue *q)
 	/* Make sure the root blkg exists. */
 	rcu_read_lock();
 	spin_lock_irq(&q->queue_lock);
+	/*
+	 * called by:
+	 *   - block/blk-cgroup.c|354| <<blkg_lookup_create>> blkg = blkg_create(pos, q, NULL);
+	 *   - block/blk-cgroup.c|663| <<__acquires>> blkg = blkg_create(pos, q, new_blkg);
+	 *   - block/blk-cgroup.c|1145| <<blkcg_init_queue>> blkg = blkg_create(&blkcg_root, q, new_blkg);
+	 */
 	blkg = blkg_create(&blkcg_root, q, new_blkg);
 	if (IS_ERR(blkg))
 		goto err_unlock;
@@ -1239,6 +1266,23 @@ static void blkcg_exit(struct task_struct *tsk)
 	tsk->throttle_queue = NULL;
 }
 
+/*
+ * 在以下使用io_cgrp_subsys:
+ *   - block/bfq-cgroup.c|512| <<bfq_cpd_init>> d->weight = cgroup_subsys_on_dfl(io_cgrp_subsys) ?
+ *   - block/bfq-iosched.c|5499| <<bfq_insert_request>> if (!cgroup_subsys_on_dfl(io_cgrp_subsys) && rq->bio)
+ *   - block/blk-cgroup.c|1472| <<blkcg_policy_register>> WARN_ON(cgroup_add_dfl_cftypes(&io_cgrp_subsys,
+ *   - block/blk-cgroup.c|1475| <<blkcg_policy_register>> WARN_ON(cgroup_add_legacy_cftypes(&io_cgrp_subsys,
+ *   - block/blk-cgroup.c|1919| <<blk_cgroup_bio_start>> if (cgroup_subsys_on_dfl(io_cgrp_subsys))
+ *   - block/blk-throttle.c|302| <<tg_bps_limit>> if (cgroup_subsys_on_dfl(io_cgrp_subsys) && !blkg->parent)
+ *   - block/blk-throttle.c|332| <<tg_iops_limit>> if (cgroup_subsys_on_dfl(io_cgrp_subsys) && !blkg->parent)
+ *   - block/blk-throttle.c|555| <<throtl_pd_init>> if (cgroup_subsys_on_dfl(io_cgrp_subsys) && blkg->parent)
+ *   - block/blk-throttle.c|1409| <<tg_conf_updated>> if (!cgroup_subsys_on_dfl(io_cgrp_subsys) || !blkg->parent ||
+ *   - block/blk-throttle.c|2178| <<blk_throtl_bio>> if (!cgroup_subsys_on_dfl(io_cgrp_subsys)) {
+ *   - include/linux/backing-dev.h|248| <<inode_cgwb_enabled>> cgroup_subsys_on_dfl(io_cgrp_subsys) &&
+ *   - mm/backing-dev.c|442| <<cgwb_create>> blkcg_css = cgroup_get_e_css(memcg_css->cgroup, &io_cgrp_subsys);
+ *   - mm/backing-dev.c|561| <<wb_get_lookup>> blkcg_css = cgroup_get_e_css(memcg_css->cgroup, &io_cgrp_subsys);
+ *   - mm/page_io.c|289| <<bio_associate_blkg_from_page>> css = cgroup_e_css(page->mem_cgroup->css.cgroup, &io_cgrp_subsys);
+ */
 struct cgroup_subsys io_cgrp_subsys = {
 	.css_alloc = blkcg_css_alloc,
 	.css_online = blkcg_css_online,
@@ -1415,6 +1459,13 @@ EXPORT_SYMBOL_GPL(blkcg_deactivate_policy);
  * Register @pol with blkcg core.  Might sleep and @pol may be modified on
  * successful registration.  Returns 0 on success and -errno on failure.
  */
+/*
+ * 在以下调用blkcg_policy_register():
+ *   - block/bfq-iosched.c|6812| <<bfq_init>> ret = blkcg_policy_register(&blkcg_policy_bfq);
+ *   - block/blk-iocost.c|2528| <<ioc_init>> return blkcg_policy_register(&blkcg_policy_iocost);
+ *   - block/blk-iolatency.c|1044| <<iolatency_init>> return blkcg_policy_register(&blkcg_policy_iolatency);
+ *   - block/blk-throttle.c|2477| <<throtl_init>> return blkcg_policy_register(&blkcg_policy_throtl);
+ */
 int blkcg_policy_register(struct blkcg_policy *pol)
 {
 	struct blkcg *blkcg;
@@ -1862,6 +1913,34 @@ static int blk_cgroup_io_type(struct bio *bio)
 	return BLKG_IOSTAT_READ;
 }
 
+/*
+ * [0] blk_cgroup_bio_start
+ * [0] submit_bio_checks
+ * [0] submit_bio_noacct
+ * [0] submit_bio
+ * [0] submit_bh_wbc.isra.57
+ * [0] ll_rw_block
+ * [0] jread
+ * [0] do_one_pass
+ * [0] jbd2_journal_recover
+ * [0] jbd2_journal_load
+ * [0] ext4_fill_super
+ * [0] mount_bdev
+ * [0] legacy_get_tree
+ * [0] vfs_get_tree
+ * [0] path_mount
+ * [0] init_mount
+ * [0] do_mount_root
+ * [0] mount_block_root
+ * [0] mount_root
+ * [0] prepare_namespace
+ * [0] kernel_init_freeable
+ * [0] kernel_init
+ * [0] ret_from_fork
+ *
+ * called by:
+ *   - block/blk-core.c|1059| <<submit_bio_checks>> blk_cgroup_bio_start(bio);
+ */
 void blk_cgroup_bio_start(struct bio *bio)
 {
 	int rwd = blk_cgroup_io_type(bio), cpu;
diff --git a/block/blk-iocost.c b/block/blk-iocost.c
index d37b55db2409..298e72f08506 100644
--- a/block/blk-iocost.c
+++ b/block/blk-iocost.c
@@ -1718,6 +1718,9 @@ static u64 calc_size_vtime_cost(struct request *rq, struct ioc *ioc)
 	return cost;
 }
 
+/*
+ * struct rq_qos_ops ioc_rqos_ops.throttle = ioc_rqos_throttle()
+ */
 static void ioc_rqos_throttle(struct rq_qos *rqos, struct bio *bio)
 {
 	struct blkcg_gq *blkg = bio->bi_blkg;
@@ -1844,6 +1847,9 @@ static void ioc_rqos_throttle(struct rq_qos *rqos, struct bio *bio)
 	finish_wait(&iocg->waitq, &wait.wait);
 }
 
+/*
+ * struct rq_qos_ops ioc_rqos_ops.merge = ioc_rqos_merge()
+ */
 static void ioc_rqos_merge(struct rq_qos *rqos, struct request *rq,
 			   struct bio *bio)
 {
@@ -1897,6 +1903,9 @@ static void ioc_rqos_merge(struct rq_qos *rqos, struct request *rq,
 	spin_unlock_irqrestore(&iocg->waitq.lock, flags);
 }
 
+/*
+ * struct rq_qos_ops ioc_rqos_ops.done_bio = ioc_rqos_done_bio()
+ */
 static void ioc_rqos_done_bio(struct rq_qos *rqos, struct bio *bio)
 {
 	struct ioc_gq *iocg = blkg_to_iocg(bio->bi_blkg);
@@ -1905,6 +1914,9 @@ static void ioc_rqos_done_bio(struct rq_qos *rqos, struct bio *bio)
 		atomic64_add(bio->bi_iocost_cost, &iocg->done_vtime);
 }
 
+/*
+ * struct rq_qos_ops ioc_rqos_ops.done = ioc_rqos_done()
+ */
 static void ioc_rqos_done(struct rq_qos *rqos, struct request *rq)
 {
 	struct ioc *ioc = rqos_to_ioc(rqos);
@@ -1940,6 +1952,9 @@ static void ioc_rqos_done(struct rq_qos *rqos, struct request *rq)
 	this_cpu_add(ioc->pcpu_stat->rq_wait_ns, rq_wait_ns);
 }
 
+/*
+ * struct rq_qos_ops ioc_rqos_ops.queue_depth_changed = ioc_rqos_queue_depth_changed()
+ */
 static void ioc_rqos_queue_depth_changed(struct rq_qos *rqos)
 {
 	struct ioc *ioc = rqos_to_ioc(rqos);
@@ -1949,6 +1964,9 @@ static void ioc_rqos_queue_depth_changed(struct rq_qos *rqos)
 	spin_unlock_irq(&ioc->lock);
 }
 
+/*
+ * struct rq_qos_ops ioc_rqos_ops.exit = ioc_rqos_exit()
+ */
 static void ioc_rqos_exit(struct rq_qos *rqos)
 {
 	struct ioc *ioc = rqos_to_ioc(rqos);
@@ -1964,6 +1982,10 @@ static void ioc_rqos_exit(struct rq_qos *rqos)
 	kfree(ioc);
 }
 
+/*
+ * 在以下使用ioc_rqos_ops:
+ *   - block/blk-iocost.c|1994| <<blk_iocost_init>> rqos->ops = &ioc_rqos_ops;
+ */
 static struct rq_qos_ops ioc_rqos_ops = {
 	.throttle = ioc_rqos_throttle,
 	.merge = ioc_rqos_merge,
@@ -1973,6 +1995,11 @@ static struct rq_qos_ops ioc_rqos_ops = {
 	.exit = ioc_rqos_exit,
 };
 
+/*
+ * called by:
+ *   - block/blk-iocost.c|2262| <<ioc_qos_write>> ret = blk_iocost_init(disk->queue);
+ *   - block/blk-iocost.c|2429| <<ioc_cost_model_write>> ret = blk_iocost_init(disk->queue);
+ */
 static int blk_iocost_init(struct request_queue *q)
 {
 	struct ioc *ioc;
@@ -2514,6 +2541,19 @@ static struct cftype ioc_files[] = {
 	{}
 };
 
+/*
+ * 在以下使用blkcg_policy_iocost:
+ *   - block/blk-iocost.c|639| <<blkg_to_iocg>> return pd_to_iocg(blkg_to_pd(blkg, &blkcg_policy_iocost));
+ *   - block/blk-iocost.c|649| <<blkcg_to_iocc>> return container_of(blkcg_to_cpd(blkcg, &blkcg_policy_iocost),
+ *   - block/blk-iocost.c|1956| <<ioc_rqos_exit>> blkcg_deactivate_policy(rqos->q, &blkcg_policy_iocost);
+ *   - block/blk-iocost.c|2014| <<blk_iocost_init>> ret = blkcg_activate_policy(q, &blkcg_policy_iocost);
+ *   - block/blk-iocost.c|2130| <<ioc_weight_show>> &blkcg_policy_iocost, seq_cft(sf)->private, false);
+ *   - block/blk-iocost.c|2169| <<ioc_weight_write>> ret = blkg_conf_prep(blkcg, &blkcg_policy_iocost, buf, &ctx);
+ *   - block/blk-iocost.c|2226| <<ioc_qos_show>> &blkcg_policy_iocost, seq_cft(sf)->private, false);
+ *   - block/blk-iocost.c|2393| <<ioc_cost_model_show>> &blkcg_policy_iocost, seq_cft(sf)->private, false);
+ *   - block/blk-iocost.c|2528| <<ioc_init>> return blkcg_policy_register(&blkcg_policy_iocost);
+ *   - block/blk-iocost.c|2533| <<ioc_exit>> return blkcg_policy_unregister(&blkcg_policy_iocost);
+ */
 static struct blkcg_policy blkcg_policy_iocost = {
 	.dfl_cftypes	= ioc_files,
 	.cpd_alloc_fn	= ioc_cpd_alloc,
@@ -2525,6 +2565,13 @@ static struct blkcg_policy blkcg_policy_iocost = {
 
 static int __init ioc_init(void)
 {
+	/*
+	 * 在以下调用blkcg_policy_register():
+	 *   - block/bfq-iosched.c|6812| <<bfq_init>> ret = blkcg_policy_register(&blkcg_policy_bfq);
+	 *   - block/blk-iocost.c|2528| <<ioc_init>> return blkcg_policy_register(&blkcg_policy_iocost);
+	 *   - block/blk-iolatency.c|1044| <<iolatency_init>> return blkcg_policy_register(&blkcg_policy_iolatency);
+	 *   - block/blk-throttle.c|2477| <<throtl_init>> return blkcg_policy_register(&blkcg_policy_throtl);
+	 */
 	return blkcg_policy_register(&blkcg_policy_iocost);
 }
 
diff --git a/block/blk-iolatency.c b/block/blk-iolatency.c
index f90429cf4edf..3092e9a6d024 100644
--- a/block/blk-iolatency.c
+++ b/block/blk-iolatency.c
@@ -715,6 +715,10 @@ static void blkiolatency_timer_fn(struct timer_list *t)
 	rcu_read_unlock();
 }
 
+/*
+ * called by:
+ *   - block/blk-cgroup.c|1173| <<blkcg_init_queue>> ret = blk_iolatency_init(q);
+ */
 int blk_iolatency_init(struct request_queue *q)
 {
 	struct blk_iolatency *blkiolat;
@@ -935,6 +939,39 @@ static size_t iolatency_pd_stat(struct blkg_policy_data *pd, char *buf,
 }
 
 
+/*
+ * [0] iolatency_pd_alloc
+ * [0] blkg_alloc
+ * [0] blkg_conf_prep
+ * [0] tg_set_conf.constprop.31
+ * [0] cgroup_file_write
+ * [0] kernfs_fop_write
+ * [0] vfs_write
+ * [0] ksys_write
+ * [0] do_syscall_64
+ * [0] entry_SYSCALL_64_after_hwframe
+ *
+ * [0] iolatency_pd_alloc
+ * [0] blkcg_activate_policy
+ * [0] blk_iolatency_init
+ * [0] blkcg_init_queue
+ * [0] blk_alloc_queue
+ * [0] blk_mq_init_queue_data
+ * [0] virtblk_probe
+ * [0] virtio_dev_probe
+ * [0] really_probe
+ * [0] driver_probe_device
+ * [0] device_driver_attach
+ * [0] __driver_attach
+ * [0] bus_for_each_dev
+ * [0] bus_add_driver
+ * [0] driver_register
+ * [0] init
+ * [0] do_one_initcall
+ * [0] kernel_init_freeable
+ * [0] kernel_init
+ * [0] ret_from_fork
+ */
 static struct blkg_policy_data *iolatency_pd_alloc(gfp_t gfp,
 						   struct request_queue *q,
 						   struct blkcg *blkcg)
@@ -950,6 +987,10 @@ static struct blkg_policy_data *iolatency_pd_alloc(gfp_t gfp,
 		kfree(iolat);
 		return NULL;
 	}
+	/*
+	 * struct iolatency_grp:
+	 *  -> struct blkg_policy_data pd;
+	 */
 	return &iolat->pd;
 }
 
@@ -1030,6 +1071,17 @@ static struct cftype iolatency_files[] = {
 	{}
 };
 
+/*
+ * 在以下使用blkcg_policy_iolatency:
+ *   - block/blk-iolatency.c|184| <<blkg_to_lat>> return pd_to_lat(blkg_to_pd(blkg, &blkcg_policy_iolatency));
+ *   - block/blk-iolatency.c|647| <<blkcg_iolatency_exit>> blkcg_deactivate_policy(rqos->q, &blkcg_policy_iolatency);
+ *   - block/blk-iolatency.c|735| <<blk_iolatency_init>> ret = blkcg_activate_policy(q, &blkcg_policy_iolatency);
+ *   - block/blk-iolatency.c|801| <<iolatency_set_limit>> ret = blkg_conf_prep(blkcg, &blkcg_policy_iolatency, buf, &ctx);
+ *   - block/blk-iolatency.c|885| <<iolatency_print_limit>> &blkcg_policy_iolatency, seq_cft(sf)->private, false);
+ *   - block/blk-iolatency.c|990| <<iolatency_pd_init>> if (blkg->parent && blkg_to_pd(blkg->parent, &blkcg_policy_iolatency)) {
+ *   - block/blk-iolatency.c|1044| <<iolatency_init>> return blkcg_policy_register(&blkcg_policy_iolatency);
+ *   - block/blk-iolatency.c|1049| <<iolatency_exit>> return blkcg_policy_unregister(&blkcg_policy_iolatency);
+ */
 static struct blkcg_policy blkcg_policy_iolatency = {
 	.dfl_cftypes	= iolatency_files,
 	.pd_alloc_fn	= iolatency_pd_alloc,
@@ -1041,6 +1093,13 @@ static struct blkcg_policy blkcg_policy_iolatency = {
 
 static int __init iolatency_init(void)
 {
+	/*
+	 * 在以下调用blkcg_policy_register():
+	 *   - block/bfq-iosched.c|6812| <<bfq_init>> ret = blkcg_policy_register(&blkcg_policy_bfq);
+	 *   - block/blk-iocost.c|2528| <<ioc_init>> return blkcg_policy_register(&blkcg_policy_iocost);
+	 *   - block/blk-iolatency.c|1044| <<iolatency_init>> return blkcg_policy_register(&blkcg_policy_iolatency);
+	 *   - block/blk-throttle.c|2477| <<throtl_init>> return blkcg_policy_register(&blkcg_policy_throtl);
+	 */
 	return blkcg_policy_register(&blkcg_policy_iolatency);
 }
 
diff --git a/block/blk-throttle.c b/block/blk-throttle.c
index fee3325edf27..a91b3ff07e34 100644
--- a/block/blk-throttle.c
+++ b/block/blk-throttle.c
@@ -14,6 +14,20 @@
 #include "blk.h"
 #include "blk-cgroup-rwstat.h"
 
+/*
+ * 似乎是cgroup-blkio有多种限流的算法 (block/Kconfig也有一些解释).
+ * - throttle
+ * - iolatency
+ * - iocost
+ * - bfq
+ *
+ * # mkdir /sys/fs/cgroup/blkio/test
+ *
+ * # echo "253:0 1" > /sys/fs/cgroup/blkio/test/blkio.throttle.write_iops_device
+ *
+ * # cgexec -g blkio:test dd if=/dev/zero of=/dev/vda bs=1M count=10 oflag=direct
+ */
+
 /* Max dispatch from a group in 1 round */
 static int throtl_grp_quantum = 8;
 
@@ -323,6 +337,15 @@ static uint64_t tg_bps_limit(struct throtl_grp *tg, int rw)
 	return ret;
 }
 
+/*
+ * called by:
+ *   - block/blk-throttle.c|575| <<tg_update_has_rules>> tg_iops_limit(tg, rw) != UINT_MAX));
+ *   - block/blk-throttle.c|872| <<throtl_trim_slice>> io_trim = (tg_iops_limit(tg, rw) * tg->td->throtl_slice * nr_slices) /
+ *   - block/blk-throttle.c|916| <<tg_with_in_iops_limit>> tmp = (u64)tg_iops_limit(tg, rw) * jiffy_elapsed_rnd;
+ *   - block/blk-throttle.c|1002| <<tg_may_dispatch>> tg_iops_limit(tg, rw) == UINT_MAX) {
+ *   - block/blk-throttle.c|1393| <<tg_conf_updated>> tg_iops_limit(tg, READ), tg_iops_limit(tg, WRITE));
+ *   - block/blk-throttle.c|2252| <<blk_throtl_bio>> tg->io_disp[rw], tg_iops_limit(tg, rw),
+ */
 static unsigned int tg_iops_limit(struct throtl_grp *tg, int rw)
 {
 	struct blkcg_gq *blkg = tg_to_blkg(tg);
@@ -482,6 +505,39 @@ static void throtl_service_queue_init(struct throtl_service_queue *sq)
 	timer_setup(&sq->pending_timer, throtl_pending_timer_fn, 0);
 }
 
+/*
+ * [0] throtl_pd_alloc
+ * [0] blkg_alloc
+ * [0] blkg_conf_prep
+ * [0] tg_set_conf.constprop.31
+ * [0] cgroup_file_write
+ * [0] kernfs_fop_write
+ * [0] vfs_write
+ * [0] ksys_write
+ * [0] do_syscall_64
+ * [0] entry_SYSCALL_64_after_hwframe
+ *
+ * [0] throtl_pd_alloc
+ * [0] blkcg_activate_policy
+ * [0] blk_throtl_init
+ * [0] blkcg_init_queue
+ * [0] blk_alloc_queue
+ * [0] blk_mq_init_queue_data
+ * [0] virtblk_probe
+ * [0] virtio_dev_probe
+ * [0] really_probe
+ * [0] driver_probe_device
+ * [0] device_driver_attach
+ * [0] __driver_attach
+ * [0] bus_for_each_dev
+ * [0] bus_add_driver
+ * [0] driver_register
+ * [0] init
+ * [0] do_one_initcall
+ * [0] kernel_init_freeable
+ * [0] kernel_init
+ * [0] ret_from_fork
+ */
 static struct blkg_policy_data *throtl_pd_alloc(gfp_t gfp,
 						struct request_queue *q,
 						struct blkcg *blkcg)
@@ -575,6 +631,18 @@ static void tg_update_has_rules(struct throtl_grp *tg)
 			  tg_iops_limit(tg, rw) != UINT_MAX));
 }
 
+/*
+ * [0] throtl_pd_online
+ * [0] blkg_create
+ * [0] blkg_conf_prep
+ * [0] tg_set_conf.constprop.31
+ * [0] cgroup_file_write
+ * [0] kernfs_fop_write
+ * [0] vfs_write
+ * [0] ksys_write
+ * [0] do_syscall_64
+ * [0] entry_SYSCALL_64_after_hwframe
+ */
 static void throtl_pd_online(struct blkg_policy_data *pd)
 {
 	struct throtl_grp *tg = pd_to_tg(pd);
@@ -1508,6 +1576,9 @@ static int tg_print_rwstat_recursive(struct seq_file *sf, void *v)
 	return 0;
 }
 
+/*
+ * struct blkcg_policy blkcg_policy_throtl.legacy_cftypes = throtl_legacy_files[]
+ */
 static struct cftype throtl_legacy_files[] = {
 	{
 		.name = "throttle.read_bps_device",
@@ -2158,6 +2229,10 @@ static inline void throtl_update_latency_buckets(struct throtl_data *td)
 }
 #endif
 
+/*
+ * called by:
+ *   - block/blk-core.c|1054| <<submit_bio_checks>> if (blk_throtl_bio(bio)) {
+ */
 bool blk_throtl_bio(struct bio *bio)
 {
 	struct request_queue *q = bio->bi_disk->queue;
@@ -2307,6 +2382,10 @@ void blk_throtl_stat_add(struct request *rq, u64 time_ns)
 			     time_ns >> 10);
 }
 
+/*
+ * called by:
+ *   - block/bio.c|1445| <<bio_endio>> blk_throtl_bio_endio(bio);
+ */
 void blk_throtl_bio_endio(struct bio *bio)
 {
 	struct blkcg_gq *blkg;
@@ -2360,6 +2439,10 @@ void blk_throtl_bio_endio(struct bio *bio)
 }
 #endif
 
+/*
+ * called by:
+ *   - block/blk-cgroup.c|1169| <<blkcg_init_queue>> ret = blk_throtl_init(q);
+ */
 int blk_throtl_init(struct request_queue *q)
 {
 	struct throtl_data *td;
@@ -2413,6 +2496,10 @@ void blk_throtl_exit(struct request_queue *q)
 	kfree(q->td);
 }
 
+/*
+ * called by:
+ *   - block/blk-sysfs.c|1049| <<blk_register_queue>> blk_throtl_register_queue(q);
+ */
 void blk_throtl_register_queue(struct request_queue *q)
 {
 	struct throtl_data *td;
@@ -2474,6 +2561,13 @@ static int __init throtl_init(void)
 	if (!kthrotld_workqueue)
 		panic("Failed to create kthrotld\n");
 
+	/*
+	 * 在以下调用blkcg_policy_register():
+	 *   - block/bfq-iosched.c|6812| <<bfq_init>> ret = blkcg_policy_register(&blkcg_policy_bfq);
+	 *   - block/blk-iocost.c|2528| <<ioc_init>> return blkcg_policy_register(&blkcg_policy_iocost);
+	 *   - block/blk-iolatency.c|1044| <<iolatency_init>> return blkcg_policy_register(&blkcg_policy_iolatency);
+	 *   - block/blk-throttle.c|2477| <<throtl_init>> return blkcg_policy_register(&blkcg_policy_throtl);
+	 */
 	return blkcg_policy_register(&blkcg_policy_throtl);
 }
 
diff --git a/block/elevator.c b/block/elevator.c
index 90ed7a28c21d..9b78a5d154ae 100644
--- a/block/elevator.c
+++ b/block/elevator.c
@@ -527,6 +527,12 @@ void elv_unregister_queue(struct request_queue *q)
 	}
 }
 
+/*
+ * called by:
+ *   - block/bfq-iosched.c|6844| <<bfq_init>> ret = elv_register(&iosched_bfq_mq);
+ *   - block/kyber-iosched.c|1037| <<kyber_init>> return elv_register(&kyber_sched);
+ *   - block/mq-deadline.c|804| <<deadline_init>> return elv_register(&mq_deadline);
+ */
 int elv_register(struct elevator_type *e)
 {
 	/* create icq_cache if requested */
diff --git a/drivers/vhost/net.c b/drivers/vhost/net.c
index 531a00d703cd..341ad63b8179 100644
--- a/drivers/vhost/net.c
+++ b/drivers/vhost/net.c
@@ -35,6 +35,11 @@
 
 #include "vhost.h"
 
+/*
+ * 在以下使用experimental_zcopytx:
+ *   - drivers/vhost/net.c|344| <<vhost_sock_zcopy>> return unlikely(experimental_zcopytx) &&
+ *   - drivers/vhost/net.c|1784| <<vhost_net_init>> if (experimental_zcopytx)
+ */
 static int experimental_zcopytx = 0;
 module_param(experimental_zcopytx, int, 0444);
 MODULE_PARM_DESC(experimental_zcopytx, "Enable Zero Copy TX;"
@@ -42,6 +47,11 @@ MODULE_PARM_DESC(experimental_zcopytx, "Enable Zero Copy TX;"
 
 /* Max number of bytes transferred before requeueing the job.
  * Using this limit prevents one virtqueue from starving others. */
+/*
+ * 在以下使用VHOST_NET_WEIGHT:
+ *   - drivers/vhost/net.c|641| <<tx_can_batch>> return total_len < VHOST_NET_WEIGHT &&
+ *   - drivers/vhost/net.c|1330| <<vhost_net_open>> VHOST_NET_PKT_WEIGHT, VHOST_NET_WEIGHT, true,
+ */
 #define VHOST_NET_WEIGHT 0x80000
 
 /* Max number of packets transferred before requeueing the job.
@@ -220,6 +230,11 @@ static int vhost_net_buf_peek(struct vhost_net_virtqueue *nvq)
 	return vhost_net_buf_peek_len(vhost_net_buf_get_ptr(rxq));
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|324| <<vhost_net_vq_reset>> vhost_net_buf_init(&n->vqs[i].rxq);
+ *   - drivers/vhost/net.c|1349| <<vhost_net_open>> vhost_net_buf_init(&n->vqs[i].rxq);
+ */
 static void vhost_net_buf_init(struct vhost_net_buf *rxq)
 {
 	rxq->head = rxq->tail = 0;
@@ -1273,6 +1288,19 @@ static void handle_rx_net(struct vhost_work *work)
 	handle_rx(net);
 }
 
+/*
+ * 为每个queue(kthread)调用一次.
+ * [0] vhost_net_open
+ * [0] misc_open
+ * [0] chrdev_open
+ * [0] do_dentry_open
+ * [0] path_openat
+ * [0] do_filp_open
+ * [0] do_sys_openat2
+ * [0] do_sys_open
+ * [0] do_syscall_64
+ * [0] entry_SYSCALL_64_after_hwframe
+ */
 static int vhost_net_open(struct inode *inode, struct file *f)
 {
 	struct vhost_net *n;
@@ -1282,9 +1310,27 @@ static int vhost_net_open(struct inode *inode, struct file *f)
 	struct xdp_buff *xdp;
 	int i;
 
+	/*
+	 * struct vhost_net:
+	 *  -> struct vhost_dev dev;
+	 *  -> struct vhost_net_virtqueue vqs[VHOST_NET_VQ_MAX];
+	 *      -> struct vhost_virtqueue vq;
+	 *          -> struct file *kick;
+	 *          -> struct vhost_vring_call call_ctx;
+	 *          -> struct eventfd_ctx *error_ctx;
+	 *          -> struct eventfd_ctx *log_ctx;
+	 *          -> struct vhost_poll poll;
+	 *  -> struct vhost_poll poll[VHOST_NET_VQ_MAX];
+	 *
+	 * 分配一个vhost_net结构
+	 */
 	n = kvmalloc(sizeof *n, GFP_KERNEL | __GFP_RETRY_MAYFAIL);
 	if (!n)
 		return -ENOMEM;
+	/*
+	 * 分配若干struct vhost_virtqueue的指针
+	 * 真正的内存是vhost_net的一部分
+	 */
 	vqs = kmalloc_array(VHOST_NET_VQ_MAX, sizeof(*vqs), GFP_KERNEL);
 	if (!vqs) {
 		kvfree(n);
@@ -1364,6 +1410,12 @@ static void vhost_net_stop(struct vhost_net *n, struct socket **tx_sock,
 	*rx_sock = vhost_net_stop_vq(n, &n->vqs[VHOST_NET_VQ_RX].vq);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|1385| <<vhost_net_flush>> vhost_net_flush_vq(n, VHOST_NET_VQ_TX);
+ *   - drivers/vhost/net.c|1386| <<vhost_net_flush>> vhost_net_flush_vq(n, VHOST_NET_VQ_RX);
+ *   - drivers/vhost/net.c|1576| <<vhost_net_set_backend>> vhost_net_flush_vq(n, index);
+ */
 static void vhost_net_flush_vq(struct vhost_net *n, int index)
 {
 	vhost_poll_flush(n->poll + index);
@@ -1396,6 +1448,16 @@ static int vhost_net_release(struct inode *inode, struct file *f)
 	vhost_net_stop(n, &tx_sock, &rx_sock);
 	vhost_net_flush(n);
 	vhost_dev_stop(&n->dev);
+	/*
+	 * 在以下调用vhost_dev_cleanup():
+	 *   - drivers/vhost/net.c|1451| <<vhost_net_release>> vhost_dev_cleanup(&n->dev);
+	 *   - drivers/vhost/scsi.c|1654| <<vhost_scsi_release>> vhost_dev_cleanup(&vs->dev);
+	 *   - drivers/vhost/test.c|165| <<vhost_test_release>> vhost_dev_cleanup(&n->dev);
+	 *   - drivers/vhost/vdpa.c|838| <<vhost_vdpa_open>> vhost_dev_cleanup(&v->vdev);
+	 *   - drivers/vhost/vdpa.c|870| <<vhost_vdpa_release>> vhost_dev_cleanup(&v->vdev);
+	 *   - drivers/vhost/vhost.c|787| <<vhost_dev_reset_owner>> vhost_dev_cleanup(dev);
+	 *   - drivers/vhost/vsock.c|715| <<vhost_vsock_dev_release>> vhost_dev_cleanup(&vsock->dev);
+	 */
 	vhost_dev_cleanup(&n->dev);
 	vhost_net_vq_reset(n);
 	if (tx_sock)
diff --git a/drivers/vhost/vhost.c b/drivers/vhost/vhost.c
index 9ad45e1d27f0..da465c073db7 100644
--- a/drivers/vhost/vhost.c
+++ b/drivers/vhost/vhost.c
@@ -33,10 +33,18 @@
 
 #include "vhost.h"
 
+/*
+ * 只在下面使用max_mem_regions:
+ *   - drivers/vhost/vhost.c|1420| <<vhost_set_memory>> if (mem.nregions > max_mem_regions)
+ */
 static ushort max_mem_regions = 64;
 module_param(max_mem_regions, ushort, 0444);
 MODULE_PARM_DESC(max_mem_regions,
 	"Maximum number of memory regions in memory map. (default: 64)");
+/*
+ * 只在下面使用max_iotlb_entries:
+ *   - drivers/vhost/vhost.c|628| <<iotlb_alloc>> return vhost_iotlb_alloc(max_iotlb_entries,
+ */
 static int max_iotlb_entries = 2048;
 module_param(max_iotlb_entries, int, 0444);
 MODULE_PARM_DESC(max_iotlb_entries,
@@ -151,6 +159,12 @@ static void vhost_flush_work(struct vhost_work *work)
 	complete(&s->wait_event);
 }
 
+/*
+ * 在以下使用vhost_poll_func():
+ *   - drivers/vhost/vhost.c|228| <<vhost_poll_init>> init_poll_funcptr(&poll->table, vhost_poll_func);
+ *
+ * 把包含参数poll_table的vhost_poll的poll->wait加入到参数的wqh (wait_queue_head_t)
+ */
 static void vhost_poll_func(struct file *file, wait_queue_head_t *wqh,
 			    poll_table *pt)
 {
@@ -158,9 +172,17 @@ static void vhost_poll_func(struct file *file, wait_queue_head_t *wqh,
 
 	poll = container_of(pt, struct vhost_poll, table);
 	poll->wqh = wqh;
+	/*
+	 * 把&poll->wait加入到wqh
+	 */
 	add_wait_queue(wqh, &poll->wait);
 }
 
+/*
+ * 在以下使用vhost_poll_wakeup():
+ *   - drivers/vhost/vhost.c|206| <<vhost_poll_init>> init_waitqueue_func_entry(&poll->wait, vhost_poll_wakeup);
+ *   - drivers/vhost/vhost.c|234| <<vhost_poll_start>> vhost_poll_wakeup(&poll->wait, 0, 0, poll_to_key(mask));
+ */
 static int vhost_poll_wakeup(wait_queue_entry_t *wait, unsigned mode, int sync,
 			     void *key)
 {
@@ -178,6 +200,16 @@ static int vhost_poll_wakeup(wait_queue_entry_t *wait, unsigned mode, int sync,
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1616| <<vhost_scsi_open>> vhost_work_init(&vs->vs_completion_work, vhost_scsi_complete_cmd_work);
+ *   - drivers/vhost/scsi.c|1617| <<vhost_scsi_open>> vhost_work_init(&vs->vs_event_work, vhost_scsi_evt_work);
+ *   - drivers/vhost/vhost.c|212| <<vhost_poll_init>> vhost_work_init(&poll->work, fn);
+ *   - drivers/vhost/vhost.c|261| <<vhost_work_flush>> vhost_work_init(&flush.work, vhost_flush_work);
+ *   - drivers/vhost/vhost.c|563| <<vhost_attach_cgroups>> vhost_work_init(&attach.work, vhost_attach_cgroups_work);
+ *   - drivers/vhost/vhost.h|39| <<vhost_attach_cgroups>> void vhost_work_init(struct vhost_work *work, vhost_work_fn_t fn);
+ *   - drivers/vhost/vsock.c|640| <<vhost_vsock_dev_open>> vhost_work_init(&vsock->send_pkt_work, vhost_transport_send_pkt_work);
+ */
 void vhost_work_init(struct vhost_work *work, vhost_work_fn_t fn)
 {
 	clear_bit(VHOST_WORK_QUEUED, &work->flags);
@@ -186,10 +218,42 @@ void vhost_work_init(struct vhost_work *work, vhost_work_fn_t fn)
 EXPORT_SYMBOL_GPL(vhost_work_init);
 
 /* Init poll structure */
+/*
+ * called by:
+ *   - drivers/vhost/net.c|1343| <<vhost_net_open>> vhost_poll_init(n->poll + VHOST_NET_VQ_TX, handle_tx_net, EPOLLOUT, dev);
+ *   - drivers/vhost/net.c|1344| <<vhost_net_open>> vhost_poll_init(n->poll + VHOST_NET_VQ_RX, handle_rx_net, EPOLLIN, dev);
+ *   - drivers/vhost/vhost.c|509| <<vhost_dev_init>> vhost_poll_init(&vq->poll, vq->handle_kick, EPOLLIN, dev);
+ */
 void vhost_poll_init(struct vhost_poll *poll, vhost_work_fn_t fn,
 		     __poll_t mask, struct vhost_dev *dev)
 {
+	/*
+	 * 设置poll->wait.func = vhost_poll_wakeup()
+	 */
 	init_waitqueue_func_entry(&poll->wait, vhost_poll_wakeup);
+	/*
+	 * socket : tun_chr_poll()
+	 * eventfd: eventfd_poll()
+	 *
+	 * poll_wait()就是调用poll_table->_qproc=vhost_poll_func()
+	 *
+	 * vhost_poll_func()把&poll->wait加入到fd的wqh
+	 *
+	 * 对于socket: 把n->poll->wait加入到socket的wqh, wait的func是vhost_poll_wakeup()
+	 * 对于eventfd, 把vhost_virtqueue->poll->wait加入到eventfd的wqh, wait的func是vhost_poll_wakeup()
+	 *
+	 * 所以到时候waitqueue唤醒的时候都是调用vhost_poll_wakeup()
+	 *
+	 * vfs_poll()调用file->f_op->poll()
+	 *
+	 * 调用_qproc的地方:
+	 *   - include/linux/poll.h|51| <<poll_wait>> p->_qproc(filp, wait_address, p);
+	 *
+	 * poll_wait()的时候会调用p->_qproc=vhost_poll_func()
+	 *
+	 * 设置poll->table._qproc = vhost_poll_func()
+	 * 这个vhost_poll_func()是把包含参数poll_table的vhost_poll的poll->wait加入到参数的wqh (wait_queue_head_t)
+	 */
 	init_poll_funcptr(&poll->table, vhost_poll_func);
 	poll->mask = mask;
 	poll->dev = dev;
@@ -201,6 +265,13 @@ EXPORT_SYMBOL_GPL(vhost_poll_init);
 
 /* Start polling a file. We add ourselves to file's wait queue. The caller must
  * keep a reference to a file until after vhost_poll_stop is called. */
+/*
+ * called by:
+ *   - drivers/vhost/net.c|454| <<vhost_net_enable_vq>> return vhost_poll_start(poll, sock->file);
+ *   - drivers/vhost/test.c|299| <<vhost_test_set_backend>> r = vhost_poll_start(&vq->poll, vq->kick);
+ *   - drivers/vhost/vhost.c|1709| <<vhost_vring_ioctl>> r = vhost_poll_start(&vq->poll, vq->kick);
+ *   - drivers/vhost/vhost.h|45| <<vhost_vring_ioctl>> int vhost_poll_start(struct vhost_poll *poll, struct file *file);
+ */
 int vhost_poll_start(struct vhost_poll *poll, struct file *file)
 {
 	__poll_t mask;
@@ -208,6 +279,21 @@ int vhost_poll_start(struct vhost_poll *poll, struct file *file)
 	if (poll->wqh)
 		return 0;
 
+	/*
+	 * socket : tun_chr_poll()
+	 * eventfd: eventfd_poll()
+	 *
+	 * poll_wait()就是调用poll_table->_qproc=vhost_poll_func()
+	 *
+	 * vhost_poll_func()把&poll->wait加入到fd的wqh
+	 *
+	 * 对于socket: 把n->poll->wait加入到socket的wqh, wait的func是vhost_poll_wakeup()
+	 * 对于eventfd, 把vhost_virtqueue->poll->wait加入到eventfd的wqh, wait的func是vhost_poll_wakeup()
+	 *
+	 * 所以到时候waitqueue唤醒的时候都是调用vhost_poll_wakeup()
+	 *
+	 * vfs_poll()调用file->f_op->poll()
+	 */
 	mask = vfs_poll(file, &poll->table);
 	if (mask)
 		vhost_poll_wakeup(&poll->wait, 0, 0, poll_to_key(mask));
@@ -222,6 +308,14 @@ EXPORT_SYMBOL_GPL(vhost_poll_start);
 
 /* Stop polling a file. After this function returns, it becomes safe to drop the
  * file reference. You must also flush afterwards. */
+/*
+ * called by:
+ *   - drivers/vhost/net.c|439| <<vhost_net_disable_vq>> vhost_poll_stop(poll);
+ *   - drivers/vhost/test.c|292| <<vhost_test_set_backend>> vhost_poll_stop(&vq->poll);
+ *   - drivers/vhost/vhost.c|301| <<vhost_poll_start>> vhost_poll_stop(poll);
+ *   - drivers/vhost/vhost.c|781| <<vhost_dev_stop>> vhost_poll_stop(&dev->vqs[i]->poll);
+ *   - drivers/vhost/vhost.c|1822| <<vhost_vring_ioctl>> vhost_poll_stop(&vq->poll);
+ */
 void vhost_poll_stop(struct vhost_poll *poll)
 {
 	if (poll->wqh) {
@@ -253,6 +347,16 @@ void vhost_poll_flush(struct vhost_poll *poll)
 }
 EXPORT_SYMBOL_GPL(vhost_poll_flush);
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|371| <<vhost_scsi_complete_cmd>> vhost_work_queue(&vs->dev, &vs->vs_completion_work);
+ *   - drivers/vhost/scsi.c|1315| <<vhost_scsi_send_evt>> vhost_work_queue(&vs->dev, &vs->vs_event_work);
+ *   - drivers/vhost/vhost.c|284| <<vhost_work_flush>> vhost_work_queue(dev, &flush.work);
+ *   - drivers/vhost/vhost.c|323| <<vhost_poll_queue>> vhost_work_queue(poll->dev, &poll->work);
+ *   - drivers/vhost/vhost.c|585| <<vhost_attach_cgroups>> vhost_work_queue(dev, &attach.work);
+ *   - drivers/vhost/vsock.c|268| <<vhost_transport_send_pkt>> vhost_work_queue(&vsock->dev, &vsock->send_pkt_work);
+ *   - drivers/vhost/vsock.c|555| <<vhost_vsock_start>> vhost_work_queue(&vsock->dev, &vsock->send_pkt_work);
+ */
 void vhost_work_queue(struct vhost_dev *dev, struct vhost_work *work)
 {
 	if (!dev->worker)
@@ -298,13 +402,33 @@ static void vhost_vq_meta_reset(struct vhost_dev *d)
 		__vhost_vq_meta_reset(d->vqs[i]);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|431| <<vhost_vq_reset>> vhost_vring_call_reset(&vq->call_ctx);
+ */
 static void vhost_vring_call_reset(struct vhost_vring_call *call_ctx)
 {
 	call_ctx->ctx = NULL;
 	memset(&call_ctx->producer, 0x0, sizeof(struct irq_bypass_producer));
+	/*
+	 * 在以下使用vhost_vring_call->ctx_lock:
+	 *   - drivers/vhost/vdpa.c|100| <<vhost_vdpa_setup_vq_irq>> spin_lock(&vq->call_ctx.ctx_lock);
+	 *   - drivers/vhost/vdpa.c|103| <<vhost_vdpa_setup_vq_irq>> spin_unlock(&vq->call_ctx.ctx_lock);
+	 *   - drivers/vhost/vdpa.c|110| <<vhost_vdpa_setup_vq_irq>> spin_unlock(&vq->call_ctx.ctx_lock);
+	 *   - drivers/vhost/vdpa.c|117| <<vhost_vdpa_unsetup_vq_irq>> spin_lock(&vq->call_ctx.ctx_lock);
+	 *   - drivers/vhost/vdpa.c|119| <<vhost_vdpa_unsetup_vq_irq>> spin_unlock(&vq->call_ctx.ctx_lock);
+	 *   - drivers/vhost/vhost.c|401| <<vhost_vring_call_reset>> spin_lock_init(&call_ctx->ctx_lock);
+	 *   - drivers/vhost/vhost.c|1782| <<vhost_vring_ioctl>> spin_lock(&vq->call_ctx.ctx_lock);
+	 *   - drivers/vhost/vhost.c|1784| <<vhost_vring_ioctl>> spin_unlock(&vq->call_ctx.ctx_lock);
+	 */
 	spin_lock_init(&call_ctx->ctx_lock);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|630| <<vhost_dev_init>> vhost_vq_reset(dev, vq);
+ *   - drivers/vhost/vhost.c|865| <<vhost_dev_cleanup>> vhost_vq_reset(dev, dev->vqs[i]);
+ */
 static void vhost_vq_reset(struct vhost_dev *dev,
 			   struct vhost_virtqueue *vq)
 {
@@ -336,6 +460,10 @@ static void vhost_vq_reset(struct vhost_dev *dev,
 	__vhost_vq_meta_reset(vq);
 }
 
+/*
+ * 在以下创建vhost_worker():
+ *   - drivers/vhost/vhost.c|710| <<vhost_dev_set_owner>> worker = kthread_create(vhost_worker, dev,
+ */
 static int vhost_worker(void *data)
 {
 	struct vhost_dev *dev = data;
@@ -459,6 +587,14 @@ static size_t vhost_get_desc_size(struct vhost_virtqueue *vq,
 	return sizeof(*vq->desc) * num;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|1338| <<vhost_net_open>> vhost_dev_init(dev, vqs, VHOST_NET_VQ_MAX,
+ *   - drivers/vhost/scsi.c|1630| <<vhost_scsi_open>> vhost_dev_init(&vs->dev, vqs, VHOST_SCSI_MAX_VQ, UIO_MAXIOV,
+ *   - drivers/vhost/test.c|122| <<vhost_test_open>> vhost_dev_init(dev, vqs, VHOST_TEST_VQ_MAX, UIO_MAXIOV,
+ *   - drivers/vhost/vdpa.c|820| <<vhost_vdpa_open>> vhost_dev_init(dev, vqs, nvqs, 0, 0, 0, false,
+ *   - drivers/vhost/vsock.c|633| <<vhost_vsock_dev_open>> vhost_dev_init(&vsock->dev, vqs, ARRAY_SIZE(vsock->vqs),
+ */
 void vhost_dev_init(struct vhost_dev *dev,
 		    struct vhost_virtqueue **vqs, int nvqs,
 		    int iov_limit, int weight, int byte_weight,
@@ -497,6 +633,19 @@ void vhost_dev_init(struct vhost_dev *dev,
 		vq->dev = dev;
 		mutex_init(&vq->mutex);
 		vhost_vq_reset(dev, vq);
+		/*
+		 * &vq->poll用来poll在eventfd或者socket上
+		 *
+		 * struct vhost_dev *dev:
+		 * -> struct vhost_virtqueue **vqs;
+		 *    -> struct vhost_poll poll;
+		 *        -> poll_table                table;
+		 *        -> wait_queue_head_t        *wqh;
+		 *        -> wait_queue_entry_t        wait;
+		 *        -> struct vhost_work         work;
+		 *        -> __poll_t                  mask;
+		 *        -> struct vhost_dev         *dev;
+		 */
 		if (vq->handle_kick)
 			vhost_poll_init(&vq->poll, vq->handle_kick,
 					EPOLLIN, dev);
@@ -636,6 +785,11 @@ struct vhost_iotlb *vhost_dev_reset_owner_prepare(void)
 EXPORT_SYMBOL_GPL(vhost_dev_reset_owner_prepare);
 
 /* Caller should have device mutex */
+/*
+ * called by:
+ *   - drivers/vhost/net.c|1659| <<vhost_net_reset_owner>> vhost_dev_reset_owner(&n->dev, umem);
+ *   - drivers/vhost/test.c|242| <<vhost_test_reset_owner>> vhost_dev_reset_owner(&n->dev, umem);
+ */
 void vhost_dev_reset_owner(struct vhost_dev *dev, struct vhost_iotlb *umem)
 {
 	int i;
@@ -683,6 +837,25 @@ static void vhost_clear_msg(struct vhost_dev *dev)
 	spin_unlock(&dev->iotlb_lock);
 }
 
+/*
+ * 每一个vhost的queue(内核线程)都会调用一次
+ * [0] vhost_dev_cleanup
+ * [0] vhost_net_release
+ * [0] __fput
+ * [0] task_work_run
+ * [0] exit_to_user_mode_prepare
+ * [0] syscall_exit_to_user_mode
+ * [0] entry_SYSCALL_64_after_hwframe
+ *
+ * called by:
+ *   - drivers/vhost/net.c|1451| <<vhost_net_release>> vhost_dev_cleanup(&n->dev);
+ *   - drivers/vhost/scsi.c|1654| <<vhost_scsi_release>> vhost_dev_cleanup(&vs->dev);
+ *   - drivers/vhost/test.c|165| <<vhost_test_release>> vhost_dev_cleanup(&n->dev);
+ *   - drivers/vhost/vdpa.c|838| <<vhost_vdpa_open>> vhost_dev_cleanup(&v->vdev);
+ *   - drivers/vhost/vdpa.c|870| <<vhost_vdpa_release>> vhost_dev_cleanup(&v->vdev);
+ *   - drivers/vhost/vhost.c|787| <<vhost_dev_reset_owner>> vhost_dev_cleanup(dev);
+ *   - drivers/vhost/vsock.c|715| <<vhost_vsock_dev_release>> vhost_dev_cleanup(&vsock->dev);
+ */
 void vhost_dev_cleanup(struct vhost_dev *dev)
 {
 	int i;
@@ -1588,6 +1761,9 @@ long vhost_vring_ioctl(struct vhost_dev *d, unsigned int ioctl, void __user *arg
 		return -ENOBUFS;
 
 	idx = array_index_nospec(idx, d->nvqs);
+	/*
+	 * vq的类型是struct vhost_virtqueue *vq;
+	 */
 	vq = d->vqs[idx];
 
 	if (ioctl == VHOST_SET_VRING_NUM ||
@@ -1624,10 +1800,18 @@ long vhost_vring_ioctl(struct vhost_dev *d, unsigned int ioctl, void __user *arg
 			r = -EFAULT;
 		break;
 	case VHOST_SET_VRING_KICK:
+		/*
+		 * struct vhost_vring_file f:
+		 *  -> unsigned int index;
+		 *  -> int fd; // Pass -1 to unbind from file.
+		 */
 		if (copy_from_user(&f, argp, sizeof f)) {
 			r = -EFAULT;
 			break;
 		}
+		/*
+		 * 如果(file->f_op != &eventfd_fops), eventfd_fget()会返回-EINVAL
+		 */
 		eventfp = f.fd == VHOST_FILE_UNBIND ? NULL : eventfd_fget(f.fd);
 		if (IS_ERR(eventfp)) {
 			r = PTR_ERR(eventfp);
@@ -1650,6 +1834,17 @@ long vhost_vring_ioctl(struct vhost_dev *d, unsigned int ioctl, void __user *arg
 			break;
 		}
 
+		/*
+		 * 在以下使用vhost_vring_call->ctx_lock:
+		 *   - drivers/vhost/vdpa.c|100| <<vhost_vdpa_setup_vq_irq>> spin_lock(&vq->call_ctx.ctx_lock);
+		 *   - drivers/vhost/vdpa.c|103| <<vhost_vdpa_setup_vq_irq>> spin_unlock(&vq->call_ctx.ctx_lock);
+		 *   - drivers/vhost/vdpa.c|110| <<vhost_vdpa_setup_vq_irq>> spin_unlock(&vq->call_ctx.ctx_lock);
+		 *   - drivers/vhost/vdpa.c|117| <<vhost_vdpa_unsetup_vq_irq>> spin_lock(&vq->call_ctx.ctx_lock);
+		 *   - drivers/vhost/vdpa.c|119| <<vhost_vdpa_unsetup_vq_irq>> spin_unlock(&vq->call_ctx.ctx_lock);
+		 *   - drivers/vhost/vhost.c|401| <<vhost_vring_call_reset>> spin_lock_init(&call_ctx->ctx_lock);
+		 *   - drivers/vhost/vhost.c|1782| <<vhost_vring_ioctl>> spin_lock(&vq->call_ctx.ctx_lock);
+		 *   - drivers/vhost/vhost.c|1784| <<vhost_vring_ioctl>> spin_unlock(&vq->call_ctx.ctx_lock);
+		 */
 		spin_lock(&vq->call_ctx.ctx_lock);
 		swap(ctx, vq->call_ctx.ctx);
 		spin_unlock(&vq->call_ctx.ctx_lock);
@@ -2417,6 +2612,10 @@ int vhost_add_used_n(struct vhost_virtqueue *vq, struct vring_used_elem *heads,
 }
 EXPORT_SYMBOL_GPL(vhost_add_used_n);
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2590| <<vhost_signal>> if (vq->call_ctx.ctx && vhost_notify(dev, vq))
+ */
 static bool vhost_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 {
 	__u16 old, new;
@@ -2455,9 +2654,22 @@ static bool vhost_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 }
 
 /* This actually signals the guest, using eventfd. */
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|565| <<vhost_scsi_complete_cmd_work>> vhost_signal(&vs->dev, &vs->vqs[vq].vq);
+ *   - drivers/vhost/vhost.c|2601| <<vhost_add_used_and_signal>> vhost_signal(dev, vq);
+ *   - drivers/vhost/vhost.c|2611| <<vhost_add_used_and_signal_n>> vhost_signal(dev, vq);
+ *   - drivers/vhost/vsock.c|225| <<vhost_transport_do_send_pkt>> vhost_signal(&vsock->dev, vq);
+ *   - drivers/vhost/vsock.c|504| <<vhost_vsock_handle_tx_kick>> vhost_signal(&vsock->dev, vq);
+ */
 void vhost_signal(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 {
 	/* Signal the Guest tell them we used something up. */
+	/*
+	 * struct vhost_virtqueue *vq:
+	 *  -> struct file *kick;
+	 *  -> struct vhost_vring_call call_ctx;
+	 */
 	if (vq->call_ctx.ctx && vhost_notify(dev, vq))
 		eventfd_signal(vq->call_ctx.ctx, 1);
 }
@@ -2502,6 +2714,20 @@ bool vhost_vq_avail_empty(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 EXPORT_SYMBOL_GPL(vhost_vq_avail_empty);
 
 /* OK, now we need to know about added descriptors. */
+/*
+ * called by:
+ *   - drivers/vhost/net.c|512| <<vhost_net_busy_poll_try_queue>> } else if (unlikely(vhost_enable_notify(&net->dev, vq))) {
+ *   - drivers/vhost/net.c|564| <<vhost_net_busy_poll>> vhost_enable_notify(&net->dev, rvq);
+ *   - drivers/vhost/net.c|803| <<handle_tx_copy>> } else if (unlikely(vhost_enable_notify(&net->dev,
+ *   - drivers/vhost/net.c|895| <<handle_tx_zerocopy>> } else if (unlikely(vhost_enable_notify(&net->dev, vq))) {
+ *   - drivers/vhost/net.c|1171| <<handle_rx>> } else if (unlikely(vhost_enable_notify(&net->dev, vq))) {
+ *   - drivers/vhost/scsi.c|470| <<vhost_scsi_do_evt_work>> if (vhost_enable_notify(&vs->dev, vq))
+ *   - drivers/vhost/scsi.c|831| <<vhost_scsi_get_desc>> if (unlikely(vhost_enable_notify(&vs->dev, vq))) {
+ *   - drivers/vhost/test.c|70| <<handle_vq>> if (unlikely(vhost_enable_notify(&n->dev, vq))) {
+ *   - drivers/vhost/vsock.c|111| <<vhost_transport_do_send_pkt>> vhost_enable_notify(&vsock->dev, vq);
+ *   - drivers/vhost/vsock.c|137| <<vhost_transport_do_send_pkt>> if (unlikely(vhost_enable_notify(&vsock->dev, vq))) {
+ *   - drivers/vhost/vsock.c|470| <<vhost_vsock_handle_tx_kick>> if (unlikely(vhost_enable_notify(&vsock->dev, vq))) {
+ */
 bool vhost_enable_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 {
 	__virtio16 avail_idx;
@@ -2540,6 +2766,26 @@ bool vhost_enable_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 EXPORT_SYMBOL_GPL(vhost_enable_notify);
 
 /* We don't need to be notified again. */
+/*
+ * called by:
+ *   - drivers/vhost/net.c|513| <<vhost_net_busy_poll_try_queue>> vhost_disable_notify(&net->dev, vq);
+ *   - drivers/vhost/net.c|536| <<vhost_net_busy_poll>> vhost_disable_notify(&net->dev, vq);
+ *   - drivers/vhost/net.c|805| <<handle_tx_copy>> vhost_disable_notify(&net->dev, vq);
+ *   - drivers/vhost/net.c|896| <<handle_tx_zerocopy>> vhost_disable_notify(&net->dev, vq);
+ *   - drivers/vhost/net.c|975| <<handle_tx>> vhost_disable_notify(&net->dev, vq);
+ *   - drivers/vhost/net.c|1144| <<handle_rx>> vhost_disable_notify(&net->dev, vq);
+ *   - drivers/vhost/net.c|1174| <<handle_rx>> vhost_disable_notify(&net->dev, vq);
+ *   - drivers/vhost/scsi.c|461| <<vhost_scsi_do_evt_work>> vhost_disable_notify(&vs->dev, vq);
+ *   - drivers/vhost/scsi.c|832| <<vhost_scsi_get_desc>> vhost_disable_notify(&vs->dev, vq);
+ *   - drivers/vhost/scsi.c|939| <<vhost_scsi_handle_vq>> vhost_disable_notify(&vs->dev, vq);
+ *   - drivers/vhost/scsi.c|1192| <<vhost_scsi_ctl_handle_vq>> vhost_disable_notify(&vs->dev, vq);
+ *   - drivers/vhost/test.c|58| <<handle_vq>> vhost_disable_notify(&n->dev, vq);
+ *   - drivers/vhost/test.c|71| <<handle_vq>> vhost_disable_notify(&n->dev, vq);
+ *   - drivers/vhost/vsock.c|98| <<vhost_transport_do_send_pkt>> vhost_disable_notify(&vsock->dev, vq);
+ *   - drivers/vhost/vsock.c|138| <<vhost_transport_do_send_pkt>> vhost_disable_notify(&vsock->dev, vq);
+ *   - drivers/vhost/vsock.c|452| <<vhost_vsock_handle_tx_kick>> vhost_disable_notify(&vsock->dev, vq);
+ *   - drivers/vhost/vsock.c|471| <<vhost_vsock_handle_tx_kick>> vhost_disable_notify(&vsock->dev, vq);
+ */
 void vhost_disable_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 {
 	int r;
diff --git a/drivers/vhost/vhost.h b/drivers/vhost/vhost.h
index 9032d3c2a9f4..551d802e9537 100644
--- a/drivers/vhost/vhost.h
+++ b/drivers/vhost/vhost.h
@@ -64,6 +64,17 @@ enum vhost_uaddr_type {
 struct vhost_vring_call {
 	struct eventfd_ctx *ctx;
 	struct irq_bypass_producer producer;
+	/*
+	 * 在以下使用vhost_vring_call->ctx_lock:
+	 *   - drivers/vhost/vdpa.c|100| <<vhost_vdpa_setup_vq_irq>> spin_lock(&vq->call_ctx.ctx_lock);
+	 *   - drivers/vhost/vdpa.c|103| <<vhost_vdpa_setup_vq_irq>> spin_unlock(&vq->call_ctx.ctx_lock);
+	 *   - drivers/vhost/vdpa.c|110| <<vhost_vdpa_setup_vq_irq>> spin_unlock(&vq->call_ctx.ctx_lock);
+	 *   - drivers/vhost/vdpa.c|117| <<vhost_vdpa_unsetup_vq_irq>> spin_lock(&vq->call_ctx.ctx_lock);
+	 *   - drivers/vhost/vdpa.c|119| <<vhost_vdpa_unsetup_vq_irq>> spin_unlock(&vq->call_ctx.ctx_lock);
+	 *   - drivers/vhost/vhost.c|401| <<vhost_vring_call_reset>> spin_lock_init(&call_ctx->ctx_lock);
+	 *   - drivers/vhost/vhost.c|1782| <<vhost_vring_ioctl>> spin_lock(&vq->call_ctx.ctx_lock);
+	 *   - drivers/vhost/vhost.c|1784| <<vhost_vring_ioctl>> spin_unlock(&vq->call_ctx.ctx_lock);
+	 */
 	spinlock_t ctx_lock;
 };
 
@@ -150,6 +161,25 @@ struct vhost_dev {
 	int nvqs;
 	struct eventfd_ctx *log_ctx;
 	struct llist_head work_list;
+	/*
+	 * 在以下使用vhost_dev->worker:
+	 *   - drivers/vhost/vhost.c|332| <<vhost_work_flush>> if (dev->worker) {
+	 *   - drivers/vhost/vhost.c|362| <<vhost_work_queue>> if (!dev->worker)
+	 *   - drivers/vhost/vhost.c|371| <<vhost_work_queue>> wake_up_process(dev->worker);
+	 *   - drivers/vhost/vhost.c|615| <<vhost_dev_init>> dev->worker = NULL;
+	 *   - drivers/vhost/vhost.c|729| <<vhost_dev_set_owner>> struct task_struct *worker;
+	 *   - drivers/vhost/vhost.c|742| <<vhost_dev_set_owner>> worker = kthread_create(vhost_worker, dev,
+	 *   - drivers/vhost/vhost.c|744| <<vhost_dev_set_owner>> if (IS_ERR(worker)) {
+	 *   - drivers/vhost/vhost.c|745| <<vhost_dev_set_owner>> err = PTR_ERR(worker);
+	 *   - drivers/vhost/vhost.c|749| <<vhost_dev_set_owner>> dev->worker = worker;
+	 *   - drivers/vhost/vhost.c|750| <<vhost_dev_set_owner>> wake_up_process(worker);
+	 *   - drivers/vhost/vhost.c|763| <<vhost_dev_set_owner>> if (dev->worker) {
+	 *   - drivers/vhost/vhost.c|764| <<vhost_dev_set_owner>> kthread_stop(dev->worker);
+	 *   - drivers/vhost/vhost.c|765| <<vhost_dev_set_owner>> dev->worker = NULL;
+	 *   - drivers/vhost/vhost.c|884| <<vhost_dev_cleanup>> if (dev->worker) {
+	 *   - drivers/vhost/vhost.c|885| <<vhost_dev_cleanup>> kthread_stop(dev->worker);
+	 *   - drivers/vhost/vhost.c|886| <<vhost_dev_cleanup>> dev->worker = NULL;
+	 */
 	struct task_struct *worker;
 	struct vhost_iotlb *umem;
 	struct vhost_iotlb *iotlb;
diff --git a/fs/eventfd.c b/fs/eventfd.c
index df466ef81ddd..38539c12f267 100644
--- a/fs/eventfd.c
+++ b/fs/eventfd.c
@@ -59,6 +59,17 @@ struct eventfd_ctx {
  * Returns the amount by which the counter was incremented.  This will be less
  * than @n if the counter has overflowed.
  */
+/*
+ * called by:
+ *   - drivers/vhost/vdpa.c|73| <<vhost_vdpa_virtqueue_cb>> eventfd_signal(call_ctx, 1);
+ *   - drivers/vhost/vdpa.c|84| <<vhost_vdpa_config_cb>> eventfd_signal(config_ctx, 1);
+ *   - drivers/vhost/vhost.c|2142| <<vhost_log_write>> eventfd_signal(vq->log_ctx, 1);
+ *   - drivers/vhost/vhost.c|2165| <<vhost_update_used_flags>> eventfd_signal(vq->log_ctx, 1);
+ *   - drivers/vhost/vhost.c|2183| <<vhost_update_avail_event>> eventfd_signal(vq->log_ctx, 1);
+ *   - drivers/vhost/vhost.c|2609| <<vhost_add_used_n>> eventfd_signal(vq->log_ctx, 1);
+ *   - drivers/vhost/vhost.c|2674| <<vhost_signal>> eventfd_signal(vq->call_ctx.ctx, 1);
+ *   - drivers/vhost/vhost.h|263| <<vq_err>> eventfd_signal((vq)->error_ctx, 1);\
+ */
 __u64 eventfd_signal(struct eventfd_ctx *ctx, __u64 n)
 {
 	unsigned long flags;
diff --git a/include/linux/kvm_host.h b/include/linux/kvm_host.h
index 05e3c2fb3ef7..dd8b1a14e444 100644
--- a/include/linux/kvm_host.h
+++ b/include/linux/kvm_host.h
@@ -498,6 +498,17 @@ struct kvm {
 	long tlbs_dirty;
 	struct list_head devices;
 	u64 manual_dirty_log_protect;
+	/*
+	 * 在以下使用kvm->debugfs_dentry:
+	 *   - arch/arm64/kvm/vgic/vgic-debug.c|294| <<vgic_debug_init>> debugfs_create_file("vgic-state", 0444, kvm->debugfs_dentry, kvm,
+	 *   - virt/kvm/kvm_main.c|677| <<kvm_destroy_vm_debugfs>> if (!kvm->debugfs_dentry)
+	 *   - virt/kvm/kvm_main.c|680| <<kvm_destroy_vm_debugfs>> debugfs_remove_recursive(kvm->debugfs_dentry);
+	 *   - virt/kvm/kvm_main.c|699| <<kvm_create_vm_debugfs>> kvm->debugfs_dentry = debugfs_create_dir(dir_name, kvm_debugfs_dir);
+	 *   - virt/kvm/kvm_main.c|716| <<kvm_create_vm_debugfs>> kvm->debugfs_dentry, stat_data,
+	 *   - virt/kvm/kvm_main.c|3077| <<kvm_create_vcpu_debugfs>> vcpu->kvm->debugfs_dentry);
+	 *   - virt/kvm/kvm_main.c|4640| <<kvm_uevent_notify_change>> if (!IS_ERR_OR_NULL(kvm->debugfs_dentry)) {
+	 *   - virt/kvm/kvm_main.c|4644| <<kvm_uevent_notify_change>> tmp = dentry_path_raw(kvm->debugfs_dentry, p, PATH_MAX);
+	 */
 	struct dentry *debugfs_dentry;
 	struct kvm_stat_data **debugfs_stat_data;
 	struct srcu_struct srcu;
diff --git a/include/linux/poll.h b/include/linux/poll.h
index 1cdc32b1f1b0..9d24cdd6d56f 100644
--- a/include/linux/poll.h
+++ b/include/linux/poll.h
@@ -45,6 +45,9 @@ typedef struct poll_table_struct {
 	__poll_t _key;
 } poll_table;
 
+/*
+ * vhost的_qproc的例子vhost_poll_func()
+ */
 static inline void poll_wait(struct file * filp, wait_queue_head_t * wait_address, poll_table *p)
 {
 	if (p && p->_qproc && wait_address)
@@ -74,6 +77,10 @@ static inline __poll_t poll_requested_events(const poll_table *p)
 
 static inline void init_poll_funcptr(poll_table *pt, poll_queue_proc qproc)
 {
+	/*
+	 * 调用_qproc的地方:
+	 *   - include/linux/poll.h|51| <<poll_wait>> p->_qproc(filp, wait_address, p);
+	 */
 	pt->_qproc = qproc;
 	pt->_key   = ~(__poll_t)0; /* all events enabled */
 }
diff --git a/virt/kvm/kvm_main.c b/virt/kvm/kvm_main.c
index cf88233b819a..78734271e2b8 100644
--- a/virt/kvm/kvm_main.c
+++ b/virt/kvm/kvm_main.c
@@ -108,6 +108,16 @@ static struct kmem_cache *kvm_vcpu_cache;
 static __read_mostly struct preempt_ops kvm_preempt_ops;
 static DEFINE_PER_CPU(struct kvm_vcpu *, kvm_running_vcpu);
 
+/*
+ * 在以下使用kvm_debugfs_dir:
+ *   - virt/kvm/kvm_main.c|112| <<global>> EXPORT_SYMBOL_GPL(kvm_debugfs_dir);
+ *   - arch/powerpc/kvm/book3s_hv.c|4978| <<kvmppc_core_init_vm_hv>> kvm->arch.debugfs_dir = debugfs_create_dir(buf, kvm_debugfs_dir);
+ *   - arch/powerpc/kvm/timing.c|214| <<kvmppc_create_vcpu_debugfs>> debugfs_file = debugfs_create_file(dbg_fname, 0666, kvm_debugfs_dir,
+ *   - virt/kvm/kvm_main.c|699| <<kvm_create_vm_debugfs>> kvm->debugfs_dentry = debugfs_create_dir(dir_name, kvm_debugfs_dir);
+ *   - virt/kvm/kvm_main.c|4660| <<kvm_init_debug>> kvm_debugfs_dir = debugfs_create_dir("kvm", NULL);
+ *   - virt/kvm/kvm_main.c|4665| <<kvm_init_debug>> kvm_debugfs_dir, (void *)(long )p->offset,
+ *   - virt/kvm/kvm_main.c|4871| <<kvm_exit>> debugfs_remove_recursive(kvm_debugfs_dir);
+ */
 struct dentry *kvm_debugfs_dir;
 EXPORT_SYMBOL_GPL(kvm_debugfs_dir);
 
@@ -696,6 +706,26 @@ static int kvm_create_vm_debugfs(struct kvm *kvm, int fd)
 		return 0;
 
 	snprintf(dir_name, sizeof(dir_name), "%d-%d", task_pid_nr(current), fd);
+	/*
+	 * 在以下使用kvm->debugfs_dentry:
+	 *   - arch/arm64/kvm/vgic/vgic-debug.c|294| <<vgic_debug_init>> debugfs_create_file("vgic-state", 0444, kvm->debugfs_dentry, kvm,
+	 *   - virt/kvm/kvm_main.c|677| <<kvm_destroy_vm_debugfs>> if (!kvm->debugfs_dentry)
+	 *   - virt/kvm/kvm_main.c|680| <<kvm_destroy_vm_debugfs>> debugfs_remove_recursive(kvm->debugfs_dentry);
+	 *   - virt/kvm/kvm_main.c|699| <<kvm_create_vm_debugfs>> kvm->debugfs_dentry = debugfs_create_dir(dir_name, kvm_debugfs_dir);
+	 *   - virt/kvm/kvm_main.c|716| <<kvm_create_vm_debugfs>> kvm->debugfs_dentry, stat_data,
+	 *   - virt/kvm/kvm_main.c|3077| <<kvm_create_vcpu_debugfs>> vcpu->kvm->debugfs_dentry);
+	 *   - virt/kvm/kvm_main.c|4640| <<kvm_uevent_notify_change>> if (!IS_ERR_OR_NULL(kvm->debugfs_dentry)) {
+	 *   - virt/kvm/kvm_main.c|4644| <<kvm_uevent_notify_change>> tmp = dentry_path_raw(kvm->debugfs_dentry, p, PATH_MAX);
+	 *
+	 * 在以下使用kvm_debugfs_dir:
+	 *   - virt/kvm/kvm_main.c|112| <<global>> EXPORT_SYMBOL_GPL(kvm_debugfs_dir);
+	 *   - arch/powerpc/kvm/book3s_hv.c|4978| <<kvmppc_core_init_vm_hv>> kvm->arch.debugfs_dir = debugfs_create_dir(buf, kvm_debugfs_dir);
+	 *   - arch/powerpc/kvm/timing.c|214| <<kvmppc_create_vcpu_debugfs>> debugfs_file = debugfs_create_file(dbg_fname, 0666, kvm_debugfs_dir,
+	 *   - virt/kvm/kvm_main.c|699| <<kvm_create_vm_debugfs>> kvm->debugfs_dentry = debugfs_create_dir(dir_name, kvm_debugfs_dir);
+	 *   - virt/kvm/kvm_main.c|4660| <<kvm_init_debug>> kvm_debugfs_dir = debugfs_create_dir("kvm", NULL);
+	 *   - virt/kvm/kvm_main.c|4665| <<kvm_init_debug>> kvm_debugfs_dir, (void *)(long )p->offset,
+	 *   - virt/kvm/kvm_main.c|4871| <<kvm_exit>> debugfs_remove_recursive(kvm_debugfs_dir);
+	 */
 	kvm->debugfs_dentry = debugfs_create_dir(dir_name, kvm_debugfs_dir);
 
 	kvm->debugfs_stat_data = kcalloc(kvm_debugfs_num_entries,
@@ -4657,6 +4687,16 @@ static void kvm_init_debug(void)
 {
 	struct kvm_stats_debugfs_item *p;
 
+	/*
+	 * 在以下使用kvm_debugfs_dir:
+	 *   - virt/kvm/kvm_main.c|112| <<global>> EXPORT_SYMBOL_GPL(kvm_debugfs_dir);
+	 *   - arch/powerpc/kvm/book3s_hv.c|4978| <<kvmppc_core_init_vm_hv>> kvm->arch.debugfs_dir = debugfs_create_dir(buf, kvm_debugfs_dir);
+	 *   - arch/powerpc/kvm/timing.c|214| <<kvmppc_create_vcpu_debugfs>> debugfs_file = debugfs_create_file(dbg_fname, 0666, kvm_debugfs_dir,
+	 *   - virt/kvm/kvm_main.c|699| <<kvm_create_vm_debugfs>> kvm->debugfs_dentry = debugfs_create_dir(dir_name, kvm_debugfs_dir);
+	 *   - virt/kvm/kvm_main.c|4660| <<kvm_init_debug>> kvm_debugfs_dir = debugfs_create_dir("kvm", NULL);
+	 *   - virt/kvm/kvm_main.c|4665| <<kvm_init_debug>> kvm_debugfs_dir, (void *)(long )p->offset,
+	 *   - virt/kvm/kvm_main.c|4871| <<kvm_exit>> debugfs_remove_recursive(kvm_debugfs_dir);
+	 */
 	kvm_debugfs_dir = debugfs_create_dir("kvm", NULL);
 
 	kvm_debugfs_num_entries = 0;
@@ -4868,6 +4908,16 @@ EXPORT_SYMBOL_GPL(kvm_init);
 
 void kvm_exit(void)
 {
+	/*
+	 * 在以下使用kvm_debugfs_dir:
+	 *   - virt/kvm/kvm_main.c|112| <<global>> EXPORT_SYMBOL_GPL(kvm_debugfs_dir);
+	 *   - arch/powerpc/kvm/book3s_hv.c|4978| <<kvmppc_core_init_vm_hv>> kvm->arch.debugfs_dir = debugfs_create_dir(buf, kvm_debugfs_dir);
+	 *   - arch/powerpc/kvm/timing.c|214| <<kvmppc_create_vcpu_debugfs>> debugfs_file = debugfs_create_file(dbg_fname, 0666, kvm_debugfs_dir,
+	 *   - virt/kvm/kvm_main.c|699| <<kvm_create_vm_debugfs>> kvm->debugfs_dentry = debugfs_create_dir(dir_name, kvm_debugfs_dir);
+	 *   - virt/kvm/kvm_main.c|4660| <<kvm_init_debug>> kvm_debugfs_dir = debugfs_create_dir("kvm", NULL);
+	 *   - virt/kvm/kvm_main.c|4665| <<kvm_init_debug>> kvm_debugfs_dir, (void *)(long )p->offset,
+	 *   - virt/kvm/kvm_main.c|4871| <<kvm_exit>> debugfs_remove_recursive(kvm_debugfs_dir);
+	 */
 	debugfs_remove_recursive(kvm_debugfs_dir);
 	misc_deregister(&kvm_dev);
 	kmem_cache_destroy(kvm_vcpu_cache);
-- 
2.17.1

