From 568f144841e423e7f13db7a19de61e6ba6e23b33 Mon Sep 17 00:00:00 2001
From: Dongli Zhang <dongli.zhang0129@gmail.com>
Date: Wed, 1 Apr 2020 16:27:12 -0700
Subject: [PATCH 1/1] kvm for linux v5.5

Signed-off-by: Dongli Zhang <dongli.zhang0129@gmail.com>
---
 arch/x86/include/asm/kvm_host.h      | 12 ++++
 arch/x86/include/uapi/asm/kvm_para.h | 14 +++++
 arch/x86/kvm/lapic.c                 | 34 ++++++++++
 arch/x86/kvm/lapic.h                 | 64 +++++++++++++++++++
 arch/x86/kvm/mmu.h                   |  6 ++
 arch/x86/kvm/mmu/mmu.c               |  5 ++
 arch/x86/kvm/vmx/vmx.c               | 10 +++
 arch/x86/kvm/x86.c                   | 63 +++++++++++++++++++
 drivers/cpuidle/driver.c             |  9 +++
 drivers/vfio/pci/vfio_pci.c          | 45 ++++++++++++++
 drivers/vfio/pci/vfio_pci_config.c   |  4 ++
 drivers/vfio/pci/vfio_pci_intrs.c    | 45 ++++++++++++++
 drivers/vfio/pci/vfio_pci_private.h  | 43 +++++++++++++
 drivers/vfio/pci/vfio_pci_rdwr.c     | 27 ++++++++
 drivers/vfio/vfio.c                  | 93 ++++++++++++++++++++++++++++
 drivers/vfio/vfio_iommu_type1.c      | 48 ++++++++++++++
 include/linux/kvm_host.h             |  8 +++
 virt/kvm/eventfd.c                   | 18 ++++++
 virt/kvm/irqchip.c                   | 12 ++++
 virt/kvm/kvm_main.c                  |  9 +++
 20 files changed, 569 insertions(+)

diff --git a/arch/x86/include/asm/kvm_host.h b/arch/x86/include/asm/kvm_host.h
index b79cd6aa4075..1ade14f3e59c 100644
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@ -943,6 +943,18 @@ struct kvm_arch {
 
 	u64 disabled_quirks;
 
+	/*
+	 * 在以下设置irqchip_mode:
+	 *   - arch/x86/kvm/x86.c|4790| <<kvm_vm_ioctl_enable_cap>> kvm->arch.irqchip_mode = KVM_IRQCHIP_SPLIT;
+	 *   - arch/x86/kvm/x86.c|4911| <<kvm_arch_vm_ioctl>> kvm->arch.irqchip_mode = KVM_IRQCHIP_KERNEL;
+	 *
+	 * 在以下使用irqchip_mode:
+	 *   - arch/x86/kvm/ioapic.h|111| <<ioapic_in_kernel>> int mode = kvm->arch.irqchip_mode;
+	 *   - arch/x86/kvm/irq.h|71| <<pic_in_kernel>> int mode = kvm->arch.irqchip_mode;
+	 *   - arch/x86/kvm/irq.h|80| <<irqchip_split>> int mode = kvm->arch.irqchip_mode;
+	 *   - arch/x86/kvm/irq.h|89| <<irqchip_kernel>> int mode = kvm->arch.irqchip_mode;
+	 *   - arch/x86/kvm/irq.h|98| <<irqchip_in_kernel>> int mode = kvm->arch.irqchip_mode;
+	 */
 	enum kvm_irqchip_mode irqchip_mode;
 	u8 nr_reserved_ioapic_pins;
 
diff --git a/arch/x86/include/uapi/asm/kvm_para.h b/arch/x86/include/uapi/asm/kvm_para.h
index 2a8e0b6b9805..96499eb7231b 100644
--- a/arch/x86/include/uapi/asm/kvm_para.h
+++ b/arch/x86/include/uapi/asm/kvm_para.h
@@ -32,6 +32,15 @@
 #define KVM_FEATURE_POLL_CONTROL	12
 #define KVM_FEATURE_PV_SCHED_YIELD	13
 
+/*
+ * 在以下使用KVM_HINTS_REALTIME:
+ *   - arch/x86/kernel/kvm.c|534| <<kvm_smp_prepare_cpus>> if (kvm_para_has_hint(KVM_HINTS_REALTIME))
+ *   - arch/x86/kernel/kvm.c|627| <<kvm_guest_init>> !kvm_para_has_hint(KVM_HINTS_REALTIME) &&
+ *   - arch/x86/kernel/kvm.c|640| <<kvm_guest_init>> !kvm_para_has_hint(KVM_HINTS_REALTIME) &&
+ *   - arch/x86/kernel/kvm.c|744| <<kvm_setup_pv_tlb_flush>> !kvm_para_has_hint(KVM_HINTS_REALTIME) &&
+ *   - arch/x86/kernel/kvm.c|839| <<kvm_spinlock_init>> if (kvm_para_has_hint(KVM_HINTS_REALTIME))
+ *   - drivers/cpuidle/cpuidle-haltpoll.c|105| <<haltpoll_init>> !kvm_para_has_hint(KVM_HINTS_REALTIME))
+ */
 #define KVM_HINTS_REALTIME      0
 
 /* The last 8 bits are used to indicate how to interpret the flags field
@@ -79,6 +88,11 @@ struct kvm_clock_pairing {
 #define KVM_MAX_MMU_OP_BATCH           32
 
 #define KVM_ASYNC_PF_ENABLED			(1 << 0)
+/*
+ * 在以下使用KVM_ASYNC_PF_SEND_ALWAYS:
+ *   - arch/x86/kernel/kvm.c|316| <<kvm_guest_cpu_init>> pa |= KVM_ASYNC_PF_SEND_ALWAYS;
+ *   - arch/x86/kvm/x86.c|2564| <<kvm_pv_enable_async_pf>> vcpu->arch.apf.send_user_only = !(data & KVM_ASYNC_PF_SEND_ALWAYS);
+ */
 #define KVM_ASYNC_PF_SEND_ALWAYS		(1 << 1)
 #define KVM_ASYNC_PF_DELIVERY_AS_PF_VMEXIT	(1 << 2)
 
diff --git a/arch/x86/kvm/lapic.c b/arch/x86/kvm/lapic.c
index cf9177b4a07f..8c38c9ff1019 100644
--- a/arch/x86/kvm/lapic.c
+++ b/arch/x86/kvm/lapic.c
@@ -96,6 +96,15 @@ static inline int __apic_test_and_clear_vector(int vec, void *bitmap)
 	return __test_and_clear_bit(VEC_POS(vec), (bitmap) + REG_POS(vec));
 }
 
+/*
+ * 在以下使用apic_hw_disabled:
+ *   - arch/x86/kvm/lapic.c|2098| <<kvm_free_lapic>> static_key_slow_dec_deferred(&apic_hw_disabled);
+ *   - arch/x86/kvm/lapic.c|2175| <<kvm_lapic_set_base>> static_key_slow_dec_deferred(&apic_hw_disabled);
+ *   - arch/x86/kvm/lapic.c|2177| <<kvm_lapic_set_base>> static_key_slow_inc(&apic_hw_disabled.key);
+ *   - arch/x86/kvm/lapic.c|2795| <<kvm_lapic_init>> jump_label_rate_limit(&apic_hw_disabled, HZ);
+ *   - arch/x86/kvm/lapic.c|2801| <<kvm_lapic_exit>> static_key_deferred_flush(&apic_hw_disabled);
+ *   - arch/x86/kvm/lapic.h|175| <<kvm_apic_hw_enabled>> if (static_key_false(&apic_hw_disabled.key))
+ */
 struct static_key_deferred apic_hw_disabled __read_mostly;
 struct static_key_deferred apic_sw_disabled __read_mostly;
 
@@ -425,6 +434,14 @@ static inline int apic_search_irr(struct kvm_lapic *apic)
 	return find_highest_vector(apic->regs + APIC_IRR);
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/lapic.c|455| <<apic_clear_irr>> apic_find_highest_irr(apic));
+ *   - arch/x86/kvm/lapic.c|543| <<kvm_lapic_find_highest_irr>> return apic_find_highest_irr(vcpu->arch.apic);
+ *   - arch/x86/kvm/lapic.c|665| <<apic_has_interrupt_for_ppr>> highest_irr = apic_find_highest_irr(apic);
+ *   - arch/x86/kvm/lapic.c|2496| <<kvm_apic_set_state>> apic_find_highest_irr(apic));
+ *   - arch/x86/kvm/lapic.c|2614| <<kvm_lapic_sync_to_vapic>> max_irr = apic_find_highest_irr(apic);
+ */
 static inline int apic_find_highest_irr(struct kvm_lapic *apic)
 {
 	int result;
@@ -2144,6 +2161,13 @@ u64 kvm_lapic_get_cr8(struct kvm_vcpu *vcpu)
 	return (tpr & 0xf0) >> 4;
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/lapic.c|2208| <<kvm_lapic_reset>> kvm_lapic_set_base(vcpu, APIC_DEFAULT_PHYS_BASE |
+ *   - arch/x86/kvm/lapic.c|2244| <<kvm_lapic_reset>> kvm_lapic_set_base(vcpu,
+ *   - arch/x86/kvm/lapic.c|2485| <<kvm_apic_set_state>> kvm_lapic_set_base(vcpu, vcpu->arch.apic_base);
+ *   - arch/x86/kvm/x86.c|349| <<kvm_set_apic_base>> kvm_lapic_set_base(vcpu, msr_info->data);
+ */
 void kvm_lapic_set_base(struct kvm_vcpu *vcpu, u64 value)
 {
 	u64 old_value = vcpu->arch.apic_base;
@@ -2268,6 +2292,12 @@ int apic_has_pending_timer(struct kvm_vcpu *vcpu)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/lapic.c|1576| <<kvm_apic_inject_pending_timer_irqs>> kvm_apic_local_deliver(apic, APIC_LVTT);
+ *   - arch/x86/kvm/lapic.c|2291| <<kvm_apic_nmi_wd_deliver>> kvm_apic_local_deliver(apic, APIC_LVT0);
+ *   - arch/x86/kvm/pmu.c|382| <<kvm_pmu_deliver_pmi>> kvm_apic_local_deliver(vcpu->arch.apic, APIC_LVTPC);
+ */
 int kvm_apic_local_deliver(struct kvm_lapic *apic, int lvt_type)
 {
 	u32 reg = kvm_lapic_get_reg(apic, lvt_type);
@@ -2599,6 +2629,10 @@ static void apic_sync_pv_eoi_to_guest(struct kvm_vcpu *vcpu,
 	pv_eoi_set_pending(apic->vcpu);
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/x86.c|8145| <<vcpu_enter_guest>> kvm_lapic_sync_to_vapic(vcpu);
+ */
 void kvm_lapic_sync_to_vapic(struct kvm_vcpu *vcpu)
 {
 	u32 data, tpr;
diff --git a/arch/x86/kvm/lapic.h b/arch/x86/kvm/lapic.h
index 39925afdfcdc..2c6ab1d4ac5f 100644
--- a/arch/x86/kvm/lapic.h
+++ b/arch/x86/kvm/lapic.h
@@ -159,19 +159,62 @@ static inline void kvm_lapic_set_reg(struct kvm_lapic *apic, int reg_off, u32 va
 	*((u32 *) (apic->regs + reg_off)) = val;
 }
 
+/*
+ * 在以下使用kvm_no_apic_vcpu:
+ *   - arch/x86/kvm/lapic.h|166| <<lapic_in_kernel>> if (static_key_false(&kvm_no_apic_vcpu))
+ *   - arch/x86/kvm/x86.c|9438| <<kvm_arch_vcpu_init>> static_key_slow_inc(&kvm_no_apic_vcpu);
+ *   - arch/x86/kvm/x86.c|9497| <<kvm_arch_vcpu_uninit>> static_key_slow_dec(&kvm_no_apic_vcpu);
+ */
 extern struct static_key kvm_no_apic_vcpu;
 
 static inline bool lapic_in_kernel(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 9419 int kvm_arch_vcpu_init(struct kvm_vcpu *vcpu)
+	 * ... ...
+	 * 9443         if (irqchip_in_kernel(vcpu->kvm)) {
+	 * 9444                 vcpu->arch.apicv_active = kvm_x86_ops->get_enable_apicv(vcpu->kvm);
+	 * 9445                 r = kvm_create_lapic(vcpu, lapic_timer_advance_ns);
+	 * 9446                 if (r < 0)
+	 * 9447                         goto fail_mmu_destroy;
+	 * 9448         } else
+	 * 9449                 static_key_slow_inc(&kvm_no_apic_vcpu);
+	 *
+	 * 在以下使用kvm_no_apic_vcpu:
+	 *   - arch/x86/kvm/lapic.h|166| <<lapic_in_kernel>> if (static_key_false(&kvm_no_apic_vcpu))
+	 *   - arch/x86/kvm/x86.c|9438| <<kvm_arch_vcpu_init>> static_key_slow_inc(&kvm_no_apic_vcpu);
+	 *   - arch/x86/kvm/x86.c|9497| <<kvm_arch_vcpu_uninit>> static_key_slow_dec(&kvm_no_apic_vcpu);
+	 *
+	 * 如果kvm_no_apic_vcpu是false, 说明kvm_arch_vcpu_init()->kvm_create_lapic()被调用了
+	 * 初始化了vcpu->arch.apic
+	 */
 	if (static_key_false(&kvm_no_apic_vcpu))
 		return vcpu->arch.apic;
 	return true;
 }
 
+/*
+ * 在以下使用apic_hw_disabled:
+ *   - arch/x86/kvm/lapic.c|2098| <<kvm_free_lapic>> static_key_slow_dec_deferred(&apic_hw_disabled);
+ *   - arch/x86/kvm/lapic.c|2175| <<kvm_lapic_set_base>> static_key_slow_dec_deferred(&apic_hw_disabled);
+ *   - arch/x86/kvm/lapic.c|2177| <<kvm_lapic_set_base>> static_key_slow_inc(&apic_hw_disabled.key);
+ *   - arch/x86/kvm/lapic.c|2795| <<kvm_lapic_init>> jump_label_rate_limit(&apic_hw_disabled, HZ);
+ *   - arch/x86/kvm/lapic.c|2801| <<kvm_lapic_exit>> static_key_deferred_flush(&apic_hw_disabled);
+ *   - arch/x86/kvm/lapic.h|175| <<kvm_apic_hw_enabled>> if (static_key_false(&apic_hw_disabled.key))
+ */
 extern struct static_key_deferred apic_hw_disabled;
 
 static inline int kvm_apic_hw_enabled(struct kvm_lapic *apic)
 {
+	/*
+	 * 在以下使用apic_hw_disabled:
+	 *   - arch/x86/kvm/lapic.c|2098| <<kvm_free_lapic>> static_key_slow_dec_deferred(&apic_hw_disabled);
+	 *   - arch/x86/kvm/lapic.c|2175| <<kvm_lapic_set_base>> static_key_slow_dec_deferred(&apic_hw_disabled);
+	 *   - arch/x86/kvm/lapic.c|2177| <<kvm_lapic_set_base>> static_key_slow_inc(&apic_hw_disabled.key);
+	 *   - arch/x86/kvm/lapic.c|2795| <<kvm_lapic_init>> jump_label_rate_limit(&apic_hw_disabled, HZ);
+	 *   - arch/x86/kvm/lapic.c|2801| <<kvm_lapic_exit>> static_key_deferred_flush(&apic_hw_disabled);
+	 *   - arch/x86/kvm/lapic.h|175| <<kvm_apic_hw_enabled>> if (static_key_false(&apic_hw_disabled.key))
+	 */
 	if (static_key_false(&apic_hw_disabled.key))
 		return apic->vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE;
 	return MSR_IA32_APICBASE_ENABLE;
@@ -186,8 +229,29 @@ static inline bool kvm_apic_sw_enabled(struct kvm_lapic *apic)
 	return true;
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/irq_comm.c|67| <<kvm_irq_delivery_to_apic>> if (!kvm_apic_present(vcpu))
+ *   - arch/x86/kvm/irq_comm.c|334| <<kvm_intr_is_single_vcpu>> if (!kvm_apic_present(vcpu))
+ *   - arch/x86/kvm/lapic.c|189| <<recalculate_apic_map>> if (kvm_apic_present(vcpu))
+ *   - arch/x86/kvm/lapic.c|209| <<recalculate_apic_map>> if (!kvm_apic_present(vcpu))
+ *   - arch/x86/kvm/lapic.c|1168| <<kvm_bitmap_or_dest_vcpus>> if (!kvm_apic_present(vcpu))
+ *   - arch/x86/kvm/lapic.h|217| <<kvm_lapic_enabled>> return kvm_apic_present(vcpu) && kvm_apic_sw_enabled(vcpu->arch.apic);
+ *   - arch/x86/kvm/x86.c|7912| <<vcpu_scan_ioapic>> if (!kvm_apic_present(vcpu))
+ */
 static inline bool kvm_apic_present(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 9419 int kvm_arch_vcpu_init(struct kvm_vcpu *vcpu)
+	 * ... ...
+	 * 9443         if (irqchip_in_kernel(vcpu->kvm)) {
+	 * 9444                 vcpu->arch.apicv_active = kvm_x86_ops->get_enable_apicv(vcpu->kvm);
+	 * 9445                 r = kvm_create_lapic(vcpu, lapic_timer_advance_ns);
+	 * 9446                 if (r < 0)
+	 * 9447                         goto fail_mmu_destroy;
+	 * 9448         } else
+	 * 9449                 static_key_slow_inc(&kvm_no_apic_vcpu);
+	 */
 	return lapic_in_kernel(vcpu) && kvm_apic_hw_enabled(vcpu->arch.apic);
 }
 
diff --git a/arch/x86/kvm/mmu.h b/arch/x86/kvm/mmu.h
index d55674f44a18..51db11a6e926 100644
--- a/arch/x86/kvm/mmu.h
+++ b/arch/x86/kvm/mmu.h
@@ -73,6 +73,12 @@ static inline unsigned long kvm_mmu_available_pages(struct kvm *kvm)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/vmx/nested.c|5234| <<nested_vmx_eptp_switching>> kvm_mmu_reload(vcpu);
+ *   - arch/x86/kvm/x86.c|8142| <<vcpu_enter_guest>> r = kvm_mmu_reload(vcpu);
+ *   - arch/x86/kvm/x86.c|10009| <<kvm_arch_async_page_ready>> r = kvm_mmu_reload(vcpu);
+ */
 static inline int kvm_mmu_reload(struct kvm_vcpu *vcpu)
 {
 	if (likely(vcpu->arch.mmu->root_hpa != INVALID_PAGE))
diff --git a/arch/x86/kvm/mmu/mmu.c b/arch/x86/kvm/mmu/mmu.c
index 6f92b40d798c..6d0b4d6216a3 100644
--- a/arch/x86/kvm/mmu/mmu.c
+++ b/arch/x86/kvm/mmu/mmu.c
@@ -5257,6 +5257,11 @@ void kvm_mmu_reset_context(struct kvm_vcpu *vcpu)
 }
 EXPORT_SYMBOL_GPL(kvm_mmu_reset_context);
 
+/*
+ * called by:
+ *   - arch/x86/kvm/mmu.h|81| <<kvm_mmu_reload>> return kvm_mmu_load(vcpu);
+ *   - arch/x86/kvm/svm.c|3442| <<nested_svm_vmexit>> kvm_mmu_load(&svm->vcpu);
+ */
 int kvm_mmu_load(struct kvm_vcpu *vcpu)
 {
 	int r;
diff --git a/arch/x86/kvm/vmx/vmx.c b/arch/x86/kvm/vmx/vmx.c
index e3394c839dea..9e834fc0b8f4 100644
--- a/arch/x86/kvm/vmx/vmx.c
+++ b/arch/x86/kvm/vmx/vmx.c
@@ -2622,6 +2622,12 @@ static void free_kvm_area(void)
 	}
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/vmx/vmx.c|7747| <<hardware_setup>> r = alloc_kvm_area();
+ *
+ * 分配vmxon_region
+ */
 static __init int alloc_kvm_area(void)
 {
 	int cpu;
@@ -6672,6 +6678,10 @@ static void vmx_free_vcpu(struct kvm_vcpu *vcpu)
 	kmem_cache_free(kvm_vcpu_cache, vmx);
 }
 
+/*
+ * x86下的调用:
+ *   - arch/x86/kvm/x86.c|9132| <<kvm_arch_vcpu_create>> vcpu = kvm_x86_ops->vcpu_create(kvm, id);
+ */
 static struct kvm_vcpu *vmx_create_vcpu(struct kvm *kvm, unsigned int id)
 {
 	int err;
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index cf917139de6b..61bc14fdeebf 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -4908,6 +4908,18 @@ long kvm_arch_vm_ioctl(struct file *filp,
 		}
 		/* Write kvm->irq_routing before enabling irqchip_in_kernel. */
 		smp_wmb();
+		/*
+		 * 在以下设置irqchip_mode:
+		 *   - arch/x86/kvm/x86.c|4790| <<kvm_vm_ioctl_enable_cap>> kvm->arch.irqchip_mode = KVM_IRQCHIP_SPLIT;
+		 *   - arch/x86/kvm/x86.c|4911| <<kvm_arch_vm_ioctl>> kvm->arch.irqchip_mode = KVM_IRQCHIP_KERNEL;
+		 *
+		 * 在以下使用irqchip_mode:
+		 *   - arch/x86/kvm/ioapic.h|111| <<ioapic_in_kernel>> int mode = kvm->arch.irqchip_mode;
+		 *   - arch/x86/kvm/irq.h|71| <<pic_in_kernel>> int mode = kvm->arch.irqchip_mode;
+		 *   - arch/x86/kvm/irq.h|80| <<irqchip_split>> int mode = kvm->arch.irqchip_mode;
+		 *   - arch/x86/kvm/irq.h|89| <<irqchip_kernel>> int mode = kvm->arch.irqchip_mode;
+		 *   - arch/x86/kvm/irq.h|98| <<irqchip_in_kernel>> int mode = kvm->arch.irqchip_mode;
+		 */
 		kvm->arch.irqchip_mode = KVM_IRQCHIP_KERNEL;
 	create_irqchip_unlock:
 		mutex_unlock(&kvm->lock);
@@ -7902,11 +7914,34 @@ void kvm_make_scan_ioapic_request_mask(struct kvm *kvm,
 	free_cpumask_var(cpus);
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/ioapic.c|267| <<kvm_arch_post_irq_ack_notifier_list_update>> kvm_make_scan_ioapic_request(kvm);
+ *   - arch/x86/kvm/ioapic.c|353| <<ioapic_write_indirect>> kvm_make_scan_ioapic_request(ioapic->kvm);
+ *   - arch/x86/kvm/ioapic.c|694| <<kvm_set_ioapic>> kvm_make_scan_ioapic_request(kvm);
+ *   - arch/x86/kvm/irq_comm.c|394| <<kvm_arch_post_irq_routing_update>> kvm_make_scan_ioapic_request(kvm);
+ *   - arch/x86/kvm/lapic.c|256| <<recalculate_apic_map>> kvm_make_scan_ioapic_request(kvm);
+ */
 void kvm_make_scan_ioapic_request(struct kvm *kvm)
 {
 	kvm_make_all_cpus_request(kvm, KVM_REQ_SCAN_IOAPIC);
 }
 
+/*
+ * [0] vcpu_scan_ioapic
+ * [0] kvm_arch_vcpu_ioctl_run
+ * [0] kvm_vcpu_ioctl
+ * [0] do_vfs_ioctl
+ * [0] ksys_ioctl
+ * [0] __x64_sys_ioctl
+ * [0] do_syscall_64
+ * [0] entry_SYSCALL_64_after_hwframe
+ *
+ * called by:
+ *   - arch/x86/kvm/x86.c|8075| <<vcpu_enter_guest>> vcpu_scan_ioapic(vcpu);
+ * 8074                 if (kvm_check_request(KVM_REQ_SCAN_IOAPIC, vcpu))
+ * 8075                         vcpu_scan_ioapic(vcpu);
+ */
 static void vcpu_scan_ioapic(struct kvm_vcpu *vcpu)
 {
 	if (!kvm_apic_present(vcpu))
@@ -8000,6 +8035,13 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 
 	bool req_immediate_exit = false;
 
+	/*
+	 * x86下调用的例子:
+	 *   - arch/x86/kvm/x86.c|8003| <<vcpu_enter_guest>> if (kvm_request_pending(vcpu)) {
+	 *   - arch/x86/kvm/x86.c|8182| <<vcpu_enter_guest>> if (vcpu->mode == EXITING_GUEST_MODE || kvm_request_pending(vcpu)
+	 *
+	 * 返回vcpu->requests (u64)
+	 */
 	if (kvm_request_pending(vcpu)) {
 		if (kvm_check_request(KVM_REQ_GET_VMCS12_PAGES, vcpu)) {
 			if (unlikely(!kvm_x86_ops->get_vmcs12_pages(vcpu))) {
@@ -8139,6 +8181,12 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 		}
 	}
 
+	/*
+	 * called by:
+	 *   - arch/x86/kvm/vmx/nested.c|5234| <<nested_vmx_eptp_switching>> kvm_mmu_reload(vcpu);
+	 *   - arch/x86/kvm/x86.c|8142| <<vcpu_enter_guest>> r = kvm_mmu_reload(vcpu);
+	 *   - arch/x86/kvm/x86.c|10009| <<kvm_arch_async_page_ready>> r = kvm_mmu_reload(vcpu);
+	 */
 	r = kvm_mmu_reload(vcpu);
 	if (unlikely(r)) {
 		goto cancel_injection;
@@ -9092,6 +9140,10 @@ void kvm_arch_vcpu_free(struct kvm_vcpu *vcpu)
 	free_cpumask_var(wbinvd_dirty_mask);
 }
 
+/*
+ * called by:
+ *   - virt/kvm/kvm_main.c|2734| <<kvm_vm_ioctl_create_vcpu>> vcpu = kvm_arch_vcpu_create(kvm, id);
+ */
 struct kvm_vcpu *kvm_arch_vcpu_create(struct kvm *kvm,
 						unsigned int id)
 {
@@ -9389,9 +9441,20 @@ bool kvm_vcpu_is_bsp(struct kvm_vcpu *vcpu)
 	return (vcpu->arch.apic_base & MSR_IA32_APICBASE_BSP) != 0;
 }
 
+/*
+ * 在以下使用kvm_no_apic_vcpu:
+ *   - arch/x86/kvm/lapic.h|166| <<lapic_in_kernel>> if (static_key_false(&kvm_no_apic_vcpu))
+ *   - arch/x86/kvm/x86.c|9438| <<kvm_arch_vcpu_init>> static_key_slow_inc(&kvm_no_apic_vcpu);
+ *   - arch/x86/kvm/x86.c|9497| <<kvm_arch_vcpu_uninit>> static_key_slow_dec(&kvm_no_apic_vcpu);
+ */
 struct static_key kvm_no_apic_vcpu __read_mostly;
 EXPORT_SYMBOL_GPL(kvm_no_apic_vcpu);
 
+/*
+ * mips, powerpc, s390和arm也都有对应的实现
+ * called by:
+ *   - virt/kvm/kvm_main.c|353| <<kvm_vcpu_init>> r = kvm_arch_vcpu_init(vcpu);
+ */
 int kvm_arch_vcpu_init(struct kvm_vcpu *vcpu)
 {
 	struct page *page;
diff --git a/drivers/cpuidle/driver.c b/drivers/cpuidle/driver.c
index ce6a5f80fb83..56ddf3e8c720 100644
--- a/drivers/cpuidle/driver.c
+++ b/drivers/cpuidle/driver.c
@@ -262,6 +262,15 @@ static void __cpuidle_unregister_driver(struct cpuidle_driver *drv)
  * Returns 0 on success, a negative error code (returned by
  * __cpuidle_register_driver()) otherwise.
  */
+/*
+ * called by:
+ *   - arch/x86/kernel/apm_32.c|2378| <<apm_init>> if (!cpuidle_register_driver(&apm_idle_driver))
+ *   - drivers/acpi/processor_idle.c|1458| <<acpi_processor_power_init>> retval = cpuidle_register_driver(&acpi_idle_driver);
+ *   - drivers/cpuidle/cpuidle-cps.c|152| <<cps_cpuidle_init>> err = cpuidle_register_driver(&cps_driver);
+ *   - drivers/cpuidle/cpuidle-haltpoll.c|108| <<haltpoll_init>> ret = cpuidle_register_driver(drv);
+ *   - drivers/cpuidle/cpuidle.c|699| <<cpuidle_register>> ret = cpuidle_register_driver(drv);
+ *   - drivers/idle/intel_idle.c|1445| <<intel_idle_init>> retval = cpuidle_register_driver(&intel_idle_driver);
+ */
 int cpuidle_register_driver(struct cpuidle_driver *drv)
 {
 	struct cpuidle_governor *gov;
diff --git a/drivers/vfio/pci/vfio_pci.c b/drivers/vfio/pci/vfio_pci.c
index 379a02c36e37..4541d9813197 100644
--- a/drivers/vfio/pci/vfio_pci.c
+++ b/drivers/vfio/pci/vfio_pci.c
@@ -260,6 +260,10 @@ int vfio_pci_set_power_state(struct vfio_pci_device *vdev, pci_power_t state)
 	return ret;
 }
 
+/*
+ * called by:
+ *   - drivers/vfio/pci/vfio_pci.c|496| <<vfio_pci_open>> ret = vfio_pci_enable(vdev);
+ */
 static int vfio_pci_enable(struct vfio_pci_device *vdev)
 {
 	struct pci_dev *pdev = vdev->pdev;
@@ -466,6 +470,8 @@ static void vfio_pci_disable(struct vfio_pci_device *vdev)
 		vfio_pci_set_power_state(vdev, PCI_D3hot);
 }
 
+/*struct vfio_device_ops vfio_pci_ops.release = vfio_pci_release()
+ */
 static void vfio_pci_release(void *device_data)
 {
 	struct vfio_pci_device *vdev = device_data;
@@ -482,6 +488,9 @@ static void vfio_pci_release(void *device_data)
 	module_put(THIS_MODULE);
 }
 
+/*
+ * struct vfio_device_ops vfio_pci_ops.open = vfio_pci_open()
+ */
 static int vfio_pci_open(void *device_data)
 {
 	struct vfio_pci_device *vdev = device_data;
@@ -691,6 +700,9 @@ int vfio_pci_register_dev_region(struct vfio_pci_device *vdev,
 	return 0;
 }
 
+/*
+ * struct vfio_device_ops vfio_pci_ops.ioctl = vfio_pci_ioctl()
+ */
 static long vfio_pci_ioctl(void *device_data,
 			   unsigned int cmd, unsigned long arg)
 {
@@ -1145,6 +1157,11 @@ static long vfio_pci_ioctl(void *device_data,
 	return -ENOTTY;
 }
 
+/*
+ * called by:
+ *   - drivers/vfio/pci/vfio_pci.c|1186| <<vfio_pci_read>> return vfio_pci_rw(device_data, buf, count, ppos, false);
+ *   - drivers/vfio/pci/vfio_pci.c|1195| <<vfio_pci_write>> return vfio_pci_rw(device_data, (char __user *)buf, count, ppos, true);
+ */
 static ssize_t vfio_pci_rw(void *device_data, char __user *buf,
 			   size_t count, loff_t *ppos, bool iswrite)
 {
@@ -1177,6 +1194,9 @@ static ssize_t vfio_pci_rw(void *device_data, char __user *buf,
 	return -EINVAL;
 }
 
+/*
+ * struct vfio_device_ops vfio_pci_ops.read = vfio_pci_read()
+ */
 static ssize_t vfio_pci_read(void *device_data, char __user *buf,
 			     size_t count, loff_t *ppos)
 {
@@ -1186,6 +1206,9 @@ static ssize_t vfio_pci_read(void *device_data, char __user *buf,
 	return vfio_pci_rw(device_data, buf, count, ppos, false);
 }
 
+/*
+ * struct vfio_device_ops vfio_pci_ops.write = vfio_pci_write()
+ */
 static ssize_t vfio_pci_write(void *device_data, const char __user *buf,
 			      size_t count, loff_t *ppos)
 {
@@ -1195,6 +1218,9 @@ static ssize_t vfio_pci_write(void *device_data, const char __user *buf,
 	return vfio_pci_rw(device_data, (char __user *)buf, count, ppos, true);
 }
 
+/*
+ * struct vfio_device_ops vfio_pci_ops.mmap = vfio_pci_mmap()
+ */
 static int vfio_pci_mmap(void *device_data, struct vm_area_struct *vma)
 {
 	struct vfio_pci_device *vdev = device_data;
@@ -1253,10 +1279,25 @@ static int vfio_pci_mmap(void *device_data, struct vm_area_struct *vma)
 	vma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);
 	vma->vm_pgoff = (pci_resource_start(pdev, index) >> PAGE_SHIFT) + pgoff;
 
+	/*
+	 * remap_pfn_range - remap kernel memory to userspace
+	 * @vma: user vma to map to
+	 * @addr: target user address to start at
+	 * @pfn: physical address of kernel memory
+	 * @size: size of map area
+	 * @prot: page protection flags for this mapping
+	 *
+	 * Note: this is only safe if the mm semaphore is held when called.
+	 *
+	 * Return: %0 on success, negative error code otherwise.
+	 */
 	return remap_pfn_range(vma, vma->vm_start, vma->vm_pgoff,
 			       req_len, vma->vm_page_prot);
 }
 
+/*
+ * struct vfio_device_ops vfio_pci_ops.request = vfio_pci_request()
+ */
 static void vfio_pci_request(void *device_data, unsigned int count)
 {
 	struct vfio_pci_device *vdev = device_data;
@@ -1278,6 +1319,10 @@ static void vfio_pci_request(void *device_data, unsigned int count)
 	mutex_unlock(&vdev->igate);
 }
 
+/*
+ * 在以下使用vfio_pci_ops:
+ *   - drivers/vfio/pci/vfio_pci.c|1334| <<vfio_pci_probe>> ret = vfio_add_group_dev(&pdev->dev, &vfio_pci_ops, vdev);
+ */
 static const struct vfio_device_ops vfio_pci_ops = {
 	.name		= "vfio-pci",
 	.open		= vfio_pci_open,
diff --git a/drivers/vfio/pci/vfio_pci_config.c b/drivers/vfio/pci/vfio_pci_config.c
index 90c0b80f8acf..2472e638796b 100644
--- a/drivers/vfio/pci/vfio_pci_config.c
+++ b/drivers/vfio/pci/vfio_pci_config.c
@@ -1831,6 +1831,10 @@ static ssize_t vfio_config_do_rw(struct vfio_pci_device *vdev, char __user *buf,
 	return ret;
 }
 
+/*
+ * called by (只在vfio_pci_rw()处理VFIO_PCI_CONFIG_REGION_INDEX):
+ *   - drivers/vfio/pci/vfio_pci.c|1164| <<vfio_pci_rw>> return vfio_pci_config_rw(vdev, buf, count, ppos, iswrite);
+ */
 ssize_t vfio_pci_config_rw(struct vfio_pci_device *vdev, char __user *buf,
 			   size_t count, loff_t *ppos, bool iswrite)
 {
diff --git a/drivers/vfio/pci/vfio_pci_intrs.c b/drivers/vfio/pci/vfio_pci_intrs.c
index 2056f3f85f59..980c3caad1d9 100644
--- a/drivers/vfio/pci/vfio_pci_intrs.c
+++ b/drivers/vfio/pci/vfio_pci_intrs.c
@@ -25,6 +25,14 @@
 /*
  * INTx
  */
+/*
+ * called by:
+ *   - drivers/vfio/pci/vfio_pci_intrs.c|113| <<vfio_pci_intx_unmask>> vfio_send_intx_eventfd(vdev, NULL);
+ *   - drivers/vfio/pci/vfio_pci_intrs.c|137| <<vfio_intx_handler>> vfio_send_intx_eventfd(vdev, NULL);
+ *   - drivers/vfio/pci/vfio_pci_intrs.c|441| <<vfio_pci_set_intx_unmask>> vfio_send_intx_eventfd, NULL,
+ *   - drivers/vfio/pci/vfio_pci_intrs.c|504| <<vfio_pci_set_intx_trigger>> vfio_send_intx_eventfd(vdev, NULL);
+ *   - drivers/vfio/pci/vfio_pci_intrs.c|508| <<vfio_pci_set_intx_trigger>> vfio_send_intx_eventfd(vdev, NULL);
+ */
 static void vfio_send_intx_eventfd(void *opaque, void *unused)
 {
 	struct vfio_pci_device *vdev = opaque;
@@ -113,6 +121,10 @@ void vfio_pci_intx_unmask(struct vfio_pci_device *vdev)
 		vfio_send_intx_eventfd(vdev, NULL);
 }
 
+/*
+ * 在以下使用vfio_intx_handler():
+ *   - drivers/vfio/pci/vfio_pci_intrs.c|205| <<vfio_intx_set_signal>> ret = request_irq(pdev->irq, vfio_intx_handler,
+ */
 static irqreturn_t vfio_intx_handler(int irq, void *dev_id)
 {
 	struct vfio_pci_device *vdev = dev_id;
@@ -168,6 +180,12 @@ static int vfio_intx_enable(struct vfio_pci_device *vdev)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vfio/pci/vfio_pci_intrs.c|230| <<vfio_intx_disable>> vfio_intx_set_signal(vdev, -1);
+ *   - drivers/vfio/pci/vfio_pci_intrs.c|487| <<vfio_pci_set_intx_trigger>> return vfio_intx_set_signal(vdev, fd);
+ *   - drivers/vfio/pci/vfio_pci_intrs.c|493| <<vfio_pci_set_intx_trigger>> ret = vfio_intx_set_signal(vdev, fd);
+ */
 static int vfio_intx_set_signal(struct vfio_pci_device *vdev, int fd)
 {
 	struct pci_dev *pdev = vdev->pdev;
@@ -236,6 +254,10 @@ static void vfio_intx_disable(struct vfio_pci_device *vdev)
 /*
  * MSI/MSI-X
  */
+/*
+ * 在以下使用vfio_msihandler:
+ *   - drivers/vfio/pci/vfio_pci_intrs.c|333| <<vfio_msi_set_vector_signal>> ret = request_irq(irq, vfio_msihandler, 0,
+ */
 static irqreturn_t vfio_msihandler(int irq, void *arg)
 {
 	struct eventfd_ctx *trigger = arg;
@@ -244,6 +266,10 @@ static irqreturn_t vfio_msihandler(int irq, void *arg)
 	return IRQ_HANDLED;
 }
 
+/*
+ * called by:
+ *   - drivers/vfio/pci/vfio_pci_intrs.c|532| <<vfio_pci_set_msi_trigger>> ret = vfio_msi_enable(vdev, start + count, msix);
+ */
 static int vfio_msi_enable(struct vfio_pci_device *vdev, int nvec, bool msix)
 {
 	struct pci_dev *pdev = vdev->pdev;
@@ -281,6 +307,11 @@ static int vfio_msi_enable(struct vfio_pci_device *vdev, int nvec, bool msix)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vfio/pci/vfio_pci_intrs.c|364| <<vfio_msi_set_block>> ret = vfio_msi_set_vector_signal(vdev, j, fd, msix);
+ *   - drivers/vfio/pci/vfio_pci_intrs.c|369| <<vfio_msi_set_block>> vfio_msi_set_vector_signal(vdev, j, -1, msix);
+ */
 static int vfio_msi_set_vector_signal(struct vfio_pci_device *vdev,
 				      int vector, int fd, bool msix)
 {
@@ -351,6 +382,12 @@ static int vfio_msi_set_vector_signal(struct vfio_pci_device *vdev,
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vfio/pci/vfio_pci_intrs.c|385| <<vfio_msi_disable>> vfio_msi_set_block(vdev, 0, vdev->num_ctx, NULL, msix);
+ *   - drivers/vfio/pci/vfio_pci_intrs.c|514| <<vfio_pci_set_msi_trigger>> return vfio_msi_set_block(vdev, start, count,
+ *   - drivers/vfio/pci/vfio_pci_intrs.c|521| <<vfio_pci_set_msi_trigger>> ret = vfio_msi_set_block(vdev, start, count, fds, msix);
+ */
 static int vfio_msi_set_block(struct vfio_pci_device *vdev, unsigned start,
 			      unsigned count, int32_t *fds, bool msix)
 {
@@ -428,6 +465,10 @@ static int vfio_pci_set_intx_unmask(struct vfio_pci_device *vdev,
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vfio/pci/vfio_pci_intrs.c|663| <<vfio_pci_set_irqs_ioctl>> func = vfio_pci_set_intx_trigger;
+ */
 static int vfio_pci_set_intx_mask(struct vfio_pci_device *vdev,
 				  unsigned index, unsigned start,
 				  unsigned count, uint32_t flags, void *data)
@@ -491,6 +532,10 @@ static int vfio_pci_set_intx_trigger(struct vfio_pci_device *vdev,
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vfio/pci/vfio_pci_intrs.c|667| <<vfio_pci_set_irqs_ioctl>> func = vfio_pci_set_msi_trigger;
+ */
 static int vfio_pci_set_msi_trigger(struct vfio_pci_device *vdev,
 				    unsigned index, unsigned start,
 				    unsigned count, uint32_t flags, void *data)
diff --git a/drivers/vfio/pci/vfio_pci_private.h b/drivers/vfio/pci/vfio_pci_private.h
index 8a2c7607d513..8e5928eb42ef 100644
--- a/drivers/vfio/pci/vfio_pci_private.h
+++ b/drivers/vfio/pci/vfio_pci_private.h
@@ -86,8 +86,36 @@ struct vfio_pci_reflck {
 
 struct vfio_pci_device {
 	struct pci_dev		*pdev;
+	/*
+	 * 在以下使用barmap[PCI_STD_NUM_BARS]:
+	 *   - drivers/vfio/pci/vfio_pci.c|410| <<vfio_pci_disable>> if (!vdev->barmap[bar])
+	 *   - drivers/vfio/pci/vfio_pci.c|412| <<vfio_pci_disable>> pci_iounmap(pdev, vdev->barmap[bar]);
+	 *   - drivers/vfio/pci/vfio_pci.c|414| <<vfio_pci_disable>> vdev->barmap[bar] = NULL;
+	 *   - drivers/vfio/pci/vfio_pci.c|1254| <<vfio_pci_mmap>> if (!vdev->barmap[index]) {
+	 *   - drivers/vfio/pci/vfio_pci.c|1260| <<vfio_pci_mmap>> vdev->barmap[index] = pci_iomap(pdev, index, 0);
+	 *   - drivers/vfio/pci/vfio_pci.c|1261| <<vfio_pci_mmap>> if (!vdev->barmap[index]) {
+	 *   - drivers/vfio/pci/vfio_pci_rdwr.c|138| <<vfio_pci_setup_barmap>> if (vdev->barmap[bar])
+	 *   - drivers/vfio/pci/vfio_pci_rdwr.c|151| <<vfio_pci_setup_barmap>> vdev->barmap[bar] = io;
+	 *   - drivers/vfio/pci/vfio_pci_rdwr.c|200| <<vfio_pci_bar_rw>> io = vdev->barmap[bar];
+	 *   - drivers/vfio/pci/vfio_pci_rdwr.c|370| <<vfio_pci_ioeventfd>> ioeventfd->addr = vdev->barmap[bar] + pos;
+	 */
 	void __iomem		*barmap[PCI_STD_NUM_BARS];
 	bool			bar_mmap_supported[PCI_STD_NUM_BARS];
+	/*
+	 * 在以下使用pci_config_map:
+	 *   - drivers/vfio/pci/vfio_pci_config.c|1045| <<vfio_find_cap_start>> cap = vdev->pci_config_map[pos];
+	 *   - drivers/vfio/pci/vfio_pci_config.c|1051| <<vfio_find_cap_start>> while (pos - 1 >= base && vdev->pci_config_map[pos - 1] == cap)
+	 *   - drivers/vfio/pci/vfio_pci_config.c|1430| <<vfio_cap_init>> u8 *map = vdev->pci_config_map;
+	 *   - drivers/vfio/pci/vfio_pci_config.c|1515| <<vfio_ecap_init>> u8 *map = vdev->pci_config_map;
+	 *   - drivers/vfio/pci/vfio_pci_config.c|1654| <<vfio_config_init>> vdev->pci_config_map = map;
+	 *   - drivers/vfio/pci/vfio_pci_config.c|1719| <<vfio_config_init>> vdev->pci_config_map = NULL;
+	 *   - drivers/vfio/pci/vfio_pci_config.c|1729| <<vfio_config_free>> kfree(vdev->pci_config_map);
+	 *   - drivers/vfio/pci/vfio_pci_config.c|1730| <<vfio_config_free>> vdev->pci_config_map = NULL;
+	 *   - drivers/vfio/pci/vfio_pci_config.c|1742| <<vfio_pci_cap_remaining_dword>> u8 cap = vdev->pci_config_map[pos];
+	 *   - drivers/vfio/pci/vfio_pci_config.c|1745| <<vfio_pci_cap_remaining_dword>> for (i = 1; (pos + i) % 4 && vdev->pci_config_map[pos + i] == cap; i++)
+	 *   - drivers/vfio/pci/vfio_pci_config.c|1779| <<vfio_config_do_rw>> cap_id = vdev->pci_config_map[*ppos];
+	 *   - drivers/vfio/pci/vfio_pci_igd.c|104| <<vfio_pci_igd_opregion_init>> memset(vdev->pci_config_map + OPREGION_PCI_ADDR,
+	 */
 	u8			*pci_config_map;
 	u8			*vconfig;
 	struct perm_bits	*msi_perm;
@@ -99,6 +127,14 @@ struct vfio_pci_device {
 	int			num_regions;
 	struct vfio_pci_region	*region;
 	u8			msi_qmax;
+	/*
+	 * 在以下使用msix_bar:
+	 *   - drivers/vfio/pci/vfio_pci.c|327| <<vfio_pci_enable>> vdev->msix_bar = table & PCI_MSIX_TABLE_BIR;
+	 *   - drivers/vfio/pci/vfio_pci.c|331| <<vfio_pci_enable>> vdev->msix_bar = 0xFF;
+	 *   - drivers/vfio/pci/vfio_pci.c|762| <<vfio_pci_ioctl>> if (info.index == vdev->msix_bar) {
+	 *   - drivers/vfio/pci/vfio_pci_rdwr.c|203| <<vfio_pci_bar_rw>> if (bar == vdev->msix_bar) {
+	 *   - drivers/vfio/pci/vfio_pci_rdwr.c|322| <<vfio_pci_ioeventfd>> if (bar == vdev->msix_bar &&
+	 */
 	u8			msix_bar;
 	u16			msix_size;
 	u32			msix_offset;
@@ -121,6 +157,13 @@ struct vfio_pci_device {
 	struct eventfd_ctx	*req_trigger;
 	struct list_head	dummy_resources_list;
 	struct mutex		ioeventfds_lock;
+	/*
+	 * 在以下使用ioeventfds_list:
+	 *   - drivers/vfio/pci/vfio_pci.c|390| <<vfio_pci_disable>> &vdev->ioeventfds_list, next) {
+	 *   - drivers/vfio/pci/vfio_pci.c|1351| <<vfio_pci_probe>> INIT_LIST_HEAD(&vdev->ioeventfds_list);
+	 *   - drivers/vfio/pci/vfio_pci_rdwr.c|338| <<vfio_pci_ioeventfd>> list_for_each_entry(ioeventfd, &vdev->ioeventfds_list, next) {
+	 *   - drivers/vfio/pci/vfio_pci_rdwr.c|383| <<vfio_pci_ioeventfd>> list_add(&ioeventfd->next, &vdev->ioeventfds_list);
+	 */
 	struct list_head	ioeventfds_list;
 };
 
diff --git a/drivers/vfio/pci/vfio_pci_rdwr.c b/drivers/vfio/pci/vfio_pci_rdwr.c
index 0120d8324a40..e7d9d83bdbd1 100644
--- a/drivers/vfio/pci/vfio_pci_rdwr.c
+++ b/drivers/vfio/pci/vfio_pci_rdwr.c
@@ -43,6 +43,11 @@
  * reads with -1.  This is intended for handling MSI-X vector tables and
  * leftover space for ROM BARs.
  */
+/*
+ * called by:
+ *   - drivers/vfio/pci/vfio_pci_rdwr.c|208| <<vfio_pci_bar_rw>> done = do_io_rw(io, buf, pos, count, x_start, x_end, iswrite);
+ *   - drivers/vfio/pci/vfio_pci_rdwr.c|270| <<vfio_pci_vga_rw>> done = do_io_rw(iomem, buf, off, count, 0, 0, iswrite);
+ */
 static ssize_t do_io_rw(void __iomem *io, char __user *buf,
 			loff_t off, size_t count, size_t x_start,
 			size_t x_end, bool iswrite)
@@ -129,6 +134,11 @@ static ssize_t do_io_rw(void __iomem *io, char __user *buf,
 	return done;
 }
 
+/*
+ * called by:
+ *   - drivers/vfio/pci/vfio_pci_rdwr.c|196| <<vfio_pci_bar_rw>> int ret = vfio_pci_setup_barmap(vdev, bar);
+ *   - drivers/vfio/pci/vfio_pci_rdwr.c|336| <<vfio_pci_ioeventfd>> ret = vfio_pci_setup_barmap(vdev, bar);
+ */
 static int vfio_pci_setup_barmap(struct vfio_pci_device *vdev, int bar)
 {
 	struct pci_dev *pdev = vdev->pdev;
@@ -153,6 +163,11 @@ static int vfio_pci_setup_barmap(struct vfio_pci_device *vdev, int bar)
 	return 0;
 }
 
+/*
+ * 处理VFIO_PCI_ROM_REGION_INDEX或者VFIO_PCI_BAR0_REGION_INDEX ... VFIO_PCI_BAR5_REGION_INDEX:
+ *   - drivers/vfio/pci/vfio_pci.c|1164| <<vfio_pci_rw>> return vfio_pci_bar_rw(vdev, buf, count, ppos, false);
+ *   - drivers/vfio/pci/vfio_pci.c|1167| <<vfio_pci_rw>> return vfio_pci_bar_rw(vdev, buf, count, ppos, iswrite);
+ */
 ssize_t vfio_pci_bar_rw(struct vfio_pci_device *vdev, char __user *buf,
 			size_t count, loff_t *ppos, bool iswrite)
 {
@@ -211,6 +226,10 @@ ssize_t vfio_pci_bar_rw(struct vfio_pci_device *vdev, char __user *buf,
 	return done;
 }
 
+/*
+ * called by:
+ *   - drivers/vfio/pci/vfio_pci.c|1182| <<vfio_pci_rw>> return vfio_pci_vga_rw(vdev, buf, count, ppos, iswrite);
+ */
 ssize_t vfio_pci_vga_rw(struct vfio_pci_device *vdev, char __user *buf,
 			       size_t count, loff_t *ppos, bool iswrite)
 {
@@ -274,6 +293,10 @@ ssize_t vfio_pci_vga_rw(struct vfio_pci_device *vdev, char __user *buf,
 	return done;
 }
 
+/*
+ * 在以下使用vfio_pci_ioeventfd_handler():
+ *   - drivers/vfio/pci/vfio_pci_rdwr.c|380| <<vfio_pci_ioeventfd>> ret = vfio_virqfd_enable(ioeventfd, vfio_pci_ioeventfd_handler,
+ */
 static int vfio_pci_ioeventfd_handler(void *opaque, void *unused)
 {
 	struct vfio_pci_ioeventfd *ioeventfd = opaque;
@@ -298,6 +321,10 @@ static int vfio_pci_ioeventfd_handler(void *opaque, void *unused)
 	return 0;
 }
 
+/*
+ * 用来处理VFIO_DEVICE_IOEVENTFD:
+ *   - drivers/vfio/pci/vfio_pci.c|1148| <<vfio_pci_ioctl>> return vfio_pci_ioeventfd(vdev, ioeventfd.offset,
+ */
 long vfio_pci_ioeventfd(struct vfio_pci_device *vdev, loff_t offset,
 			uint64_t data, int count, int fd)
 {
diff --git a/drivers/vfio/vfio.c b/drivers/vfio/vfio.c
index c8482624ca34..3ee62fff8e6f 100644
--- a/drivers/vfio/vfio.c
+++ b/drivers/vfio/vfio.c
@@ -37,8 +37,46 @@
 #define DRIVER_AUTHOR	"Alex Williamson <alex.williamson@redhat.com>"
 #define DRIVER_DESC	"VFIO - User Level meta-driver"
 
+/*
+ * [    1.243470] pci 0000:00:00.0: Adding to iommu group 0
+ * [    1.248484] pci 0000:00:02.0: Adding to iommu group 1
+ * [    1.248572] pci 0000:00:08.0: Adding to iommu group 2
+ * [    1.248644] pci 0000:00:12.0: Adding to iommu group 3
+ * [    1.248776] pci 0000:00:14.0: Adding to iommu group 4
+ * [    1.248789] pci 0000:00:14.2: Adding to iommu group 4
+ * [    1.248829] pci 0000:00:14.3: Adding to iommu group 4
+ * [    1.248910] pci 0000:00:15.0: Adding to iommu group 5
+ * [    1.248977] pci 0000:00:16.0: Adding to iommu group 6
+ * [    1.248989] pci 0000:00:16.3: Adding to iommu group 6
+ * [    1.249069] pci 0000:00:17.0: Adding to iommu group 7
+ * [    1.249143] pci 0000:00:1b.0: Adding to iommu group 8
+ * [    1.251231] pci 0000:00:1f.0: Adding to iommu group 9
+ * [    1.251245] pci 0000:00:1f.3: Adding to iommu group 9
+ * [    1.251257] pci 0000:00:1f.4: Adding to iommu group 9
+ * [    1.251270] pci 0000:00:1f.5: Adding to iommu group 9
+ * [    1.251283] pci 0000:00:1f.6: Adding to iommu group 9
+ * [    1.251365] pci 0000:01:00.0: Adding to iommu group 10
+
+ * # echo 0000:01:00.0 > /sys/bus/pci/devices/0000\:01\:00.0/driver/unbind
+ * # lspci -ns 01:00.0
+ * 01:00.0 0108: 1179:011a
+ * # echo "1179 011a" > /sys/bus/pci/drivers/vfio-pci/new_id
+ *
+ * # ls /dev/vfio/
+ * 10    vfio  ----> 10是group
+ */
+
 static struct vfio {
 	struct class			*class;
+	/*
+	 * 在以下使用iommu_drivers_list:
+	 *   - drivers/vfio/vfio.c|235| <<vfio_register_iommu_driver>> list_for_each_entry(tmp, &vfio.iommu_drivers_list, vfio_next) {
+	 *   - drivers/vfio/vfio.c|243| <<vfio_register_iommu_driver>> list_add(&driver->vfio_next, &vfio.iommu_drivers_list);
+	 *   - drivers/vfio/vfio.c|256| <<vfio_unregister_iommu_driver>> list_for_each_entry(driver, &vfio.iommu_drivers_list, vfio_next) {
+	 *   - drivers/vfio/vfio.c|1025| <<vfio_ioctl_check_extension>> list_for_each_entry(driver, &vfio.iommu_drivers_list,
+	 *   - drivers/vfio/vfio.c|1103| <<vfio_ioctl_set_iommu>> list_for_each_entry(driver, &vfio.iommu_drivers_list, vfio_next) {
+	 *   - drivers/vfio/vfio.c|2173| <<vfio_init>> INIT_LIST_HEAD(&vfio.iommu_drivers_list);
+	 */
 	struct list_head		iommu_drivers_list;
 	struct mutex			iommu_drivers_lock;
 	struct list_head		group_list;
@@ -58,6 +96,11 @@ struct vfio_container {
 	struct kref			kref;
 	struct list_head		group_list;
 	struct rw_semaphore		group_lock;
+	/*
+	 * 在以下设置iommu_driver:
+	 *   - drivers/vfio/vfio.c|1144| <<vfio_ioctl_set_iommu>> container->iommu_driver = driver;
+	 *   - drivers/vfio/vfio.c|1308| <<__vfio_group_unset_container>> container->iommu_driver = NULL;
+	 */
 	struct vfio_iommu_driver	*iommu_driver;
 	void				*iommu_data;
 	bool				noiommu;
@@ -74,6 +117,15 @@ struct vfio_group {
 	atomic_t			container_users;
 	struct iommu_group		*iommu_group;
 	struct vfio_container		*container;
+	/*
+	 * 在以下使用device_list:
+	 *   - drivers/vfio/vfio.c|354| <<vfio_create_group>> INIT_LIST_HEAD(&group->device_list);
+	 *   - drivers/vfio/vfio.c|426| <<vfio_group_release>> WARN_ON(!list_empty(&group->device_list));
+	 *   - drivers/vfio/vfio.c|577| <<vfio_group_create_device>> list_add(&device->group_next, &group->device_list);
+	 *   - drivers/vfio/vfio.c|621| <<vfio_group_get_device>> list_for_each_entry(device, &group->device_list, group_next) {
+	 *   - drivers/vfio/vfio.c|901| <<vfio_device_get_from_name>> list_for_each_entry(it, &group->device_list, group_next) {
+	 *   - drivers/vfio/vfio.c|1012| <<vfio_del_group_dev>> if (list_empty(&group->device_list))
+	 */
 	struct list_head		device_list;
 	struct mutex			device_lock;
 	struct device			*dev;
@@ -219,6 +271,12 @@ static const struct vfio_iommu_driver_ops vfio_noiommu_ops = {
 /**
  * IOMMU driver registration
  */
+/*
+ * called by:
+ *   - drivers/vfio/vfio.c|2203| <<vfio_init>> vfio_register_iommu_driver(&vfio_noiommu_ops);
+ *   - drivers/vfio/vfio_iommu_spapr_tce.c|1374| <<tce_iommu_init>> return vfio_register_iommu_driver(&tce_iommu_driver_ops);
+ *   - drivers/vfio/vfio_iommu_type1.c|2345| <<vfio_iommu_type1_init>> return vfio_register_iommu_driver(&vfio_iommu_driver_ops_type1);
+ */
 int vfio_register_iommu_driver(const struct vfio_iommu_driver_ops *ops)
 {
 	struct vfio_iommu_driver *driver, *tmp;
@@ -531,6 +589,10 @@ static struct vfio_group *vfio_group_get_from_dev(struct device *dev)
 /**
  * Device objects - create, release, get, put, search
  */
+/*
+ * called by:
+ *   - drivers/vfio/vfio.c|855| <<vfio_add_group_dev>> device = vfio_group_create_device(group, dev, ops, device_data);
+ */
 static
 struct vfio_device *vfio_group_create_device(struct vfio_group *group,
 					     struct device *dev,
@@ -797,6 +859,12 @@ static int vfio_iommu_group_notifier(struct notifier_block *nb,
 /**
  * VFIO driver API
  */
+/*
+ * called by:
+ *   - drivers/vfio/mdev/vfio_mdev.c|115| <<vfio_mdev_probe>> return vfio_add_group_dev(dev, &vfio_mdev_dev_ops, mdev);
+ *   - drivers/vfio/pci/vfio_pci.c|1334| <<vfio_pci_probe>> ret = vfio_add_group_dev(&pdev->dev, &vfio_pci_ops, vdev);
+ *   - drivers/vfio/platform/vfio_platform_common.c|689| <<vfio_platform_probe_common>> ret = vfio_add_group_dev(dev, &vfio_platform_ops, vdev);
+ */
 int vfio_add_group_dev(struct device *dev,
 		       const struct vfio_device_ops *ops, void *device_data)
 {
@@ -1184,6 +1252,9 @@ static long vfio_fops_unl_ioctl(struct file *filep,
 	return ret;
 }
 
+/*
+ * 核心思想是分配一个struct vfio_container用来设置为这个file的private_data
+ */
 static int vfio_fops_open(struct inode *inode, struct file *filep)
 {
 	struct vfio_container *container;
@@ -1259,6 +1330,15 @@ static int vfio_fops_mmap(struct file *filep, struct vm_area_struct *vma)
 	return ret;
 }
 
+/*
+ * static struct miscdevice vfio_dev = {
+ *	.minor = VFIO_MINOR,
+ *	.name = "vfio",
+ *	.fops = &vfio_fops,
+ *	.nodename = "vfio/vfio",
+ *	.mode = S_IRUGO | S_IWUGO,
+ * };
+ */
 static const struct file_operations vfio_fops = {
 	.owner		= THIS_MODULE,
 	.open		= vfio_fops_open,
@@ -1597,6 +1677,12 @@ static int vfio_group_fops_release(struct inode *inode, struct file *filep)
 	return 0;
 }
 
+/*
+ * 在以下使用vfio_group_fops:
+ *   - drivers/vfio/vfio.c|1710| <<vfio_group_get_external_user>> if (filep->f_op != &vfio_group_fops)
+ *   - drivers/vfio/vfio.c|1735| <<vfio_external_group_match_file>> return (filep->f_op == &vfio_group_fops) && (group == test_group);
+ *   - drivers/vfio/vfio.c|2177| <<vfio_init>> cdev_init(&vfio.group_cdev, &vfio_group_fops);
+ */
 static const struct file_operations vfio_group_fops = {
 	.owner		= THIS_MODULE,
 	.unlocked_ioctl	= vfio_group_fops_unl_ioctl,
@@ -2131,6 +2217,10 @@ EXPORT_SYMBOL(vfio_unregister_notifier);
 /**
  * Module/class support
  */
+/*
+ * 在以下使用vfio_devnode():
+ *   - drivers/vfio/vfio.c|2212| <<vfio_init>> vfio.class->devnode = vfio_devnode;
+ */
 static char *vfio_devnode(struct device *dev, umode_t *mode)
 {
 	return kasprintf(GFP_KERNEL, "vfio/%s", dev_name(dev));
@@ -2148,6 +2238,9 @@ static int __init vfio_init(void)
 {
 	int ret;
 
+	/*
+	 * struct vfio vfio在文件的一开始定义
+	 */
 	idr_init(&vfio.group_idr);
 	mutex_init(&vfio.group_lock);
 	mutex_init(&vfio.iommu_drivers_lock);
diff --git a/drivers/vfio/vfio_iommu_type1.c b/drivers/vfio/vfio_iommu_type1.c
index 2ada8e6cdb88..25101cedb504 100644
--- a/drivers/vfio/vfio_iommu_type1.c
+++ b/drivers/vfio/vfio_iommu_type1.c
@@ -520,6 +520,9 @@ static int vfio_unpin_page_external(struct vfio_dma *dma, dma_addr_t iova,
 	return unlocked;
 }
 
+/*
+ * struct vfio_iommu_driver_ops vfio_iommu_driver_ops_type1.pin_pages = vfio_iommu_type1_pin_pages()
+ */
 static int vfio_iommu_type1_pin_pages(void *iommu_data,
 				      unsigned long *user_pfn,
 				      int npage, int prot,
@@ -606,6 +609,9 @@ static int vfio_iommu_type1_pin_pages(void *iommu_data,
 	return ret;
 }
 
+/*
+ * struct vfio_iommu_driver_ops vfio_iommu_driver_ops_type1.unpin_pages = vfio_iommu_type1_unpin_pages()
+ */
 static int vfio_iommu_type1_unpin_pages(void *iommu_data,
 					unsigned long *user_pfn,
 					int npage)
@@ -964,6 +970,10 @@ static int vfio_dma_do_unmap(struct vfio_iommu *iommu,
 	return ret;
 }
 
+/*
+ * called by:
+ *   - drivers/vfio/vfio_iommu_type1.c|1018| <<vfio_pin_map_dma>> ret = vfio_iommu_map(iommu, iova + dma->size, pfn, npage,
+ */
 static int vfio_iommu_map(struct vfio_iommu *iommu, dma_addr_t iova,
 			  unsigned long pfn, long npage, int prot)
 {
@@ -1418,6 +1428,13 @@ static int vfio_mdev_iommu_device(struct device *dev, void *data)
  * or with any existing dma mappings. The list is also modified to
  * exclude any reserved regions associated with the device group.
  */
+/*
+ * called by:
+ *   - drivers/vfio/vfio_iommu_type1.c|1482| <<vfio_iommu_aper_resize>> return vfio_iommu_iova_insert(iova, start, end);
+ *   - drivers/vfio/vfio_iommu_type1.c|1566| <<vfio_iommu_resv_exclude>> ret = vfio_iommu_iova_insert(&n->list, n->start,
+ *   - drivers/vfio/vfio_iommu_type1.c|1569| <<vfio_iommu_resv_exclude>> ret = vfio_iommu_iova_insert(&n->list, end + 1,
+ *   - drivers/vfio/vfio_iommu_type1.c|1613| <<vfio_iommu_iova_get_copy>> ret = vfio_iommu_iova_insert(iova_copy, n->start, n->end);
+ */
 static int vfio_iommu_iova_insert(struct list_head *head,
 				  dma_addr_t start, dma_addr_t end)
 {
@@ -1631,6 +1648,13 @@ static void vfio_iommu_iova_insert_copy(struct vfio_iommu *iommu,
 
 	list_splice_tail(iova_copy, iova);
 }
+/*
+ * called by:
+ *   - drivers/vfio/vfio.c|1085| <<__vfio_container_attach_groups>> ret = driver->ops->attach_group(data, group->iommu_group);
+ *   - drivers/vfio/vfio.c|1406| <<vfio_group_set_container>> ret = driver->ops->attach_group(container->iommu_data,
+ *
+ * struct vfio_iommu_driver_ops vfio_iommu_driver_ops_type1.attach_group = vfio_iommu_type1_attach_group()
+ */
 static int vfio_iommu_type1_attach_group(void *iommu_data,
 					 struct iommu_group *iommu_group)
 {
@@ -1961,6 +1985,9 @@ static int vfio_iommu_resv_refresh(struct vfio_iommu *iommu,
 	return ret;
 }
 
+/*
+ * struct vfio_iommu_driver_ops vfio_iommu_driver_ops_type1.detach_group = vfio_iommu_type1_detach_group()
+ */
 static void vfio_iommu_type1_detach_group(void *iommu_data,
 					  struct iommu_group *iommu_group)
 {
@@ -2036,6 +2063,9 @@ static void vfio_iommu_type1_detach_group(void *iommu_data,
 	mutex_unlock(&iommu->lock);
 }
 
+/*
+ * struct vfio_iommu_driver_ops vfio_iommu_driver_ops_type1.open = vfio_iommu_type1_open()
+ */
 static void *vfio_iommu_type1_open(unsigned long arg)
 {
 	struct vfio_iommu *iommu;
@@ -2084,6 +2114,9 @@ static void vfio_release_domain(struct vfio_domain *domain, bool external)
 		iommu_domain_free(domain->domain);
 }
 
+/*
+ * struct vfio_iommu_driver_ops vfio_iommu_driver_ops_type1.release = vfio_iommu_type1_release()
+ */
 static void vfio_iommu_type1_release(void *iommu_data)
 {
 	struct vfio_iommu *iommu = iommu_data;
@@ -2193,6 +2226,9 @@ static int vfio_iommu_iova_build_caps(struct vfio_iommu *iommu,
 	return ret;
 }
 
+/*
+ * struct vfio_iommu_driver_ops vfio_iommu_driver_ops_type1.ioctl = vfio_iommu_type1_ioctl()
+ */
 static long vfio_iommu_type1_ioctl(void *iommu_data,
 				   unsigned int cmd, unsigned long arg)
 {
@@ -2302,6 +2338,9 @@ static long vfio_iommu_type1_ioctl(void *iommu_data,
 	return -ENOTTY;
 }
 
+/*
+ * struct vfio_iommu_driver_ops vfio_iommu_driver_ops_type1.register_notifier = vfio_iommu_type1_register_notifier()
+ */
 static int vfio_iommu_type1_register_notifier(void *iommu_data,
 					      unsigned long *events,
 					      struct notifier_block *nb)
@@ -2318,6 +2357,9 @@ static int vfio_iommu_type1_register_notifier(void *iommu_data,
 	return blocking_notifier_chain_register(&iommu->notifier, nb);
 }
 
+/*
+ * struct vfio_iommu_driver_ops vfio_iommu_driver_ops_type1.unregister_notifier = vfio_iommu_type1_unregister_notifier()
+ */
 static int vfio_iommu_type1_unregister_notifier(void *iommu_data,
 						struct notifier_block *nb)
 {
@@ -2342,6 +2384,12 @@ static const struct vfio_iommu_driver_ops vfio_iommu_driver_ops_type1 = {
 
 static int __init vfio_iommu_type1_init(void)
 {
+	/*
+	 * called by:
+	 *   - drivers/vfio/vfio.c|2203| <<vfio_init>> vfio_register_iommu_driver(&vfio_noiommu_ops);
+	 *   - drivers/vfio/vfio_iommu_spapr_tce.c|1374| <<tce_iommu_init>> return vfio_register_iommu_driver(&tce_iommu_driver_ops);
+	 *   - drivers/vfio/vfio_iommu_type1.c|2345| <<vfio_iommu_type1_init>> return vfio_register_iommu_driver(&vfio_iommu_driver_ops_type1);
+	 */
 	return vfio_register_iommu_driver(&vfio_iommu_driver_ops_type1);
 }
 
diff --git a/include/linux/kvm_host.h b/include/linux/kvm_host.h
index 538c25e778c0..667f26b67bf9 100644
--- a/include/linux/kvm_host.h
+++ b/include/linux/kvm_host.h
@@ -219,6 +219,8 @@ int kvm_async_pf_wakeup_all(struct kvm_vcpu *vcpu);
 
 enum {
 	OUTSIDE_GUEST_MODE,
+	/*
+	 */
 	IN_GUEST_MODE,
 	EXITING_GUEST_MODE,
 	READING_SHADOW_PAGE_TABLES,
@@ -1221,8 +1223,14 @@ static inline void kvm_make_request(int req, struct kvm_vcpu *vcpu)
 	set_bit(req & KVM_REQUEST_MASK, (void *)&vcpu->requests);
 }
 
+/*
+ * x86下调用的例子:
+ *   - arch/x86/kvm/x86.c|8003| <<vcpu_enter_guest>> if (kvm_request_pending(vcpu)) {
+ *   - arch/x86/kvm/x86.c|8182| <<vcpu_enter_guest>> if (vcpu->mode == EXITING_GUEST_MODE || kvm_request_pending(vcpu)
+ */
 static inline bool kvm_request_pending(struct kvm_vcpu *vcpu)
 {
+	/* u64 requests */
 	return READ_ONCE(vcpu->requests);
 }
 
diff --git a/virt/kvm/eventfd.c b/virt/kvm/eventfd.c
index 67b6fc153e9c..1aa6e9099bdc 100644
--- a/virt/kvm/eventfd.c
+++ b/virt/kvm/eventfd.c
@@ -38,6 +38,16 @@ kvm_arch_irqfd_allowed(struct kvm *kvm, struct kvm_irqfd *args)
 	return true;
 }
 
+/*
+ * 在以下使用irqfd->inject:
+ *   - virt/kvm/eventfd.c|136| <<irqfd_shutdown>> flush_work(&irqfd->inject);
+ *   - virt/kvm/eventfd.c|209| <<irqfd_wakeup>> schedule_work(&irqfd->inject);
+ *   - virt/kvm/eventfd.c|308| <<kvm_irqfd_assign>> INIT_WORK(&irqfd->inject, irqfd_inject);
+ *   - virt/kvm/eventfd.c|408| <<kvm_irqfd_assign>> schedule_work(&irqfd->inject);
+ *
+ * 在以下使用irqfd_inject():
+ *   - virt/kvm/eventfd.c|304| <<kvm_irqfd_assign>> INIT_WORK(&irqfd->inject, irqfd_inject);
+ */
 static void
 irqfd_inject(struct work_struct *work)
 {
@@ -181,6 +191,10 @@ int __attribute__((weak)) kvm_arch_set_irq_inatomic(
 /*
  * Called with wqh->lock held and interrupts disabled
  */
+/*
+ * 在以下使用irqfd_wakeup():
+ *   - virt/kvm/eventfd.c|379| <<kvm_irqfd_assign>> init_waitqueue_func_entry(&irqfd->wait, irqfd_wakeup);
+ */
 static int
 irqfd_wakeup(wait_queue_entry_t *wait, unsigned mode, int sync, void *key)
 {
@@ -952,6 +966,10 @@ kvm_assign_ioeventfd(struct kvm *kvm, struct kvm_ioeventfd *args)
 	return ret;
 }
 
+/*
+ * called by (处理KVM_IOEVENTFD):
+ *   - virt/kvm/kvm_main.c|3364| <<kvm_vm_ioctl>> r = kvm_ioeventfd(kvm, &data);
+ */
 int
 kvm_ioeventfd(struct kvm *kvm, struct kvm_ioeventfd *args)
 {
diff --git a/virt/kvm/irqchip.c b/virt/kvm/irqchip.c
index 58e4f88b2b9f..2a28cba67930 100644
--- a/virt/kvm/irqchip.c
+++ b/virt/kvm/irqchip.c
@@ -68,6 +68,18 @@ int kvm_send_userspace_msi(struct kvm *kvm, struct kvm_msi *msi)
  *  = 0   Interrupt was coalesced (previous irq is still pending)
  *  > 0   Number of CPUs interrupt was delivered to
  */
+/*
+ * called by:
+ *   - arch/x86/kvm/i8254.c|250| <<pit_do_work>> kvm_set_irq(kvm, pit->irq_source_id, 0, 1, false);
+ *   - arch/x86/kvm/i8254.c|251| <<pit_do_work>> kvm_set_irq(kvm, pit->irq_source_id, 0, 0, false);
+ *   - arch/x86/kvm/x86.c|4756| <<kvm_vm_ioctl_irq_line>> irq_event->status = kvm_set_irq(kvm, KVM_USERSPACE_IRQ_SOURCE_ID,
+ *   - include/trace/events/kvm.h|66| <<__field>> TRACE_EVENT(kvm_set_irq,
+ *   - virt/kvm/eventfd.c|53| <<irqfd_inject>> kvm_set_irq(kvm, KVM_USERSPACE_IRQ_SOURCE_ID, irqfd->gsi, 1,
+ *   - virt/kvm/eventfd.c|55| <<irqfd_inject>> kvm_set_irq(kvm, KVM_USERSPACE_IRQ_SOURCE_ID, irqfd->gsi, 0,
+ *   - virt/kvm/eventfd.c|58| <<irqfd_inject>> kvm_set_irq(kvm, KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID,
+ *   - virt/kvm/eventfd.c|79| <<irqfd_resampler_ack>> kvm_set_irq(kvm, KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID,
+ *   - virt/kvm/eventfd.c|104| <<irqfd_resampler_shutdown>> kvm_set_irq(kvm, KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID,
+ */
 int kvm_set_irq(struct kvm *kvm, int irq_source_id, u32 irq, int level,
 		bool line_status)
 {
diff --git a/virt/kvm/kvm_main.c b/virt/kvm/kvm_main.c
index 00268290dcbd..1890c8bab13b 100644
--- a/virt/kvm/kvm_main.c
+++ b/virt/kvm/kvm_main.c
@@ -322,6 +322,11 @@ void kvm_reload_remote_mmus(struct kvm *kvm)
 	kvm_make_all_cpus_request(kvm, KVM_REQ_MMU_RELOAD);
 }
 
+/*
+ * x86下的调用:
+ *   - arch/x86/kvm/svm.c|2181| <<svm_create_vcpu>> err = kvm_vcpu_init(&svm->vcpu, kvm, id);
+ *   - arch/x86/kvm/vmx/vmx.c|6713| <<vmx_create_vcpu>> err = kvm_vcpu_init(&vmx->vcpu, kvm, id);
+ */
 int kvm_vcpu_init(struct kvm_vcpu *vcpu, struct kvm *kvm, unsigned id)
 {
 	struct page *page;
@@ -2714,6 +2719,10 @@ static void kvm_create_vcpu_debugfs(struct kvm_vcpu *vcpu)
 /*
  * Creates some virtual cpus.  Good luck creating more than one.
  */
+/*
+ * called by:
+ *   - virt/kvm/kvm_main.c|3287| <<kvm_vm_ioctl(KVM_CREATE_VCPU)>> r = kvm_vm_ioctl_create_vcpu(kvm, arg);
+ */
 static int kvm_vm_ioctl_create_vcpu(struct kvm *kvm, u32 id)
 {
 	int r;
-- 
2.17.1

