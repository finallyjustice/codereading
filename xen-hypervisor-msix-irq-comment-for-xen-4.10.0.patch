From c8c22847a83032cccb47a4f1e5e1cebde6c3d259 Mon Sep 17 00:00:00 2001
From: Dongli Zhang <dongli.zhang0129@gmail.com>
Date: Sun, 18 Aug 2019 22:38:21 +0800
Subject: [PATCH 1/1] xen hypervisor msix irq comment for xen-4.10.0

xen-4.10.0

Signed-off-by: Dongli Zhang <dongli.zhang0129@gmail.com>
---
 xen/arch/x86/hvm/ioreq.c                     |   9 ++
 xen/arch/x86/hvm/vmsi.c                      |  59 +++++++++
 xen/arch/x86/io_apic.c                       |  20 ++++
 xen/arch/x86/irq.c                           | 171 +++++++++++++++++++++++++++
 xen/arch/x86/msi.c                           |  29 +++++
 xen/arch/x86/pci.c                           |  21 ++++
 xen/arch/x86/physdev.c                       |  17 +++
 xen/arch/x86/pv/emul-priv-op.c               |   5 +
 xen/common/irq.c                             |   1 +
 xen/drivers/passthrough/io.c                 |  26 ++++
 xen/include/asm-x86/hvm/domain.h             |  10 ++
 xen/include/asm-x86/mach-generic/mach_apic.h |   5 +
 xen/include/xen/pci.h                        |   5 +
 13 files changed, 378 insertions(+)

diff --git a/xen/arch/x86/hvm/ioreq.c b/xen/arch/x86/hvm/ioreq.c
index d5afe20..9591da5 100644
--- a/xen/arch/x86/hvm/ioreq.c
+++ b/xen/arch/x86/hvm/ioreq.c
@@ -66,6 +66,11 @@ bool hvm_io_pending(struct vcpu *v)
     return false;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/ioreq.c|103| <<hvm_wait_for_io>> hvm_io_assist(sv, ~0ul);
+ *   - arch/x86/hvm/ioreq.c|107| <<hvm_wait_for_io>> hvm_io_assist(sv, p->data);
+ */
 static void hvm_io_assist(struct hvm_ioreq_vcpu *sv, uint64_t data)
 {
     struct vcpu *v = sv->vcpu;
@@ -85,6 +90,10 @@ static void hvm_io_assist(struct hvm_ioreq_vcpu *sv, uint64_t data)
     sv->pending = false;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/ioreq.c|143| <<handle_hvm_io_completion>> if ( !hvm_wait_for_io(sv, get_ioreq(s, v)) )
+ */
 static bool hvm_wait_for_io(struct hvm_ioreq_vcpu *sv, ioreq_t *p)
 {
     while ( sv->pending )
diff --git a/xen/arch/x86/hvm/vmsi.c b/xen/arch/x86/hvm/vmsi.c
index 7126de7..d2e147b 100644
--- a/xen/arch/x86/hvm/vmsi.c
+++ b/xen/arch/x86/hvm/vmsi.c
@@ -40,6 +40,11 @@
 #include <asm/event.h>
 #include <asm/io_apic.h>
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vmsi.c|77| <<vmsi_deliver>> vmsi_inj_irq(target, vector, trig_mode, delivery_mode);
+ *   - arch/x86/hvm/vmsi.c|88| <<vmsi_deliver>> vmsi_inj_irq(vcpu_vlapic(v), vector,
+ */
 static void vmsi_inj_irq(
     struct vlapic *target,
     uint8_t vector,
@@ -60,6 +65,12 @@ static void vmsi_inj_irq(
     }
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/irq.c|380| <<hvm_inject_msi>> return vmsi_deliver(d, vector, dest, dest_mode, delivery_mode, trig_mode);
+ *   - arch/x86/hvm/vmsi.c|118| <<vmsi_deliver_pirq>> vmsi_deliver(d, vector, dest, dest_mode, delivery_mode, trig_mode);
+ *   - drivers/passthrough/amd/iommu_guest.c|138| <<guest_iommu_deliver_msi>> vmsi_deliver(d, vector, dest, dest_mode, delivery_mode, trig_mode);
+ */
 int vmsi_deliver(
     struct domain *d, int vector,
     uint8_t dest, uint8_t dest_mode,
@@ -99,6 +110,10 @@ int vmsi_deliver(
     return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/passthrough/io.c|918| <<hvm_dirq_assist>> vmsi_deliver_pirq(d, pirq_dpci);
+ */
 void vmsi_deliver_pirq(struct domain *d, const struct hvm_pirq_dpci *pirq_dpci)
 {
     uint32_t flags = pirq_dpci->gmsi.gflags;
@@ -119,6 +134,10 @@ void vmsi_deliver_pirq(struct domain *d, const struct hvm_pirq_dpci *pirq_dpci)
 }
 
 /* Return value, -1 : multi-dests, non-negative value: dest_vcpu_id */
+/*
+ * called by:
+ *   - drivers/passthrough/io.c|428| <<pt_irq_create_bind>> dest_vcpu_id = hvm_girq_dest_2_vcpu_id(d, dest, dest_mode);
+ */
 int hvm_girq_dest_2_vcpu_id(struct domain *d, uint8_t dest, uint8_t dest_mode)
 {
     int dest_vcpu_id = -1, w = 0;
@@ -207,6 +226,9 @@ static struct msi_desc *msixtbl_addr_to_desc(
     return NULL;
 }
 
+/*
+ * struct hvm_io_ops msixtbl_mmio_ops.read = msixtbl_read()
+ */
 static int msixtbl_read(const struct hvm_io_handler *handler,
                         uint64_t address, uint32_t len, uint64_t *pval)
 {
@@ -263,6 +285,11 @@ out:
     return r;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vmsi.c|346| <<_msixtbl_write>> return msixtbl_write(current, address, len, val);
+ *   - arch/x86/hvm/vmsi.c|621| <<msix_write_completion>> if ( msixtbl_write(v, ctrl_address, 4, 0) != X86EMUL_OKAY )
+ */
 static int msixtbl_write(struct vcpu *v, unsigned long address,
                          unsigned int len, unsigned long val)
 {
@@ -340,12 +367,18 @@ out:
     return r;
 }
 
+/*
+ * struct hvm_io_ops msixtbl_mmio_ops.write = _msixtlb_write()
+ */
 static int _msixtbl_write(const struct hvm_io_handler *handler,
                           uint64_t address, uint32_t len, uint64_t val)
 {
     return msixtbl_write(current, address, len, val);
 }
 
+/*
+ * struct hvm_io_ops msixtbl_mmio_ops.accept = msixtbl_range()
+ */
 static bool_t msixtbl_range(const struct hvm_io_handler *handler,
                             const ioreq_t *r)
 {
@@ -415,6 +448,10 @@ static const struct hvm_io_ops msixtbl_mmio_ops = {
     .write = _msixtbl_write,
 };
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vmsi.c|504| <<msixtbl_pt_register>> add_msixtbl_entry(d, pdev, gtable, entry);
+ */
 static void add_msixtbl_entry(struct domain *d,
                               struct pci_dev *pdev,
                               uint64_t gtable,
@@ -446,6 +483,10 @@ static void del_msixtbl_entry(struct msixtbl_entry *entry)
     call_rcu(&entry->rcu, free_msixtbl_entry);
 }
 
+/*
+ * called by:
+ *   - drivers/passthrough/io.c|376| <<pt_irq_create_bind>> rc = msixtbl_pt_register(d, info, pt_irq_bind->u.msi.gtable);
+ */
 int msixtbl_pt_register(struct domain *d, struct pirq *pirq, uint64_t gtable)
 {
     struct irq_desc *irq_desc;
@@ -555,6 +596,10 @@ found:
     spin_unlock_irq(&irq_desc->lock);
 }
 
+/*
+ * called by:
+ *   - drivers/passthrough/pci.c|1412| <<assign_device>> msixtbl_init(d);
+ */
 void msixtbl_init(struct domain *d)
 {
     struct hvm_io_handler *handler;
@@ -562,6 +607,16 @@ void msixtbl_init(struct domain *d)
     if ( !is_hvm_domain(d) || !has_vlapic(d) || msixtbl_initialised(d) )
         return;
 
+    /*
+     * used by:
+     *   - arch/x86/hvm/vmsi.c|174| <<msixtbl_initialised>> return !!d->arch.hvm_domain.msixtbl_list.next;
+     *   - arch/x86/hvm/vmsi.c|183| <<msixtbl_find_entry>> list_for_each_entry( entry, &d->arch.hvm_domain.msixtbl_list, list )
+     *   - arch/x86/hvm/vmsi.c|445| <<add_msixtbl_entry>> list_add_rcu(&entry->list, &d->arch.hvm_domain.msixtbl_list);
+     *   - arch/x86/hvm/vmsi.c|498| <<msixtbl_pt_register>> list_for_each_entry( entry, &d->arch.hvm_domain.msixtbl_list, list )
+     *   - arch/x86/hvm/vmsi.c|557| <<msixtbl_pt_unregister>> list_for_each_entry( entry, &d->arch.hvm_domain.msixtbl_list, list )
+     *   - arch/x86/hvm/vmsi.c|583| <<msixtbl_init>> INIT_LIST_HEAD(&d->arch.hvm_domain.msixtbl_list);
+     *   - arch/x86/hvm/vmsi.c|603| <<msixtbl_pt_cleanup>> &d->arch.hvm_domain.msixtbl_list, list )
+     */
     INIT_LIST_HEAD(&d->arch.hvm_domain.msixtbl_list);
 
     handler = hvm_next_io_handler(d);
@@ -588,6 +643,10 @@ void msixtbl_pt_cleanup(struct domain *d)
     spin_unlock(&d->event_lock);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/ioreq.c|82| <<hvm_io_assist>> msix_write_completion(v);
+ */
 void msix_write_completion(struct vcpu *v)
 {
     unsigned long ctrl_address = v->arch.hvm_vcpu.hvm_io.msix_unmask_address;
diff --git a/xen/arch/x86/io_apic.c b/xen/arch/x86/io_apic.c
index f959090..71864a8 100644
--- a/xen/arch/x86/io_apic.c
+++ b/xen/arch/x86/io_apic.c
@@ -2522,6 +2522,12 @@ void __init init_ioapic_mappings(void)
     unsigned int i, idx = FIX_IO_APIC_BASE_0;
     union IO_APIC_reg_01 reg_01;
 
+    /*
+     * 在desktop上:
+     *   smp_found_config = true
+     *   nr_ioapics = 1
+     */
+
     if ( smp_found_config )
         nr_irqs_gsi = 0;
     for ( i = 0; i < nr_ioapics; i++ )
@@ -2560,6 +2566,9 @@ void __init init_ioapic_mappings(void)
             /* The number of IO-APIC IRQ registers (== #pins): */
             reg_01.raw = io_apic_read(i, 1);
             nr_ioapic_entries[i] = reg_01.bits.entries + 1;
+	    /*
+	     * nr_irqs_gsi上面设置的开始是0, nr_ioapic_entries[i]是120
+	     */
             nr_irqs_gsi += nr_ioapic_entries[i];
 
             if ( rangeset_add_singleton(mmio_ro_ranges,
@@ -2569,8 +2578,16 @@ void __init init_ioapic_mappings(void)
         }
     }
 
+    /*
+     * highest_gsi()是119
+     */
     nr_irqs_gsi = max(nr_irqs_gsi, highest_gsi() + 1);
 
+    /*
+     * max_gsi_irqs是0
+     *
+     * 因为nr_irqs默认是0, max_gsi_irqs=4096
+     */
     if ( max_gsi_irqs == 0 )
         max_gsi_irqs = nr_irqs ? nr_irqs / 8 : PAGE_SIZE;
     else if ( nr_irqs != 0 && max_gsi_irqs > nr_irqs )
@@ -2595,6 +2612,9 @@ void __init init_ioapic_mappings(void)
         nr_irqs_gsi = max_gsi_irqs;
     }
 
+    /*
+     * 在desktop上默认nr_irqs在这里是0
+     */
     if ( nr_irqs == 0 )
         nr_irqs = cpu_has_apic ?
                   max(16U + num_present_cpus() * NR_DYNAMIC_VECTORS,
diff --git a/xen/arch/x86/irq.c b/xen/arch/x86/irq.c
index c0ab299..64066c6 100644
--- a/xen/arch/x86/irq.c
+++ b/xen/arch/x86/irq.c
@@ -26,6 +26,53 @@
 #include <asm/mach-generic/mach_apic.h>
 #include <public/physdev.h>
 
+/*
+ * 在arch/x86/x86_64/entry.S,
+ * autogen_entrypoints生成vector table, 每一个vector指向一个处理函数
+ * 函数都差不多 (每个cpu支持256个vector):
+ *
+ * 先"movb  $vec,4(%rsp)", 再"jmp   common_interrupt"
+ *
+ * 在arch/x86/x86_64/entry.S:
+ * 392 ENTRY(common_interrupt)
+ * 393         SAVE_ALL CLAC
+ * 394         CR4_PV32_RESTORE
+ * 395         movq %rsp,%rdi
+ * 396         callq do_IRQ
+ * 397         jmp ret_from_intr
+ *
+ * do_IRQ()如何把vector发送到guest?
+ *
+ * 1. 先通过vector查找percpu的vector_irq[vector]找到irq:
+ * int irq = __get_cpu_var(vector_irq[vector]);
+ *
+ * 2. 再通过irq找到对应的struct irq_desc, x86下就是&irq_desc[irq]:
+ * desc = irq_to_desc(irq);
+ *
+ * 3. 很可能desc->status & IRQ_GUEST是true, 就要调用__do_IRQ_guest(irq)了
+ *
+ * 4. 如果是dom0, 调用send_guest_pirq()往dom0插入event
+ *
+ *
+ * 重要的函数或者数据结构:
+ *
+ * - vector_irq[vector]: 把cpu的vector转换成irq, 索引&irq_desc[irq]
+ * - domain_irq_to_pirq(d, irq)负责将xen的irq转换成某个domain d的pirq
+ * - pirq_info(d, pirq)负责将某个domain d的pirq转换成'struct pirq'
+ *
+ * struct pirq {
+ *   int pirq;
+ *   u16 evtchn;
+ *   bool_t masked;
+ *   struct rcu_head rcu_head;
+ *   struct arch_pirq arch;
+ * };
+ *
+ * dom0 linux的核心函数感觉是__startup_pirq()
+ *
+ * xen有自己的irq, linux有自己的irq, pirq是domain相关的, linux和xen都认识
+ */
+
 static int parse_irq_vector_map_param(const char *s);
 
 /* opt_noirqbalance: If true, software IRQ balancing/affinity is disabled. */
@@ -48,6 +95,27 @@ static DECLARE_BITMAP(used_vectors, NR_VECTORS);
 
 static DEFINE_SPINLOCK(vector_lock);
 
+/*
+ * 使用的地方:
+ *   - xen/arch/x86/i8259.c|106| <<_disable_8259A_irq>> per_cpu(vector_irq, 0)[LEGACY_VECTOR(irq)] = ~irq;
+ *   - xen/arch/x86/i8259.c|122| <<enable_8259A_irq>> per_cpu(vector_irq, 0)[LEGACY_VECTOR(desc->irq)] = desc->irq;
+ *   - xen/arch/x86/i8259.c|352| <<init_IRQ>> per_cpu(vector_irq, cpu)[FIRST_LEGACY_VECTOR + irq] = irq;
+ *   - xen/arch/x86/i8259.c|357| <<init_IRQ>> per_cpu(vector_irq, cpu)[IRQ0_VECTOR] = 0;
+ *   - xen/arch/x86/irq.c|134| <<__bind_irq_vector>> per_cpu(vector_irq, cpu)[vector] = irq;
+ *   - xen/arch/x86/irq.c|284| <<__clear_irq_vector>> ASSERT( per_cpu(vector_irq, cpu)[vector] == irq );
+ *   - xen/arch/x86/irq.c|285| <<__clear_irq_vector>> per_cpu(vector_irq, cpu)[vector] = ~irq;
+ *   - xen/arch/x86/irq.c|309| <<__clear_irq_vector>> ASSERT( per_cpu(vector_irq, cpu)[old_vector] == irq );
+ *   - xen/arch/x86/irq.c|311| <<__clear_irq_vector>> per_cpu(vector_irq, cpu)[old_vector] = ~irq;
+ *   - xen/arch/x86/irq.c|385| <<init_irq_data>> this_cpu(vector_irq)[vector] = INT_MIN;
+ *   - xen/arch/x86/irq.c|548| <<__assign_irq_vector>> if (per_cpu(vector_irq, new_cpu)[vector] >= 0)
+ *   - xen/arch/x86/irq.c|560| <<__assign_irq_vector>> per_cpu(vector_irq, new_cpu)[vector] = irq;
+ *   - xen/arch/x86/irq.c|617| <<setup_vector_irq>> per_cpu(vector_irq, cpu)[vector] = INT_MIN;
+ *   - xen/arch/x86/irq.c|631| <<setup_vector_irq>> per_cpu(vector_irq, cpu)[vector] = irq;
+ *   - xen/arch/x86/irq.c|691| <<irq_move_cleanup_interrupt>> irq = __get_cpu_var(vector_irq)[vector];
+ *   - xen/arch/x86/irq.c|729| <<irq_move_cleanup_interrupt>> __get_cpu_var(vector_irq)[vector] = ~irq;
+ *   - xen/arch/x86/irq.c|861| <<do_IRQ>> int irq = __get_cpu_var(vector_irq[vector]);
+ *   - xen/arch/x86/smpboot.c|1060| <<smp_intr_init>> per_cpu(vector_irq, cpu)[vector] = irq;
+ */
 DEFINE_PER_CPU(vector_irq_t, vector_irq);
 
 DEFINE_PER_CPU(struct cpu_user_regs *, __irq_regs);
@@ -112,6 +180,10 @@ static void trace_irq_mask(u32 event, int irq, int vector, cpumask_t *mask)
     trace_var(event, 1, sizeof(d), &d);
 }
 
+/*
+ * called by:
+ *   - arch/x86/irq.c|220| <<bind_irq_vector>> ret = __bind_irq_vector(irq, vector, cpu_mask);
+ */
 static int __init __bind_irq_vector(int irq, int vector, const cpumask_t *cpu_mask)
 {
     cpumask_t online_mask;
@@ -143,6 +215,10 @@ static int __init __bind_irq_vector(int irq, int vector, const cpumask_t *cpu_ma
     return 0;
 }
 
+/*
+ * called by:
+ *   - arch/x86/io_apic.c|1896| <<check_timer>> if ((ret = bind_irq_vector(0, vector, &mask_all)))
+ */
 int __init bind_irq_vector(int irq, int vector, const cpumask_t *cpu_mask)
 {
     unsigned long flags;
@@ -157,18 +233,43 @@ int __init bind_irq_vector(int irq, int vector, const cpumask_t *cpu_mask)
 /*
  * Dynamic irq allocate and deallocation for MSI
  */
+/*
+ * called by:
+ *   - arch/x86/hpet.c|376| <<hpet_assign_irq>> if ( (irq = create_irq(NUMA_NO_NODE)) < 0 )
+ *   - arch/x86/irq.c|2036| <<map_domain_pirq>> irq = create_irq(NUMA_NO_NODE);
+ *   - arch/x86/irq.c|2673| <<allocate_and_map_msi_pirq>> irq = create_irq(NUMA_NO_NODE);
+ *   - drivers/passthrough/amd/iommu_init.c|783| <<set_iommu_interrupt_handler>> irq = create_irq(NUMA_NO_NODE);
+ *   - drivers/passthrough/vtd/iommu.c|1130| <<iommu_set_interrupt>> irq = create_irq(rhsa ? pxm_to_node(rhsa->proximity_domain)
+ */
 int create_irq(nodeid_t node)
 {
     int irq, ret;
     struct irq_desc *desc;
 
+    /*
+     * 在desktop默认:
+     * (XEN) IRQ limits: 120 GSI, 1432 MSI/MSI-X
+     * nr_irqs_gsi = 120, nr_irqs = 1552
+     *
+     * 设置nr_irqs=4096后:
+     * (XEN) IRQ limits: 120 GSI, 3976 MSI/MSI-X
+     */
+
     for (irq = nr_irqs_gsi; irq < nr_irqs; irq++)
     {
+        /* 返回&irq_desc[irq] */
         desc = irq_to_desc(irq);
+        /*
+	 * For use with irq_desc.arch.used
+	 *   #define IRQ_UNUSED      (0)
+	 *   #define IRQ_USED        (1)
+	 *   #define IRQ_RESERVED    (-1)
+	 */
         if (cmpxchg(&desc->arch.used, IRQ_UNUSED, IRQ_RESERVED) == IRQ_UNUSED)
            break;
     }
 
+    /* 上面也间接设置了返回值irq */
     if (irq >= nr_irqs)
          return -ENOSPC;
 
@@ -188,6 +289,7 @@ int create_irq(nodeid_t node)
     if (ret < 0)
     {
         desc->arch.used = IRQ_UNUSED;
+	/* 设置返回值irq的地方 */
         irq = ret;
     }
     else if ( hardware_domain )
@@ -438,6 +540,28 @@ static vmask_t *irq_get_used_vector_mask(int irq)
     return ret;
 }
 
+/*
+ * called by:
+ *   - xen/arch/x86/irq.c|591| <<assign_irq_vector>> ret = __assign_irq_vector(irq, desc, mask ?: TARGET_CPUS);
+ *   - xen/arch/x86/irq.c|780| <<set_desc_affinity>> ret = __assign_irq_vector(irq, desc, mask);
+ *
+ * 如果是assign_irq_vector()进来的, 如果之前mask是NULL, 则参数mask是genapic->target_cpus()
+ *
+ * 调用以下的代码可以获得allocation mask:
+ *
+ * 2274 static void dump_cpu_allocation(void)
+ * 2275 {
+ * 2276     int cpu, new_cpu;
+ * 2277 
+ * 2278     for_each_cpu(cpu, TARGET_CPUS) {
+ * 2279         const cpumask_t *mask = vector_allocation_cpumask(cpu);
+ * 2280 
+ * 2281         for_each_cpu(new_cpu, mask) {
+ * 2282             printk("allocation mask: %d: %d\n", cpu, new_cpu);
+ * 2283         }
+ * 2284     }
+ * 2285 }
+ */
 static int __assign_irq_vector(
     int irq, struct irq_desc *desc, const cpumask_t *mask)
 {
@@ -452,6 +576,11 @@ static int __assign_irq_vector(
      * Also, we've got to be careful not to trash gate
      * 0x80, because int 0x80 is hm, kind of importantish. ;)
      */
+    /*
+     * #define FIRST_DYNAMIC_VECTOR    0x20
+     * #define LAST_DYNAMIC_VECTOR     0xdf 
+     * #define NR_DYNAMIC_VECTORS      (LAST_DYNAMIC_VECTOR - FIRST_DYNAMIC_VECTOR + 1)
+     */
     static int current_vector = FIRST_DYNAMIC_VECTOR, current_offset = 0;
     int cpu, err, old_vector;
     cpumask_t tmp_mask;
@@ -489,6 +618,13 @@ static int __assign_irq_vector(
         if (!cpu_online(cpu))
             continue;
 
+	/*
+	 * 设置genapic的地方:
+	 *   - xen/arch/x86/apic.c|945| <<x2apic_bsp_setup>> genapic = apic_x2apic_probe();
+	 *      xen/arch/x86/apic.c|946| <<x2apic_bsp_setup>> printk("Switched to APIC driver %s.\n", genapic->name);
+	 *
+	 * "x2apic_cluster"是vector_allocation_cpumask_x2apic_cluster()
+	 */
         cpumask_and(&tmp_mask, vector_allocation_cpumask(cpu),
                     &cpu_online_map);
 
@@ -546,10 +682,18 @@ next:
     return err;
 }
 
+/*
+ * called by:
+ *   - xen/arch/x86/io_apic.c|1032| <<setup_IO_APIC_irqs>> vector = assign_irq_vector(irq, NULL);
+ *   - xen/arch/x86/io_apic.c|2232| <<io_apic_set_pci_routing>> vector = assign_irq_vector(irq, NULL);
+ *   - xen/arch/x86/io_apic.c|2396| <<ioapic_guest_write>> ret = assign_irq_vector(irq, NULL);
+ *   - xen/arch/x86/irq.c|204| <<create_irq>> ret = assign_irq_vector(irq, mask);
+ */
 int assign_irq_vector(int irq, const cpumask_t *mask)
 {
     int ret;
     unsigned long flags;
+    /* 相当于&irq_desc[irq] */
     struct irq_desc *desc = irq_to_desc(irq);
     
     BUG_ON(irq >= nr_irqs || irq <0);
@@ -568,6 +712,10 @@ int assign_irq_vector(int irq, const cpumask_t *mask)
  * Initialize vector_irq on a new cpu. This function must be called
  * with vector_lock held.
  */
+/*
+ * called by:
+ *   - arch/x86/smpboot.c|372| <<start_secondary>> setup_vector_irq(cpu);
+ */
 void setup_vector_irq(unsigned int cpu)
 {
     unsigned int irq, vector;
@@ -859,6 +1007,7 @@ void do_IRQ(struct cpu_user_regs *regs)
         goto out_no_unlock;
     }
 
+    /* 就是&irq_desc[irq] */
     desc = irq_to_desc(irq);
 
     spin_lock(&desc->lock);
@@ -1863,12 +2012,16 @@ static inline bool is_free_pirq(const struct domain *d,
         pirq->arch.hvm.emuirq == IRQ_UNBOUND));
 }
 
+/*
+ * 搜索返回一个没人用的pirq
+ */
 int get_free_pirq(struct domain *d, int type)
 {
     int i;
 
     ASSERT(spin_is_locked(&d->event_lock));
 
+    /* gsi用的是nr_irqs_gsi之前的 */
     if ( type == MAP_PIRQ_TYPE_GSI )
     {
         for ( i = 16; i < nr_irqs_gsi; i++ )
@@ -1878,6 +2031,7 @@ int get_free_pirq(struct domain *d, int type)
                 return i;
             }
     }
+    /* msi用的是nr_irqs_gsi之后的?? */
     for ( i = d->nr_pirqs - 1; i >= nr_irqs_gsi; i-- )
         if ( is_free_pirq(d, pirq_info(d, i)) )
         {
@@ -1909,6 +2063,12 @@ int get_free_pirqs(struct domain *d, unsigned int nr)
 
 #define MAX_MSI_IRQS 32 /* limited by MSI capability struct properties */
 
+/*
+ * called and used by:
+ *   - arch/x86/io_apic.c|2411| <<ioapic_guest_write>> ret = map_domain_pirq(hardware_domain, pirq, irq,
+ *   - arch/x86/irq.c|2807| <<allocate_and_map_gsi_pirq>> ret = map_domain_pirq(d, pirq, irq, MAP_PIRQ_TYPE_GSI, NULL);
+ *   - arch/x86/irq.c|2870| <<allocate_and_map_msi_pirq>> ret = map_domain_pirq(d, pirq, irq, type, msi);
+ */
 int map_domain_pirq(
     struct domain *d, int pirq, int irq, int type, void *data)
 {
@@ -2561,6 +2721,9 @@ bool hvm_domain_use_pirq(const struct domain *d, const struct pirq *pirq)
     return is_hvm_domain(d) && pirq && pirq->arch.hvm.emuirq != IRQ_UNBOUND;
 }
 
+/*
+ * 核心思想是搜索返回一个没人用的pirq
+ */
 static int allocate_pirq(struct domain *d, int index, int pirq, int irq,
                          int type, int *nr)
 {
@@ -2598,6 +2761,7 @@ static int allocate_pirq(struct domain *d, int index, int pirq, int irq,
         }
         else
         {
+            /* 搜索返回一个没人用的pirq */
             pirq = get_free_pirq(d, type);
             if ( pirq < 0 )
                 dprintk(XENLOG_G_ERR, "dom%d: no free pirq\n", d->domain_id);
@@ -2656,6 +2820,10 @@ int allocate_and_map_gsi_pirq(struct domain *d, int index, int *pirq_p)
     return ret;
 }
 
+/*
+ * called by only:
+ *   - arch/x86/physdev.c|129| <<physdev_map_pirq>> ret = allocate_and_map_msi_pirq(d, *index, pirq_p, type, msi);
+ */
 int allocate_and_map_msi_pirq(struct domain *d, int index, int *pirq_p,
                               int type, struct msi_info *msi)
 {
@@ -2695,6 +2863,9 @@ int allocate_and_map_msi_pirq(struct domain *d, int index, int *pirq_p,
     pcidevs_lock();
     /* Verify or get pirq. */
     spin_lock(&d->event_lock);
+    /*
+     * 核心思想是搜索返回一个没人用的pirq
+     */
     pirq = allocate_pirq(d, index, *pirq_p, irq, type, &msi->entry_nr);
     if ( pirq < 0 )
     {
diff --git a/xen/arch/x86/msi.c b/xen/arch/x86/msi.c
index 4652b98..d8be6b7 100644
--- a/xen/arch/x86/msi.c
+++ b/xen/arch/x86/msi.c
@@ -585,6 +585,10 @@ static struct msi_desc *alloc_msi_entry(unsigned int nr)
     return entry;
 }
 
+/*
+ * called by:
+ *   - arch/x86/irq.c|2163| <<map_domain_pirq>> while ( !(ret = setup_msi_irq(desc, msi_desc + nr)) )
+ */
 int setup_msi_irq(struct irq_desc *desc, struct msi_desc *msidesc)
 {
     const struct pci_dev *pdev = msidesc->dev;
@@ -614,6 +618,11 @@ int setup_msi_irq(struct irq_desc *desc, struct msi_desc *msidesc)
     return rc;
 }
 
+/*
+ * called by:
+ *   - arch/x86/msi.c|606| <<setup_msi_irq>> rc = __setup_msi_irq(desc, msidesc,
+ *   - drivers/passthrough/amd/iommu_init.c|814| <<set_iommu_interrupt_handler>> ret = __setup_msi_irq(irq_to_desc(irq), &iommu->msi, handler);
+ */
 int __setup_msi_irq(struct irq_desc *desc, struct msi_desc *msidesc,
                     hw_irq_controller *handler)
 {
@@ -681,6 +690,10 @@ static struct msi_desc *find_msi_entry(struct pci_dev *dev,
  * multiple messages. A return of zero indicates the successful setup
  * of an entry zero with the new MSI irq or non-zero for otherwise.
  **/
+/*
+ * called by:
+ *   - arch/x86/msi.c|1077| <<__pci_enable_msi>> return msi_capability_init(pdev, msi->irq, desc, msi->entry_nr);
+ */
 static int msi_capability_init(struct pci_dev *dev,
                                int irq,
                                struct msi_desc **desc,
@@ -1037,6 +1050,10 @@ static int msix_capability_init(struct pci_dev *dev,
  * irq or non-zero for otherwise.
  **/
 
+/*
+ * called by:
+ *   - arch/x86/msi.c|1255| <<pci_enable_msi>> __pci_enable_msi(msi, desc);
+ */
 static int __pci_enable_msi(struct msi_info *msi, struct msi_desc **desc)
 {
     struct pci_dev *pdev;
@@ -1093,6 +1110,10 @@ static void __pci_disable_msi(struct msi_desc *entry)
  * of irqs available. Driver should use the returned value to re-send
  * its request.
  **/
+/*
+ * called by:
+ *   - arch/x86/msi.c|1262| <<pci_enable_msi>> return msi->table_base ? __pci_enable_msix(msi, desc) :
+ */
 static int __pci_enable_msix(struct msi_info *msi, struct msi_desc **desc)
 {
     int pos, nr_entries;
@@ -1231,6 +1252,10 @@ int pci_prepare_msix(u16 seg, u8 bus, u8 devfn, bool off)
  * Notice: only construct the msi_desc
  * no change to irq_desc here, and the interrupt is masked
  */
+/*
+ * called by:
+ *   - arch/x86/irq.c|2142| <<map_domain_pirq>> ret = pci_enable_msi(msi, &msi_desc);
+ */
 int pci_enable_msi(struct msi_info *msi, struct msi_desc **desc)
 {
     ASSERT(pcidevs_locked());
@@ -1272,6 +1297,10 @@ void pci_cleanup_msi(struct pci_dev *pdev)
     msi_free_irqs(pdev);
 }
 
+/*
+ * called by:
+ *   - arch/x86/pci.c|95| <<pci_conf_write_intercept>> rc = pci_msi_conf_write_intercept(pdev, reg, size, data);
+ */
 int pci_msi_conf_write_intercept(struct pci_dev *pdev, unsigned int reg,
                                  unsigned int size, uint32_t *data)
 {
diff --git a/xen/arch/x86/pci.c b/xen/arch/x86/pci.c
index a9decd4..db0f2d9 100644
--- a/xen/arch/x86/pci.c
+++ b/xen/arch/x86/pci.c
@@ -11,6 +11,14 @@
 
 static DEFINE_SPINLOCK(pci_config_lock);
 
+/*
+ * called by:
+ *   - arch/x86/pv/emul-priv-op.c|274| <<guest_io_read>> sub_data = pci_conf_read(currd->arch.pci_cf8, port & 3, size);
+ *   - arch/x86/x86_64/pci.c|28| <<pci_conf_read8>> return pci_conf_read(PCI_CONF_ADDRESS(bus, dev, func, reg), reg & 3, 1);
+ *   - arch/x86/x86_64/pci.c|46| <<pci_conf_read16>> return pci_conf_read(PCI_CONF_ADDRESS(bus, dev, func, reg), reg & 2, 2);
+ *   - arch/x86/x86_64/pci.c|64| <<pci_conf_read32>> return pci_conf_read(PCI_CONF_ADDRESS(bus, dev, func, reg), 0, 4);
+ *   - include/xen/pci.h|159| <<pci_conf_read32>> uint32_t pci_conf_read(uint32_t cf8, uint8_t offset, uint8_t bytes);
+ */
 uint32_t pci_conf_read(uint32_t cf8, uint8_t offset, uint8_t bytes)
 {
     unsigned long flags;
@@ -43,6 +51,14 @@ uint32_t pci_conf_read(uint32_t cf8, uint8_t offset, uint8_t bytes)
     return value;
 }
 
+/*
+ * called by:
+ *   - arch/x86/pv/emul-priv-op.c|412| <<guest_io_write>> pci_conf_write(currd->arch.pci_cf8, port & 3, size, data);
+ *   - arch/x86/x86_64/pci.c|77| <<pci_conf_write8>> pci_conf_write(PCI_CONF_ADDRESS(bus, dev, func, reg), reg & 3, 1, data);
+ *   - arch/x86/x86_64/pci.c|90| <<pci_conf_write16>> pci_conf_write(PCI_CONF_ADDRESS(bus, dev, func, reg), reg & 2, 2, data);
+ *   - arch/x86/x86_64/pci.c|103| <<pci_conf_write32>> pci_conf_write(PCI_CONF_ADDRESS(bus, dev, func, reg), 0, 4, data);
+ *   - include/xen/pci.h|160| <<pci_conf_write32>> void pci_conf_write(uint32_t cf8, uint8_t offset, uint8_t bytes, uint32_t data);
+ */
 void pci_conf_write(uint32_t cf8, uint8_t offset, uint8_t bytes, uint32_t data)
 {
     unsigned long flags;
@@ -69,6 +85,11 @@ void pci_conf_write(uint32_t cf8, uint8_t offset, uint8_t bytes, uint32_t data)
     spin_unlock_irqrestore(&pci_config_lock, flags);
 }
 
+/*
+ * called by:
+ *   - arch/x86/mm.c|4444| <<mmcfg_intercept_write>> if ( pci_conf_write_intercept(mmio_ctxt->seg, mmio_ctxt->bdf,
+ *   - arch/x86/pv/emul-priv-op.c|216| <<pci_cfg_ok>> pci_conf_write_intercept(0, machine_bdf, start, size, write) >= 0;
+ */
 int pci_conf_write_intercept(unsigned int seg, unsigned int bdf,
                              unsigned int reg, unsigned int size,
                              uint32_t *data)
diff --git a/xen/arch/x86/physdev.c b/xen/arch/x86/physdev.c
index a5fedca..3ab6973 100644
--- a/xen/arch/x86/physdev.c
+++ b/xen/arch/x86/physdev.c
@@ -88,6 +88,12 @@ static int physdev_hvm_map_pirq(
     return ret;
 }
 
+/*
+ * called only by:
+ *   - arch/x86/physdev.c|335| <<XEN_GUEST_HANDLE_PARAM>> ret = physdev_map_pirq(map.domid, map.type, &map.index, &map.pirq,
+ *
+ * 从desktop nvme进来的时候猜测, type=MAP_PIRQ_TYPE_MSI, *index=-1
+ */
 int physdev_map_pirq(domid_t domid, int type, int *index, int *pirq_p,
                      struct msi_info *msi)
 {
@@ -126,6 +132,9 @@ int physdev_map_pirq(domid_t domid, int type, int *index, int *pirq_p,
             msi->entry_nr = 1;
         /* fallthrough */
     case MAP_PIRQ_TYPE_MULTI_MSI:
+        /*
+	 * 上面desktop的nvme进来, 猜测msi->entry_nr每次分别是0, 1, 2, 3, 4, 5, 6, 7
+         */
         ret = allocate_and_map_msi_pirq(d, *index, pirq_p, type, msi);
         break;
 
@@ -313,6 +322,9 @@ ret_t do_physdev_op(int cmd, XEN_GUEST_HANDLE_PARAM(void) arg)
 
         switch ( map.type )
         {
+        /*
+	 * 在desktop nvme上猜测这里应该是MAP_PIRQ_TYPE_MSI_SEG
+	 */
         case MAP_PIRQ_TYPE_MSI_SEG:
             map.type = MAP_PIRQ_TYPE_MSI;
             msi.seg = map.bus >> 16;
@@ -332,6 +344,11 @@ ret_t do_physdev_op(int cmd, XEN_GUEST_HANDLE_PARAM(void) arg)
         msi.devfn = map.devfn;
         msi.entry_nr = map.entry_nr;
         msi.table_base = map.table_base;
+        /*
+	 * 因为上面在desktop nvme上猜测应该是MAP_PIRQ_TYPE_MSI_SEG
+	 *
+	 * 所以上面把map.type换成了MAP_PIRQ_TYPE_MSI, msi.seg包含了seg的信息
+         */
         ret = physdev_map_pirq(map.domid, map.type, &map.index, &map.pirq,
                                &msi);
 
diff --git a/xen/arch/x86/pv/emul-priv-op.c b/xen/arch/x86/pv/emul-priv-op.c
index 2f92645..52b58a1 100644
--- a/xen/arch/x86/pv/emul-priv-op.c
+++ b/xen/arch/x86/pv/emul-priv-op.c
@@ -177,6 +177,11 @@ static bool admin_io_okay(unsigned int port, unsigned int bytes,
     return ioports_access_permitted(d, port, port + bytes - 1);
 }
 
+/*
+ * called by:
+ *   - arch/x86/pv/emul-priv-op.c|268| <<guest_io_read>> if ( pci_cfg_ok(currd, port & 3, size, NULL) )
+ *   - arch/x86/pv/emul-priv-op.c|406| <<guest_io_write>> if ( pci_cfg_ok(currd, port & 3, size, &data) )
+ */
 static bool pci_cfg_ok(struct domain *currd, unsigned int start,
                        unsigned int size, uint32_t *write)
 {
diff --git a/xen/common/irq.c b/xen/common/irq.c
index f42512d..1eadfc7 100644
--- a/xen/common/irq.c
+++ b/xen/common/irq.c
@@ -5,6 +5,7 @@ int init_one_irq_desc(struct irq_desc *desc)
 {
     int err;
 
+    /* 如果(desc)->handler != NULL */
     if (irq_desc_initialized(desc))
         return 0;
 
diff --git a/xen/drivers/passthrough/io.c b/xen/drivers/passthrough/io.c
index 8f16e6c..47a4934 100644
--- a/xen/drivers/passthrough/io.c
+++ b/xen/drivers/passthrough/io.c
@@ -275,6 +275,11 @@ static struct vcpu *vector_hashing_dest(const struct domain *d,
     return dest;
 }
 
+/*
+ * called by:
+ *   - arch/x86/domctl.c|729| <<arch_do_domctl()::XEN_DOMCTL_bind_pt_irq>> ret = pt_irq_create_bind(d, bind);
+ *   - arch/x86/hvm/vioapic.c|193| <<vioapic_hwdom_map_gsi>> ret = pt_irq_create_bind(currd, &pt_irq_bind);
+ */
 int pt_irq_create_bind(
     struct domain *d, const struct xen_domctl_bind_pt_irq *pt_irq_bind)
 {
@@ -795,6 +800,10 @@ int pt_pirq_iterate(struct domain *d,
     return rc;
 }
 
+/*
+ * called by only:
+ *   - arch/x86/irq.c|1340| <<__do_IRQ_guest>> if ( !is_hvm_domain(d) || !hvm_do_IRQ_dpci(d, pirq) )
+ */
 int hvm_do_IRQ_dpci(struct domain *d, struct pirq *pirq)
 {
     struct hvm_irq_dpci *dpci = domain_get_irq_dpci(d);
@@ -812,6 +821,11 @@ int hvm_do_IRQ_dpci(struct domain *d, struct pirq *pirq)
 }
 
 /* called with d->event_lock held */
+/*
+ * called by:
+ *   - drivers/passthrough/io.c|847| <<_hvm_dpci_msi_eoi>> __msi_pirq_eoi(pirq_dpci);
+ *   - drivers/passthrough/io.c|913| <<hvm_dirq_assist>> __msi_pirq_eoi(pirq_dpci);
+ */
 static void __msi_pirq_eoi(struct hvm_pirq_dpci *pirq_dpci)
 {
     irq_desc_t *desc;
@@ -829,6 +843,10 @@ static void __msi_pirq_eoi(struct hvm_pirq_dpci *pirq_dpci)
     }
 }
 
+/*
+ * called by:
+ *   - drivers/passthrough/io.c|861| <<hvm_dpci_msi_eoi>> pt_pirq_iterate(d, _hvm_dpci_msi_eoi, (void *)(long )vector);
+ */
 static int _hvm_dpci_msi_eoi(struct domain *d,
                              struct hvm_pirq_dpci *pirq_dpci, void *arg)
 {
@@ -852,6 +870,10 @@ static int _hvm_dpci_msi_eoi(struct domain *d,
     return 0;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vlapic.c|440| <<vlapic_handle_EOI>> hvm_dpci_msi_eoi(d, vector);
+ */
 void hvm_dpci_msi_eoi(struct domain *d, int vector)
 {
     if ( !iommu_enabled || !hvm_domain_irq(d)->dpci )
@@ -862,6 +884,10 @@ void hvm_dpci_msi_eoi(struct domain *d, int vector)
     spin_unlock(&d->event_lock);
 }
 
+/*
+ * called by:
+ *   - drivers/passthrough/io.c|1074| <<dpci_softirq>> hvm_dirq_assist(d, pirq_dpci);
+ */
 static void hvm_dirq_assist(struct domain *d, struct hvm_pirq_dpci *pirq_dpci)
 {
     if ( unlikely(!hvm_domain_irq(d)->dpci) && !is_hardware_domain(d) )
diff --git a/xen/include/asm-x86/hvm/domain.h b/xen/include/asm-x86/hvm/domain.h
index 7f128c0..dbbcd02 100644
--- a/xen/include/asm-x86/hvm/domain.h
+++ b/xen/include/asm-x86/hvm/domain.h
@@ -162,6 +162,16 @@ struct hvm_domain {
     bool_t                 is_in_uc_mode;
 
     /* hypervisor intercepted msix table */
+    /*
+     * used by:
+     *   - arch/x86/hvm/vmsi.c|174| <<msixtbl_initialised>> return !!d->arch.hvm_domain.msixtbl_list.next;
+     *   - arch/x86/hvm/vmsi.c|183| <<msixtbl_find_entry>> list_for_each_entry( entry, &d->arch.hvm_domain.msixtbl_list, list )
+     *   - arch/x86/hvm/vmsi.c|445| <<add_msixtbl_entry>> list_add_rcu(&entry->list, &d->arch.hvm_domain.msixtbl_list);
+     *   - arch/x86/hvm/vmsi.c|498| <<msixtbl_pt_register>> list_for_each_entry( entry, &d->arch.hvm_domain.msixtbl_list, list )
+     *   - arch/x86/hvm/vmsi.c|557| <<msixtbl_pt_unregister>> list_for_each_entry( entry, &d->arch.hvm_domain.msixtbl_list, list )
+     *   - arch/x86/hvm/vmsi.c|583| <<msixtbl_init>> INIT_LIST_HEAD(&d->arch.hvm_domain.msixtbl_list);
+     *   - arch/x86/hvm/vmsi.c|603| <<msixtbl_pt_cleanup>> &d->arch.hvm_domain.msixtbl_list, list )
+     */
     struct list_head       msixtbl_list;
 
     struct viridian_domain viridian;
diff --git a/xen/include/asm-x86/mach-generic/mach_apic.h b/xen/include/asm-x86/mach-generic/mach_apic.h
index 03e9e8a..c7ba8f5 100644
--- a/xen/include/asm-x86/mach-generic/mach_apic.h
+++ b/xen/include/asm-x86/mach-generic/mach_apic.h
@@ -16,6 +16,11 @@
 #define init_apic_ldr (genapic->init_apic_ldr)
 #define clustered_apic_check (genapic->clustered_apic_check) 
 #define cpu_mask_to_apicid (genapic->cpu_mask_to_apicid)
+/*
+ * 设置genapic的地方:
+ *   - xen/arch/x86/apic.c|945| <<x2apic_bsp_setup>> genapic = apic_x2apic_probe();
+ *   - xen/arch/x86/apic.c|946| <<x2apic_bsp_setup>> printk("Switched to APIC driver %s.\n", genapic->name);
+ */
 #define vector_allocation_cpumask(cpu) (genapic->vector_allocation_cpumask(cpu))
 
 static inline void enable_apic_mode(void)
diff --git a/xen/include/xen/pci.h b/xen/include/xen/pci.h
index 43f2125..b4f27b9 100644
--- a/xen/include/xen/pci.h
+++ b/xen/include/xen/pci.h
@@ -55,6 +55,11 @@ struct pci_dev {
     struct list_head alldevs_list;
     struct list_head domain_list;
 
+    /*
+     * 在以下添加:
+     *   - arch/x86/msi.c|750| <<msi_capability_init>> list_add_tail(&entry->list, &dev->msi_list);
+     *   - arch/x86/msi.c|990| <<msix_capability_init>> list_add_tail(&entry->list, &dev->msi_list);
+     */
     struct list_head msi_list;
 
     struct arch_msix *msix;
-- 
2.7.4

