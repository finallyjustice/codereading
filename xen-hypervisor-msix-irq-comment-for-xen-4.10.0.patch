From 06d25a75c8c5bc00bbf2f27cb7e1f56bbf71d57e Mon Sep 17 00:00:00 2001
From: Dongli Zhang <dongli.zhang0129@gmail.com>
Date: Wed, 30 Oct 2019 16:17:43 +0800
Subject: [PATCH 1/1] xen hypervisor msix irq comment for xen-4.10.0

xen-4.10.0

Signed-off-by: Dongli Zhang <dongli.zhang0129@gmail.com>
---
 tools/libxl/libxl_pci.c                      |   4 +
 tools/qemu-xen-traditional/hw/pass-through.c |   8 ++
 tools/qemu-xen-traditional/hw/piix4acpi.c    |   4 +
 tools/qemu-xen-traditional/i386-dm/helper2.c |  29 ++++
 tools/qemu-xen-traditional/xen-vl-extra.c    |   5 +
 tools/qemu-xen-traditional/xenstore.c        |   9 ++
 tools/qemu-xen/hw/i386/xen/xen-hvm.c         |  49 +++++++
 tools/qemu-xen/hw/xen/xen_pt_msi.c           |  29 ++++
 xen/arch/x86/domain.c                        |  23 ++++
 xen/arch/x86/domain_page.c                   |  88 ++++++++++++
 xen/arch/x86/hvm/emulate.c                   |  45 +++++++
 xen/arch/x86/hvm/hvm.c                       |   6 +
 xen/arch/x86/hvm/intercept.c                 |  37 +++++
 xen/arch/x86/hvm/ioreq.c                     |  19 +++
 xen/arch/x86/hvm/irq.c                       |   9 ++
 xen/arch/x86/hvm/vioapic.c                   |  57 ++++++++
 xen/arch/x86/hvm/vlapic.c                    | 195 +++++++++++++++++++++++++++
 xen/arch/x86/hvm/vmsi.c                      | 125 +++++++++++++++++
 xen/arch/x86/hvm/vmx/intr.c                  |  14 ++
 xen/arch/x86/hvm/vmx/vmcs.c                  |  10 ++
 xen/arch/x86/hvm/vmx/vmx.c                   |  73 ++++++++++
 xen/arch/x86/io_apic.c                       |  20 +++
 xen/arch/x86/irq.c                           | 171 +++++++++++++++++++++++
 xen/arch/x86/mm.c                            |  17 +++
 xen/arch/x86/msi.c                           |  29 ++++
 xen/arch/x86/pci.c                           |  21 +++
 xen/arch/x86/physdev.c                       |  17 +++
 xen/arch/x86/pv/emul-priv-op.c               |   5 +
 xen/arch/x86/traps.c                         |  12 ++
 xen/arch/x86/x86_emulate/x86_emulate.h       |   9 ++
 xen/common/domain.c                          |   8 ++
 xen/common/grant_table.c                     |  47 +++++++
 xen/common/irq.c                             |   1 +
 xen/common/memory.c                          |   6 +
 xen/common/page_alloc.c                      |  55 ++++++++
 xen/drivers/passthrough/io.c                 |  53 ++++++++
 xen/include/asm-x86/config.h                 |   8 ++
 xen/include/asm-x86/domain.h                 |   8 ++
 xen/include/asm-x86/hvm/domain.h             |  10 ++
 xen/include/asm-x86/hvm/hvm.h                |  11 ++
 xen/include/asm-x86/hvm/irq.h                |  21 +++
 xen/include/asm-x86/hvm/vlapic.h             |  17 +++
 xen/include/asm-x86/hvm/vmx/vmcs.h           |  23 ++++
 xen/include/asm-x86/hvm/vmx/vmx.h            |   6 +
 xen/include/asm-x86/mach-generic/mach_apic.h |   5 +
 xen/include/asm-x86/page.h                   |   8 ++
 xen/include/public/arch-x86/hvm/save.h       |  14 ++
 xen/include/public/arch-x86/xen.h            |   8 ++
 xen/include/xen/event.h                      |   8 ++
 xen/include/xen/pci.h                        |   5 +
 xen/include/xen/sched.h                      |  37 +++++
 51 files changed, 1498 insertions(+)

diff --git a/tools/libxl/libxl_pci.c b/tools/libxl/libxl_pci.c
index 88a55ce..c259730 100644
--- a/tools/libxl/libxl_pci.c
+++ b/tools/libxl/libxl_pci.c
@@ -938,6 +938,10 @@ static int pci_ins_check(libxl__gc *gc, uint32_t domid, const char *state, void
     return 1;
 }
 
+/*
+ * called by:
+ *   - libxl/libxl_pci.c|1005| <<do_pci_add>> rc = qemu_pci_add_xenstore(gc, domid, pcidev);
+ */
 static int qemu_pci_add_xenstore(libxl__gc *gc, uint32_t domid,
                                  libxl_device_pci *pcidev)
 {
diff --git a/tools/qemu-xen-traditional/hw/pass-through.c b/tools/qemu-xen-traditional/hw/pass-through.c
index 0b76585..0371795 100644
--- a/tools/qemu-xen-traditional/hw/pass-through.c
+++ b/tools/qemu-xen-traditional/hw/pass-through.c
@@ -4339,6 +4339,10 @@ static int pt_intel_opregion_write(struct pt_dev *ptdev,
     return 0;
 }
 
+/*
+ * called by:
+ *   - hw/pass-through.c|4613| <<power_on_php_devfn>> register_real_device(dpci_infos.e_bus,
+ */
 static struct pt_dev * register_real_device(PCIBus *e_bus,
         const char *e_dev_name, int e_devfn, uint8_t r_bus, uint8_t r_dev,
         uint8_t r_func, uint32_t machine_irq, struct pci_access *pci_access,
@@ -4602,6 +4606,10 @@ static int unregister_real_device(int devfn)
     return 0;
 }
 
+/*
+ * called by only:
+ *   - hw/piix4acpi.c|714| <<acpi_php_add>> power_on_php_devfn(devfn);
+ */
 int power_on_php_devfn(int devfn)
 {
     struct php_dev *php_dev = &dpci_infos.php_devs[devfn];
diff --git a/tools/qemu-xen-traditional/hw/piix4acpi.c b/tools/qemu-xen-traditional/hw/piix4acpi.c
index ddbe8e0..0d8cb47 100644
--- a/tools/qemu-xen-traditional/hw/piix4acpi.c
+++ b/tools/qemu-xen-traditional/hw/piix4acpi.c
@@ -668,6 +668,10 @@ void acpi_php_del(int devfn)
     acpi_sci_intr(s);
 }
 
+/*
+ * called by:
+ *   - xen-vl-extra.c|129| <<do_pci_add>> acpi_php_add(devfn);
+ */
 void acpi_php_add(int devfn)
 {
     GPEState *s = &gpe_state;
diff --git a/tools/qemu-xen-traditional/i386-dm/helper2.c b/tools/qemu-xen-traditional/i386-dm/helper2.c
index 78093fe..c3ce163 100644
--- a/tools/qemu-xen-traditional/i386-dm/helper2.c
+++ b/tools/qemu-xen-traditional/i386-dm/helper2.c
@@ -105,6 +105,18 @@ buffered_iopage_t *buffered_io_page = NULL;
 QEMUTimer *buffered_io_timer;
 
 /* the evtchn fd for polling */
+/*
+ * used by:
+ *   - i386-dm/helper2.c|145| <<cpu_x86_init>> xce_handle = xenevtchn_open(NULL, 0);
+ *   - i386-dm/helper2.c|146| <<cpu_x86_init>> if (xce_handle == NULL) {
+ *   - i386-dm/helper2.c|154| <<cpu_x86_init>> xce_handle, domid, shared_page->vcpu_ioreq[i].vp_eport);
+ *   - i386-dm/helper2.c|168| <<cpu_x86_init>> rc = xenevtchn_bind_interdomain(xce_handle, domid, (uint32_t)bufioreq_evtchn);
+ *   - i386-dm/helper2.c|282| <<cpu_get_ioreq>> port = xenevtchn_pending(xce_handle);
+ *   - i386-dm/helper2.c|300| <<cpu_get_ioreq>> xenevtchn_unmask(xce_handle, port);
+ *   - i386-dm/helper2.c|556| <<handle_buffered_io>> xenevtchn_unmask(xce_handle, bufioreq_local_port);
+ *   - i386-dm/helper2.c|604| <<cpu_handle_ioreq>> xenevtchn_notify(xce_handle, ioreq_local_port[send_vcpu]);
+ *   - i386-dm/helper2.c|613| <<main_loop>> int evtchn_fd = xce_handle == NULL ? -1 : xenevtchn_fd(xce_handle);
+ */
 xenevtchn_handle *xce_handle = NULL;
 
 /* which vcpu we are serving */
@@ -274,6 +286,10 @@ static ioreq_t *__cpu_get_ioreq(int vcpu)
 //use poll to get the port notification
 //ioreq_vec--out,the
 //retval--the number of ioreq packet
+/*
+ * called by:
+ *   - i386-dm/helper2.c|564| <<cpu_handle_ioreq>> ioreq_t *req = cpu_get_ioreq();
+ */
 static ioreq_t *cpu_get_ioreq(void)
 {
     int i;
@@ -544,6 +560,11 @@ static int __handle_buffered_iopage(CPUState *env)
     return req.count;
 }
 
+/*
+ * called by:
+ *   - i386-dm/helper2.c|619| <<main_loop>> buffered_io_timer = qemu_new_timer(rt_clock, handle_buffered_io,
+ *   - i386-dm/helper2.c|643| <<main_loop>> handle_buffered_io(env);
+ */
 static void handle_buffered_io(void *opaque)
 {
     CPUState *env = opaque;
@@ -557,6 +578,10 @@ static void handle_buffered_io(void *opaque)
     }
 }
 
+/*
+ * called by:
+ *   - i386-dm/helper2.c|623| <<main_loop>> qemu_set_fd_handler(evtchn_fd, cpu_handle_ioreq, NULL, env);
+ */
 static void cpu_handle_ioreq(void *opaque)
 {
     extern int shutdown_requested;
@@ -607,6 +632,10 @@ static void cpu_handle_ioreq(void *opaque)
 
 int xen_pause_requested;
 
+/*
+ * called by:
+ *   - vl.c|6221| <<main>> main_loop();
+ */
 int main_loop(void)
 {
     CPUState *env = cpu_single_env;
diff --git a/tools/qemu-xen-traditional/xen-vl-extra.c b/tools/qemu-xen-traditional/xen-vl-extra.c
index 206ac65..63e8e90 100644
--- a/tools/qemu-xen-traditional/xen-vl-extra.c
+++ b/tools/qemu-xen-traditional/xen-vl-extra.c
@@ -120,6 +120,11 @@ void do_pci_del(char *devname)
     free(devname_cpy);
 }
 
+/*
+ * used by:
+ *   - monitor.c|1548| <<global>> { "pci_add", "s", do_pci_add,
+ *   - xenstore.c|919| <<xenstore_process_dm_command_event>> do_pci_add(par);
+ */
 void do_pci_add(char *devname)
 {
     int devfn;
diff --git a/tools/qemu-xen-traditional/xenstore.c b/tools/qemu-xen-traditional/xenstore.c
index 8af2715..2c050af 100644
--- a/tools/qemu-xen-traditional/xenstore.c
+++ b/tools/qemu-xen-traditional/xenstore.c
@@ -843,6 +843,10 @@ out:
 
 
 /* Accept state change commands from the control tools */
+/*
+ * called by:
+ *   - xenstore.c|1088| <<xenstore_process_event>> xenstore_process_dm_command_event();
+ */
 static void xenstore_process_dm_command_event(void)
 {
     char *path = NULL, *command = NULL, *par = NULL;
@@ -1074,6 +1078,11 @@ static void xenstore_process_vcpu_set_event(char **vec)
     return;
 }
 
+/*
+ * 在以下使用:
+ *   - i386-dm/helper2.c|627| <<main_loop>> qemu_set_fd_handler(xenstore_fd(), xenstore_process_event, NULL, NULL);
+ *   - i386-dm/helper2.c|658| <<main_loop>> xenstore_process_event(NULL);
+ */
 void xenstore_process_event(void *opaque)
 {
     char **vec, *offset, *bpath = NULL, *buf = NULL, *drv = NULL, *image = NULL;
diff --git a/tools/qemu-xen/hw/i386/xen/xen-hvm.c b/tools/qemu-xen/hw/i386/xen/xen-hvm.c
index d9ccd5d..8973d31 100644
--- a/tools/qemu-xen/hw/i386/xen/xen-hvm.c
+++ b/tools/qemu-xen/hw/i386/xen/xen-hvm.c
@@ -94,8 +94,21 @@ typedef struct XenIOState {
     QEMUTimer *buffered_io_timer;
     CPUState **cpu_by_vcpu_id;
     /* the evtchn port for polling the notification, */
+    /*
+     * used by:
+     *   - hw/i386/xen/xen-hvm.c|738| <<cpu_get_ioreq>> if (state->ioreq_local_port[i] == port) {
+     *   - hw/i386/xen/xen-hvm.c|1156| <<cpu_handle_ioreq>> state->ioreq_local_port[state->send_vcpu]);
+     *   - hw/i386/xen/xen-hvm.c|1364| <<xen_hvm_init>> state->ioreq_local_port = g_malloc0(max_cpus * sizeof (evtchn_port_t));
+     *   - hw/i386/xen/xen-hvm.c|1374| <<xen_hvm_init>> state->ioreq_local_port[i] = rc;
+     */
     evtchn_port_t *ioreq_local_port;
     /* evtchn local port for buffered io */
+    /*
+     * used by:
+     *   - hw/i386/xen/xen-hvm.c|730| <<cpu_get_ioreq>> if (port == state->bufioreq_local_port) {
+     *   - hw/i386/xen/xen-hvm.c|1089| <<handle_buffered_io>> xenevtchn_unmask(state->xce_handle, state->bufioreq_local_port);
+     *   - hw/i386/xen/xen-hvm.c|1383| <<xen_hvm_init>> state->bufioreq_local_port = rc;
+     */
     evtchn_port_t bufioreq_local_port;
     /* the evtchn fd for polling */
     xenevtchn_handle *xce_handle;
@@ -942,6 +955,20 @@ static void handle_vmport_ioreq(XenIOState *state, ioreq_t *req)
     current_cpu = NULL;
 }
 
+/*
+ * (gdb) bt
+ * #0  handle_ioreq (state=state@entry=0x55e009e82fd0, req=req@entry=0x7ffdfcd1f820) at /home/zhang/xen/xen-4.10.0-build/tools/qemu-xen/hw/i386/xen/xen-hvm.c:946
+ * #1  0x000055e008fd7079 in cpu_handle_ioreq (opaque=0x55e009e82fd0) at /home/zhang/xen/xen-4.10.0-build/tools/qemu-xen/hw/i386/xen/xen-hvm.c:1089
+ * #2  0x000055e0092a65bc in aio_dispatch_handlers (ctx=ctx@entry=0x55e009e51a90) at /home/zhang/xen/xen-4.10.0-build/tools/qemu-xen/util/aio-posix.c:399
+ * #3  0x000055e0092a6e48 in aio_dispatch (ctx=0x55e009e51a90) at /home/zhang/xen/xen-4.10.0-build/tools/qemu-xen/util/aio-posix.c:430
+ * #4  0x000055e0092a3d9e in aio_ctx_dispatch (source=<optimized out>, callback=<optimized out>, user_data=<optimized out>) at /home/zhang/xen/xen-4.10.0-build/tools/qemu-xen/util/async.c:261
+ * #5  0x00007f8e2c992197 in g_main_context_dispatch () from /lib/x86_64-linux-gnu/libglib-2.0.so.0
+ * #6  0x000055e0092a5fb3 in glib_pollfds_poll () at /home/zhang/xen/xen-4.10.0-build/tools/qemu-xen/util/main-loop.c:257
+ * #7  os_host_main_loop_wait (timeout=<optimized out>) at /home/zhang/xen/xen-4.10.0-build/tools/qemu-xen/util/main-loop.c:307
+ * #8  main_loop_wait (nonblocking=<optimized out>) at /home/zhang/xen/xen-4.10.0-build/tools/qemu-xen/util/main-loop.c:563
+ * #9  0x000055e008f14a47 in main_loop () at /home/zhang/xen/xen-4.10.0-build/tools/qemu-xen/vl.c:1917
+ * #10 main (argc=<optimized out>, argv=<optimized out>, envp=<optimized out>) at /home/zhang/xen/xen-4.10.0-build/tools/qemu-xen/vl.c:4795
+ */
 static void handle_ioreq(XenIOState *state, ioreq_t *req)
 {
     trace_handle_ioreq(req, req->type, req->dir, req->df, req->data_is_ptr,
@@ -1076,6 +1103,23 @@ static void handle_buffered_io(void *opaque)
     }
 }
 
+/*
+ * (gdb) bt
+ * #0  handle_ioreq (state=state@entry=0x55e009e82fd0, req=req@entry=0x7ffdfcd1f820) at /home/zhang/xen/xen-4.10.0-build/tools/qemu-xen/hw/i386/xen/xen-hvm.c:946
+ * #1  0x000055e008fd7079 in cpu_handle_ioreq (opaque=0x55e009e82fd0) at /home/zhang/xen/xen-4.10.0-build/tools/qemu-xen/hw/i386/xen/xen-hvm.c:1089
+ * #2  0x000055e0092a65bc in aio_dispatch_handlers (ctx=ctx@entry=0x55e009e51a90) at /home/zhang/xen/xen-4.10.0-build/tools/qemu-xen/util/aio-posix.c:399
+ * #3  0x000055e0092a6e48 in aio_dispatch (ctx=0x55e009e51a90) at /home/zhang/xen/xen-4.10.0-build/tools/qemu-xen/util/aio-posix.c:430
+ * #4  0x000055e0092a3d9e in aio_ctx_dispatch (source=<optimized out>, callback=<optimized out>, user_data=<optimized out>) at /home/zhang/xen/xen-4.10.0-build/tools/qemu-xen/util/async.c:261
+ * #5  0x00007f8e2c992197 in g_main_context_dispatch () from /lib/x86_64-linux-gnu/libglib-2.0.so.0
+ * #6  0x000055e0092a5fb3 in glib_pollfds_poll () at /home/zhang/xen/xen-4.10.0-build/tools/qemu-xen/util/main-loop.c:257
+ * #7  os_host_main_loop_wait (timeout=<optimized out>) at /home/zhang/xen/xen-4.10.0-build/tools/qemu-xen/util/main-loop.c:307
+ * #8  main_loop_wait (nonblocking=<optimized out>) at /home/zhang/xen/xen-4.10.0-build/tools/qemu-xen/util/main-loop.c:563
+ * #9  0x000055e008f14a47 in main_loop () at /home/zhang/xen/xen-4.10.0-build/tools/qemu-xen/vl.c:1917
+ * #10 main (argc=<optimized out>, argv=<optimized out>, envp=<optimized out>) at /home/zhang/xen/xen-4.10.0-build/tools/qemu-xen/vl.c:4795
+ *
+ * used by:
+ *   - hw/i386/xen/xen-hvm.c|1149| <<xen_main_loop_prepare>> qemu_set_fd_handler(evtchn_fd, cpu_handle_ioreq, NULL, state);
+ */
 static void cpu_handle_ioreq(void *opaque)
 {
     XenIOState *state = opaque;
@@ -1232,6 +1276,11 @@ static void xen_wakeup_notifier(Notifier *notifier, void *data)
     xc_set_hvm_param(xen_xc, xen_domid, HVM_PARAM_ACPI_S_STATE, 0);
 }
 
+/*
+ * called by:
+ *   - hw/i386/pc_piix.c|122| <<pc_init1>> xen_hvm_init(pcms, &ram_memory);
+ *   - hw/i386/pc_q35.c|119| <<pc_q35_init>> xen_hvm_init(pcms, &ram_memory)
+ */
 void xen_hvm_init(PCMachineState *pcms, MemoryRegion **ram_memory)
 {
     int i, rc;
diff --git a/tools/qemu-xen/hw/xen/xen_pt_msi.c b/tools/qemu-xen/hw/xen/xen_pt_msi.c
index 6d1e3bd..ed7ab12 100644
--- a/tools/qemu-xen/hw/xen/xen_pt_msi.c
+++ b/tools/qemu-xen/hw/xen/xen_pt_msi.c
@@ -436,6 +436,35 @@ static void set_entry_value(XenPTMSIXEntry *e, int offset, uint32_t val)
     e->latch[offset / sizeof(*e->latch)] = val;
 }
 
+/*
+ * (gdb) bt
+ * #0  pci_msix_write (opaque=0x556af1c22310, addr=0, val=0, size=4) at /home/zhang/xen/xen-4.10.0/tools/qemu-xen/hw/xen/xen_pt_msi.c:441
+ * #1  0x0000556aee6b2d78 in memory_region_write_accessor (mr=0x556af1a4ed50, addr=0, value=<optimized out>, size=4, shift=<optimized out>, mask=<optimized out>, attrs=...)
+ *     at /home/zhang/xen/xen-4.10.0/tools/qemu-xen/memory.c:529
+ * #2  0x0000556aee6b093d in access_with_adjusted_size (addr=addr@entry=0, value=value@entry=0x7ffd64ef9608, size=size@entry=4, access_size_min=<optimized out>, access_size_max=<optimized out>, 
+ *     access=0x556aee6b2d00 <memory_region_write_accessor>, mr=0x556af1a4ed50, attrs=...) at /home/zhang/xen/xen-4.10.0/tools/qemu-xen/memory.c:595
+ * #3  0x0000556aee6b4ba6 in memory_region_dispatch_write (mr=mr@entry=0x556af1a4ed50, addr=0, data=0, size=size@entry=4, attrs=..., attrs@entry=...) at /home/zhang/xen/xen-4.10.0/tools/qemu-xen/memory.c:1350
+ * #4  0x0000556aee66e441 in address_space_write_continue (mr=0x556af1a4ed50, l=4, addr1=0, len=4, buf=0x7ffd64ef9788 "", attrs=..., addr=4077977600, as=0x556aeeffacc0 <address_space_memory>)
+ *     at /home/zhang/xen/xen-4.10.0/tools/qemu-xen/exec.c:2930
+ * #5  address_space_write (as=<optimized out>, addr=<optimized out>, attrs=..., buf=<optimized out>, len=<optimized out>) at /home/zhang/xen/xen-4.10.0/tools/qemu-xen/exec.c:2987
+ * #6  0x0000556aee66e99d in address_space_rw (as=as@entry=0x556aeeffacc0 <address_space_memory>, addr=<optimized out>, attrs=..., attrs@entry=..., buf=buf@entry=0x7ffd64ef9788 "", len=<optimized out>, 
+ *     is_write=<optimized out>) at /home/zhang/xen/xen-4.10.0/tools/qemu-xen/exec.c:3089
+ * #7  0x0000556aee66e9c7 in cpu_physical_memory_rw (addr=<optimized out>, buf=buf@entry=0x7ffd64ef9788 "", len=<optimized out>, is_write=is_write@entry=1) at /home/zhang/xen/xen-4.10.0/tools/qemu-xen/exec.c:3098
+ * #8  0x0000556aee72578c in rw_phys_req_item (rw=1, val=0x7ffd64ef9788, i=0, req=0x7ffd64ef9780, addr=<optimized out>) at /home/zhang/xen/xen-4.10.0/tools/qemu-xen/hw/i386/xen/xen-hvm.c:809
+ * #9  write_phys_req_item (val=0x7ffd64ef9788, i=0, req=0x7ffd64ef9780, addr=<optimized out>) at /home/zhang/xen/xen-4.10.0/tools/qemu-xen/hw/i386/xen/xen-hvm.c:820
+ * #10 cpu_ioreq_move (req=<optimized out>) at /home/zhang/xen/xen-4.10.0/tools/qemu-xen/hw/i386/xen/xen-hvm.c:882
+ * #11 handle_ioreq (state=state@entry=0x556af0549000, req=req@entry=0x7ffd64ef9780) at /home/zhang/xen/xen-4.10.0/tools/qemu-xen/hw/i386/xen/xen-hvm.c:964
+ * #12 0x0000556aee727679 in cpu_handle_ioreq (opaque=0x556af0549000) at /home/zhang/xen/xen-4.10.0/tools/qemu-xen/hw/i386/xen/xen-hvm.c:1089
+ * #13 0x0000556aee9e05dc in aio_dispatch_handlers (ctx=ctx@entry=0x556af0524ec0) at /home/zhang/xen/xen-4.10.0/tools/qemu-xen/util/aio-posix.c:399
+ * #14 0x0000556aee9e0e68 in aio_dispatch (ctx=0x556af0524ec0) at /home/zhang/xen/xen-4.10.0/tools/qemu-xen/util/aio-posix.c:430
+ * #15 0x0000556aee9dddbe in aio_ctx_dispatch (source=<optimized out>, callback=<optimized out>, user_data=<optimized out>) at /home/zhang/xen/xen-4.10.0/tools/qemu-xen/util/async.c:261
+ * #16 0x00007fc0d9d6a197 in g_main_context_dispatch () from /lib/x86_64-linux-gnu/libglib-2.0.so.0
+ * #17 0x0000556aee9dffd3 in glib_pollfds_poll () at /home/zhang/xen/xen-4.10.0/tools/qemu-xen/util/main-loop.c:257
+ * #18 os_host_main_loop_wait (timeout=<optimized out>) at /home/zhang/xen/xen-4.10.0/tools/qemu-xen/util/main-loop.c:307
+ * #19 main_loop_wait (nonblocking=<optimized out>) at /home/zhang/xen/xen-4.10.0/tools/qemu-xen/util/main-loop.c:563
+ * #20 0x0000556aee665177 in main_loop () at /home/zhang/xen/xen-4.10.0/tools/qemu-xen/vl.c:1917
+ * #21 main (argc=<optimized out>, argv=<optimized out>, envp=<optimized out>) at /home/zhang/xen/xen-4.10.0/tools/qemu-xen/vl.c:4795
+ */
 static void pci_msix_write(void *opaque, hwaddr addr,
                            uint64_t val, unsigned size)
 {
diff --git a/xen/arch/x86/domain.c b/xen/arch/x86/domain.c
index 735f45c..a061def 100644
--- a/xen/arch/x86/domain.c
+++ b/xen/arch/x86/domain.c
@@ -156,6 +156,10 @@ static void noreturn continue_idle_domain(struct vcpu *v)
     reset_stack_and_jump(idle_loop);
 }
 
+/*
+ * called by:
+ *   - common/keyhandler.c|325| <<dump_domains>> dump_pageframe_info(d);
+ */
 void dump_pageframe_info(struct domain *d)
 {
     struct page_info *page;
@@ -573,6 +577,11 @@ int arch_domain_create(struct domain *d, unsigned int domcr_flags,
     return rc;
 }
 
+/*
+ * x86调用的例子:
+ *   - common/domain.c|408| <<domain_create>> arch_domain_destroy(d);
+ *   - common/domain.c|817| <<complete_domain_destroy>> arch_domain_destroy(d);
+ */
 void arch_domain_destroy(struct domain *d)
 {
     if ( is_hvm_domain(d) )
@@ -1792,6 +1801,13 @@ void sync_vcpu_execstate(struct vcpu *v)
     flush_tlb_mask(v->vcpu_dirty_cpumask);
 }
 
+/*
+ * called by:
+ *   - arch/x86/domain.c|1981| <<domain_relinquish_resources>> ret = relinquish_memory(d, &d->xenpage_list, ~0UL);
+ *   - arch/x86/domain.c|1988| <<domain_relinquish_resources>> ret = relinquish_memory(d, &d->page_list, PGT_l4_page_table);
+ *   - arch/x86/domain.c|1995| <<domain_relinquish_resources>> ret = relinquish_memory(d, &d->page_list, PGT_l3_page_table);
+ *   - arch/x86/domain.c|2002| <<domain_relinquish_resources>> ret = relinquish_memory(d, &d->page_list, PGT_l2_page_table);
+ */
 static int relinquish_memory(
     struct domain *d, struct page_list_head *list, unsigned long type)
 {
@@ -1802,6 +1818,9 @@ static int relinquish_memory(
     /* Use a recursive lock, as we may enter 'free_domheap_page'. */
     spin_lock_recursive(&d->page_alloc_lock);
 
+    /*
+     * page_list_remove_head()会移除page
+     */
     while ( (page = page_list_remove_head(list)) )
     {
         /* Grab a reference to the page so it won't disappear from under us. */
@@ -1902,6 +1921,10 @@ static int relinquish_memory(
     return ret;
 }
 
+/*
+ * called by:
+ *   - common/domain.c|633| <<domain_kill>> rc = domain_relinquish_resources(d);
+ */
 int domain_relinquish_resources(struct domain *d)
 {
     int ret;
diff --git a/xen/arch/x86/domain_page.c b/xen/arch/x86/domain_page.c
index 3432a85..e4a4710 100644
--- a/xen/arch/x86/domain_page.c
+++ b/xen/arch/x86/domain_page.c
@@ -57,11 +57,21 @@ static inline struct vcpu *mapcache_current_vcpu(void)
     return v;
 }
 
+/*
+ * called by:
+ *   - arch/x86/pv/dom0_build.c|704| <<dom0_construct_pv>> mapcache_override_current(v);
+ *   - arch/x86/pv/dom0_build.c|723| <<dom0_construct_pv>> mapcache_override_current(NULL);
+ *   - arch/x86/pv/dom0_build.c|844| <<dom0_construct_pv>> mapcache_override_current(NULL);
+ */
 void __init mapcache_override_current(struct vcpu *v)
 {
     this_cpu(override) = v;
 }
 
+/*
+ * 只在下面的MAPCACHE_L2_ENTRIES()使用
+ *   - arch/x86/domain_page.c|66| <<MAPCACHE_L2_ENTRIES>> #define MAPCACHE_L2_ENTRIES (mapcache_l2_entry(MAPCACHE_ENTRIES - 1) + 1)
+ */
 #define mapcache_l2_entry(e) ((e) >> PAGETABLE_ORDER)
 #define MAPCACHE_L2_ENTRIES (mapcache_l2_entry(MAPCACHE_ENTRIES - 1) + 1)
 #define MAPCACHE_L1ENT(idx) \
@@ -85,7 +95,30 @@ void *map_domain_page(mfn_t mfn)
     if ( !v || !is_pv_vcpu(v) )
         return mfn_to_virt(mfn_x(mfn));
 
+    /*
+     * struct vcpu
+     *  -> struct domain *domain;
+     *      -> struct arch_domain arch;
+     *          -> union
+     *              -> struct pv_domain pv_domain;
+     *                  -> struct mapcache_domain mapcache;
+     *              -> struct hvm_domain hvm_domain;
+     */
     dcache = &v->domain->arch.pv_domain.mapcache;
+    /*
+     * struct vcpu
+     *  -> struct arch_vcpu arch;
+     *      -> union
+     *          -> struct pv_vcpu pv_vcpu;
+     *              -> struct mapcache_vcpu mapcache;
+     *                      48     //Lock-free per-VCPU hash of recently-used mappings.
+     *                      49     struct vcpu_maphash_entry {
+     *                      50         unsigned long mfn;
+     *                      51         uint32_t      idx;
+     *                      52         uint32_t      refcnt;
+     *                      53     } hash[MAPHASH_ENTRIES];
+     *          -> struct hvm_vcpu hvm_vcpu;
+     */
     vcache = &v->arch.pv_vcpu.mapcache;
     if ( !dcache->inuse )
         return mfn_to_virt(mfn_x(mfn));
@@ -186,18 +219,43 @@ void unmap_domain_page(const void *ptr)
 
     ASSERT(va >= MAPCACHE_VIRT_START && va < MAPCACHE_VIRT_END);
 
+    /* 返回的v是struct vcpu */
     v = mapcache_current_vcpu();
     ASSERT(v && is_pv_vcpu(v));
 
+    /*
+     * struct vcpu
+     *  -> struct domain *domain;
+     *      -> struct arch_domain arch;
+     *          -> union
+     *              -> struct pv_domain pv_domain;
+     *                  -> struct mapcache_domain mapcache;
+     *              -> struct hvm_domain hvm_domain;
+     */
     dcache = &v->domain->arch.pv_domain.mapcache;
     ASSERT(dcache->inuse);
 
     idx = PFN_DOWN(va - MAPCACHE_VIRT_START);
     mfn = l1e_get_pfn(MAPCACHE_L1ENT(idx));
+    /*
+     * struct vcpu
+     *  -> struct arch_vcpu arch;
+     *      -> union
+     *          -> struct pv_vcpu pv_vcpu;
+     *              -> struct mapcache_vcpu mapcache;
+     *                      48     //Lock-free per-VCPU hash of recently-used mappings.
+     *                      49     struct vcpu_maphash_entry {
+     *                      50         unsigned long mfn;
+     *                      51         uint32_t      idx;
+     *                      52         uint32_t      refcnt;
+     *                      53     } hash[MAPHASH_ENTRIES];
+     *          -> struct hvm_vcpu hvm_vcpu;
+     */
     hashent = &v->arch.pv_vcpu.mapcache.hash[MAPHASH_HASHFN(mfn)];
 
     local_irq_save(flags);
 
+    /* 如果在cpu的hash里找到了 */
     if ( hashent->idx == idx )
     {
         ASSERT(hashent->mfn == mfn);
@@ -231,8 +289,20 @@ void unmap_domain_page(const void *ptr)
     local_irq_restore(flags);
 }
 
+/*
+ * called by only:
+ *   - arch/x86/domain.c|476| <<arch_domain_create>> mapcache_domain_init(d);
+ */
 int mapcache_domain_init(struct domain *d)
 {
+    /*
+     * struct domain *domain;
+     *  -> struct arch_domain arch;
+     *      -> union
+     *          -> struct pv_domain pv_domain;
+     *              -> struct mapcache_domain mapcache;
+     *          -> struct hvm_domain hvm_domain;
+     */
     struct mapcache_domain *dcache = &d->arch.pv_domain.mapcache;
     unsigned int bitmap_pages;
 
@@ -259,6 +329,10 @@ int mapcache_domain_init(struct domain *d)
                                     NIL(l1_pgentry_t *), NULL);
 }
 
+/*
+ * called by:
+ *   - arch/x86/domain.c|327| <<vcpu_initialise>> rc = mapcache_vcpu_init(v);
+ */
 int mapcache_vcpu_init(struct vcpu *v)
 {
     struct domain *d = v->domain;
@@ -331,6 +405,17 @@ void unmap_domain_page_global(const void *ptr)
 }
 
 /* Translate a map-domain-page'd address to the underlying MFN */
+/*
+ * called by:
+ *   - arch/x86/cpu/vpmu.c|677| <<pvpmu_finish>> mfn = domain_page_map_to_mfn(xenpmu_data);
+ *   - arch/x86/hvm/hvm.c|2642| <<hvm_unmap_guest_frame>> mfn = domain_page_map_to_mfn(p);
+ *   - arch/x86/hvm/viridian.c|430| <<teardown_vp_assist>> page = mfn_to_page(domain_page_map_to_mfn(va));
+ *   - arch/x86/hvm/vmx/vvmx.c|1732| <<nvmx_handle_vmptrld>> pfn_to_paddr(domain_page_map_to_mfn(vvmcx));
+ *   - arch/x86/hvm/vmx/vvmx.c|1818| <<nvmx_handle_vmclear>> domain_page_map_to_mfn(vvmcs));
+ *   - common/event_fifo.c|392| <<unmap_guest_page>> page = mfn_to_page(domain_page_map_to_mfn(virt))
+ * 
+ * Given a VA from map_domain_page(), return its underlying MFN.
+ */
 unsigned long domain_page_map_to_mfn(const void *ptr)
 {
     unsigned long va = (unsigned long)ptr;
@@ -350,5 +435,8 @@ unsigned long domain_page_map_to_mfn(const void *ptr)
         pl1e = &__linear_l1_table[l1_linear_offset(va)];
     }
 
+    /*
+     * Get pfn mapped by pte (unsigned long).
+     */
     return l1e_get_pfn(*pl1e);
 }
diff --git a/xen/arch/x86/hvm/emulate.c b/xen/arch/x86/hvm/emulate.c
index f88a011..873858a 100644
--- a/xen/arch/x86/hvm/emulate.c
+++ b/xen/arch/x86/hvm/emulate.c
@@ -117,6 +117,11 @@ static const struct hvm_io_handler ioreq_server_handler = {
     .ops = &ioreq_server_ops
 };
 
+/*
+ * called by:
+ *   - arch/x86/hvm/emulate.c|321| <<hvmemul_do_io_buffer>> rc = hvmemul_do_io(is_mmio, addr, reps, size, dir, df, 0,
+ *   - arch/x86/hvm/emulate.c|415| <<hvmemul_do_io_addr>> rc = hvmemul_do_io(is_mmio, addr, &count, size, dir, df, 1,
+ */
 static int hvmemul_do_io(
     bool_t is_mmio, paddr_t addr, unsigned long *reps, unsigned int size,
     uint8_t dir, bool_t df, bool_t data_is_addr, uintptr_t data)
@@ -310,6 +315,11 @@ static int hvmemul_do_io(
     return X86EMUL_OKAY;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/emulate.c|450| <<hvmemul_do_pio_buffer>> return hvmemul_do_io_buffer(0, port, &one_rep, size, dir, 0, buffer);
+ *   - arch/x86/hvm/emulate.c|494| <<hvmemul_do_mmio_buffer>> return hvmemul_do_io_buffer(1, mmio_gpa, reps, size, dir, df, buffer);
+ */
 static int hvmemul_do_io_buffer(
     bool_t is_mmio, paddr_t addr, unsigned long *reps, unsigned int size,
     uint8_t dir, bool_t df, void *buffer)
@@ -479,6 +489,11 @@ static int hvmemul_do_pio_addr(uint16_t port,
  *       <buffer> pointer; there is no implicit interation over a
  *       block of memory starting at <buffer>.
  */
+/*
+ * called by:
+ *   - arch/x86/hvm/emulate.c|880| <<hvmemul_phys_mmio_access>> rc = hvmemul_do_mmio_buffer(gpa, &one_rep, chunk, dir, 0,
+ *   - arch/x86/hvm/emulate.c|1695| <<hvmemul_rep_stos>> return hvmemul_do_mmio_buffer(gpa, reps, bytes_per_rep, IOREQ_WRITE, df,
+ */
 static int hvmemul_do_mmio_buffer(paddr_t mmio_gpa,
                                   unsigned long *reps,
                                   unsigned int size,
@@ -835,6 +850,10 @@ static int hvmemul_virtual_to_linear(
     return X86EMUL_EXCEPTION;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/emulate.c|1001| <<hvmemul_linear_mmio_access>> rc = hvmemul_phys_mmio_access(cache, gpa, chunk, dir, buffer, buffer_offset);
+ */
 static int hvmemul_phys_mmio_access(
     struct hvm_mmio_cache *cache, paddr_t gpa, unsigned int size, uint8_t dir,
     uint8_t *buffer, unsigned int offset)
@@ -952,6 +971,11 @@ static void latch_linear_to_phys(struct hvm_vcpu_io *vio, unsigned long gla,
                                        .write_access = write };
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/emulate.c|1027| <<hvmemul_linear_mmio_read>> return hvmemul_linear_mmio_access(gla, size, IOREQ_READ, buffer,
+ *   - arch/x86/hvm/emulate.c|1036| <<hvmemul_linear_mmio_write>> return hvmemul_linear_mmio_access(gla, size, IOREQ_WRITE, buffer,
+ */
 static int hvmemul_linear_mmio_access(
     unsigned long gla, unsigned int size, uint8_t dir, void *buffer,
     uint32_t pfec, struct hvm_emulate_ctxt *hvmemul_ctxt, bool_t known_gpfn)
@@ -1013,6 +1037,11 @@ static inline int hvmemul_linear_mmio_read(
                                       pfec, hvmemul_ctxt, translate);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/emulate.c|1189| <<hvmemul_write>> return hvmemul_linear_mmio_write(addr, bytes, p_data, pfec, hvmemul_ctxt, 1);
+ *   - arch/x86/hvm/emulate.c|1196| <<hvmemul_write>> return hvmemul_linear_mmio_write(addr, bytes, p_data, pfec, hvmemul_ctxt, 0);
+ */
 static inline int hvmemul_linear_mmio_write(
     unsigned long gla, unsigned int size, void *buffer,
     uint32_t pfec, struct hvm_emulate_ctxt *hvmemul_ctxt,
@@ -1143,6 +1172,11 @@ int hvmemul_insn_fetch(
     return X86EMUL_OKAY;
 }
 
+/*
+ * used by:
+ *   - struct x86_emulate_ops hvm_emulate_ops.write = hvmemu_write()
+ *   - arch/x86/hvm/emulate.c|1313| <<hvmemul_cmpxchg>> return hvmemul_write(seg, offset, p_new, bytes, ctxt);
+ */
 static int hvmemul_write(
     enum x86_segment seg,
     unsigned long offset,
@@ -2044,6 +2078,10 @@ static int hvmemul_vmfunc(
     return rc;
 }
 
+/*
+ * used and called by:
+ *   - arch/x86/hvm/emulate.c|2203| <<hvm_emulate_one>> return _hvm_emulate_one(hvmemul_ctxt, &hvm_emulate_ops);
+ */
 static const struct x86_emulate_ops hvm_emulate_ops = {
     .read          = hvmemul_read,
     .insn_fetch    = hvmemul_insn_fetch,
@@ -2163,6 +2201,13 @@ static int _hvm_emulate_one(struct hvm_emulate_ctxt *hvmemul_ctxt,
     return rc;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/emulate.c|2291| <<hvm_emulate_one_vm_event>> rc = hvm_emulate_one(&ctx);
+ *   - arch/x86/hvm/hvm.c|3780| <<hvm_ud_intercept>> switch ( hvm_emulate_one(&ctxt) )
+ *   - arch/x86/hvm/io.c|89| <<hvm_emulate_one_insn>> rc = hvm_emulate_one(&ctxt);
+ *   - arch/x86/hvm/vmx/realmode.c|104| <<vmx_realmode_emulate_one>> rc = hvm_emulate_one(hvmemul_ctxt);
+ */
 int hvm_emulate_one(
     struct hvm_emulate_ctxt *hvmemul_ctxt)
 {
diff --git a/xen/arch/x86/hvm/hvm.c b/xen/arch/x86/hvm/hvm.c
index 28bc7e4..1f00cdd 100644
--- a/xen/arch/x86/hvm/hvm.c
+++ b/xen/arch/x86/hvm/hvm.c
@@ -3402,6 +3402,12 @@ void hvm_rdtsc_intercept(struct cpu_user_regs *regs)
     HVMTRACE_2D(RDTSC, regs->eax, regs->edx);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/emulate.c|1855| <<hvmemul_read_msr>> int rc = hvm_msr_read_intercept(reg, val);
+ *   - arch/x86/hvm/svm/svm.c|2129| <<svm_do_msr_access>> rc = hvm_msr_read_intercept(regs->ecx, &msr_content);
+ *   - arch/x86/hvm/vmx/vmx.c|3949| <<vmx_vmexit_handler>> switch ( hvm_msr_read_intercept(regs->ecx, &msr_content) )
+ */
 int hvm_msr_read_intercept(unsigned int msr, uint64_t *msr_content)
 {
     struct vcpu *v = current;
diff --git a/xen/arch/x86/hvm/intercept.c b/xen/arch/x86/hvm/intercept.c
index 2bc156d..cea22a8 100644
--- a/xen/arch/x86/hvm/intercept.c
+++ b/xen/arch/x86/hvm/intercept.c
@@ -57,6 +57,9 @@ static int hvm_mmio_read(const struct hvm_io_handler *handler,
     return handler->mmio.ops->read(current, addr, size, data);
 }
 
+/*
+ * struct hvm_io_ops mmio_ops.write = hvm_mmio_write()
+ */
 static int hvm_mmio_write(const struct hvm_io_handler *handler,
                           uint64_t addr, uint32_t size, uint64_t data)
 {
@@ -112,6 +115,12 @@ static const struct hvm_io_ops portio_ops = {
     .write = hvm_portio_write
 };
 
+/*
+ * called by:
+ *   - arch/x86/hvm/emulate.c|263| <<hvmemul_do_io>> rc = hvm_process_io_intercept(&ioreq_server_handler, &p);
+ *   - arch/x86/hvm/emulate.c|276| <<hvmemul_do_io>> rc = hvm_process_io_intercept(&null_handler, &p);
+ *   - arch/x86/hvm/intercept.c|249| <<hvm_io_intercept>> rc = hvm_process_io_intercept(handler, p);
+ */
 int hvm_process_io_intercept(const struct hvm_io_handler *handler,
                              ioreq_t *p)
 {
@@ -235,6 +244,10 @@ static const struct hvm_io_handler *hvm_find_io_handler(const ioreq_t *p)
     return NULL;
 }
 
+/*
+ * called by onlu:
+ *   - arch/x86/hvm/emulate.c|188| <<hvmemul_do_io>> rc = hvm_io_intercept(&p);
+ */
 int hvm_io_intercept(ioreq_t *p)
 {
     const struct hvm_io_handler *handler;
@@ -255,6 +268,14 @@ int hvm_io_intercept(ioreq_t *p)
     return rc;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/intercept.c|286| <<register_mmio_handler>> struct hvm_io_handler *handler = hvm_next_io_handler(d);
+ *   - arch/x86/hvm/intercept.c|299| <<register_portio_handler>> struct hvm_io_handler *handler = hvm_next_io_handler(d);
+ *   - arch/x86/hvm/io.c|255| <<register_g2m_portio_handler>> struct hvm_io_handler *handler = hvm_next_io_handler(d);
+ *   - arch/x86/hvm/stdvga.c|606| <<stdvga_init>> handler = hvm_next_io_handler(d);
+ *   - arch/x86/hvm/vmsi.c|688| <<msixtbl_init>> handler = hvm_next_io_handler(d);
+ */
 struct hvm_io_handler *hvm_next_io_handler(struct domain *d)
 {
     unsigned int i = d->arch.hvm_domain.io_handler_count++;
@@ -283,6 +304,22 @@ void register_mmio_handler(struct domain *d,
     handler->mmio.ops = ops;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/hvm.c|649| <<hvm_domain_initialise>> register_portio_handler(d, 0xe9, 1, hvm_print_line);
+ *   - arch/x86/hvm/i8254.c|479| <<pit_init>> register_portio_handler(d, PIT_BASE, 4, handle_pit_io);
+ *   - arch/x86/hvm/i8254.c|480| <<pit_init>> register_portio_handler(d, 0x61, 1, handle_speaker_io);
+ *   - arch/x86/hvm/ioreq.c|1462| <<hvm_ioreq_init>> register_portio_handler(d, 0xcf8, 4, hvm_access_cf8);
+ *   - arch/x86/hvm/pmtimer.c|362| <<pmtimer_init>> register_portio_handler(v->domain, TMR_VAL_ADDR_V0, 4, handle_pmt_io);
+ *   - arch/x86/hvm/pmtimer.c|363| <<pmtimer_init>> register_portio_handler(v->domain, PM1a_STS_ADDR_V0, 4, handle_evt_io);
+ *   - arch/x86/hvm/rtc.c|814| <<rtc_init>> register_portio_handler(d, RTC_PORT(0), 2, handle_rtc_io);
+ *   - arch/x86/hvm/stdvga.c|601| <<stdvga_init>> register_portio_handler(d, 0x3c4, 2, stdvga_intercept_pio);
+ *   - arch/x86/hvm/stdvga.c|603| <<stdvga_init>> register_portio_handler(d, 0x3ce, 2, stdvga_intercept_pio);
+ *   - arch/x86/hvm/vpic.c|441| <<vpic_init>> register_portio_handler(d, 0x20, 2, vpic_intercept_pic_io);
+ *   - arch/x86/hvm/vpic.c|442| <<vpic_init>> register_portio_handler(d, 0xa0, 2, vpic_intercept_pic_io);
+ *   - arch/x86/hvm/vpic.c|444| <<vpic_init>> register_portio_handler(d, 0x4d0, 1, vpic_intercept_elcr_io);
+ *   - arch/x86/hvm/vpic.c|445| <<vpic_init>> register_portio_handler(d, 0x4d1, 1, vpic_intercept_elcr_io);
+ */
 void register_portio_handler(struct domain *d, unsigned int port,
                              unsigned int size, portio_action_t action)
 {
diff --git a/xen/arch/x86/hvm/ioreq.c b/xen/arch/x86/hvm/ioreq.c
index d5afe20..1886e6a 100644
--- a/xen/arch/x86/hvm/ioreq.c
+++ b/xen/arch/x86/hvm/ioreq.c
@@ -66,6 +66,11 @@ bool hvm_io_pending(struct vcpu *v)
     return false;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/ioreq.c|103| <<hvm_wait_for_io>> hvm_io_assist(sv, ~0ul);
+ *   - arch/x86/hvm/ioreq.c|107| <<hvm_wait_for_io>> hvm_io_assist(sv, p->data);
+ */
 static void hvm_io_assist(struct hvm_ioreq_vcpu *sv, uint64_t data)
 {
     struct vcpu *v = sv->vcpu;
@@ -85,6 +90,10 @@ static void hvm_io_assist(struct hvm_ioreq_vcpu *sv, uint64_t data)
     sv->pending = false;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/ioreq.c|143| <<handle_hvm_io_completion>> if ( !hvm_wait_for_io(sv, get_ioreq(s, v)) )
+ */
 static bool hvm_wait_for_io(struct hvm_ioreq_vcpu *sv, ioreq_t *p)
 {
     while ( sv->pending )
@@ -1352,6 +1361,12 @@ static int hvm_send_buffered_ioreq(struct hvm_ioreq_server *s, ioreq_t *p)
     return X86EMUL_OKAY;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/emulate.c|286| <<hvmemul_do_io>> rc = hvm_send_ioreq(s, &p, 0);
+ *   - arch/x86/hvm/ioreq.c|1433| <<hvm_broadcast_ioreq>> if ( hvm_send_ioreq(s, p, buffered) == X86EMUL_UNHANDLEABLE )
+ *   - arch/x86/hvm/stdvga.c|514| <<stdvga_mem_write>> return hvm_send_ioreq(srv, &p, 1);
+ */
 int hvm_send_ioreq(struct hvm_ioreq_server *s, ioreq_t *proto_p,
                    bool buffered)
 {
@@ -1439,6 +1454,10 @@ static int hvm_access_cf8(
     return X86EMUL_UNHANDLEABLE;
 }
 
+/*
+ * called by only:
+ *   - arch/x86/hvm/hvm.c|633| <<hvm_domain_initialise>> hvm_ioreq_init(d);
+ */
 void hvm_ioreq_init(struct domain *d)
 {
     spin_lock_init(&d->arch.hvm_domain.ioreq_server.lock);
diff --git a/xen/arch/x86/hvm/irq.c b/xen/arch/x86/hvm/irq.c
index 0077f68..4699f68 100644
--- a/xen/arch/x86/hvm/irq.c
+++ b/xen/arch/x86/hvm/irq.c
@@ -467,6 +467,15 @@ void hvm_set_callback_via(struct domain *d, uint64_t via)
 #endif
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/irq.c|532| <<hvm_local_events_need_delivery>> struct hvm_intack intack = hvm_vcpu_has_pending_irq(v);
+ *   - arch/x86/hvm/svm/intr.c|144| <<svm_intr_assist>> intack = hvm_vcpu_has_pending_irq(v);
+ *   - arch/x86/hvm/svm/intr.c|216| <<svm_intr_assist>> intack = hvm_vcpu_has_pending_irq(v);
+ *   - arch/x86/hvm/vmx/intr.c|207| <<nvmx_intr_intercept>> intack = hvm_vcpu_has_pending_irq(v);
+ *   - arch/x86/hvm/vmx/intr.c|249| <<vmx_intr_assist>> intack = hvm_vcpu_has_pending_irq(v);
+ *   - arch/x86/hvm/vmx/intr.c|396| <<vmx_intr_assist>> intack = hvm_vcpu_has_pending_irq(v);
+ */
 struct hvm_intack hvm_vcpu_has_pending_irq(struct vcpu *v)
 {
     struct hvm_domain *plat = &v->domain->arch.hvm_domain;
diff --git a/xen/arch/x86/hvm/vioapic.c b/xen/arch/x86/hvm/vioapic.c
index 97b419f..fef9fb7 100644
--- a/xen/arch/x86/hvm/vioapic.c
+++ b/xen/arch/x86/hvm/vioapic.c
@@ -44,6 +44,12 @@
 
 static void vioapic_deliver(struct hvm_vioapic *vioapic, unsigned int irq);
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vioapic.c|139| <<vioapic_read>> vioapic = addr_vioapic(v->domain, addr);
+ *   - arch/x86/hvm/vioapic.c|321| <<vioapic_write>> vioapic = addr_vioapic(v->domain, addr);
+ *   - arch/x86/hvm/vioapic.c|349| <<vioapic_range>> return !!addr_vioapic(v->domain, addr);
+ */
 static struct hvm_vioapic *addr_vioapic(const struct domain *d,
                                         unsigned long addr)
 {
@@ -61,6 +67,13 @@ static struct hvm_vioapic *addr_vioapic(const struct domain *d,
     return NULL;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vioapic.c|467| <<vioapic_irq_positive_edge>> struct hvm_vioapic *vioapic = gsi_vioapic(d, irq, &pin);
+ *   - arch/x86/hvm/vioapic.c|542| <<vioapic_get_mask>> const struct hvm_vioapic *vioapic = gsi_vioapic(d, gsi, &pin);
+ *   - arch/x86/hvm/vioapic.c|553| <<vioapic_get_vector>> const struct hvm_vioapic *vioapic = gsi_vioapic(d, gsi, &pin);
+ *   - arch/x86/hvm/vioapic.c|564| <<vioapic_get_trigger_mode>> const struct hvm_vioapic *vioapic = gsi_vioapic(d, gsi, &pin);
+ */
 static struct hvm_vioapic *gsi_vioapic(const struct domain *d,
                                        unsigned int gsi, unsigned int *pin)
 {
@@ -81,6 +94,10 @@ static struct hvm_vioapic *gsi_vioapic(const struct domain *d,
     return NULL;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vioapic.c|149| <<vioapic_read>> result = vioapic_read_indirect(vioapic);
+ */
 static uint32_t vioapic_read_indirect(const struct hvm_vioapic *vioapic)
 {
     uint32_t result = 0;
@@ -127,6 +144,9 @@ static uint32_t vioapic_read_indirect(const struct hvm_vioapic *vioapic)
     return result;
 }
 
+/*
+ * struct hvm_mmio_ops vioapic_mmio_ops.read = vioapic_read()
+ */
 static int vioapic_read(
     struct vcpu *v, unsigned long addr,
     unsigned int length, unsigned long *pval)
@@ -158,6 +178,10 @@ static int vioapic_read(
     return X86EMUL_OKAY;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vioapic.c|263| <<vioapic_write_redirent>> ret = vioapic_hwdom_map_gsi(gsi, ent.fields.trig_mode,
+ */
 static int vioapic_hwdom_map_gsi(unsigned int gsi, unsigned int trig,
                                  unsigned int pol)
 {
@@ -204,6 +228,10 @@ static int vioapic_hwdom_map_gsi(unsigned int gsi, unsigned int trig,
     return ret;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vioapic.c|328| <<vioapic_write_indirect>> vioapic_write_redirent(
+ */
 static void vioapic_write_redirent(
     struct hvm_vioapic *vioapic, unsigned int idx,
     int top_word, uint32_t val)
@@ -270,6 +298,10 @@ static void vioapic_write_redirent(
         pt_may_unmask_irq(d, NULL);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vioapic.c|354| <<vioapic_write>> vioapic_write_indirect(vioapic, val);
+ */
 static void vioapic_write_indirect(
     struct hvm_vioapic *vioapic, uint32_t val)
 {
@@ -312,6 +344,9 @@ static void vioapic_write_indirect(
     }
 }
 
+/*
+ * struct hvm_mmio_ops vioapic_mmio_ops.write = vioapic_write()
+ */
 static int vioapic_write(
     struct vcpu *v, unsigned long addr,
     unsigned int length, unsigned long val)
@@ -344,6 +379,9 @@ static int vioapic_write(
     return X86EMUL_OKAY;
 }
 
+/*
+ * struct hvm_mmio_ops vioapic_mmio_ops.check = vioapic_range()
+ */
 static int vioapic_range(struct vcpu *v, unsigned long addr)
 {
     return !!addr_vioapic(v->domain, addr);
@@ -603,6 +641,11 @@ static int ioapic_load(struct domain *d, hvm_domain_context_t *h)
 
 HVM_REGISTER_SAVE_RESTORE(IOAPIC, ioapic_save, ioapic_load, 1, HVMSR_PER_DOM);
 
+/*
+ * called by:
+ *   - arch/x86/hvm/hvm.c|3992| <<hvm_s3_suspend>> vioapic_reset(d);
+ *   - arch/x86/hvm/vioapic.c|729| <<vioapic_init>> vioapic_reset(d);
+ */
 void vioapic_reset(struct domain *d)
 {
     unsigned int i;
@@ -640,6 +683,11 @@ void vioapic_reset(struct domain *d)
     }
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vioapic.c|713| <<vioapic_init>> vioapic_free(d, nr_vioapics);
+ *   - arch/x86/hvm/vioapic.c|744| <<vioapic_deinit>> vioapic_free(d, d->arch.hvm_domain.nr_vioapics);
+ */
 static void vioapic_free(const struct domain *d, unsigned int nr_vioapics)
 {
     unsigned int i;
@@ -649,6 +697,10 @@ static void vioapic_free(const struct domain *d, unsigned int nr_vioapics)
     xfree(d->arch.hvm_domain.vioapic);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/hvm.c|641| <<hvm_domain_initialise>> rc = vioapic_init(d);
+ */
 int vioapic_init(struct domain *d)
 {
     unsigned int i, nr_vioapics, nr_gsis = 0;
@@ -707,6 +759,11 @@ int vioapic_init(struct domain *d)
     return 0;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/hvm.c|663| <<hvm_domain_initialise>> vioapic_deinit(d);
+ *   - arch/x86/hvm/hvm.c|714| <<hvm_domain_destroy>> vioapic_deinit(d);
+ */
 void vioapic_deinit(struct domain *d)
 {
     if ( !has_vioapic(d) )
diff --git a/xen/arch/x86/hvm/vlapic.c b/xen/arch/x86/hvm/vlapic.c
index 50f53bd..f90c6d8 100644
--- a/xen/arch/x86/hvm/vlapic.c
+++ b/xen/arch/x86/hvm/vlapic.c
@@ -85,6 +85,11 @@ static const unsigned int vlapic_lvt_mask[VLAPIC_LVT_NUM] =
 
 static void vlapic_do_init(struct vlapic *vlapic);
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vlapic.c|127| <<vlapic_find_highest_irr>> return vlapic_find_highest_vector(&vlapic->regs->data[APIC_IRR]);
+ *   - arch/x86/hvm/vlapic.c|184| <<vlapic_find_highest_isr>> return vlapic_find_highest_vector(&vlapic->regs->data[APIC_ISR]);
+ */
 static int vlapic_find_highest_vector(const void *bitmap)
 {
     const uint32_t *word = bitmap;
@@ -101,6 +106,10 @@ static int vlapic_find_highest_vector(const void *bitmap)
  * IRR-specific bitmap update & search routines.
  */
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vlapic.c|170| <<vlapic_set_irq>> else if ( !vlapic_test_and_set_irr(vec, vlapic) )
+ */
 static int vlapic_test_and_set_irr(int vector, struct vlapic *vlapic)
 {
     return vlapic_test_and_set_vector(vector, &vlapic->regs->data[APIC_IRR]);
@@ -111,14 +120,34 @@ static void vlapic_clear_irr(int vector, struct vlapic *vlapic)
     vlapic_clear_vector(vector, &vlapic->regs->data[APIC_IRR]);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vlapic.c|1255| <<vlapic_has_pending_irq>> irr = vlapic_find_highest_irr(vlapic);
+ */
 static int vlapic_find_highest_irr(struct vlapic *vlapic)
 {
+    /*
+     * used by:
+     *   - arch/x86/hvm/vlapic.c|124| <<vlapic_find_highest_irr>> if ( hvm_funcs.sync_pir_to_irr )
+     *   - arch/x86/hvm/vlapic.c|125| <<vlapic_find_highest_irr>> hvm_funcs.sync_pir_to_irr(vlapic_vcpu(vlapic));
+     *   - arch/x86/hvm/vlapic.c|1503| <<lapic_save_regs>> if ( hvm_funcs.sync_pir_to_irr )
+     *   - arch/x86/hvm/vlapic.c|1504| <<lapic_save_regs>> hvm_funcs.sync_pir_to_irr(v);
+     *   - arch/x86/hvm/vmx/vmx.c|2526| <<start_vmx>> vmx_function_table.sync_pir_to_irr = NULL;
+     *
+     * struct hvm_function_table vmx_function_table.sync_pir_to_irr = vmx_sync_pir_to_irr()
+     */
     if ( hvm_funcs.sync_pir_to_irr )
         hvm_funcs.sync_pir_to_irr(vlapic_vcpu(vlapic));
 
     return vlapic_find_highest_vector(&vlapic->regs->data[APIC_IRR]);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vlapic.c|192| <<vlapic_set_irq>> vlapic_error(vlapic, APIC_ESR_RECVILL);
+ *   - arch/x86/hvm/vlapic.c|534| <<vlapic_ipi>> vlapic_error(vlapic, APIC_ESR_SENDILL);
+ *   - arch/x86/hvm/vlapic.c|543| <<vlapic_ipi>> vlapic_error(vlapic, APIC_ESR_SENDILL);
+ */
 static void vlapic_error(struct vlapic *vlapic, unsigned int errmask)
 {
     unsigned long flags;
@@ -137,6 +166,10 @@ static void vlapic_error(struct vlapic *vlapic, unsigned int errmask)
     spin_unlock_irqrestore(&vlapic->esr_lock, flags);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpt.c|321| <<pt_update_irq>> if ( pt_vector < 0 || !vlapic_test_irq(vcpu_vlapic(v), pt_vector) )
+ */
 bool vlapic_test_irq(const struct vlapic *vlapic, uint8_t vec)
 {
     if ( unlikely(vec < 16) )
@@ -149,6 +182,17 @@ bool vlapic_test_irq(const struct vlapic *vlapic, uint8_t vec)
     return vlapic_test_vector(vec, &vlapic->regs->data[APIC_IRR]);
 }
 
+/*
+ * called by:
+ *   - arch/x86/cpu/vpmu.c|342| <<vpmu_do_interrupt>> vlapic_set_irq(vlapic, vlapic_lvtpc & APIC_VECTOR_MASK, 0);
+ *   - arch/x86/hvm/irq.c|282| <<hvm_assert_evtchn_irq>> vlapic_set_irq(vcpu_vlapic(v), vector, 0);
+ *   - arch/x86/hvm/svm/svm.c|945| <<svm_lwp_interrupt>> vlapic_set_irq(
+ *   - arch/x86/hvm/vioapic.c|371| <<ioapic_inj_irq>> vlapic_set_irq(target, vector, trig_mode);
+ *   - arch/x86/hvm/vlapic.c|143| <<vlapic_error>> vlapic_set_irq(vlapic, lvterr & APIC_VECTOR_MASK, 0);
+ *   - arch/x86/hvm/vlapic.c|358| <<vlapic_accept_irq>> vlapic_set_irq(vlapic, vector, 0);
+ *   - arch/x86/hvm/vmsi.c|61| <<vmsi_inj_irq>> vlapic_set_irq(target, vector, trig_mode);
+ *   - arch/x86/hvm/vpt.c|302| <<pt_update_irq>> vlapic_set_irq(vcpu_vlapic(v), irq, 0);
+ */
 void vlapic_set_irq(struct vlapic *vlapic, uint8_t vec, uint8_t trig)
 {
     struct vcpu *target = vlapic_vcpu(vlapic);
@@ -171,11 +215,25 @@ void vlapic_set_irq(struct vlapic *vlapic, uint8_t vec, uint8_t trig)
         vcpu_kick(target);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vlapic.c|219| <<vlapic_get_ppr>> isr = vlapic_find_highest_isr(vlapic);
+ *   - arch/x86/hvm/vlapic.c|459| <<vlapic_EOI_set>> int vector = vlapic_find_highest_isr(vlapic);
+ *   - arch/x86/hvm/vlapic.c|1320| <<vlapic_has_pending_irq>> isr = vlapic_find_highest_isr(vlapic);
+ *   - arch/x86/hvm/vlapic.c|1348| <<vlapic_ack_pending_irq>> isr = vlapic_find_highest_isr(vlapic);
+ *   - arch/x86/hvm/vlapic.c|1646| <<lapic_load_regs>> hvm_funcs.process_isr(vlapic_find_highest_isr(s), v);
+ */
 static int vlapic_find_highest_isr(struct vlapic *vlapic)
 {
     return vlapic_find_highest_vector(&vlapic->regs->data[APIC_ISR]);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vlapic.c|236| <<vlapic_set_ppr>> uint32_t ppr = vlapic_get_ppr(vlapic);
+ *   - arch/x86/hvm/vlapic.c|437| <<vlapic_lowest_prio>> ((ppr = vlapic_get_ppr(vlapic)) < target_ppr) )
+ *   - arch/x86/hvm/vlapic.c|611| <<vlapic_read_aligned>> return vlapic_get_ppr(vlapic);
+ */
 static uint32_t vlapic_get_ppr(struct vlapic *vlapic)
 {
     uint32_t tpr, isrv, ppr;
@@ -197,6 +255,10 @@ static uint32_t vlapic_get_ppr(struct vlapic *vlapic)
     return ppr;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vmx/vvmx.c|1345| <<nvmx_update_apicv>> ppr = vlapic_set_ppr(vlapic);
+ */
 uint32_t vlapic_set_ppr(struct vlapic *vlapic)
 {
    uint32_t ppr = vlapic_get_ppr(vlapic);
@@ -414,6 +476,12 @@ struct vlapic *vlapic_lowest_prio(
     return target;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/viridian.c|589| <<wrmsr_viridian_regs>> vlapic_EOI_set(vcpu_vlapic(v));
+ *   - arch/x86/hvm/vlapic.c|787| <<vlapic_reg_write>> vlapic_EOI_set(vlapic);
+ *   - arch/x86/hvm/vmx/vmx.c|3425| <<vmx_handle_eoi_write>> vlapic_EOI_set(vcpu_vlapic(current));
+ */
 void vlapic_EOI_set(struct vlapic *vlapic)
 {
     int vector = vlapic_find_highest_isr(vlapic);
@@ -434,6 +502,13 @@ void vlapic_handle_EOI(struct vlapic *vlapic, u8 vector)
 {
     struct domain *d = vlapic_domain(vlapic);
 
+    /*
+     * 使用APIC_TMR的地方:
+     *   - arch/x86/hvm/vlapic.c|207| <<vlapic_set_irq>> vlapic_set_vector(vec, &vlapic->regs->data[APIC_TMR]);
+     *   - arch/x86/hvm/vlapic.c|501| <<vlapic_handle_EOI>> if ( vlapic_test_and_clear_vector(vector, &vlapic->regs->data[APIC_TMR]) )
+     *   - arch/x86/hvm/vlapic.c|1373| <<vlapic_ack_pending_irq>> vlapic_test_vector(vector, &vlapic->regs->data[APIC_TMR]) )
+     *   - arch/x86/hvm/vlapic.c|1421| <<vlapic_do_init>> vlapic_set_reg(vlapic, APIC_TMR + 0x10 * i, 0);
+     */
     if ( vlapic_test_and_clear_vector(vector, &vlapic->regs->data[APIC_TMR]) )
         vioapic_update_EOI(d, vector);
 
@@ -936,6 +1011,10 @@ static int vlapic_write(struct vcpu *v, unsigned long address,
     return rc;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vmx/vmx.c|3548| <<vmx_handle_apic_write>> return vlapic_apicv_write(current, exit_qualification & 0xfff);
+ */
 int vlapic_apicv_write(struct vcpu *v, unsigned int offset)
 {
     struct vlapic *vlapic = vcpu_vlapic(v);
@@ -955,6 +1034,10 @@ int vlapic_apicv_write(struct vcpu *v, unsigned int offset)
     return X86EMUL_OKAY;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/hvm.c|3604| <<hvm_msr_write_intercept>> if ( hvm_x2apic_msr_write(v, msr, msr_content) )
+ */
 int hvm_x2apic_msr_write(struct vcpu *v, unsigned int msr, uint64_t msr_content)
 {
     struct vlapic *vlapic = vcpu_vlapic(v);
@@ -1045,6 +1128,10 @@ static int vlapic_range(struct vcpu *v, unsigned long addr)
            (offset < PAGE_SIZE);
 }
 
+/*
+ * used by:
+ *   - arch/x86/hvm/vlapic.c|1593| <<vlapic_init>> register_mmio_handler(v->domain, &vlapic_mmio_ops);
+ */
 static const struct hvm_mmio_ops vlapic_mmio_ops = {
     .check = vlapic_range,
     .read = vlapic_read,
@@ -1195,6 +1282,14 @@ static int __vlapic_accept_pic_intr(struct vcpu *v)
              vlapic_hw_disabled(vlapic)));
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/irq.c|494| <<hvm_vcpu_has_pending_irq>> if ( vlapic_accept_pic_intr(v) && plat->vpic[0].int_output )
+ *   - arch/x86/hvm/vpic.c|491| <<vpic_ack_pending_irq>> TRACE_2D(TRC_HVM_EMUL_PIC_PEND_IRQ_CALL, vlapic_accept_pic_intr(v),
+ *   - arch/x86/hvm/vpic.c|493| <<vpic_ack_pending_irq>> if ( !vlapic_accept_pic_intr(v) || !vpic->int_output )
+ *   - arch/x86/hvm/vpt.c|133| <<pt_irq_masked>> return (((pic_imr & (1 << (isa_irq & 7))) || !vlapic_accept_pic_intr(v)) &&
+ *   - arch/x86/hvm/vpt.c|308| <<pt_update_irq>> if ( platform_legacy_irq(irq) && vlapic_accept_pic_intr(v) &&
+ */
 int vlapic_accept_pic_intr(struct vcpu *v)
 {
     if ( vlapic_hw_disabled(vcpu_vlapic(v)) || !has_vpic(v->domain) )
@@ -1230,12 +1325,20 @@ void vlapic_adjust_i8259_target(struct domain *d)
 
 int vlapic_virtual_intr_delivery_enabled(void)
 {
+    /*
+     * vmx: vmx_virtual_intr_delivery_enabled()
+     */
     if ( hvm_funcs.virtual_intr_delivery_enabled )
         return hvm_funcs.virtual_intr_delivery_enabled();
     else
         return 0;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/irq.c|488| <<hvm_vcpu_has_pending_irq>> vector = vlapic_has_pending_irq(v);
+ *   - arch/x86/hvm/vmx/vvmx.c|1349| <<nvmx_update_apicv>> rvi = vlapic_has_pending_irq(v);
+ */
 int vlapic_has_pending_irq(struct vcpu *v)
 {
     struct vlapic *vlapic = vcpu_vlapic(v);
@@ -1275,6 +1378,11 @@ int vlapic_has_pending_irq(struct vcpu *v)
     return ((isr & 0xf0) < (irr & 0xf0)) ? irr : -1;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/irq.c|526| <<hvm_vcpu_ack_pending_irq>> if ( !vlapic_ack_pending_irq(v, intack.vector, 0) )
+ *   - arch/x86/hvm/vmx/vvmx.c|1343| <<nvmx_update_apicv>> vlapic_ack_pending_irq(v, vector, 1);
+ */
 int vlapic_ack_pending_irq(struct vcpu *v, int vector, bool_t force_ack)
 {
     struct vlapic *vlapic = vcpu_vlapic(v);
@@ -1285,6 +1393,13 @@ int vlapic_ack_pending_irq(struct vcpu *v, int vector, bool_t force_ack)
         return 1;
 
     /* If there's no chance of using APIC assist then bail now. */
+    /*
+     * 使用APIC_TMR的地方:
+     *   - arch/x86/hvm/vlapic.c|207| <<vlapic_set_irq>> vlapic_set_vector(vec, &vlapic->regs->data[APIC_TMR]);
+     *   - arch/x86/hvm/vlapic.c|501| <<vlapic_handle_EOI>> if ( vlapic_test_and_clear_vector(vector, &vlapic->regs->data[APIC_TMR]) )
+     *   - arch/x86/hvm/vlapic.c|1373| <<vlapic_ack_pending_irq>> vlapic_test_vector(vector, &vlapic->regs->data[APIC_TMR]) )
+     *   - arch/x86/hvm/vlapic.c|1421| <<vlapic_do_init>> vlapic_set_reg(vlapic, APIC_TMR + 0x10 * i, 0);
+     */
     if ( !has_viridian_apic_assist(v->domain) ||
          vlapic_test_vector(vector, &vlapic->regs->data[APIC_TMR]) )
         goto done;
@@ -1305,6 +1420,10 @@ int vlapic_ack_pending_irq(struct vcpu *v, int vector, bool_t force_ack)
     return 1;
 }
 
+/*
+ * called by only:
+ *   - arch/x86/cpu/vpmu.c|334| <<vpmu_do_interrupt>> !is_vlapic_lvtpc_enabled(vlapic) )
+ */
 bool_t is_vlapic_lvtpc_enabled(struct vlapic *vlapic)
 {
     return (vlapic_enabled(vlapic) &&
@@ -1312,6 +1431,11 @@ bool_t is_vlapic_lvtpc_enabled(struct vlapic *vlapic)
 }
 
 /* Reset the VLAPIC back to its init state. */
+/*
+ * called by:
+ *   - arch/x86/hvm/vlapic.c|306| <<vlapic_init_sipi_one>> vlapic_do_init(vcpu_vlapic(target));
+ *   - arch/x86/hvm/vlapic.c|1392| <<vlapic_reset>> vlapic_do_init(vlapic);
+ */
 static void vlapic_do_init(struct vlapic *vlapic)
 {
     int i;
@@ -1353,6 +1477,12 @@ static void vlapic_do_init(struct vlapic *vlapic)
 }
 
 /* Reset the VLAPIC back to its power-on/reset state. */
+/*
+ * called by:
+ *   - arch/x86/hvm/hvm.c|3980| <<hvm_s3_suspend>> vlapic_reset(vcpu_vlapic(v));
+ *   - arch/x86/hvm/vlapic.c|1074| <<vlapic_msr_set>> vlapic_reset(vlapic);
+ *   - arch/x86/hvm/vlapic.c|1584| <<vlapic_init>> vlapic_reset(vlapic);
+ */
 void vlapic_reset(struct vlapic *vlapic)
 {
     const struct vcpu *v = vlapic_vcpu(vlapic);
@@ -1360,6 +1490,20 @@ void vlapic_reset(struct vlapic *vlapic)
     if ( !has_vlapic(v->domain) )
         return;
 
+    /*
+     * 在以下使用apic_base_msr:
+     *   - arch/x86/hvm/hvm.c|3441| <<hvm_msr_read_intercept>> *msr_content = vcpu_vlapic(v)->hw.apic_base_msr;
+     *   - arch/x86/hvm/vlapic.c|1080| <<vlapic_msr_set>> if ( (vlapic->hw.apic_base_msr ^ value) & MSR_IA32_APICBASE_ENABLE )
+     *   - arch/x86/hvm/vlapic.c|1096| <<vlapic_msr_set>> else if ( ((vlapic->hw.apic_base_msr ^ value) & MSR_IA32_APICBASE_EXTD) &&
+     *   - arch/x86/hvm/vlapic.c|1100| <<vlapic_msr_set>> vlapic->hw.apic_base_msr = value;
+     *   - arch/x86/hvm/vlapic.c|1109| <<vlapic_msr_set>> "apic base msr is 0x%016"PRIx64, vlapic->hw.apic_base_msr);
+     *   - arch/x86/hvm/vlapic.c|1386| <<vlapic_reset>> vlapic->hw.apic_base_msr = (MSR_IA32_APICBASE_ENABLE |
+     *   - arch/x86/hvm/vlapic.c|1389| <<vlapic_reset>> vlapic->hw.apic_base_msr |= MSR_IA32_APICBASE_BSP;
+     *   - arch/x86/hvm/vlapic.c|1521| <<lapic_load_hidden>> if ( !(s->hw.apic_base_msr & MSR_IA32_APICBASE_ENABLE) &&
+     *   - include/asm-x86/hvm/vlapic.h|53| <<vlapic_base_address>> ((vlapic)->hw.apic_base_msr & MSR_IA32_APICBASE_BASE)
+     *   - include/asm-x86/hvm/vlapic.h|56| <<vlapic_x2apic_mode>> ((vlapic)->hw.apic_base_msr & MSR_IA32_APICBASE_EXTD)
+     *   - include/asm-x86/hvm/vlapic.h|59| <<vlapic_xapic_mode>> !((vlapic)->hw.apic_base_msr & MSR_IA32_APICBASE_EXTD))
+     */
     vlapic->hw.apic_base_msr = (MSR_IA32_APICBASE_ENABLE |
                                 APIC_DEFAULT_PHYS_BASE);
     if ( v->vcpu_id == 0 )
@@ -1370,6 +1514,10 @@ void vlapic_reset(struct vlapic *vlapic)
 }
 
 /* rearm the actimer if needed, after a HVM restore */
+/*
+ * called by:
+ *   - arch/x86/hvm/vlapic.c|1612| <<lapic_load_regs>> lapic_rearm(s);
+ */
 static void lapic_rearm(struct vlapic *s)
 {
     unsigned long tmict;
@@ -1399,6 +1547,10 @@ static void lapic_rearm(struct vlapic *s)
     s->timer_last_update = s->pt.last_plt_gtime;
 }
 
+/*
+ * used by:
+ *   - arch/x86/hvm/vlapic.c|1595| <<global>> HVM_REGISTER_SAVE_RESTORE(LAPIC, lapic_save_hidden, lapic_load_hidden,
+ */
 static int lapic_save_hidden(struct domain *d, hvm_domain_context_t *h)
 {
     struct vcpu *v;
@@ -1418,6 +1570,10 @@ static int lapic_save_hidden(struct domain *d, hvm_domain_context_t *h)
     return rc;
 }
 
+/*
+ * used by:
+ *   - arch/x86/hvm/vlapic.c|1597| <<global>> HVM_REGISTER_SAVE_RESTORE(LAPIC_REGS, lapic_save_regs, lapic_load_regs,
+ */
 static int lapic_save_regs(struct domain *d, hvm_domain_context_t *h)
 {
     struct vcpu *v;
@@ -1444,6 +1600,11 @@ static int lapic_save_regs(struct domain *d, hvm_domain_context_t *h)
  * Following lapic_load_hidden()/lapic_load_regs() we may need to
  * correct ID and LDR when they come from an old, broken hypervisor.
  */
+/*
+ * called by:
+ *   - arch/x86/hvm/vlapic.c|1548| <<lapic_load_hidden>> lapic_load_fixup(s);
+ *   - arch/x86/hvm/vlapic.c|1585| <<lapic_load_regs>> lapic_load_fixup(s);
+ */
 static void lapic_load_fixup(struct vlapic *vlapic)
 {
     uint32_t id = vlapic->loaded.id;
@@ -1469,6 +1630,10 @@ static void lapic_load_fixup(struct vlapic *vlapic)
     }
 }
 
+/*
+ * used by:
+ *   - arch/x86/hvm/vlapic.c|1595| <<global>> HVM_REGISTER_SAVE_RESTORE(LAPIC, lapic_save_hidden, lapic_load_hidden,
+ */
 static int lapic_load_hidden(struct domain *d, hvm_domain_context_t *h)
 {
     uint16_t vcpuid;
@@ -1504,6 +1669,10 @@ static int lapic_load_hidden(struct domain *d, hvm_domain_context_t *h)
     return 0;
 }
 
+/*
+ * used by:
+ *   - arch/x86/hvm/vlapic.c|1597| <<global>> HVM_REGISTER_SAVE_RESTORE(LAPIC_REGS, lapic_save_regs, lapic_load_regs,
+ */
 static int lapic_load_regs(struct domain *d, hvm_domain_context_t *h)
 {
     uint16_t vcpuid;
@@ -1545,6 +1714,10 @@ HVM_REGISTER_SAVE_RESTORE(LAPIC, lapic_save_hidden, lapic_load_hidden,
 HVM_REGISTER_SAVE_RESTORE(LAPIC_REGS, lapic_save_regs, lapic_load_regs,
                           1, HVMSR_PER_VCPU);
 
+/*
+ * called by:
+ *   - arch/x86/hvm/hvm.c|1522| <<hvm_vcpu_initialise>> rc = vlapic_init(v);
+ */
 int vlapic_init(struct vcpu *v)
 {
     struct vlapic *vlapic = vcpu_vlapic(v);
@@ -1553,14 +1726,35 @@ int vlapic_init(struct vcpu *v)
 
     if ( !has_vlapic(v->domain) )
     {
+        /*
+	 * APIC can be disabled in two ways:
+	 *  1. 'Hardware disable': via IA32_APIC_BASE_MSR[11]
+	 *     CPU should behave as if it does not have an APIC.
+	 *  2. 'Software disable': via APIC_SPIV[8].
+	 *     APIC is visible but does not respond to interrupt messages.
+	 */
         vlapic->hw.disabled = VLAPIC_HW_DISABLED;
         return 0;
     }
 
+    /*
+     * struct vlapic包含struct periodic_time pt;
+     */
     vlapic->pt.source = PTSRC_lapic;
 
+    /* regs_page类型是struct page_info* */
     if (vlapic->regs_page == NULL)
     {
+        /*
+	 * regs_page使用的地方:
+	 *   - arch/x86/hvm/vlapic.c|1586| <<vlapic_init>> if (vlapic->regs_page == NULL)
+	 *   - arch/x86/hvm/vlapic.c|1588| <<vlapic_init>> vlapic->regs_page = alloc_domheap_page(v->domain, MEMF_no_owner);
+	 *   - arch/x86/hvm/vlapic.c|1589| <<vlapic_init>> if ( vlapic->regs_page == NULL )
+	 *   - arch/x86/hvm/vlapic.c|1599| <<vlapic_init>> vlapic->regs = __map_domain_page_global(vlapic->regs_page);
+	 *   - arch/x86/hvm/vlapic.c|1634| <<vlapic_destroy>> free_domheap_page(vlapic->regs_page);
+	 *   - arch/x86/hvm/vmx/vmcs.c|1241| <<construct_vmcs>> page_to_maddr(vcpu_vlapic(v)->regs_page));
+	 *   - arch/x86/hvm/vmx/vmx.c|3029| <<vmx_install_vlapic_mapping>> virt_page_ma = page_to_maddr(vcpu_vlapic(v)->regs_page);
+	 */
         vlapic->regs_page = alloc_domheap_page(v->domain, MEMF_no_owner);
         if ( vlapic->regs_page == NULL )
         {
@@ -1569,6 +1763,7 @@ int vlapic_init(struct vcpu *v)
             return -ENOMEM;
         }
     }
+    /* reges类型是struct hvm_hw_lapic_regs *regs; */
     if (vlapic->regs == NULL) 
     {
         vlapic->regs = __map_domain_page_global(vlapic->regs_page);
diff --git a/xen/arch/x86/hvm/vmsi.c b/xen/arch/x86/hvm/vmsi.c
index 7126de7..bb29ec4 100644
--- a/xen/arch/x86/hvm/vmsi.c
+++ b/xen/arch/x86/hvm/vmsi.c
@@ -40,6 +40,11 @@
 #include <asm/event.h>
 #include <asm/io_apic.h>
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vmsi.c|77| <<vmsi_deliver>> vmsi_inj_irq(target, vector, trig_mode, delivery_mode);
+ *   - arch/x86/hvm/vmsi.c|88| <<vmsi_deliver>> vmsi_inj_irq(vcpu_vlapic(v), vector,
+ */
 static void vmsi_inj_irq(
     struct vlapic *target,
     uint8_t vector,
@@ -60,6 +65,12 @@ static void vmsi_inj_irq(
     }
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/irq.c|380| <<hvm_inject_msi>> return vmsi_deliver(d, vector, dest, dest_mode, delivery_mode, trig_mode);
+ *   - arch/x86/hvm/vmsi.c|118| <<vmsi_deliver_pirq>> vmsi_deliver(d, vector, dest, dest_mode, delivery_mode, trig_mode);
+ *   - drivers/passthrough/amd/iommu_guest.c|138| <<guest_iommu_deliver_msi>> vmsi_deliver(d, vector, dest, dest_mode, delivery_mode, trig_mode);
+ */
 int vmsi_deliver(
     struct domain *d, int vector,
     uint8_t dest, uint8_t dest_mode,
@@ -99,9 +110,27 @@ int vmsi_deliver(
     return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/passthrough/io.c|918| <<hvm_dirq_assist>> vmsi_deliver_pirq(d, pirq_dpci);
+ */
 void vmsi_deliver_pirq(struct domain *d, const struct hvm_pirq_dpci *pirq_dpci)
 {
     uint32_t flags = pirq_dpci->gmsi.gflags;
+    /*
+     * 更新msi.gvec的地方:
+     *   - drivers/passthrough/io.c|376| <<pt_irq_create_bind>> pirq_dpci->gmsi.gvec = pt_irq_bind->u.msi.gvec;
+     *   - drivers/passthrough/io.c|410| <<pt_irq_create_bind>> pirq_dpci->gmsi.gvec = 0;
+     *   - drivers/passthrough/io.c|435| <<pt_irq_create_bind>> pirq_dpci->gmsi.gvec = pt_irq_bind->u.msi.gvec;
+     *
+     * 使用XEN_DOMCTL_bind_pt_irq的例子:
+     *   - libxc/xc_domain.c|1747| <<xc_domain_update_msi_irq>> domctl.cmd = XEN_DOMCTL_bind_pt_irq;
+     *   - libxc/xc_domain.c|1801| <<xc_domain_bind_pt_irq_int>> domctl.cmd = XEN_DOMCTL_bind_pt_irq;
+     *
+     * qemu-xen-traditional中调用xc_domain_update_msi_irq()的例子:
+     *   - hw/pt-msi.c|144| <<pt_msi_update>> ret = xc_domain_update_msi_irq(xc_handle, domid, gvec,
+     *   - hw/pt-msi.c|322| <<pt_msix_update_one>> ret = xc_domain_update_msi_irq(xc_handle, domid, gvec, pirq, gflags,
+     */
     int vector = pirq_dpci->gmsi.gvec;
     uint8_t dest = (uint8_t)flags;
     bool dest_mode = flags & XEN_DOMCTL_VMSI_X86_DM_MASK;
@@ -119,6 +148,10 @@ void vmsi_deliver_pirq(struct domain *d, const struct hvm_pirq_dpci *pirq_dpci)
 }
 
 /* Return value, -1 : multi-dests, non-negative value: dest_vcpu_id */
+/*
+ * called by:
+ *   - drivers/passthrough/io.c|428| <<pt_irq_create_bind>> dest_vcpu_id = hvm_girq_dest_2_vcpu_id(d, dest, dest_mode);
+ */
 int hvm_girq_dest_2_vcpu_id(struct domain *d, uint8_t dest, uint8_t dest_mode)
 {
     int dest_vcpu_id = -1, w = 0;
@@ -180,6 +213,16 @@ static struct msixtbl_entry *msixtbl_find_entry(
     struct msixtbl_entry *entry;
     struct domain *d = v->domain;
 
+    /*
+     * msixtbl_list在以下使用:
+     *   - arch/x86/hvm/vmsi.c|174| <<msixtbl_initialised>> return !!d->arch.hvm_domain.msixtbl_list.next;
+     *   - arch/x86/hvm/vmsi.c|183| <<msixtbl_find_entry>> list_for_each_entry( entry, &d->arch.hvm_domain.msixtbl_list, list )
+     *   - arch/x86/hvm/vmsi.c|445| <<add_msixtbl_entry>> list_add_rcu(&entry->list, &d->arch.hvm_domain.msixtbl_list);
+     *   - arch/x86/hvm/vmsi.c|498| <<msixtbl_pt_register>> list_for_each_entry( entry, &d->arch.hvm_domain.msixtbl_list, list )
+     *   - arch/x86/hvm/vmsi.c|557| <<msixtbl_pt_unregister>> list_for_each_entry( entry, &d->arch.hvm_domain.msixtbl_list, list )
+     *   - arch/x86/hvm/vmsi.c|583| <<msixtbl_init>> INIT_LIST_HEAD(&d->arch.hvm_domain.msixtbl_list);
+     *   - arch/x86/hvm/vmsi.c|603| <<msixtbl_pt_cleanup>> &d->arch.hvm_domain.msixtbl_list, list )
+     */
     list_for_each_entry( entry, &d->arch.hvm_domain.msixtbl_list, list )
         if ( addr >= entry->gtable &&
              addr < entry->gtable + entry->table_len )
@@ -207,6 +250,9 @@ static struct msi_desc *msixtbl_addr_to_desc(
     return NULL;
 }
 
+/*
+ * struct hvm_io_ops msixtbl_mmio_ops.read = msixtbl_read()
+ */
 static int msixtbl_read(const struct hvm_io_handler *handler,
                         uint64_t address, uint32_t len, uint64_t *pval)
 {
@@ -263,6 +309,11 @@ out:
     return r;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vmsi.c|346| <<_msixtbl_write>> return msixtbl_write(current, address, len, val);
+ *   - arch/x86/hvm/vmsi.c|621| <<msix_write_completion>> if ( msixtbl_write(v, ctrl_address, 4, 0) != X86EMUL_OKAY )
+ */
 static int msixtbl_write(struct vcpu *v, unsigned long address,
                          unsigned int len, unsigned long val)
 {
@@ -285,11 +336,26 @@ static int msixtbl_write(struct vcpu *v, unsigned long address,
     nr_entry = (address - entry->gtable) / PCI_MSIX_ENTRY_SIZE;
 
     offset = address & (PCI_MSIX_ENTRY_SIZE - 1);
+    /*
+     * vector control | msg data | msg upperaddr | msg addr
+     *
+     * PCI_MSIX_ENTRY_VECTOR_CTRL_OFFSET是12, 指向vector control的地址
+     *
+     * 这里的if语句如果满足, 说明下面index是0, 1或者2
+     */
     if ( offset != PCI_MSIX_ENTRY_VECTOR_CTRL_OFFSET )
     {
         index = offset / sizeof(uint32_t);
         if ( nr_entry < MAX_MSIX_ACC_ENTRIES ) 
         {
+            /*
+	     * entry->gentries的定义:
+	     * #define MAX_MSIX_ACC_ENTRIES 3
+	     * unsigned int table_len;
+	     * struct {
+	     *     uint32_t msi_ad[3]; //Shadow of address low, high and data
+             * } gentries[MAX_MSIX_ACC_ENTRIES];
+	     */
             entry->gentries[nr_entry].msi_ad[index] = val;
             acc_bit(set, entry, nr_entry, index);
             if ( len == 8 && !index )
@@ -340,12 +406,45 @@ out:
     return r;
 }
 
+/*
+ * [<ffff82d0802f2ea0>] vmsi.c#msixtbl_write+0x160/0x240
+ * [<ffff82d0802e587a>] hvm_process_io_intercept+0x6a/0x270
+ * [<ffff82d0802e55c7>] intercept.c#hvm_mmio_accept+0x37/0xe0
+ * [<ffff82d0802f2c5f>] vmsi.c#msixtbl_range+0x6f/0x150
+ * [<ffff82d0802e5aa4>] hvm_io_intercept+0x24/0x40
+ * [<ffff82d0802d7407>] emulate.c#hvmemul_do_io+0x1e7/0x5b0
+ * [<ffff82d0802f2c5f>] vmsi.c#msixtbl_range+0x6f/0x150
+ * [<ffff82d0802d7f4e>] emulate.c#hvmemul_do_io_buffer+0x2e/0x70
+ * [<ffff82d0802d8c5b>] emulate.c#hvmemul_linear_mmio_access+0x23b/0x530
+ * [<ffff82d0802d96cc>] emulate.c#hvmemul_write+0x46c/0x500
+ * [<ffff82d0802d91cf>] hvmemul_insn_fetch+0x3f/0xa0
+ * [<ffff82d0802a16c1>] x86_emulate.c#x86_decode+0x11b1/0x1e40
+ * [<ffff82d0802a4427>] x86_emulate+0x20d7/0x1d610
+ * [<ffff82d080311073>] __get_gfn_type_access+0xf3/0x280
+ * [<ffff82d0802da26a>] emulate.c#_hvm_emulate_one+0x4a/0x1c0
+ * [<ffff82d0802da088>] hvm_emulate_init_once+0x78/0xb0
+ * [<ffff82d0802e5efb>] hvm_emulate_one_insn+0x3b/0x120
+ * [<ffff82d0802e0177>] hvm.c#__hvm_copy+0xd7/0x350
+ * [<ffff82d0802bfa60>] x86_insn_is_mem_access+0/0xc0
+ * [<ffff82d0802de977>] hvm_hap_nested_page_fault+0x117/0x6b0
+ * [<ffff82d080234635>] schedule.c#schedule+0x245/0x620
+ * [<ffff82d0803076e9>] vmx_vmexit_handler+0x969/0x1b20
+ * [<ffff82d08030a161>] nvmx_switch_guest+0x81/0x19c0
+ * [<ffff82d080308989>] vmx_vmenter_helper+0xe9/0x3a0
+ * [<ffff82d08023a6bd>] tasklet.c#tasklet_softirq_action+0x3d/0x70
+ * [<ffff82d08030db4c>] vmx_asm_vmexit_handler+0x3c/0x110
+ *
+ * struct hvm_io_ops msixtbl_mmio_ops.write = _msixtlb_write()
+ */
 static int _msixtbl_write(const struct hvm_io_handler *handler,
                           uint64_t address, uint32_t len, uint64_t val)
 {
     return msixtbl_write(current, address, len, val);
 }
 
+/*
+ * struct hvm_io_ops msixtbl_mmio_ops.accept = msixtbl_range()
+ */
 static bool_t msixtbl_range(const struct hvm_io_handler *handler,
                             const ioreq_t *r)
 {
@@ -415,6 +514,10 @@ static const struct hvm_io_ops msixtbl_mmio_ops = {
     .write = _msixtbl_write,
 };
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vmsi.c|504| <<msixtbl_pt_register>> add_msixtbl_entry(d, pdev, gtable, entry);
+ */
 static void add_msixtbl_entry(struct domain *d,
                               struct pci_dev *pdev,
                               uint64_t gtable,
@@ -446,6 +549,10 @@ static void del_msixtbl_entry(struct msixtbl_entry *entry)
     call_rcu(&entry->rcu, free_msixtbl_entry);
 }
 
+/*
+ * called by:
+ *   - drivers/passthrough/io.c|376| <<pt_irq_create_bind>> rc = msixtbl_pt_register(d, info, pt_irq_bind->u.msi.gtable);
+ */
 int msixtbl_pt_register(struct domain *d, struct pirq *pirq, uint64_t gtable)
 {
     struct irq_desc *irq_desc;
@@ -555,6 +662,10 @@ found:
     spin_unlock_irq(&irq_desc->lock);
 }
 
+/*
+ * called by:
+ *   - drivers/passthrough/pci.c|1412| <<assign_device>> msixtbl_init(d);
+ */
 void msixtbl_init(struct domain *d)
 {
     struct hvm_io_handler *handler;
@@ -562,6 +673,16 @@ void msixtbl_init(struct domain *d)
     if ( !is_hvm_domain(d) || !has_vlapic(d) || msixtbl_initialised(d) )
         return;
 
+    /*
+     * used by:
+     *   - arch/x86/hvm/vmsi.c|174| <<msixtbl_initialised>> return !!d->arch.hvm_domain.msixtbl_list.next;
+     *   - arch/x86/hvm/vmsi.c|183| <<msixtbl_find_entry>> list_for_each_entry( entry, &d->arch.hvm_domain.msixtbl_list, list )
+     *   - arch/x86/hvm/vmsi.c|445| <<add_msixtbl_entry>> list_add_rcu(&entry->list, &d->arch.hvm_domain.msixtbl_list);
+     *   - arch/x86/hvm/vmsi.c|498| <<msixtbl_pt_register>> list_for_each_entry( entry, &d->arch.hvm_domain.msixtbl_list, list )
+     *   - arch/x86/hvm/vmsi.c|557| <<msixtbl_pt_unregister>> list_for_each_entry( entry, &d->arch.hvm_domain.msixtbl_list, list )
+     *   - arch/x86/hvm/vmsi.c|583| <<msixtbl_init>> INIT_LIST_HEAD(&d->arch.hvm_domain.msixtbl_list);
+     *   - arch/x86/hvm/vmsi.c|603| <<msixtbl_pt_cleanup>> &d->arch.hvm_domain.msixtbl_list, list )
+     */
     INIT_LIST_HEAD(&d->arch.hvm_domain.msixtbl_list);
 
     handler = hvm_next_io_handler(d);
@@ -588,6 +709,10 @@ void msixtbl_pt_cleanup(struct domain *d)
     spin_unlock(&d->event_lock);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/ioreq.c|82| <<hvm_io_assist>> msix_write_completion(v);
+ */
 void msix_write_completion(struct vcpu *v)
 {
     unsigned long ctrl_address = v->arch.hvm_vcpu.hvm_io.msix_unmask_address;
diff --git a/xen/arch/x86/hvm/vmx/intr.c b/xen/arch/x86/hvm/vmx/intr.c
index 4c0f1c8..88a1410 100644
--- a/xen/arch/x86/hvm/vmx/intr.c
+++ b/xen/arch/x86/hvm/vmx/intr.c
@@ -67,6 +67,17 @@
  * the STI- and MOV-SS-blocking interruptibility-state flags.
  */
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vmx/intr.c|185| <<nvmx_intr_intercept>> vmx_enable_intr_window(v, intack);
+ *   - arch/x86/hvm/vmx/intr.c|209| <<nvmx_intr_intercept>> vmx_enable_intr_window(v, intack);
+ *   - arch/x86/hvm/vmx/intr.c|212| <<nvmx_intr_intercept>> vmx_enable_intr_window(v, intack);
+ *   - arch/x86/hvm/vmx/intr.c|268| <<vmx_intr_assist>> vmx_enable_intr_window(v, intack);
+ *   - arch/x86/hvm/vmx/intr.c|278| <<vmx_intr_assist>> vmx_enable_intr_window(v, intack);
+ *   - arch/x86/hvm/vmx/intr.c|291| <<vmx_intr_assist>> vmx_enable_intr_window(v, intack);
+ *   - arch/x86/hvm/vmx/intr.c|299| <<vmx_intr_assist>> vmx_enable_intr_window(v, intack);
+ *   - arch/x86/hvm/vmx/intr.c|405| <<vmx_intr_assist>> vmx_enable_intr_window(v, intack);
+ */
 static void vmx_enable_intr_window(struct vcpu *v, struct hvm_intack intack)
 {
     u32 ctl = CPU_BASED_VIRTUAL_INTR_PENDING;
@@ -223,6 +234,9 @@ static int nvmx_intr_intercept(struct vcpu *v, struct hvm_intack intack)
     return 0;
 }
 
+/*
+ * 在arch/x86/hvm/vmx/entry.S中各种调用
+ */
 void vmx_intr_assist(void)
 {
     struct hvm_intack intack;
diff --git a/xen/arch/x86/hvm/vmx/vmcs.c b/xen/arch/x86/hvm/vmx/vmcs.c
index b5100b5..286f524 100644
--- a/xen/arch/x86/hvm/vmx/vmcs.c
+++ b/xen/arch/x86/hvm/vmx/vmcs.c
@@ -1237,6 +1237,16 @@ static int construct_vmcs(struct vcpu *v)
 
     if ( cpu_has_vmx_tpr_shadow )
     {
+        /*
+	 * regs_page使用的地方:
+	 *   - arch/x86/hvm/vlapic.c|1586| <<vlapic_init>> if (vlapic->regs_page == NULL)
+	 *   - arch/x86/hvm/vlapic.c|1588| <<vlapic_init>> vlapic->regs_page = alloc_domheap_page(v->domain, MEMF_no_owner);
+	 *   - arch/x86/hvm/vlapic.c|1589| <<vlapic_init>> if ( vlapic->regs_page == NULL )
+	 *   - arch/x86/hvm/vlapic.c|1599| <<vlapic_init>> vlapic->regs = __map_domain_page_global(vlapic->regs_page);
+	 *   - arch/x86/hvm/vlapic.c|1634| <<vlapic_destroy>> free_domheap_page(vlapic->regs_page);
+	 *   - arch/x86/hvm/vmx/vmcs.c|1241| <<construct_vmcs>> page_to_maddr(vcpu_vlapic(v)->regs_page));
+	 *   - arch/x86/hvm/vmx/vmx.c|3029| <<vmx_install_vlapic_mapping>> virt_page_ma = page_to_maddr(vcpu_vlapic(v)->regs_page);
+	 */
         __vmwrite(VIRTUAL_APIC_PAGE_ADDR,
                   page_to_maddr(vcpu_vlapic(v)->regs_page));
         __vmwrite(TPR_THRESHOLD, 0);
diff --git a/xen/arch/x86/hvm/vmx/vmx.c b/xen/arch/x86/hvm/vmx/vmx.c
index b18ccea..ab8d11b 100644
--- a/xen/arch/x86/hvm/vmx/vmx.c
+++ b/xen/arch/x86/hvm/vmx/vmx.c
@@ -1749,6 +1749,12 @@ static int nvmx_vmexit_event(struct vcpu *v, const struct x86_event *event)
     return NESTEDHVM_VMEXIT_DONE;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vmx/vmx.c|1799| <<vmx_inject_extint>> __vmx_inject_exception(trap, X86_EVENTTYPE_EXT_INTR,
+ *   - arch/x86/hvm/vmx/vmx.c|1819| <<vmx_inject_nmi>> __vmx_inject_exception(2, X86_EVENTTYPE_NMI,
+ *   - arch/x86/hvm/vmx/vmx.c|1902| <<vmx_inject_event>> __vmx_inject_exception(_event.vector, _event.type, _event.error_code);
+ */
 static void __vmx_inject_exception(int trap, int type, int error_code)
 {
     unsigned long intr_fields;
@@ -1780,6 +1786,12 @@ static void __vmx_inject_exception(int trap, int type, int error_code)
         curr->arch.hvm_vmx.vmx_emulate = 1;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vmx/intr.c|198| <<nvmx_intr_intercept>> vmx_inject_extint(intack.vector, intack.source);
+ *   - arch/x86/hvm/vmx/intr.c|218| <<nvmx_intr_intercept>> vmx_inject_extint(intack.vector, intack.source);
+ *   - arch/x86/hvm/vmx/intr.c|391| <<vmx_intr_assist>> vmx_inject_extint(intack.vector, intack.source);
+ */
 void vmx_inject_extint(int trap, uint8_t source)
 {
     struct vcpu *v = current;
@@ -1796,6 +1808,9 @@ void vmx_inject_extint(int trap, uint8_t source)
             return;
         }
     }
+    /*
+     * 参数的trap就是vector
+     */
     __vmx_inject_exception(trap, X86_EVENTTYPE_EXT_INTR,
                            X86_EVENT_NO_EC);
 }
@@ -1947,6 +1962,12 @@ static void vmx_set_info_guest(struct vcpu *v)
     vmx_vmcs_exit(v);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vlapic.c|200| <<vlapic_set_irq>> hvm_funcs.update_eoi_exit_bitmap(target, vec, trig);
+ *
+ * struct hvm_function_table vmx_function_table.update_eoi_exit_bitmap = vmx_update_eoi_exit_bitmap()
+ */
 static void vmx_update_eoi_exit_bitmap(struct vcpu *v, u8 vector, u8 trig)
 {
     if ( trig )
@@ -1960,6 +1981,12 @@ static int vmx_virtual_intr_delivery_enabled(void)
     return cpu_has_vmx_virtual_intr_delivery;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vlapic.c|1578| <<lapic_load_regs>> hvm_funcs.process_isr(vlapic_find_highest_isr(s), v);
+ *
+ * struct hvm_function_table vmx_function_table.process_isr = vmx_process_isr()
+ */
 static void vmx_process_isr(int isr, struct vcpu *v)
 {
     unsigned long status;
@@ -2059,6 +2086,12 @@ static void __vmx_deliver_posted_interrupt(struct vcpu *v)
     }
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vlapic.c|173| <<vlapic_set_irq>> hvm_funcs.deliver_posted_intr(target, vec);
+ *
+ * struct hvm_function_table vmx_function_table.deliver_posted_intr = vmx_deliver_posted_intr()
+ */
 static void vmx_deliver_posted_intr(struct vcpu *v, u8 vector)
 {
     if ( pi_test_and_set_pir(vector, &v->arch.hvm_vmx.pi_desc) )
@@ -2109,6 +2142,16 @@ static void vmx_deliver_posted_intr(struct vcpu *v, u8 vector)
     vcpu_kick(v);
 }
 
+/*
+ * used by:
+ *   - arch/x86/hvm/vlapic.c|124| <<vlapic_find_highest_irr>> if ( hvm_funcs.sync_pir_to_irr )
+ *   - arch/x86/hvm/vlapic.c|125| <<vlapic_find_highest_irr>> hvm_funcs.sync_pir_to_irr(vlapic_vcpu(vlapic));
+ *   - arch/x86/hvm/vlapic.c|1503| <<lapic_save_regs>> if ( hvm_funcs.sync_pir_to_irr )
+ *   - arch/x86/hvm/vlapic.c|1504| <<lapic_save_regs>> hvm_funcs.sync_pir_to_irr(v);
+ *   - arch/x86/hvm/vmx/vmx.c|2526| <<start_vmx>> vmx_function_table.sync_pir_to_irr = NULL;
+ *
+ * struct hvm_function_table vmx_function_table.sync_pir_to_irr = vmx_sync_pir_to_irr()
+ */
 static void vmx_sync_pir_to_irr(struct vcpu *v)
 {
     struct vlapic *vlapic = vcpu_vlapic(v);
@@ -2125,6 +2168,12 @@ static void vmx_sync_pir_to_irr(struct vcpu *v)
         vlapic_set_vector(i, &vlapic->regs->data[APIC_IRR]);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vlapic.c|169| <<vlapic_test_irq>> hvm_funcs.test_pir(const_vlapic_vcpu(vlapic), vec) )
+ *
+ * struct hvm_function_table vmx_function_table.test_pir = vmx_test_pir()
+ */
 static bool vmx_test_pir(const struct vcpu *v, uint8_t vec)
 {
     return pi_test_pir(vec, &v->arch.hvm_vmx.pi_desc);
@@ -2975,6 +3024,10 @@ gp_fault:
     return X86EMUL_EXCEPTION;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vmx/vmx.c|412| <<vmx_domain_initialise>> if ( (rc = vmx_alloc_vlapic_mapping(d)) != 0 )
+ */
 static int vmx_alloc_vlapic_mapping(struct domain *d)
 {
     struct page_info *pg;
@@ -2989,6 +3042,14 @@ static int vmx_alloc_vlapic_mapping(struct domain *d)
     mfn = page_to_mfn(pg);
     clear_domain_page(_mfn(mfn));
     share_xen_page_with_guest(pg, d, XENSHARE_writable);
+    /*
+     *  apic_access_mfn在以下使用:
+     *   - arch/x86/hvm/mtrr.c|787| <<epte_get_entry_emt>> if ( (mfn_x(mfn) ^ d->arch.hvm_domain.vmx.apic_access_mfn) >> order )
+     *   - arch/x86/hvm/vmx/vmx.c|3005| <<vmx_alloc_vlapic_mapping>> d->arch.hvm_domain.vmx.apic_access_mfn = mfn;
+     *   - arch/x86/hvm/vmx/vmx.c|3014| <<vmx_free_vlapic_mapping>> unsigned long mfn = d->arch.hvm_domain.vmx.apic_access_mfn;
+     *   - arch/x86/hvm/vmx/vmx.c|3024| <<vmx_install_vlapic_mapping>> if ( v->domain->arch.hvm_domain.vmx.apic_access_mfn == 0 )
+     *   - arch/x86/hvm/vmx/vmx.c|3030| <<vmx_install_vlapic_mapping>> apic_page_ma = v->domain->arch.hvm_domain.vmx.apic_access_mfn;
+     */
     d->arch.hvm_domain.vmx.apic_access_mfn = mfn;
     set_mmio_p2m_entry(d, paddr_to_pfn(APIC_DEFAULT_PHYS_BASE), _mfn(mfn),
                        PAGE_ORDER_4K, p2m_get_hostp2m(d)->default_access);
@@ -3004,6 +3065,10 @@ static void vmx_free_vlapic_mapping(struct domain *d)
         free_shared_domheap_page(mfn_to_page(mfn));
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vmx/vmx.c|465| <<vmx_vcpu_initialise>> vmx_install_vlapic_mapping(v);
+ */
 static void vmx_install_vlapic_mapping(struct vcpu *v)
 {
     paddr_t virt_page_ma, apic_page_ma;
@@ -3014,6 +3079,14 @@ static void vmx_install_vlapic_mapping(struct vcpu *v)
     ASSERT(cpu_has_vmx_virtualize_apic_accesses);
 
     virt_page_ma = page_to_maddr(vcpu_vlapic(v)->regs_page);
+    /*
+     * apic_access_mfn在以下使用:
+     *   - arch/x86/hvm/mtrr.c|787| <<epte_get_entry_emt>> if ( (mfn_x(mfn) ^ d->arch.hvm_domain.vmx.apic_access_mfn) >> order )
+     *   - arch/x86/hvm/vmx/vmx.c|3005| <<vmx_alloc_vlapic_mapping>> d->arch.hvm_domain.vmx.apic_access_mfn = mfn;
+     *   - arch/x86/hvm/vmx/vmx.c|3014| <<vmx_free_vlapic_mapping>> unsigned long mfn = d->arch.hvm_domain.vmx.apic_access_mfn;
+     *   - arch/x86/hvm/vmx/vmx.c|3024| <<vmx_install_vlapic_mapping>> if ( v->domain->arch.hvm_domain.vmx.apic_access_mfn == 0 )
+     *   - arch/x86/hvm/vmx/vmx.c|3030| <<vmx_install_vlapic_mapping>> apic_page_ma = v->domain->arch.hvm_domain.vmx.apic_access_mfn;
+     */
     apic_page_ma = v->domain->arch.hvm_domain.vmx.apic_access_mfn;
     apic_page_ma <<= PAGE_SHIFT;
 
diff --git a/xen/arch/x86/io_apic.c b/xen/arch/x86/io_apic.c
index f959090..71864a8 100644
--- a/xen/arch/x86/io_apic.c
+++ b/xen/arch/x86/io_apic.c
@@ -2522,6 +2522,12 @@ void __init init_ioapic_mappings(void)
     unsigned int i, idx = FIX_IO_APIC_BASE_0;
     union IO_APIC_reg_01 reg_01;
 
+    /*
+     * 在desktop上:
+     *   smp_found_config = true
+     *   nr_ioapics = 1
+     */
+
     if ( smp_found_config )
         nr_irqs_gsi = 0;
     for ( i = 0; i < nr_ioapics; i++ )
@@ -2560,6 +2566,9 @@ void __init init_ioapic_mappings(void)
             /* The number of IO-APIC IRQ registers (== #pins): */
             reg_01.raw = io_apic_read(i, 1);
             nr_ioapic_entries[i] = reg_01.bits.entries + 1;
+	    /*
+	     * nr_irqs_gsi上面设置的开始是0, nr_ioapic_entries[i]是120
+	     */
             nr_irqs_gsi += nr_ioapic_entries[i];
 
             if ( rangeset_add_singleton(mmio_ro_ranges,
@@ -2569,8 +2578,16 @@ void __init init_ioapic_mappings(void)
         }
     }
 
+    /*
+     * highest_gsi()是119
+     */
     nr_irqs_gsi = max(nr_irqs_gsi, highest_gsi() + 1);
 
+    /*
+     * max_gsi_irqs是0
+     *
+     * 因为nr_irqs默认是0, max_gsi_irqs=4096
+     */
     if ( max_gsi_irqs == 0 )
         max_gsi_irqs = nr_irqs ? nr_irqs / 8 : PAGE_SIZE;
     else if ( nr_irqs != 0 && max_gsi_irqs > nr_irqs )
@@ -2595,6 +2612,9 @@ void __init init_ioapic_mappings(void)
         nr_irqs_gsi = max_gsi_irqs;
     }
 
+    /*
+     * 在desktop上默认nr_irqs在这里是0
+     */
     if ( nr_irqs == 0 )
         nr_irqs = cpu_has_apic ?
                   max(16U + num_present_cpus() * NR_DYNAMIC_VECTORS,
diff --git a/xen/arch/x86/irq.c b/xen/arch/x86/irq.c
index c0ab299..64066c6 100644
--- a/xen/arch/x86/irq.c
+++ b/xen/arch/x86/irq.c
@@ -26,6 +26,53 @@
 #include <asm/mach-generic/mach_apic.h>
 #include <public/physdev.h>
 
+/*
+ * 在arch/x86/x86_64/entry.S,
+ * autogen_entrypoints生成vector table, 每一个vector指向一个处理函数
+ * 函数都差不多 (每个cpu支持256个vector):
+ *
+ * 先"movb  $vec,4(%rsp)", 再"jmp   common_interrupt"
+ *
+ * 在arch/x86/x86_64/entry.S:
+ * 392 ENTRY(common_interrupt)
+ * 393         SAVE_ALL CLAC
+ * 394         CR4_PV32_RESTORE
+ * 395         movq %rsp,%rdi
+ * 396         callq do_IRQ
+ * 397         jmp ret_from_intr
+ *
+ * do_IRQ()如何把vector发送到guest?
+ *
+ * 1. 先通过vector查找percpu的vector_irq[vector]找到irq:
+ * int irq = __get_cpu_var(vector_irq[vector]);
+ *
+ * 2. 再通过irq找到对应的struct irq_desc, x86下就是&irq_desc[irq]:
+ * desc = irq_to_desc(irq);
+ *
+ * 3. 很可能desc->status & IRQ_GUEST是true, 就要调用__do_IRQ_guest(irq)了
+ *
+ * 4. 如果是dom0, 调用send_guest_pirq()往dom0插入event
+ *
+ *
+ * 重要的函数或者数据结构:
+ *
+ * - vector_irq[vector]: 把cpu的vector转换成irq, 索引&irq_desc[irq]
+ * - domain_irq_to_pirq(d, irq)负责将xen的irq转换成某个domain d的pirq
+ * - pirq_info(d, pirq)负责将某个domain d的pirq转换成'struct pirq'
+ *
+ * struct pirq {
+ *   int pirq;
+ *   u16 evtchn;
+ *   bool_t masked;
+ *   struct rcu_head rcu_head;
+ *   struct arch_pirq arch;
+ * };
+ *
+ * dom0 linux的核心函数感觉是__startup_pirq()
+ *
+ * xen有自己的irq, linux有自己的irq, pirq是domain相关的, linux和xen都认识
+ */
+
 static int parse_irq_vector_map_param(const char *s);
 
 /* opt_noirqbalance: If true, software IRQ balancing/affinity is disabled. */
@@ -48,6 +95,27 @@ static DECLARE_BITMAP(used_vectors, NR_VECTORS);
 
 static DEFINE_SPINLOCK(vector_lock);
 
+/*
+ * 使用的地方:
+ *   - xen/arch/x86/i8259.c|106| <<_disable_8259A_irq>> per_cpu(vector_irq, 0)[LEGACY_VECTOR(irq)] = ~irq;
+ *   - xen/arch/x86/i8259.c|122| <<enable_8259A_irq>> per_cpu(vector_irq, 0)[LEGACY_VECTOR(desc->irq)] = desc->irq;
+ *   - xen/arch/x86/i8259.c|352| <<init_IRQ>> per_cpu(vector_irq, cpu)[FIRST_LEGACY_VECTOR + irq] = irq;
+ *   - xen/arch/x86/i8259.c|357| <<init_IRQ>> per_cpu(vector_irq, cpu)[IRQ0_VECTOR] = 0;
+ *   - xen/arch/x86/irq.c|134| <<__bind_irq_vector>> per_cpu(vector_irq, cpu)[vector] = irq;
+ *   - xen/arch/x86/irq.c|284| <<__clear_irq_vector>> ASSERT( per_cpu(vector_irq, cpu)[vector] == irq );
+ *   - xen/arch/x86/irq.c|285| <<__clear_irq_vector>> per_cpu(vector_irq, cpu)[vector] = ~irq;
+ *   - xen/arch/x86/irq.c|309| <<__clear_irq_vector>> ASSERT( per_cpu(vector_irq, cpu)[old_vector] == irq );
+ *   - xen/arch/x86/irq.c|311| <<__clear_irq_vector>> per_cpu(vector_irq, cpu)[old_vector] = ~irq;
+ *   - xen/arch/x86/irq.c|385| <<init_irq_data>> this_cpu(vector_irq)[vector] = INT_MIN;
+ *   - xen/arch/x86/irq.c|548| <<__assign_irq_vector>> if (per_cpu(vector_irq, new_cpu)[vector] >= 0)
+ *   - xen/arch/x86/irq.c|560| <<__assign_irq_vector>> per_cpu(vector_irq, new_cpu)[vector] = irq;
+ *   - xen/arch/x86/irq.c|617| <<setup_vector_irq>> per_cpu(vector_irq, cpu)[vector] = INT_MIN;
+ *   - xen/arch/x86/irq.c|631| <<setup_vector_irq>> per_cpu(vector_irq, cpu)[vector] = irq;
+ *   - xen/arch/x86/irq.c|691| <<irq_move_cleanup_interrupt>> irq = __get_cpu_var(vector_irq)[vector];
+ *   - xen/arch/x86/irq.c|729| <<irq_move_cleanup_interrupt>> __get_cpu_var(vector_irq)[vector] = ~irq;
+ *   - xen/arch/x86/irq.c|861| <<do_IRQ>> int irq = __get_cpu_var(vector_irq[vector]);
+ *   - xen/arch/x86/smpboot.c|1060| <<smp_intr_init>> per_cpu(vector_irq, cpu)[vector] = irq;
+ */
 DEFINE_PER_CPU(vector_irq_t, vector_irq);
 
 DEFINE_PER_CPU(struct cpu_user_regs *, __irq_regs);
@@ -112,6 +180,10 @@ static void trace_irq_mask(u32 event, int irq, int vector, cpumask_t *mask)
     trace_var(event, 1, sizeof(d), &d);
 }
 
+/*
+ * called by:
+ *   - arch/x86/irq.c|220| <<bind_irq_vector>> ret = __bind_irq_vector(irq, vector, cpu_mask);
+ */
 static int __init __bind_irq_vector(int irq, int vector, const cpumask_t *cpu_mask)
 {
     cpumask_t online_mask;
@@ -143,6 +215,10 @@ static int __init __bind_irq_vector(int irq, int vector, const cpumask_t *cpu_ma
     return 0;
 }
 
+/*
+ * called by:
+ *   - arch/x86/io_apic.c|1896| <<check_timer>> if ((ret = bind_irq_vector(0, vector, &mask_all)))
+ */
 int __init bind_irq_vector(int irq, int vector, const cpumask_t *cpu_mask)
 {
     unsigned long flags;
@@ -157,18 +233,43 @@ int __init bind_irq_vector(int irq, int vector, const cpumask_t *cpu_mask)
 /*
  * Dynamic irq allocate and deallocation for MSI
  */
+/*
+ * called by:
+ *   - arch/x86/hpet.c|376| <<hpet_assign_irq>> if ( (irq = create_irq(NUMA_NO_NODE)) < 0 )
+ *   - arch/x86/irq.c|2036| <<map_domain_pirq>> irq = create_irq(NUMA_NO_NODE);
+ *   - arch/x86/irq.c|2673| <<allocate_and_map_msi_pirq>> irq = create_irq(NUMA_NO_NODE);
+ *   - drivers/passthrough/amd/iommu_init.c|783| <<set_iommu_interrupt_handler>> irq = create_irq(NUMA_NO_NODE);
+ *   - drivers/passthrough/vtd/iommu.c|1130| <<iommu_set_interrupt>> irq = create_irq(rhsa ? pxm_to_node(rhsa->proximity_domain)
+ */
 int create_irq(nodeid_t node)
 {
     int irq, ret;
     struct irq_desc *desc;
 
+    /*
+     * 在desktop默认:
+     * (XEN) IRQ limits: 120 GSI, 1432 MSI/MSI-X
+     * nr_irqs_gsi = 120, nr_irqs = 1552
+     *
+     * 设置nr_irqs=4096后:
+     * (XEN) IRQ limits: 120 GSI, 3976 MSI/MSI-X
+     */
+
     for (irq = nr_irqs_gsi; irq < nr_irqs; irq++)
     {
+        /* 返回&irq_desc[irq] */
         desc = irq_to_desc(irq);
+        /*
+	 * For use with irq_desc.arch.used
+	 *   #define IRQ_UNUSED      (0)
+	 *   #define IRQ_USED        (1)
+	 *   #define IRQ_RESERVED    (-1)
+	 */
         if (cmpxchg(&desc->arch.used, IRQ_UNUSED, IRQ_RESERVED) == IRQ_UNUSED)
            break;
     }
 
+    /* 上面也间接设置了返回值irq */
     if (irq >= nr_irqs)
          return -ENOSPC;
 
@@ -188,6 +289,7 @@ int create_irq(nodeid_t node)
     if (ret < 0)
     {
         desc->arch.used = IRQ_UNUSED;
+	/* 设置返回值irq的地方 */
         irq = ret;
     }
     else if ( hardware_domain )
@@ -438,6 +540,28 @@ static vmask_t *irq_get_used_vector_mask(int irq)
     return ret;
 }
 
+/*
+ * called by:
+ *   - xen/arch/x86/irq.c|591| <<assign_irq_vector>> ret = __assign_irq_vector(irq, desc, mask ?: TARGET_CPUS);
+ *   - xen/arch/x86/irq.c|780| <<set_desc_affinity>> ret = __assign_irq_vector(irq, desc, mask);
+ *
+ * 如果是assign_irq_vector()进来的, 如果之前mask是NULL, 则参数mask是genapic->target_cpus()
+ *
+ * 调用以下的代码可以获得allocation mask:
+ *
+ * 2274 static void dump_cpu_allocation(void)
+ * 2275 {
+ * 2276     int cpu, new_cpu;
+ * 2277 
+ * 2278     for_each_cpu(cpu, TARGET_CPUS) {
+ * 2279         const cpumask_t *mask = vector_allocation_cpumask(cpu);
+ * 2280 
+ * 2281         for_each_cpu(new_cpu, mask) {
+ * 2282             printk("allocation mask: %d: %d\n", cpu, new_cpu);
+ * 2283         }
+ * 2284     }
+ * 2285 }
+ */
 static int __assign_irq_vector(
     int irq, struct irq_desc *desc, const cpumask_t *mask)
 {
@@ -452,6 +576,11 @@ static int __assign_irq_vector(
      * Also, we've got to be careful not to trash gate
      * 0x80, because int 0x80 is hm, kind of importantish. ;)
      */
+    /*
+     * #define FIRST_DYNAMIC_VECTOR    0x20
+     * #define LAST_DYNAMIC_VECTOR     0xdf 
+     * #define NR_DYNAMIC_VECTORS      (LAST_DYNAMIC_VECTOR - FIRST_DYNAMIC_VECTOR + 1)
+     */
     static int current_vector = FIRST_DYNAMIC_VECTOR, current_offset = 0;
     int cpu, err, old_vector;
     cpumask_t tmp_mask;
@@ -489,6 +618,13 @@ static int __assign_irq_vector(
         if (!cpu_online(cpu))
             continue;
 
+	/*
+	 * 设置genapic的地方:
+	 *   - xen/arch/x86/apic.c|945| <<x2apic_bsp_setup>> genapic = apic_x2apic_probe();
+	 *      xen/arch/x86/apic.c|946| <<x2apic_bsp_setup>> printk("Switched to APIC driver %s.\n", genapic->name);
+	 *
+	 * "x2apic_cluster"是vector_allocation_cpumask_x2apic_cluster()
+	 */
         cpumask_and(&tmp_mask, vector_allocation_cpumask(cpu),
                     &cpu_online_map);
 
@@ -546,10 +682,18 @@ next:
     return err;
 }
 
+/*
+ * called by:
+ *   - xen/arch/x86/io_apic.c|1032| <<setup_IO_APIC_irqs>> vector = assign_irq_vector(irq, NULL);
+ *   - xen/arch/x86/io_apic.c|2232| <<io_apic_set_pci_routing>> vector = assign_irq_vector(irq, NULL);
+ *   - xen/arch/x86/io_apic.c|2396| <<ioapic_guest_write>> ret = assign_irq_vector(irq, NULL);
+ *   - xen/arch/x86/irq.c|204| <<create_irq>> ret = assign_irq_vector(irq, mask);
+ */
 int assign_irq_vector(int irq, const cpumask_t *mask)
 {
     int ret;
     unsigned long flags;
+    /* 相当于&irq_desc[irq] */
     struct irq_desc *desc = irq_to_desc(irq);
     
     BUG_ON(irq >= nr_irqs || irq <0);
@@ -568,6 +712,10 @@ int assign_irq_vector(int irq, const cpumask_t *mask)
  * Initialize vector_irq on a new cpu. This function must be called
  * with vector_lock held.
  */
+/*
+ * called by:
+ *   - arch/x86/smpboot.c|372| <<start_secondary>> setup_vector_irq(cpu);
+ */
 void setup_vector_irq(unsigned int cpu)
 {
     unsigned int irq, vector;
@@ -859,6 +1007,7 @@ void do_IRQ(struct cpu_user_regs *regs)
         goto out_no_unlock;
     }
 
+    /* 就是&irq_desc[irq] */
     desc = irq_to_desc(irq);
 
     spin_lock(&desc->lock);
@@ -1863,12 +2012,16 @@ static inline bool is_free_pirq(const struct domain *d,
         pirq->arch.hvm.emuirq == IRQ_UNBOUND));
 }
 
+/*
+ * 搜索返回一个没人用的pirq
+ */
 int get_free_pirq(struct domain *d, int type)
 {
     int i;
 
     ASSERT(spin_is_locked(&d->event_lock));
 
+    /* gsi用的是nr_irqs_gsi之前的 */
     if ( type == MAP_PIRQ_TYPE_GSI )
     {
         for ( i = 16; i < nr_irqs_gsi; i++ )
@@ -1878,6 +2031,7 @@ int get_free_pirq(struct domain *d, int type)
                 return i;
             }
     }
+    /* msi用的是nr_irqs_gsi之后的?? */
     for ( i = d->nr_pirqs - 1; i >= nr_irqs_gsi; i-- )
         if ( is_free_pirq(d, pirq_info(d, i)) )
         {
@@ -1909,6 +2063,12 @@ int get_free_pirqs(struct domain *d, unsigned int nr)
 
 #define MAX_MSI_IRQS 32 /* limited by MSI capability struct properties */
 
+/*
+ * called and used by:
+ *   - arch/x86/io_apic.c|2411| <<ioapic_guest_write>> ret = map_domain_pirq(hardware_domain, pirq, irq,
+ *   - arch/x86/irq.c|2807| <<allocate_and_map_gsi_pirq>> ret = map_domain_pirq(d, pirq, irq, MAP_PIRQ_TYPE_GSI, NULL);
+ *   - arch/x86/irq.c|2870| <<allocate_and_map_msi_pirq>> ret = map_domain_pirq(d, pirq, irq, type, msi);
+ */
 int map_domain_pirq(
     struct domain *d, int pirq, int irq, int type, void *data)
 {
@@ -2561,6 +2721,9 @@ bool hvm_domain_use_pirq(const struct domain *d, const struct pirq *pirq)
     return is_hvm_domain(d) && pirq && pirq->arch.hvm.emuirq != IRQ_UNBOUND;
 }
 
+/*
+ * 核心思想是搜索返回一个没人用的pirq
+ */
 static int allocate_pirq(struct domain *d, int index, int pirq, int irq,
                          int type, int *nr)
 {
@@ -2598,6 +2761,7 @@ static int allocate_pirq(struct domain *d, int index, int pirq, int irq,
         }
         else
         {
+            /* 搜索返回一个没人用的pirq */
             pirq = get_free_pirq(d, type);
             if ( pirq < 0 )
                 dprintk(XENLOG_G_ERR, "dom%d: no free pirq\n", d->domain_id);
@@ -2656,6 +2820,10 @@ int allocate_and_map_gsi_pirq(struct domain *d, int index, int *pirq_p)
     return ret;
 }
 
+/*
+ * called by only:
+ *   - arch/x86/physdev.c|129| <<physdev_map_pirq>> ret = allocate_and_map_msi_pirq(d, *index, pirq_p, type, msi);
+ */
 int allocate_and_map_msi_pirq(struct domain *d, int index, int *pirq_p,
                               int type, struct msi_info *msi)
 {
@@ -2695,6 +2863,9 @@ int allocate_and_map_msi_pirq(struct domain *d, int index, int *pirq_p,
     pcidevs_lock();
     /* Verify or get pirq. */
     spin_lock(&d->event_lock);
+    /*
+     * 核心思想是搜索返回一个没人用的pirq
+     */
     pirq = allocate_pirq(d, index, *pirq_p, irq, type, &msi->entry_nr);
     if ( pirq < 0 )
     {
diff --git a/xen/arch/x86/mm.c b/xen/arch/x86/mm.c
index a7a76a7..9fd7553 100644
--- a/xen/arch/x86/mm.c
+++ b/xen/arch/x86/mm.c
@@ -3821,6 +3821,12 @@ int donate_page(
     return -EINVAL;
 }
 
+/*
+ * called by:
+ *   - common/grant_table.c|2064| <<gnttab_transfer>> if ( (rc = steal_page(d, page, 0)) < 0 )
+ *   - common/memory.c|611| <<memory_exchange>> rc = steal_page(d, page, MEMF_no_refcount);
+ *   - include/xen/tmem_xen.h|127| <<__tmem_free_page_thispool>> if ( (d == NULL) || steal_page(d,pi,0) == 0 )
+ */
 int steal_page(
     struct domain *d, struct page_info *page, unsigned int memflags)
 {
@@ -5234,6 +5240,17 @@ void __iomem *ioremap(paddr_t pa, size_t len)
     return (void __force __iomem *)va;
 }
 
+/*
+ * called by:
+ *   - arch/x86/domain_page.c|327| <<mapcache_domain_init>> return create_perdomain_mapping(d, (unsigned long )dcache->inuse,
+ *   - arch/x86/domain_page.c|350| <<mapcache_vcpu_init>> int rc = create_perdomain_mapping(d, MAPCACHE_VIRT_START, ents,
+ *   - arch/x86/domain_page.c|355| <<mapcache_vcpu_init>> rc = create_perdomain_mapping(d, (unsigned long )dcache->inuse,
+ *   - arch/x86/domain_page.c|358| <<mapcache_vcpu_init>> rc = create_perdomain_mapping(d, (unsigned long )dcache->garbage,
+ *   - arch/x86/hvm/hvm.c|586| <<hvm_domain_initialise>> rc = create_perdomain_mapping(d, PERDOMAIN_VIRT_START, 0, NULL, NULL);
+ *   - arch/x86/pv/domain.c|100| <<pv_create_gdt_ldt_l1tab>> return create_perdomain_mapping(v->domain, GDT_VIRT_START(v),
+ *   - arch/x86/pv/domain.c|205| <<pv_domain_initialise>> rc = create_perdomain_mapping(d, GDT_LDT_VIRT_START,
+ *   - arch/x86/x86_64/mm.c|702| <<setup_compat_arg_xlat>> return create_perdomain_mapping(v->domain, ARG_XLAT_START(v),
+ */
 int create_perdomain_mapping(struct domain *d, unsigned long va,
                              unsigned int nr, l1_pgentry_t **pl1tab,
                              struct page_info **ppg)
diff --git a/xen/arch/x86/msi.c b/xen/arch/x86/msi.c
index 4652b98..d8be6b7 100644
--- a/xen/arch/x86/msi.c
+++ b/xen/arch/x86/msi.c
@@ -585,6 +585,10 @@ static struct msi_desc *alloc_msi_entry(unsigned int nr)
     return entry;
 }
 
+/*
+ * called by:
+ *   - arch/x86/irq.c|2163| <<map_domain_pirq>> while ( !(ret = setup_msi_irq(desc, msi_desc + nr)) )
+ */
 int setup_msi_irq(struct irq_desc *desc, struct msi_desc *msidesc)
 {
     const struct pci_dev *pdev = msidesc->dev;
@@ -614,6 +618,11 @@ int setup_msi_irq(struct irq_desc *desc, struct msi_desc *msidesc)
     return rc;
 }
 
+/*
+ * called by:
+ *   - arch/x86/msi.c|606| <<setup_msi_irq>> rc = __setup_msi_irq(desc, msidesc,
+ *   - drivers/passthrough/amd/iommu_init.c|814| <<set_iommu_interrupt_handler>> ret = __setup_msi_irq(irq_to_desc(irq), &iommu->msi, handler);
+ */
 int __setup_msi_irq(struct irq_desc *desc, struct msi_desc *msidesc,
                     hw_irq_controller *handler)
 {
@@ -681,6 +690,10 @@ static struct msi_desc *find_msi_entry(struct pci_dev *dev,
  * multiple messages. A return of zero indicates the successful setup
  * of an entry zero with the new MSI irq or non-zero for otherwise.
  **/
+/*
+ * called by:
+ *   - arch/x86/msi.c|1077| <<__pci_enable_msi>> return msi_capability_init(pdev, msi->irq, desc, msi->entry_nr);
+ */
 static int msi_capability_init(struct pci_dev *dev,
                                int irq,
                                struct msi_desc **desc,
@@ -1037,6 +1050,10 @@ static int msix_capability_init(struct pci_dev *dev,
  * irq or non-zero for otherwise.
  **/
 
+/*
+ * called by:
+ *   - arch/x86/msi.c|1255| <<pci_enable_msi>> __pci_enable_msi(msi, desc);
+ */
 static int __pci_enable_msi(struct msi_info *msi, struct msi_desc **desc)
 {
     struct pci_dev *pdev;
@@ -1093,6 +1110,10 @@ static void __pci_disable_msi(struct msi_desc *entry)
  * of irqs available. Driver should use the returned value to re-send
  * its request.
  **/
+/*
+ * called by:
+ *   - arch/x86/msi.c|1262| <<pci_enable_msi>> return msi->table_base ? __pci_enable_msix(msi, desc) :
+ */
 static int __pci_enable_msix(struct msi_info *msi, struct msi_desc **desc)
 {
     int pos, nr_entries;
@@ -1231,6 +1252,10 @@ int pci_prepare_msix(u16 seg, u8 bus, u8 devfn, bool off)
  * Notice: only construct the msi_desc
  * no change to irq_desc here, and the interrupt is masked
  */
+/*
+ * called by:
+ *   - arch/x86/irq.c|2142| <<map_domain_pirq>> ret = pci_enable_msi(msi, &msi_desc);
+ */
 int pci_enable_msi(struct msi_info *msi, struct msi_desc **desc)
 {
     ASSERT(pcidevs_locked());
@@ -1272,6 +1297,10 @@ void pci_cleanup_msi(struct pci_dev *pdev)
     msi_free_irqs(pdev);
 }
 
+/*
+ * called by:
+ *   - arch/x86/pci.c|95| <<pci_conf_write_intercept>> rc = pci_msi_conf_write_intercept(pdev, reg, size, data);
+ */
 int pci_msi_conf_write_intercept(struct pci_dev *pdev, unsigned int reg,
                                  unsigned int size, uint32_t *data)
 {
diff --git a/xen/arch/x86/pci.c b/xen/arch/x86/pci.c
index a9decd4..db0f2d9 100644
--- a/xen/arch/x86/pci.c
+++ b/xen/arch/x86/pci.c
@@ -11,6 +11,14 @@
 
 static DEFINE_SPINLOCK(pci_config_lock);
 
+/*
+ * called by:
+ *   - arch/x86/pv/emul-priv-op.c|274| <<guest_io_read>> sub_data = pci_conf_read(currd->arch.pci_cf8, port & 3, size);
+ *   - arch/x86/x86_64/pci.c|28| <<pci_conf_read8>> return pci_conf_read(PCI_CONF_ADDRESS(bus, dev, func, reg), reg & 3, 1);
+ *   - arch/x86/x86_64/pci.c|46| <<pci_conf_read16>> return pci_conf_read(PCI_CONF_ADDRESS(bus, dev, func, reg), reg & 2, 2);
+ *   - arch/x86/x86_64/pci.c|64| <<pci_conf_read32>> return pci_conf_read(PCI_CONF_ADDRESS(bus, dev, func, reg), 0, 4);
+ *   - include/xen/pci.h|159| <<pci_conf_read32>> uint32_t pci_conf_read(uint32_t cf8, uint8_t offset, uint8_t bytes);
+ */
 uint32_t pci_conf_read(uint32_t cf8, uint8_t offset, uint8_t bytes)
 {
     unsigned long flags;
@@ -43,6 +51,14 @@ uint32_t pci_conf_read(uint32_t cf8, uint8_t offset, uint8_t bytes)
     return value;
 }
 
+/*
+ * called by:
+ *   - arch/x86/pv/emul-priv-op.c|412| <<guest_io_write>> pci_conf_write(currd->arch.pci_cf8, port & 3, size, data);
+ *   - arch/x86/x86_64/pci.c|77| <<pci_conf_write8>> pci_conf_write(PCI_CONF_ADDRESS(bus, dev, func, reg), reg & 3, 1, data);
+ *   - arch/x86/x86_64/pci.c|90| <<pci_conf_write16>> pci_conf_write(PCI_CONF_ADDRESS(bus, dev, func, reg), reg & 2, 2, data);
+ *   - arch/x86/x86_64/pci.c|103| <<pci_conf_write32>> pci_conf_write(PCI_CONF_ADDRESS(bus, dev, func, reg), 0, 4, data);
+ *   - include/xen/pci.h|160| <<pci_conf_write32>> void pci_conf_write(uint32_t cf8, uint8_t offset, uint8_t bytes, uint32_t data);
+ */
 void pci_conf_write(uint32_t cf8, uint8_t offset, uint8_t bytes, uint32_t data)
 {
     unsigned long flags;
@@ -69,6 +85,11 @@ void pci_conf_write(uint32_t cf8, uint8_t offset, uint8_t bytes, uint32_t data)
     spin_unlock_irqrestore(&pci_config_lock, flags);
 }
 
+/*
+ * called by:
+ *   - arch/x86/mm.c|4444| <<mmcfg_intercept_write>> if ( pci_conf_write_intercept(mmio_ctxt->seg, mmio_ctxt->bdf,
+ *   - arch/x86/pv/emul-priv-op.c|216| <<pci_cfg_ok>> pci_conf_write_intercept(0, machine_bdf, start, size, write) >= 0;
+ */
 int pci_conf_write_intercept(unsigned int seg, unsigned int bdf,
                              unsigned int reg, unsigned int size,
                              uint32_t *data)
diff --git a/xen/arch/x86/physdev.c b/xen/arch/x86/physdev.c
index a5fedca..3ab6973 100644
--- a/xen/arch/x86/physdev.c
+++ b/xen/arch/x86/physdev.c
@@ -88,6 +88,12 @@ static int physdev_hvm_map_pirq(
     return ret;
 }
 
+/*
+ * called only by:
+ *   - arch/x86/physdev.c|335| <<XEN_GUEST_HANDLE_PARAM>> ret = physdev_map_pirq(map.domid, map.type, &map.index, &map.pirq,
+ *
+ * 从desktop nvme进来的时候猜测, type=MAP_PIRQ_TYPE_MSI, *index=-1
+ */
 int physdev_map_pirq(domid_t domid, int type, int *index, int *pirq_p,
                      struct msi_info *msi)
 {
@@ -126,6 +132,9 @@ int physdev_map_pirq(domid_t domid, int type, int *index, int *pirq_p,
             msi->entry_nr = 1;
         /* fallthrough */
     case MAP_PIRQ_TYPE_MULTI_MSI:
+        /*
+	 * 上面desktop的nvme进来, 猜测msi->entry_nr每次分别是0, 1, 2, 3, 4, 5, 6, 7
+         */
         ret = allocate_and_map_msi_pirq(d, *index, pirq_p, type, msi);
         break;
 
@@ -313,6 +322,9 @@ ret_t do_physdev_op(int cmd, XEN_GUEST_HANDLE_PARAM(void) arg)
 
         switch ( map.type )
         {
+        /*
+	 * 在desktop nvme上猜测这里应该是MAP_PIRQ_TYPE_MSI_SEG
+	 */
         case MAP_PIRQ_TYPE_MSI_SEG:
             map.type = MAP_PIRQ_TYPE_MSI;
             msi.seg = map.bus >> 16;
@@ -332,6 +344,11 @@ ret_t do_physdev_op(int cmd, XEN_GUEST_HANDLE_PARAM(void) arg)
         msi.devfn = map.devfn;
         msi.entry_nr = map.entry_nr;
         msi.table_base = map.table_base;
+        /*
+	 * 因为上面在desktop nvme上猜测应该是MAP_PIRQ_TYPE_MSI_SEG
+	 *
+	 * 所以上面把map.type换成了MAP_PIRQ_TYPE_MSI, msi.seg包含了seg的信息
+         */
         ret = physdev_map_pirq(map.domid, map.type, &map.index, &map.pirq,
                                &msi);
 
diff --git a/xen/arch/x86/pv/emul-priv-op.c b/xen/arch/x86/pv/emul-priv-op.c
index 2f92645..52b58a1 100644
--- a/xen/arch/x86/pv/emul-priv-op.c
+++ b/xen/arch/x86/pv/emul-priv-op.c
@@ -177,6 +177,11 @@ static bool admin_io_okay(unsigned int port, unsigned int bytes,
     return ioports_access_permitted(d, port, port + bytes - 1);
 }
 
+/*
+ * called by:
+ *   - arch/x86/pv/emul-priv-op.c|268| <<guest_io_read>> if ( pci_cfg_ok(currd, port & 3, size, NULL) )
+ *   - arch/x86/pv/emul-priv-op.c|406| <<guest_io_write>> if ( pci_cfg_ok(currd, port & 3, size, &data) )
+ */
 static bool pci_cfg_ok(struct domain *currd, unsigned int start,
                        unsigned int size, uint32_t *write)
 {
diff --git a/xen/arch/x86/traps.c b/xen/arch/x86/traps.c
index 86506f3..b60e24b 100644
--- a/xen/arch/x86/traps.c
+++ b/xen/arch/x86/traps.c
@@ -905,6 +905,12 @@ void cpuid_hypervisor_leaves(const struct vcpu *v, uint32_t leaf,
         if ( !is_hvm_domain(d) || subleaf != 0 )
             break;
 
+	/*
+	 * 在dell测试机上:
+	 * cpu_has_vmx_virtualize_x2apic_mode = 16
+	 * cpu_has_vmx_apic_reg_virt = 0
+	 * cpu_has_vmx_virtual_intr_delivery = 0
+	 */
         if ( cpu_has_vmx_apic_reg_virt )
             res->a |= XEN_HVM_CPUID_APIC_ACCESS_VIRT;
 
@@ -914,6 +920,12 @@ void cpuid_hypervisor_leaves(const struct vcpu *v, uint32_t leaf,
          * and wrmsr in the guest will run without VMEXITs (see
          * vmx_vlapic_msr_changed()).
          */
+	/*
+	 * 在dell测试机上:
+	 * cpu_has_vmx_virtualize_x2apic_mode = 16
+	 * cpu_has_vmx_apic_reg_virt = 0
+	 * cpu_has_vmx_virtual_intr_delivery = 0
+	 */
         if ( cpu_has_vmx_virtualize_x2apic_mode &&
              cpu_has_vmx_apic_reg_virt &&
              cpu_has_vmx_virtual_intr_delivery )
diff --git a/xen/arch/x86/x86_emulate/x86_emulate.h b/xen/arch/x86/x86_emulate/x86_emulate.h
index 0c8c80a..2761881 100644
--- a/xen/arch/x86/x86_emulate/x86_emulate.h
+++ b/xen/arch/x86/x86_emulate/x86_emulate.h
@@ -66,6 +66,15 @@ static inline bool is_x86_system_segment(enum x86_segment seg)
  *  AMD SVM: eventinj[10:8] and exitintinfo[10:8] (types 0-4 only)
  */
 enum x86_event_type {
+    /*
+     * used by:
+     *   - arch/x86/hvm/hvm.c|214| <<hvm_event_needs_reinjection>> case X86_EVENTTYPE_EXT_INTR:
+     *   - arch/x86/hvm/svm/intr.c|70| <<svm_inject_extint>> event.fields.type = X86_EVENTTYPE_EXT_INTR;
+     *   - arch/x86/hvm/vmx/vmx.c|1793| <<vmx_inject_extint>> MASK_INSR(X86_EVENTTYPE_EXT_INTR, INTR_INFO_INTR_TYPE_MASK) |
+     *   - arch/x86/hvm/vmx/vmx.c|1799| <<vmx_inject_extint>> __vmx_inject_exception(trap, X86_EVENTTYPE_EXT_INTR,
+     *   - arch/x86/hvm/vmx/vvmx.c|1301| <<sync_exception_state>> case X86_EVENTTYPE_EXT_INTR:
+     *   - arch/x86/x86_emulate/x86_emulate.c|8043| <<build_assertions>> BUILD_BUG_ON(X86_EVENTTYPE_EXT_INTR != 0);
+     */
     X86_EVENTTYPE_EXT_INTR,         /* External interrupt */
     X86_EVENTTYPE_NMI = 2,          /* NMI */
     X86_EVENTTYPE_HW_EXCEPTION,     /* Hardware exception */
diff --git a/xen/common/domain.c b/xen/common/domain.c
index 7484693..a160c0a 100644
--- a/xen/common/domain.c
+++ b/xen/common/domain.c
@@ -607,6 +607,10 @@ int rcu_lock_live_remote_domain_by_id(domid_t dom, struct domain **d)
     return 0;
 }
 
+/*
+ * called by: XEN_DOMCTL_destroydomain
+ *   - common/domctl.c|668| <<do_domctl(XEN_DOMCTL_destroydomain)>> ret = domain_kill(d);
+ */
 int domain_kill(struct domain *d)
 {
     int rc = 0;
@@ -788,6 +792,10 @@ void domain_pause_for_debugger(void)
 #endif
 
 /* Complete domain destroy after RCU readers are not holding old references. */
+/*
+ * used by:
+ *   - common/domain.c|892| <<domain_destroy>> call_rcu(&d->rcu, complete_domain_destroy);
+ */
 static void complete_domain_destroy(struct rcu_head *head)
 {
     struct domain *d = container_of(head, struct domain, rcu);
diff --git a/xen/common/grant_table.c b/xen/common/grant_table.c
index c5950f2..214c349 100644
--- a/xen/common/grant_table.c
+++ b/xen/common/grant_table.c
@@ -2312,6 +2312,11 @@ static void fixup_status_for_copy_pin(const struct active_grant_entry *act,
    count as appropriate. If rc == GNTST_okay, note that this *does*
    take one ref count on the target page, stored in *page.
    If there is any error, *page = NULL, no ref taken. */
+/*
+ * called by:
+ *   - common/grant_table.c|2407| <<acquire_grant_for_copy>> rc = acquire_grant_for_copy(td, trans_gref, rd->domain_id,
+ *   - common/grant_table.c|2709| <<gnttab_copy_claim_buf>> rc = acquire_grant_for_copy(buf->domain, ptr->u.ref,
+ */
 static int
 acquire_grant_for_copy(
     struct domain *rd, grant_ref_t gref, domid_t ldom, bool readonly,
@@ -2600,6 +2605,12 @@ static int gnttab_copy_lock_domain(domid_t domid, bool is_gref,
     return GNTST_okay;
 }
 
+/*
+ * called by:
+ *   - common/grant_table.c|2642| <<gnttab_copy_lock_domains>> gnttab_copy_unlock_domains(src, dest);
+ *   - common/grant_table.c|2800| <<gnttab_copy_one>> gnttab_copy_unlock_domains(src, dest);
+ *   - common/grant_table.c|2887| <<gnttab_copy>> gnttab_copy_unlock_domains(&src, &dest);
+ */
 static void gnttab_copy_unlock_domains(struct gnttab_copy_buf *src,
                                        struct gnttab_copy_buf *dest)
 {
@@ -2615,6 +2626,10 @@ static void gnttab_copy_unlock_domains(struct gnttab_copy_buf *src,
     }
 }
 
+/*
+ * called by:
+ *   - common/grant_table.c|2802| <<gnttab_copy_one>> rc = gnttab_copy_lock_domains(op, src, dest);
+ */
 static int gnttab_copy_lock_domains(const struct gnttab_copy *op,
                                     struct gnttab_copy_buf *src,
                                     struct gnttab_copy_buf *dest)
@@ -2643,6 +2658,24 @@ static int gnttab_copy_lock_domains(const struct gnttab_copy *op,
     return rc;
 }
 
+/*
+ * called by:
+ *   - common/grant_table.c|2776| <<gnttab_copy_one>> gnttab_copy_release_buf(src);
+ *   - common/grant_table.c|2777| <<gnttab_copy_one>> gnttab_copy_release_buf(dest);
+ *   - common/grant_table.c|2789| <<gnttab_copy_one>> gnttab_copy_release_buf(src);
+ *   - common/grant_table.c|2799| <<gnttab_copy_one>> gnttab_copy_release_buf(dest);
+ *   - common/grant_table.c|2849| <<gnttab_copy>> gnttab_copy_release_buf(&src);
+ *   - common/grant_table.c|2850| <<gnttab_copy>> gnttab_copy_release_buf(&dest);
+ *   - common/grant_table.c|2863| <<gnttab_copy>> gnttab_copy_release_buf(&src);
+ *   - common/grant_table.c|2864| <<gnttab_copy>> gnttab_copy_release_buf(&dest);
+ *
+ * gnttab_copy()
+ *  -> gnttab_copy_release_buf()
+ *
+ * gnttab_copy()
+ *  -> gnttab_copy_one()
+ *      -> gnttab_copy_release_buf()
+ */
 static void gnttab_copy_release_buf(struct gnttab_copy_buf *buf)
 {
     if ( buf->virt )
@@ -2667,6 +2700,11 @@ static void gnttab_copy_release_buf(struct gnttab_copy_buf *buf)
     }
 }
 
+/*
+ * called by:
+ *   - common/grant_table.c|2822| <<gnttab_copy_one>> rc = gnttab_copy_claim_buf(op, &op->source, src, GNTCOPY_source_gref);
+ *   - common/grant_table.c|2832| <<gnttab_copy_one>> rc = gnttab_copy_claim_buf(op, &op->dest, dest, GNTCOPY_dest_gref);
+ */
 static int gnttab_copy_claim_buf(const struct gnttab_copy *op,
                                  const struct gnttab_copy_ptr *ptr,
                                  struct gnttab_copy_buf *buf,
@@ -2764,6 +2802,10 @@ static int gnttab_copy_buf(const struct gnttab_copy *op,
     return rc;
 }
 
+/*
+ * called by:
+ *   - common/grant_table.c|2841| <<gnttab_copy()>> rc = gnttab_copy_one(&op, &dest, &src);
+ */
 static int gnttab_copy_one(const struct gnttab_copy *op,
                            struct gnttab_copy_buf *dest,
                            struct gnttab_copy_buf *src)
@@ -2815,6 +2857,11 @@ static int gnttab_copy_one(const struct gnttab_copy *op,
  * positive value) a non-zero value is being handed back (zero needs
  * to be avoided, as that means "success, all done").
  */
+/*
+ * called by:
+ *   - common/compat/grant_table.c|251| <<compat_grant_table_op>> rc = gnttab_copy(guest_handle_cast(nat.uop, gnttab_copy_t), n);
+ *   - common/grant_table.c|3434| <<do_grant_table_op>> rc = gnttab_copy(copy, count);
+ */
 static long gnttab_copy(
     XEN_GUEST_HANDLE_PARAM(gnttab_copy_t) uop, unsigned int count)
 {
diff --git a/xen/common/irq.c b/xen/common/irq.c
index f42512d..1eadfc7 100644
--- a/xen/common/irq.c
+++ b/xen/common/irq.c
@@ -5,6 +5,7 @@ int init_one_irq_desc(struct irq_desc *desc)
 {
     int err;
 
+    /* 如果(desc)->handler != NULL */
     if (irq_desc_initialized(desc))
         return 0;
 
diff --git a/xen/common/memory.c b/xen/common/memory.c
index a6ba33f..e7d326e 100644
--- a/xen/common/memory.c
+++ b/xen/common/memory.c
@@ -273,6 +273,12 @@ out:
     a->nr_done = i;
 }
 
+/*
+ * called by:
+ *   - arch/x86/mm.c|4137| <<xenmem_add_to_physmap_one>> rc = guest_remove_page(d, gfn_x(gpfn));
+ *   - arch/x86/mm/p2m.c|2709| <<p2m_add_foreign>> rc = guest_remove_page(tdom, gpfn);
+ *   - common/memory.c|425| <<decrease_reservation>> if ( guest_remove_page(a->domain, gmfn + j) )
+ */
 int guest_remove_page(struct domain *d, unsigned long gmfn)
 {
     struct page_info *page;
diff --git a/xen/common/page_alloc.c b/xen/common/page_alloc.c
index 5616a82..ffe3f44 100644
--- a/xen/common/page_alloc.c
+++ b/xen/common/page_alloc.c
@@ -160,6 +160,10 @@ string_param("badpage", opt_badpage);
 /*
  * no-bootscrub -> Free pages are not zeroed during boot.
  */
+/*
+ * 在以下使用opt_bootscrub:
+ *   - common/page_alloc.c|2019| <<heap_init_late>> if ( opt_bootscrub )
+ */
 static bool_t opt_bootscrub __initdata = 1;
 boolean_param("bootscrub", opt_bootscrub);
 
@@ -400,6 +404,18 @@ static long midsize_alloc_zone_pages;
 static DEFINE_SPINLOCK(heap_lock);
 static long outstanding_claims; /* total outstanding claims by all domains */
 
+/*
+ * called by:
+ *   - arch/x86/mm.c|3804| <<donate_page>> domain_adjust_tot_pages(d, 1);
+ *   - arch/x86/mm.c|3871| <<steal_page>> if ( !(memflags & MEMF_no_refcount) && !domain_adjust_tot_pages(d, -1) )
+ *   - arch/x86/mm/mem_sharing.c|631| <<page_make_sharable>> drop_dom_ref = !domain_adjust_tot_pages(d, -1);
+ *   - arch/x86/mm/mem_sharing.c|678| <<page_make_private>> if ( domain_adjust_tot_pages(d, 1) == 1 )
+ *   - common/grant_table.c|2149| <<gnttab_transfer>> if ( unlikely(domain_adjust_tot_pages(e, 1) == 1) )
+ *   - common/grant_table.c|2164| <<gnttab_transfer>> bool_t drop_dom_ref = !domain_adjust_tot_pages(e, -1);
+ *   - common/memory.c|673| <<memory_exchange>> !domain_adjust_tot_pages(d, -dec_count));
+ *   - common/page_alloc.c|2195| <<assign_pages>> domain_adjust_tot_pages(d, 1 << order);
+ *   - common/page_alloc.c|2286| <<free_domheap_pages>> drop_dom_ref = !domain_adjust_tot_pages(d, -(1 << order));
+ */
 unsigned long domain_adjust_tot_pages(struct domain *d, long pages)
 {
     long dom_before, dom_after, dom_claimed, sys_before, sys_after;
@@ -2158,6 +2174,13 @@ void init_domheap_pages(paddr_t ps, paddr_t pe)
 }
 
 
+/*
+ * called by:
+ *   - arch/x86/pv/dom0_build.c|516| <<dom0_construct_pv>> if ( assign_pages(d, mfn_to_page(mfn++), 0, 0) )
+ *   - common/memory.c|660| <<memory_exchange>> if ( assign_pages(d, page, exch.out.extent_order,
+ *   - common/memory.c|729| <<memory_exchange>> if ( assign_pages(d, page, 0, MEMF_no_refcount) )
+ *   - common/page_alloc.c|2257| <<alloc_domheap_pages>> assign_pages(d, pg, order, memflags) )
+ */
 int assign_pages(
     struct domain *d,
     struct page_info *pg,
@@ -2211,6 +2234,28 @@ int assign_pages(
 }
 
 
+/*
+ * x86在以下调用
+ *   - arch/x86/hvm/dom0_build.c|104| <<pvh_populate_memory_range>> page = alloc_domheap_pages(d, order, dom0_memflags);
+ *   - arch/x86/mm/p2m-pod.c|221| <<p2m_pod_set_cache_target>> page = alloc_domheap_pages(d, order, 0);
+ *   - arch/x86/pv/dom0_build.c|153| <<setup_pv_physmap>> (page = alloc_domheap_pages(d, 
+ *   - arch/x86/pv/dom0_build.c|179| <<setup_pv_physmap>> (page = alloc_domheap_pages(d,
+ *   - arch/x86/pv/dom0_build.c|234| <<alloc_chunk>> while ( (page = alloc_domheap_pages(d, order, dom0_memflags)) == NULL )
+ *   - arch/x86/pv/dom0_build.c|260| <<alloc_chunk>> pg2 = alloc_domheap_pages(d, order, MEMF_exact_node);
+ *   - arch/x86/pv/dom0_build.c|480| <<dom0_construct_pv>> page = alloc_domheap_pages(d, order, 0);
+ *   - arch/x86/pv/dom0_build.c|497| <<dom0_construct_pv>> page = alloc_domheap_pages(d, order, 0);
+ *   - arch/x86/x86_64/mm.c|565| <<paging_init>> (l1_pg = alloc_domheap_pages(NULL, 2 * PAGETABLE_ORDER,
+ *   - arch/x86/x86_64/mm.c|591| <<paging_init>> else if ( (l1_pg = alloc_domheap_pages(NULL, PAGETABLE_ORDER,
+ *   - arch/x86/x86_64/mm.c|657| <<paging_init>> if ( (l1_pg = alloc_domheap_pages(NULL, PAGETABLE_ORDER,
+ *   - common/memory.c|117| <<increase_reservation>> page = alloc_domheap_pages(d, a->extent_order, a->memflags);
+ *   - common/memory.c|230| <<populate_physmap>> page = alloc_domheap_pages(d, a->extent_order, a->memflags);
+ *   - common/memory.c|626| <<memory_exchange>> page = alloc_domheap_pages(d, exch.out.extent_order,
+ *   - common/page_alloc.c|2125| <<alloc_xenheap_pages>> pg = alloc_domheap_pages(NULL, order, memflags | MEMF_no_scrub);
+ *   - drivers/passthrough/vtd/iommu.c|199| <<alloc_pgtable_maddr>> pg = alloc_domheap_pages(NULL, get_order_from_pages(npages),
+ *   - include/xen/mm.h|194| <<alloc_domheap_page>> #define alloc_domheap_page(d,f) (alloc_domheap_pages(d,0,f))
+ *   - include/xen/tmem_xen.h|115| <<__tmem_alloc_page_thispool>> pi = alloc_domheap_pages(d,0,MEMF_tmem);
+ *   - include/xen/tmem_xen.h|145| <<__tmem_alloc_page>> pi = alloc_domheap_pages(0,0,MEMF_tmem);
+ */
 struct page_info *alloc_domheap_pages(
     struct domain *d, unsigned int order, unsigned int memflags)
 {
@@ -2247,6 +2292,16 @@ struct page_info *alloc_domheap_pages(
     return pg;
 }
 
+/*
+ * x86下的调用:
+ *   - arch/x86/pv/dom0_build.c|263| <<alloc_chunk>> free_domheap_pages(page, free_order);
+ *   - arch/x86/pv/dom0_build.c|268| <<alloc_chunk>> free_domheap_pages(pg2, order);
+ *   - arch/x86/pv/dom0_build.c|503| <<dom0_construct_pv>> free_domheap_pages(page, order);
+ *   - common/memory.c|679| <<XEN_GUEST_HANDLE_PARAM>> free_domheap_pages(page, exch.out.extent_order);
+ *   - common/memory.c|734| <<XEN_GUEST_HANDLE_PARAM>> free_domheap_pages(page, exch.out.extent_order);
+ *   - include/xen/mm.h|195| <<free_domheap_page>> #define free_domheap_page(p) (free_domheap_pages(p,0))
+ *   - include/xen/tmem_xen.h|133| <<__tmem_free_page_thispool>> free_domheap_pages(pi,0);
+ */
 void free_domheap_pages(struct page_info *pg, unsigned int order)
 {
     struct domain *d = page_get_owner(pg);
diff --git a/xen/drivers/passthrough/io.c b/xen/drivers/passthrough/io.c
index 8f16e6c..979fc97 100644
--- a/xen/drivers/passthrough/io.c
+++ b/xen/drivers/passthrough/io.c
@@ -25,6 +25,15 @@
 #include <asm/hvm/support.h>
 #include <asm/io_apic.h>
 
+/*
+ * 在以下使用dpci_list:
+ *   - drivers/passthrough/io.c|71| <<raise_softirq_for>> list_add_tail(&pirq_dpci->softirq_list, &this_cpu(dpci_list));
+ *   - drivers/passthrough/io.c|1053| <<dpci_softirq>> list_splice_init(&per_cpu(dpci_list, cpu), &our_list);
+ *   - drivers/passthrough/io.c|1072| <<dpci_softirq>> list_add_tail(&pirq_dpci->softirq_list, &this_cpu(dpci_list));
+ *   - drivers/passthrough/io.c|1098| <<cpu_callback>> INIT_LIST_HEAD(&per_cpu(dpci_list, cpu));
+ *   - drivers/passthrough/io.c|1109| <<cpu_callback>> ASSERT(list_empty(&per_cpu(dpci_list, cpu)));
+ *   - drivers/passthrough/io.c|1125| <<setup_dpci_softirq>> INIT_LIST_HEAD(&per_cpu(dpci_list, cpu));
+ */
 static DEFINE_PER_CPU(struct list_head, dpci_list);
 
 /*
@@ -68,6 +77,15 @@ static void raise_softirq_for(struct hvm_pirq_dpci *pirq_dpci)
     get_knownalive_domain(pirq_dpci->dom);
 
     local_irq_save(flags);
+    /*
+     * 在以下使用dpci_list:
+     *   - drivers/passthrough/io.c|71| <<raise_softirq_for>> list_add_tail(&pirq_dpci->softirq_list, &this_cpu(dpci_list));
+     *   - drivers/passthrough/io.c|1053| <<dpci_softirq>> list_splice_init(&per_cpu(dpci_list, cpu), &our_list);
+     *   - drivers/passthrough/io.c|1072| <<dpci_softirq>> list_add_tail(&pirq_dpci->softirq_list, &this_cpu(dpci_list));
+     *   - drivers/passthrough/io.c|1098| <<cpu_callback>> INIT_LIST_HEAD(&per_cpu(dpci_list, cpu));
+     *   - drivers/passthrough/io.c|1109| <<cpu_callback>> ASSERT(list_empty(&per_cpu(dpci_list, cpu)));
+     *   - drivers/passthrough/io.c|1125| <<setup_dpci_softirq>> INIT_LIST_HEAD(&per_cpu(dpci_list, cpu));
+     */
     list_add_tail(&pirq_dpci->softirq_list, &this_cpu(dpci_list));
     local_irq_restore(flags);
 
@@ -275,6 +293,11 @@ static struct vcpu *vector_hashing_dest(const struct domain *d,
     return dest;
 }
 
+/*
+ * called by:
+ *   - arch/x86/domctl.c|729| <<arch_do_domctl()::XEN_DOMCTL_bind_pt_irq>> ret = pt_irq_create_bind(d, bind);
+ *   - arch/x86/hvm/vioapic.c|193| <<vioapic_hwdom_map_gsi>> ret = pt_irq_create_bind(currd, &pt_irq_bind);
+ */
 int pt_irq_create_bind(
     struct domain *d, const struct xen_domctl_bind_pt_irq *pt_irq_bind)
 {
@@ -795,6 +818,10 @@ int pt_pirq_iterate(struct domain *d,
     return rc;
 }
 
+/*
+ * called by only:
+ *   - arch/x86/irq.c|1340| <<__do_IRQ_guest>> if ( !is_hvm_domain(d) || !hvm_do_IRQ_dpci(d, pirq) )
+ */
 int hvm_do_IRQ_dpci(struct domain *d, struct pirq *pirq)
 {
     struct hvm_irq_dpci *dpci = domain_get_irq_dpci(d);
@@ -812,6 +839,11 @@ int hvm_do_IRQ_dpci(struct domain *d, struct pirq *pirq)
 }
 
 /* called with d->event_lock held */
+/*
+ * called by:
+ *   - drivers/passthrough/io.c|847| <<_hvm_dpci_msi_eoi>> __msi_pirq_eoi(pirq_dpci);
+ *   - drivers/passthrough/io.c|913| <<hvm_dirq_assist>> __msi_pirq_eoi(pirq_dpci);
+ */
 static void __msi_pirq_eoi(struct hvm_pirq_dpci *pirq_dpci)
 {
     irq_desc_t *desc;
@@ -829,6 +861,10 @@ static void __msi_pirq_eoi(struct hvm_pirq_dpci *pirq_dpci)
     }
 }
 
+/*
+ * called by:
+ *   - drivers/passthrough/io.c|861| <<hvm_dpci_msi_eoi>> pt_pirq_iterate(d, _hvm_dpci_msi_eoi, (void *)(long )vector);
+ */
 static int _hvm_dpci_msi_eoi(struct domain *d,
                              struct hvm_pirq_dpci *pirq_dpci, void *arg)
 {
@@ -852,6 +888,10 @@ static int _hvm_dpci_msi_eoi(struct domain *d,
     return 0;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vlapic.c|440| <<vlapic_handle_EOI>> hvm_dpci_msi_eoi(d, vector);
+ */
 void hvm_dpci_msi_eoi(struct domain *d, int vector)
 {
     if ( !iommu_enabled || !hvm_domain_irq(d)->dpci )
@@ -862,6 +902,10 @@ void hvm_dpci_msi_eoi(struct domain *d, int vector)
     spin_unlock(&d->event_lock);
 }
 
+/*
+ * called by:
+ *   - drivers/passthrough/io.c|1074| <<dpci_softirq>> hvm_dirq_assist(d, pirq_dpci);
+ */
 static void hvm_dirq_assist(struct domain *d, struct hvm_pirq_dpci *pirq_dpci)
 {
     if ( unlikely(!hvm_domain_irq(d)->dpci) && !is_hardware_domain(d) )
@@ -1024,6 +1068,15 @@ static void dpci_softirq(void)
     LIST_HEAD(our_list);
 
     local_irq_disable();
+    /*
+     * 在以下使用dpci_list:
+     *   - drivers/passthrough/io.c|71| <<raise_softirq_for>> list_add_tail(&pirq_dpci->softirq_list, &this_cpu(dpci_list));
+     *   - drivers/passthrough/io.c|1053| <<dpci_softirq>> list_splice_init(&per_cpu(dpci_list, cpu), &our_list);
+     *   - drivers/passthrough/io.c|1072| <<dpci_softirq>> list_add_tail(&pirq_dpci->softirq_list, &this_cpu(dpci_list));
+     *   - drivers/passthrough/io.c|1098| <<cpu_callback>> INIT_LIST_HEAD(&per_cpu(dpci_list, cpu));
+     *   - drivers/passthrough/io.c|1109| <<cpu_callback>> ASSERT(list_empty(&per_cpu(dpci_list, cpu)));
+     *   - drivers/passthrough/io.c|1125| <<setup_dpci_softirq>> INIT_LIST_HEAD(&per_cpu(dpci_list, cpu));
+     */
     list_splice_init(&per_cpu(dpci_list, cpu), &our_list);
     local_irq_enable();
 
diff --git a/xen/include/asm-x86/config.h b/xen/include/asm-x86/config.h
index 9ef9d03..0babe5e 100644
--- a/xen/include/asm-x86/config.h
+++ b/xen/include/asm-x86/config.h
@@ -203,6 +203,14 @@ extern unsigned char boot_edid_info[128];
 #define PERDOMAIN_VIRT_START    (PML4_ADDR(260))
 #define PERDOMAIN_SLOT_MBYTES   (PML4_ENTRY_BYTES >> (20 + PAGETABLE_ORDER))
 #define PERDOMAIN_SLOTS         3
+/*
+ * 在以下调用PERDOMAIN_VIRT_SLOT():
+ *   - arch/x86/mm.c|5248| <<create_perdomain_mapping>> va < PERDOMAIN_VIRT_SLOT(PERDOMAIN_SLOTS));
+ *   - arch/x86/mm.c|5366| <<destroy_perdomain_mapping>> va < PERDOMAIN_VIRT_SLOT(PERDOMAIN_SLOTS));
+ *   - include/asm-x86/config.h|290| <<GDT_LDT_VIRT_START>> #define GDT_LDT_VIRT_START PERDOMAIN_VIRT_SLOT(0)
+ *   - include/asm-x86/config.h|302| <<MAPCACHE_VIRT_START>> #define MAPCACHE_VIRT_START PERDOMAIN_VIRT_SLOT(1)
+ *   - include/asm-x86/config.h|307| <<ARG_XLAT_VIRT_START>> #define ARG_XLAT_VIRT_START PERDOMAIN_VIRT_SLOT(2)
+ */
 #define PERDOMAIN_VIRT_SLOT(s)  (PERDOMAIN_VIRT_START + (s) * \
                                  (PERDOMAIN_SLOT_MBYTES << 20))
 /* Slot 261: machine-to-phys conversion table (256GB). */
diff --git a/xen/include/asm-x86/domain.h b/xen/include/asm-x86/domain.h
index f699119..3b2f153 100644
--- a/xen/include/asm-x86/domain.h
+++ b/xen/include/asm-x86/domain.h
@@ -421,6 +421,14 @@ struct arch_domain
     uint32_t emulation_flags;
 } __cacheline_aligned;
 
+/*
+ * XEN_X86_EMU_LAPIC在以下使用:
+ *   - arch/x86/domain.c|400| <<emulation_flags_ok>> emflags != (XEN_X86_EMU_LAPIC|XEN_X86_EMU_IOAPIC) )
+ *   - arch/x86/domain.c|403| <<emulation_flags_ok>> emflags != XEN_X86_EMU_ALL && emflags != XEN_X86_EMU_LAPIC )
+ *   - arch/x86/setup.c|1585| <<__start_xen>> config.emulation_flags = XEN_X86_EMU_LAPIC|XEN_X86_EMU_IOAPIC;
+ *   - include/asm-x86/domain.h|424| <<has_vlapic>> #define has_vlapic(d) (!!((d)->arch.emulation_flags & XEN_X86_EMU_LAPIC))
+ *   - include/public/arch-x86/xen.h|298| <<XEN_X86_EMU_ALL>> #define XEN_X86_EMU_ALL (XEN_X86_EMU_LAPIC | XEN_X86_EMU_HPET | \
+ */
 #define has_vlapic(d)      (!!((d)->arch.emulation_flags & XEN_X86_EMU_LAPIC))
 #define has_vhpet(d)       (!!((d)->arch.emulation_flags & XEN_X86_EMU_HPET))
 #define has_vpm(d)         (!!((d)->arch.emulation_flags & XEN_X86_EMU_PM))
diff --git a/xen/include/asm-x86/hvm/domain.h b/xen/include/asm-x86/hvm/domain.h
index 7f128c0..dbbcd02 100644
--- a/xen/include/asm-x86/hvm/domain.h
+++ b/xen/include/asm-x86/hvm/domain.h
@@ -162,6 +162,16 @@ struct hvm_domain {
     bool_t                 is_in_uc_mode;
 
     /* hypervisor intercepted msix table */
+    /*
+     * used by:
+     *   - arch/x86/hvm/vmsi.c|174| <<msixtbl_initialised>> return !!d->arch.hvm_domain.msixtbl_list.next;
+     *   - arch/x86/hvm/vmsi.c|183| <<msixtbl_find_entry>> list_for_each_entry( entry, &d->arch.hvm_domain.msixtbl_list, list )
+     *   - arch/x86/hvm/vmsi.c|445| <<add_msixtbl_entry>> list_add_rcu(&entry->list, &d->arch.hvm_domain.msixtbl_list);
+     *   - arch/x86/hvm/vmsi.c|498| <<msixtbl_pt_register>> list_for_each_entry( entry, &d->arch.hvm_domain.msixtbl_list, list )
+     *   - arch/x86/hvm/vmsi.c|557| <<msixtbl_pt_unregister>> list_for_each_entry( entry, &d->arch.hvm_domain.msixtbl_list, list )
+     *   - arch/x86/hvm/vmsi.c|583| <<msixtbl_init>> INIT_LIST_HEAD(&d->arch.hvm_domain.msixtbl_list);
+     *   - arch/x86/hvm/vmsi.c|603| <<msixtbl_pt_cleanup>> &d->arch.hvm_domain.msixtbl_list, list )
+     */
     struct list_head       msixtbl_list;
 
     struct viridian_domain viridian;
diff --git a/xen/include/asm-x86/hvm/hvm.h b/xen/include/asm-x86/hvm/hvm.h
index 6ecad33..6088b9c 100644
--- a/xen/include/asm-x86/hvm/hvm.h
+++ b/xen/include/asm-x86/hvm/hvm.h
@@ -38,6 +38,17 @@ extern bool_t opt_hvm_fep;
 enum hvm_intsrc {
     hvm_intsrc_none,
     hvm_intsrc_pic,
+    /*
+     * used by:
+     *   - arch/x86/hvm/hvm.c|3822| <<hvm_interrupt_blocked>> if ( intack.source == hvm_intsrc_lapic )
+     *   - arch/x86/hvm/irq.c|516| <<hvm_vcpu_ack_pending_irq>> case hvm_intsrc_lapic:
+     *   - arch/x86/hvm/svm/intr.c|127| <<svm_enable_intr_window>> intr.fields.ign_tpr = (intack.source != hvm_intsrc_lapic);
+     *   - arch/x86/hvm/svm/nestedsvm.c|1567| <<nestedsvm_vcpu_interrupt>> case hvm_intsrc_lapic:
+     *   - arch/x86/hvm/vmx/intr.c|196| <<nvmx_intr_intercept>> intack.source == hvm_intsrc_lapic )
+     *   - arch/x86/hvm/vmx/intr.c|282| <<vmx_intr_assist>> ASSERT(intack.source == hvm_intsrc_lapic);
+     *   - arch/x86/hvm/vmx/vvmx.c|1335| <<nvmx_update_apicv>> nvmx->intr.source == hvm_intsrc_lapic &&
+     *   - arch/x86/hvm/vpt.c|94| <<pt_irq_vector>> ASSERT(src == hvm_intsrc_lapic);
+     */
     hvm_intsrc_lapic,
     hvm_intsrc_nmi,
     hvm_intsrc_mce,
diff --git a/xen/include/asm-x86/hvm/irq.h b/xen/include/asm-x86/hvm/irq.h
index f756cb5..5ceed6f 100644
--- a/xen/include/asm-x86/hvm/irq.h
+++ b/xen/include/asm-x86/hvm/irq.h
@@ -132,9 +132,30 @@ struct dev_intx_gsi_link {
 #define HVM_IRQ_DPCI_TRANSLATE       (1u << _HVM_IRQ_DPCI_TRANSLATE_SHIFT)
 
 struct hvm_gmsi_info {
+    /*
+     * 更新msi.gvec的地方:
+     *   - drivers/passthrough/io.c|376| <<pt_irq_create_bind>> pirq_dpci->gmsi.gvec = pt_irq_bind->u.msi.gvec;
+     *   - drivers/passthrough/io.c|410| <<pt_irq_create_bind>> pirq_dpci->gmsi.gvec = 0;
+     *   - drivers/passthrough/io.c|435| <<pt_irq_create_bind>> pirq_dpci->gmsi.gvec = pt_irq_bind->u.msi.gvec;
+     *
+     * 使用XEN_DOMCTL_bind_pt_irq的例子:
+     *   - libxc/xc_domain.c|1747| <<xc_domain_update_msi_irq>> domctl.cmd = XEN_DOMCTL_bind_pt_irq;
+     *   - libxc/xc_domain.c|1801| <<xc_domain_bind_pt_irq_int>> domctl.cmd = XEN_DOMCTL_bind_pt_irq;
+     *
+     * qemu-xen-traditional中调用xc_domain_update_msi_irq()的例子:
+     *   - hw/pt-msi.c|144| <<pt_msi_update>> ret = xc_domain_update_msi_irq(xc_handle, domid, gvec,
+     *   - hw/pt-msi.c|322| <<pt_msix_update_one>> ret = xc_domain_update_msi_irq(xc_handle, domid, gvec, pirq, gflags,
+     */
     uint32_t gvec;
     uint32_t gflags;
     int dest_vcpu_id; /* -1 :multi-dest, non-negative: dest_vcpu_id */
+    /*
+     * 使用posted的地方:
+     *   - arch/x86/hvm/hvm.c|471| <<hvm_migrate_pirq>> !pirq_dpci->gmsi.posted &&
+     *   - drivers/passthrough/io.c|450| <<pt_irq_create_bind>> pirq_dpci->gmsi.posted = false;
+     *   - drivers/passthrough/io.c|458| <<pt_irq_create_bind>> pirq_dpci->gmsi.posted = true;
+     *   - drivers/passthrough/io.c|739| <<pt_irq_destroy_bind>> else if ( pirq_dpci && pirq_dpci->gmsi.posted )
+     */
     bool posted; /* directly deliver to guest via VT-d PI? */
 };
 
diff --git a/xen/include/asm-x86/hvm/vlapic.h b/xen/include/asm-x86/hvm/vlapic.h
index 212c36b..74c42f4 100644
--- a/xen/include/asm-x86/hvm/vlapic.h
+++ b/xen/include/asm-x86/hvm/vlapic.h
@@ -43,6 +43,13 @@
  *     APIC is visible but does not respond to interrupt messages.
  */
 #define VLAPIC_HW_DISABLED              0x1
+/*
+ * VLAPIC_SW_DISABLED在以下使用:
+ *   - arch/x86/hvm/vlapic.c|838| <<vlapic_reg_write>> vlapic->hw.disabled |= VLAPIC_SW_DISABLED;
+ *   - arch/x86/hvm/vlapic.c|849| <<vlapic_reg_write>> vlapic->hw.disabled &= ~VLAPIC_SW_DISABLED;
+ *   - arch/x86/hvm/vlapic.c|1414| <<vlapic_do_init>> vlapic->hw.disabled |= VLAPIC_SW_DISABLED;
+ *   - include/asm-x86/hvm/vlapic.h|47| <<vlapic_sw_disabled>> #define vlapic_sw_disabled(vlapic) ((vlapic)->hw.disabled & VLAPIC_SW_DISABLED)
+ */
 #define VLAPIC_SW_DISABLED              0x2
 #define vlapic_sw_disabled(vlapic) ((vlapic)->hw.disabled & VLAPIC_SW_DISABLED)
 #define vlapic_hw_disabled(vlapic) ((vlapic)->hw.disabled & VLAPIC_HW_DISABLED)
@@ -85,6 +92,16 @@ struct vlapic {
     spinlock_t               esr_lock;
     struct periodic_time     pt;
     s_time_t                 timer_last_update;
+    /*
+     * regs_page使用的地方:
+     *   - arch/x86/hvm/vlapic.c|1586| <<vlapic_init>> if (vlapic->regs_page == NULL)
+     *   - arch/x86/hvm/vlapic.c|1588| <<vlapic_init>> vlapic->regs_page = alloc_domheap_page(v->domain, MEMF_no_owner);
+     *   - arch/x86/hvm/vlapic.c|1589| <<vlapic_init>> if ( vlapic->regs_page == NULL )
+     *   - arch/x86/hvm/vlapic.c|1599| <<vlapic_init>> vlapic->regs = __map_domain_page_global(vlapic->regs_page);
+     *   - arch/x86/hvm/vlapic.c|1634| <<vlapic_destroy>> free_domheap_page(vlapic->regs_page);
+     *   - arch/x86/hvm/vmx/vmcs.c|1241| <<construct_vmcs>> page_to_maddr(vcpu_vlapic(v)->regs_page));
+     *   - arch/x86/hvm/vmx/vmx.c|3029| <<vmx_install_vlapic_mapping>> virt_page_ma = page_to_maddr(vcpu_vlapic(v)->regs_page);
+     */
     struct page_info         *regs_page;
     /* INIT-SIPI-SIPI work gets deferred to a tasklet. */
     struct {
diff --git a/xen/include/asm-x86/hvm/vmx/vmcs.h b/xen/include/asm-x86/hvm/vmx/vmcs.h
index 8fb9e3c..8b010c1 100644
--- a/xen/include/asm-x86/hvm/vmx/vmcs.h
+++ b/xen/include/asm-x86/hvm/vmx/vmcs.h
@@ -60,6 +60,14 @@ struct ept_data {
 #define _VMX_DOMAIN_PML_ENABLED    0
 #define VMX_DOMAIN_PML_ENABLED     (1ul << _VMX_DOMAIN_PML_ENABLED)
 struct vmx_domain {
+    /*
+     * apic_access_mfn在以下使用:
+     *   - arch/x86/hvm/mtrr.c|787| <<epte_get_entry_emt>> if ( (mfn_x(mfn) ^ d->arch.hvm_domain.vmx.apic_access_mfn) >> order )
+     *   - arch/x86/hvm/vmx/vmx.c|3005| <<vmx_alloc_vlapic_mapping>> d->arch.hvm_domain.vmx.apic_access_mfn = mfn;
+     *   - arch/x86/hvm/vmx/vmx.c|3014| <<vmx_free_vlapic_mapping>> unsigned long mfn = d->arch.hvm_domain.vmx.apic_access_mfn;
+     *   - arch/x86/hvm/vmx/vmx.c|3024| <<vmx_install_vlapic_mapping>> if ( v->domain->arch.hvm_domain.vmx.apic_access_mfn == 0 )
+     *   - arch/x86/hvm/vmx/vmx.c|3030| <<vmx_install_vlapic_mapping>> apic_page_ma = v->domain->arch.hvm_domain.vmx.apic_access_mfn;
+     */
     unsigned long apic_access_mfn;
     /* VMX_DOMAIN_* */
     unsigned int status;
@@ -389,7 +397,22 @@ enum vmcs_field {
     VM_ENTRY_MSR_LOAD_ADDR          = 0x0000200a,
     PML_ADDRESS                     = 0x0000200e,
     TSC_OFFSET                      = 0x00002010,
+    /*
+     * VIRTUAL_APIC_PAGE_ADDR在以下使用:
+     *   - arch/x86/hvm/vmx/vmcs.c|1250| <<construct_vmcs>> __vmwrite(VIRTUAL_APIC_PAGE_ADDR,
+     *   - arch/x86/hvm/vmx/vmx.c|3034| <<vmx_install_vlapic_mapping>> __vmwrite(VIRTUAL_APIC_PAGE_ADDR, virt_page_ma);
+     *   - arch/x86/hvm/vmx/vvmx.c|721| <<nvmx_update_virtual_apic_address>> vapic_gpfn = get_vvmcs(v, VIRTUAL_APIC_PAGE_ADDR) >> PAGE_SHIFT;
+     *   - arch/x86/hvm/vmx/vvmx.c|724| <<nvmx_update_virtual_apic_address>> __vmwrite(VIRTUAL_APIC_PAGE_ADDR, page_to_maddr(vapic_pg));
+     *   - arch/x86/hvm/vmx/vvmx.c|728| <<nvmx_update_virtual_apic_address>> __vmwrite(VIRTUAL_APIC_PAGE_ADDR, 0);
+     */
     VIRTUAL_APIC_PAGE_ADDR          = 0x00002012,
+    /*
+     * APIC_ACCESS_ADDR在以下使用:
+     *   - arch/x86/hvm/vmx/vmx.c|3035| <<vmx_install_vlapic_mapping>> __vmwrite(APIC_ACCESS_ADDR, apic_page_ma);
+     *   - arch/x86/hvm/vmx/vvmx.c|700| <<nvmx_update_apic_access_address>> apic_gpfn = get_vvmcs(v, APIC_ACCESS_ADDR) >> PAGE_SHIFT;
+     *   - arch/x86/hvm/vmx/vvmx.c|703| <<nvmx_update_apic_access_address>> __vmwrite(APIC_ACCESS_ADDR, page_to_maddr(apic_pg));
+     *   - arch/x86/hvm/vmx/vvmx.c|707| <<nvmx_update_apic_access_address>> __vmwrite(APIC_ACCESS_ADDR, 0);
+     */
     APIC_ACCESS_ADDR                = 0x00002014,
     PI_DESC_ADDR                    = 0x00002016,
     VM_FUNCTION_CONTROL             = 0x00002018,
diff --git a/xen/include/asm-x86/hvm/vmx/vmx.h b/xen/include/asm-x86/hvm/vmx/vmx.h
index 7341cb1..eeeddc5 100644
--- a/xen/include/asm-x86/hvm/vmx/vmx.h
+++ b/xen/include/asm-x86/hvm/vmx/vmx.h
@@ -106,6 +106,7 @@ void vmx_update_secondary_exec_control(struct vcpu *v);
 #define POSTED_INTR_SN  1
 static inline int pi_test_and_set_pir(uint8_t vector, struct pi_desc *pi_desc)
 {
+    /* Set a bit and return its old value */
     return test_and_set_bit(vector, pi_desc->pir);
 }
 
@@ -124,8 +125,13 @@ static inline void pi_set_on(struct pi_desc *pi_desc)
     set_bit(POSTED_INTR_ON, &pi_desc->control);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vmx/vmx.c|2137| <<vmx_sync_pir_to_irr>> if ( !pi_test_and_clear_on(&v->arch.hvm_vmx.pi_desc) )
+ */
 static inline int pi_test_and_clear_on(struct pi_desc *pi_desc)
 {
+    /* Clear a bit and return its old value */
     return test_and_clear_bit(POSTED_INTR_ON, &pi_desc->control);
 }
 
diff --git a/xen/include/asm-x86/mach-generic/mach_apic.h b/xen/include/asm-x86/mach-generic/mach_apic.h
index 03e9e8a..c7ba8f5 100644
--- a/xen/include/asm-x86/mach-generic/mach_apic.h
+++ b/xen/include/asm-x86/mach-generic/mach_apic.h
@@ -16,6 +16,11 @@
 #define init_apic_ldr (genapic->init_apic_ldr)
 #define clustered_apic_check (genapic->clustered_apic_check) 
 #define cpu_mask_to_apicid (genapic->cpu_mask_to_apicid)
+/*
+ * 设置genapic的地方:
+ *   - xen/arch/x86/apic.c|945| <<x2apic_bsp_setup>> genapic = apic_x2apic_probe();
+ *   - xen/arch/x86/apic.c|946| <<x2apic_bsp_setup>> printk("Switched to APIC driver %s.\n", genapic->name);
+ */
 #define vector_allocation_cpumask(cpu) (genapic->vector_allocation_cpumask(cpu))
 
 static inline void enable_apic_mode(void)
diff --git a/xen/include/asm-x86/page.h b/xen/include/asm-x86/page.h
index 45ca742..bc07ac8 100644
--- a/xen/include/asm-x86/page.h
+++ b/xen/include/asm-x86/page.h
@@ -279,6 +279,14 @@ void copy_page_sse2(void *, const void *);
 #endif /* !defined(__ASSEMBLY__) */
 
 /* Where to find each level of the linear mapping */
+/*
+ * 使用__linear_l1_table的地方:
+ *   - arch/x86/domain_page.c|68| <<MAPCACHE_L1ENT>> __linear_l1_table[l1_linear_offset(MAPCACHE_VIRT_START + pfn_to_paddr(idx))]
+ *   - arch/x86/domain_page.c|394| <<domain_page_map_to_mfn>> pl1e = &__linear_l1_table[l1_linear_offset(va)];
+ *   - arch/x86/mm/shadow/types.h|174| <<sh_linear_l2_table>> (is_hvm_vcpu(v) ? __linear_l1_table : __sh_linear_l1_table) + \
+ *   - arch/x86/pv/mm.h|18| <<guest_get_eff_l1e>> &__linear_l1_table[l1_linear_offset(linear)],
+ *   - include/asm-x86/page.h|284| <<__linear_l2_table>> ((l2_pgentry_t *)(__linear_l1_table + l1_linear_offset(LINEAR_PT_VIRT_START)))
+ */
 #define __linear_l1_table ((l1_pgentry_t *)(LINEAR_PT_VIRT_START))
 #define __linear_l2_table \
  ((l2_pgentry_t *)(__linear_l1_table + l1_linear_offset(LINEAR_PT_VIRT_START)))
diff --git a/xen/include/public/arch-x86/hvm/save.h b/xen/include/public/arch-x86/hvm/save.h
index fd7bf3f..44b0739 100644
--- a/xen/include/public/arch-x86/hvm/save.h
+++ b/xen/include/public/arch-x86/hvm/save.h
@@ -405,6 +405,20 @@ DECLARE_HVM_SAVE_TYPE(IOAPIC, 4, struct hvm_hw_vioapic);
  */
 
 struct hvm_hw_lapic {
+    /*
+     * 在以下使用apic_base_msr:
+     *   - arch/x86/hvm/hvm.c|3441| <<hvm_msr_read_intercept>> *msr_content = vcpu_vlapic(v)->hw.apic_base_msr;
+     *   - arch/x86/hvm/vlapic.c|1080| <<vlapic_msr_set>> if ( (vlapic->hw.apic_base_msr ^ value) & MSR_IA32_APICBASE_ENABLE )
+     *   - arch/x86/hvm/vlapic.c|1096| <<vlapic_msr_set>> else if ( ((vlapic->hw.apic_base_msr ^ value) & MSR_IA32_APICBASE_EXTD) &&
+     *   - arch/x86/hvm/vlapic.c|1100| <<vlapic_msr_set>> vlapic->hw.apic_base_msr = value;
+     *   - arch/x86/hvm/vlapic.c|1109| <<vlapic_msr_set>> "apic base msr is 0x%016"PRIx64, vlapic->hw.apic_base_msr);
+     *   - arch/x86/hvm/vlapic.c|1386| <<vlapic_reset>> vlapic->hw.apic_base_msr = (MSR_IA32_APICBASE_ENABLE |
+     *   - arch/x86/hvm/vlapic.c|1389| <<vlapic_reset>> vlapic->hw.apic_base_msr |= MSR_IA32_APICBASE_BSP;
+     *   - arch/x86/hvm/vlapic.c|1521| <<lapic_load_hidden>> if ( !(s->hw.apic_base_msr & MSR_IA32_APICBASE_ENABLE) &&
+     *   - include/asm-x86/hvm/vlapic.h|53| <<vlapic_base_address>> ((vlapic)->hw.apic_base_msr & MSR_IA32_APICBASE_BASE)
+     *   - include/asm-x86/hvm/vlapic.h|56| <<vlapic_x2apic_mode>> ((vlapic)->hw.apic_base_msr & MSR_IA32_APICBASE_EXTD)
+     *   - include/asm-x86/hvm/vlapic.h|59| <<vlapic_xapic_mode>> !((vlapic)->hw.apic_base_msr & MSR_IA32_APICBASE_EXTD))
+     */
     uint64_t             apic_base_msr;
     uint32_t             disabled; /* VLAPIC_xx_DISABLED */
     uint32_t             timer_divisor;
diff --git a/xen/include/public/arch-x86/xen.h b/xen/include/public/arch-x86/xen.h
index 3b0b1d6..53fbe1e 100644
--- a/xen/include/public/arch-x86/xen.h
+++ b/xen/include/public/arch-x86/xen.h
@@ -275,6 +275,14 @@ typedef struct arch_shared_info arch_shared_info_t;
  */
 struct xen_arch_domainconfig {
 #define _XEN_X86_EMU_LAPIC          0
+/*
+ * used by:
+ *   - arch/x86/domain.c|400| <<emulation_flags_ok>> emflags != (XEN_X86_EMU_LAPIC|XEN_X86_EMU_IOAPIC) )
+ *   - arch/x86/domain.c|403| <<emulation_flags_ok>> emflags != XEN_X86_EMU_ALL && emflags != XEN_X86_EMU_LAPIC )
+ *   - arch/x86/setup.c|1585| <<__start_xen>> config.emulation_flags = XEN_X86_EMU_LAPIC|XEN_X86_EMU_IOAPIC;
+ *   - include/asm-x86/domain.h|424| <<has_vlapic>> #define has_vlapic(d) (!!((d)->arch.emulation_flags & XEN_X86_EMU_LAPIC))
+ *   - include/public/arch-x86/xen.h|298| <<XEN_X86_EMU_ALL>> #define XEN_X86_EMU_ALL (XEN_X86_EMU_LAPIC | XEN_X86_EMU_HPET | \
+ */
 #define XEN_X86_EMU_LAPIC           (1U<<_XEN_X86_EMU_LAPIC)
 #define _XEN_X86_EMU_HPET           1
 #define XEN_X86_EMU_HPET            (1U<<_XEN_X86_EMU_HPET)
diff --git a/xen/include/xen/event.h b/xen/include/xen/event.h
index 87915ea..6e0926e 100644
--- a/xen/include/xen/event.h
+++ b/xen/include/xen/event.h
@@ -100,6 +100,10 @@ static inline struct evtchn *evtchn_from_port(struct domain *d, unsigned int p)
 }
 
 /* Wait on a Xen-attached event channel. */
+/*
+ * called by:
+ *   - arch/x86/hvm/ioreq.c|120| <<hvm_wait_for_io>> wait_on_xen_event_channel(sv->ioreq_evtchn, p->state != state);
+ */
 #define wait_on_xen_event_channel(port, condition)                      \
     do {                                                                \
         if ( condition )                                                \
@@ -115,6 +119,10 @@ static inline struct evtchn *evtchn_from_port(struct domain *d, unsigned int p)
         do_softirq();                                                   \
     } while ( 0 )
 
+/*
+ * called by:
+ *   - arch/x86/hvm/ioreq.c|1412| <<hvm_send_ioreq>> prepare_wait_on_xen_event_channel(port);
+ */
 #define prepare_wait_on_xen_event_channel(port)                         \
     do {                                                                \
         set_bit(_VPF_blocked_in_xen, &current->pause_flags);            \
diff --git a/xen/include/xen/pci.h b/xen/include/xen/pci.h
index 43f2125..b4f27b9 100644
--- a/xen/include/xen/pci.h
+++ b/xen/include/xen/pci.h
@@ -55,6 +55,11 @@ struct pci_dev {
     struct list_head alldevs_list;
     struct list_head domain_list;
 
+    /*
+     * 在以下添加:
+     *   - arch/x86/msi.c|750| <<msi_capability_init>> list_add_tail(&entry->list, &dev->msi_list);
+     *   - arch/x86/msi.c|990| <<msix_capability_init>> list_add_tail(&entry->list, &dev->msi_list);
+     */
     struct list_head msi_list;
 
     struct arch_msix *msix;
diff --git a/xen/include/xen/sched.h b/xen/include/xen/sched.h
index 002ba29..4a8b131 100644
--- a/xen/include/xen/sched.h
+++ b/xen/include/xen/sched.h
@@ -314,7 +314,44 @@ struct domain
     spinlock_t       domain_lock;
 
     spinlock_t       page_alloc_lock; /* protects all the following fields  */
+    /*
+     * x86在以下部分主要使用page_list:
+     *   - arch/x86/domain.c|174| <<dump_pageframe_info>> page_list_for_each ( page, &d->page_list )
+     *   - arch/x86/domain.c|990| <<arch_set_info_guest>> struct page_info *page = page_list_remove_head(&d->page_list);
+     *   - arch/x86/domain.c|1001| <<arch_set_info_guest>> page_list_add_tail(page, &d->page_list);
+     *   - arch/x86/domain.c|1989| <<domain_relinquish_resources>> page_list_splice(&d->arch.relmem_list, &d->page_list);
+     *   - arch/x86/domain.c|2002| <<domain_relinquish_resources>> ret = relinquish_memory(d, &d->page_list, PGT_l4_page_table);
+     *   - arch/x86/domain.c|2009| <<domain_relinquish_resources>> ret = relinquish_memory(d, &d->page_list, PGT_l3_page_table);
+     *   - arch/x86/domain.c|2016| <<domain_relinquish_resources>> ret = relinquish_memory(d, &d->page_list, PGT_l2_page_table);
+     *   - arch/x86/domctl.c|428| <<arch_do_domctl(XEN_DOMCTL_getmemlist)>> page_list_for_each(page, &d->page_list)
+     *   - arch/x86/mm.c|3809| <<donate_page>> page_list_add_tail(page,&d->page_list);
+     *   - arch/x86/mm.c|3879| <<steal_page>> page_list_del(page, &d->page_list);
+     *   - arch/x86/mm/mem_sharing.c|632| <<page_make_sharable>> page_list_del(page, &d->page_list);
+     *   - arch/x86/mm/mem_sharing.c|680| <<page_make_private>> page_list_add_tail(page, &d->page_list);
+     *   - arch/x86/mm/p2m-pod.c|111| <<p2m_pod_cache_add>> page_list_del(p, &d->page_list);
+     *   - arch/x86/mm/p2m-pod.c|194| <<p2m_pod_cache_get>> page_list_add_tail(p + i, &p2m->domain->page_list);
+     *   - arch/x86/mm/p2m-pod.c|397| <<p2m_pod_empty_cache>> page_list_add_tail(page + i, &d->page_list);
+     *   - arch/x86/mm/p2m-pod.c|409| <<p2m_pod_empty_cache>> page_list_add_tail(page, &d->page_list);
+     *   - arch/x86/mm/p2m.c|625| <<p2m_alloc_table>> && !page_list_empty(&d->page_list) )
+     *   - arch/x86/mm/p2m.c|2562| <<audit_p2m>> page_list_for_each ( page, &d->page_list )
+     *   - arch/x86/numa.c|431| <<dump_numa>> page_list_for_each(page, &d->page_list)
+     *   - arch/x86/pv/dom0_build.c|785| <<dom0_construct_pv>> page_list_for_each ( page, &d->page_list )
+     *   - arch/x86/tboot.c|220| <<tboot_gen_domain_integrity>> page_list_for_each(page, &d->page_list)
+     *   - common/domain.c|290| <<domain_create>> INIT_PAGE_LIST_HEAD(&d->page_list);
+     *   - common/page_alloc.c|2221| <<assign_pages>> page_list_add_tail(&pg[i], &d->page_list);
+     *   - include/asm-x86/mm.h|614| <<arch_free_heap_page>> &(d)->xenpage_list : &(d)->page_list, \
+     *   - include/xen/mm.h|575| <<arch_free_heap_page>> &(d)->xenpage_list : &(d)->page_list)
+     */
     struct page_list_head page_list;  /* linked list */
+    /*
+     * x86在以下使用xenpage_list:
+     *   - arch/x86/domain.c|199| <<dump_pageframe_info>> page_list_for_each ( page, &d->xenpage_list )
+     *   - arch/x86/domain.c|1995| <<domain_relinquish_resources>> ret = relinquish_memory(d, &d->xenpage_list, ~0UL);
+     *   - arch/x86/mm.c|455| <<share_xen_page_with_guest>> page_list_add_tail(page, &d->xenpage_list);
+     *   - common/domain.c|291| <<domain_create>> INIT_PAGE_LIST_HEAD(&d->xenpage_list);
+     *   - include/asm-x86/mm.h|614| <<arch_free_heap_page>> &(d)->xenpage_list : &(d)->page_list, \
+     *   - include/xen/mm.h|575| <<arch_free_heap_page>> &(d)->xenpage_list : &(d)->page_list)
+     */
     struct page_list_head xenpage_list; /* linked list (size xenheap_pages) */
     unsigned int     tot_pages;       /* number of pages currently possesed */
     unsigned int     xenheap_pages;   /* # pages allocated from Xen heap    */
-- 
2.7.4

