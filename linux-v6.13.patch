From 79af31cd080ad08a745713098b4b9fbb536e7493 Mon Sep 17 00:00:00 2001
From: Dongli Zhang <dongli.zhang0129@gmail.com>
Date: Sat, 8 Feb 2025 14:11:30 -0800
Subject: [PATCH 1/1] linux-v6.13

Signed-off-by: Dongli Zhang <dongli.zhang0129@gmail.com>
---
 arch/x86/include/asm/kvm_host.h        |   44 +
 arch/x86/kernel/kvmclock.c             |   32 +
 arch/x86/kvm/hyperv.c                  |   13 +
 arch/x86/kvm/i8254.c                   |    7 +
 arch/x86/kvm/lapic.c                   |    4 +
 arch/x86/kvm/lapic.h                   |   20 +
 arch/x86/kvm/mmu.h                     |    7 +
 arch/x86/kvm/mmu/mmu.c                 |   31 +
 arch/x86/kvm/mmu/mmu_internal.h        |    6 +
 arch/x86/kvm/x86.c                     |  180 +++++
 drivers/net/virtio_net.c               |   72 ++
 drivers/net/xen-netfront.c             |    4 +
 drivers/scsi/virtio_scsi.c             |  199 +++++
 drivers/target/loopback/tcm_loop.c     |   17 +
 drivers/target/target_core_configfs.c  |   17 +
 drivers/target/target_core_file.c      |   34 +
 drivers/target/target_core_hba.c       |    8 +
 drivers/target/target_core_iblock.c    |   14 +
 drivers/target/target_core_sbc.c       |   39 +
 drivers/target/target_core_spc.c       |    5 +
 drivers/target/target_core_transport.c |   57 ++
 drivers/vdpa/ifcvf/ifcvf_main.c        |   16 +
 drivers/vdpa/mlx5/net/mlx5_vnet.c      |   27 +
 drivers/vdpa/vdpa.c                    |   60 ++
 drivers/vdpa/vdpa_sim/vdpa_sim.c       |   26 +
 drivers/vdpa/vdpa_sim/vdpa_sim_blk.c   |   11 +
 drivers/vdpa/vdpa_sim/vdpa_sim_net.c   |   20 +
 drivers/vdpa/vdpa_user/vduse_dev.c     |   16 +
 drivers/vdpa/virtio_pci/vp_vdpa.c      |   16 +
 drivers/vhost/net.c                    |  238 ++++++
 drivers/vhost/scsi.c                   |  820 +++++++++++++++++++
 drivers/vhost/test.c                   |   55 ++
 drivers/vhost/vdpa.c                   |   42 +
 drivers/vhost/vhost.c                  | 1018 ++++++++++++++++++++++++
 drivers/vhost/vhost.h                  |   63 ++
 drivers/vhost/vringh.c                 |    8 +
 drivers/vhost/vsock.c                  |   96 +++
 drivers/virtio/virtio.c                |   47 ++
 drivers/virtio/virtio_ring.c           |   31 +
 drivers/virtio/virtio_vdpa.c           |   20 +
 include/linux/sched.h                  |   43 +
 include/linux/skbuff.h                 |   10 +
 include/linux/vdpa.h                   |   27 +
 include/linux/virtio.h                 |    6 +
 include/target/target_core_base.h      |   15 +
 include/uapi/linux/vhost_types.h       |   11 +
 kernel/sched/fair.c                    |   22 +
 kernel/vhost_task.c                    |    8 +
 lib/iov_iter.c                         |   35 +
 net/core/skbuff.c                      |   10 +
 virt/lib/irqbypass.c                   |   23 +
 51 files changed, 3650 insertions(+)

diff --git a/arch/x86/include/asm/kvm_host.h b/arch/x86/include/asm/kvm_host.h
index e159e44a6..f13ee42ee 100644
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@ -1349,8 +1349,32 @@ struct kvm_arch {
 	bool apic_access_memslot_enabled;
 	bool apic_access_memslot_inhibited;
 
+	/*
+	 * 在以下使用kvm_arch->apicv_update_lock:
+	 *   - arch/x86/kvm/hyperv.c|137| <<synic_update_vector>> down_write(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/hyperv.c|152| <<synic_update_vector>> up_write(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|9955| <<kvm_apicv_init>> init_rwsem(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10542| <<__kvm_vcpu_update_apicv>> down_read(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10567| <<__kvm_vcpu_update_apicv>> up_read(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10607| <<__kvm_set_or_clear_apicv_inhibit>> lockdep_assert_held_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10654| <<kvm_set_or_clear_apicv_inhibit>> down_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10656| <<kvm_set_or_clear_apicv_inhibit>> up_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|12060| <<kvm_arch_vcpu_guestdbg_update_apicv_inhibit>> down_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|12069| <<kvm_arch_vcpu_guestdbg_update_apicv_inhibit>> up_write(&kvm->arch.apicv_update_lock);
+	 */
 	/* Protects apicv_inhibit_reasons */
 	struct rw_semaphore apicv_update_lock;
+	/*
+	 * 在以下使用kvm_arch->apicv_inhibit_reasons:
+	 *   - arch/x86/kvm/x86.c|9919| <<kvm_apicv_activated>> return (READ_ONCE(kvm->arch.apicv_inhibit_reasons) == 0);
+	 *   - arch/x86/kvm/x86.c|9925| <<kvm_vcpu_apicv_activated>> ulong vm_reasons = READ_ONCE(vcpu->kvm->arch.apicv_inhibit_reasons);
+	 *   - arch/x86/kvm/x86.c|9953| <<kvm_apicv_init>> set_or_clear_apicv_inhibit(&kvm->arch.apicv_inhibit_reasons, reason, true);
+	 *   - arch/x86/kvm/x86.c|10612| <<__kvm_set_or_clear_apicv_inhibit>> old = new = kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|10630| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 *   - arch/x86/kvm/x86.c|10639| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 *
+	 * 被kvm_arch->apicv_update_lock保护.
+	 */
 	unsigned long apicv_inhibit_reasons;
 
 	gpa_t wall_clock;
@@ -2169,15 +2193,35 @@ void __kvm_set_or_clear_apicv_inhibit(struct kvm *kvm,
 void kvm_set_or_clear_apicv_inhibit(struct kvm *kvm,
 				    enum kvm_apicv_inhibit reason, bool set);
 
+/*
+ * called by:
+ *   - arch/x86/kvm/i8254.c|308| <<kvm_pit_set_reinject>> kvm_set_apicv_inhibit(kvm, APICV_INHIBIT_REASON_PIT_REINJ);
+ *   - arch/x86/kvm/lapic.c|466| <<kvm_recalculate_apic_map>> kvm_set_apicv_inhibit(kvm, APICV_INHIBIT_REASON_PHYSICAL_ID_ALIASED);
+ *   - arch/x86/kvm/lapic.c|471| <<kvm_recalculate_apic_map>> kvm_set_apicv_inhibit(kvm, APICV_INHIBIT_REASON_LOGICAL_ID_ALIASED);
+ *   - arch/x86/kvm/lapic.c|476| <<kvm_recalculate_apic_map>> kvm_set_apicv_inhibit(kvm, APICV_INHIBIT_REASON_APIC_ID_MODIFIED);
+ *   - arch/x86/kvm/lapic.c|2623| <<__kvm_apic_set_base>> kvm_set_apicv_inhibit(apic->vcpu->kvm, APICV_INHIBIT_REASON_APIC_BASE_MODIFIED);
+ *   - arch/x86/kvm/svm/sev.c|463| <<__sev_guest_init>> kvm_set_apicv_inhibit(kvm, APICV_INHIBIT_REASON_SEV);
+ *   - arch/x86/kvm/svm/svm.c|3883| <<svm_enable_irq_window>> kvm_set_apicv_inhibit(vcpu->kvm, APICV_INHIBIT_REASON_IRQWIN);
+ */
 static inline void kvm_set_apicv_inhibit(struct kvm *kvm,
 					 enum kvm_apicv_inhibit reason)
 {
+	/*
+	 * called by:
+	 *   - arch/x86/include/asm/kvm_host.h|2175| <<kvm_set_apicv_inhibit>> kvm_set_or_clear_apicv_inhibit(kvm, reason, true);
+	 *   - arch/x86/include/asm/kvm_host.h|2181| <<kvm_clear_apicv_inhibit>> kvm_set_or_clear_apicv_inhibit(kvm, reason, false);
+	 */
 	kvm_set_or_clear_apicv_inhibit(kvm, reason, true);
 }
 
 static inline void kvm_clear_apicv_inhibit(struct kvm *kvm,
 					   enum kvm_apicv_inhibit reason)
 {
+	/*
+	 * called by:
+	 *   - arch/x86/include/asm/kvm_host.h|2175| <<kvm_set_apicv_inhibit>> kvm_set_or_clear_apicv_inhibit(kvm, reason, true);
+	 *   - arch/x86/include/asm/kvm_host.h|2181| <<kvm_clear_apicv_inhibit>> kvm_set_or_clear_apicv_inhibit(kvm, reason, false);
+	 */
 	kvm_set_or_clear_apicv_inhibit(kvm, reason, false);
 }
 
diff --git a/arch/x86/kernel/kvmclock.c b/arch/x86/kernel/kvmclock.c
index 5b2c15214..2786cef9d 100644
--- a/arch/x86/kernel/kvmclock.c
+++ b/arch/x86/kernel/kvmclock.c
@@ -25,6 +25,14 @@
 static int kvmclock __initdata = 1;
 static int kvmclock_vsyscall __initdata = 1;
 static int msr_kvm_system_time __ro_after_init;
+/*
+ * 在以下使用msr_kvm_wall_clock:
+ *   - arch/x86/kernel/kvmclock.c|63| <<kvm_get_wallclock>> wrmsrl(msr_kvm_wall_clock, slow_virt_to_phys(&wall_clock));
+ *   - arch/x86/kernel/kvmclock.c|297| <<kvmclock_init>> msr_kvm_wall_clock = MSR_KVM_WALL_CLOCK_NEW;
+ *   - arch/x86/kernel/kvmclock.c|300| <<kvmclock_init>> msr_kvm_wall_clock = MSR_KVM_WALL_CLOCK;
+ *   - arch/x86/kernel/kvmclock.c|311| <<kvmclock_init>> pr_info("kvm-clock: Using msrs %x and %x",
+ *                                       msr_kvm_system_time, msr_kvm_wall_clock);
+ */
 static int msr_kvm_wall_clock __ro_after_init;
 static u64 kvm_sched_clock_offset __ro_after_init;
 
@@ -60,6 +68,14 @@ EXPORT_PER_CPU_SYMBOL_GPL(hv_clock_per_cpu);
  */
 static void kvm_get_wallclock(struct timespec64 *now)
 {
+	/*
+	 * 在以下使用msr_kvm_wall_clock:
+	 *   - arch/x86/kernel/kvmclock.c|63| <<kvm_get_wallclock>> wrmsrl(msr_kvm_wall_clock, slow_virt_to_phys(&wall_clock));
+	 *   - arch/x86/kernel/kvmclock.c|297| <<kvmclock_init>> msr_kvm_wall_clock = MSR_KVM_WALL_CLOCK_NEW;
+	 *   - arch/x86/kernel/kvmclock.c|300| <<kvmclock_init>> msr_kvm_wall_clock = MSR_KVM_WALL_CLOCK;
+	 *   - arch/x86/kernel/kvmclock.c|311| <<kvmclock_init>> pr_info("kvm-clock: Using msrs %x and %x",
+	 *                                       msr_kvm_system_time, msr_kvm_wall_clock);
+	 */
 	wrmsrl(msr_kvm_wall_clock, slow_virt_to_phys(&wall_clock));
 	preempt_disable();
 	pvclock_read_wallclock(&wall_clock, this_cpu_pvti(), now);
@@ -292,6 +308,14 @@ void __init kvmclock_init(void)
 	if (!kvm_para_available() || !kvmclock)
 		return;
 
+	/*
+	 * 在以下使用msr_kvm_wall_clock:
+	 *   - arch/x86/kernel/kvmclock.c|63| <<kvm_get_wallclock>> wrmsrl(msr_kvm_wall_clock, slow_virt_to_phys(&wall_clock));
+	 *   - arch/x86/kernel/kvmclock.c|297| <<kvmclock_init>> msr_kvm_wall_clock = MSR_KVM_WALL_CLOCK_NEW;
+	 *   - arch/x86/kernel/kvmclock.c|300| <<kvmclock_init>> msr_kvm_wall_clock = MSR_KVM_WALL_CLOCK;
+	 *   - arch/x86/kernel/kvmclock.c|311| <<kvmclock_init>> pr_info("kvm-clock: Using msrs %x and %x",
+	 *                                       msr_kvm_system_time, msr_kvm_wall_clock);
+	 */
 	if (kvm_para_has_feature(KVM_FEATURE_CLOCKSOURCE2)) {
 		msr_kvm_system_time = MSR_KVM_SYSTEM_TIME_NEW;
 		msr_kvm_wall_clock = MSR_KVM_WALL_CLOCK_NEW;
@@ -307,6 +331,14 @@ void __init kvmclock_init(void)
 		return;
 	}
 
+	/*
+	 * 在以下使用msr_kvm_wall_clock:
+	 *   - arch/x86/kernel/kvmclock.c|63| <<kvm_get_wallclock>> wrmsrl(msr_kvm_wall_clock, slow_virt_to_phys(&wall_clock));
+	 *   - arch/x86/kernel/kvmclock.c|297| <<kvmclock_init>> msr_kvm_wall_clock = MSR_KVM_WALL_CLOCK_NEW;
+	 *   - arch/x86/kernel/kvmclock.c|300| <<kvmclock_init>> msr_kvm_wall_clock = MSR_KVM_WALL_CLOCK;
+	 *   - arch/x86/kernel/kvmclock.c|311| <<kvmclock_init>> pr_info("kvm-clock: Using msrs %x and %x",
+	 *                                       msr_kvm_system_time, msr_kvm_wall_clock);
+	 */
 	pr_info("kvm-clock: Using msrs %x and %x",
 		msr_kvm_system_time, msr_kvm_wall_clock);
 
diff --git a/arch/x86/kvm/hyperv.c b/arch/x86/kvm/hyperv.c
index 4f0a94346..5bbb81eab 100644
--- a/arch/x86/kvm/hyperv.c
+++ b/arch/x86/kvm/hyperv.c
@@ -134,6 +134,19 @@ static void synic_update_vector(struct kvm_vcpu_hv_synic *synic,
 	if (!enable_apicv)
 		return;
 
+	/*
+	 * 在以下使用kvm_arch->apicv_update_lock:
+	 *   - arch/x86/kvm/hyperv.c|137| <<synic_update_vector>> down_write(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/hyperv.c|152| <<synic_update_vector>> up_write(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|9955| <<kvm_apicv_init>> init_rwsem(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10542| <<__kvm_vcpu_update_apicv>> down_read(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10567| <<__kvm_vcpu_update_apicv>> up_read(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10607| <<__kvm_set_or_clear_apicv_inhibit>> lockdep_assert_held_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10654| <<kvm_set_or_clear_apicv_inhibit>> down_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10656| <<kvm_set_or_clear_apicv_inhibit>> up_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|12060| <<kvm_arch_vcpu_guestdbg_update_apicv_inhibit>> down_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|12069| <<kvm_arch_vcpu_guestdbg_update_apicv_inhibit>> up_write(&kvm->arch.apicv_update_lock);
+	 */
 	down_write(&vcpu->kvm->arch.apicv_update_lock);
 
 	if (auto_eoi_new)
diff --git a/arch/x86/kvm/i8254.c b/arch/x86/kvm/i8254.c
index cd57a517d..62f4c2730 100644
--- a/arch/x86/kvm/i8254.c
+++ b/arch/x86/kvm/i8254.c
@@ -288,6 +288,13 @@ static inline void kvm_pit_reset_reinject(struct kvm_pit *pit)
 	atomic_set(&pit->pit_state.irq_ack, 1);
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/i8254.c|702| <<kvm_create_pit>> kvm_pit_set_reinject(pit, true);
+ *   - arch/x86/kvm/i8254.c|727| <<kvm_create_pit>> kvm_pit_set_reinject(pit, false);
+ *   - arch/x86/kvm/i8254.c|745| <<kvm_free_pit>> kvm_pit_set_reinject(pit, false);
+ *   - arch/x86/kvm/x86.c|6473| <<kvm_vm_ioctl_reinject>> kvm_pit_set_reinject(pit, control->pit_reinject);
+ */
 void kvm_pit_set_reinject(struct kvm_pit *pit, bool reinject)
 {
 	struct kvm_kpit_state *ps = &pit->pit_state;
diff --git a/arch/x86/kvm/lapic.c b/arch/x86/kvm/lapic.c
index 3c83951c6..3e9f60393 100644
--- a/arch/x86/kvm/lapic.c
+++ b/arch/x86/kvm/lapic.c
@@ -698,6 +698,10 @@ bool __kvm_apic_update_irr(u32 *pir, void *regs, int *max_irr)
 }
 EXPORT_SYMBOL_GPL(__kvm_apic_update_irr);
 
+/*
+ * called by:
+ *   - arch/x86/kvm/vmx/vmx.c|6930| <<vmx_sync_pir_to_irr>> kvm_apic_update_irr(vcpu, vmx->pi_desc.pir, &max_irr);
+ */
 bool kvm_apic_update_irr(struct kvm_vcpu *vcpu, u32 *pir, int *max_irr)
 {
 	struct kvm_lapic *apic = vcpu->arch.apic;
diff --git a/arch/x86/kvm/lapic.h b/arch/x86/kvm/lapic.h
index 24add38be..ab6d87ca5 100644
--- a/arch/x86/kvm/lapic.h
+++ b/arch/x86/kvm/lapic.h
@@ -61,6 +61,26 @@ struct kvm_lapic {
 	struct kvm_timer lapic_timer;
 	u32 divide_count;
 	struct kvm_vcpu *vcpu;
+	/*
+	 * 在以下使用kvm_lapic->apicv_active:
+	 *   - arch/x86/kvm/lapic.c|706| <<kvm_apic_update_irr>> if (unlikely(!apic->apicv_active && irr_updated))
+	 *   - arch/x86/kvm/lapic.c|736| <<apic_clear_irr>> if (unlikely(apic->apicv_active)) {
+	 *   - arch/x86/kvm/lapic.c|765| <<apic_set_isr>> if (unlikely(apic->apicv_active))
+	 *   - arch/x86/kvm/lapic.c|810| <<apic_clear_isr>> if (unlikely(apic->apicv_active))
+	 *   - arch/x86/kvm/lapic.c|1798| <<lapic_timer_int_injected>> if (apic->apicv_active)
+	 *   - arch/x86/kvm/lapic.c|1913| <<apic_timer_expired>> if (!from_timer_fn && apic->apicv_active) {
+	 *   - arch/x86/kvm/lapic.c|2672| <<kvm_apic_update_apicv>> if (apic->apicv_active)
+	 *   - arch/x86/kvm/lapic.c|2806| <<kvm_lapic_reset>> if (apic->apicv_active) {
+	 *   - arch/x86/kvm/lapic.c|2942| <<kvm_create_lapic>> apic->apicv_active = true;
+	 *   - arch/x86/kvm/lapic.c|3122| <<kvm_apic_set_state>> if (apic->apicv_active) {
+	 *   - arch/x86/kvm/lapic.h|222| <<kvm_vcpu_apicv_active>> return lapic_in_kernel(vcpu) && vcpu->arch.apic->apicv_active;
+	 *   - arch/x86/kvm/svm/svm.c|3689| <<svm_complete_interrupt_delivery>> if (!READ_ONCE(vcpu->arch.apic->apicv_active)) {
+	 *   - arch/x86/kvm/vmx/vmx.c|4280| <<vmx_deliver_posted_interrupt>> if (!vcpu->arch.apic->apicv_active)
+	 *   - arch/x86/kvm/x86.c|10265| <<update_cr8_intercept>> if (vcpu->arch.apic->apicv_active)
+	 *   - arch/x86/kvm/x86.c|10641| <<__kvm_vcpu_update_apicv>> if (apic->apicv_active == activate)
+	 *   - arch/x86/kvm/x86.c|10644| <<__kvm_vcpu_update_apicv>> apic->apicv_active = activate;
+	 *   - arch/x86/kvm/x86.c|10654| <<__kvm_vcpu_update_apicv>> if (!apic->apicv_active)
+	 */
 	bool apicv_active;
 	bool sw_enabled;
 	bool irr_pending;
diff --git a/arch/x86/kvm/mmu.h b/arch/x86/kvm/mmu.h
index e93223586..c16bc0624 100644
--- a/arch/x86/kvm/mmu.h
+++ b/arch/x86/kvm/mmu.h
@@ -270,6 +270,13 @@ kvm_mmu_slot_lpages(struct kvm_memory_slot *slot, int level)
 	return __kvm_mmu_slot_lpages(slot, slot->npages, level);
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/mmu/mmu.c|535| <<mmu_spte_clear_track_bits>> kvm_update_page_stats(kvm, level, -1);
+ *   - arch/x86/kvm/mmu/mmu.c|1526| <<__rmap_add>> kvm_update_page_stats(kvm, sp->role.level, 1);
+ *   - arch/x86/kvm/mmu/tdp_mmu.c|512| <<handle_changed_spte>> kvm_update_page_stats(kvm, level, is_leaf ? 1 : -1);
+ *   - arch/x86/kvm/mmu/tdp_mmu.c|1341| <<tdp_mmu_split_huge_page>> kvm_update_page_stats(kvm, level - 1, SPTE_ENT_PER_PAGE);
+ */
 static inline void kvm_update_page_stats(struct kvm *kvm, int level, int count)
 {
 	atomic64_add(count, &kvm->stat.pages[level - 1]);
diff --git a/arch/x86/kvm/mmu/mmu.c b/arch/x86/kvm/mmu/mmu.c
index 2401606db..22cb08b82 100644
--- a/arch/x86/kvm/mmu/mmu.c
+++ b/arch/x86/kvm/mmu/mmu.c
@@ -1512,6 +1512,11 @@ bool kvm_unmap_gfn_range(struct kvm *kvm, struct kvm_gfn_range *range)
 
 #define RMAP_RECYCLE_THRESHOLD 1000
 
+/*
+ * called by:
+ *   - arch/x86/kvm/mmu/mmu.c|1544| <<rmap_add>> __rmap_add(vcpu->kvm, cache, slot, spte, gfn, access);
+ *   - arch/x86/kvm/mmu/mmu.c|6730| <<shadow_mmu_split_huge_page>> __rmap_add(kvm, cache, slot, sptep, gfn, sp->role.access);
+ */
 static void __rmap_add(struct kvm *kvm,
 		       struct kvm_mmu_memory_cache *cache,
 		       const struct kvm_memory_slot *slot,
@@ -4375,6 +4380,12 @@ static int __kvm_mmu_faultin_pfn(struct kvm_vcpu *vcpu,
 	return RET_PF_CONTINUE;
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/mmu/mmu.c|4539| <<direct_page_fault>> r = kvm_mmu_faultin_pfn(vcpu, fault, ACC_ALL);
+ *   - arch/x86/kvm/mmu/mmu.c|4630| <<kvm_tdp_mmu_page_fault>> r = kvm_mmu_faultin_pfn(vcpu, fault, ACC_ALL);
+ *   - arch/x86/kvm/mmu/paging_tmpl.h|804| <<FNAME(page_fault)>> r = kvm_mmu_faultin_pfn(vcpu, fault, walker.pte_access);
+ */
 static int kvm_mmu_faultin_pfn(struct kvm_vcpu *vcpu,
 			       struct kvm_page_fault *fault, unsigned int access)
 {
@@ -4517,6 +4528,11 @@ static bool is_page_fault_stale(struct kvm_vcpu *vcpu,
 	       mmu_invalidate_retry_gfn(vcpu->kvm, fault->mmu_seq, fault->gfn);
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/mmu/mmu.c|4566| <<nonpaging_page_fault>> return direct_page_fault(vcpu, fault);
+ *   - arch/x86/kvm/mmu/mmu.c|4669| <<kvm_tdp_page_fault>> return direct_page_fault(vcpu, fault);
+ */
 static int direct_page_fault(struct kvm_vcpu *vcpu, struct kvm_page_fault *fault)
 {
 	int r;
@@ -4659,6 +4675,13 @@ bool kvm_mmu_may_ignore_guest_pat(void)
 	return shadow_memtype_mask;
 }
 
+/*
+ * 在以下使用kvm_tdp_page_fault():
+ *  - arch/x86/kvm/mmu/mmu.c|4681| <<kvm_tdp_map_page>> if (vcpu->arch.mmu->page_fault != kvm_tdp_page_fault)
+ *  - arch/x86/kvm/mmu/mmu.c|5450| <<init_kvm_tdp_mmu>> context->page_fault = kvm_tdp_page_fault;
+ *  - arch/x86/kvm/mmu/mmu_internal.h|306| <<kvm_mmu_do_page_fault>> .is_tdp = likely(vcpu->arch.mmu->page_fault == kvm_tdp_page_fault),
+ *  - arch/x86/kvm/mmu/mmu_internal.h|325| <<kvm_mmu_do_page_fault>> r = kvm_tdp_page_fault(vcpu, &fault);
+ */
 int kvm_tdp_page_fault(struct kvm_vcpu *vcpu, struct kvm_page_fault *fault)
 {
 #ifdef CONFIG_X86_64
@@ -7417,6 +7440,14 @@ int kvm_mmu_post_init_vm(struct kvm *kvm)
 		return 0;
 
 	kvm->arch.nx_huge_page_last = get_jiffies_64();
+	/*
+	 * called by:
+	 *   - arch/x86/kvm/mmu/mmu.c|7420| <<kvm_mmu_post_init_vm>> kvm->arch.nx_huge_page_recovery_thread =
+	 *            vhost_task_create(kvm_nx_huge_page_recovery_worker,
+	 *                              kvm_nx_huge_page_recovery_worker_kill, kvm, "kvm-nx-lpage-recovery");
+	 * drivers/vhost/vhost.c|701| <<vhost_worker_create>> vtsk = vhost_task_create(vhost_run_work_list,
+	 *            vhost_worker_killed, worker, name);
+	 */
 	kvm->arch.nx_huge_page_recovery_thread = vhost_task_create(
 		kvm_nx_huge_page_recovery_worker, kvm_nx_huge_page_recovery_worker_kill,
 		kvm, "kvm-nx-lpage-recovery");
diff --git a/arch/x86/kvm/mmu/mmu_internal.h b/arch/x86/kvm/mmu/mmu_internal.h
index b00abbe3f..ff9616238 100644
--- a/arch/x86/kvm/mmu/mmu_internal.h
+++ b/arch/x86/kvm/mmu/mmu_internal.h
@@ -290,6 +290,12 @@ static inline void kvm_mmu_prepare_memory_fault_exit(struct kvm_vcpu *vcpu,
 				      fault->is_private);
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/mmu/mmu.c|4254| <<kvm_arch_async_page_ready>> r = kvm_mmu_do_page_fault(vcpu, work->cr2_or_gpa, work->arch.error_code,
+ *   - arch/x86/kvm/mmu/mmu.c|4688| <<kvm_tdp_map_page>> r = kvm_mmu_do_page_fault(vcpu, gpa, error_code, true, NULL, level);
+ *   - arch/x86/kvm/mmu/mmu.c|6078| <<kvm_mmu_page_fault>> r = kvm_mmu_do_page_fault(vcpu, cr2_or_gpa, error_code, false,
+ */
 static inline int kvm_mmu_do_page_fault(struct kvm_vcpu *vcpu, gpa_t cr2_or_gpa,
 					u64 err, bool prefetch,
 					int *emulation_type, u8 *level)
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index c79a8cc57..f75908a2c 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -2282,6 +2282,11 @@ static s64 get_kvmclock_base_ns(void)
 }
 #endif
 
+/*
+ * called by:
+ *   - arch/x86/kvm/x86.c|3953| <<kvm_set_msr_common(MSR_KVM_WALL_CLOCK_NEW)>> kvm_write_wall_clock(vcpu->kvm, data, 0);
+ *   - arch/x86/kvm/x86.c|3960| <<kvm_set_msr_common(MSR_KVM_WALL_CLOCK)>> kvm_write_wall_clock(vcpu->kvm, data, 0);
+ */
 static void kvm_write_wall_clock(struct kvm *kvm, gpa_t wall_clock, int sec_hi_ofs)
 {
 	int version;
@@ -2307,6 +2312,13 @@ static void kvm_write_wall_clock(struct kvm *kvm, gpa_t wall_clock, int sec_hi_o
 
 	wall_nsec = kvm_get_wall_clock_epoch(kvm);
 
+	/*
+	 * struct pvclock_wall_clock {
+	 *     u32   version;
+	 *     u32   sec;
+	 *     u32   nsec;
+	 * } __attribute__((__packed__));
+	 */
 	wc.nsec = do_div(wall_nsec, NSEC_PER_SEC);
 	wc.sec = (u32)wall_nsec; /* overflow in 2106 guest time */
 	wc.version = version;
@@ -3315,6 +3327,11 @@ static int kvm_guest_time_update(struct kvm_vcpu *v)
  * Fall back to using their values at slightly different moments by
  * calling ktime_get_real_ns() and get_kvmclock_ns() separately.
  */
+/*
+ * called by:
+ *   - arch/x86/kvm/x86.c|2308| <<kvm_write_wall_clock>> wall_nsec = kvm_get_wall_clock_epoch(kvm);
+ *   - arch/x86/kvm/xen.c|63| <<kvm_xen_shared_info_init>> wall_nsec = kvm_get_wall_clock_epoch(kvm);
+ */
 uint64_t kvm_get_wall_clock_epoch(struct kvm *kvm)
 {
 #ifdef CONFIG_X86_64
@@ -6443,6 +6460,10 @@ static int kvm_vm_ioctl_set_pit2(struct kvm *kvm, struct kvm_pit_state2 *ps)
 	return 0;
 }
 
+/*
+ * 处理KVM_REINJECT_CONTROL:
+ *   - arch/x86/kvm/x86.c|7223| <<kvm_arch_vm_ioctl(KVM_REINJECT_CONTROL)>> r = kvm_vm_ioctl_reinject(kvm, &control);
+ */
 static int kvm_vm_ioctl_reinject(struct kvm *kvm,
 				 struct kvm_reinject_control *control)
 {
@@ -9897,15 +9918,58 @@ static void kvm_pv_kick_cpu_op(struct kvm *kvm, int apicid)
 	kvm_irq_delivery_to_apic(kvm, NULL, &lapic_irq, NULL);
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/ioapic.c|229| <<ioapic_set_irq>> if (edge && kvm_apicv_activated(ioapic->kvm))
+ *   - arch/x86/kvm/mmu/mmu.c|4434| <<kvm_mmu_faultin_pfn>> if (!kvm_apicv_activated(vcpu->kvm))
+ *   - arch/x86/kvm/svm/avic.c|256| <<avic_init_vmcb>> if (kvm_apicv_activated(svm->vcpu.kvm))
+ *   - arch/x86/kvm/svm/avic.c|290| <<avic_init_backing_page>> if (kvm_apicv_activated(vcpu->kvm)) {
+ *   - arch/x86/kvm/svm/nested.c|1164| <<nested_svm_vmexit>> if (kvm_apicv_activated(vcpu->kvm))
+ *   - arch/x86/kvm/svm/nested.c|1248| <<svm_leave_nested>> if (kvm_apicv_activated(vcpu->kvm))
+ */
 bool kvm_apicv_activated(struct kvm *kvm)
 {
+	/*
+	 * 在以下使用kvm_arch->apicv_inhibit_reasons:
+	 *   - arch/x86/kvm/x86.c|9919| <<kvm_apicv_activated>> return (READ_ONCE(kvm->arch.apicv_inhibit_reasons) == 0);
+	 *   - arch/x86/kvm/x86.c|9925| <<kvm_vcpu_apicv_activated>> ulong vm_reasons = READ_ONCE(vcpu->kvm->arch.apicv_inhibit_reasons);
+	 *   - arch/x86/kvm/x86.c|9953| <<kvm_apicv_init>> set_or_clear_apicv_inhibit(&kvm->arch.apicv_inhibit_reasons, reason, true);
+	 *   - arch/x86/kvm/x86.c|10612| <<__kvm_set_or_clear_apicv_inhibit>> old = new = kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|10630| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 *   - arch/x86/kvm/x86.c|10639| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 *
+	 * 被kvm_arch->apicv_update_lock保护.
+	 */
 	return (READ_ONCE(kvm->arch.apicv_inhibit_reasons) == 0);
 }
 EXPORT_SYMBOL_GPL(kvm_apicv_activated);
 
+/*
+ * called by:
+ *   - arch/x86/kvm/svm/svm.c|1642| <<svm_set_vintr>> WARN_ON(kvm_vcpu_apicv_activated(&svm->vcpu));
+ *   - arch/x86/kvm/x86.c|10584| <<__kvm_vcpu_update_apicv>> activate = kvm_vcpu_apicv_activated(vcpu) &&
+ *                  (kvm_get_apic_mode(vcpu) != LAPIC_MODE_DISABLED);
+ *   - arch/x86/kvm/x86.c|11074| <<vcpu_enter_guest>> WARN_ON_ONCE((kvm_vcpu_apicv_activated(vcpu) !=
+ *                  kvm_vcpu_apicv_active(vcpu)) && (kvm_get_apic_mode(vcpu) != LAPIC_MODE_DISABLED));
+ */
 bool kvm_vcpu_apicv_activated(struct kvm_vcpu *vcpu)
 {
+	/*
+	 * 在以下使用kvm_arch->apicv_inhibit_reasons:
+	 *   - arch/x86/kvm/x86.c|9919| <<kvm_apicv_activated>> return (READ_ONCE(kvm->arch.apicv_inhibit_reasons) == 0);
+	 *   - arch/x86/kvm/x86.c|9925| <<kvm_vcpu_apicv_activated>> ulong vm_reasons = READ_ONCE(vcpu->kvm->arch.apicv_inhibit_reasons);
+	 *   - arch/x86/kvm/x86.c|9953| <<kvm_apicv_init>> set_or_clear_apicv_inhibit(&kvm->arch.apicv_inhibit_reasons, reason, true);
+	 *   - arch/x86/kvm/x86.c|10612| <<__kvm_set_or_clear_apicv_inhibit>> old = new = kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|10630| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 *   - arch/x86/kvm/x86.c|10639| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 *
+	 * 被kvm_arch->apicv_update_lock保护.
+	 */
 	ulong vm_reasons = READ_ONCE(vcpu->kvm->arch.apicv_inhibit_reasons);
+	/*
+	 * 只有svm:
+	 * avic_vcpu_get_apicv_inhibit_reasons()
+	 */
 	ulong vcpu_reasons =
 			kvm_x86_call(vcpu_get_apicv_inhibit_reasons)(vcpu);
 
@@ -9913,6 +9977,11 @@ bool kvm_vcpu_apicv_activated(struct kvm_vcpu *vcpu)
 }
 EXPORT_SYMBOL_GPL(kvm_vcpu_apicv_activated);
 
+/*
+ * called by:
+ *   - arch/x86/kvm/x86.c|9953| <<kvm_apicv_init>> set_or_clear_apicv_inhibit(&kvm->arch.apicv_inhibit_reasons, reason, true);
+ *   - arch/x86/kvm/x86.c|10614| <<__kvm_set_or_clear_apicv_inhibit>> set_or_clear_apicv_inhibit(&new, reason, set);
+ */
 static void set_or_clear_apicv_inhibit(unsigned long *inhibits,
 				       enum kvm_apicv_inhibit reason, bool set)
 {
@@ -9925,16 +9994,47 @@ static void set_or_clear_apicv_inhibit(unsigned long *inhibits,
 	else
 		__clear_bit(reason, inhibits);
 
+	/*
+	 * 只在此处trace
+	 */
 	trace_kvm_apicv_inhibit_changed(reason, set, *inhibits);
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/x86.c|12757| <<kvm_arch_init_vm>> kvm_apicv_init(kvm);
+ */
 static void kvm_apicv_init(struct kvm *kvm)
 {
 	enum kvm_apicv_inhibit reason = enable_apicv ? APICV_INHIBIT_REASON_ABSENT :
 						       APICV_INHIBIT_REASON_DISABLED;
 
+	/*
+	 * 在以下使用kvm_arch->apicv_inhibit_reasons:
+	 *   - arch/x86/kvm/x86.c|9919| <<kvm_apicv_activated>> return (READ_ONCE(kvm->arch.apicv_inhibit_reasons) == 0);
+	 *   - arch/x86/kvm/x86.c|9925| <<kvm_vcpu_apicv_activated>> ulong vm_reasons = READ_ONCE(vcpu->kvm->arch.apicv_inhibit_reasons);
+	 *   - arch/x86/kvm/x86.c|9953| <<kvm_apicv_init>> set_or_clear_apicv_inhibit(&kvm->arch.apicv_inhibit_reasons, reason, true);
+	 *   - arch/x86/kvm/x86.c|10612| <<__kvm_set_or_clear_apicv_inhibit>> old = new = kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|10630| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 *   - arch/x86/kvm/x86.c|10639| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 *
+	 * 被kvm_arch->apicv_update_lock保护.
+	 */
 	set_or_clear_apicv_inhibit(&kvm->arch.apicv_inhibit_reasons, reason, true);
 
+	/*
+	 * 在以下使用kvm_arch->apicv_update_lock:
+	 *   - arch/x86/kvm/hyperv.c|137| <<synic_update_vector>> down_write(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/hyperv.c|152| <<synic_update_vector>> up_write(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|9955| <<kvm_apicv_init>> init_rwsem(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10542| <<__kvm_vcpu_update_apicv>> down_read(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10567| <<__kvm_vcpu_update_apicv>> up_read(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10607| <<__kvm_set_or_clear_apicv_inhibit>> lockdep_assert_held_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10654| <<kvm_set_or_clear_apicv_inhibit>> down_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10656| <<kvm_set_or_clear_apicv_inhibit>> up_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|12060| <<kvm_arch_vcpu_guestdbg_update_apicv_inhibit>> down_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|12069| <<kvm_arch_vcpu_guestdbg_update_apicv_inhibit>> up_write(&kvm->arch.apicv_update_lock);
+	 */
 	init_rwsem(&kvm->arch.apicv_update_lock);
 }
 
@@ -10522,6 +10622,19 @@ void __kvm_vcpu_update_apicv(struct kvm_vcpu *vcpu)
 	if (!lapic_in_kernel(vcpu))
 		return;
 
+	/*
+	 * 在以下使用kvm_arch->apicv_update_lock:
+	 *   - arch/x86/kvm/hyperv.c|137| <<synic_update_vector>> down_write(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/hyperv.c|152| <<synic_update_vector>> up_write(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|9955| <<kvm_apicv_init>> init_rwsem(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10542| <<__kvm_vcpu_update_apicv>> down_read(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10567| <<__kvm_vcpu_update_apicv>> up_read(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10607| <<__kvm_set_or_clear_apicv_inhibit>> lockdep_assert_held_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10654| <<kvm_set_or_clear_apicv_inhibit>> down_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10656| <<kvm_set_or_clear_apicv_inhibit>> up_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|12060| <<kvm_arch_vcpu_guestdbg_update_apicv_inhibit>> down_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|12069| <<kvm_arch_vcpu_guestdbg_update_apicv_inhibit>> up_write(&kvm->arch.apicv_update_lock);
+	 */
 	down_read(&vcpu->kvm->arch.apicv_update_lock);
 	preempt_disable();
 
@@ -10574,16 +10687,48 @@ static void kvm_vcpu_update_apicv(struct kvm_vcpu *vcpu)
 	__kvm_vcpu_update_apicv(vcpu);
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/hyperv.c|148| <<synic_update_vector>> __kvm_set_or_clear_apicv_inhibit(vcpu->kvm,
+ *                  APICV_INHIBIT_REASON_HYPERV, !!hv->synic_auto_eoi_used);
+ *   - arch/x86/kvm/x86.c|10642| <<kvm_set_or_clear_apicv_inhibit>> __kvm_set_or_clear_apicv_inhibit(kvm, reason, set);
+ *   - arch/x86/kvm/x86.c|12051| <<kvm_arch_vcpu_guestdbg_update_apicv_inhibit>> __kvm_set_or_clear_apicv_inhibit(kvm,
+ *                  APICV_INHIBIT_REASON_BLOCKIRQ, set);
+ */
 void __kvm_set_or_clear_apicv_inhibit(struct kvm *kvm,
 				      enum kvm_apicv_inhibit reason, bool set)
 {
 	unsigned long old, new;
 
+	/*
+	 * 在以下使用kvm_arch->apicv_update_lock:
+	 *   - arch/x86/kvm/hyperv.c|137| <<synic_update_vector>> down_write(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/hyperv.c|152| <<synic_update_vector>> up_write(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|9955| <<kvm_apicv_init>> init_rwsem(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10542| <<__kvm_vcpu_update_apicv>> down_read(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10567| <<__kvm_vcpu_update_apicv>> up_read(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10607| <<__kvm_set_or_clear_apicv_inhibit>> lockdep_assert_held_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10654| <<kvm_set_or_clear_apicv_inhibit>> down_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10656| <<kvm_set_or_clear_apicv_inhibit>> up_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|12060| <<kvm_arch_vcpu_guestdbg_update_apicv_inhibit>> down_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|12069| <<kvm_arch_vcpu_guestdbg_update_apicv_inhibit>> up_write(&kvm->arch.apicv_update_lock);
+	 */
 	lockdep_assert_held_write(&kvm->arch.apicv_update_lock);
 
 	if (!(kvm_x86_ops.required_apicv_inhibits & BIT(reason)))
 		return;
 
+	/*
+	 * 在以下使用kvm_arch->apicv_inhibit_reasons:
+	 *   - arch/x86/kvm/x86.c|9919| <<kvm_apicv_activated>> return (READ_ONCE(kvm->arch.apicv_inhibit_reasons) == 0);
+	 *   - arch/x86/kvm/x86.c|9925| <<kvm_vcpu_apicv_activated>> ulong vm_reasons = READ_ONCE(vcpu->kvm->arch.apicv_inhibit_reasons);
+	 *   - arch/x86/kvm/x86.c|9953| <<kvm_apicv_init>> set_or_clear_apicv_inhibit(&kvm->arch.apicv_inhibit_reasons, reason, true);
+	 *   - arch/x86/kvm/x86.c|10612| <<__kvm_set_or_clear_apicv_inhibit>> old = new = kvm->arch.apicv_inhibit_reasons;
+	 *   - arch/x86/kvm/x86.c|10630| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 *   - arch/x86/kvm/x86.c|10639| <<__kvm_set_or_clear_apicv_inhibit>> kvm->arch.apicv_inhibit_reasons = new;
+	 *
+	 * 被kvm_arch->apicv_update_lock保护.
+	 */
 	old = new = kvm->arch.apicv_inhibit_reasons;
 
 	set_or_clear_apicv_inhibit(&new, reason, set);
@@ -10615,12 +10760,30 @@ void __kvm_set_or_clear_apicv_inhibit(struct kvm *kvm,
 	}
 }
 
+/*
+ * called by:
+ *   - arch/x86/include/asm/kvm_host.h|2175| <<kvm_set_apicv_inhibit>> kvm_set_or_clear_apicv_inhibit(kvm, reason, true);
+ *   - arch/x86/include/asm/kvm_host.h|2181| <<kvm_clear_apicv_inhibit>> kvm_set_or_clear_apicv_inhibit(kvm, reason, false);
+ */
 void kvm_set_or_clear_apicv_inhibit(struct kvm *kvm,
 				    enum kvm_apicv_inhibit reason, bool set)
 {
 	if (!enable_apicv)
 		return;
 
+	/*
+	 * 在以下使用kvm_arch->apicv_update_lock:
+	 *   - arch/x86/kvm/hyperv.c|137| <<synic_update_vector>> down_write(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/hyperv.c|152| <<synic_update_vector>> up_write(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|9955| <<kvm_apicv_init>> init_rwsem(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10542| <<__kvm_vcpu_update_apicv>> down_read(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10567| <<__kvm_vcpu_update_apicv>> up_read(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10607| <<__kvm_set_or_clear_apicv_inhibit>> lockdep_assert_held_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10654| <<kvm_set_or_clear_apicv_inhibit>> down_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10656| <<kvm_set_or_clear_apicv_inhibit>> up_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|12060| <<kvm_arch_vcpu_guestdbg_update_apicv_inhibit>> down_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|12069| <<kvm_arch_vcpu_guestdbg_update_apicv_inhibit>> up_write(&kvm->arch.apicv_update_lock);
+	 */
 	down_write(&kvm->arch.apicv_update_lock);
 	__kvm_set_or_clear_apicv_inhibit(kvm, reason, set);
 	up_write(&kvm->arch.apicv_update_lock);
@@ -12014,6 +12177,10 @@ int kvm_arch_vcpu_ioctl_set_sregs(struct kvm_vcpu *vcpu,
 	return ret;
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/x86.c|12107| <<kvm_arch_vcpu_ioctl_set_guest_debug>> kvm_arch_vcpu_guestdbg_update_apicv_inhibit(vcpu->kvm);
+ */
 static void kvm_arch_vcpu_guestdbg_update_apicv_inhibit(struct kvm *kvm)
 {
 	bool set = false;
@@ -12023,6 +12190,19 @@ static void kvm_arch_vcpu_guestdbg_update_apicv_inhibit(struct kvm *kvm)
 	if (!enable_apicv)
 		return;
 
+	/*
+	 * 在以下使用kvm_arch->apicv_update_lock:
+	 *   - arch/x86/kvm/hyperv.c|137| <<synic_update_vector>> down_write(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/hyperv.c|152| <<synic_update_vector>> up_write(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|9955| <<kvm_apicv_init>> init_rwsem(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10542| <<__kvm_vcpu_update_apicv>> down_read(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10567| <<__kvm_vcpu_update_apicv>> up_read(&vcpu->kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10607| <<__kvm_set_or_clear_apicv_inhibit>> lockdep_assert_held_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10654| <<kvm_set_or_clear_apicv_inhibit>> down_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|10656| <<kvm_set_or_clear_apicv_inhibit>> up_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|12060| <<kvm_arch_vcpu_guestdbg_update_apicv_inhibit>> down_write(&kvm->arch.apicv_update_lock);
+	 *   - arch/x86/kvm/x86.c|12069| <<kvm_arch_vcpu_guestdbg_update_apicv_inhibit>> up_write(&kvm->arch.apicv_update_lock);
+	 */
 	down_write(&kvm->arch.apicv_update_lock);
 
 	kvm_for_each_vcpu(i, vcpu, kvm) {
diff --git a/drivers/net/virtio_net.c b/drivers/net/virtio_net.c
index 7646ddd9b..142115a0e 100644
--- a/drivers/net/virtio_net.c
+++ b/drivers/net/virtio_net.c
@@ -444,6 +444,14 @@ struct virtnet_info {
 	/* The lock to synchronize the access to refill_enabled */
 	spinlock_t refill_lock;
 
+	/*
+	 * 在以下使用virtnet_info->config_work:
+	 *   - drivers/net/virtio_net.c|3661| <<virtnet_close>> cancel_work_sync(&vi->config_work);
+	 *   - drivers/net/virtio_net.c|5611| <<virtnet_freeze_down>> flush_work(&vi->config_work);
+	 *   - drivers/net/virtio_net.c|6125| <<virtnet_config_changed_work>> container_of(work, struct virtnet_info, config_work);
+	 *   - drivers/net/virtio_net.c|6159| <<virtnet_config_changed>> schedule_work(&vi->config_work);
+	 *   - drivers/net/virtio_net.c|6719| <<virtnet_probe>> INIT_WORK(&vi->config_work, virtnet_config_changed_work);
+	 */
 	/* Work struct for config space updates */
 	struct work_struct config_work;
 
@@ -1059,6 +1067,13 @@ static void virtnet_rq_unmap_free_buf(struct virtqueue *vq, void *buf)
 	virtnet_rq_free_buf(vi, rq, buf);
 }
 
+/*
+ * called by:
+ *   - drivers/net/virtio_net.c|1130| <<check_sq_full_and_disable>> free_old_xmit(sq, txq, false);
+ *   - drivers/net/virtio_net.c|2976| <<virtnet_poll_cleantx>> free_old_xmit(sq, txq, !!budget);
+ *   - drivers/net/virtio_net.c|3174| <<virtnet_poll_tx>> free_old_xmit(sq, txq, !!budget);
+ *   - drivers/net/virtio_net.c|3278| <<start_xmit>> free_old_xmit(sq, txq, false);
+ */
 static void free_old_xmit(struct send_queue *sq, struct netdev_queue *txq,
 			  bool in_napi)
 {
@@ -2789,6 +2804,15 @@ static void skb_recv_done(struct virtqueue *rvq)
 	virtqueue_napi_schedule(&rq->napi, rvq);
 }
 
+/*
+ * called by:
+ *   - drivers/net/virtio_net.c|2828| <<virtnet_napi_tx_enable>> return virtnet_napi_enable(vq, napi);
+ *   - drivers/net/virtio_net.c|2849| <<refill_work>> virtnet_napi_enable(rq->vq, &rq->napi);
+ *   - drivers/net/virtio_net.c|3066| <<virtnet_enable_queue_pair>> virtnet_napi_enable(vi->rq[qp_index].vq, &vi->rq[qp_index].napi);
+ *   - drivers/net/virtio_net.c|3331| <<virtnet_rx_resume>> virtnet_napi_enable(rq->vq, &rq->napi);
+ *   - drivers/net/virtio_net.c|5991| <<virtnet_xdp_set>> virtnet_napi_enable(vi->rq[i].vq, &vi->rq[i].napi);
+ *   - drivers/net/virtio_net.c|6008| <<virtnet_xdp_set>> virtnet_napi_enable(vi->rq[i].vq, &vi->rq[i].napi);
+ */
 static void virtnet_napi_enable(struct virtqueue *vq, struct napi_struct *napi)
 {
 	napi_enable(napi);
@@ -3658,6 +3682,14 @@ static int virtnet_close(struct net_device *dev)
 	/* Stop getting status/speed updates: we don't care until next
 	 * open
 	 */
+	/*
+	 * 在以下使用virtnet_info->config_work:
+	 *   - drivers/net/virtio_net.c|3661| <<virtnet_close>> cancel_work_sync(&vi->config_work);
+	 *   - drivers/net/virtio_net.c|5611| <<virtnet_freeze_down>> flush_work(&vi->config_work);
+	 *   - drivers/net/virtio_net.c|6125| <<virtnet_config_changed_work>> container_of(work, struct virtnet_info, config_work);
+	 *   - drivers/net/virtio_net.c|6159| <<virtnet_config_changed>> schedule_work(&vi->config_work);
+	 *   - drivers/net/virtio_net.c|6719| <<virtnet_probe>> INIT_WORK(&vi->config_work, virtnet_config_changed_work);
+	 */
 	cancel_work_sync(&vi->config_work);
 
 	for (i = 0; i < vi->max_queue_pairs; i++) {
@@ -5607,6 +5639,14 @@ static void virtnet_freeze_down(struct virtio_device *vdev)
 {
 	struct virtnet_info *vi = vdev->priv;
 
+	/*
+	 * 在以下使用virtnet_info->config_work:
+	 *   - drivers/net/virtio_net.c|3661| <<virtnet_close>> cancel_work_sync(&vi->config_work);
+	 *   - drivers/net/virtio_net.c|5611| <<virtnet_freeze_down>> flush_work(&vi->config_work);
+	 *   - drivers/net/virtio_net.c|6125| <<virtnet_config_changed_work>> container_of(work, struct virtnet_info, config_work);
+	 *   - drivers/net/virtio_net.c|6159| <<virtnet_config_changed>> schedule_work(&vi->config_work);
+	 *   - drivers/net/virtio_net.c|6719| <<virtnet_probe>> INIT_WORK(&vi->config_work, virtnet_config_changed_work);
+	 */
 	/* Make sure no work handler is accessing the device */
 	flush_work(&vi->config_work);
 	disable_rx_mode_work(vi);
@@ -6156,6 +6196,14 @@ static void virtnet_config_changed(struct virtio_device *vdev)
 {
 	struct virtnet_info *vi = vdev->priv;
 
+	/*
+	 * 在以下使用virtnet_info->config_work:
+	 *   - drivers/net/virtio_net.c|3661| <<virtnet_close>> cancel_work_sync(&vi->config_work);
+	 *   - drivers/net/virtio_net.c|5611| <<virtnet_freeze_down>> flush_work(&vi->config_work);
+	 *   - drivers/net/virtio_net.c|6125| <<virtnet_config_changed_work>> container_of(work, struct virtnet_info, config_work);
+	 *   - drivers/net/virtio_net.c|6159| <<virtnet_config_changed>> schedule_work(&vi->config_work);
+	 *   - drivers/net/virtio_net.c|6719| <<virtnet_probe>> INIT_WORK(&vi->config_work, virtnet_config_changed_work);
+	 */
 	schedule_work(&vi->config_work);
 }
 
@@ -6716,6 +6764,14 @@ static int virtnet_probe(struct virtio_device *vdev)
 	vi->vdev = vdev;
 	vdev->priv = vi;
 
+	/*
+	 * 在以下使用virtnet_info->config_work:
+	 *   - drivers/net/virtio_net.c|3661| <<virtnet_close>> cancel_work_sync(&vi->config_work);
+	 *   - drivers/net/virtio_net.c|5611| <<virtnet_freeze_down>> flush_work(&vi->config_work);
+	 *   - drivers/net/virtio_net.c|6125| <<virtnet_config_changed_work>> container_of(work, struct virtnet_info, config_work);
+	 *   - drivers/net/virtio_net.c|6159| <<virtnet_config_changed>> schedule_work(&vi->config_work);
+	 *   - drivers/net/virtio_net.c|6719| <<virtnet_probe>> INIT_WORK(&vi->config_work, virtnet_config_changed_work);
+	 */
 	INIT_WORK(&vi->config_work, virtnet_config_changed_work);
 	INIT_WORK(&vi->rx_mode_work, virtnet_rx_mode_work);
 	spin_lock_init(&vi->refill_lock);
@@ -6935,6 +6991,14 @@ static int virtnet_probe(struct virtio_device *vdev)
 	   otherwise get link status from config. */
 	netif_carrier_off(dev);
 	if (virtio_has_feature(vi->vdev, VIRTIO_NET_F_STATUS)) {
+		/*
+		 * 在以下使用virtnet_info->config_work:
+		 *   - drivers/net/virtio_net.c|3661| <<virtnet_close>> cancel_work_sync(&vi->config_work);
+		 *   - drivers/net/virtio_net.c|5611| <<virtnet_freeze_down>> flush_work(&vi->config_work);
+		 *   - drivers/net/virtio_net.c|6125| <<virtnet_config_changed_work>> container_of(work, struct virtnet_info, config_work);
+		 *   - drivers/net/virtio_net.c|6159| <<virtnet_config_changed>> schedule_work(&vi->config_work);
+		 *   - drivers/net/virtio_net.c|6719| <<virtnet_probe>> INIT_WORK(&vi->config_work, virtnet_config_changed_work);
+		 */
 		virtnet_config_changed_work(&vi->config_work);
 	} else {
 		vi->status = VIRTIO_NET_S_LINK_UP;
@@ -7003,6 +7067,14 @@ static void virtnet_remove(struct virtio_device *vdev)
 
 	virtnet_cpu_notif_remove(vi);
 
+	/*
+	 * 在以下使用virtnet_info->config_work:
+	 *   - drivers/net/virtio_net.c|3661| <<virtnet_close>> cancel_work_sync(&vi->config_work);
+	 *   - drivers/net/virtio_net.c|5611| <<virtnet_freeze_down>> flush_work(&vi->config_work);
+	 *   - drivers/net/virtio_net.c|6125| <<virtnet_config_changed_work>> container_of(work, struct virtnet_info, config_work);
+	 *   - drivers/net/virtio_net.c|6159| <<virtnet_config_changed>> schedule_work(&vi->config_work);
+	 *   - drivers/net/virtio_net.c|6719| <<virtnet_probe>> INIT_WORK(&vi->config_work, virtnet_config_changed_work);
+	 */
 	/* Make sure no work handler is accessing the device. */
 	flush_work(&vi->config_work);
 	disable_rx_mode_work(vi);
diff --git a/drivers/net/xen-netfront.c b/drivers/net/xen-netfront.c
index 63fe51d0e..3c807001d 100644
--- a/drivers/net/xen-netfront.c
+++ b/drivers/net/xen-netfront.c
@@ -267,6 +267,10 @@ static void xennet_maybe_wake_tx(struct netfront_queue *queue)
 }
 
 
+/*
+ * called by:
+ *   - drivers/net/xen-netfront.c|316| <<xennet_alloc_rx_buffers>> skb = xennet_alloc_one_rx_buffer(queue);
+ */
 static struct sk_buff *xennet_alloc_one_rx_buffer(struct netfront_queue *queue)
 {
 	struct sk_buff *skb;
diff --git a/drivers/scsi/virtio_scsi.c b/drivers/scsi/virtio_scsi.c
index 8471f38b7..a826381dd 100644
--- a/drivers/scsi/virtio_scsi.c
+++ b/drivers/scsi/virtio_scsi.c
@@ -42,6 +42,18 @@ module_param(virtscsi_poll_queues, uint, 0644);
 MODULE_PARM_DESC(virtscsi_poll_queues,
 		 "The number of dedicated virtqueues for polling I/O");
 
+/*
+ * 在以下使用virtio_scsi_cmd->resp:
+ *   - drivers/scsi/virtio_scsi.c|126| <<virtscsi_complete_cmd>> struct virtio_scsi_cmd_resp *resp = &cmd->resp.cmd;
+ *   - drivers/scsi/virtio_scsi.c|556| <<__virtscsi_add_cmd>> sg_init_one(&resp, &cmd->resp, resp_size);
+ *   - drivers/scsi/virtio_scsi.c|708| <<virtscsi_queuecommand>> ret = virtscsi_add_cmd(req_vq, cmd,
+ *             req_size, sizeof(cmd->resp.cmd), kick);
+ *   - drivers/scsi/virtio_scsi.c|710| <<virtscsi_queuecommand>> cmd->resp.cmd.response = VIRTIO_SCSI_S_BAD_TARGET;
+ *   - drivers/scsi/virtio_scsi.c|739| <<virtscsi_tmf>> if (virtscsi_add_cmd(&vscsi->ctrl_vq, cmd,
+ *             sizeof cmd->req.tmf, sizeof cmd->resp.tmf, true) < 0)
+ *   - drivers/scsi/virtio_scsi.c|751| <<virtscsi_tmf>> if (cmd->resp.tmf.response == VIRTIO_SCSI_S_OK ||
+ *   - drivers/scsi/virtio_scsi.c|752| <<virtscsi_tmf>> cmd->resp.tmf.response == VIRTIO_SCSI_S_FUNCTION_SUCCEEDED)
+ */
 /* Command queue element */
 struct virtio_scsi_cmd {
 	struct scsi_cmnd *sc;
@@ -112,10 +124,29 @@ static void virtscsi_compute_resid(struct scsi_cmnd *sc, u32 resid)
  *
  * Called with vq_lock held.
  */
+/*
+ * 在以下使用virtscsi_complete_cmd():
+ *   - drivers/scsi/virtio_scsi.c|228| <<virtscsi_req_done>> virtscsi_vq_done(vscsi, req_vq, virtscsi_complete_cmd);
+ *   - drivers/scsi/virtio_scsi.c|253| <<virtscsi_poll_requests>> virtscsi_vq_done(vscsi, &vscsi->req_vqs[i], virtscsi_complete_cmd);
+ *   - drivers/scsi/virtio_scsi.c|699| <<virtscsi_queuecommand>> virtscsi_complete_cmd(vscsi, cmd);
+ *   - drivers/scsi/virtio_scsi.c|889| <<virtscsi_mq_poll>> virtscsi_complete_cmd(vscsi, buf);
+ */
 static void virtscsi_complete_cmd(struct virtio_scsi *vscsi, void *buf)
 {
 	struct virtio_scsi_cmd *cmd = buf;
 	struct scsi_cmnd *sc = cmd->sc;
+	/*
+	 * 在以下使用virtio_scsi_cmd->resp:
+	 *   - drivers/scsi/virtio_scsi.c|126| <<virtscsi_complete_cmd>> struct virtio_scsi_cmd_resp *resp = &cmd->resp.cmd;
+	 *   - drivers/scsi/virtio_scsi.c|556| <<__virtscsi_add_cmd>> sg_init_one(&resp, &cmd->resp, resp_size);
+	 *   - drivers/scsi/virtio_scsi.c|708| <<virtscsi_queuecommand>> ret = virtscsi_add_cmd(req_vq, cmd,
+	 *             req_size, sizeof(cmd->resp.cmd), kick);
+	 *   - drivers/scsi/virtio_scsi.c|710| <<virtscsi_queuecommand>> cmd->resp.cmd.response = VIRTIO_SCSI_S_BAD_TARGET;
+	 *   - drivers/scsi/virtio_scsi.c|739| <<virtscsi_tmf>> if (virtscsi_add_cmd(&vscsi->ctrl_vq, cmd,
+	 *             sizeof cmd->req.tmf, sizeof cmd->resp.tmf, true) < 0)
+	 *   - drivers/scsi/virtio_scsi.c|751| <<virtscsi_tmf>> if (cmd->resp.tmf.response == VIRTIO_SCSI_S_OK ||
+	 *   - drivers/scsi/virtio_scsi.c|752| <<virtscsi_tmf>> cmd->resp.tmf.response == VIRTIO_SCSI_S_FUNCTION_SUCCEEDED)
+	 */
 	struct virtio_scsi_cmd_resp *resp = &cmd->resp.cmd;
 
 	dev_dbg(&sc->device->sdev_gendev,
@@ -173,6 +204,17 @@ static void virtscsi_complete_cmd(struct virtio_scsi *vscsi, void *buf)
 	scsi_done(sc);
 }
 
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|202| <<virtscsi_req_done>> virtscsi_vq_done(vscsi,
+ *             req_vq, virtscsi_complete_cmd);
+ *   - drivers/scsi/virtio_scsi.c|211| <<virtscsi_poll_requests>> virtscsi_vq_done(vscsi,
+ *             &vscsi->req_vqs[i], virtscsi_complete_cmd);
+ *   - drivers/scsi/virtio_scsi.c|228| <<virtscsi_ctrl_done>> virtscsi_vq_done(vscsi,
+ *             &vscsi->ctrl_vq, virtscsi_complete_free);
+ *   - drivers/scsi/virtio_scsi.c|426| <<virtscsi_event_done>> virtscsi_vq_done(vscsi,
+ *             &vscsi->event_vq, virtscsi_complete_event);
+ */
 static void virtscsi_vq_done(struct virtio_scsi *vscsi,
 			     struct virtio_scsi_vq *virtscsi_vq,
 			     void (*fn)(struct virtio_scsi *vscsi, void *buf))
@@ -192,6 +234,10 @@ static void virtscsi_vq_done(struct virtio_scsi *vscsi,
 	spin_unlock_irqrestore(&virtscsi_vq->vq_lock, flags);
 }
 
+/*
+ * 在以下使用virtscsi_req_done():
+ *   - drivers/scsi/virtio_scsi.c|919| <<virtscsi_init>> vqs_info[i].callback = virtscsi_req_done;
+ */
 static void virtscsi_req_done(struct virtqueue *vq)
 {
 	struct Scsi_Host *sh = virtio_scsi_host(vq->vdev);
@@ -199,19 +245,51 @@ static void virtscsi_req_done(struct virtqueue *vq)
 	int index = vq->index - VIRTIO_SCSI_VQ_BASE;
 	struct virtio_scsi_vq *req_vq = &vscsi->req_vqs[index];
 
+	/*
+	 * called by:
+	 *   - drivers/scsi/virtio_scsi.c|202| <<virtscsi_req_done>> virtscsi_vq_done(vscsi,
+	 *             req_vq, virtscsi_complete_cmd);
+	 *   - drivers/scsi/virtio_scsi.c|211| <<virtscsi_poll_requests>> virtscsi_vq_done(vscsi,
+	 *             &vscsi->req_vqs[i], virtscsi_complete_cmd);
+	 *   - drivers/scsi/virtio_scsi.c|228| <<virtscsi_ctrl_done>> virtscsi_vq_done(vscsi,
+	 *             &vscsi->ctrl_vq, virtscsi_complete_free);
+	 *   - drivers/scsi/virtio_scsi.c|426| <<virtscsi_event_done>> virtscsi_vq_done(vscsi,
+	 *             &vscsi->event_vq, virtscsi_complete_event);
+	 */
 	virtscsi_vq_done(vscsi, req_vq, virtscsi_complete_cmd);
 };
 
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|664| <<virtscsi_tmf>> virtscsi_poll_requests(vscsi);
+ */
 static void virtscsi_poll_requests(struct virtio_scsi *vscsi)
 {
 	int i, num_vqs;
 
 	num_vqs = vscsi->num_queues;
+	/*
+	 * called by:
+	 *   - drivers/scsi/virtio_scsi.c|202| <<virtscsi_req_done>> virtscsi_vq_done(vscsi,
+	 *             req_vq, virtscsi_complete_cmd);
+	 *   - drivers/scsi/virtio_scsi.c|211| <<virtscsi_poll_requests>> virtscsi_vq_done(vscsi,
+	 *             &vscsi->req_vqs[i], virtscsi_complete_cmd);
+	 *   - drivers/scsi/virtio_scsi.c|228| <<virtscsi_ctrl_done>> virtscsi_vq_done(vscsi,
+	 *             &vscsi->ctrl_vq, virtscsi_complete_free);
+	 *   - drivers/scsi/virtio_scsi.c|426| <<virtscsi_event_done>> virtscsi_vq_done(vscsi,
+	 *             &vscsi->event_vq, virtscsi_complete_event);
+	 *
+	 * 这里是&vscsi->req_vqs[i], 不是ctrl或者event!
+	 */
 	for (i = 0; i < num_vqs; i++)
 		virtscsi_vq_done(vscsi, &vscsi->req_vqs[i],
 				 virtscsi_complete_cmd);
 }
 
+/*
+ * 只在以下使用virtscsi_complete_free():
+ *   - drivers/scsi/virtio_scsi.c|289| <<virtscsi_ctrl_done>> virtscsi_vq_done(vscsi, &vscsi->ctrl_vq, virtscsi_complete_free);
+ */
 static void virtscsi_complete_free(struct virtio_scsi *vscsi, void *buf)
 {
 	struct virtio_scsi_cmd *cmd = buf;
@@ -225,6 +303,17 @@ static void virtscsi_ctrl_done(struct virtqueue *vq)
 	struct Scsi_Host *sh = virtio_scsi_host(vq->vdev);
 	struct virtio_scsi *vscsi = shost_priv(sh);
 
+	/*
+	 * called by:
+	 *   - drivers/scsi/virtio_scsi.c|202| <<virtscsi_req_done>> virtscsi_vq_done(vscsi,
+	 *             req_vq, virtscsi_complete_cmd);
+	 *   - drivers/scsi/virtio_scsi.c|211| <<virtscsi_poll_requests>> virtscsi_vq_done(vscsi,
+	 *             &vscsi->req_vqs[i], virtscsi_complete_cmd);
+	 *   - drivers/scsi/virtio_scsi.c|228| <<virtscsi_ctrl_done>> virtscsi_vq_done(vscsi,
+	 *             &vscsi->ctrl_vq, virtscsi_complete_free);
+	 *   - drivers/scsi/virtio_scsi.c|426| <<virtscsi_event_done>> virtscsi_vq_done(vscsi,
+	 *             &vscsi->event_vq, virtscsi_complete_event);
+	 */
 	virtscsi_vq_done(vscsi, &vscsi->ctrl_vq, virtscsi_complete_free);
 };
 
@@ -423,9 +512,24 @@ static void virtscsi_event_done(struct virtqueue *vq)
 	struct Scsi_Host *sh = virtio_scsi_host(vq->vdev);
 	struct virtio_scsi *vscsi = shost_priv(sh);
 
+	/*
+	 * called by:
+	 *   - drivers/scsi/virtio_scsi.c|202| <<virtscsi_req_done>> virtscsi_vq_done(vscsi,
+	 *             req_vq, virtscsi_complete_cmd);
+	 *   - drivers/scsi/virtio_scsi.c|211| <<virtscsi_poll_requests>> virtscsi_vq_done(vscsi,
+	 *             &vscsi->req_vqs[i], virtscsi_complete_cmd);
+	 *   - drivers/scsi/virtio_scsi.c|228| <<virtscsi_ctrl_done>> virtscsi_vq_done(vscsi,
+	 *             &vscsi->ctrl_vq, virtscsi_complete_free);
+	 *   - drivers/scsi/virtio_scsi.c|426| <<virtscsi_event_done>> virtscsi_vq_done(vscsi,
+	 *             &vscsi->event_vq, virtscsi_complete_event);
+	 */
 	virtscsi_vq_done(vscsi, &vscsi->event_vq, virtscsi_complete_event);
 };
 
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|505| <<virtscsi_add_cmd>> err = __virtscsi_add_cmd(vq->vq, cmd, req_size, resp_size);
+ */
 static int __virtscsi_add_cmd(struct virtqueue *vq,
 			    struct virtio_scsi_cmd *cmd,
 			    size_t req_size, size_t resp_size)
@@ -456,6 +560,34 @@ static int __virtscsi_add_cmd(struct virtqueue *vq,
 		sgs[out_num++] = out->sgl;
 	}
 
+	/*
+	 * 在以下使用virtio_scsi_cmd->resp:
+	 *   - drivers/scsi/virtio_scsi.c|126| <<virtscsi_complete_cmd>> struct virtio_scsi_cmd_resp *resp = &cmd->resp.cmd;
+	 *   - drivers/scsi/virtio_scsi.c|556| <<__virtscsi_add_cmd>> sg_init_one(&resp, &cmd->resp, resp_size);
+	 *   - drivers/scsi/virtio_scsi.c|708| <<virtscsi_queuecommand>> ret = virtscsi_add_cmd(req_vq, cmd,
+	 *             req_size, sizeof(cmd->resp.cmd), kick);
+	 *   - drivers/scsi/virtio_scsi.c|710| <<virtscsi_queuecommand>> cmd->resp.cmd.response = VIRTIO_SCSI_S_BAD_TARGET;
+	 *   - drivers/scsi/virtio_scsi.c|739| <<virtscsi_tmf>> if (virtscsi_add_cmd(&vscsi->ctrl_vq, cmd,
+	 *             sizeof cmd->req.tmf, sizeof cmd->resp.tmf, true) < 0)
+	 *   - drivers/scsi/virtio_scsi.c|751| <<virtscsi_tmf>> if (cmd->resp.tmf.response == VIRTIO_SCSI_S_OK ||
+	 *   - drivers/scsi/virtio_scsi.c|752| <<virtscsi_tmf>> cmd->resp.tmf.response == VIRTIO_SCSI_S_FUNCTION_SUCCEEDED)
+	 *
+	 *
+	 * struct virtio_scsi_cmd_resp {
+	 *     __virtio32 sense_len;           // Sense data length
+	 *     __virtio32 resid;               // Residual bytes in data buffer
+	 *     __virtio16 status_qualifier;    // Status qualifier
+	 *     __u8 status;            // Command completion status
+	 *     __u8 response;          // Response values
+	 *     __u8 sense[VIRTIO_SCSI_SENSE_SIZE];
+	 * } __attribute__((packed));
+	 *
+	 * 参考代码:
+	 * memset(sgl, 0, sizeof(*sgl) * nents);
+	 * sg_set_page(sg, virt_to_page(buf), buflen, offset_in_page(buf));
+	 * sg_mark_end(&sgl[nents - 1]);
+	 */
+
 	/* Response header.  */
 	sg_init_one(&resp, &cmd->resp, resp_size);
 	sgs[out_num + in_num++] = &resp;
@@ -492,6 +624,13 @@ static void virtscsi_kick_vq(struct virtio_scsi_vq *vq)
  * @resp_size	: size of the response buffer
  * @kick	: whether to kick the virtqueue immediately
  */
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|602| <<virtscsi_queuecommand>> ret = virtscsi_add_cmd(req_vq,
+ *             cmd, req_size, sizeof(cmd->resp.cmd), kick);
+ *   - drivers/scsi/virtio_scsi.c|620| <<virtscsi_tmf>> if (virtscsi_add_cmd(&vscsi->ctrl_vq,
+ *             cmd, sizeof cmd->req.tmf, sizeof cmd->resp.tmf, true) < 0)
+ */
 static int virtscsi_add_cmd(struct virtio_scsi_vq *vq,
 			     struct virtio_scsi_cmd *cmd,
 			     size_t req_size, size_t resp_size,
@@ -502,6 +641,9 @@ static int virtscsi_add_cmd(struct virtio_scsi_vq *vq,
 	bool needs_kick = false;
 
 	spin_lock_irqsave(&vq->vq_lock, flags);
+	/*
+	 * 只在此处调用
+	 */
 	err = __virtscsi_add_cmd(vq->vq, cmd, req_size, resp_size);
 	if (!err && kick)
 		needs_kick = virtqueue_kick_prepare(vq->vq);
@@ -598,6 +740,18 @@ static int virtscsi_queuecommand(struct Scsi_Host *shost,
 		req_size = sizeof(cmd->req.cmd);
 	}
 
+	/*
+	 * 在以下使用virtio_scsi_cmd->resp:
+	 *   - drivers/scsi/virtio_scsi.c|126| <<virtscsi_complete_cmd>> struct virtio_scsi_cmd_resp *resp = &cmd->resp.cmd;
+	 *   - drivers/scsi/virtio_scsi.c|556| <<__virtscsi_add_cmd>> sg_init_one(&resp, &cmd->resp, resp_size);
+	 *   - drivers/scsi/virtio_scsi.c|708| <<virtscsi_queuecommand>> ret = virtscsi_add_cmd(req_vq, cmd,
+	 *             req_size, sizeof(cmd->resp.cmd), kick);
+	 *   - drivers/scsi/virtio_scsi.c|710| <<virtscsi_queuecommand>> cmd->resp.cmd.response = VIRTIO_SCSI_S_BAD_TARGET;
+	 *   - drivers/scsi/virtio_scsi.c|739| <<virtscsi_tmf>> if (virtscsi_add_cmd(&vscsi->ctrl_vq, cmd,
+	 *             sizeof cmd->req.tmf, sizeof cmd->resp.tmf, true) < 0)
+	 *   - drivers/scsi/virtio_scsi.c|751| <<virtscsi_tmf>> if (cmd->resp.tmf.response == VIRTIO_SCSI_S_OK ||
+	 *   - drivers/scsi/virtio_scsi.c|752| <<virtscsi_tmf>> cmd->resp.tmf.response == VIRTIO_SCSI_S_FUNCTION_SUCCEEDED)
+	 */
 	kick = (sc->flags & SCMD_LAST) != 0;
 	ret = virtscsi_add_cmd(req_vq, cmd, req_size, sizeof(cmd->resp.cmd), kick);
 	if (ret == -EIO) {
@@ -611,17 +765,37 @@ static int virtscsi_queuecommand(struct Scsi_Host *shost,
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/scsi/virtio_scsi.c|665| <<virtscsi_device_reset>> return virtscsi_tmf(vscsi, cmd);
+ *   - drivers/scsi/virtio_scsi.c|723| <<virtscsi_abort>> return virtscsi_tmf(vscsi, cmd);
+ */
 static int virtscsi_tmf(struct virtio_scsi *vscsi, struct virtio_scsi_cmd *cmd)
 {
 	DECLARE_COMPLETION_ONSTACK(comp);
 	int ret = FAILED;
 
 	cmd->comp = &comp;
+	/*
+	 * called by:
+	 *   - drivers/scsi/virtio_scsi.c|602| <<virtscsi_queuecommand>> ret = virtscsi_add_cmd(req_vq,
+	 *             cmd, req_size, sizeof(cmd->resp.cmd), kick);
+	 *   - drivers/scsi/virtio_scsi.c|620| <<virtscsi_tmf>> if (virtscsi_add_cmd(&vscsi->ctrl_vq,
+	 *             cmd, sizeof cmd->req.tmf, sizeof cmd->resp.tmf, true) < 0)
+	 */
 	if (virtscsi_add_cmd(&vscsi->ctrl_vq, cmd,
 			      sizeof cmd->req.tmf, sizeof cmd->resp.tmf, true) < 0)
 		goto out;
 
 	wait_for_completion(&comp);
+	/*
+	 * struct virtio_scsi_ctrl_tmf_resp {
+	 *     __u8 response;
+	 * } __attribute__((packed));
+	 *
+	 * struct virtio_scsi_cmd *cmd:
+	 * -> struct virtio_scsi_ctrl_tmf_resp tmf;
+	 */
 	if (cmd->resp.tmf.response == VIRTIO_SCSI_S_OK ||
 	    cmd->resp.tmf.response == VIRTIO_SCSI_S_FUNCTION_SUCCEEDED)
 		ret = SUCCESS;
@@ -635,6 +809,9 @@ static int virtscsi_tmf(struct virtio_scsi *vscsi, struct virtio_scsi_cmd *cmd)
 	 * In the abort case, scsi_done() will do nothing, because the
 	 * command timed out and hence SCMD_STATE_COMPLETE has been set.
 	 */
+	/*
+	 * 只在此处调用	
+	 */
 	virtscsi_poll_requests(vscsi);
 
 out:
@@ -642,6 +819,9 @@ static int virtscsi_tmf(struct virtio_scsi *vscsi, struct virtio_scsi_cmd *cmd)
 	return ret;
 }
 
+/*
+ * struct scsi_host_template virtscsi_host_template.eh_device_reset_handler = virtscsi_device_reset()
+ */
 static int virtscsi_device_reset(struct scsi_cmnd *sc)
 {
 	struct virtio_scsi *vscsi = shost_priv(sc->device->host);
@@ -653,6 +833,17 @@ static int virtscsi_device_reset(struct scsi_cmnd *sc)
 		return FAILED;
 
 	memset(cmd, 0, sizeof(*cmd));
+	/*
+	 * struct virtio_scsi_ctrl_tmf_req {
+	 *     __virtio32 type;
+	 *     __virtio32 subtype;
+	 *     __u8 lun[8];
+	 *     __virtio64 tag;
+	 * } __attribute__((packed));
+	 *
+	 * struct virtio_scsi_cmd *cmd:
+	 * -> struct virtio_scsi_ctrl_tmf_req tmf;
+	 */
 	cmd->req.tmf = (struct virtio_scsi_ctrl_tmf_req){
 		.type = VIRTIO_SCSI_T_TMF,
 		.subtype = cpu_to_virtio32(vscsi->vdev,
@@ -662,6 +853,11 @@ static int virtscsi_device_reset(struct scsi_cmnd *sc)
 		.lun[2] = (sc->device->lun >> 8) | 0x40,
 		.lun[3] = sc->device->lun & 0xff,
 	};
+	/*
+	 * called by:
+	 *   - drivers/scsi/virtio_scsi.c|665| <<virtscsi_device_reset>> return virtscsi_tmf(vscsi, cmd);
+	 *   - drivers/scsi/virtio_scsi.c|723| <<virtscsi_abort>> return virtscsi_tmf(vscsi, cmd);
+	 */
 	return virtscsi_tmf(vscsi, cmd);
 }
 
@@ -750,6 +946,9 @@ static void virtscsi_map_queues(struct Scsi_Host *shost)
 	}
 }
 
+/*
+ * struct scsi_host_template virtscsi_host_template.mq_poll = virtscsi_mq_poll()
+ */
 static int virtscsi_mq_poll(struct Scsi_Host *shost, unsigned int queue_num)
 {
 	struct virtio_scsi *vscsi = shost_priv(shost);
diff --git a/drivers/target/loopback/tcm_loop.c b/drivers/target/loopback/tcm_loop.c
index 761c511ae..e31c21781 100644
--- a/drivers/target/loopback/tcm_loop.c
+++ b/drivers/target/loopback/tcm_loop.c
@@ -1123,6 +1123,23 @@ static int __init tcm_loop_fabric_init(void)
 	if (ret)
 		goto out_destroy_cache;
 
+	/*
+	 * called by:
+	 *   - drivers/infiniband/ulp/srpt/ib_srpt.c|3961| <<srpt_init_module>> ret = target_register_template(&srpt_template);
+	 *   - drivers/scsi/elx/efct/efct_lio.c|1662| <<efct_scsi_tgt_driver_init>> rc = target_register_template(&efct_lio_ops);
+	 *   - drivers/scsi/elx/efct/efct_lio.c|1667| <<efct_scsi_tgt_driver_init>> rc = target_register_template(&efct_lio_npiv_ops);
+	 *   - drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c|4036| <<ibmvscsis_init>> rc = target_register_template(&ibmvscsis_ops);
+	 *   - drivers/scsi/qla2xxx/tcm_qla2xxx.c|1878| <<tcm_qla2xxx_register_configfs>> ret = target_register_template(&tcm_qla2xxx_ops);
+	 *   - drivers/scsi/qla2xxx/tcm_qla2xxx.c|1882| <<tcm_qla2xxx_register_configfs>> ret = target_register_template(&tcm_qla2xxx_npiv_ops);
+	 *   - drivers/target/iscsi/iscsi_target.c|695| <<iscsi_target_init_module>> ret = target_register_template(&iscsi_ops);
+	 *   - drivers/target/loopback/tcm_loop.c|1126| <<tcm_loop_fabric_init>> ret = target_register_template(&loop_ops);
+	 *   - drivers/target/sbp/sbp_target.c|2288| <<sbp_init>> return target_register_template(&sbp_ops);
+	 *   - drivers/target/tcm_fc/tfc_conf.c|448| <<ft_init>> ret = target_register_template(&ft_fabric_ops);
+	 *   - drivers/target/tcm_remote/tcm_remote.c|256| <<tcm_remote_fabric_init>> return target_register_template(&remote_ops);
+	 *   - drivers/usb/gadget/function/f_tcm.c|2289| <<tcm_init>> ret = target_register_template(&usbg_ops);
+	 *   - drivers/vhost/scsi.c|2792| <<vhost_scsi_init>> ret = target_register_template(&vhost_scsi_ops);
+	 *   - drivers/xen/xen-scsiback.c|1866| <<scsiback_init>> ret = target_register_template(&scsiback_ops);
+	 */
 	ret = target_register_template(&loop_ops);
 	if (ret)
 		goto out_release_core_bus;
diff --git a/drivers/target/target_core_configfs.c b/drivers/target/target_core_configfs.c
index c40217f44..c57948538 100644
--- a/drivers/target/target_core_configfs.c
+++ b/drivers/target/target_core_configfs.c
@@ -465,6 +465,23 @@ static void target_set_default_ops(struct target_core_fabric_ops *tfo)
 		tfo->get_cmd_state = target_default_get_cmd_state;
 }
 
+/*
+ * called by:
+ *   - drivers/infiniband/ulp/srpt/ib_srpt.c|3961| <<srpt_init_module>> ret = target_register_template(&srpt_template);
+ *   - drivers/scsi/elx/efct/efct_lio.c|1662| <<efct_scsi_tgt_driver_init>> rc = target_register_template(&efct_lio_ops);
+ *   - drivers/scsi/elx/efct/efct_lio.c|1667| <<efct_scsi_tgt_driver_init>> rc = target_register_template(&efct_lio_npiv_ops);
+ *   - drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c|4036| <<ibmvscsis_init>> rc = target_register_template(&ibmvscsis_ops);
+ *   - drivers/scsi/qla2xxx/tcm_qla2xxx.c|1878| <<tcm_qla2xxx_register_configfs>> ret = target_register_template(&tcm_qla2xxx_ops);
+ *   - drivers/scsi/qla2xxx/tcm_qla2xxx.c|1882| <<tcm_qla2xxx_register_configfs>> ret = target_register_template(&tcm_qla2xxx_npiv_ops);
+ *   - drivers/target/iscsi/iscsi_target.c|695| <<iscsi_target_init_module>> ret = target_register_template(&iscsi_ops);
+ *   - drivers/target/loopback/tcm_loop.c|1126| <<tcm_loop_fabric_init>> ret = target_register_template(&loop_ops);
+ *   - drivers/target/sbp/sbp_target.c|2288| <<sbp_init>> return target_register_template(&sbp_ops);
+ *   - drivers/target/tcm_fc/tfc_conf.c|448| <<ft_init>> ret = target_register_template(&ft_fabric_ops);
+ *   - drivers/target/tcm_remote/tcm_remote.c|256| <<tcm_remote_fabric_init>> return target_register_template(&remote_ops);
+ *   - drivers/usb/gadget/function/f_tcm.c|2289| <<tcm_init>> ret = target_register_template(&usbg_ops);
+ *   - drivers/vhost/scsi.c|2792| <<vhost_scsi_init>> ret = target_register_template(&vhost_scsi_ops);
+ *   - drivers/xen/xen-scsiback.c|1866| <<scsiback_init>> ret = target_register_template(&scsiback_ops);
+ */
 int target_register_template(const struct target_core_fabric_ops *fo)
 {
 	struct target_core_fabric_ops *tfo;
diff --git a/drivers/target/target_core_file.c b/drivers/target/target_core_file.c
index 2d78ef746..297a8bb2a 100644
--- a/drivers/target/target_core_file.c
+++ b/drivers/target/target_core_file.c
@@ -167,6 +167,21 @@ static int fd_configure_device(struct se_device *dev)
 			" block_device blocks: %llu logical_block_size: %d\n",
 			dev_size, div_u64(dev_size, fd_dev->fd_block_size),
 			fd_dev->fd_block_size);
+		/*
+		 * 在以下使用se_dev_attrib->max_write_same_len:
+		 *   - drivers/target/target_core_configfs.c|595| <<global>> DEF_CONFIGFS_ATTRIB_SHOW(max_write_same_len);
+		 *   - drivers/target/target_core_configfs.c|618| <<global>> DEF_CONFIGFS_ATTRIB_STORE_U32(max_write_same_len);
+		 *   - drivers/target/target_core_configfs.c|1318| <<global>> CONFIGFS_ATTR(, max_write_same_len);
+		 *   - drivers/target/target_core_device.c|775| <<target_alloc_device>> dev->dev_attrib.max_write_same_len = DA_MAX_WRITE_SAME_LEN;
+		 *   - drivers/target/target_core_file.c|174| <<fd_configure_device>> dev->dev_attrib.max_write_same_len = 0xFFFF;
+		 *   - drivers/target/target_core_file.c|192| <<fd_configure_device>> dev->dev_attrib.max_write_same_len = 0x1000;
+		 *   - drivers/target/target_core_iblock.c|143| <<iblock_configure_device>> dev->dev_attrib.max_write_same_len = max_write_zeroes_sectors;
+		 *   - drivers/target/target_core_iblock.c|145| <<iblock_configure_device>> dev->dev_attrib.max_write_same_len = 0xFFFF;
+		 *   - drivers/target/target_core_sbc.c|294| <<sbc_setup_write_same>> if (sectors > cmd->se_dev->dev_attrib.max_write_same_len) {
+		 *   - drivers/target/target_core_sbc.c|296| <<sbc_setup_write_same>> pr_warn("WRITE_SAME sectors: %u exceeds max_write_same_len: %u\n",
+		 *                    sectors, cmd->se_dev->dev_attrib.max_write_same_len);
+		 *   - drivers/target/target_core_spc.c|599| <<spc_emulate_evpd_b0>> put_unaligned_be64(dev->dev_attrib.max_write_same_len, &buf[36]);
+		 */
 		/*
 		 * Enable write same emulation for IBLOCK and use 0xFFFF as
 		 * the smaller WRITE_SAME(10) only has a two-byte block count.
@@ -248,6 +263,10 @@ struct target_core_file_cmd {
 	struct bio_vec	bvecs[];
 };
 
+/*
+ * called by:
+ *   - drivers/target/target_core_file.c|686| <<fd_execute_rw>> return fd_execute_rw_aio(cmd, sgl, sgl_nents, data_direction);
+ */
 static void cmd_rw_aio_complete(struct kiocb *iocb, long ret)
 {
 	struct target_core_file_cmd *cmd;
@@ -309,6 +328,13 @@ fd_execute_rw_aio(struct se_cmd *cmd, struct scatterlist *sgl, u32 sgl_nents,
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/target/target_core_file.c|599| <<fd_execute_rw_buffered>> ret = fd_do_rw(cmd, pfile, dev->prot_length,
+ *   - drivers/target/target_core_file.c|606| <<fd_execute_rw_buffered>> ret = fd_do_rw(cmd, file, dev->dev_attrib.block_size,
+ *   - drivers/target/target_core_file.c|631| <<fd_execute_rw_buffered>> ret = fd_do_rw(cmd, file, dev->dev_attrib.block_size,
+ *   - drivers/target/target_core_file.c|652| <<fd_execute_rw_buffered>> ret = fd_do_rw(cmd, pfile, dev->prot_length,
+ */
 static int fd_do_rw(struct se_cmd *cmd, struct file *fd,
 		    u32 block_size, struct scatterlist *sgl,
 		    u32 sgl_nents, u32 data_length, int is_write)
@@ -934,6 +960,14 @@ static const struct target_backend_ops fileio_ops = {
 
 static int __init fileio_module_init(void)
 {
+	/*
+	 * called by:
+	 *   - drivers/target/target_core_file.c|937| <<fileio_module_init>> return transport_backend_register(&fileio_ops);
+	 *   - drivers/target/target_core_iblock.c|1189| <<iblock_module_init>> return transport_backend_register(&iblock_ops);
+	 *   - drivers/target/target_core_pscsi.c|1059| <<pscsi_module_init>> return transport_backend_register(&pscsi_ops);
+	 *   - drivers/target/target_core_rd.c|678| <<rd_module_init>> return transport_backend_register(&rd_mcp_ops);
+	 *   - drivers/target/target_core_user.c|3359| <<tcmu_module_init>> ret = transport_backend_register(&tcmu_ops);
+	 */
 	return transport_backend_register(&fileio_ops);
 }
 
diff --git a/drivers/target/target_core_hba.c b/drivers/target/target_core_hba.c
index d508b343b..20f9cb8bb 100644
--- a/drivers/target/target_core_hba.c
+++ b/drivers/target/target_core_hba.c
@@ -35,6 +35,14 @@ static DEFINE_SPINLOCK(hba_lock);
 static LIST_HEAD(hba_list);
 
 
+/*
+ * called by:
+ *   - drivers/target/target_core_file.c|937| <<fileio_module_init>> return transport_backend_register(&fileio_ops);
+ *   - drivers/target/target_core_iblock.c|1189| <<iblock_module_init>> return transport_backend_register(&iblock_ops);
+ *   - drivers/target/target_core_pscsi.c|1059| <<pscsi_module_init>> return transport_backend_register(&pscsi_ops);
+ *   - drivers/target/target_core_rd.c|678| <<rd_module_init>> return transport_backend_register(&rd_mcp_ops);
+ *   - drivers/target/target_core_user.c|3359| <<tcmu_module_init>> ret = transport_backend_register(&tcmu_ops);
+ */
 int transport_backend_register(const struct target_backend_ops *ops)
 {
 	struct target_backend *tb, *old;
diff --git a/drivers/target/target_core_iblock.c b/drivers/target/target_core_iblock.c
index c8dc92a7d..b141f6e33 100644
--- a/drivers/target/target_core_iblock.c
+++ b/drivers/target/target_core_iblock.c
@@ -381,6 +381,12 @@ static struct bio *iblock_get_bio(struct se_cmd *cmd, sector_t lba, u32 sg_num,
 	return bio;
 }
 
+/*
+ * called by:
+ *   - drivers/target/target_core_iblock.c|562| <<iblock_execute_write_same>> iblock_submit_bios(&list);
+ *   - drivers/target/target_core_iblock.c|810| <<iblock_execute_rw>> iblock_submit_bios(&list);
+ *   - drivers/target/target_core_iblock.c|834| <<iblock_execute_rw>> iblock_submit_bios(&list);
+ */
 static void iblock_submit_bios(struct bio_list *list)
 {
 	struct blk_plug plug;
@@ -1186,6 +1192,14 @@ static const struct target_backend_ops iblock_ops = {
 
 static int __init iblock_module_init(void)
 {
+	/*
+	 * called by:
+	 *   - drivers/target/target_core_file.c|937| <<fileio_module_init>> return transport_backend_register(&fileio_ops);
+	 *   - drivers/target/target_core_iblock.c|1189| <<iblock_module_init>> return transport_backend_register(&iblock_ops);
+	 *   - drivers/target/target_core_pscsi.c|1059| <<pscsi_module_init>> return transport_backend_register(&pscsi_ops);
+	 *   - drivers/target/target_core_rd.c|678| <<rd_module_init>> return transport_backend_register(&rd_mcp_ops);
+	 *   - drivers/target/target_core_user.c|3359| <<tcmu_module_init>> ret = transport_backend_register(&tcmu_ops);
+	 */
 	return transport_backend_register(&iblock_ops);
 }
 
diff --git a/drivers/target/target_core_sbc.c b/drivers/target/target_core_sbc.c
index fe8beb7db..e99f4d929 100644
--- a/drivers/target/target_core_sbc.c
+++ b/drivers/target/target_core_sbc.c
@@ -270,6 +270,12 @@ static inline unsigned long long transport_lba_64(unsigned char *cdb)
 	return get_unaligned_be64(&cdb[2]);
 }
 
+/*
+ * called by:
+ *   - drivers/target/target_core_sbc.c|892| <<sbc_parse_cdb(VARIABLE_LENGTH_CMD)>> ret = sbc_setup_write_same(cmd, cdb[10], ops);
+ *   - drivers/target/target_core_sbc.c|991| <<sbc_parse_cdb(WRITE_SAME_16)>> ret = sbc_setup_write_same(cmd, cdb[1], ops);
+ *   - drivers/target/target_core_sbc.c|1009| <<sbc_parse_cdb(WRITE_SAME)>> ret = sbc_setup_write_same(cmd, cdb[1], ops);
+ */
 static sense_reason_t
 sbc_setup_write_same(struct se_cmd *cmd, unsigned char flags,
 		     struct exec_cmd_ops *ops)
@@ -285,6 +291,21 @@ sbc_setup_write_same(struct se_cmd *cmd, unsigned char flags,
 			" Emulation\n");
 		return TCM_UNSUPPORTED_SCSI_OPCODE;
 	}
+	/*
+	 * 在以下使用se_dev_attrib->max_write_same_len:
+	 *   - drivers/target/target_core_configfs.c|595| <<global>> DEF_CONFIGFS_ATTRIB_SHOW(max_write_same_len);
+	 *   - drivers/target/target_core_configfs.c|618| <<global>> DEF_CONFIGFS_ATTRIB_STORE_U32(max_write_same_len);
+	 *   - drivers/target/target_core_configfs.c|1318| <<global>> CONFIGFS_ATTR(, max_write_same_len);
+	 *   - drivers/target/target_core_device.c|775| <<target_alloc_device>> dev->dev_attrib.max_write_same_len = DA_MAX_WRITE_SAME_LEN;
+	 *   - drivers/target/target_core_file.c|174| <<fd_configure_device>> dev->dev_attrib.max_write_same_len = 0xFFFF;
+	 *   - drivers/target/target_core_file.c|192| <<fd_configure_device>> dev->dev_attrib.max_write_same_len = 0x1000;
+	 *   - drivers/target/target_core_iblock.c|143| <<iblock_configure_device>> dev->dev_attrib.max_write_same_len = max_write_zeroes_sectors;
+	 *   - drivers/target/target_core_iblock.c|145| <<iblock_configure_device>> dev->dev_attrib.max_write_same_len = 0xFFFF;
+	 *   - drivers/target/target_core_sbc.c|294| <<sbc_setup_write_same>> if (sectors > cmd->se_dev->dev_attrib.max_write_same_len) {
+	 *   - drivers/target/target_core_sbc.c|296| <<sbc_setup_write_same>> pr_warn("WRITE_SAME sectors: %u exceeds max_write_same_len: %u\n",
+	 *                    sectors, cmd->se_dev->dev_attrib.max_write_same_len);
+	 *   - drivers/target/target_core_spc.c|599| <<spc_emulate_evpd_b0>> put_unaligned_be64(dev->dev_attrib.max_write_same_len, &buf[36]);
+	 */
 	if (sectors > cmd->se_dev->dev_attrib.max_write_same_len) {
 		pr_warn("WRITE_SAME sectors: %u exceeds max_write_same_len: %u\n",
 			sectors, cmd->se_dev->dev_attrib.max_write_same_len);
@@ -889,6 +910,12 @@ sbc_parse_cdb(struct se_cmd *cmd, struct exec_cmd_ops *ops)
 			size = sbc_get_size(cmd, 1);
 			cmd->t_task_lba = get_unaligned_be64(&cdb[12]);
 
+			/*
+			 * called by:
+			 *   - drivers/target/target_core_sbc.c|892| <<sbc_parse_cdb(VARIABLE_LENGTH_CMD)>> ret = sbc_setup_write_same(cmd, cdb[10], ops);
+			 *   - drivers/target/target_core_sbc.c|991| <<sbc_parse_cdb(WRITE_SAME_16)>> ret = sbc_setup_write_same(cmd, cdb[1], ops);
+			 *   - drivers/target/target_core_sbc.c|1009| <<sbc_parse_cdb(WRITE_SAME)>> ret = sbc_setup_write_same(cmd, cdb[1], ops);
+			 */
 			ret = sbc_setup_write_same(cmd, cdb[10], ops);
 			if (ret)
 				return ret;
@@ -988,6 +1015,12 @@ sbc_parse_cdb(struct se_cmd *cmd, struct exec_cmd_ops *ops)
 		size = sbc_get_size(cmd, 1);
 		cmd->t_task_lba = get_unaligned_be64(&cdb[2]);
 
+		/*
+		 * called by:
+		 *   - drivers/target/target_core_sbc.c|892| <<sbc_parse_cdb(VARIABLE_LENGTH_CMD)>> ret = sbc_setup_write_same(cmd, cdb[10], ops);
+		 *   - drivers/target/target_core_sbc.c|991| <<sbc_parse_cdb(WRITE_SAME_16)>> ret = sbc_setup_write_same(cmd, cdb[1], ops);
+		 *   - drivers/target/target_core_sbc.c|1009| <<sbc_parse_cdb(WRITE_SAME)>> ret = sbc_setup_write_same(cmd, cdb[1], ops);
+		 */
 		ret = sbc_setup_write_same(cmd, cdb[1], ops);
 		if (ret)
 			return ret;
@@ -1006,6 +1039,12 @@ sbc_parse_cdb(struct se_cmd *cmd, struct exec_cmd_ops *ops)
 		 * Follow sbcr26 with WRITE_SAME (10) and check for the existence
 		 * of byte 1 bit 3 UNMAP instead of original reserved field
 		 */
+		/*
+		 * called by:
+		 *   - drivers/target/target_core_sbc.c|892| <<sbc_parse_cdb(VARIABLE_LENGTH_CMD)>> ret = sbc_setup_write_same(cmd, cdb[10], ops);
+		 *   - drivers/target/target_core_sbc.c|991| <<sbc_parse_cdb(WRITE_SAME_16)>> ret = sbc_setup_write_same(cmd, cdb[1], ops);
+		 *   - drivers/target/target_core_sbc.c|1009| <<sbc_parse_cdb(WRITE_SAME)>> ret = sbc_setup_write_same(cmd, cdb[1], ops);
+		 */
 		ret = sbc_setup_write_same(cmd, cdb[1], ops);
 		if (ret)
 			return ret;
diff --git a/drivers/target/target_core_spc.c b/drivers/target/target_core_spc.c
index ea14a3835..745280030 100644
--- a/drivers/target/target_core_spc.c
+++ b/drivers/target/target_core_spc.c
@@ -1015,6 +1015,11 @@ static int spc_modesense_long_blockdesc(unsigned char *buf, u64 blocks, u32 bloc
 	return 17;
 }
 
+/*
+ * called by:
+ *   - drivers/target/target_core_spc.c|2298| <<spc_parse_cdb>> cmd->execute_cmd = spc_emulate_modesense;
+ *   - drivers/target/target_core_spc.c|2302| <<spc_parse_cdb>> cmd->execute_cmd = spc_emulate_modesense;
+ */
 static sense_reason_t spc_emulate_modesense(struct se_cmd *cmd)
 {
 	struct se_device *dev = cmd->se_dev;
diff --git a/drivers/target/target_core_transport.c b/drivers/target/target_core_transport.c
index 05d29201b..307adca53 100644
--- a/drivers/target/target_core_transport.c
+++ b/drivers/target/target_core_transport.c
@@ -945,6 +945,52 @@ void target_complete_cmd_with_sense(struct se_cmd *cmd, u8 scsi_status,
 }
 EXPORT_SYMBOL(target_complete_cmd_with_sense);
 
+/*
+ * called by:
+ *   - drivers/target/iscsi/iscsi_target.c|4239| <<iscsit_release_commands_from_conn>> target_complete_cmd(&cmd->se_cmd, SAM_STAT_TASK_ABORTED);
+ *   - drivers/target/target_core_alua.c|126| <<target_emulate_report_referrals>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_alua.c|430| <<target_emulate_set_target_port_groups>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_file.c|258| <<cmd_rw_aio_complete>> target_complete_cmd(cmd->cmd, SAM_STAT_CHECK_CONDITION);
+ *   - drivers/target/target_core_file.c|260| <<cmd_rw_aio_complete>> target_complete_cmd(cmd->cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_file.c|396| <<fd_execute_sync_cache>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_file.c|420| <<fd_execute_sync_cache>> target_complete_cmd(cmd, SAM_STAT_CHECK_CONDITION);
+ *   - drivers/target/target_core_file.c|422| <<fd_execute_sync_cache>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_file.c|478| <<fd_execute_write_same>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_file.c|663| <<fd_execute_rw_buffered>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_iblock.c|336| <<iblock_complete_cmd>> target_complete_cmd(cmd, status);
+ *   - drivers/target/target_core_iblock.c|407| <<iblock_end_io_flush>> target_complete_cmd(cmd, SAM_STAT_CHECK_CONDITION);
+ *   - drivers/target/target_core_iblock.c|409| <<iblock_end_io_flush>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_iblock.c|431| <<iblock_execute_sync_cache>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_iblock.c|490| <<iblock_execute_zero_out>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_pr.c|237| <<target_scsi2_reservation_release>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_pr.c|300| <<target_scsi2_reservation_reserve>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_pr.c|3725| <<target_scsi3_emulate_pr_out>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_pr.c|4161| <<target_scsi3_emulate_pr_in>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_pscsi.c|1028| <<pscsi_req_done>> target_complete_cmd(cmd, SAM_STAT_CHECK_CONDITION);
+ *   - drivers/target/target_core_rd.c|433| <<rd_execute_rw>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_rd.c|528| <<rd_execute_rw>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_sbc.c|165| <<sbc_emulate_startstop>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_sbc.c|205| <<sbc_execute_write_same_unmap>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_sbc.c|212| <<sbc_emulate_noop>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_sbc.c|1118| <<sbc_execute_unmap>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_sbc.c|1181| <<sbc_execute_unmap>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_spc.c|1162| <<spc_emulate_modeselect>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_spc.c|1205| <<spc_emulate_modeselect>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_spc.c|1238| <<spc_emulate_request_sense>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_spc.c|1313| <<spc_emulate_testunitready>> target_complete_cmd(cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_transport.c|978| <<target_complete_cmd_with_length>> target_complete_cmd(cmd, scsi_status);
+ *   - drivers/target/target_core_user.c|1284| <<tcmu_tmr_notify>> target_complete_cmd(se_cmd, SAM_STAT_TASK_ABORTED);
+ *   - drivers/target/target_core_user.c|1390| <<tcmu_handle_completion>> target_complete_cmd(cmd->se_cmd, entry->rsp.scsi_status);
+ *   - drivers/target/target_core_user.c|1534| <<tcmu_check_expired_ring_cmd>> target_complete_cmd(se_cmd, SAM_STAT_CHECK_CONDITION);
+ *   - drivers/target/target_core_user.c|1552| <<tcmu_check_expired_queue_cmd>> target_complete_cmd(se_cmd, SAM_STAT_TASK_SET_FULL);
+ *   - drivers/target/target_core_user.c|1779| <<run_qfull_queue>> target_complete_cmd(tcmu_cmd->se_cmd, SAM_STAT_BUSY);
+ *   - drivers/target/target_core_user.c|1793| <<run_qfull_queue>> target_complete_cmd(tcmu_cmd->se_cmd,
+ *   - drivers/target/target_core_user.c|2389| <<tcmu_reset_ring>> target_complete_cmd(cmd->se_cmd, SAM_STAT_BUSY);
+ *   - drivers/target/target_core_user.c|2392| <<tcmu_reset_ring>> target_complete_cmd(cmd->se_cmd,
+ *   - drivers/target/target_core_xcopy.c|763| <<target_xcopy_do_work>> target_complete_cmd(ec_cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_xcopy.c|892| <<target_do_xcopy>> target_complete_cmd(se_cmd, SAM_STAT_GOOD);
+ *   - drivers/target/target_core_xcopy.c|1002| <<target_rcr_operating_parameters>> target_complete_cmd(se_cmd, SAM_STAT_GOOD);
+ */
 void target_complete_cmd(struct se_cmd *cmd, u8 scsi_status)
 {
 	target_complete_cmd_with_sense(cmd, scsi_status, scsi_status ?
@@ -1976,6 +2022,17 @@ static void target_complete_tmr_failure(struct work_struct *work)
  * Callable from all contexts.
  **/
 
+/*
+ * called by:
+ *   - drivers/infiniband/ulp/srpt/ib_srpt.c|1667| <<srpt_handle_tsk_mgmt>> rc = target_submit_tmr(&send_ioctx->cmd, sess, NULL,
+ *   - drivers/scsi/elx/efct/efct_lio.c|1449| <<efct_scsi_recv_tmf>> rc = target_submit_tmr(&ocp->cmd, se_sess, NULL, lun, ocp, tmr_func,
+ *   - drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c|2799| <<ibmvscsis_parse_task>> rc = target_submit_tmr(&cmd->se_cmd, nexus->se_sess, NULL,
+ *   - drivers/scsi/qla2xxx/tcm_qla2xxx.c|617| <<tcm_qla2xxx_handle_tmr>> return target_submit_tmr(se_cmd, sess->se_sess, NULL, lun, mcmd,
+ *   - drivers/target/loopback/tcm_loop.c|216| <<tcm_loop_issue_tmr>> rc = target_submit_tmr(se_cmd, se_sess, tl_cmd->tl_sense_buf, lun,
+ *   - drivers/target/tcm_fc/tfc_cmd.c|365| <<ft_send_tm>> rc = target_submit_tmr(&cmd->se_cmd, cmd->sess->se_sess,
+ *   - drivers/vhost/scsi.c|1701| <<vhost_scsi_handle_tmf>> if (target_submit_tmr(&tmf->se_cmd, tpg->tpg_nexus->tvn_se_sess, NULL,
+ *   - drivers/xen/xen-scsiback.c|626| <<scsiback_device_action>> rc = target_submit_tmr(&pending_req->se_cmd, nexus->tvn_se_sess,
+ */
 int target_submit_tmr(struct se_cmd *se_cmd, struct se_session *se_sess,
 		unsigned char *sense, u64 unpacked_lun,
 		void *fabric_tmr_ptr, unsigned char tm_type,
diff --git a/drivers/vdpa/ifcvf/ifcvf_main.c b/drivers/vdpa/ifcvf/ifcvf_main.c
index ccf64d7bb..f016468db 100644
--- a/drivers/vdpa/ifcvf/ifcvf_main.c
+++ b/drivers/vdpa/ifcvf/ifcvf_main.c
@@ -518,6 +518,22 @@ static int ifcvf_vdpa_set_vq_address(struct vdpa_device *vdpa_dev, u16 qid,
 	return ifcvf_set_vq_address(vf, qid, desc_area, driver_area, device_area);
 }
 
+/*
+ * 在以下调用vdpa_config_ops->kick_vq:
+ *   - drivers/vhost/vdpa.c|173| <<handle_vq_kick>> ops->kick_vq(v->vdpa, vq - v->vqs);
+ *   - drivers/virtio/virtio_vdpa.c|111| <<virtio_vdpa_notify>> ops->kick_vq(vdpa, vq->index);
+ * 在以下设置vdpa_config_ops->kick_vq:
+ *   - drivers/vdpa/alibaba/eni_vdpa.c|434| <<global>> .kick_vq = eni_vdpa_kick_vq,
+ *   - drivers/vdpa/ifcvf/ifcvf_main.c|650| <<global>> .kick_vq = ifcvf_vdpa_kick_vq,
+ *   - drivers/vdpa/mlx5/net/mlx5_vnet.c|3656| <<global>> .kick_vq = mlx5_vdpa_kick_vq,
+ *   - drivers/vdpa/octeon_ep/octep_vdpa_main.c|344| <<global>> .kick_vq = octep_vdpa_kick_vq,
+ *   - drivers/vdpa/pds/vdpa_dev.c|581| <<global>> .kick_vq = pds_vdpa_kick_vq,
+ *   - drivers/vdpa/solidrun/snet_main.c|529| <<global>> .kick_vq = snet_kick_vq,
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim.c|774| <<global>> .kick_vq = vdpasim_kick_vq,
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim.c|815| <<global>> .kick_vq = vdpasim_kick_vq,
+ *   - drivers/vdpa/vdpa_user/vduse_dev.c|787| <<global>> .kick_vq = vduse_vdpa_kick_vq,
+ *   - drivers/vdpa/virtio_pci/vp_vdpa.c|474| <<global>> .kick_vq = vp_vdpa_kick_vq,
+ */
 static void ifcvf_vdpa_kick_vq(struct vdpa_device *vdpa_dev, u16 qid)
 {
 	struct ifcvf_hw *vf = vdpa_to_vf(vdpa_dev);
diff --git a/drivers/vdpa/mlx5/net/mlx5_vnet.c b/drivers/vdpa/mlx5/net/mlx5_vnet.c
index 5f581e71e..cca3ecfd2 100644
--- a/drivers/vdpa/mlx5/net/mlx5_vnet.c
+++ b/drivers/vdpa/mlx5/net/mlx5_vnet.c
@@ -1455,6 +1455,10 @@ static irqreturn_t mlx5_vdpa_int_handler(int irq, void *priv)
 	return IRQ_HANDLED;
 }
 
+/*
+ * called by:
+ *   - drivers/vdpa/mlx5/net/mlx5_vnet.c|1528| <<setup_vq>> alloc_vector(ndev, mvq);
+ */
 static void alloc_vector(struct mlx5_vdpa_net *ndev,
 			 struct mlx5_vdpa_virtqueue *mvq)
 {
@@ -2425,6 +2429,22 @@ static void mlx5_cvq_kick_handler(struct work_struct *work)
 	up_write(&ndev->reslock);
 }
 
+/*
+ * 在以下调用vdpa_config_ops->kick_vq:
+ *   - drivers/vhost/vdpa.c|173| <<handle_vq_kick>> ops->kick_vq(v->vdpa, vq - v->vqs);
+ *   - drivers/virtio/virtio_vdpa.c|111| <<virtio_vdpa_notify>> ops->kick_vq(vdpa, vq->index);
+ * 在以下设置vdpa_config_ops->kick_vq:
+ *   - drivers/vdpa/alibaba/eni_vdpa.c|434| <<global>> .kick_vq = eni_vdpa_kick_vq,
+ *   - drivers/vdpa/ifcvf/ifcvf_main.c|650| <<global>> .kick_vq = ifcvf_vdpa_kick_vq,
+ *   - drivers/vdpa/mlx5/net/mlx5_vnet.c|3656| <<global>> .kick_vq = mlx5_vdpa_kick_vq,
+ *   - drivers/vdpa/octeon_ep/octep_vdpa_main.c|344| <<global>> .kick_vq = octep_vdpa_kick_vq,
+ *   - drivers/vdpa/pds/vdpa_dev.c|581| <<global>> .kick_vq = pds_vdpa_kick_vq,
+ *   - drivers/vdpa/solidrun/snet_main.c|529| <<global>> .kick_vq = snet_kick_vq,
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim.c|774| <<global>> .kick_vq = vdpasim_kick_vq,
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim.c|815| <<global>> .kick_vq = vdpasim_kick_vq,
+ *   - drivers/vdpa/vdpa_user/vduse_dev.c|787| <<global>> .kick_vq = vduse_vdpa_kick_vq,
+ *   - drivers/vdpa/virtio_pci/vp_vdpa.c|474| <<global>> .kick_vq = vp_vdpa_kick_vq,
+ */
 static void mlx5_vdpa_kick_vq(struct vdpa_device *vdev, u16 idx)
 {
 	struct mlx5_vdpa_dev *mvdev = to_mvdev(vdev);
@@ -2446,6 +2466,13 @@ static void mlx5_vdpa_kick_vq(struct vdpa_device *vdev, u16 idx)
 	if (unlikely(!mvq->ready))
 		return;
 
+	/*
+	 * struct mlx5_vdpa_net *ndev:
+	 * -> struct mlx5_vdpa_dev mvdev;
+	 *    -> struct vdpa_device vdev;
+	 *    -> struct mlx5_vdpa_resources res;
+	 *       -> void __iomem *kick_addr;
+	 */
 	iowrite16(idx, ndev->mvdev.res.kick_addr);
 }
 
diff --git a/drivers/vdpa/vdpa.c b/drivers/vdpa/vdpa.c
index 8a372b51c..205cbb500 100644
--- a/drivers/vdpa/vdpa.c
+++ b/drivers/vdpa/vdpa.c
@@ -16,6 +16,13 @@
 #include <linux/mod_devicetable.h>
 #include <linux/virtio_ids.h>
 
+/*
+ * 在以下使用mdev_head:
+ *   - drivers/vdpa/vdpa.c|19| <<global>> static LIST_HEAD(mdev_head);
+ *   - drivers/vdpa/vdpa.c|344| <<vdpa_mgmtdev_register>> list_add_tail(&mdev->list, &mdev_head);
+ *   - drivers/vdpa/vdpa.c|451| <<vdpa_mgmtdev_get_from_attr>> list_for_each_entry(mdev, &mdev_head, list) {
+ *   - drivers/vdpa/vdpa.c|564| <<vdpa_nl_cmd_mgmtdev_get_dumpit>> list_for_each_entry(mdev, &mdev_head, list) {
+ */
 static LIST_HEAD(mdev_head);
 /* A global mutex that protects vdpa management device and device level operations. */
 static DECLARE_RWSEM(vdpa_dev_lock);
@@ -24,6 +31,11 @@ static DEFINE_IDA(vdpa_index_ida);
 void vdpa_set_status(struct vdpa_device *vdev, u8 status)
 {
 	down_write(&vdev->cf_lock);
+	/*
+	 * struct vdpa_device *vdev:
+	 * -> const struct vdpa_config_ops *config;
+	 *    -> void (*set_status)(struct vdpa_device *vdev, u8 status);
+	 */
 	vdev->config->set_status(vdev, status);
 	up_write(&vdev->cf_lock);
 }
@@ -154,6 +166,11 @@ static void vdpa_release_dev(struct device *d)
  * Return: Returns an error when parent/config/dma_dev is not set or fail to get
  *	   ida.
  */
+/*
+ * called by:
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim.c|218| <<vdpasim_create>> vdpa = __vdpa_alloc_device(NULL, ops,
+ *   - include/linux/vdpa.h|469| <<vdpa_alloc_device>> container_of((__vdpa_alloc_device( \
+ */
 struct vdpa_device *__vdpa_alloc_device(struct device *parent,
 					const struct vdpa_config_ops *config,
 					unsigned int ngroups, unsigned int nas,
@@ -245,6 +262,17 @@ static int __vdpa_register_device(struct vdpa_device *vdev, u32 nvqs)
  *
  * Return: Returns an error when fail to add device to vDPA bus
  */
+/*
+ * called by:
+ *   - drivers/vdpa/ifcvf/ifcvf_main.c|737| <<ifcvf_vdpa_dev_add>> ret = _vdpa_register_device(&adapter->vdpa, vf->nr_vring);
+ *   - drivers/vdpa/mlx5/net/mlx5_vnet.c|3991| <<mlx5_vdpa_dev_add>> err = _vdpa_register_device(&mvdev->vdev, max_vqs + 1);
+ *   - drivers/vdpa/octeon_ep/octep_vdpa_main.c|515| <<octep_vdpa_dev_add>> ret = _vdpa_register_device(&oct_vdpa->vdpa, oct_hw->nr_vring);
+ *   - drivers/vdpa/pds/vdpa_dev.c|749| <<pds_vdpa_dev_add>> err = _vdpa_register_device(&pdsv->vdpa_dev, pdsv->num_vqs);
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim_blk.c|448| <<vdpasim_blk_dev_add>> ret = _vdpa_register_device(&simdev->vdpa, VDPASIM_BLK_VQ_NUM);
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim_net.c|510| <<vdpasim_net_dev_add>> ret = _vdpa_register_device(&simdev->vdpa, VDPASIM_NET_VQ_NUM);
+ *   - drivers/vdpa/vdpa_user/vduse_dev.c|2057| <<vdpa_dev_add>> ret = _vdpa_register_device(&dev->vdev->vdpa, dev->vq_num);
+ *   - drivers/vdpa/virtio_pci/vp_vdpa.c|562| <<vp_vdpa_dev_add>> ret = _vdpa_register_device(&vp_vdpa->vdpa, vp_vdpa->queues);
+ */
 int _vdpa_register_device(struct vdpa_device *vdev, u32 nvqs)
 {
 	if (!vdev->mdev)
@@ -334,6 +362,17 @@ EXPORT_SYMBOL_GPL(vdpa_unregister_driver);
  * Return: Returns 0 on success or failure when required callback ops are not
  *         initialized.
  */
+/*
+ * called by:
+ *   - drivers/vdpa/ifcvf/ifcvf_main.c|838| <<ifcvf_probe>> ret = vdpa_mgmtdev_register(&ifcvf_mgmt_dev->mdev);
+ *   - drivers/vdpa/mlx5/net/mlx5_vnet.c|4108| <<mlx5v_probe>> err = vdpa_mgmtdev_register(&mgtdev->mgtdev);
+ *   - drivers/vdpa/octeon_ep/octep_vdpa_main.c|604| <<octep_vdpa_setup_task>> ret = vdpa_mgmtdev_register(&mgmt_dev->mdev);
+ *   - drivers/vdpa/pds/aux_drv.c|67| <<pds_vdpa_probe>> err = vdpa_mgmtdev_register(&vdpa_aux->vdpa_mdev);
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim_blk.c|493| <<vdpasim_blk_init>> ret = vdpa_mgmtdev_register(&mgmt_dev);
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim_net.c|561| <<vdpasim_net_init>> ret = vdpa_mgmtdev_register(&mgmt_dev);
+ *   - drivers/vdpa/vdpa_user/vduse_dev.c|2117| <<vduse_mgmtdev_init>> ret = vdpa_mgmtdev_register(&vduse_mgmt->mgmt_dev);
+ *   - drivers/vdpa/virtio_pci/vp_vdpa.c|648| <<vp_vdpa_probe>> err = vdpa_mgmtdev_register(mgtdev);
+ */
 int vdpa_mgmtdev_register(struct vdpa_mgmt_dev *mdev)
 {
 	if (!mdev->device || !mdev->ops || !mdev->ops->dev_add || !mdev->ops->dev_del)
@@ -341,6 +380,13 @@ int vdpa_mgmtdev_register(struct vdpa_mgmt_dev *mdev)
 
 	INIT_LIST_HEAD(&mdev->list);
 	down_write(&vdpa_dev_lock);
+	/*
+	 * 在以下使用mdev_head:
+	 *   - drivers/vdpa/vdpa.c|19| <<global>> static LIST_HEAD(mdev_head);
+	 *   - drivers/vdpa/vdpa.c|344| <<vdpa_mgmtdev_register>> list_add_tail(&mdev->list, &mdev_head);
+	 *   - drivers/vdpa/vdpa.c|451| <<vdpa_mgmtdev_get_from_attr>> list_for_each_entry(mdev, &mdev_head, list) {
+	 *   - drivers/vdpa/vdpa.c|564| <<vdpa_nl_cmd_mgmtdev_get_dumpit>> list_for_each_entry(mdev, &mdev_head, list) {
+	 */
 	list_add_tail(&mdev->list, &mdev_head);
 	up_write(&vdpa_dev_lock);
 	return 0;
@@ -448,6 +494,13 @@ static struct vdpa_mgmt_dev *vdpa_mgmtdev_get_from_attr(struct nlattr **attrs)
 	if (attrs[VDPA_ATTR_MGMTDEV_BUS_NAME])
 		busname = nla_data(attrs[VDPA_ATTR_MGMTDEV_BUS_NAME]);
 
+	/*
+	 * 在以下使用mdev_head:
+	 *   - drivers/vdpa/vdpa.c|19| <<global>> static LIST_HEAD(mdev_head);
+	 *   - drivers/vdpa/vdpa.c|344| <<vdpa_mgmtdev_register>> list_add_tail(&mdev->list, &mdev_head);
+	 *   - drivers/vdpa/vdpa.c|451| <<vdpa_mgmtdev_get_from_attr>> list_for_each_entry(mdev, &mdev_head, list) {
+	 *   - drivers/vdpa/vdpa.c|564| <<vdpa_nl_cmd_mgmtdev_get_dumpit>> list_for_each_entry(mdev, &mdev_head, list) {
+	 */
 	list_for_each_entry(mdev, &mdev_head, list) {
 		if (mgmtdev_handle_match(mdev, busname, devname))
 			return mdev;
@@ -561,6 +614,13 @@ vdpa_nl_cmd_mgmtdev_get_dumpit(struct sk_buff *msg, struct netlink_callback *cb)
 	int err;
 
 	down_read(&vdpa_dev_lock);
+	/*
+	 * 在以下使用mdev_head:
+	 *   - drivers/vdpa/vdpa.c|19| <<global>> static LIST_HEAD(mdev_head);
+	 *   - drivers/vdpa/vdpa.c|344| <<vdpa_mgmtdev_register>> list_add_tail(&mdev->list, &mdev_head);
+	 *   - drivers/vdpa/vdpa.c|451| <<vdpa_mgmtdev_get_from_attr>> list_for_each_entry(mdev, &mdev_head, list) {
+	 *   - drivers/vdpa/vdpa.c|564| <<vdpa_nl_cmd_mgmtdev_get_dumpit>> list_for_each_entry(mdev, &mdev_head, list) {
+	 */
 	list_for_each_entry(mdev, &mdev_head, list) {
 		if (idx < start) {
 			idx++;
diff --git a/drivers/vdpa/vdpa_sim/vdpa_sim.c b/drivers/vdpa/vdpa_sim/vdpa_sim.c
index 8ffea8430..cdfa7d29f 100644
--- a/drivers/vdpa/vdpa_sim/vdpa_sim.c
+++ b/drivers/vdpa/vdpa_sim/vdpa_sim.c
@@ -79,6 +79,10 @@ static struct vdpasim *vdpa_to_sim(struct vdpa_device *vdpa)
 	return container_of(vdpa, struct vdpasim, vdpa);
 }
 
+/*
+ * 在以下使用vdpasim_vq_notify():
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim.c|124| <<vdpasim_queue_ready>> vq->vring.notify = vdpasim_vq_notify;
+ */
 static void vdpasim_vq_notify(struct vringh *vring)
 {
 	struct vdpasim_virtqueue *vq =
@@ -283,6 +287,12 @@ struct vdpasim *vdpasim_create(struct vdpasim_dev_attr *dev_attr,
 }
 EXPORT_SYMBOL_GPL(vdpasim_create);
 
+/*
+ * called by:
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim.c|357| <<vdpasim_kick_vq>> vdpasim_schedule_work(vdpasim);
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim_blk.c|363| <<vdpasim_blk_work>> vdpasim_schedule_work(vdpasim);
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim_net.c|262| <<vdpasim_net_work>> vdpasim_schedule_work(vdpasim);
+ */
 void vdpasim_schedule_work(struct vdpasim *vdpasim)
 {
 	kthread_queue_work(vdpasim->worker, &vdpasim->work);
@@ -322,6 +332,22 @@ static u16 vdpasim_get_vq_size(struct vdpa_device *vdpa, u16 idx)
 		return VDPASIM_QUEUE_MAX;
 }
 
+/*
+ * 在以下调用vdpa_config_ops->kick_vq:
+ *   - drivers/vhost/vdpa.c|173| <<handle_vq_kick>> ops->kick_vq(v->vdpa, vq - v->vqs);
+ *   - drivers/virtio/virtio_vdpa.c|111| <<virtio_vdpa_notify>> ops->kick_vq(vdpa, vq->index);
+ * 在以下设置vdpa_config_ops->kick_vq:
+ *   - drivers/vdpa/alibaba/eni_vdpa.c|434| <<global>> .kick_vq = eni_vdpa_kick_vq,
+ *   - drivers/vdpa/ifcvf/ifcvf_main.c|650| <<global>> .kick_vq = ifcvf_vdpa_kick_vq,
+ *   - drivers/vdpa/mlx5/net/mlx5_vnet.c|3656| <<global>> .kick_vq = mlx5_vdpa_kick_vq,
+ *   - drivers/vdpa/octeon_ep/octep_vdpa_main.c|344| <<global>> .kick_vq = octep_vdpa_kick_vq,
+ *   - drivers/vdpa/pds/vdpa_dev.c|581| <<global>> .kick_vq = pds_vdpa_kick_vq,
+ *   - drivers/vdpa/solidrun/snet_main.c|529| <<global>> .kick_vq = snet_kick_vq,
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim.c|774| <<global>> .kick_vq = vdpasim_kick_vq,
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim.c|815| <<global>> .kick_vq = vdpasim_kick_vq,
+ *   - drivers/vdpa/vdpa_user/vduse_dev.c|787| <<global>> .kick_vq = vduse_vdpa_kick_vq,
+ *   - drivers/vdpa/virtio_pci/vp_vdpa.c|474| <<global>> .kick_vq = vp_vdpa_kick_vq,
+ */
 static void vdpasim_kick_vq(struct vdpa_device *vdpa, u16 idx)
 {
 	struct vdpasim *vdpasim = vdpa_to_sim(vdpa);
diff --git a/drivers/vdpa/vdpa_sim/vdpa_sim_blk.c b/drivers/vdpa/vdpa_sim/vdpa_sim_blk.c
index b137f3679..522cfde5f 100644
--- a/drivers/vdpa/vdpa_sim/vdpa_sim_blk.c
+++ b/drivers/vdpa/vdpa_sim/vdpa_sim_blk.c
@@ -490,6 +490,17 @@ static int __init vdpasim_blk_init(void)
 		return ret;
 	}
 
+	/*
+	 * called by:
+	 *   - drivers/vdpa/ifcvf/ifcvf_main.c|838| <<ifcvf_probe>> ret = vdpa_mgmtdev_register(&ifcvf_mgmt_dev->mdev);
+	 *   - drivers/vdpa/mlx5/net/mlx5_vnet.c|4108| <<mlx5v_probe>> err = vdpa_mgmtdev_register(&mgtdev->mgtdev);
+	 *   - drivers/vdpa/octeon_ep/octep_vdpa_main.c|604| <<octep_vdpa_setup_task>> ret = vdpa_mgmtdev_register(&mgmt_dev->mdev);
+	 *   - drivers/vdpa/pds/aux_drv.c|67| <<pds_vdpa_probe>> err = vdpa_mgmtdev_register(&vdpa_aux->vdpa_mdev);
+	 *   - drivers/vdpa/vdpa_sim/vdpa_sim_blk.c|493| <<vdpasim_blk_init>> ret = vdpa_mgmtdev_register(&mgmt_dev);
+	 *   - drivers/vdpa/vdpa_sim/vdpa_sim_net.c|561| <<vdpasim_net_init>> ret = vdpa_mgmtdev_register(&mgmt_dev);
+	 *   - drivers/vdpa/vdpa_user/vduse_dev.c|2117| <<vduse_mgmtdev_init>> ret = vdpa_mgmtdev_register(&vduse_mgmt->mgmt_dev);
+	 *   - drivers/vdpa/virtio_pci/vp_vdpa.c|648| <<vp_vdpa_probe>> err = vdpa_mgmtdev_register(mgtdev);
+	 */
 	ret = vdpa_mgmtdev_register(&mgmt_dev);
 	if (ret)
 		goto parent_err;
diff --git a/drivers/vdpa/vdpa_sim/vdpa_sim_net.c b/drivers/vdpa/vdpa_sim/vdpa_sim_net.c
index 6caf09a19..b00f10d0e 100644
--- a/drivers/vdpa/vdpa_sim/vdpa_sim_net.c
+++ b/drivers/vdpa/vdpa_sim/vdpa_sim_net.c
@@ -66,6 +66,13 @@ static struct vdpasim_net *sim_to_net(struct vdpasim *vdpasim)
 	return container_of(vdpasim, struct vdpasim_net, vdpasim);
 }
 
+/*
+ * called by:
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim_net.c|236| <<vdpasim_net_work>> vdpasim_net_complete(txq, 0);
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim_net.c|244| <<vdpasim_net_work>> vdpasim_net_complete(txq, 0);
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim_net.c|258| <<vdpasim_net_work>> vdpasim_net_complete(txq, 0);
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim_net.c|259| <<vdpasim_net_work>> vdpasim_net_complete(rxq, write);
+ */
 static void vdpasim_net_complete(struct vdpasim_virtqueue *vq, size_t len)
 {
 	/* Make sure data is wrote before advancing index */
@@ -237,6 +244,19 @@ static void vdpasim_net_work(struct vdpasim *vdpasim)
 			continue;
 		}
 
+		/*
+		 * called by:
+		 *   - drivers/vdpa/mlx5/net/mlx5_vnet.c|2388| <<mlx5_cvq_kick_handler>> err = vringh_getdesc_iotlb(&cvq->vring,
+		 *             &cvq->riov, &cvq->wiov, &cvq->head,
+		 *   - drivers/vdpa/vdpa_sim/vdpa_sim_blk.c|123| <<vdpasim_blk_handle_req>> ret = vringh_getdesc_iotlb(&vq->vring,
+		 *             &vq->out_iov, &vq->in_iov,
+		 *   - drivers/vdpa/vdpa_sim/vdpa_sim_net.c|144| <<vdpasim_handle_cvq>> err = vringh_getdesc_iotlb(&cvq->vring,
+		 *             &cvq->in_iov,
+		 *   - drivers/vdpa/vdpa_sim/vdpa_sim_net.c|220| <<vdpasim_net_work>> err = vringh_getdesc_iotlb(&txq->vring,
+		 *             &txq->out_iov, NULL,
+		 *   - drivers/vdpa/vdpa_sim/vdpa_sim_net.c|240| <<vdpasim_net_work>> err = vringh_getdesc_iotlb(&rxq->vring,
+		 *             NULL, &rxq->in_iov,
+		 */
 		err = vringh_getdesc_iotlb(&rxq->vring, NULL, &rxq->in_iov,
 					   &rxq->head, GFP_ATOMIC);
 		if (err <= 0) {
diff --git a/drivers/vdpa/vdpa_user/vduse_dev.c b/drivers/vdpa/vdpa_user/vduse_dev.c
index 7ae99691e..e77fee971 100644
--- a/drivers/vdpa/vdpa_user/vduse_dev.c
+++ b/drivers/vdpa/vdpa_user/vduse_dev.c
@@ -511,6 +511,22 @@ static void vduse_vq_kick_work(struct work_struct *work)
 	vduse_vq_kick(vq);
 }
 
+/*
+ * 在以下调用vdpa_config_ops->kick_vq:
+ *   - drivers/vhost/vdpa.c|173| <<handle_vq_kick>> ops->kick_vq(v->vdpa, vq - v->vqs);
+ *   - drivers/virtio/virtio_vdpa.c|111| <<virtio_vdpa_notify>> ops->kick_vq(vdpa, vq->index);
+ * 在以下设置vdpa_config_ops->kick_vq:
+ *   - drivers/vdpa/alibaba/eni_vdpa.c|434| <<global>> .kick_vq = eni_vdpa_kick_vq,
+ *   - drivers/vdpa/ifcvf/ifcvf_main.c|650| <<global>> .kick_vq = ifcvf_vdpa_kick_vq,
+ *   - drivers/vdpa/mlx5/net/mlx5_vnet.c|3656| <<global>> .kick_vq = mlx5_vdpa_kick_vq,
+ *   - drivers/vdpa/octeon_ep/octep_vdpa_main.c|344| <<global>> .kick_vq = octep_vdpa_kick_vq,
+ *   - drivers/vdpa/pds/vdpa_dev.c|581| <<global>> .kick_vq = pds_vdpa_kick_vq,
+ *   - drivers/vdpa/solidrun/snet_main.c|529| <<global>> .kick_vq = snet_kick_vq,
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim.c|774| <<global>> .kick_vq = vdpasim_kick_vq,
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim.c|815| <<global>> .kick_vq = vdpasim_kick_vq,
+ *   - drivers/vdpa/vdpa_user/vduse_dev.c|787| <<global>> .kick_vq = vduse_vdpa_kick_vq,
+ *   - drivers/vdpa/virtio_pci/vp_vdpa.c|474| <<global>> .kick_vq = vp_vdpa_kick_vq,
+ */
 static void vduse_vdpa_kick_vq(struct vdpa_device *vdpa, u16 idx)
 {
 	struct vduse_dev *dev = vdpa_to_vduse(vdpa);
diff --git a/drivers/vdpa/virtio_pci/vp_vdpa.c b/drivers/vdpa/virtio_pci/vp_vdpa.c
index 163807642..3901e5ad0 100644
--- a/drivers/vdpa/virtio_pci/vp_vdpa.c
+++ b/drivers/vdpa/virtio_pci/vp_vdpa.c
@@ -360,6 +360,22 @@ static int vp_vdpa_set_vq_address(struct vdpa_device *vdpa, u16 qid,
 	return 0;
 }
 
+/*
+ * 在以下调用vdpa_config_ops->kick_vq:
+ *   - drivers/vhost/vdpa.c|173| <<handle_vq_kick>> ops->kick_vq(v->vdpa, vq - v->vqs);
+ *   - drivers/virtio/virtio_vdpa.c|111| <<virtio_vdpa_notify>> ops->kick_vq(vdpa, vq->index);
+ * 在以下设置vdpa_config_ops->kick_vq:
+ *   - drivers/vdpa/alibaba/eni_vdpa.c|434| <<global>> .kick_vq = eni_vdpa_kick_vq,
+ *   - drivers/vdpa/ifcvf/ifcvf_main.c|650| <<global>> .kick_vq = ifcvf_vdpa_kick_vq,
+ *   - drivers/vdpa/mlx5/net/mlx5_vnet.c|3656| <<global>> .kick_vq = mlx5_vdpa_kick_vq,
+ *   - drivers/vdpa/octeon_ep/octep_vdpa_main.c|344| <<global>> .kick_vq = octep_vdpa_kick_vq,
+ *   - drivers/vdpa/pds/vdpa_dev.c|581| <<global>> .kick_vq = pds_vdpa_kick_vq,
+ *   - drivers/vdpa/solidrun/snet_main.c|529| <<global>> .kick_vq = snet_kick_vq,
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim.c|774| <<global>> .kick_vq = vdpasim_kick_vq,
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim.c|815| <<global>> .kick_vq = vdpasim_kick_vq,
+ *   - drivers/vdpa/vdpa_user/vduse_dev.c|787| <<global>> .kick_vq = vduse_vdpa_kick_vq,
+ *   - drivers/vdpa/virtio_pci/vp_vdpa.c|474| <<global>> .kick_vq = vp_vdpa_kick_vq,
+ */
 static void vp_vdpa_kick_vq(struct vdpa_device *vdpa, u16 qid)
 {
 	struct vp_vdpa *vp_vdpa = vdpa_to_vp(vdpa);
diff --git a/drivers/vhost/net.c b/drivers/vhost/net.c
index 9ad37c012..db1a429bf 100644
--- a/drivers/vhost/net.c
+++ b/drivers/vhost/net.c
@@ -123,6 +123,18 @@ struct vhost_net_virtqueue {
 	/* Reference counting for outstanding ubufs.
 	 * Protected by vq mutex. Writers must also take device mutex. */
 	struct vhost_net_ubuf_ref *ubufs;
+	/*
+	 * 在以下使用vhost_net_virtqueue->rx_ring:
+	 *   - drivers/vhost/net.c|180| <<vhost_net_buf_produce>> rxq->tail = ptr_ring_consume_batched(nvq->rx_ring, rxq->queue,
+	 *   - drivers/vhost/net.c|189| <<vhost_net_buf_unproduce>> if (nvq->rx_ring && !vhost_net_buf_is_empty(rxq)) {
+	 *   - drivers/vhost/net.c|190| <<vhost_net_buf_unproduce>> ptr_ring_unconsume(nvq->rx_ring, rxq->queue + rxq->head,
+	 *   - drivers/vhost/net.c|1076| <<peek_head_len>> if (rvq->rx_ring)
+	 *   - drivers/vhost/net.c|1304| <<handle_rx>> if (nvq->rx_ring)
+	 *   - drivers/vhost/net.c|1479| <<vhost_net_open>> n->vqs[i].rx_ring = NULL;
+	 *   - drivers/vhost/net.c|1526| <<vhost_net_stop_vq>> nvq->rx_ring = NULL;
+	 *   - drivers/vhost/net.c|1716| <<vhost_net_set_backend>> nvq->rx_ring = get_tap_ptr_ring(sock->file);
+	 *   - drivers/vhost/net.c|1718| <<vhost_net_set_backend>> nvq->rx_ring = NULL;
+	 */
 	struct ptr_ring *rx_ring;
 	struct vhost_net_buf rxq;
 	/* Batched XDP buffs */
@@ -205,6 +217,10 @@ static int vhost_net_buf_peek_len(void *ptr)
 	return __skb_array_len_with_tag(ptr);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|1077| <<peek_head_len>> return vhost_net_buf_peek(rvq);
+ */
 static int vhost_net_buf_peek(struct vhost_net_virtqueue *nvq)
 {
 	struct vhost_net_buf *rxq = &nvq->rxq;
@@ -373,6 +389,11 @@ static void vhost_zerocopy_signal_used(struct vhost_net *net,
 	}
 	while (j) {
 		add = min(UIO_MAXIOV - nvq->done_idx, j);
+		/*
+		 * called by:
+		 *   - drivers/vhost/net.c|376| <<vhost_zerocopy_signal_used>> vhost_add_used_and_signal_n(vq->dev, vq,
+		 *   - drivers/vhost/net.c|460| <<vhost_net_signal_used>> vhost_add_used_and_signal_n(dev, vq, vq->heads, nvq->done_idx);
+		 */
 		vhost_add_used_and_signal_n(vq->dev, vq,
 					    &vq->heads[nvq->done_idx], add);
 		nvq->done_idx = (nvq->done_idx + add) % UIO_MAXIOV;
@@ -431,6 +452,18 @@ static void vhost_net_disable_vq(struct vhost_net *n,
 	struct vhost_poll *poll = n->poll + (nvq - n->vqs);
 	if (!vhost_vq_get_backend(vq))
 		return;
+	/*
+	 * 在以下调用vhost_poll_stop():
+	 *   - drivers/vhost/net.c|439| <<vhost_net_disable_vq>> vhost_poll_stop(poll);
+	 *   - drivers/vhost/test.c|309| <<vhost_test_set_backend>> vhost_poll_stop(&vq->poll);
+	 *   - drivers/vhost/vhost.c|235| <<vhost_poll_start>> vhost_poll_stop(poll);
+	 *   - drivers/vhost/vhost.c|1088| <<vhost_dev_stop>> vhost_poll_stop(&dev->vqs[i]->poll);
+	 *   - drivers/vhost/vhost.c|2244| <<vhost_vring_ioctl>> vhost_poll_stop(&vq->poll);
+	 *
+	 * 注释:
+	 * Stop polling a file. After this function returns, it becomes safe to drop the
+	 * file reference. You must also flush afterwards.
+	 */
 	vhost_poll_stop(poll);
 }
 
@@ -446,6 +479,17 @@ static int vhost_net_enable_vq(struct vhost_net *n,
 	if (!sock)
 		return 0;
 
+	/*
+	 * 在以下调用vhost_poll_start():
+	 *   - drivers/vhost/net.c|454| <<vhost_net_enable_vq>> return vhost_poll_start(poll, sock->file);
+	 *   - drivers/vhost/test.c|324| <<vhost_test_set_backend>> r = vhost_poll_start(&vq->poll, vq->kick);
+	 *   - drivers/vhost/vhost.c|2252| <<vhost_vring_ioctl>> r = vhost_poll_start(&vq->poll, vq->kick);
+	 *   - drivers/vhost/vhost.h|56| <<vhost_vring_ioctl>> int vhost_poll_start(struct vhost_poll *poll, struct file *file);
+	 *
+	 * 注释:
+	 * Start polling a file. We add ourselves to file's wait queue. The caller must
+	 * keep a reference to a file until after vhost_poll_stop is called.
+	 */
 	return vhost_poll_start(poll, sock->file);
 }
 
@@ -457,6 +501,11 @@ static void vhost_net_signal_used(struct vhost_net_virtqueue *nvq)
 	if (!nvq->done_idx)
 		return;
 
+	/*
+	 * called by:
+	 *   - drivers/vhost/net.c|376| <<vhost_zerocopy_signal_used>> vhost_add_used_and_signal_n(vq->dev, vq,
+	 *   - drivers/vhost/net.c|460| <<vhost_net_signal_used>> vhost_add_used_and_signal_n(dev, vq, vq->heads, nvq->done_idx);
+	 */
 	vhost_add_used_and_signal_n(dev, vq, vq->heads, nvq->done_idx);
 	nvq->done_idx = 0;
 }
@@ -580,6 +629,25 @@ static int vhost_net_tx_get_vq_desc(struct vhost_net *net,
 	struct vhost_virtqueue *rvq = &rnvq->vq;
 	struct vhost_virtqueue *tvq = &tnvq->vq;
 
+	/*
+	 * called by:
+	 *   - drivers/vhost/net.c|583| <<vhost_net_tx_get_vq_desc>> int r = vhost_get_vq_desc(
+	 *                tvq, tvq->iov, ARRAY_SIZE(tvq->iov), out_num, in_num, NULL, NULL);
+	 *   - drivers/vhost/net.c|595| <<vhost_net_tx_get_vq_desc>> r = vhost_get_vq_desc(
+	 *                tvq, tvq->iov, ARRAY_SIZE(tvq->iov), out_num, in_num, NULL, NULL);
+	 *   - drivers/vhost/net.c|1041| <<get_rx_bufs>> r = vhost_get_vq_desc(
+	 *                vq, vq->iov + seg, ARRAY_SIZE(vq->iov) - seg, &out, &in, log, log_num);
+	 *   - drivers/vhost/scsi.c|477| <<vhost_scsi_do_evt_work>> head = vhost_get_vq_desc(
+	 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+	 *   - drivers/vhost/scsi.c|957| <<vhost_scsi_get_desc>> vc->head = vhost_get_vq_desc(
+	 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &vc->out, &vc->in, NULL, NULL);
+	 *   - drivers/vhost/test.c|61| <<handle_vq>> head = vhost_get_vq_desc(
+	 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+	 *   - drivers/vhost/vsock.c|127| <<vhost_transport_do_send_pkt>> head = vhost_get_vq_desc(
+	 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+	 *   - drivers/vhost/vsock.c|509| <<vhost_vsock_handle_tx_kick>> head = vhost_get_vq_desc(
+	 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+	 */
 	int r = vhost_get_vq_desc(tvq, tvq->iov, ARRAY_SIZE(tvq->iov),
 				  out_num, in_num, NULL, NULL);
 
@@ -592,6 +660,25 @@ static int vhost_net_tx_get_vq_desc(struct vhost_net *net,
 
 		vhost_net_busy_poll(net, rvq, tvq, busyloop_intr, false);
 
+		/*
+		 * called by:
+		 *   - drivers/vhost/net.c|583| <<vhost_net_tx_get_vq_desc>> int r = vhost_get_vq_desc(
+		 *                tvq, tvq->iov, ARRAY_SIZE(tvq->iov), out_num, in_num, NULL, NULL);
+		 *   - drivers/vhost/net.c|595| <<vhost_net_tx_get_vq_desc>> r = vhost_get_vq_desc(
+		 *                tvq, tvq->iov, ARRAY_SIZE(tvq->iov), out_num, in_num, NULL, NULL);
+		 *   - drivers/vhost/net.c|1041| <<get_rx_bufs>> r = vhost_get_vq_desc(
+		 *                vq, vq->iov + seg, ARRAY_SIZE(vq->iov) - seg, &out, &in, log, log_num);
+		 *   - drivers/vhost/scsi.c|477| <<vhost_scsi_do_evt_work>> head = vhost_get_vq_desc(
+		 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+		 *   - drivers/vhost/scsi.c|957| <<vhost_scsi_get_desc>> vc->head = vhost_get_vq_desc(
+		 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &vc->out, &vc->in, NULL, NULL);
+		 *   - drivers/vhost/test.c|61| <<handle_vq>> head = vhost_get_vq_desc(
+		 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+		 *   - drivers/vhost/vsock.c|127| <<vhost_transport_do_send_pkt>> head = vhost_get_vq_desc(
+		 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+		 *   - drivers/vhost/vsock.c|509| <<vhost_vsock_handle_tx_kick>> head = vhost_get_vq_desc(
+		 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+		 */
 		r = vhost_get_vq_desc(tvq, tvq->iov, ARRAY_SIZE(tvq->iov),
 				      out_num, in_num, NULL, NULL);
 	}
@@ -790,6 +877,17 @@ static void handle_tx_copy(struct vhost_net *net, struct socket *sock)
 				goto done;
 			} else if (unlikely(err != -ENOSPC)) {
 				vhost_tx_batch(net, nvq, sock, &msg);
+				/*
+				 * called by:
+				 *   - drivers/vhost/net.c|831| <<handle_tx_copy>> vhost_discard_vq_desc(vq, 1);
+				 *   - drivers/vhost/net.c|852| <<handle_tx_copy>> vhost_discard_vq_desc(vq, 1);
+				 *   - drivers/vhost/net.c|960| <<handle_tx_zerocopy>> vhost_discard_vq_desc(vq, 1);
+				 *   - drivers/vhost/net.c|1138| <<get_rx_bufs>> vhost_discard_vq_desc(vq, headcount);
+				 *   - drivers/vhost/net.c|1245| <<handle_rx>> vhost_discard_vq_desc(vq, headcount);
+				 *   - drivers/vhost/net.c|1269| <<handle_rx>> vhost_discard_vq_desc(vq, headcount);
+				 *
+				 * 把vhost_virtqueue->last_avail_idx减少n
+				 */
 				vhost_discard_vq_desc(vq, 1);
 				vhost_net_enable_vq(net, vq);
 				break;
@@ -811,6 +909,17 @@ static void handle_tx_copy(struct vhost_net *net, struct socket *sock)
 		err = sock->ops->sendmsg(sock, &msg, len);
 		if (unlikely(err < 0)) {
 			if (err == -EAGAIN || err == -ENOMEM || err == -ENOBUFS) {
+				/*
+				 * called by:
+				 *   - drivers/vhost/net.c|831| <<handle_tx_copy>> vhost_discard_vq_desc(vq, 1);
+				 *   - drivers/vhost/net.c|852| <<handle_tx_copy>> vhost_discard_vq_desc(vq, 1);
+				 *   - drivers/vhost/net.c|960| <<handle_tx_zerocopy>> vhost_discard_vq_desc(vq, 1);
+				 *   - drivers/vhost/net.c|1138| <<get_rx_bufs>> vhost_discard_vq_desc(vq, headcount);
+				 *   - drivers/vhost/net.c|1245| <<handle_rx>> vhost_discard_vq_desc(vq, headcount);
+				 *   - drivers/vhost/net.c|1269| <<handle_rx>> vhost_discard_vq_desc(vq, headcount);
+				 *
+				 * 把vhost_virtqueue->last_avail_idx减少n
+				 */
 				vhost_discard_vq_desc(vq, 1);
 				vhost_net_enable_vq(net, vq);
 				break;
@@ -919,6 +1028,17 @@ static void handle_tx_zerocopy(struct vhost_net *net, struct socket *sock)
 					vq->heads[ubuf->desc].len = VHOST_DMA_DONE_LEN;
 			}
 			if (retry) {
+				/*
+				 * called by:
+				 *   - drivers/vhost/net.c|831| <<handle_tx_copy>> vhost_discard_vq_desc(vq, 1);
+				 *   - drivers/vhost/net.c|852| <<handle_tx_copy>> vhost_discard_vq_desc(vq, 1);
+				 *   - drivers/vhost/net.c|960| <<handle_tx_zerocopy>> vhost_discard_vq_desc(vq, 1);
+				 *   - drivers/vhost/net.c|1138| <<get_rx_bufs>> vhost_discard_vq_desc(vq, headcount);
+				 *   - drivers/vhost/net.c|1245| <<handle_rx>> vhost_discard_vq_desc(vq, headcount);
+				 *   - drivers/vhost/net.c|1269| <<handle_rx>> vhost_discard_vq_desc(vq, headcount);
+				 *
+				 * 把vhost_virtqueue->last_avail_idx减少n
+				 */
 				vhost_discard_vq_desc(vq, 1);
 				vhost_net_enable_vq(net, vq);
 				break;
@@ -963,12 +1083,23 @@ static void handle_tx(struct vhost_net *net)
 	mutex_unlock(&vq->mutex);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|1098| <<vhost_net_rx_peek_head_len>> int len = peek_head_len(rnvq, sk);
+ *   - drivers/vhost/net.c|1106| <<vhost_net_rx_peek_head_len>> len = peek_head_len(rnvq, sk);
+ */
 static int peek_head_len(struct vhost_net_virtqueue *rvq, struct sock *sk)
 {
 	struct sk_buff *head;
 	int len = 0;
 	unsigned long flags;
 
+	/*
+	 * struct vhost_net_virtqueue *rvq:
+	 * -> struct ptr_ring *rx_ring;
+	 *
+	 * 只在此处调用vhost_net_buf_peek()
+	 */
 	if (rvq->rx_ring)
 		return vhost_net_buf_peek(rvq);
 
@@ -984,6 +1115,10 @@ static int peek_head_len(struct vhost_net_virtqueue *rvq, struct sock *sk)
 	return len;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|1274| <<handle_rx>> sock_len = vhost_net_rx_peek_head_len(net, sock->sk,
+ */
 static int vhost_net_rx_peek_head_len(struct vhost_net *net, struct sock *sk,
 				      bool *busyloop_intr)
 {
@@ -993,6 +1128,16 @@ static int vhost_net_rx_peek_head_len(struct vhost_net *net, struct sock *sk,
 	struct vhost_virtqueue *tvq = &tnvq->vq;
 	int len = peek_head_len(rnvq, sk);
 
+	/*
+	 * 在以下使用vhost_virtqueue->busyloop_timeout:
+	 *   - drivers/vhost/net.c|577| <<vhost_net_busy_poll>> busyloop_timeout = poll_rx ?
+	 *             rvq->busyloop_timeout: tvq->busyloop_timeout;
+	 *   - drivers/vhost/net.c|638| <<vhost_net_tx_get_vq_desc>> if (r == tvq->num && tvq->busyloop_timeout) {
+	 *   - drivers/vhost/net.c|1100| <<vhost_net_rx_peek_head_len>> if (!len && rvq->busyloop_timeout) {
+	 *   - drivers/vhost/vhost.c|550| <<vhost_vq_reset>> vq->busyloop_timeout = 0;
+	 *   - drivers/vhost/vhost.c|2369| <<vhost_vring_ioctl(VHOST_SET_VRING_BUSYLOOP_TIMEOUT)>> vq->busyloop_timeout = s.num;
+	 *   - drivers/vhost/vhost.c|2373| <<vhost_vring_ioctl(VHOST_GET_VRING_BUSYLOOP_TIMEOUT)>> s.num = vq->busyloop_timeout;
+	 */
 	if (!len && rvq->busyloop_timeout) {
 		/* Flush batched heads first */
 		vhost_net_signal_used(rnvq);
@@ -1015,6 +1160,12 @@ static int vhost_net_rx_peek_head_len(struct vhost_net *net, struct sock *sk,
  * @quota       - headcount quota, 1 for big buffer
  *	returns number of buffer heads allocated, negative on error
  */
+/*
+ * called by:
+ *   - drivers/vhost/net.c|1274| <<handle_rx>> headcount = get_rx_bufs(vq,
+ *             vq->heads + nvq->done_idx, vhost_len, &in, vq_log, &log,
+ *             likely(mergeable) ? UIO_MAXIOV : 1);
+ */
 static int get_rx_bufs(struct vhost_virtqueue *vq,
 		       struct vring_used_elem *heads,
 		       int datalen,
@@ -1038,6 +1189,25 @@ static int get_rx_bufs(struct vhost_virtqueue *vq,
 			r = -ENOBUFS;
 			goto err;
 		}
+		/*
+		 * called by:
+		 *   - drivers/vhost/net.c|583| <<vhost_net_tx_get_vq_desc>> int r = vhost_get_vq_desc(
+		 *                tvq, tvq->iov, ARRAY_SIZE(tvq->iov), out_num, in_num, NULL, NULL);
+		 *   - drivers/vhost/net.c|595| <<vhost_net_tx_get_vq_desc>> r = vhost_get_vq_desc(
+		 *                tvq, tvq->iov, ARRAY_SIZE(tvq->iov), out_num, in_num, NULL, NULL);
+		 *   - drivers/vhost/net.c|1041| <<get_rx_bufs>> r = vhost_get_vq_desc(
+		 *                vq, vq->iov + seg, ARRAY_SIZE(vq->iov) - seg, &out, &in, log, log_num);
+		 *   - drivers/vhost/scsi.c|477| <<vhost_scsi_do_evt_work>> head = vhost_get_vq_desc(
+		 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+		 *   - drivers/vhost/scsi.c|957| <<vhost_scsi_get_desc>> vc->head = vhost_get_vq_desc(
+		 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &vc->out, &vc->in, NULL, NULL);
+		 *   - drivers/vhost/test.c|61| <<handle_vq>> head = vhost_get_vq_desc(
+		 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+		 *   - drivers/vhost/vsock.c|127| <<vhost_transport_do_send_pkt>> head = vhost_get_vq_desc(
+		 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+		 *   - drivers/vhost/vsock.c|509| <<vhost_vsock_handle_tx_kick>> head = vhost_get_vq_desc(
+		 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+		 */
 		r = vhost_get_vq_desc(vq, vq->iov + seg,
 				      ARRAY_SIZE(vq->iov) - seg, &out,
 				      &in, log, log_num);
@@ -1078,10 +1248,26 @@ static int get_rx_bufs(struct vhost_virtqueue *vq,
 	}
 	return headcount;
 err:
+	/*
+	 * called by:
+	 *   - drivers/vhost/net.c|831| <<handle_tx_copy>> vhost_discard_vq_desc(vq, 1);
+	 *   - drivers/vhost/net.c|852| <<handle_tx_copy>> vhost_discard_vq_desc(vq, 1);
+	 *   - drivers/vhost/net.c|960| <<handle_tx_zerocopy>> vhost_discard_vq_desc(vq, 1);
+	 *   - drivers/vhost/net.c|1138| <<get_rx_bufs>> vhost_discard_vq_desc(vq, headcount);
+	 *   - drivers/vhost/net.c|1245| <<handle_rx>> vhost_discard_vq_desc(vq, headcount);
+	 *   - drivers/vhost/net.c|1269| <<handle_rx>> vhost_discard_vq_desc(vq, headcount);
+	 *
+	 * 把vhost_virtqueue->last_avail_idx减少n
+	 */
 	vhost_discard_vq_desc(vq, headcount);
 	return r;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|1454| <<handle_rx_kick>> handle_rx(net);
+ *   - drivers/vhost/net.c|1468| <<handle_rx_net>> handle_rx(net);
+ */
 /* Expects to be always run from workqueue - which acts as
  * read-size critical section for our kind of RCU. */
 static void handle_rx(struct vhost_net *net)
@@ -1131,12 +1317,18 @@ static void handle_rx(struct vhost_net *net)
 	mergeable = vhost_has_feature(vq, VIRTIO_NET_F_MRG_RXBUF);
 
 	do {
+		/*
+		 * 只在此处调用
+		 */
 		sock_len = vhost_net_rx_peek_head_len(net, sock->sk,
 						      &busyloop_intr);
 		if (!sock_len)
 			break;
 		sock_len += sock_hlen;
 		vhost_len = sock_len + vhost_hlen;
+		/*
+		 * 只在此处调用
+		 */
 		headcount = get_rx_bufs(vq, vq->heads + nvq->done_idx,
 					vhost_len, &in, vq_log, &log,
 					likely(mergeable) ? UIO_MAXIOV : 1);
@@ -1185,6 +1377,17 @@ static void handle_rx(struct vhost_net *net)
 		if (unlikely(err != sock_len)) {
 			pr_debug("Discarded rx packet: "
 				 " len %d, expected %zd\n", err, sock_len);
+			/*
+			 * called by:
+			 *   - drivers/vhost/net.c|831| <<handle_tx_copy>> vhost_discard_vq_desc(vq, 1);
+			 *   - drivers/vhost/net.c|852| <<handle_tx_copy>> vhost_discard_vq_desc(vq, 1);
+			 *   - drivers/vhost/net.c|960| <<handle_tx_zerocopy>> vhost_discard_vq_desc(vq, 1);
+			 *   - drivers/vhost/net.c|1138| <<get_rx_bufs>> vhost_discard_vq_desc(vq, headcount);
+			 *   - drivers/vhost/net.c|1245| <<handle_rx>> vhost_discard_vq_desc(vq, headcount);
+			 *   - drivers/vhost/net.c|1269| <<handle_rx>> vhost_discard_vq_desc(vq, headcount);
+			 *
+			 * 把vhost_virtqueue->last_avail_idx减少n
+			 */
 			vhost_discard_vq_desc(vq, headcount);
 			continue;
 		}
@@ -1209,6 +1412,17 @@ static void handle_rx(struct vhost_net *net)
 		    copy_to_iter(&num_buffers, sizeof num_buffers,
 				 &fixup) != sizeof num_buffers) {
 			vq_err(vq, "Failed num_buffers write");
+			/*
+			 * called by:
+			 *   - drivers/vhost/net.c|831| <<handle_tx_copy>> vhost_discard_vq_desc(vq, 1);
+			 *   - drivers/vhost/net.c|852| <<handle_tx_copy>> vhost_discard_vq_desc(vq, 1);
+			 *   - drivers/vhost/net.c|960| <<handle_tx_zerocopy>> vhost_discard_vq_desc(vq, 1);
+			 *   - drivers/vhost/net.c|1138| <<get_rx_bufs>> vhost_discard_vq_desc(vq, headcount);
+			 *   - drivers/vhost/net.c|1245| <<handle_rx>> vhost_discard_vq_desc(vq, headcount);
+			 *   - drivers/vhost/net.c|1269| <<handle_rx>> vhost_discard_vq_desc(vq, headcount);
+			 *
+			 * 把vhost_virtqueue->last_avail_idx减少n
+			 */
 			vhost_discard_vq_desc(vq, headcount);
 			goto out;
 		}
@@ -1314,6 +1528,22 @@ static int vhost_net_open(struct inode *inode, struct file *f)
 		n->vqs[i].rx_ring = NULL;
 		vhost_net_buf_init(&n->vqs[i].rxq);
 	}
+	/*
+	 * called by:
+	 *   - drivers/vhost/net.c|1374| <<vhost_net_open>> vhost_dev_init(dev, vqs,
+	 *             VHOST_NET_VQ_MAX, UIO_MAXIOV + VHOST_NET_BATCH,
+	 *             HOST_NET_PKT_WEIGHT, VHOST_NET_WEIGHT, true, NULL);
+	 *   - drivers/vhost/scsi.c|2258| <<vhost_scsi_open>> vhost_dev_init(&vs->dev, vqs,
+	 *             nvqs, UIO_MAXIOV, VHOST_SCSI_WEIGHT, 0, true, NULL);
+	 *   - drivers/vhost/test.c|122| <<vhost_test_open>> vhost_dev_init(dev, vqs,
+	 *             VHOST_TEST_VQ_MAX, UIO_MAXIOV,
+	 *             VHOST_TEST_PKT_WEIGHT, VHOST_TEST_WEIGHT, true, NULL);
+	 *   - drivers/vhost/vdpa.c|1433| <<vhost_vdpa_open>> vhost_dev_init(dev, vqs,
+	 *             nvqs, 0, 0, 0, false, vhost_vdpa_process_iotlb_msg);
+	 *   - drivers/vhost/vsock.c|719| <<vhost_vsock_dev_open>> vhost_dev_init(&vsock->dev, vqs,
+	 *             ARRAY_SIZE(vsock->vqs), UIO_MAXIOV,
+	 *             VHOST_VSOCK_PKT_WEIGHT, VHOST_VSOCK_WEIGHT, true, NULL);
+	 */
 	vhost_dev_init(dev, vqs, VHOST_NET_VQ_MAX,
 		       UIO_MAXIOV + VHOST_NET_BATCH,
 		       VHOST_NET_PKT_WEIGHT, VHOST_NET_WEIGHT, true,
@@ -1516,6 +1746,14 @@ static long vhost_net_set_backend(struct vhost_net *n, unsigned index, int fd)
 		vhost_net_disable_vq(n, vq);
 		vhost_vq_set_backend(vq, sock);
 		vhost_net_buf_unproduce(nvq);
+		/*
+		 * called by:
+		 *   - drivers/vhost/net.c|1658| <<vhost_net_set_backend>> r = vhost_vq_init_access(vq);
+		 *   - drivers/vhost/scsi.c|2285| <<vhost_scsi_set_endpoint>> vhost_vq_init_access(vq);
+		 *   - drivers/vhost/test.c|213| <<vhost_test_run>> r = vhost_vq_init_access(&n->vqs[index]);
+		 *   - drivers/vhost/test.c|306| <<vhost_test_set_backend>> r = vhost_vq_init_access(vq);
+		 *   - drivers/vhost/vsock.c|643| <<vhost_vsock_start>> ret = vhost_vq_init_access(vq);
+		 */
 		r = vhost_vq_init_access(vq);
 		if (r)
 			goto err_used;
diff --git a/drivers/vhost/scsi.c b/drivers/vhost/scsi.c
index 718fa4e0b..6a5f913aa 100644
--- a/drivers/vhost/scsi.c
+++ b/drivers/vhost/scsi.c
@@ -64,6 +64,12 @@ struct vhost_scsi_cmd {
 	int tvc_vq_desc;
 	/* virtio-scsi initiator task attribute */
 	int tvc_task_attr;
+	/*
+	 * 在以下使用vhost_scsi_cmd->yvc_in_iovs:
+	 *   - drivers/vhost/scsi.c|855| <<vhost_scsi_complete_cmd_work>> iov_iter_init(&iov_iter,
+	 *             ITER_DEST, cmd->tvc_resp_iov, cmd->tvc_in_iovs, sizeof(v_rsp));
+	 *   - drivers/vhost/scsi.c|1562| <<vhost_scsi_handle_vq>> cmd->tvc_in_iovs = vc.in;
+	 */
 	/* virtio-scsi response incoming iovecs */
 	int tvc_in_iovs;
 	/* virtio-scsi initiator data direction */
@@ -112,8 +118,24 @@ struct vhost_scsi_nexus {
 struct vhost_scsi_tpg {
 	/* Vhost port target portal group tag for TCM */
 	u16 tport_tpgt;
+	/*
+	 * 在以下使用vhost_scsi_tpg->tv_tpg_port_count:
+	 *   - drivers/vhost/scsi.c|2927| <<vhost_scsi_port_link>> tpg->tv_tpg_port_count++;
+	 *   - drivers/vhost/scsi.c|2944| <<vhost_scsi_port_unlink>> tpg->tv_tpg_port_count--;
+	 *   - drivers/vhost/scsi.c|3046| <<vhost_scsi_drop_nexus>> if (tpg->tv_tpg_port_count != 0) {
+	 *   - drivers/vhost/scsi.c|3050| <<vhost_scsi_drop_nexus>> pr_err("Unable ... tpg->tv_tpg_port_count);
+	 */
 	/* Used to track number of TPG Port/Lun Links wrt to explict I_T Nexus shutdown */
 	int tv_tpg_port_count;
+	/*
+	 * 在以下使用vhost_scsi_tpg->tv_tpg_vhost_count:
+	 *   - drivers/vhost/scsi.c|2328| <<vhost_scsi_set_endpoint>> if (tpg->tv_tpg_vhost_count != 0) {
+	 *   - drivers/vhost/scsi.c|2355| <<vhost_scsi_set_endpoint>> tpg->tv_tpg_vhost_count++;
+	 *   - drivers/vhost/scsi.c|2424| <<vhost_scsi_set_endpoint>> tpg->tv_tpg_vhost_count--;
+	 *   - drivers/vhost/scsi.c|2519| <<vhost_scsi_clear_endpoint>> tpg->tv_tpg_vhost_count--;
+	 *   - drivers/vhost/scsi.c|3054| <<vhost_scsi_drop_nexus>> if (tpg->tv_tpg_vhost_count != 0) {
+	 *   - drivers/vhost/scsi.c|3058| <<vhost_scsi_drop_nexus>> pr_err(... tpg->tv_tpg_vhost_count);
+	 */
 	/* Used for vhost_scsi device reference to tpg_nexus, protected by tv_tpg_mutex */
 	int tv_tpg_vhost_count;
 	/* Used for enabling T10-PI with legacy devices */
@@ -128,6 +150,13 @@ struct vhost_scsi_tpg {
 	struct vhost_scsi_tport *tport;
 	/* Returned by vhost_scsi_make_tpg() */
 	struct se_portal_group se_tpg;
+	/*
+	 * 在以下使用vhost_scsi_tpg->vhost_scsi:
+	 *   - drivers/vhost/scsi.c|2349| <<vhost_scsi_set_endpoint>> tpg->vhost_scsi = vs;
+	 *   - drivers/vhost/scsi.c|2416| <<vhost_scsi_set_endpoint>> tpg->vhost_scsi = NULL;
+	 *   - drivers/vhost/scsi.c|2513| <<vhost_scsi_clear_endpoint>> tpg->vhost_scsi = NULL;
+	 *   - drivers/vhost/scsi.c|2828| <<vhost_scsi_do_plug>> struct vhost_scsi *vs = tpg->vhost_scsi;
+	 */
 	/* Pointer back to vhost_scsi, protected by tv_tpg_mutex */
 	struct vhost_scsi *vhost_scsi;
 };
@@ -201,20 +230,68 @@ struct vhost_scsi {
 	struct vhost_scsi_virtqueue *vqs;
 	struct vhost_scsi_inflight **old_inflight;
 
+	/*
+	 * 在以下使用vhost_scsi->vs_event_work:
+	 *   - drivers/vhost/scsi.c|1623| <<vhost_scsi_send_evt>> if (!vhost_vq_work_queue(vq, &vs->vs_event_work))
+	 *   - drivers/vhost/scsi.c|2067| <<vhost_scsi_open>> vhost_work_init(&vs->vs_event_work, vhost_scsi_evt_work);
+	 */
 	struct vhost_work vs_event_work; /* evt injection work item */
+	/*
+	 * 在以下使用vhost_scsi->vs_event_list:
+	 *   - drivers/vhost/scsi.c|541| <<vhost_scsi_complete_events>> llnode = llist_del_all(&vs->vs_event_list);
+	 *   - drivers/vhost/scsi.c|1578| <<vhost_scsi_send_evt>> llist_add(&evt->list, &vs->vs_event_list);
+	 */
 	struct llist_head vs_event_list; /* evt injection queue */
 
+	/*
+	 * 在以下使用vhost_scsi->vs_events_missed:
+	 *   - drivers/vhost/scsi.c|483| <<vhost_scsi_allocate_evt>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|490| <<vhost_scsi_allocate_evt>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|530| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|559| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|565| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|579| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|583| <<vhost_scsi_do_evt_work>> if (vs->vs_events_missed) {
+	 *   - drivers/vhost/scsi.c|585| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = false;
+	 *   - drivers/vhost/scsi.c|1693| <<vhost_scsi_evt_handle_kick>> if (vs->vs_events_missed)
+	 *   - drivers/vhost/scsi.c|2131| <<vhost_scsi_open>> vs->vs_events_missed = false;
+	 *   - drivers/vhost/scsi.c|2221| <<vhost_scsi_ioctl(VHOST_SCSI_SET_EVENTS_MISSED)>> vs->vs_events_missed = events_missed;
+	 *   - drivers/vhost/scsi.c|2226| <<vhost_scsi_ioctl(VHOST_SCSI_GET_EVENTS_MISSED)>> events_missed = vs->vs_events_missed;
+	 */
 	bool vs_events_missed; /* any missed events, protected by vq->mutex */
+	/*
+	 * 在以下使用vhost_scsi->vs_events_nr:
+	 *   - drivers/vhost/scsi.c|471| <<vhost_scsi_free_evt>> vs->vs_events_nr--;
+	 *   - drivers/vhost/scsi.c|482| <<vhost_scsi_allocate_evt>> if (vs->vs_events_nr > VHOST_SCSI_MAX_EVENT) {
+	 *   - drivers/vhost/scsi.c|496| <<vhost_scsi_allocate_evt>> vs->vs_events_nr++;
+	 *   - drivers/vhost/scsi.c|2054| <<vhost_scsi_clear_endpoint>> WARN_ON(vs->vs_events_nr);
+	 *   - drivers/vhost/scsi.c|2130| <<vhost_scsi_open>> vs->vs_events_nr = 0;
+	 */
 	int vs_events_nr; /* num of pending events, protected by vq->mutex */
 };
 
 struct vhost_scsi_tmf {
+	/*
+	 * 在以下使用vhost_scsi_tmf->vwork:
+	 *   - drivers/vhost/scsi.c|1537| <<vhost_scsi_tmf_flush_work>> if (!vhost_vq_work_queue(vq, &tmf->vwork))
+	 *   - drivers/vhost/scsi.c|1565| <<vhost_scsi_handle_tmf>> vhost_work_init(&tmf->vwork, vhost_scsi_tmf_resp_work);
+	 */
 	struct vhost_work vwork;
+	/*
+	 * 在以下使用vhost_scsi_tmf->flush_work:
+	 *   - drivers/vhost/scsi.c|457| <<vhost_scsi_release_cmd>> schedule_work(&tmf->flush_work);
+	 *   - drivers/vhost/scsi.c|1660| <<vhost_scsi_handle_tmf>> INIT_WORK(&tmf->flush_work, vhost_scsi_tmf_flush_work);
+	 */
 	struct work_struct flush_work;
 	struct vhost_scsi *vhost;
 	struct vhost_scsi_virtqueue *svq;
 
 	struct se_cmd se_cmd;
+	/*
+	 * 在以下使用vhost_scsi_tmf->scsi_resp:
+	 *   - drivers/vhost/scsi.c|543| <<vhost_scsi_queue_tm_rsp>> tmf->scsi_resp = se_cmd->se_tmr_req->response;
+	 *   - drivers/vhost/scsi.c|1680| <<vhost_scsi_tmf_resp_work>> if (tmf->scsi_resp == TMR_FUNCTION_COMPLETE)
+	 */
 	u8 scsi_resp;
 	struct vhost_scsi_inflight *inflight;
 	struct iovec resp_iov;
@@ -230,6 +307,15 @@ struct vhost_scsi_ctx {
 	unsigned int out, in;
 	size_t req_size, rsp_size;
 	size_t out_size, in_size;
+	/*
+	 * 在以下使用vhost_scsi_ctx->lunp:
+	 *   - drivers/vhost/scsi.c|1273| <<vhost_scsi_get_req>> } else if (unlikely(*vc->lunp != 1)) {
+	 *   - drivers/vhost/scsi.c|1275| <<vhost_scsi_get_req>> vq_err(vq, "Illegal virtio-scsi lun: %u\n", *vc->lunp);
+	 *   - drivers/vhost/scsi.c|1349| <<vhost_scsi_handle_vq>> vc.lunp = &v_req_pi.lun[0];
+	 *   - drivers/vhost/scsi.c|1354| <<vhost_scsi_handle_vq>> vc.lunp = &v_req.lun[0];
+	 *   - drivers/vhost/scsi.c|1778| <<vhost_scsi_ctl_handle_vq>> vc.lunp = &v_req.tmf.lun[0];
+	 *   - drivers/vhost/scsi.c|1786| <<vhost_scsi_ctl_handle_vq>> vc.lunp = &v_req.an.lun[0];
+	 */
 	u8 *target, *lunp;
 	void *req;
 	struct iov_iter out_iter;
@@ -240,6 +326,12 @@ struct vhost_scsi_ctx {
  * configfs management operations.
  */
 static DEFINE_MUTEX(vhost_scsi_mutex);
+/*
+ * 在以下使用vhost_scsi_list:
+ *   - drivers/vhost/scsi.c|308| <<global>> static LIST_HEAD(vhost_scsi_list);
+ *   - drivers/vhost/scsi.c|2322| <<vhost_scsi_set_endpoint>> list_for_each_entry(tpg, &vhost_scsi_list, tv_tpg_list) {
+ *   - drivers/vhost/scsi.c|3220| <<vhost_scsi_make_tpg>> list_add_tail(&tpg->tv_tpg_list, &vhost_scsi_list);
+ */
 static LIST_HEAD(vhost_scsi_list);
 
 static void vhost_scsi_done_inflight(struct kref *kref)
@@ -250,6 +342,11 @@ static void vhost_scsi_done_inflight(struct kref *kref)
 	complete(&inflight->comp);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|2143| <<vhost_scsi_flush>> vhost_scsi_init_inflight(vs, vs->old_inflight);
+ *   - drivers/vhost/scsi.c|2618| <<vhost_scsi_open>> vhost_scsi_init_inflight(vs, NULL);
+ */
 static void vhost_scsi_init_inflight(struct vhost_scsi *vs,
 				    struct vhost_scsi_inflight *old_inflight[])
 {
@@ -277,6 +374,11 @@ static void vhost_scsi_init_inflight(struct vhost_scsi *vs,
 	}
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|851| <<vhost_scsi_get_cmd>> cmd->inflight = vhost_scsi_get_inflight(vq);
+ *   - drivers/vhost/scsi.c|1571| <<vhost_scsi_handle_tmf>> tmf->inflight = vhost_scsi_get_inflight(vq);
+ */
 static struct vhost_scsi_inflight *
 vhost_scsi_get_inflight(struct vhost_virtqueue *vq)
 {
@@ -290,16 +392,28 @@ vhost_scsi_get_inflight(struct vhost_virtqueue *vq)
 	return inflight;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|397| <<vhost_scsi_release_cmd_res>> vhost_scsi_put_inflight(inflight);
+ *   - drivers/vhost/scsi.c|405| <<vhost_scsi_release_tmf_res>> vhost_scsi_put_inflight(inflight);
+ */
 static void vhost_scsi_put_inflight(struct vhost_scsi_inflight *inflight)
 {
 	kref_put(&inflight->kref, vhost_scsi_done_inflight);
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.tpg_check_demo_mode = vhost_scsi_check_true()
+ * struct target_core_fabric_ops vhost_scsi_ops.tpg_check_demo_mode_cache = vhost_scsi_check_true()
+ */
 static int vhost_scsi_check_true(struct se_portal_group *se_tpg)
 {
 	return 1;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.tpg_get_wwn = vhost_scsi_get_fabric_wwn()
+ */
 static char *vhost_scsi_get_fabric_wwn(struct se_portal_group *se_tpg)
 {
 	struct vhost_scsi_tpg *tpg = container_of(se_tpg,
@@ -309,6 +423,9 @@ static char *vhost_scsi_get_fabric_wwn(struct se_portal_group *se_tpg)
 	return &tport->tport_name[0];
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.tpg_get_tag = vhost_scsi_get_tpgt()
+ */
 static u16 vhost_scsi_get_tpgt(struct se_portal_group *se_tpg)
 {
 	struct vhost_scsi_tpg *tpg = container_of(se_tpg,
@@ -316,6 +433,9 @@ static u16 vhost_scsi_get_tpgt(struct se_portal_group *se_tpg)
 	return tpg->tport_tpgt;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.tpg_check_prot_fabric_only = vhost_scsi_check_prot_fabric_only()
+ */
 static int vhost_scsi_check_prot_fabric_only(struct se_portal_group *se_tpg)
 {
 	struct vhost_scsi_tpg *tpg = container_of(se_tpg,
@@ -324,6 +444,12 @@ static int vhost_scsi_check_prot_fabric_only(struct se_portal_group *se_tpg)
 	return tpg->tv_fabric_prot_type;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|468| <<vhost_scsi_drop_cmds>> vhost_scsi_release_cmd_res(&cmd->tvc_se_cmd);
+ *   - drivers/vhost/scsi.c|882| <<vhost_scsi_complete_cmd_work>> vhost_scsi_release_cmd_res(se_cmd);
+ *   - drivers/vhost/scsi.c|1592| <<vhost_scsi_handle_vq>> vhost_scsi_release_cmd_res(&cmd->tvc_se_cmd);
+ */
 static void vhost_scsi_release_cmd_res(struct se_cmd *se_cmd)
 {
 	struct vhost_scsi_cmd *tv_cmd = container_of(se_cmd,
@@ -351,6 +477,12 @@ static void vhost_scsi_release_cmd_res(struct se_cmd *se_cmd)
 	vhost_scsi_put_inflight(inflight);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1524| <<vhost_scsi_tmf_resp_work>> vhost_scsi_release_tmf_res(tmf);
+ *   - drivers/vhost/scsi.c|1538| <<vhost_scsi_tmf_flush_work>> vhost_scsi_release_tmf_res(tmf);
+ *   - drivers/vhost/scsi.c|1577| <<vhost_scsi_handle_tmf>> vhost_scsi_release_tmf_res(tmf);
+ */
 static void vhost_scsi_release_tmf_res(struct vhost_scsi_tmf *tmf)
 {
 	struct vhost_scsi_inflight *inflight = tmf->inflight;
@@ -359,6 +491,10 @@ static void vhost_scsi_release_tmf_res(struct vhost_scsi_tmf *tmf)
 	vhost_scsi_put_inflight(inflight);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|503| <<vhost_scsi_release_cmd>> vhost_scsi_drop_cmds(svq);
+ */
 static void vhost_scsi_drop_cmds(struct vhost_scsi_virtqueue *svq)
 {
 	struct vhost_scsi_cmd *cmd, *t;
@@ -369,12 +505,20 @@ static void vhost_scsi_drop_cmds(struct vhost_scsi_virtqueue *svq)
 		vhost_scsi_release_cmd_res(&cmd->tvc_se_cmd);
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.release_cmd = vhost_scsi_release_cmd()
+ */
 static void vhost_scsi_release_cmd(struct se_cmd *se_cmd)
 {
 	if (se_cmd->se_cmd_flags & SCF_SCSI_TMR_CDB) {
 		struct vhost_scsi_tmf *tmf = container_of(se_cmd,
 					struct vhost_scsi_tmf, se_cmd);
 
+		/*
+		 * 在以下使用vhost_scsi_tmf->flush_work:
+		 *   - drivers/vhost/scsi.c|457| <<vhost_scsi_release_cmd>> schedule_work(&tmf->flush_work);
+		 *   - drivers/vhost/scsi.c|1660| <<vhost_scsi_handle_tmf>> INIT_WORK(&tmf->flush_work, vhost_scsi_tmf_flush_work);
+		 */
 		schedule_work(&tmf->flush_work);
 	} else {
 		struct vhost_scsi_cmd *cmd = container_of(se_cmd,
@@ -383,11 +527,23 @@ static void vhost_scsi_release_cmd(struct se_cmd *se_cmd)
 					struct vhost_scsi_virtqueue, vq);
 
 		llist_add(&cmd->tvc_completion_list, &svq->completion_list);
+		/*
+		 * 在以下使用vhost_vq_work_queue():
+		 *   - drivers/vhost/scsi.c|475| <<vhost_scsi_release_cmd>> if (!vhost_vq_work_queue(&svq->vq, &svq->completion_work))
+		 *   - drivers/vhost/scsi.c|1688| <<vhost_scsi_tmf_flush_work>> if (!vhost_vq_work_queue(vq, &tmf->vwork))
+		 *   - drivers/vhost/scsi.c|2022| <<vhost_scsi_send_evt>> if (!vhost_vq_work_queue(vq, &vs->vs_event_work))
+		 *   - drivers/vhost/vhost.c|357| <<vhost_poll_queue>> vhost_vq_work_queue(poll->vq, &poll->work);
+		 *   - drivers/vhost/vsock.c|319| <<vhost_transport_send_pkt>> vhost_vq_work_queue(&vsock->vqs[VSOCK_VQ_RX], &vsock->send_pkt_work);
+		 *   - drivers/vhost/vsock.c|662| <<vhost_vsock_start>> vhost_vq_work_queue(&vsock->vqs[VSOCK_VQ_RX], &vsock->send_pkt_work);
+		 */
 		if (!vhost_vq_work_queue(&svq->vq, &svq->completion_work))
 			vhost_scsi_drop_cmds(svq);
 	}
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.write_pending = vhost_scsi_write_pending()
+ */
 static int vhost_scsi_write_pending(struct se_cmd *se_cmd)
 {
 	/* Go ahead and process the write immediately */
@@ -395,18 +551,27 @@ static int vhost_scsi_write_pending(struct se_cmd *se_cmd)
 	return 0;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.queue_data_in = vhost_scsi_queue_data_in()
+ */
 static int vhost_scsi_queue_data_in(struct se_cmd *se_cmd)
 {
 	transport_generic_free_cmd(se_cmd, 0);
 	return 0;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.queue_status = vhost_scsi_queue_status()
+ */
 static int vhost_scsi_queue_status(struct se_cmd *se_cmd)
 {
 	transport_generic_free_cmd(se_cmd, 0);
 	return 0;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.queue_tm_rsp = vhost_scsi_queue_tm_rsp()
+ */
 static void vhost_scsi_queue_tm_rsp(struct se_cmd *se_cmd)
 {
 	struct vhost_scsi_tmf *tmf = container_of(se_cmd, struct vhost_scsi_tmf,
@@ -416,17 +581,36 @@ static void vhost_scsi_queue_tm_rsp(struct se_cmd *se_cmd)
 	transport_generic_free_cmd(&tmf->se_cmd, 0);
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.aborted_task = vhost_scsi_aborted_task()
+ */
 static void vhost_scsi_aborted_task(struct se_cmd *se_cmd)
 {
 	return;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|545| <<vhost_scsi_complete_events>> vhost_scsi_free_evt(vs, evt);
+ */
 static void vhost_scsi_free_evt(struct vhost_scsi *vs, struct vhost_scsi_evt *evt)
 {
+	/*
+	 * 在以下使用vhost_scsi->vs_events_nr:
+	 *   - drivers/vhost/scsi.c|471| <<vhost_scsi_free_evt>> vs->vs_events_nr--;
+	 *   - drivers/vhost/scsi.c|482| <<vhost_scsi_allocate_evt>> if (vs->vs_events_nr > VHOST_SCSI_MAX_EVENT) {
+	 *   - drivers/vhost/scsi.c|496| <<vhost_scsi_allocate_evt>> vs->vs_events_nr++;
+	 *   - drivers/vhost/scsi.c|2054| <<vhost_scsi_clear_endpoint>> WARN_ON(vs->vs_events_nr);
+	 *   - drivers/vhost/scsi.c|2130| <<vhost_scsi_open>> vs->vs_events_nr = 0;
+	 */
 	vs->vs_events_nr--;
 	kfree(evt);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1719| <<vhost_scsi_send_evt>> evt = vhost_scsi_allocate_evt(vs, event, reason);
+ */
 static struct vhost_scsi_evt *
 vhost_scsi_allocate_evt(struct vhost_scsi *vs,
 		       u32 event, u32 reason)
@@ -434,6 +618,28 @@ vhost_scsi_allocate_evt(struct vhost_scsi *vs,
 	struct vhost_virtqueue *vq = &vs->vqs[VHOST_SCSI_VQ_EVT].vq;
 	struct vhost_scsi_evt *evt;
 
+	/*
+	 * 在以下使用vhost_scsi->vs_events_nr:
+	 *   - drivers/vhost/scsi.c|471| <<vhost_scsi_free_evt>> vs->vs_events_nr--;
+	 *   - drivers/vhost/scsi.c|482| <<vhost_scsi_allocate_evt>> if (vs->vs_events_nr > VHOST_SCSI_MAX_EVENT) {
+	 *   - drivers/vhost/scsi.c|496| <<vhost_scsi_allocate_evt>> vs->vs_events_nr++;
+	 *   - drivers/vhost/scsi.c|2054| <<vhost_scsi_clear_endpoint>> WARN_ON(vs->vs_events_nr);
+	 *   - drivers/vhost/scsi.c|2130| <<vhost_scsi_open>> vs->vs_events_nr = 0;
+	 *
+	 * 在以下使用vhost_scsi->vs_events_missed:
+	 *   - drivers/vhost/scsi.c|483| <<vhost_scsi_allocate_evt>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|490| <<vhost_scsi_allocate_evt>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|530| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|559| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|565| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|579| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|583| <<vhost_scsi_do_evt_work>> if (vs->vs_events_missed) {
+	 *   - drivers/vhost/scsi.c|585| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = false;
+	 *   - drivers/vhost/scsi.c|1693| <<vhost_scsi_evt_handle_kick>> if (vs->vs_events_missed)
+	 *   - drivers/vhost/scsi.c|2131| <<vhost_scsi_open>> vs->vs_events_missed = false;
+	 *   - drivers/vhost/scsi.c|2221| <<vhost_scsi_ioctl(VHOST_SCSI_SET_EVENTS_MISSED)>> vs->vs_events_missed = events_missed;
+	 *   - drivers/vhost/scsi.c|2226| <<vhost_scsi_ioctl(VHOST_SCSI_GET_EVENTS_MISSED)>> events_missed = vs->vs_events_missed;
+	 */
 	if (vs->vs_events_nr > VHOST_SCSI_MAX_EVENT) {
 		vs->vs_events_missed = true;
 		return NULL;
@@ -448,16 +654,38 @@ vhost_scsi_allocate_evt(struct vhost_scsi *vs,
 
 	evt->event.event = cpu_to_vhost32(vq, event);
 	evt->event.reason = cpu_to_vhost32(vq, reason);
+	/*
+	 * 在以下使用vhost_scsi->vs_events_nr:
+	 *   - drivers/vhost/scsi.c|471| <<vhost_scsi_free_evt>> vs->vs_events_nr--;
+	 *   - drivers/vhost/scsi.c|482| <<vhost_scsi_allocate_evt>> if (vs->vs_events_nr > VHOST_SCSI_MAX_EVENT) {
+	 *   - drivers/vhost/scsi.c|496| <<vhost_scsi_allocate_evt>> vs->vs_events_nr++;
+	 *   - drivers/vhost/scsi.c|2054| <<vhost_scsi_clear_endpoint>> WARN_ON(vs->vs_events_nr);
+	 *   - drivers/vhost/scsi.c|2130| <<vhost_scsi_open>> vs->vs_events_nr = 0;
+	 */
 	vs->vs_events_nr++;
 
 	return evt;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.check_stop_free = vhost_scsi_check_stop_free()
+ */
 static int vhost_scsi_check_stop_free(struct se_cmd *se_cmd)
 {
 	return target_put_sess_cmd(se_cmd);
 }
 
+/*
+ * vhost_scsi_evt_work() or vhost_scsi_send_evt()
+ * -> vhost_scsi_complete_events()
+ *    -> vhost_scsi_do_evt_work()
+ *       -> vhost_get_vq_desc()
+ *
+ * called by:
+ *   - drivers/vhost/scsi.c|521| <<vhost_scsi_complete_events>> vhost_scsi_do_evt_work(vs, evt);
+ *
+ * vq->mutex被拿着
+ */
 static void
 vhost_scsi_do_evt_work(struct vhost_scsi *vs, struct vhost_scsi_evt *evt)
 {
@@ -467,6 +695,21 @@ vhost_scsi_do_evt_work(struct vhost_scsi *vs, struct vhost_scsi_evt *evt)
 	unsigned out, in;
 	int head, ret;
 
+	/*
+	 * 在以下使用vhost_scsi->vs_events_missed:
+	 *   - drivers/vhost/scsi.c|483| <<vhost_scsi_allocate_evt>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|490| <<vhost_scsi_allocate_evt>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|530| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|559| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|565| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|579| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|583| <<vhost_scsi_do_evt_work>> if (vs->vs_events_missed) {
+	 *   - drivers/vhost/scsi.c|585| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = false;
+	 *   - drivers/vhost/scsi.c|1693| <<vhost_scsi_evt_handle_kick>> if (vs->vs_events_missed)
+	 *   - drivers/vhost/scsi.c|2131| <<vhost_scsi_open>> vs->vs_events_missed = false;
+	 *   - drivers/vhost/scsi.c|2221| <<vhost_scsi_ioctl(VHOST_SCSI_SET_EVENTS_MISSED)>> vs->vs_events_missed = events_missed;
+	 *   - drivers/vhost/scsi.c|2226| <<vhost_scsi_ioctl(VHOST_SCSI_GET_EVENTS_MISSED)>> events_missed = vs->vs_events_missed;
+	 */
 	if (!vhost_vq_get_backend(vq)) {
 		vs->vs_events_missed = true;
 		return;
@@ -474,6 +717,25 @@ vhost_scsi_do_evt_work(struct vhost_scsi *vs, struct vhost_scsi_evt *evt)
 
 again:
 	vhost_disable_notify(&vs->dev, vq);
+	/*
+	 * called by:
+	 *   - drivers/vhost/net.c|583| <<vhost_net_tx_get_vq_desc>> int r = vhost_get_vq_desc(
+	 *                tvq, tvq->iov, ARRAY_SIZE(tvq->iov), out_num, in_num, NULL, NULL);
+	 *   - drivers/vhost/net.c|595| <<vhost_net_tx_get_vq_desc>> r = vhost_get_vq_desc(
+	 *                tvq, tvq->iov, ARRAY_SIZE(tvq->iov), out_num, in_num, NULL, NULL);
+	 *   - drivers/vhost/net.c|1041| <<get_rx_bufs>> r = vhost_get_vq_desc(
+	 *                vq, vq->iov + seg, ARRAY_SIZE(vq->iov) - seg, &out, &in, log, log_num);
+	 *   - drivers/vhost/scsi.c|477| <<vhost_scsi_do_evt_work>> head = vhost_get_vq_desc(
+	 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+	 *   - drivers/vhost/scsi.c|957| <<vhost_scsi_get_desc>> vc->head = vhost_get_vq_desc(
+	 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &vc->out, &vc->in, NULL, NULL);
+	 *   - drivers/vhost/test.c|61| <<handle_vq>> head = vhost_get_vq_desc(
+	 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+	 *   - drivers/vhost/vsock.c|127| <<vhost_transport_do_send_pkt>> head = vhost_get_vq_desc(
+	 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+	 *   - drivers/vhost/vsock.c|509| <<vhost_vsock_handle_tx_kick>> head = vhost_get_vq_desc(
+	 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+	 */
 	head = vhost_get_vq_desc(vq, vq->iov,
 			ARRAY_SIZE(vq->iov), &out, &in,
 			NULL, NULL);
@@ -488,6 +750,15 @@ vhost_scsi_do_evt_work(struct vhost_scsi *vs, struct vhost_scsi_evt *evt)
 		return;
 	}
 
+	/*
+	 * struct virtio_scsi_event {
+	 *     __virtio32 event;
+	 *     __u8 lun[8];
+	 *     __virtio32 reason;
+	 * } __attribute__((packed));
+	 *
+	 * 对于event, 就一个desc, 不会是两个!
+	 */
 	if ((vq->iov[out].iov_len != sizeof(struct virtio_scsi_event))) {
 		vq_err(vq, "Expecting virtio_scsi_event, got %zu bytes\n",
 				vq->iov[out].iov_len);
@@ -500,14 +771,25 @@ vhost_scsi_do_evt_work(struct vhost_scsi *vs, struct vhost_scsi_evt *evt)
 		vs->vs_events_missed = false;
 	}
 
+	/*
+	 * struct virtio_scsi_event __user *eventp;
+	 */
 	eventp = vq->iov[out].iov_base;
 	ret = __copy_to_user(eventp, event, sizeof(*event));
+	/*
+	 * 这里被vq保护着, 可以log!
+	 */
 	if (!ret)
 		vhost_add_used_and_signal(&vs->dev, vq, head, 0);
 	else
 		vq_err(vq, "Faulted on vhost_scsi_send_event\n");
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|554| <<vhost_scsi_evt_work>> vhost_scsi_complete_events(vs, false);
+ *   - drivers/vhost/scsi.c|1580| <<vhost_scsi_send_evt>> vhost_scsi_complete_events(vs, true);
+ */
 static void vhost_scsi_complete_events(struct vhost_scsi *vs, bool drop)
 {
 	struct vhost_virtqueue *vq = &vs->vqs[VHOST_SCSI_VQ_EVT].vq;
@@ -515,22 +797,44 @@ static void vhost_scsi_complete_events(struct vhost_scsi *vs, bool drop)
 	struct llist_node *llnode;
 
 	mutex_lock(&vq->mutex);
+	/*
+	 * 在以下使用vhost_scsi->vs_event_list:
+	 *   - drivers/vhost/scsi.c|541| <<vhost_scsi_complete_events>> llnode = llist_del_all(&vs->vs_event_list);
+	 *   - drivers/vhost/scsi.c|1578| <<vhost_scsi_send_evt>> llist_add(&evt->list, &vs->vs_event_list);
+	 */
 	llnode = llist_del_all(&vs->vs_event_list);
 	llist_for_each_entry_safe(evt, t, llnode, list) {
 		if (!drop)
 			vhost_scsi_do_evt_work(vs, evt);
+		/*
+		 * 只在此处调用
+		 */
 		vhost_scsi_free_evt(vs, evt);
 	}
 	mutex_unlock(&vq->mutex);
 }
 
+/*
+ * 在以下使用vhost_scsi->vs_event_work:
+ *   - drivers/vhost/scsi.c|1623| <<vhost_scsi_send_evt>> if (!vhost_vq_work_queue(vq, &vs->vs_event_work))
+ *   - drivers/vhost/scsi.c|2067| <<vhost_scsi_open>> vhost_work_init(&vs->vs_event_work, vhost_scsi_evt_work);
+ */
 static void vhost_scsi_evt_work(struct vhost_work *work)
 {
 	struct vhost_scsi *vs = container_of(work, struct vhost_scsi,
 					     vs_event_work);
+	/*
+	 * called by:
+	 *   - drivers/vhost/scsi.c|554| <<vhost_scsi_evt_work>> vhost_scsi_complete_events(vs, false);
+	 *   - drivers/vhost/scsi.c|1580| <<vhost_scsi_send_evt>> vhost_scsi_complete_events(vs, true);
+	 */
 	vhost_scsi_complete_events(vs, false);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|821| <<vhost_scsi_complete_cmd_work>> if (cmd->saved_iter_addr && vhost_scsi_copy_sgl_to_iov(cmd)) {
+ */
 static int vhost_scsi_copy_sgl_to_iov(struct vhost_scsi_cmd *cmd)
 {
 	struct iov_iter *iter = &cmd->saved_iter;
@@ -558,6 +862,10 @@ static int vhost_scsi_copy_sgl_to_iov(struct vhost_scsi_cmd *cmd)
  * This is scheduled in the vhost work queue so we are called with the owner
  * process mm and can access the vring.
  */
+/*
+ * 在以下使用vhost_scsi_complete_cmd_work():
+ *   - vhost_work_init(&svq->completion_work, vhost_scsi_complete_cmd_work);
+ */
 static void vhost_scsi_complete_cmd_work(struct vhost_work *work)
 {
 	struct vhost_scsi_virtqueue *svq = container_of(work,
@@ -578,9 +886,16 @@ static void vhost_scsi_complete_cmd_work(struct vhost_work *work)
 			cmd, se_cmd->residual_count, se_cmd->scsi_status);
 		memset(&v_rsp, 0, sizeof(v_rsp));
 
+		/*
+		 * 只在此处调用vhost_scsi_copy_sgl_to_iov()
+		 */
 		if (cmd->saved_iter_addr && vhost_scsi_copy_sgl_to_iov(cmd)) {
 			v_rsp.response = VIRTIO_SCSI_S_BAD_TARGET;
 		} else {
+			/*
+			 * 就算是这里也看不出是好是坏!!!
+			 * 谁会看status???
+			 */
 			v_rsp.resid = cpu_to_vhost32(cmd->tvc_vq,
 						     se_cmd->residual_count);
 			/* TODO is status_qualifier field needed? */
@@ -604,10 +919,22 @@ static void vhost_scsi_complete_cmd_work(struct vhost_work *work)
 		vhost_scsi_release_cmd_res(se_cmd);
 	}
 
+	/*
+	 * called by:
+	 *   - drivers/vhost/scsi.c|859| <<vhost_scsi_complete_cmd_work>> vhost_signal(&svq->vs->dev, &svq->vq);
+	 *   - drivers/vhost/vhost.c|3167| <<vhost_add_used_and_signal>> vhost_signal(dev, vq);
+	 *   - drivers/vhost/vhost.c|3182| <<vhost_add_used_and_signal_n>> vhost_signal(dev, vq);
+	 *   - drivers/vhost/vsock.c|270| <<vhost_transport_do_send_pkt>> vhost_signal(&vsock->dev, vq);
+	 *   - drivers/vhost/vsock.c|587| <<vhost_vsock_handle_tx_kick>> vhost_signal(&vsock->dev, vq);
+	 */
 	if (signal)
 		vhost_signal(&svq->vs->dev, &svq->vq);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1496| <<vhost_scsi_handle_vq>> cmd = vhost_scsi_get_cmd(vq, tpg, cdb, tag, lun, task_attr,
+ */
 static struct vhost_scsi_cmd *
 vhost_scsi_get_cmd(struct vhost_virtqueue *vq, struct vhost_scsi_tpg *tpg,
 		   unsigned char *cdb, u64 scsi_tag, u16 lun, u8 task_attr,
@@ -929,6 +1256,29 @@ static void vhost_scsi_target_queue_cmd(struct vhost_scsi_cmd *cmd)
 	target_submit(se_cmd);
 }
 
+/*
+ * struct virtio_scsi_ctrl_tmf_resp {
+ *     __u8 response;
+ * } __attribute__((packed));
+ * 
+ * struct virtio_scsi_ctrl_an_resp {
+ *     __virtio32 event_actual;
+ *     __u8 response;
+ * } __attribute__((packed));
+ *
+ * struct virtio_scsi_cmd_resp {
+ *     __virtio32 sense_len;           // Sense data length
+ *     __virtio32 resid;               // Residual bytes in data buffer
+ *     __virtio16 status_qualifier;    // Status qualifier
+ *     __u8 status;            // Command completion status
+ *     __u8 response;          // Response values
+ *     __u8 sense[VIRTIO_SCSI_SENSE_SIZE];
+ * } __attribute__((packed));
+ *
+ * called by:
+ *   - drivers/vhost/scsi.c|1510| <<vhost_scsi_handle_vq>> vhost_scsi_send_bad_target(vs, vq, vc.head, vc.out);
+ *   - drivers/vhost/scsi.c|1827| <<vhost_scsi_ctl_handle_vq>> vhost_scsi_send_bad_target(vs, vq, vc.head, vc.out);
+ */
 static void
 vhost_scsi_send_bad_target(struct vhost_scsi *vs,
 			   struct vhost_virtqueue *vq,
@@ -940,6 +1290,9 @@ vhost_scsi_send_bad_target(struct vhost_scsi *vs,
 
 	memset(&rsp, 0, sizeof(rsp));
 	rsp.response = VIRTIO_SCSI_S_BAD_TARGET;
+	/*
+	 * 怎么可以做这种假设?????!!!!
+	 */
 	resp = vq->iov[out].iov_base;
 	ret = __copy_to_user(resp, &rsp, sizeof(rsp));
 	if (!ret)
@@ -948,12 +1301,36 @@ vhost_scsi_send_bad_target(struct vhost_scsi *vs,
 		pr_err("Faulted on virtio_scsi_cmd_resp\n");
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1093| <<vhost_scsi_handle_vq>> ret = vhost_scsi_get_desc(vs, vq, &vc);
+ *   - drivers/vhost/scsi.c|1418| <<vhost_scsi_ctl_handle_vq>> ret = vhost_scsi_get_desc(vs, vq, &vc);
+ */
 static int
 vhost_scsi_get_desc(struct vhost_scsi *vs, struct vhost_virtqueue *vq,
 		    struct vhost_scsi_ctx *vc)
 {
 	int ret = -ENXIO;
 
+	/*
+	 * called by:
+	 *   - drivers/vhost/net.c|583| <<vhost_net_tx_get_vq_desc>> int r = vhost_get_vq_desc(
+	 *                tvq, tvq->iov, ARRAY_SIZE(tvq->iov), out_num, in_num, NULL, NULL);
+	 *   - drivers/vhost/net.c|595| <<vhost_net_tx_get_vq_desc>> r = vhost_get_vq_desc(
+	 *                tvq, tvq->iov, ARRAY_SIZE(tvq->iov), out_num, in_num, NULL, NULL);
+	 *   - drivers/vhost/net.c|1041| <<get_rx_bufs>> r = vhost_get_vq_desc(
+	 *                vq, vq->iov + seg, ARRAY_SIZE(vq->iov) - seg, &out, &in, log, log_num);
+	 *   - drivers/vhost/scsi.c|477| <<vhost_scsi_do_evt_work>> head = vhost_get_vq_desc(
+	 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+	 *   - drivers/vhost/scsi.c|957| <<vhost_scsi_get_desc>> vc->head = vhost_get_vq_desc(
+	 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &vc->out, &vc->in, NULL, NULL);
+	 *   - drivers/vhost/test.c|61| <<handle_vq>> head = vhost_get_vq_desc(
+	 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+	 *   - drivers/vhost/vsock.c|127| <<vhost_transport_do_send_pkt>> head = vhost_get_vq_desc(
+	 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+	 *   - drivers/vhost/vsock.c|509| <<vhost_vsock_handle_tx_kick>> head = vhost_get_vq_desc(
+	 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+	 */
 	vc->head = vhost_get_vq_desc(vq, vq->iov,
 				     ARRAY_SIZE(vq->iov), &vc->out, &vc->in,
 				     NULL, NULL);
@@ -998,6 +1375,11 @@ vhost_scsi_get_desc(struct vhost_scsi *vs, struct vhost_virtqueue *vq,
 	return ret;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1432| <<vhost_scsi_handle_vq>> ret = vhost_scsi_chk_size(vq, &vc);
+ *   - drivers/vhost/scsi.c|1937| <<vhost_scsi_ctl_handle_vq>> ret = vhost_scsi_chk_size(vq, &vc);
+ */
 static int
 vhost_scsi_chk_size(struct vhost_virtqueue *vq, struct vhost_scsi_ctx *vc)
 {
@@ -1016,6 +1398,11 @@ vhost_scsi_chk_size(struct vhost_virtqueue *vq, struct vhost_scsi_ctx *vc)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1367| <<vhost_scsi_handle_vq>> ret = vhost_scsi_get_req(vq, &vc, &tpg);
+ *   - drivers/vhost/scsi.c|1809| <<vhost_scsi_ctl_handle_vq>> ret = vhost_scsi_get_req(vq, &vc, &tpg);
+ */
 static int
 vhost_scsi_get_req(struct vhost_virtqueue *vq, struct vhost_scsi_ctx *vc,
 		   struct vhost_scsi_tpg **tpgp)
@@ -1054,6 +1441,10 @@ static u16 vhost_buf_to_lun(u8 *lun_buf)
 	return ((lun_buf[2] << 8) | lun_buf[3]) & 0x3FFF;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1826| <<vhost_scsi_handle_kick>> vhost_scsi_handle_vq(vs, vq);
+ */
 static void
 vhost_scsi_handle_vq(struct vhost_scsi *vs, struct vhost_virtqueue *vq)
 {
@@ -1086,6 +1477,11 @@ vhost_scsi_handle_vq(struct vhost_scsi *vs, struct vhost_virtqueue *vq)
 	vhost_disable_notify(&vs->dev, vq);
 
 	do {
+		/*
+		 * called by:
+		 *   - drivers/vhost/scsi.c|1093| <<vhost_scsi_handle_vq>> ret = vhost_scsi_get_desc(vs, vq, &vc);
+		 *   - drivers/vhost/scsi.c|1418| <<vhost_scsi_ctl_handle_vq>> ret = vhost_scsi_get_desc(vs, vq, &vc);
+		 */
 		ret = vhost_scsi_get_desc(vs, vq, &vc);
 		if (ret)
 			goto err;
@@ -1212,6 +1608,9 @@ vhost_scsi_handle_vq(struct vhost_scsi *vs, struct vhost_virtqueue *vq)
 				scsi_command_size(cdb), VHOST_SCSI_MAX_CDB_SIZE);
 				goto err;
 		}
+		/*
+		 * 只在此处调用
+		 */
 		cmd = vhost_scsi_get_cmd(vq, tpg, cdb, tag, lun, task_attr,
 					 exp_data_len + prot_bytes,
 					 data_direction);
@@ -1259,16 +1658,35 @@ vhost_scsi_handle_vq(struct vhost_scsi *vs, struct vhost_virtqueue *vq)
 			break;
 		else if (ret == -EIO)
 			vhost_scsi_send_bad_target(vs, vq, vc.head, vc.out);
+		/*
+		 * 调用vhost_scsi_send_bad_target()的地方:
+		 *   - drivers/vhost/scsi.c|1510| <<vhost_scsi_handle_vq>> vhost_scsi_send_bad_target(vs, vq, vc.head, vc.out);
+		 *   - drivers/vhost/scsi.c|1827| <<vhost_scsi_ctl_handle_vq>> vhost_scsi_send_bad_target(vs, vq, vc.head, vc.out);
+		 */
 	} while (likely(!vhost_exceeds_weight(vq, ++c, 0)));
 out:
 	mutex_unlock(&vq->mutex);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1522| <<vhost_scsi_tmf_resp_work>> vhost_scsi_send_tmf_resp(tmf->vhost,
+ *                   &tmf->svq->vq, tmf->in_iovs, tmf->vq_desc, &tmf->resp_iov, resp_code);
+ *   - drivers/vhost/scsi.c|1584| <<vhost_scsi_handle_tmf>> vhost_scsi_send_tmf_resp(vs, vq,
+ *                   vc->in, vc->head, &vq->iov[vc->out], VIRTIO_SCSI_S_FUNCTION_REJECTED);
+ */
 static void
 vhost_scsi_send_tmf_resp(struct vhost_scsi *vs, struct vhost_virtqueue *vq,
 			 int in_iovs, int vq_desc, struct iovec *resp_iov,
 			 int tmf_resp_code)
 {
+	/*
+	 * 大小一定是1个byte, 怎么都不会垮两个desc了!
+	 *
+	 * struct virtio_scsi_ctrl_tmf_resp {
+	 *     __u8 response;
+	 * } __attribute__((packed));
+	 */
 	struct virtio_scsi_ctrl_tmf_resp rsp;
 	struct iov_iter iov_iter;
 	int ret;
@@ -1279,6 +1697,9 @@ vhost_scsi_send_tmf_resp(struct vhost_scsi *vs, struct vhost_virtqueue *vq,
 
 	iov_iter_init(&iov_iter, ITER_DEST, resp_iov, in_iovs, sizeof(rsp));
 
+	/*
+	 * copy, 可以是多个desc
+	 */
 	ret = copy_to_iter(&rsp, sizeof(rsp), &iov_iter);
 	if (likely(ret == sizeof(rsp)))
 		vhost_add_used_and_signal(&vs->dev, vq, vq_desc, 0);
@@ -1286,6 +1707,16 @@ vhost_scsi_send_tmf_resp(struct vhost_scsi *vs, struct vhost_virtqueue *vq,
 		pr_err("Faulted on virtio_scsi_ctrl_tmf_resp\n");
 }
 
+/*
+ * 在以下使用vhost_scsi_tmf->vwork:
+ *   - drivers/vhost/scsi.c|1537| <<vhost_scsi_tmf_flush_work>> if (!vhost_vq_work_queue(vq, &tmf->vwork))
+ *   - drivers/vhost/scsi.c|1565| <<vhost_scsi_handle_tmf>> vhost_work_init(&tmf->vwork, vhost_scsi_tmf_resp_work);
+ *
+ * 在以下使用vhost_scsi_tmf_resp_work():
+ *   - drivers/vhost/scsi.c|1565| <<vhost_scsi_handle_tmf>> vhost_work_init(&tmf->vwork, vhost_scsi_tmf_resp_work);
+ *
+ * 一个work对应一个tmf cmd
+ */
 static void vhost_scsi_tmf_resp_work(struct vhost_work *work)
 {
 	struct vhost_scsi_tmf *tmf = container_of(work, struct vhost_scsi_tmf,
@@ -1297,25 +1728,71 @@ static void vhost_scsi_tmf_resp_work(struct vhost_work *work)
 	else
 		resp_code = VIRTIO_SCSI_S_FUNCTION_REJECTED;
 
+	/*
+	 * called by:
+	 *   - drivers/vhost/scsi.c|1522| <<vhost_scsi_tmf_resp_work>> vhost_scsi_send_tmf_resp(tmf->vhost,
+	 *                   &tmf->svq->vq, tmf->in_iovs, tmf->vq_desc, &tmf->resp_iov, resp_code);
+	 *   - drivers/vhost/scsi.c|1584| <<vhost_scsi_handle_tmf>> vhost_scsi_send_tmf_resp(vs, vq,
+	 *                   vc->in, vc->head, &vq->iov[vc->out], VIRTIO_SCSI_S_FUNCTION_REJECTED);
+	 */
 	vhost_scsi_send_tmf_resp(tmf->vhost, &tmf->svq->vq, tmf->in_iovs,
 				 tmf->vq_desc, &tmf->resp_iov, resp_code);
+	/*
+	 * called by:
+	 *   - drivers/vhost/scsi.c|1524| <<vhost_scsi_tmf_resp_work>> vhost_scsi_release_tmf_res(tmf);
+	 *   - drivers/vhost/scsi.c|1538| <<vhost_scsi_tmf_flush_work>> vhost_scsi_release_tmf_res(tmf);
+	 *   - drivers/vhost/scsi.c|1577| <<vhost_scsi_handle_tmf>> vhost_scsi_release_tmf_res(tmf);
+	 */
 	vhost_scsi_release_tmf_res(tmf);
 }
 
+/*
+ * 在以下使用vhost_scsi_tmf_flush_work():
+ *   - drivers/vhost/scsi.c|1660| <<vhost_scsi_handle_tmf>> INIT_WORK(&tmf->flush_work, vhost_scsi_tmf_flush_work);
+ */
 static void vhost_scsi_tmf_flush_work(struct work_struct *work)
 {
 	struct vhost_scsi_tmf *tmf = container_of(work, struct vhost_scsi_tmf,
 						 flush_work);
 	struct vhost_virtqueue *vq = &tmf->svq->vq;
+	/*
+	 * called by:
+	 *   - drivers/vhost/net.c|1432| <<vhost_net_flush>> vhost_dev_flush(&n->dev);
+	 *   - drivers/vhost/net.c|1623| <<vhost_net_set_backend>> vhost_dev_flush(&n->dev);
+	 *   - drivers/vhost/scsi.c|1639| <<vhost_scsi_tmf_flush_work>> vhost_dev_flush(vq->dev);
+	 *   - drivers/vhost/scsi.c|2044| <<vhost_scsi_flush>> vhost_dev_flush(&vs->dev);
+	 *   - drivers/vhost/test.c|165| <<vhost_test_flush>> vhost_dev_flush(&n->dev);
+	 *   - drivers/vhost/vhost.c|1050| <<vhost_dev_stop>> vhost_dev_flush(dev);
+	 *   - drivers/vhost/vhost.c|2147| <<vhost_vring_ioctl>> vhost_dev_flush(vq->poll.dev);
+	 *   - drivers/vhost/vhost.h|61| <<vhost_vring_ioctl>> void vhost_dev_flush(struct vhost_dev *dev);
+	 *   - drivers/vhost/vsock.c|751| <<vhost_vsock_flush>> vhost_dev_flush(&vsock->dev);
+	 */
 	/*
 	 * Make sure we have sent responses for other commands before we
 	 * send our response.
 	 */
 	vhost_dev_flush(vq->dev);
+	/*
+	 * 在以下使用vhost_vq_work_queue():
+	 *   - drivers/vhost/scsi.c|475| <<vhost_scsi_release_cmd>> if (!vhost_vq_work_queue(&svq->vq, &svq->completion_work))
+	 *   - drivers/vhost/scsi.c|1688| <<vhost_scsi_tmf_flush_work>> if (!vhost_vq_work_queue(vq, &tmf->vwork))
+	 *   - drivers/vhost/scsi.c|2022| <<vhost_scsi_send_evt>> if (!vhost_vq_work_queue(vq, &vs->vs_event_work))
+	 *   - drivers/vhost/vhost.c|357| <<vhost_poll_queue>> vhost_vq_work_queue(poll->vq, &poll->work);
+	 *   - drivers/vhost/vsock.c|319| <<vhost_transport_send_pkt>> vhost_vq_work_queue(&vsock->vqs[VSOCK_VQ_RX], &vsock->send_pkt_work);
+	 *   - drivers/vhost/vsock.c|662| <<vhost_vsock_start>> vhost_vq_work_queue(&vsock->vqs[VSOCK_VQ_RX], &vsock->send_pkt_work);
+	 *
+	 * 在以下使用vhost_scsi_tmf->vwork:
+	 *   - drivers/vhost/scsi.c|1537| <<vhost_scsi_tmf_flush_work>> if (!vhost_vq_work_queue(vq, &tmf->vwork))
+	 *   - drivers/vhost/scsi.c|1565| <<vhost_scsi_handle_tmf>> vhost_work_init(&tmf->vwork, vhost_scsi_tmf_resp_work);
+	 */
 	if (!vhost_vq_work_queue(vq, &tmf->vwork))
 		vhost_scsi_release_tmf_res(tmf);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1700| <<vhost_scsi_ctl_handle_vq>> vhost_scsi_handle_tmf(vs, tpg, vq, &v_req.tmf, &vc);
+ */
 static void
 vhost_scsi_handle_tmf(struct vhost_scsi *vs, struct vhost_scsi_tpg *tpg,
 		      struct vhost_virtqueue *vq,
@@ -1335,19 +1812,57 @@ vhost_scsi_handle_tmf(struct vhost_scsi *vs, struct vhost_scsi_tpg *tpg,
 		goto send_reject;
 	}
 
+	/*
+	 * struct virtio_scsi_ctrl_tmf_req {
+	 *     __virtio32 type;
+	 *     __virtio32 subtype;
+	 *     __u8 lun[8];
+	 *     __virtio64 tag;
+	 * } __attribute__((packed));
+	 */
 	tmf = kzalloc(sizeof(*tmf), GFP_KERNEL);
 	if (!tmf)
 		goto send_reject;
 
+	/*
+	 * 在以下使用vhost_scsi_tmf->flush_work:
+	 *   - drivers/vhost/scsi.c|457| <<vhost_scsi_release_cmd>> schedule_work(&tmf->flush_work);
+	 *   - drivers/vhost/scsi.c|1660| <<vhost_scsi_handle_tmf>> INIT_WORK(&tmf->flush_work, vhost_scsi_tmf_flush_work);
+	 */
 	INIT_WORK(&tmf->flush_work, vhost_scsi_tmf_flush_work);
+	/*
+	 * 在以下使用vhost_scsi_tmf->vwork:
+	 *   - drivers/vhost/scsi.c|1537| <<vhost_scsi_tmf_flush_work>> if (!vhost_vq_work_queue(vq, &tmf->vwork))
+	 *   - drivers/vhost/scsi.c|1565| <<vhost_scsi_handle_tmf>> vhost_work_init(&tmf->vwork, vhost_scsi_tmf_resp_work);
+	 */
 	vhost_work_init(&tmf->vwork, vhost_scsi_tmf_resp_work);
 	tmf->vhost = vs;
 	tmf->svq = svq;
+	/*
+	 * 大小一定是1个byte, 怎么都不会垮两个desc了!
+	 *
+	 * struct virtio_scsi_ctrl_tmf_resp { 
+	 *     __u8 response;
+	 * } __attribute__((packed));
+	 *
+	 * 这里假设一定是一个????
+	 */
 	tmf->resp_iov = vq->iov[vc->out];
 	tmf->vq_desc = vc->head;
 	tmf->in_iovs = vc->in;
 	tmf->inflight = vhost_scsi_get_inflight(vq);
 
+	/*
+	 * called by:
+	 *   - drivers/infiniband/ulp/srpt/ib_srpt.c|1667| <<srpt_handle_tsk_mgmt>> rc = target_submit_tmr(&send_ioctx->cmd, sess, NULL,
+	 *   - drivers/scsi/elx/efct/efct_lio.c|1449| <<efct_scsi_recv_tmf>> rc = target_submit_tmr(&ocp->cmd, se_sess, NULL, lun, ocp, tmr_func,
+	 *   - drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c|2799| <<ibmvscsis_parse_task>> rc = target_submit_tmr(&cmd->se_cmd, nexus->se_sess, NULL,
+	 *   - drivers/scsi/qla2xxx/tcm_qla2xxx.c|617| <<tcm_qla2xxx_handle_tmr>> return target_submit_tmr(se_cmd, sess->se_sess, NULL, lun, mcmd,
+	 *   - drivers/target/loopback/tcm_loop.c|216| <<tcm_loop_issue_tmr>> rc = target_submit_tmr(se_cmd, se_sess, tl_cmd->tl_sense_buf, lun,
+	 *   - drivers/target/tcm_fc/tfc_cmd.c|365| <<ft_send_tm>> rc = target_submit_tmr(&cmd->se_cmd, cmd->sess->se_sess,
+	 *   - drivers/vhost/scsi.c|1701| <<vhost_scsi_handle_tmf>> if (target_submit_tmr(&tmf->se_cmd, tpg->tpg_nexus->tvn_se_sess, NULL,
+	 *   - drivers/xen/xen-scsiback.c|626| <<scsiback_device_action>> rc = target_submit_tmr(&pending_req->se_cmd, nexus->tvn_se_sess,
+	 */
 	if (target_submit_tmr(&tmf->se_cmd, tpg->tpg_nexus->tvn_se_sess, NULL,
 			      vhost_buf_to_lun(vtmf->lun), NULL,
 			      TMR_LUN_RESET, GFP_KERNEL, 0,
@@ -1359,10 +1874,21 @@ vhost_scsi_handle_tmf(struct vhost_scsi *vs, struct vhost_scsi_tpg *tpg,
 	return;
 
 send_reject:
+	/*
+	 * called by:
+	 *   - drivers/vhost/scsi.c|1522| <<vhost_scsi_tmf_resp_work>> vhost_scsi_send_tmf_resp(tmf->vhost,
+	 *                   &tmf->svq->vq, tmf->in_iovs, tmf->vq_desc, &tmf->resp_iov, resp_code);
+	 *   - drivers/vhost/scsi.c|1584| <<vhost_scsi_handle_tmf>> vhost_scsi_send_tmf_resp(vs, vq,
+	 *                   vc->in, vc->head, &vq->iov[vc->out], VIRTIO_SCSI_S_FUNCTION_REJECTED);
+	 */
 	vhost_scsi_send_tmf_resp(vs, vq, vc->in, vc->head, &vq->iov[vc->out],
 				 VIRTIO_SCSI_S_FUNCTION_REJECTED);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1702| <<vhost_scsi_ctl_handle_vq>> vhost_scsi_send_an_resp(vs, vq, &vc);
+ */
 static void
 vhost_scsi_send_an_resp(struct vhost_scsi *vs,
 			struct vhost_virtqueue *vq,
@@ -1378,6 +1904,16 @@ vhost_scsi_send_an_resp(struct vhost_scsi *vs,
 
 	iov_iter_init(&iov_iter, ITER_DEST, &vq->iov[vc->out], vc->in, sizeof(rsp));
 
+	/*
+	 * called by:
+	 *   - drivers/vhost/net.c|969| <<handle_tx_zerocopy>> vhost_add_used_and_signal(&net->dev, vq, head, 0);
+	 *   - drivers/vhost/scsi.c|529| <<vhost_scsi_do_evt_work>> vhost_add_used_and_signal(&vs->dev, vq, head, 0);
+	 *   - drivers/vhost/scsi.c|969| <<vhost_scsi_send_bad_target>> vhost_add_used_and_signal(&vs->dev, vq, head, 0);
+	 *   - drivers/vhost/scsi.c|1331| <<vhost_scsi_send_tmf_resp>> vhost_add_used_and_signal(&vs->dev, vq, vq_desc, 0);
+	 *   - drivers/vhost/scsi.c|1430| <<vhost_scsi_send_an_resp>> vhost_add_used_and_signal(&vs->dev, vq, vc->head, 0);
+	 *   - drivers/vhost/test.c|87| <<handle_vq>> vhost_add_used_and_signal(&n->dev, vq, head, 0);
+	 */
+
 	ret = copy_to_iter(&rsp, sizeof(rsp), &iov_iter);
 	if (likely(ret == sizeof(rsp)))
 		vhost_add_used_and_signal(&vs->dev, vq, vc->head, 0);
@@ -1385,6 +1921,10 @@ vhost_scsi_send_an_resp(struct vhost_scsi *vs,
 		pr_err("Faulted on virtio_scsi_ctrl_an_resp\n");
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1726| <<vhost_scsi_ctl_handle_kick>> vhost_scsi_ctl_handle_vq(vs, vq);
+ */
 static void
 vhost_scsi_ctl_handle_vq(struct vhost_scsi *vs, struct vhost_virtqueue *vq)
 {
@@ -1411,10 +1951,28 @@ vhost_scsi_ctl_handle_vq(struct vhost_scsi *vs, struct vhost_virtqueue *vq)
 	vhost_disable_notify(&vs->dev, vq);
 
 	do {
+		/*
+		 * called by:
+		 *   - drivers/vhost/scsi.c|1093| <<vhost_scsi_handle_vq>> ret = vhost_scsi_get_desc(vs, vq, &vc);
+		 *   - drivers/vhost/scsi.c|1418| <<vhost_scsi_ctl_handle_vq>> ret = vhost_scsi_get_desc(vs, vq, &vc);
+		 *
+		 * 可以假设log只有一个吗???
+		 */
 		ret = vhost_scsi_get_desc(vs, vq, &vc);
 		if (ret)
 			goto err;
 
+		/*
+		 * struct vhost_scsi_ctx {
+		 *     int head;
+		 *     unsigned int out, in;
+		 *     size_t req_size, rsp_size;
+		 *     size_t out_size, in_size;
+		 *     u8 *target, *lunp;
+		 *     void *req;
+		 *     struct iov_iter out_iter;
+		 * };
+		 */
 		/*
 		 * Get the request type first in order to setup
 		 * other parameters dependent on the type.
@@ -1470,10 +2028,23 @@ vhost_scsi_ctl_handle_vq(struct vhost_scsi *vs, struct vhost_virtqueue *vq)
 		vc.req += typ_size;
 		vc.req_size -= typ_size;
 
+		/*
+		 * called by:
+		 *   - drivers/vhost/scsi.c|1367| <<vhost_scsi_handle_vq>> ret = vhost_scsi_get_req(vq, &vc, &tpg);
+		 *   - drivers/vhost/scsi.c|1809| <<vhost_scsi_ctl_handle_vq>> ret = vhost_scsi_get_req(vq, &vc, &tpg);
+		 *
+		 * 有ret err立刻跳下去!!!
+		 */
 		ret = vhost_scsi_get_req(vq, &vc, &tpg);
 		if (ret)
 			goto err;
 
+		/*
+		 * TMF
+		 * - virtio_scsi_ctrl_tmf_resp
+		 * AN
+		 * - virtio_scsi_ctrl_an_resp
+		 */
 		if (v_req.type == VIRTIO_SCSI_T_TMF)
 			vhost_scsi_handle_tmf(vs, tpg, vq, &v_req.tmf, &vc);
 		else
@@ -1489,11 +2060,20 @@ vhost_scsi_ctl_handle_vq(struct vhost_scsi *vs, struct vhost_virtqueue *vq)
 			break;
 		else if (ret == -EIO)
 			vhost_scsi_send_bad_target(vs, vq, vc.head, vc.out);
+		/*
+		 * 调用vhost_scsi_send_bad_target()的地方:
+		 *   - drivers/vhost/scsi.c|1510| <<vhost_scsi_handle_vq>> vhost_scsi_send_bad_target(vs, vq, vc.head, vc.out);
+		 *   - drivers/vhost/scsi.c|1827| <<vhost_scsi_ctl_handle_vq>> vhost_scsi_send_bad_target(vs, vq, vc.head, vc.out);
+		 */
 	} while (likely(!vhost_exceeds_weight(vq, ++c, 0)));
 out:
 	mutex_unlock(&vq->mutex);
 }
 
+/*
+ * 在以下使用vhost_scsi_ctl_handle_kick():
+ *   - drivers/vhost/scsi.c|2271| <<vhost_scsi_open>> vs->vqs[VHOST_SCSI_VQ_CTL].vq.handle_kick = vhost_scsi_ctl_handle_kick;
+ */
 static void vhost_scsi_ctl_handle_kick(struct vhost_work *work)
 {
 	struct vhost_virtqueue *vq = container_of(work, struct vhost_virtqueue,
@@ -1504,6 +2084,11 @@ static void vhost_scsi_ctl_handle_kick(struct vhost_work *work)
 	vhost_scsi_ctl_handle_vq(vs, vq);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1594| <<vhost_scsi_evt_handle_kick>> vhost_scsi_send_evt(vs, vq, NULL, NULL, VIRTIO_SCSI_T_NO_EVENT,
+ *   - drivers/vhost/scsi.c|2222| <<vhost_scsi_do_plug>> vhost_scsi_send_evt(vs, vq, tpg, lun, VIRTIO_SCSI_T_TRANSPORT_RESET, reason);
+ */
 static void
 vhost_scsi_send_evt(struct vhost_scsi *vs, struct vhost_virtqueue *vq,
 		    struct vhost_scsi_tpg *tpg, struct se_lun *lun,
@@ -1511,6 +2096,9 @@ vhost_scsi_send_evt(struct vhost_scsi *vs, struct vhost_virtqueue *vq,
 {
 	struct vhost_scsi_evt *evt;
 
+	/*
+	 * 只在此处调用
+	 */
 	evt = vhost_scsi_allocate_evt(vs, event, reason);
 	if (!evt)
 		return;
@@ -1528,11 +2116,37 @@ vhost_scsi_send_evt(struct vhost_scsi *vs, struct vhost_virtqueue *vq,
 		evt->event.lun[3] = lun->unpacked_lun & 0xFF;
 	}
 
+	/*
+	 * 在以下使用vhost_scsi->vs_event_list:
+	 *   - drivers/vhost/scsi.c|541| <<vhost_scsi_complete_events>> llnode = llist_del_all(&vs->vs_event_list);
+	 *   - drivers/vhost/scsi.c|1578| <<vhost_scsi_send_evt>> llist_add(&evt->list, &vs->vs_event_list);
+	 */
 	llist_add(&evt->list, &vs->vs_event_list);
+	/*
+	 * 在以下使用vhost_vq_work_queue():
+	 *   - drivers/vhost/scsi.c|475| <<vhost_scsi_release_cmd>> if (!vhost_vq_work_queue(&svq->vq, &svq->completion_work))
+	 *   - drivers/vhost/scsi.c|1688| <<vhost_scsi_tmf_flush_work>> if (!vhost_vq_work_queue(vq, &tmf->vwork))
+	 *   - drivers/vhost/scsi.c|2022| <<vhost_scsi_send_evt>> if (!vhost_vq_work_queue(vq, &vs->vs_event_work))
+	 *   - drivers/vhost/vhost.c|357| <<vhost_poll_queue>> vhost_vq_work_queue(poll->vq, &poll->work);
+	 *   - drivers/vhost/vsock.c|319| <<vhost_transport_send_pkt>> vhost_vq_work_queue(&vsock->vqs[VSOCK_VQ_RX], &vsock->send_pkt_work);
+	 *   - drivers/vhost/vsock.c|662| <<vhost_vsock_start>> vhost_vq_work_queue(&vsock->vqs[VSOCK_VQ_RX], &vsock->send_pkt_work);
+	 *
+	 * 在以下调用vhost_scsi_complete_events():
+	 *   - drivers/vhost/scsi.c|554| <<vhost_scsi_evt_work>> vhost_scsi_complete_events(vs, false);
+	 *   - drivers/vhost/scsi.c|1580| <<vhost_scsi_send_evt>> vhost_scsi_complete_events(vs, true);
+	 *
+	 * 在以下使用vhost_scsi->vs_event_work:
+	 *   - drivers/vhost/scsi.c|1623| <<vhost_scsi_send_evt>> if (!vhost_vq_work_queue(vq, &vs->vs_event_work))
+	 *   - drivers/vhost/scsi.c|2067| <<vhost_scsi_open>> vhost_work_init(&vs->vs_event_work, vhost_scsi_evt_work);
+	 */
 	if (!vhost_vq_work_queue(vq, &vs->vs_event_work))
 		vhost_scsi_complete_events(vs, true);
 }
 
+/*
+ * 在以下使用vhost_scsi_evt_handle_kick():
+ *   - drivers/vhost/scsi.c|2136| <<vhost_scsi_open>> vs->vqs[VHOST_SCSI_VQ_EVT].vq.handle_kick = vhost_scsi_evt_handle_kick;
+ */
 static void vhost_scsi_evt_handle_kick(struct vhost_work *work)
 {
 	struct vhost_virtqueue *vq = container_of(work, struct vhost_virtqueue,
@@ -1543,6 +2157,25 @@ static void vhost_scsi_evt_handle_kick(struct vhost_work *work)
 	if (!vhost_vq_get_backend(vq))
 		goto out;
 
+	/*
+	 * 在以下使用vhost_scsi->vs_events_missed:
+	 *   - drivers/vhost/scsi.c|483| <<vhost_scsi_allocate_evt>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|490| <<vhost_scsi_allocate_evt>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|530| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|559| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|565| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|579| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = true;
+	 *   - drivers/vhost/scsi.c|583| <<vhost_scsi_do_evt_work>> if (vs->vs_events_missed) {
+	 *   - drivers/vhost/scsi.c|585| <<vhost_scsi_do_evt_work>> vs->vs_events_missed = false;
+	 *   - drivers/vhost/scsi.c|1693| <<vhost_scsi_evt_handle_kick>> if (vs->vs_events_missed)
+	 *   - drivers/vhost/scsi.c|2131| <<vhost_scsi_open>> vs->vs_events_missed = false;
+	 *   - drivers/vhost/scsi.c|2221| <<vhost_scsi_ioctl(VHOST_SCSI_SET_EVENTS_MISSED)>> vs->vs_events_missed = events_missed;
+	 *   - drivers/vhost/scsi.c|2226| <<vhost_scsi_ioctl(VHOST_SCSI_GET_EVENTS_MISSED)>> events_missed = vs->vs_events_missed;
+	 *
+	 * 在以下使用vhost_scsi_send_evt():
+	 *   - drivers/vhost/scsi.c|1594| <<vhost_scsi_evt_handle_kick>> vhost_scsi_send_evt(vs, vq, NULL, NULL, VIRTIO_SCSI_T_NO_EVENT,
+	 *   - drivers/vhost/scsi.c|2222| <<vhost_scsi_do_plug>> vhost_scsi_send_evt(vs, vq, tpg, lun,
+	 */
 	if (vs->vs_events_missed)
 		vhost_scsi_send_evt(vs, vq, NULL, NULL, VIRTIO_SCSI_T_NO_EVENT,
 				    0);
@@ -1559,11 +2192,22 @@ static void vhost_scsi_handle_kick(struct vhost_work *work)
 	vhost_scsi_handle_vq(vs, vq);
 }
 
+/*
+ * caled by:
+ *   - drivers/vhost/scsi.c|2367| <<vhost_scsi_set_endpoint>> vhost_scsi_flush(vs);
+ *   - drivers/vhost/scsi.c|2453| <<vhost_scsi_clear_endpoint>> vhost_scsi_flush(vs);
+ *   - drivers/vhost/scsi.c|2487| <<vhost_scsi_clear_endpoint>> vhost_scsi_flush(vs);
+ */
 /* Callers must hold dev mutex */
 static void vhost_scsi_flush(struct vhost_scsi *vs)
 {
 	int i;
 
+	/*
+	 * called by:
+	 *   - drivers/vhost/scsi.c|2143| <<vhost_scsi_flush>> vhost_scsi_init_inflight(vs, vs->old_inflight);
+	 *   - drivers/vhost/scsi.c|2618| <<vhost_scsi_open>> vhost_scsi_init_inflight(vs, NULL);
+	 */
 	/* Init new inflight and remember the old inflight */
 	vhost_scsi_init_inflight(vs, vs->old_inflight);
 
@@ -1575,6 +2219,18 @@ static void vhost_scsi_flush(struct vhost_scsi *vs)
 	for (i = 0; i < vs->dev.nvqs; i++)
 		kref_put(&vs->old_inflight[i]->kref, vhost_scsi_done_inflight);
 
+	/*
+	 * called by:
+	 *   - drivers/vhost/net.c|1432| <<vhost_net_flush>> vhost_dev_flush(&n->dev);
+	 *   - drivers/vhost/net.c|1623| <<vhost_net_set_backend>> vhost_dev_flush(&n->dev);
+	 *   - drivers/vhost/scsi.c|1639| <<vhost_scsi_tmf_flush_work>> vhost_dev_flush(vq->dev);
+	 *   - drivers/vhost/scsi.c|2044| <<vhost_scsi_flush>> vhost_dev_flush(&vs->dev);
+	 *   - drivers/vhost/test.c|165| <<vhost_test_flush>> vhost_dev_flush(&n->dev);
+	 *   - drivers/vhost/vhost.c|1050| <<vhost_dev_stop>> vhost_dev_flush(dev);
+	 *   - drivers/vhost/vhost.c|2147| <<vhost_vring_ioctl>> vhost_dev_flush(vq->poll.dev);
+	 *   - drivers/vhost/vhost.h|61| <<vhost_vring_ioctl>> void vhost_dev_flush(struct vhost_dev *dev);
+	 *   - drivers/vhost/vsock.c|751| <<vhost_vsock_flush>> vhost_dev_flush(&vsock->dev);
+	 */
 	/* Flush both the vhost poll and vhost work */
 	vhost_dev_flush(&vs->dev);
 
@@ -1769,6 +2425,14 @@ vhost_scsi_set_endpoint(struct vhost_scsi *vs,
 			vq = &vs->vqs[i].vq;
 			mutex_lock(&vq->mutex);
 			vhost_vq_set_backend(vq, vs_tpg);
+			/*
+			 * called by:
+			 *   - drivers/vhost/net.c|1658| <<vhost_net_set_backend>> r = vhost_vq_init_access(vq);
+			 *   - drivers/vhost/scsi.c|2285| <<vhost_scsi_set_endpoint>> vhost_vq_init_access(vq);
+			 *   - drivers/vhost/test.c|213| <<vhost_test_run>> r = vhost_vq_init_access(&n->vqs[index]);
+			 *   - drivers/vhost/test.c|306| <<vhost_test_set_backend>> r = vhost_vq_init_access(vq);
+			 *   - drivers/vhost/vsock.c|643| <<vhost_vsock_start>> ret = vhost_vq_init_access(vq);
+			 */
 			vhost_vq_init_access(vq);
 			mutex_unlock(&vq->mutex);
 		}
@@ -1781,6 +2445,12 @@ vhost_scsi_set_endpoint(struct vhost_scsi *vs,
 	 * Act as synchronize_rcu to make sure access to
 	 * old vs->vs_tpg is finished.
 	 */
+	/*
+	 * called by:
+	 *   - drivers/vhost/scsi.c|2367| <<vhost_scsi_set_endpoint>> vhost_scsi_flush(vs);
+	 *   - drivers/vhost/scsi.c|2453| <<vhost_scsi_clear_endpoint>> vhost_scsi_flush(vs);
+	 *   - drivers/vhost/scsi.c|2487| <<vhost_scsi_clear_endpoint>> vhost_scsi_flush(vs);
+	 */
 	vhost_scsi_flush(vs);
 	kfree(vs->vs_tpg);
 	vs->vs_tpg = vs_tpg;
@@ -1866,6 +2536,12 @@ vhost_scsi_clear_endpoint(struct vhost_scsi *vs,
 		vhost_vq_set_backend(vq, NULL);
 		mutex_unlock(&vq->mutex);
 	}
+	/*
+	 * called by:
+	 *   - drivers/vhost/scsi.c|2367| <<vhost_scsi_set_endpoint>> vhost_scsi_flush(vs);
+	 *   - drivers/vhost/scsi.c|2453| <<vhost_scsi_clear_endpoint>> vhost_scsi_flush(vs);
+	 *   - drivers/vhost/scsi.c|2487| <<vhost_scsi_clear_endpoint>> vhost_scsi_flush(vs);
+	 */
 	/* Make sure cmds are not running before tearing them down. */
 	vhost_scsi_flush(vs);
 
@@ -1901,9 +2577,23 @@ vhost_scsi_clear_endpoint(struct vhost_scsi *vs,
 	 * Act as synchronize_rcu to make sure access to
 	 * old vs->vs_tpg is finished.
 	 */
+	/*
+	 * called by:
+	 *   - drivers/vhost/scsi.c|2367| <<vhost_scsi_set_endpoint>> vhost_scsi_flush(vs);
+	 *   - drivers/vhost/scsi.c|2453| <<vhost_scsi_clear_endpoint>> vhost_scsi_flush(vs);
+	 *   - drivers/vhost/scsi.c|2487| <<vhost_scsi_clear_endpoint>> vhost_scsi_flush(vs);
+	 */
 	vhost_scsi_flush(vs);
 	kfree(vs->vs_tpg);
 	vs->vs_tpg = NULL;
+	/*
+	 * 在以下使用vhost_scsi->vs_events_nr:
+	 *   - drivers/vhost/scsi.c|471| <<vhost_scsi_free_evt>> vs->vs_events_nr--;
+	 *   - drivers/vhost/scsi.c|482| <<vhost_scsi_allocate_evt>> if (vs->vs_events_nr > VHOST_SCSI_MAX_EVENT) {
+	 *   - drivers/vhost/scsi.c|496| <<vhost_scsi_allocate_evt>> vs->vs_events_nr++;
+	 *   - drivers/vhost/scsi.c|2054| <<vhost_scsi_clear_endpoint>> WARN_ON(vs->vs_events_nr);
+	 *   - drivers/vhost/scsi.c|2130| <<vhost_scsi_open>> vs->vs_events_nr = 0;
+	 */
 	WARN_ON(vs->vs_events_nr);
 	mutex_unlock(&vs->dev.mutex);
 	return 0;
@@ -1973,8 +2663,21 @@ static int vhost_scsi_open(struct inode *inode, struct file *f)
 	if (!vqs)
 		goto err_local_vqs;
 
+	/*
+	 * 在以下使用vhost_scsi->vs_event_work:
+	 *   - drivers/vhost/scsi.c|1623| <<vhost_scsi_send_evt>> if (!vhost_vq_work_queue(vq, &vs->vs_event_work))
+	 *   - drivers/vhost/scsi.c|2067| <<vhost_scsi_open>> vhost_work_init(&vs->vs_event_work, vhost_scsi_evt_work);
+	 */
 	vhost_work_init(&vs->vs_event_work, vhost_scsi_evt_work);
 
+	/*
+	 * 在以下使用vhost_scsi->vs_events_nr:
+	 *   - drivers/vhost/scsi.c|471| <<vhost_scsi_free_evt>> vs->vs_events_nr--;
+	 *   - drivers/vhost/scsi.c|482| <<vhost_scsi_allocate_evt>> if (vs->vs_events_nr > VHOST_SCSI_MAX_EVENT) {
+	 *   - drivers/vhost/scsi.c|496| <<vhost_scsi_allocate_evt>> vs->vs_events_nr++;
+	 *   - drivers/vhost/scsi.c|2054| <<vhost_scsi_clear_endpoint>> WARN_ON(vs->vs_events_nr);
+	 *   - drivers/vhost/scsi.c|2130| <<vhost_scsi_open>> vs->vs_events_nr = 0;
+	 */
 	vs->vs_events_nr = 0;
 	vs->vs_events_missed = false;
 
@@ -1992,6 +2695,22 @@ static int vhost_scsi_open(struct inode *inode, struct file *f)
 				vhost_scsi_complete_cmd_work);
 		svq->vq.handle_kick = vhost_scsi_handle_kick;
 	}
+	/*
+	 * called by:
+	 *   - drivers/vhost/net.c|1374| <<vhost_net_open>> vhost_dev_init(dev, vqs,
+	 *             VHOST_NET_VQ_MAX, UIO_MAXIOV + VHOST_NET_BATCH,
+	 *             HOST_NET_PKT_WEIGHT, VHOST_NET_WEIGHT, true, NULL);
+	 *   - drivers/vhost/scsi.c|2258| <<vhost_scsi_open>> vhost_dev_init(&vs->dev, vqs,
+	 *             nvqs, UIO_MAXIOV, VHOST_SCSI_WEIGHT, 0, true, NULL);
+	 *   - drivers/vhost/test.c|122| <<vhost_test_open>> vhost_dev_init(dev, vqs,
+	 *             VHOST_TEST_VQ_MAX, UIO_MAXIOV,
+	 *             VHOST_TEST_PKT_WEIGHT, VHOST_TEST_WEIGHT, true, NULL);
+	 *   - drivers/vhost/vdpa.c|1433| <<vhost_vdpa_open>> vhost_dev_init(dev, vqs,
+	 *             nvqs, 0, 0, 0, false, vhost_vdpa_process_iotlb_msg);
+	 *   - drivers/vhost/vsock.c|719| <<vhost_vsock_dev_open>> vhost_dev_init(&vsock->dev, vqs,
+	 *             ARRAY_SIZE(vsock->vqs), UIO_MAXIOV,
+	 *             VHOST_VSOCK_PKT_WEIGHT, VHOST_VSOCK_WEIGHT, true, NULL);
+	 */
 	vhost_dev_init(&vs->dev, vqs, nvqs, UIO_MAXIOV,
 		       VHOST_SCSI_WEIGHT, 0, true, NULL);
 
@@ -2145,11 +2864,51 @@ static char *vhost_scsi_dump_proto_id(struct vhost_scsi_tport *tport)
 	return "Unknown";
 }
 
+/*
+ * add:
+ *
+ * vhost_scsi_do_plug
+ * vhost_scsi_port_link
+ * target_fabric_port_link
+ * configfs_symlink
+ * vfs_symlink
+ * do_symlinkat
+ * __x64_sys_symlink
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * del:
+ *
+ * vhost_scsi_do_plug
+ * vhost_scsi_port_unlink
+ * target_fabric_port_unlink
+ * configfs_unlink
+ * vfs_unlink
+ * do_unlinkat
+ * __x64_sys_unlink
+ * do_syscall_64
+ * entry_SYSCALL_64_after_hwframe
+ *
+ * QEMU是下面的代码:
+ *   - hw/scsi/virtio-scsi.c|1148| <<virtio_scsi_hotplug>> if (virtio_vdev_has_feature(vdev, VIRTIO_SCSI_F_HOTPLUG)) {
+ *   - hw/scsi/virtio-scsi.c|1185| <<virtio_scsi_hotunplug>> if (virtio_vdev_has_feature(vdev, VIRTIO_SCSI_F_HOTPLUG)) {
+ *
+ * called by:
+ *   - drivers/vhost/scsi.c|2230| <<vhost_scsi_hotplug>> vhost_scsi_do_plug(tpg, lun, true);
+ *   - drivers/vhost/scsi.c|2235| <<vhost_scsi_hotunplug>> vhost_scsi_do_plug(tpg, lun, false);
+ */
 static void
 vhost_scsi_do_plug(struct vhost_scsi_tpg *tpg,
 		  struct se_lun *lun, bool plug)
 {
 
+	/*
+	 * 在以下使用vhost_scsi_tpg->vhost_scsi:
+	 *   - drivers/vhost/scsi.c|2349| <<vhost_scsi_set_endpoint>> tpg->vhost_scsi = vs;
+	 *   - drivers/vhost/scsi.c|2416| <<vhost_scsi_set_endpoint>> tpg->vhost_scsi = NULL;
+	 *   - drivers/vhost/scsi.c|2513| <<vhost_scsi_clear_endpoint>> tpg->vhost_scsi = NULL;
+	 *   - drivers/vhost/scsi.c|2828| <<vhost_scsi_do_plug>> struct vhost_scsi *vs = tpg->vhost_scsi;
+	 */
 	struct vhost_scsi *vs = tpg->vhost_scsi;
 	struct vhost_virtqueue *vq;
 	u32 reason;
@@ -2171,6 +2930,15 @@ vhost_scsi_do_plug(struct vhost_scsi_tpg *tpg,
 	if (!vhost_vq_get_backend(vq))
 		goto unlock;
 
+	/*
+	 * QEMU是下面的代码:
+	 *   - hw/scsi/virtio-scsi.c|1148| <<virtio_scsi_hotplug>> if (virtio_vdev_has_feature(vdev, VIRTIO_SCSI_F_HOTPLUG)) {
+	 *   - hw/scsi/virtio-scsi.c|1185| <<virtio_scsi_hotunplug>> if (virtio_vdev_has_feature(vdev, VIRTIO_SCSI_F_HOTPLUG)) {
+	 *
+	 * 在以下使用vhost_scsi_send_evt():
+	 *   - drivers/vhost/scsi.c|1594| <<vhost_scsi_evt_handle_kick>> vhost_scsi_send_evt(vs, vq, NULL, NULL, VIRTIO_SCSI_T_NO_EVENT,
+	 *   - drivers/vhost/scsi.c|2222| <<vhost_scsi_do_plug>> vhost_scsi_send_evt(vs, vq, tpg, lun,
+	 */
 	if (vhost_has_feature(vq, VIRTIO_SCSI_F_HOTPLUG))
 		vhost_scsi_send_evt(vs, vq, tpg, lun,
 				   VIRTIO_SCSI_T_TRANSPORT_RESET, reason);
@@ -2178,6 +2946,10 @@ vhost_scsi_do_plug(struct vhost_scsi_tpg *tpg,
 	mutex_unlock(&vq->mutex);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|2246| <<vhost_scsi_port_link>> vhost_scsi_hotplug(tpg, lun);
+ */
 static void vhost_scsi_hotplug(struct vhost_scsi_tpg *tpg, struct se_lun *lun)
 {
 	vhost_scsi_do_plug(tpg, lun, true);
@@ -2188,6 +2960,9 @@ static void vhost_scsi_hotunplug(struct vhost_scsi_tpg *tpg, struct se_lun *lun)
 	vhost_scsi_do_plug(tpg, lun, false);
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.fabric_post_link = vhost_scsi_port_link()
+ */
 static int vhost_scsi_port_link(struct se_portal_group *se_tpg,
 			       struct se_lun *lun)
 {
@@ -2202,6 +2977,9 @@ static int vhost_scsi_port_link(struct se_portal_group *se_tpg,
 	return 0;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.fabric_pre_unlink = vhost_scsi_port_unlink()
+ */
 static void vhost_scsi_port_unlink(struct se_portal_group *se_tpg,
 				  struct se_lun *lun)
 {
@@ -2248,11 +3026,18 @@ static ssize_t vhost_scsi_tpg_attrib_fabric_prot_type_show(
 
 CONFIGFS_ATTR(vhost_scsi_tpg_attrib_, fabric_prot_type);
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.tfc_tpg_attrib_attrs = vhost_scsi_tpg_attrib_attrs()
+ */
 static struct configfs_attribute *vhost_scsi_tpg_attrib_attrs[] = {
 	&vhost_scsi_tpg_attrib_attr_fabric_prot_type,
 	NULL,
 };
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|3169| <<vhost_scsi_tpg_nexus_store>> ret = vhost_scsi_make_nexus(tpg, port_ptr);
+ */
 static int vhost_scsi_make_nexus(struct vhost_scsi_tpg *tpg,
 				const char *name)
 {
@@ -2440,11 +3225,17 @@ static ssize_t vhost_scsi_tpg_nexus_store(struct config_item *item,
 
 CONFIGFS_ATTR(vhost_scsi_tpg_, nexus);
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.tfc_tpg_base_attrs = vhost_scsi_tpg_attrs()
+ */
 static struct configfs_attribute *vhost_scsi_tpg_attrs[] = {
 	&vhost_scsi_tpg_attr_nexus,
 	NULL,
 };
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.fabric_make_tpg = vhost_scsi_make_tpg()
+ */
 static struct se_portal_group *
 vhost_scsi_make_tpg(struct se_wwn *wwn, const char *name)
 {
@@ -2482,6 +3273,9 @@ vhost_scsi_make_tpg(struct se_wwn *wwn, const char *name)
 	return &tpg->se_tpg;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.fabric_drop_tpg = vhost_scsi_drop_tpg()
+ */
 static void vhost_scsi_drop_tpg(struct se_portal_group *se_tpg)
 {
 	struct vhost_scsi_tpg *tpg = container_of(se_tpg,
@@ -2501,6 +3295,9 @@ static void vhost_scsi_drop_tpg(struct se_portal_group *se_tpg)
 	kfree(tpg);
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.fabric_make_wwn = vhost_scsi_make_tport()
+ */
 static struct se_wwn *
 vhost_scsi_make_tport(struct target_fabric_configfs *tf,
 		     struct config_group *group,
@@ -2562,6 +3359,9 @@ vhost_scsi_make_tport(struct target_fabric_configfs *tf,
 	return &tport->tport_wwn;
 }
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.fabric_drop_wwn = vhost_scsi_drop_tport()
+ */
 static void vhost_scsi_drop_tport(struct se_wwn *wwn)
 {
 	struct vhost_scsi_tport *tport = container_of(wwn,
@@ -2584,6 +3384,9 @@ vhost_scsi_wwn_version_show(struct config_item *item, char *page)
 
 CONFIGFS_ATTR_RO(vhost_scsi_wwn_, version);
 
+/*
+ * struct target_core_fabric_ops vhost_scsi_ops.tfc_wwn_attrs = vhost_scsi_wwn_attrs()
+ */
 static struct configfs_attribute *vhost_scsi_wwn_attrs[] = {
 	&vhost_scsi_wwn_attr_version,
 	NULL,
@@ -2636,6 +3439,23 @@ static int __init vhost_scsi_init(void)
 	if (ret < 0)
 		goto out;
 
+	/*
+	 * called by:
+	 *   - drivers/infiniband/ulp/srpt/ib_srpt.c|3961| <<srpt_init_module>> ret = target_register_template(&srpt_template);
+	 *   - drivers/scsi/elx/efct/efct_lio.c|1662| <<efct_scsi_tgt_driver_init>> rc = target_register_template(&efct_lio_ops);
+	 *   - drivers/scsi/elx/efct/efct_lio.c|1667| <<efct_scsi_tgt_driver_init>> rc = target_register_template(&efct_lio_npiv_ops);
+	 *   - drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c|4036| <<ibmvscsis_init>> rc = target_register_template(&ibmvscsis_ops);
+	 *   - drivers/scsi/qla2xxx/tcm_qla2xxx.c|1878| <<tcm_qla2xxx_register_configfs>> ret = target_register_template(&tcm_qla2xxx_ops);
+	 *   - drivers/scsi/qla2xxx/tcm_qla2xxx.c|1882| <<tcm_qla2xxx_register_configfs>> ret = target_register_template(&tcm_qla2xxx_npiv_ops);
+	 *   - drivers/target/iscsi/iscsi_target.c|695| <<iscsi_target_init_module>> ret = target_register_template(&iscsi_ops);
+	 *   - drivers/target/loopback/tcm_loop.c|1126| <<tcm_loop_fabric_init>> ret = target_register_template(&loop_ops);
+	 *   - drivers/target/sbp/sbp_target.c|2288| <<sbp_init>> return target_register_template(&sbp_ops);
+	 *   - drivers/target/tcm_fc/tfc_conf.c|448| <<ft_init>> ret = target_register_template(&ft_fabric_ops);
+	 *   - drivers/target/tcm_remote/tcm_remote.c|256| <<tcm_remote_fabric_init>> return target_register_template(&remote_ops);
+	 *   - drivers/usb/gadget/function/f_tcm.c|2289| <<tcm_init>> ret = target_register_template(&usbg_ops);
+	 *   - drivers/vhost/scsi.c|2792| <<vhost_scsi_init>> ret = target_register_template(&vhost_scsi_ops);
+	 *   - drivers/xen/xen-scsiback.c|1866| <<scsiback_init>> ret = target_register_template(&scsiback_ops);
+	 */
 	ret = target_register_template(&vhost_scsi_ops);
 	if (ret < 0)
 		goto out_vhost_scsi_deregister;
diff --git a/drivers/vhost/test.c b/drivers/vhost/test.c
index 42c955a5b..d5b29fb89 100644
--- a/drivers/vhost/test.c
+++ b/drivers/vhost/test.c
@@ -119,6 +119,22 @@ static int vhost_test_open(struct inode *inode, struct file *f)
 	dev = &n->dev;
 	vqs[VHOST_TEST_VQ] = &n->vqs[VHOST_TEST_VQ];
 	n->vqs[VHOST_TEST_VQ].handle_kick = handle_vq_kick;
+	/*
+	 * called by:
+	 *   - drivers/vhost/net.c|1374| <<vhost_net_open>> vhost_dev_init(dev, vqs,
+	 *             VHOST_NET_VQ_MAX, UIO_MAXIOV + VHOST_NET_BATCH,
+	 *             HOST_NET_PKT_WEIGHT, VHOST_NET_WEIGHT, true, NULL);
+	 *   - drivers/vhost/scsi.c|2258| <<vhost_scsi_open>> vhost_dev_init(&vs->dev, vqs,
+	 *             nvqs, UIO_MAXIOV, VHOST_SCSI_WEIGHT, 0, true, NULL);
+	 *   - drivers/vhost/test.c|122| <<vhost_test_open>> vhost_dev_init(dev, vqs,
+	 *             VHOST_TEST_VQ_MAX, UIO_MAXIOV,
+	 *             VHOST_TEST_PKT_WEIGHT, VHOST_TEST_WEIGHT, true, NULL);
+	 *   - drivers/vhost/vdpa.c|1433| <<vhost_vdpa_open>> vhost_dev_init(dev, vqs,
+	 *             nvqs, 0, 0, 0, false, vhost_vdpa_process_iotlb_msg);
+	 *   - drivers/vhost/vsock.c|719| <<vhost_vsock_dev_open>> vhost_dev_init(&vsock->dev, vqs,
+	 *             ARRAY_SIZE(vsock->vqs), UIO_MAXIOV,
+	 *             VHOST_VSOCK_PKT_WEIGHT, VHOST_VSOCK_WEIGHT, true, NULL);
+	 */
 	vhost_dev_init(dev, vqs, VHOST_TEST_VQ_MAX, UIO_MAXIOV,
 		       VHOST_TEST_PKT_WEIGHT, VHOST_TEST_WEIGHT, true, NULL);
 
@@ -194,6 +210,14 @@ static long vhost_test_run(struct vhost_test *n, int test)
 		oldpriv = vhost_vq_get_backend(vq);
 		vhost_vq_set_backend(vq, priv);
 
+		/*
+		 * called by:
+		 *   - drivers/vhost/net.c|1658| <<vhost_net_set_backend>> r = vhost_vq_init_access(vq);
+		 *   - drivers/vhost/scsi.c|2285| <<vhost_scsi_set_endpoint>> vhost_vq_init_access(vq);
+		 *   - drivers/vhost/test.c|213| <<vhost_test_run>> r = vhost_vq_init_access(&n->vqs[index]);
+		 *   - drivers/vhost/test.c|306| <<vhost_test_set_backend>> r = vhost_vq_init_access(vq);
+		 *   - drivers/vhost/vsock.c|643| <<vhost_vsock_start>> ret = vhost_vq_init_access(vq);
+		 */
 		r = vhost_vq_init_access(&n->vqs[index]);
 
 		mutex_unlock(&vq->mutex);
@@ -282,12 +306,43 @@ static long vhost_test_set_backend(struct vhost_test *n, unsigned index, int fd)
 		goto err_vq;
 	}
 	if (!enable) {
+		/*
+		 * 在以下调用vhost_poll_stop():
+		 *   - drivers/vhost/net.c|439| <<vhost_net_disable_vq>> vhost_poll_stop(poll);
+		 *   - drivers/vhost/test.c|309| <<vhost_test_set_backend>> vhost_poll_stop(&vq->poll);
+		 *   - drivers/vhost/vhost.c|235| <<vhost_poll_start>> vhost_poll_stop(poll);
+		 *   - drivers/vhost/vhost.c|1088| <<vhost_dev_stop>> vhost_poll_stop(&dev->vqs[i]->poll);
+		 *   - drivers/vhost/vhost.c|2244| <<vhost_vring_ioctl>> vhost_poll_stop(&vq->poll);
+		 *
+		 * 注释:
+		 * Stop polling a file. After this function returns, it becomes safe to drop the
+		 * file reference. You must also flush afterwards.
+		 */
 		vhost_poll_stop(&vq->poll);
 		backend = vhost_vq_get_backend(vq);
 		vhost_vq_set_backend(vq, NULL);
 	} else {
 		vhost_vq_set_backend(vq, backend);
+		/*
+		 * called by:
+		 *   - drivers/vhost/net.c|1658| <<vhost_net_set_backend>> r = vhost_vq_init_access(vq);
+		 *   - drivers/vhost/scsi.c|2285| <<vhost_scsi_set_endpoint>> vhost_vq_init_access(vq);
+		 *   - drivers/vhost/test.c|213| <<vhost_test_run>> r = vhost_vq_init_access(&n->vqs[index]);
+		 *   - drivers/vhost/test.c|306| <<vhost_test_set_backend>> r = vhost_vq_init_access(vq);
+		 *   - drivers/vhost/vsock.c|643| <<vhost_vsock_start>> ret = vhost_vq_init_access(vq);
+		 */
 		r = vhost_vq_init_access(vq);
+		/*
+		 * 在以下调用vhost_poll_start():
+		 *   - drivers/vhost/net.c|454| <<vhost_net_enable_vq>> return vhost_poll_start(poll, sock->file);
+		 *   - drivers/vhost/test.c|324| <<vhost_test_set_backend>> r = vhost_poll_start(&vq->poll, vq->kick);
+		 *   - drivers/vhost/vhost.c|2252| <<vhost_vring_ioctl>> r = vhost_poll_start(&vq->poll, vq->kick);
+		 *   - drivers/vhost/vhost.h|56| <<vhost_vring_ioctl>> int vhost_poll_start(struct vhost_poll *poll, struct file *file);
+		 *
+		 * 注释:
+		 * Start polling a file. We add ourselves to file's wait queue. The caller must
+		 * keep a reference to a file until after vhost_poll_stop is called.
+		 */
 		if (r == 0)
 			r = vhost_poll_start(&vq->poll, vq->kick);
 	}
diff --git a/drivers/vhost/vdpa.c b/drivers/vhost/vdpa.c
index 5a49b5a6d..ff1ab9197 100644
--- a/drivers/vhost/vdpa.c
+++ b/drivers/vhost/vdpa.c
@@ -170,9 +170,29 @@ static void handle_vq_kick(struct vhost_work *work)
 	struct vhost_vdpa *v = container_of(vq->dev, struct vhost_vdpa, vdev);
 	const struct vdpa_config_ops *ops = v->vdpa->config;
 
+	/*
+	 * 在以下调用vdpa_config_ops->kick_vq:
+	 *   - drivers/vhost/vdpa.c|173| <<handle_vq_kick>> ops->kick_vq(v->vdpa, vq - v->vqs);
+	 *   - drivers/virtio/virtio_vdpa.c|111| <<virtio_vdpa_notify>> ops->kick_vq(vdpa, vq->index);
+	 * 在以下设置vdpa_config_ops->kick_vq:
+	 *   - drivers/vdpa/alibaba/eni_vdpa.c|434| <<global>> .kick_vq = eni_vdpa_kick_vq,
+	 *   - drivers/vdpa/ifcvf/ifcvf_main.c|650| <<global>> .kick_vq = ifcvf_vdpa_kick_vq,
+	 *   - drivers/vdpa/mlx5/net/mlx5_vnet.c|3656| <<global>> .kick_vq = mlx5_vdpa_kick_vq,
+	 *   - drivers/vdpa/octeon_ep/octep_vdpa_main.c|344| <<global>> .kick_vq = octep_vdpa_kick_vq,
+	 *   - drivers/vdpa/pds/vdpa_dev.c|581| <<global>> .kick_vq = pds_vdpa_kick_vq,
+	 *   - drivers/vdpa/solidrun/snet_main.c|529| <<global>> .kick_vq = snet_kick_vq,
+	 *   - drivers/vdpa/vdpa_sim/vdpa_sim.c|774| <<global>> .kick_vq = vdpasim_kick_vq,
+	 *   - drivers/vdpa/vdpa_sim/vdpa_sim.c|815| <<global>> .kick_vq = vdpasim_kick_vq,
+	 *   - drivers/vdpa/vdpa_user/vduse_dev.c|787| <<global>> .kick_vq = vduse_vdpa_kick_vq,
+	 *   - drivers/vdpa/virtio_pci/vp_vdpa.c|474| <<global>> .kick_vq = vp_vdpa_kick_vq,
+	 */
 	ops->kick_vq(v->vdpa, vq - v->vqs);
 }
 
+/*
+ * 在以下使用vhost_vdpa_virtqueue_cb():
+ *   - drivers/vhost/vdpa.c|753| <<vhost_vdpa_vring_ioctl(VHOST_SET_VRING_CALL)>> cb.callback = vhost_vdpa_virtqueue_cb;
+ */
 static irqreturn_t vhost_vdpa_virtqueue_cb(void *private)
 {
 	struct vhost_virtqueue *vq = private;
@@ -989,6 +1009,12 @@ static int perm_to_iommu_flags(u32 perm)
 	return flags | IOMMU_CACHE;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vdpa.c|1075| <<vhost_vdpa_va_map>> ret = vhost_vdpa_map(v, iotlb, map_iova, map_size, uaddr,
+ *   - drivers/vhost/vdpa.c|1160| <<vhost_vdpa_pa_map>> ret = vhost_vdpa_map(v, iotlb, iova, csize,
+ *   - drivers/vhost/vdpa.c|1190| <<vhost_vdpa_pa_map>> ret = vhost_vdpa_map(v, iotlb, iova, PFN_PHYS(last_pfn - map_pfn + 1),
+ */
 static int vhost_vdpa_map(struct vhost_vdpa *v, struct vhost_iotlb *iotlb,
 			  u64 iova, u64 size, u64 pa, u32 perm, void *opaque)
 {
@@ -1430,6 +1456,22 @@ static int vhost_vdpa_open(struct inode *inode, struct file *filep)
 		vqs[i]->handle_kick = handle_vq_kick;
 		vqs[i]->call_ctx.ctx = NULL;
 	}
+	/*
+	 * called by:
+	 *   - drivers/vhost/net.c|1374| <<vhost_net_open>> vhost_dev_init(dev, vqs,
+	 *             VHOST_NET_VQ_MAX, UIO_MAXIOV + VHOST_NET_BATCH,
+	 *             HOST_NET_PKT_WEIGHT, VHOST_NET_WEIGHT, true, NULL);
+	 *   - drivers/vhost/scsi.c|2258| <<vhost_scsi_open>> vhost_dev_init(&vs->dev, vqs,
+	 *             nvqs, UIO_MAXIOV, VHOST_SCSI_WEIGHT, 0, true, NULL);
+	 *   - drivers/vhost/test.c|122| <<vhost_test_open>> vhost_dev_init(dev, vqs,
+	 *             VHOST_TEST_VQ_MAX, UIO_MAXIOV,
+	 *             VHOST_TEST_PKT_WEIGHT, VHOST_TEST_WEIGHT, true, NULL);
+	 *   - drivers/vhost/vdpa.c|1433| <<vhost_vdpa_open>> vhost_dev_init(dev, vqs,
+	 *             nvqs, 0, 0, 0, false, vhost_vdpa_process_iotlb_msg);
+	 *   - drivers/vhost/vsock.c|719| <<vhost_vsock_dev_open>> vhost_dev_init(&vsock->dev, vqs,
+	 *             ARRAY_SIZE(vsock->vqs), UIO_MAXIOV,
+	 *             VHOST_VSOCK_PKT_WEIGHT, VHOST_VSOCK_WEIGHT, true, NULL);
+	 */
 	vhost_dev_init(dev, vqs, nvqs, 0, 0, 0, false,
 		       vhost_vdpa_process_iotlb_msg);
 
diff --git a/drivers/vhost/vhost.c b/drivers/vhost/vhost.c
index 9ac25d08f..74efae45c 100644
--- a/drivers/vhost/vhost.c
+++ b/drivers/vhost/vhost.c
@@ -143,6 +143,10 @@ struct vhost_flush_struct {
 	struct completion wait_event;
 };
 
+/*
+ * 在以下使用vhost_flush_work():
+ *   - drivers/vhost/vhost.c|307| <<__vhost_worker_flush>> vhost_work_init(&flush.work, vhost_flush_work);
+ */
 static void vhost_flush_work(struct vhost_work *work)
 {
 	struct vhost_flush_struct *s;
@@ -151,6 +155,10 @@ static void vhost_flush_work(struct vhost_work *work)
 	complete(&s->wait_event);
 }
 
+/*
+ * 在以下使用vhost_poll_func():
+ *   - drivers/vhost/vhost.c|212| <<vhost_poll_init>> init_poll_funcptr(&poll->table, vhost_poll_func);
+ */
 static void vhost_poll_func(struct file *file, wait_queue_head_t *wqh,
 			    poll_table *pt)
 {
@@ -161,6 +169,11 @@ static void vhost_poll_func(struct file *file, wait_queue_head_t *wqh,
 	add_wait_queue(wqh, &poll->wait);
 }
 
+/*
+ * 在以下使用vhost_poll_wakeup():
+ *   - drivers/vhost/vhost.c|211| <<vhost_poll_init>> init_waitqueue_func_entry(&poll->wait, vhost_poll_wakeup);
+ *   - drivers/vhost/vhost.c|233| <<vhost_poll_start>> vhost_poll_wakeup(&poll->wait, 0, 0, poll_to_key(mask));
+ */
 static int vhost_poll_wakeup(wait_queue_entry_t *wait, unsigned mode, int sync,
 			     void *key)
 {
@@ -170,6 +183,23 @@ static int vhost_poll_wakeup(wait_queue_entry_t *wait, unsigned mode, int sync,
 	if (!(key_to_poll(key) & poll->mask))
 		return 0;
 
+	/*
+	 * 在以下使用vhost_poll_queue():
+	 *   - drivers/vhost/net.c|411| <<vhost_zerocopy_complete>> vhost_poll_queue(&vq->poll);
+	 *   - drivers/vhost/net.c|526| <<vhost_net_busy_poll_try_queue>> vhost_poll_queue(&vq->poll);
+	 *   - drivers/vhost/net.c|529| <<vhost_net_busy_poll_try_queue>> vhost_poll_queue(&vq->poll);
+	 *   - drivers/vhost/net.c|821| <<handle_tx_copy>> vhost_poll_queue(&vq->poll);
+	 *   - drivers/vhost/net.c|937| <<handle_tx_zerocopy>> vhost_poll_queue(&vq->poll);
+	 *   - drivers/vhost/net.c|1260| <<handle_rx>> vhost_poll_queue(&vq->poll);
+	 *   - drivers/vhost/net.c|1358| <<handle_rx>> vhost_poll_queue(&vq->poll);
+	 *   - drivers/vhost/vhost.c|176| <<vhost_poll_wakeup>> vhost_poll_queue(poll);
+	 *   - drivers/vhost/vhost.c|531| <<vhost_exceeds_weight>> vhost_poll_queue(&vq->poll);
+	 *   - drivers/vhost/vhost.c|1552| <<vhost_iotlb_notify_vq>> vhost_poll_queue(&node->vq->poll);
+	 *   - drivers/vhost/vhost.h|58| <<vhost_iotlb_notify_vq>> void vhost_poll_queue(struct vhost_poll *poll);
+	 *   - drivers/vhost/vsock.c|284| <<vhost_transport_do_send_pkt>> vhost_poll_queue(&tx_vq->poll);
+	 *   - drivers/vhost/vsock.c|347| <<vhost_transport_cancel_pkt>> vhost_poll_queue(&tx_vq->poll);
+	 */
+
 	if (!poll->dev->use_worker)
 		work->fn(work);
 	else
@@ -178,6 +208,15 @@ static int vhost_poll_wakeup(wait_queue_entry_t *wait, unsigned mode, int sync,
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|1547| <<vhost_scsi_handle_tmf>> vhost_work_init(&tmf->vwork, vhost_scsi_tmf_resp_work);
+ *   - drivers/vhost/scsi.c|2231| <<vhost_scsi_open>> vhost_work_init(&vs->vs_event_work, vhost_scsi_evt_work);
+ *   - drivers/vhost/scsi.c|2254| <<vhost_scsi_open>> vhost_work_init(&svq->completion_work, vhost_scsi_complete_cmd_work);
+ *   - drivers/vhost/vhost.c|200| <<vhost_poll_init>> vhost_work_init(&poll->work, fn);
+ *   - drivers/vhost/vhost.c|280| <<__vhost_worker_flush>> vhost_work_init(&flush.work, vhost_flush_work);
+ *   - drivers/vhost/vsock.c|725| <<vhost_vsock_dev_open>> vhost_work_init(&vsock->send_pkt_work, vhost_transport_send_pkt_work);
+ */
 void vhost_work_init(struct vhost_work *work, vhost_work_fn_t fn)
 {
 	clear_bit(VHOST_WORK_QUEUED, &work->flags);
@@ -185,6 +224,15 @@ void vhost_work_init(struct vhost_work *work, vhost_work_fn_t fn)
 }
 EXPORT_SYMBOL_GPL(vhost_work_init);
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|570| <<vhost_dev_init>> vhost_poll_init(&vq->poll,
+ *                   vq->handle_kick, EPOLLIN, dev, vq);
+ *   - drivers/vhost/net.c|1379| <<vhost_net_open>> vhost_poll_init(n->poll + VHOST_NET_VQ_TX,
+ *                   handle_tx_net, EPOLLOUT, dev, vqs[VHOST_NET_VQ_TX]);
+ *   - drivers/vhost/net.c|1381| <<vhost_net_open>> vhost_poll_init(n->poll + VHOST_NET_VQ_RX,
+ *                   handle_rx_net, EPOLLIN, dev, vqs[VHOST_NET_VQ_RX]);
+ */
 /* Init poll structure */
 void vhost_poll_init(struct vhost_poll *poll, vhost_work_fn_t fn,
 		     __poll_t mask, struct vhost_dev *dev,
@@ -203,6 +251,16 @@ EXPORT_SYMBOL_GPL(vhost_poll_init);
 
 /* Start polling a file. We add ourselves to file's wait queue. The caller must
  * keep a reference to a file until after vhost_poll_stop is called. */
+/*
+ * 在以下调用vhost_poll_start():
+ *   - drivers/vhost/net.c|454| <<vhost_net_enable_vq>> return vhost_poll_start(poll, sock->file);
+ *   - drivers/vhost/test.c|324| <<vhost_test_set_backend>> r = vhost_poll_start(&vq->poll, vq->kick);
+ *   - drivers/vhost/vhost.c|2252| <<vhost_vring_ioctl>> r = vhost_poll_start(&vq->poll, vq->kick);
+ *
+ * 注释:
+ * Start polling a file. We add ourselves to file's wait queue. The caller must
+ * keep a reference to a file until after vhost_poll_stop is called.
+ */
 int vhost_poll_start(struct vhost_poll *poll, struct file *file)
 {
 	__poll_t mask;
@@ -214,6 +272,18 @@ int vhost_poll_start(struct vhost_poll *poll, struct file *file)
 	if (mask)
 		vhost_poll_wakeup(&poll->wait, 0, 0, poll_to_key(mask));
 	if (mask & EPOLLERR) {
+		/*
+		 * 在以下调用vhost_poll_stop():
+		 *   - drivers/vhost/net.c|439| <<vhost_net_disable_vq>> vhost_poll_stop(poll);
+		 *   - drivers/vhost/test.c|309| <<vhost_test_set_backend>> vhost_poll_stop(&vq->poll);
+		 *   - drivers/vhost/vhost.c|235| <<vhost_poll_start>> vhost_poll_stop(poll);
+		 *   - drivers/vhost/vhost.c|1088| <<vhost_dev_stop>> vhost_poll_stop(&dev->vqs[i]->poll);
+		 *   - drivers/vhost/vhost.c|2244| <<vhost_vring_ioctl>> vhost_poll_stop(&vq->poll);
+		 *
+		 * 注释:
+		 * Stop polling a file. After this function returns, it becomes safe to drop the
+		 * file reference. You must also flush afterwards.
+		 */
 		vhost_poll_stop(poll);
 		return -EINVAL;
 	}
@@ -224,6 +294,18 @@ EXPORT_SYMBOL_GPL(vhost_poll_start);
 
 /* Stop polling a file. After this function returns, it becomes safe to drop the
  * file reference. You must also flush afterwards. */
+/*
+ * 在以下调用vhost_poll_stop():
+ *   - drivers/vhost/net.c|439| <<vhost_net_disable_vq>> vhost_poll_stop(poll);
+ *   - drivers/vhost/test.c|309| <<vhost_test_set_backend>> vhost_poll_stop(&vq->poll);
+ *   - drivers/vhost/vhost.c|235| <<vhost_poll_start>> vhost_poll_stop(poll);
+ *   - drivers/vhost/vhost.c|1088| <<vhost_dev_stop>> vhost_poll_stop(&dev->vqs[i]->poll);
+ *   - drivers/vhost/vhost.c|2244| <<vhost_vring_ioctl>> vhost_poll_stop(&vq->poll);
+ *
+ * 注释:
+ * Stop polling a file. After this function returns, it becomes safe to drop the
+ * file reference. You must also flush afterwards.
+ */
 void vhost_poll_stop(struct vhost_poll *poll)
 {
 	if (poll->wqh) {
@@ -233,6 +315,11 @@ void vhost_poll_stop(struct vhost_poll *poll)
 }
 EXPORT_SYMBOL_GPL(vhost_poll_stop);
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|285| <<vhost_vq_work_queue>> vhost_worker_queue(worker, work);
+ *   - drivers/vhost/vhost.c|309| <<__vhost_worker_flush>> vhost_worker_queue(worker, &flush.work);
+ */
 static void vhost_worker_queue(struct vhost_worker *worker,
 			       struct vhost_work *work)
 {
@@ -246,6 +333,15 @@ static void vhost_worker_queue(struct vhost_worker *worker,
 	}
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|475| <<vhost_scsi_release_cmd>> if (!vhost_vq_work_queue(&svq->vq, &svq->completion_work))
+ *   - drivers/vhost/scsi.c|1688| <<vhost_scsi_tmf_flush_work>> if (!vhost_vq_work_queue(vq, &tmf->vwork))
+ *   - drivers/vhost/scsi.c|2022| <<vhost_scsi_send_evt>> if (!vhost_vq_work_queue(vq, &vs->vs_event_work))
+ *   - drivers/vhost/vhost.c|357| <<vhost_poll_queue>> vhost_vq_work_queue(poll->vq, &poll->work);
+ *   - drivers/vhost/vsock.c|319| <<vhost_transport_send_pkt>> vhost_vq_work_queue(&vsock->vqs[VSOCK_VQ_RX], &vsock->send_pkt_work);
+ *   - drivers/vhost/vsock.c|662| <<vhost_vsock_start>> vhost_vq_work_queue(&vsock->vqs[VSOCK_VQ_RX], &vsock->send_pkt_work);
+ */
 bool vhost_vq_work_queue(struct vhost_virtqueue *vq, struct vhost_work *work)
 {
 	struct vhost_worker *worker;
@@ -255,6 +351,11 @@ bool vhost_vq_work_queue(struct vhost_virtqueue *vq, struct vhost_work *work)
 	worker = rcu_dereference(vq->worker);
 	if (worker) {
 		queued = true;
+		/*
+		 * called by:
+		 *   - drivers/vhost/vhost.c|285| <<vhost_vq_work_queue>> vhost_worker_queue(worker, work);
+		 *   - drivers/vhost/vhost.c|309| <<__vhost_worker_flush>> vhost_worker_queue(worker, &flush.work);
+		 */
 		vhost_worker_queue(worker, work);
 	}
 	rcu_read_unlock();
@@ -269,6 +370,12 @@ EXPORT_SYMBOL_GPL(vhost_vq_work_queue);
  *
  * The worker's flush_mutex must be held.
  */
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|322| <<vhost_worker_flush>> __vhost_worker_flush(worker);
+ *   - drivers/vhost/vhost.c|845| <<__vhost_vq_attach_worker>> __vhost_worker_flush(old_worker);
+ *   - drivers/vhost/vhost.c|904| <<vhost_free_worker>> __vhost_worker_flush(worker);
+ */
 static void __vhost_worker_flush(struct vhost_worker *worker)
 {
 	struct vhost_flush_struct flush;
@@ -279,6 +386,11 @@ static void __vhost_worker_flush(struct vhost_worker *worker)
 	init_completion(&flush.wait_event);
 	vhost_work_init(&flush.work, vhost_flush_work);
 
+	/*
+	 * called by:
+	 *   - drivers/vhost/vhost.c|285| <<vhost_vq_work_queue>> vhost_worker_queue(worker, work);
+	 *   - drivers/vhost/vhost.c|309| <<__vhost_worker_flush>> vhost_worker_queue(worker, &flush.work);
+	 */
 	vhost_worker_queue(worker, &flush.work);
 	/*
 	 * Drop mutex in case our worker is killed and it needs to take the
@@ -289,23 +401,52 @@ static void __vhost_worker_flush(struct vhost_worker *worker)
 	mutex_lock(&worker->mutex);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|344| <<vhost_dev_flush>> vhost_worker_flush(worker);
+ */
 static void vhost_worker_flush(struct vhost_worker *worker)
 {
 	mutex_lock(&worker->mutex);
+	/*
+	 * called by:
+	 *   - drivers/vhost/vhost.c|322| <<vhost_worker_flush>> __vhost_worker_flush(worker);
+	 *   - drivers/vhost/vhost.c|845| <<__vhost_vq_attach_worker>> __vhost_worker_flush(old_worker);
+	 *   - drivers/vhost/vhost.c|904| <<vhost_free_worker>> __vhost_worker_flush(worker);
+	 */
 	__vhost_worker_flush(worker);
 	mutex_unlock(&worker->mutex);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|1432| <<vhost_net_flush>> vhost_dev_flush(&n->dev);
+ *   - drivers/vhost/net.c|1623| <<vhost_net_set_backend>> vhost_dev_flush(&n->dev);
+ *   - drivers/vhost/scsi.c|1639| <<vhost_scsi_tmf_flush_work>> vhost_dev_flush(vq->dev);
+ *   - drivers/vhost/scsi.c|2044| <<vhost_scsi_flush>> vhost_dev_flush(&vs->dev);
+ *   - drivers/vhost/test.c|165| <<vhost_test_flush>> vhost_dev_flush(&n->dev);
+ *   - drivers/vhost/vhost.c|1050| <<vhost_dev_stop>> vhost_dev_flush(dev);
+ *   - drivers/vhost/vhost.c|2147| <<vhost_vring_ioctl>> vhost_dev_flush(vq->poll.dev);
+ *   - drivers/vhost/vhost.h|61| <<vhost_vring_ioctl>> void vhost_dev_flush(struct vhost_dev *dev);
+ *   - drivers/vhost/vsock.c|751| <<vhost_vsock_flush>> vhost_dev_flush(&vsock->dev);
+ */
 void vhost_dev_flush(struct vhost_dev *dev)
 {
 	struct vhost_worker *worker;
 	unsigned long i;
 
+	/*
+	 * 只在此处调用vhost_worker_flush()
+	 */
 	xa_for_each(&dev->worker_xa, i, worker)
 		vhost_worker_flush(worker);
 }
 EXPORT_SYMBOL_GPL(vhost_dev_flush);
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|561| <<vhost_net_busy_poll>> if (vhost_vq_has_work(vq)) {
+ */
 /* A lockless hint for busy polling code to exit the loop */
 bool vhost_vq_has_work(struct vhost_virtqueue *vq)
 {
@@ -322,8 +463,33 @@ bool vhost_vq_has_work(struct vhost_virtqueue *vq)
 }
 EXPORT_SYMBOL_GPL(vhost_vq_has_work);
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|411| <<vhost_zerocopy_complete>> vhost_poll_queue(&vq->poll);
+ *   - drivers/vhost/net.c|526| <<vhost_net_busy_poll_try_queue>> vhost_poll_queue(&vq->poll);
+ *   - drivers/vhost/net.c|529| <<vhost_net_busy_poll_try_queue>> vhost_poll_queue(&vq->poll);
+ *   - drivers/vhost/net.c|821| <<handle_tx_copy>> vhost_poll_queue(&vq->poll);
+ *   - drivers/vhost/net.c|937| <<handle_tx_zerocopy>> vhost_poll_queue(&vq->poll);
+ *   - drivers/vhost/net.c|1260| <<handle_rx>> vhost_poll_queue(&vq->poll);
+ *   - drivers/vhost/net.c|1358| <<handle_rx>> vhost_poll_queue(&vq->poll);
+ *   - drivers/vhost/vhost.c|176| <<vhost_poll_wakeup>> vhost_poll_queue(poll);
+ *   - drivers/vhost/vhost.c|531| <<vhost_exceeds_weight>> vhost_poll_queue(&vq->poll);
+ *   - drivers/vhost/vhost.c|1552| <<vhost_iotlb_notify_vq>> vhost_poll_queue(&node->vq->poll);
+ *   - drivers/vhost/vhost.h|58| <<vhost_iotlb_notify_vq>> void vhost_poll_queue(struct vhost_poll *poll);
+ *   - drivers/vhost/vsock.c|284| <<vhost_transport_do_send_pkt>> vhost_poll_queue(&tx_vq->poll);
+ *   - drivers/vhost/vsock.c|347| <<vhost_transport_cancel_pkt>> vhost_poll_queue(&tx_vq->poll);
+ */
 void vhost_poll_queue(struct vhost_poll *poll)
 {
+	/*
+	 * called by:
+	 *   - drivers/vhost/scsi.c|475| <<vhost_scsi_release_cmd>> if (!vhost_vq_work_queue(&svq->vq, &svq->completion_work))
+	 *   - drivers/vhost/scsi.c|1688| <<vhost_scsi_tmf_flush_work>> if (!vhost_vq_work_queue(vq, &tmf->vwork))
+	 *   - drivers/vhost/scsi.c|2022| <<vhost_scsi_send_evt>> if (!vhost_vq_work_queue(vq, &vs->vs_event_work))
+	 *   - drivers/vhost/vhost.c|357| <<vhost_poll_queue>> vhost_vq_work_queue(poll->vq, &poll->work);
+	 *   - drivers/vhost/vsock.c|319| <<vhost_transport_send_pkt>> vhost_vq_work_queue(&vsock->vqs[VSOCK_VQ_RX], &vsock->send_pkt_work);
+	 *   - drivers/vhost/vsock.c|662| <<vhost_vsock_start>> vhost_vq_work_queue(&vsock->vqs[VSOCK_VQ_RX], &vsock->send_pkt_work);
+	 */
 	vhost_vq_work_queue(poll->vq, &poll->work);
 }
 EXPORT_SYMBOL_GPL(vhost_poll_queue);
@@ -350,12 +516,21 @@ static void vhost_vring_call_reset(struct vhost_vring_call *call_ctx)
 	memset(&call_ctx->producer, 0x0, sizeof(struct irq_bypass_producer));
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|2335| <<vhost_scsi_set_endpoint>> if (!vhost_vq_is_setup(vq))
+ */
 bool vhost_vq_is_setup(struct vhost_virtqueue *vq)
 {
 	return vq->avail && vq->desc && vq->used && vhost_vq_access_ok(vq);
 }
 EXPORT_SYMBOL_GPL(vhost_vq_is_setup);
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|772| <<vhost_vq_reset>> vhost_vq_reset(dev, vq);
+ *   - drivers/vhost/vhost.c|1285| <<vhost_dev_cleanup>> vhost_vq_reset(dev, dev->vqs[i]);
+ */
 static void vhost_vq_reset(struct vhost_dev *dev,
 			   struct vhost_virtqueue *vq)
 {
@@ -369,11 +544,43 @@ static void vhost_vq_reset(struct vhost_dev *dev,
 	vq->signalled_used = 0;
 	vq->signalled_used_valid = false;
 	vq->used_flags = 0;
+	/*
+	 * 在以下设置vhost_virtqueue->log_used:
+	 *   - drivers/vhost/vhost.c|539| <<vhost_vq_reset>> vq->log_used = false;
+	 *   - drivers/vhost/vhost.c|2228| <<vhost_vring_set_addr>> vq->log_used = !!(a.flags & (0x1 << VHOST_VRING_F_LOG));
+	 * 在以下使用vhost_virtqueue->log_used:
+	 *   - drivers/vhost/vhost.c|2075| <<vq_log_access_ok>> vq_log_used_access_ok(vq, log_base, vq->log_used, vq->log_addr);
+	 *   - drivers/vhost/vhost.c|2765| <<vhost_update_used_flags>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|2793| <<vhost_update_avail_event>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|3331| <<__vhost_add_used_n>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|3395| <<vhost_add_used_n>> if (unlikely(vq->log_used)) {
+	 */
 	vq->log_used = false;
+	/*
+	 * 在以下设置vhost_virtqueue->log_addr:
+	 *   - drivers/vhost/vhost.c|540| <<vhost_vq_reset>> vq->log_addr = -1ull;
+	 *   - drivers/vhost/vhost.c|2231| <<vhost_vring_set_addr>> vq->log_addr = a.log_guest_addr;
+	 * 在以下使用vhost_virtqueue->log_addr:
+	 *   - drivers/vhost/vhost.c|2075| <<vq_log_access_ok>> vq_log_used_access_ok(vq, log_base, vq->log_used, vq->log_addr);
+	 *   - drivers/vhost/vhost.c|2658| <<log_used>> return log_write(vq->log_base, vq->log_addr + used_offset, len);
+	 */
 	vq->log_addr = -1ull;
 	vq->private_data = NULL;
 	vq->acked_features = 0;
 	vq->acked_backend_features = 0;
+	/*
+	 * 在以下设置vhost_virtqueue->log_base:
+	 *   - drivers/vhost/vhost.c|544| <<vhost_vq_reset>> vq->log_base = NULL;
+	 *   - drivers/vhost/vhost.c|2499| <<vhost_dev_ioctl(VHOST_SET_LOG_BASE)>> vq->log_base = base;
+	 * 在以下使用vhost_virtqueue->log_base:
+	 *   - drivers/vhost/vhost.c|1360| <<memory_access_ok>> ok = vq_memory_access_ok(d->vqs[i]->log_base, umem, log);
+	 *   - drivers/vhost/vhost.c|2082| <<vhost_vq_access_ok>> if (!vq_log_access_ok(vq, vq->log_base))
+	 *   - drivers/vhost/vhost.c|2222| <<vhost_vring_set_addr>> if (!vq_log_used_access_ok(vq, vq->log_base,
+	 *             a.flags & (0x1 << VHOST_VRING_F_LOG), a.log_guest_addr))
+	 *   - drivers/vhost/vhost.c|2620| <<log_write_hva>> r = log_write(vq->log_base, u->start + start - u->addr, l);
+	 *   - drivers/vhost/vhost.c|2658| <<log_used>> return log_write(vq->log_base, vq->log_addr + used_offset, len);
+	 *   - drivers/vhost/vhost.c|2738| <<vhost_log_write>> r = log_write(vq->log_base, log[i].addr, l);
+	 */
 	vq->log_base = NULL;
 	vq->error_ctx = NULL;
 	vq->kick = NULL;
@@ -413,6 +620,11 @@ static bool vhost_run_work_list(void *data)
 	return !!node;
 }
 
+/*
+ * 在以下使用vhost_worker_killed():
+ *   - drivers/vhost/vhost.c|903| <<vhost_worker_create>> vtsk = vhost_task_create(vhost_run_work_list,
+ *             vhost_worker_killed, worker, name);
+ */
 static void vhost_worker_killed(void *data)
 {
 	struct vhost_worker *worker = data;
@@ -530,6 +742,22 @@ static size_t vhost_get_desc_size(struct vhost_virtqueue *vq,
 	return sizeof(*vq->desc) * num;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|1374| <<vhost_net_open>> vhost_dev_init(dev, vqs,
+ *             VHOST_NET_VQ_MAX, UIO_MAXIOV + VHOST_NET_BATCH,
+ *             HOST_NET_PKT_WEIGHT, VHOST_NET_WEIGHT, true, NULL);
+ *   - drivers/vhost/scsi.c|2258| <<vhost_scsi_open>> vhost_dev_init(&vs->dev, vqs,
+ *             nvqs, UIO_MAXIOV, VHOST_SCSI_WEIGHT, 0, true, NULL);
+ *   - drivers/vhost/test.c|122| <<vhost_test_open>> vhost_dev_init(dev, vqs,
+ *             VHOST_TEST_VQ_MAX, UIO_MAXIOV,
+ *             VHOST_TEST_PKT_WEIGHT, VHOST_TEST_WEIGHT, true, NULL);
+ *   - drivers/vhost/vdpa.c|1433| <<vhost_vdpa_open>> vhost_dev_init(dev, vqs,
+ *             nvqs, 0, 0, 0, false, vhost_vdpa_process_iotlb_msg);
+ *   - drivers/vhost/vsock.c|719| <<vhost_vsock_dev_open>> vhost_dev_init(&vsock->dev, vqs,
+ *             ARRAY_SIZE(vsock->vqs), UIO_MAXIOV,
+ *             VHOST_VSOCK_PKT_WEIGHT, VHOST_VSOCK_WEIGHT, true, NULL);
+ */
 void vhost_dev_init(struct vhost_dev *dev,
 		    struct vhost_virtqueue **vqs, int nvqs,
 		    int iov_limit, int weight, int byte_weight,
@@ -649,6 +877,11 @@ static void vhost_workers_free(struct vhost_dev *dev)
 	xa_destroy(&dev->worker_xa);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|821| <<vhost_new_worker>> worker = vhost_worker_create(dev);
+ *   - drivers/vhost/vhost.c|979| <<vhost_dev_set_owner>> worker = vhost_worker_create(dev);
+ */
 static struct vhost_worker *vhost_worker_create(struct vhost_dev *dev)
 {
 	struct vhost_worker *worker;
@@ -664,6 +897,14 @@ static struct vhost_worker *vhost_worker_create(struct vhost_dev *dev)
 	worker->dev = dev;
 	snprintf(name, sizeof(name), "vhost-%d", current->pid);
 
+	/*
+	 * called by:
+	 *   - arch/x86/kvm/mmu/mmu.c|7420| <<kvm_mmu_post_init_vm>> kvm->arch.nx_huge_page_recovery_thread =
+	 *            vhost_task_create(kvm_nx_huge_page_recovery_worker,
+	 *                              kvm_nx_huge_page_recovery_worker_kill, kvm, "kvm-nx-lpage-recovery");
+	 * drivers/vhost/vhost.c|701| <<vhost_worker_create>> vtsk = vhost_task_create(vhost_run_work_list,
+	 *            vhost_worker_killed, worker, name);
+	 */
 	vtsk = vhost_task_create(vhost_run_work_list, vhost_worker_killed,
 				 worker, name);
 	if (!vtsk)
@@ -753,6 +994,12 @@ static void __vhost_vq_attach_worker(struct vhost_virtqueue *vq,
 
 	/* Make sure new vq queue/flush/poll calls see the new worker */
 	synchronize_rcu();
+	/*
+	 * called by:
+	 *   - drivers/vhost/vhost.c|322| <<vhost_worker_flush>> __vhost_worker_flush(worker);
+	 *   - drivers/vhost/vhost.c|845| <<__vhost_vq_attach_worker>> __vhost_worker_flush(old_worker);
+	 *   - drivers/vhost/vhost.c|904| <<vhost_free_worker>> __vhost_worker_flush(worker);
+	 */
 	/* Make sure whatever was queued gets run */
 	__vhost_worker_flush(old_worker);
 	old_worker->attachment_cnt--;
@@ -813,6 +1060,12 @@ static int vhost_free_worker(struct vhost_dev *dev,
 	 * to zero. Make sure flushes are flushed from the queue before
 	 * freeing.
 	 */
+	/*
+	 * called by:
+	 *   - drivers/vhost/vhost.c|322| <<vhost_worker_flush>> __vhost_worker_flush(worker);
+	 *   - drivers/vhost/vhost.c|845| <<__vhost_vq_attach_worker>> __vhost_worker_flush(old_worker);
+	 *   - drivers/vhost/vhost.c|904| <<vhost_free_worker>> __vhost_worker_flush(worker);
+	 */
 	__vhost_worker_flush(worker);
 	mutex_unlock(&worker->mutex);
 
@@ -963,6 +1216,12 @@ long vhost_dev_set_owner(struct vhost_dev *dev)
 }
 EXPORT_SYMBOL_GPL(vhost_dev_set_owner);
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|1182| <<vhost_dev_reset_owner_prepare>> return iotlb_alloc();
+ *   - drivers/vhost/vhost.c|2117| <<vhost_set_memory>> newumem = iotlb_alloc();
+ *   - drivers/vhost/vhost.c|2411| <<vhost_init_device_iotlb>> niotlb = iotlb_alloc();
+ */
 static struct vhost_iotlb *iotlb_alloc(void)
 {
 	return vhost_iotlb_alloc(max_iotlb_entries,
@@ -991,11 +1250,33 @@ void vhost_dev_reset_owner(struct vhost_dev *dev, struct vhost_iotlb *umem)
 }
 EXPORT_SYMBOL_GPL(vhost_dev_reset_owner);
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|1611| <<vhost_net_release>> vhost_dev_stop(&n->dev);
+ *   - drivers/vhost/net.c|1828| <<vhost_net_reset_owner>> vhost_dev_stop(&n->dev);
+ *   - drivers/vhost/scsi.c|2642| <<vhost_scsi_release>> vhost_dev_stop(&vs->dev);
+ *   - drivers/vhost/test.c|175| <<vhost_test_release>> vhost_dev_stop(&n->dev);
+ *   - drivers/vhost/test.c|258| <<vhost_test_reset_owner>> vhost_dev_stop(&n->dev);
+ *   - drivers/vhost/vdpa.c|1486| <<vhost_vdpa_release>> vhost_dev_stop(&v->vdev);
+ *   - drivers/vhost/vsock.c|846| <<vhost_vsock_dev_release>> vhost_dev_stop(&vsock->dev);
+ */
 void vhost_dev_stop(struct vhost_dev *dev)
 {
 	int i;
 
 	for (i = 0; i < dev->nvqs; ++i) {
+		/*
+		 * 在以下调用vhost_poll_stop():
+		 *   - drivers/vhost/net.c|439| <<vhost_net_disable_vq>> vhost_poll_stop(poll);
+		 *   - drivers/vhost/test.c|309| <<vhost_test_set_backend>> vhost_poll_stop(&vq->poll);
+		 *   - drivers/vhost/vhost.c|235| <<vhost_poll_start>> vhost_poll_stop(poll);
+		 *   - drivers/vhost/vhost.c|1088| <<vhost_dev_stop>> vhost_poll_stop(&dev->vqs[i]->poll);
+		 *   - drivers/vhost/vhost.c|2244| <<vhost_vring_ioctl>> vhost_poll_stop(&vq->poll);
+		 *
+		 * 注释:
+		 * Stop polling a file. After this function returns, it becomes safe to drop the
+		 * file reference. You must also flush afterwards.
+		 */
 		if (dev->vqs[i]->kick && dev->vqs[i]->handle_kick)
 			vhost_poll_stop(&dev->vqs[i]->poll);
 	}
@@ -1053,6 +1334,11 @@ void vhost_dev_cleanup(struct vhost_dev *dev)
 }
 EXPORT_SYMBOL_GPL(vhost_dev_cleanup);
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|1366| <<vq_memory_access_ok>> else if (log_all && !log_access_ok(log_base,
+ *   - drivers/vhost/vhost.c|2118| <<vq_log_used_access_ok>> return !log_used || log_access_ok(log_base, log_addr,
+ */
 static bool log_access_ok(void __user *log_base, u64 addr, unsigned long sz)
 {
 	u64 a = addr / VHOST_PAGE_SIZE / 8;
@@ -1066,6 +1352,11 @@ static bool log_access_ok(void __user *log_base, u64 addr, unsigned long sz)
 			 (sz + VHOST_PAGE_SIZE * 8 - 1) / VHOST_PAGE_SIZE / 8);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|1360| <<vq_memory_access_ok>> if (vhost_overflow(map->addr, map->size))
+ *   - drivers/vhost/vhost.c|1787| <<umem_access_ok>> if (vhost_overflow(uaddr, size))
+ */
 /* Make sure 64 bit math will not overflow. */
 static bool vhost_overflow(u64 uaddr, u64 size)
 {
@@ -1078,6 +1369,13 @@ static bool vhost_overflow(u64 uaddr, u64 size)
 	return uaddr > ULONG_MAX - size + 1;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|1414| <<memory_access_ok>> ok = vq_memory_access_ok(d->vqs[i]->log_base, umem, log);
+ *   - drivers/vhost/vhost.c|2150| <<vq_log_access_ok>> return vq_memory_access_ok(log_base, vq->umem,
+ *             vhost_has_feature(vq, VHOST_F_LOG_ALL)) &&
+ *             vq_log_used_access_ok(vq, log_base, vq->log_used, vq->log_addr);
+ */
 /* Caller should have vq mutex and device mutex. */
 static bool vq_memory_access_ok(void __user *log_base, struct vhost_iotlb *umem,
 				int log_all)
@@ -1118,6 +1416,11 @@ static inline void __user *vhost_vq_meta_fetch(struct vhost_virtqueue *vq,
 
 /* Can we switch to this memory table? */
 /* Caller should have device mutex but not vq mutex */
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2104| <<vhost_log_access_ok>> return memory_access_ok(dev, dev->umem, 1);
+ *   - drivers/vhost/vhost.c|2231| <<vhost_set_memory>> if (!memory_access_ok(d, newumem, 0))
+ */
 static bool memory_access_ok(struct vhost_dev *d, struct vhost_iotlb *umem,
 			     int log_all)
 {
@@ -1129,6 +1432,19 @@ static bool memory_access_ok(struct vhost_dev *d, struct vhost_iotlb *umem,
 
 		mutex_lock(&d->vqs[i]->mutex);
 		log = log_all || vhost_has_feature(d->vqs[i], VHOST_F_LOG_ALL);
+		/*
+		 * 在以下设置vhost_virtqueue->log_base:
+		 *   - drivers/vhost/vhost.c|544| <<vhost_vq_reset>> vq->log_base = NULL;
+		 *   - drivers/vhost/vhost.c|2499| <<vhost_dev_ioctl(VHOST_SET_LOG_BASE)>> vq->log_base = base;
+		 * 在以下使用vhost_virtqueue->log_base:
+		 *   - drivers/vhost/vhost.c|1360| <<memory_access_ok>> ok = vq_memory_access_ok(d->vqs[i]->log_base, umem, log);
+		 *   - drivers/vhost/vhost.c|2082| <<vhost_vq_access_ok>> if (!vq_log_access_ok(vq, vq->log_base))
+		 *   - drivers/vhost/vhost.c|2222| <<vhost_vring_set_addr>> if (!vq_log_used_access_ok(vq, vq->log_base,
+		 *             a.flags & (0x1 << VHOST_VRING_F_LOG), a.log_guest_addr))
+		 *   - drivers/vhost/vhost.c|2620| <<log_write_hva>> r = log_write(vq->log_base, u->start + start - u->addr, l);
+		 *   - drivers/vhost/vhost.c|2658| <<log_used>> return log_write(vq->log_base, vq->log_addr + used_offset, len);
+		 *   - drivers/vhost/vhost.c|2738| <<vhost_log_write>> r = log_write(vq->log_base, log[i].addr, l);
+		 */
 		/* If ring is inactive, will check when it's enabled. */
 		if (d->vqs[i]->private_data)
 			ok = vq_memory_access_ok(d->vqs[i]->log_base,
@@ -1166,6 +1482,29 @@ static int vhost_copy_to_user(struct vhost_virtqueue *vq, void __user *to,
 		if (uaddr)
 			return __copy_to_user(uaddr, from, size);
 
+		/*
+		 * called by:
+		 *   - drivers/vhost/vhost.c|1228| <<vhost_copy_to_user>> ret = translate_desc(vq,
+		 *             (u64)(uintptr_t)to, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+		 *             VHOST_ACCESS_WO);
+		 *   - drivers/vhost/vhost.c|1263| <<vhost_copy_from_user>> ret = translate_desc(vq,
+		 *             (u64)(uintptr_t)from, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+		 *             VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|1288| <<__vhost_get_user_slow>> ret = translate_desc(vq,
+		 *             (u64)(uintptr_t)addr, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+		 *             VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|2359| <<log_used>> ret = translate_desc(vq,
+		 *             (uintptr_t)vq->used + used_offset, len, iov, 64, VHOST_ACCESS_WO);
+		 *   - drivers/vhost/vhost.c|2563| <<get_indirect>> ret = translate_desc(vq,
+		 *             vhost64_to_cpu(vq, indirect->addr), len, vq->indirect, UIO_MAXIOV,
+		 *             VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|2604| <<get_indirect>> ret = translate_desc(vq,
+		 *             vhost64_to_cpu(vq, desc.addr), vhost32_to_cpu(vq, desc.len),
+		 *             iov + iov_count, iov_size - iov_count, access);
+		 *   - drivers/vhost/vhost.c|2742| <<vhost_get_vq_desc>> ret = translate_desc(vq,
+		 *             vhost64_to_cpu(vq, desc.addr), vhost32_to_cpu(vq, desc.len),
+		 *             iov + iov_count, iov_size - iov_count, access);
+		 */
 		ret = translate_desc(vq, (u64)(uintptr_t)to, size, vq->iotlb_iov,
 				     ARRAY_SIZE(vq->iotlb_iov),
 				     VHOST_ACCESS_WO);
@@ -1201,6 +1540,29 @@ static int vhost_copy_from_user(struct vhost_virtqueue *vq, void *to,
 		if (uaddr)
 			return __copy_from_user(to, uaddr, size);
 
+		/*
+		 * called by:
+		 *   - drivers/vhost/vhost.c|1228| <<vhost_copy_to_user>> ret = translate_desc(vq,
+		 *             (u64)(uintptr_t)to, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+		 *             VHOST_ACCESS_WO);
+		 *   - drivers/vhost/vhost.c|1263| <<vhost_copy_from_user>> ret = translate_desc(vq,
+		 *             (u64)(uintptr_t)from, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+		 *             VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|1288| <<__vhost_get_user_slow>> ret = translate_desc(vq,
+		 *             (u64)(uintptr_t)addr, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+		 *             VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|2359| <<log_used>> ret = translate_desc(vq,
+		 *             (uintptr_t)vq->used + used_offset, len, iov, 64, VHOST_ACCESS_WO);
+		 *   - drivers/vhost/vhost.c|2563| <<get_indirect>> ret = translate_desc(vq,
+		 *             vhost64_to_cpu(vq, indirect->addr), len, vq->indirect, UIO_MAXIOV,
+		 *             VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|2604| <<get_indirect>> ret = translate_desc(vq,
+		 *             vhost64_to_cpu(vq, desc.addr), vhost32_to_cpu(vq, desc.len),
+		 *             iov + iov_count, iov_size - iov_count, access);
+		 *   - drivers/vhost/vhost.c|2742| <<vhost_get_vq_desc>> ret = translate_desc(vq,
+		 *             vhost64_to_cpu(vq, desc.addr), vhost32_to_cpu(vq, desc.len),
+		 *             iov + iov_count, iov_size - iov_count, access);
+		 */
 		ret = translate_desc(vq, (u64)(uintptr_t)from, size, vq->iotlb_iov,
 				     ARRAY_SIZE(vq->iotlb_iov),
 				     VHOST_ACCESS_RO);
@@ -1226,6 +1588,29 @@ static void __user *__vhost_get_user_slow(struct vhost_virtqueue *vq,
 {
 	int ret;
 
+	/*
+	 * called by:
+	 *   - drivers/vhost/vhost.c|1228| <<vhost_copy_to_user>> ret = translate_desc(vq,
+	 *             (u64)(uintptr_t)to, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+	 *             VHOST_ACCESS_WO);
+	 *   - drivers/vhost/vhost.c|1263| <<vhost_copy_from_user>> ret = translate_desc(vq,
+	 *             (u64)(uintptr_t)from, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+	 *             VHOST_ACCESS_RO);
+	 *   - drivers/vhost/vhost.c|1288| <<__vhost_get_user_slow>> ret = translate_desc(vq,
+	 *             (u64)(uintptr_t)addr, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+	 *             VHOST_ACCESS_RO);
+	 *   - drivers/vhost/vhost.c|2359| <<log_used>> ret = translate_desc(vq,
+	 *             (uintptr_t)vq->used + used_offset, len, iov, 64, VHOST_ACCESS_WO);
+	 *   - drivers/vhost/vhost.c|2563| <<get_indirect>> ret = translate_desc(vq,
+	 *             vhost64_to_cpu(vq, indirect->addr), len, vq->indirect, UIO_MAXIOV,
+	 *             VHOST_ACCESS_RO);
+	 *   - drivers/vhost/vhost.c|2604| <<get_indirect>> ret = translate_desc(vq,
+	 *             vhost64_to_cpu(vq, desc.addr), vhost32_to_cpu(vq, desc.len),
+	 *             iov + iov_count, iov_size - iov_count, access);
+	 *   - drivers/vhost/vhost.c|2742| <<vhost_get_vq_desc>> ret = translate_desc(vq,
+	 *             vhost64_to_cpu(vq, desc.addr), vhost32_to_cpu(vq, desc.len),
+	 *             iov + iov_count, iov_size - iov_count, access);
+	 */
 	ret = translate_desc(vq, (u64)(uintptr_t)addr, size, vq->iotlb_iov,
 			     ARRAY_SIZE(vq->iotlb_iov),
 			     VHOST_ACCESS_RO);
@@ -1697,6 +2082,12 @@ static void vhost_vq_meta_update(struct vhost_virtqueue *vq,
 		vq->meta_iotlb[type] = map;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2090| <<vq_meta_prefetch>> return iotlb_access_ok(vq, VHOST_MAP_RO, (u64)(uintptr_t)vq->desc,
+ *   - drivers/vhost/vhost.c|2092| <<vq_meta_prefetch>> iotlb_access_ok(vq, VHOST_MAP_RO, (u64)(uintptr_t)vq->avail,
+ *   - drivers/vhost/vhost.c|2095| <<vq_meta_prefetch>> iotlb_access_ok(vq, VHOST_MAP_WO, (u64)(uintptr_t)vq->used,
+ */
 static bool iotlb_access_ok(struct vhost_virtqueue *vq,
 			    int access, u64 addr, u64 len, int type)
 {
@@ -1748,6 +2139,13 @@ int vq_meta_prefetch(struct vhost_virtqueue *vq)
 }
 EXPORT_SYMBOL_GPL(vq_meta_prefetch);
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|1860| <<vhost_net_set_features>> !vhost_log_access_ok(&n->dev))
+ *   - drivers/vhost/scsi.c|2517| <<vhost_scsi_set_features>> !vhost_log_access_ok(&vs->dev)) {
+ *   - drivers/vhost/test.c|271| <<vhost_test_set_features>> !vhost_log_access_ok(&n->dev)) {
+ *   - drivers/vhost/vsock.c|903| <<vhost_vsock_set_features>> !vhost_log_access_ok(&vsock->dev)) {
+ */
 /* Can we log writes? */
 /* Caller should have device mutex but not vq mutex */
 bool vhost_log_access_ok(struct vhost_dev *dev)
@@ -1756,6 +2154,11 @@ bool vhost_log_access_ok(struct vhost_dev *dev)
 }
 EXPORT_SYMBOL_GPL(vhost_log_access_ok);
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2180| <<vq_log_access_ok>> vq_log_used_access_ok(vq, log_base, vq->log_used, vq->log_addr);
+ *   - drivers/vhost/vhost.c|2353| <<vhost_vring_set_addr>> if (!vq_log_used_access_ok(vq, vq->log_base,
+ */
 static bool vq_log_used_access_ok(struct vhost_virtqueue *vq,
 				  void __user *log_base,
 				  bool log_used,
@@ -1772,9 +2175,34 @@ static bool vq_log_used_access_ok(struct vhost_virtqueue *vq,
 
 /* Verify access for write logging. */
 /* Caller should have vq mutex and device mutex */
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2137| <<vhost_vq_access_ok>> if (!vq_log_access_ok(vq, vq->log_base))
+ *   - drivers/vhost/vhost.c|2585| <<vhost_dev_ioctl>> if (vq->private_data && !vq_log_access_ok(vq, base))
+ *
+ * 判断log_base合法性的唯一入口!
+ */
 static bool vq_log_access_ok(struct vhost_virtqueue *vq,
 			     void __user *log_base)
 {
+	/*
+	 * 在以下设置vhost_virtqueue->log_used:
+	 *   - drivers/vhost/vhost.c|539| <<vhost_vq_reset>> vq->log_used = false;
+	 *   - drivers/vhost/vhost.c|2228| <<vhost_vring_set_addr>> vq->log_used = !!(a.flags & (0x1 << VHOST_VRING_F_LOG));
+	 * 在以下使用vhost_virtqueue->log_used:
+	 *   - drivers/vhost/vhost.c|2075| <<vq_log_access_ok>> vq_log_used_access_ok(vq, log_base, vq->log_used, vq->log_addr);
+	 *   - drivers/vhost/vhost.c|2765| <<vhost_update_used_flags>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|2793| <<vhost_update_avail_event>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|3331| <<__vhost_add_used_n>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|3395| <<vhost_add_used_n>> if (unlikely(vq->log_used)) {
+	 *
+	 * 在以下设置vhost_virtqueue->log_addr:
+	 *   - drivers/vhost/vhost.c|540| <<vhost_vq_reset>> vq->log_addr = -1ull;
+	 *   - drivers/vhost/vhost.c|2231| <<vhost_vring_set_addr>> vq->log_addr = a.log_guest_addr;
+	 * 在以下使用vhost_virtqueue->log_addr:
+	 *   - drivers/vhost/vhost.c|2075| <<vq_log_access_ok>> vq_log_used_access_ok(vq, log_base, vq->log_used, vq->log_addr);
+	 *   - drivers/vhost/vhost.c|2658| <<log_used>> return log_write(vq->log_base, vq->log_addr + used_offset, len);
+	 */
 	return vq_memory_access_ok(log_base, vq->umem,
 				   vhost_has_feature(vq, VHOST_F_LOG_ALL)) &&
 		vq_log_used_access_ok(vq, log_base, vq->log_used, vq->log_addr);
@@ -1784,6 +2212,19 @@ static bool vq_log_access_ok(struct vhost_virtqueue *vq,
 /* Caller should have vq mutex and device mutex */
 bool vhost_vq_access_ok(struct vhost_virtqueue *vq)
 {
+	/*
+	 * 在以下设置vhost_virtqueue->log_base:
+	 *   - drivers/vhost/vhost.c|544| <<vhost_vq_reset>> vq->log_base = NULL;
+	 *   - drivers/vhost/vhost.c|2499| <<vhost_dev_ioctl(VHOST_SET_LOG_BASE)>> vq->log_base = base;
+	 * 在以下使用vhost_virtqueue->log_base:
+	 *   - drivers/vhost/vhost.c|1360| <<memory_access_ok>> ok = vq_memory_access_ok(d->vqs[i]->log_base, umem, log);
+	 *   - drivers/vhost/vhost.c|2082| <<vhost_vq_access_ok>> if (!vq_log_access_ok(vq, vq->log_base))
+	 *   - drivers/vhost/vhost.c|2222| <<vhost_vring_set_addr>> if (!vq_log_used_access_ok(vq, vq->log_base,
+	 *             a.flags & (0x1 << VHOST_VRING_F_LOG), a.log_guest_addr))
+	 *   - drivers/vhost/vhost.c|2620| <<log_write_hva>> r = log_write(vq->log_base, u->start + start - u->addr, l);
+	 *   - drivers/vhost/vhost.c|2658| <<log_used>> return log_write(vq->log_base, vq->log_addr + used_offset, len);
+	 *   - drivers/vhost/vhost.c|2738| <<vhost_log_write>> r = log_write(vq->log_base, log[i].addr, l);
+	 */
 	if (!vq_log_access_ok(vq, vq->log_base))
 		return false;
 
@@ -1794,6 +2235,14 @@ EXPORT_SYMBOL_GPL(vhost_vq_access_ok);
 static long vhost_set_memory(struct vhost_dev *d, struct vhost_memory __user *m)
 {
 	struct vhost_memory mem, *newmem;
+	/*
+	 * struct vhost_memory_region {
+	 *     __u64 guest_phys_addr;
+	 *     __u64 memory_size; // bytes
+	 *     __u64 userspace_addr;
+	 *     __u64 flags_padding; // No flags are currently specified.
+	 * };
+	 */
 	struct vhost_memory_region *region;
 	struct vhost_iotlb *newumem, *oldumem;
 	unsigned long size = offsetof(struct vhost_memory, regions);
@@ -1879,6 +2328,10 @@ static long vhost_vring_set_num(struct vhost_dev *d,
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2401| <<vhost_vring_set_num_addr(VHOST_SET_VRING_ADDR)>> r = vhost_vring_set_addr(d, vq, argp);
+ */
 static long vhost_vring_set_addr(struct vhost_dev *d,
 				 struct vhost_virtqueue *vq,
 				 void __user *argp)
@@ -1915,6 +2368,19 @@ static long vhost_vring_set_addr(struct vhost_dev *d,
 			(void __user *)(unsigned long)a.used_user_addr))
 			return -EINVAL;
 
+		/*
+		 * 在以下设置vhost_virtqueue->log_base:
+		 *   - drivers/vhost/vhost.c|544| <<vhost_vq_reset>> vq->log_base = NULL;
+		 *   - drivers/vhost/vhost.c|2499| <<vhost_dev_ioctl(VHOST_SET_LOG_BASE)>> vq->log_base = base;
+		 * 在以下使用vhost_virtqueue->log_base:
+		 *   - drivers/vhost/vhost.c|1360| <<memory_access_ok>> ok = vq_memory_access_ok(d->vqs[i]->log_base, umem, log);
+		 *   - drivers/vhost/vhost.c|2082| <<vhost_vq_access_ok>> if (!vq_log_access_ok(vq, vq->log_base))
+		 *   - drivers/vhost/vhost.c|2222| <<vhost_vring_set_addr>> if (!vq_log_used_access_ok(vq, vq->log_base,
+		 *             a.flags & (0x1 << VHOST_VRING_F_LOG), a.log_guest_addr))
+		 *   - drivers/vhost/vhost.c|2620| <<log_write_hva>> r = log_write(vq->log_base, u->start + start - u->addr, l);
+		 *   - drivers/vhost/vhost.c|2658| <<log_used>> return log_write(vq->log_base, vq->log_addr + used_offset, len);
+		 *   - drivers/vhost/vhost.c|2738| <<vhost_log_write>> r = log_write(vq->log_base, log[i].addr, l);
+		 */
 		/* Also validate log access for used ring if enabled. */
 		if (!vq_log_used_access_ok(vq, vq->log_base,
 				a.flags & (0x1 << VHOST_VRING_F_LOG),
@@ -1922,9 +2388,28 @@ static long vhost_vring_set_addr(struct vhost_dev *d,
 			return -EINVAL;
 	}
 
+	/*
+	 * 在以下设置vhost_virtqueue->log_used:
+	 *   - drivers/vhost/vhost.c|539| <<vhost_vq_reset>> vq->log_used = false;
+	 *   - drivers/vhost/vhost.c|2228| <<vhost_vring_set_addr>> vq->log_used = !!(a.flags & (0x1 << VHOST_VRING_F_LOG));
+	 * 在以下使用vhost_virtqueue->log_used:
+	 *   - drivers/vhost/vhost.c|2075| <<vq_log_access_ok>> vq_log_used_access_ok(vq, log_base, vq->log_used, vq->log_addr);
+	 *   - drivers/vhost/vhost.c|2765| <<vhost_update_used_flags>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|2793| <<vhost_update_avail_event>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|3331| <<__vhost_add_used_n>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|3395| <<vhost_add_used_n>> if (unlikely(vq->log_used)) {
+	 */
 	vq->log_used = !!(a.flags & (0x1 << VHOST_VRING_F_LOG));
 	vq->desc = (void __user *)(unsigned long)a.desc_user_addr;
 	vq->avail = (void __user *)(unsigned long)a.avail_user_addr;
+	/*
+	 * 在以下设置vhost_virtqueue->log_addr:
+	 *   - drivers/vhost/vhost.c|540| <<vhost_vq_reset>> vq->log_addr = -1ull;
+	 *   - drivers/vhost/vhost.c|2231| <<vhost_vring_set_addr>> vq->log_addr = a.log_guest_addr;
+	 * 在以下使用vhost_virtqueue->log_addr:
+	 *   - drivers/vhost/vhost.c|2075| <<vq_log_access_ok>> vq_log_used_access_ok(vq, log_base, vq->log_used, vq->log_addr);
+	 *   - drivers/vhost/vhost.c|2658| <<log_used>> return log_write(vq->log_base, vq->log_addr + used_offset, len);
+	 */
 	vq->log_addr = a.log_guest_addr;
 	vq->used = (void __user *)(unsigned long)a.used_user_addr;
 
@@ -2075,6 +2560,18 @@ long vhost_vring_ioctl(struct vhost_dev *d, unsigned int ioctl, void __user *arg
 		r = -ENOIOCTLCMD;
 	}
 
+	/*
+	 * 在以下调用vhost_poll_stop():
+	 *   - drivers/vhost/net.c|439| <<vhost_net_disable_vq>> vhost_poll_stop(poll);
+	 *   - drivers/vhost/test.c|309| <<vhost_test_set_backend>> vhost_poll_stop(&vq->poll);
+	 *   - drivers/vhost/vhost.c|235| <<vhost_poll_start>> vhost_poll_stop(poll);
+	 *   - drivers/vhost/vhost.c|1088| <<vhost_dev_stop>> vhost_poll_stop(&dev->vqs[i]->poll);
+	 *   - drivers/vhost/vhost.c|2244| <<vhost_vring_ioctl>> vhost_poll_stop(&vq->poll);
+	 *
+	 * 注释:
+	 * Stop polling a file. After this function returns, it becomes safe to drop the
+	 * file reference. You must also flush afterwards.
+	 */
 	if (pollstop && vq->handle_kick)
 		vhost_poll_stop(&vq->poll);
 
@@ -2083,6 +2580,17 @@ long vhost_vring_ioctl(struct vhost_dev *d, unsigned int ioctl, void __user *arg
 	if (filep)
 		fput(filep);
 
+	/*
+	 * 在以下调用vhost_poll_start():
+	 *   - drivers/vhost/net.c|454| <<vhost_net_enable_vq>> return vhost_poll_start(poll, sock->file);
+	 *   - drivers/vhost/test.c|324| <<vhost_test_set_backend>> r = vhost_poll_start(&vq->poll, vq->kick);
+	 *   - drivers/vhost/vhost.c|2252| <<vhost_vring_ioctl>> r = vhost_poll_start(&vq->poll, vq->kick);
+	 *   - drivers/vhost/vhost.h|56| <<vhost_vring_ioctl>> int vhost_poll_start(struct vhost_poll *poll, struct file *file);
+	 *
+	 * 注释:
+	 * Start polling a file. We add ourselves to file's wait queue. The caller must
+	 * keep a reference to a file until after vhost_poll_stop is called.
+	 */
 	if (pollstart && vq->handle_kick)
 		r = vhost_poll_start(&vq->poll, vq->kick);
 
@@ -2121,6 +2629,14 @@ int vhost_init_device_iotlb(struct vhost_dev *d)
 }
 EXPORT_SYMBOL_GPL(vhost_init_device_iotlb);
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|1849| <<vhost_net_ioctl>> r = vhost_dev_ioctl(&n->dev, ioctl, argp);
+ *   - drivers/vhost/scsi.c|2648| <<vhost_scsi_ioctl>> r = vhost_dev_ioctl(&vs->dev, ioctl, argp);
+ *   - drivers/vhost/test.c|361| <<vhost_test_ioctl>> r = vhost_dev_ioctl(&n->dev, ioctl, argp);
+ *   - drivers/vhost/vdpa.c|888| <<vhost_vdpa_unlocked_ioctl>> r = vhost_dev_ioctl(&v->vdev, cmd, argp);
+ *   - drivers/vhost/vsock.c|947| <<vhost_vsock_dev_ioctl>> r = vhost_dev_ioctl(&vsock->dev, ioctl, argp); 
+ */
 /* Caller must have device mutex */
 long vhost_dev_ioctl(struct vhost_dev *d, unsigned int ioctl, void __user *argp)
 {
@@ -2158,6 +2674,19 @@ long vhost_dev_ioctl(struct vhost_dev *d, unsigned int ioctl, void __user *argp)
 			void __user *base = (void __user *)(unsigned long)p;
 			vq = d->vqs[i];
 			mutex_lock(&vq->mutex);
+			/*
+			 * 在以下设置vhost_virtqueue->log_base:
+			 *   - drivers/vhost/vhost.c|544| <<vhost_vq_reset>> vq->log_base = NULL;
+			 *   - drivers/vhost/vhost.c|2499| <<vhost_dev_ioctl(VHOST_SET_LOG_BASE)>> vq->log_base = base;
+			 * 在以下使用vhost_virtqueue->log_base:
+			 *   - drivers/vhost/vhost.c|1360| <<memory_access_ok>> ok = vq_memory_access_ok(d->vqs[i]->log_base, umem, log);
+			 *   - drivers/vhost/vhost.c|2082| <<vhost_vq_access_ok>> if (!vq_log_access_ok(vq, vq->log_base))
+			 *   - drivers/vhost/vhost.c|2222| <<vhost_vring_set_addr>> if (!vq_log_used_access_ok(vq, vq->log_base,
+			 *             a.flags & (0x1 << VHOST_VRING_F_LOG), a.log_guest_addr))
+			 *   - drivers/vhost/vhost.c|2620| <<log_write_hva>> r = log_write(vq->log_base, u->start + start - u->addr, l);
+			 *   - drivers/vhost/vhost.c|2658| <<log_used>> return log_write(vq->log_base, vq->log_addr + used_offset, len);
+			 *   - drivers/vhost/vhost.c|2738| <<vhost_log_write>> r = log_write(vq->log_base, log[i].addr, l);
+			 */
 			/* If ring is inactive, will check when it's enabled. */
 			if (vq->private_data && !vq_log_access_ok(vq, base))
 				r = -EFAULT;
@@ -2197,6 +2726,10 @@ EXPORT_SYMBOL_GPL(vhost_dev_ioctl);
  * (instruction directly accesses the data, with an exception table entry
  * returning -EFAULT). See Documentation/arch/x86/exception-tables.rst.
  */
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2370| <<log_write>> r = set_bit_to_user(bit, (void __user *)(unsigned long )log);
+ */
 static int set_bit_to_user(int nr, void __user *addr)
 {
 	unsigned long log = (unsigned long)addr;
@@ -2216,6 +2749,12 @@ static int set_bit_to_user(int nr, void __user *addr)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2401| <<log_write_hva>> r = log_write(vq->log_base, u->start + start - u->addr, l);
+ *   - drivers/vhost/vhost.c|2426| <<log_used>> return log_write(vq->log_base, vq->log_addr + used_offset, len);
+ *   - drivers/vhost/vhost.c|2486| <<vhost_log_write>> r = log_write(vq->log_base, log[i].addr, l);
+ */
 static int log_write(void __user *log_base,
 		     u64 write_address, u64 write_length)
 {
@@ -2242,6 +2781,11 @@ static int log_write(void __user *log_base,
 	return r;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2457| <<log_used>> ret = log_write_hva(vq, (uintptr_t)iov[i].iov_base,
+ *   - drivers/vhost/vhost.c|2476| <<vhost_log_write>> r = log_write_hva(vq, (uintptr_t)iov[i].iov_base,
+ */
 static int log_write_hva(struct vhost_virtqueue *vq, u64 hva, u64 len)
 {
 	struct vhost_iotlb *umem = vq->umem;
@@ -2262,6 +2806,24 @@ static int log_write_hva(struct vhost_virtqueue *vq, u64 hva, u64 len)
 			start = max(u->addr, hva);
 			end = min(u->addr - 1 + u->size, hva - 1 + len);
 			l = end - start + 1;
+			/*
+			 * 在以下设置vhost_virtqueue->log_base:
+			 *   - drivers/vhost/vhost.c|544| <<vhost_vq_reset>> vq->log_base = NULL;
+			 *   - drivers/vhost/vhost.c|2499| <<vhost_dev_ioctl(VHOST_SET_LOG_BASE)>> vq->log_base = base;
+			 * 在以下使用vhost_virtqueue->log_base:
+			 *   - drivers/vhost/vhost.c|1360| <<memory_access_ok>> ok = vq_memory_access_ok(d->vqs[i]->log_base, umem, log);
+			 *   - drivers/vhost/vhost.c|2082| <<vhost_vq_access_ok>> if (!vq_log_access_ok(vq, vq->log_base))
+			 *   - drivers/vhost/vhost.c|2222| <<vhost_vring_set_addr>> if (!vq_log_used_access_ok(vq, vq->log_base,
+			 *             a.flags & (0x1 << VHOST_VRING_F_LOG), a.log_guest_addr))
+			 *   - drivers/vhost/vhost.c|2620| <<log_write_hva>> r = log_write(vq->log_base, u->start + start - u->addr, l);
+			 *   - drivers/vhost/vhost.c|2658| <<log_used>> return log_write(vq->log_base, vq->log_addr + used_offset, len);
+			 *   - drivers/vhost/vhost.c|2738| <<vhost_log_write>> r = log_write(vq->log_base, log[i].addr, l);
+			 *
+			 * called by:
+			 *   - drivers/vhost/vhost.c|2401| <<log_write_hva>> r = log_write(vq->log_base, u->start + start - u->addr, l);
+			 *   - drivers/vhost/vhost.c|2426| <<log_used>> return log_write(vq->log_base, vq->log_addr + used_offset, len);
+			 *   - drivers/vhost/vhost.c|2486| <<vhost_log_write>> r = log_write(vq->log_base, log[i].addr, l);
+			 */
 			r = log_write(vq->log_base,
 				      u->start + start - u->addr,
 				      l);
@@ -2281,20 +2843,80 @@ static int log_write_hva(struct vhost_virtqueue *vq, u64 hva, u64 len)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2512| <<vhost_update_used_flags>> log_used(vq, (used - (void __user *)vq->used),
+ *   - drivers/vhost/vhost.c|2530| <<vhost_update_avail_event>> log_used(vq, (used - (void __user *)vq->used),
+ *   - drivers/vhost/vhost.c|3040| <<__vhost_add_used_n>> log_used(vq, ((void __user *)used - (void __user *)vq->used),
+ *   - drivers/vhost/vhost.c|3097| <<vhost_add_used_n>> log_used(vq, offsetof(struct vring_used, idx),
+ */
 static int log_used(struct vhost_virtqueue *vq, u64 used_offset, u64 len)
 {
 	struct iovec *iov = vq->log_iov;
 	int i, ret;
 
+	/*
+	 * 在以下设置vhost_virtqueue->log_base:
+	 *   - drivers/vhost/vhost.c|544| <<vhost_vq_reset>> vq->log_base = NULL;
+	 *   - drivers/vhost/vhost.c|2499| <<vhost_dev_ioctl(VHOST_SET_LOG_BASE)>> vq->log_base = base;
+	 * 在以下使用vhost_virtqueue->log_base:
+	 *   - drivers/vhost/vhost.c|1360| <<memory_access_ok>> ok = vq_memory_access_ok(d->vqs[i]->log_base, umem, log);
+	 *   - drivers/vhost/vhost.c|2082| <<vhost_vq_access_ok>> if (!vq_log_access_ok(vq, vq->log_base))
+	 *   - drivers/vhost/vhost.c|2222| <<vhost_vring_set_addr>> if (!vq_log_used_access_ok(vq, vq->log_base,
+	 *             a.flags & (0x1 << VHOST_VRING_F_LOG), a.log_guest_addr))
+	 *   - drivers/vhost/vhost.c|2620| <<log_write_hva>> r = log_write(vq->log_base, u->start + start - u->addr, l);
+	 *   - drivers/vhost/vhost.c|2658| <<log_used>> return log_write(vq->log_base, vq->log_addr + used_offset, len);
+	 *   - drivers/vhost/vhost.c|2738| <<vhost_log_write>> r = log_write(vq->log_base, log[i].addr, l);
+	 *
+	 * 在以下设置vhost_virtqueue->log_addr:
+	 *   - drivers/vhost/vhost.c|540| <<vhost_vq_reset>> vq->log_addr = -1ull;
+	 *   - drivers/vhost/vhost.c|2231| <<vhost_vring_set_addr>> vq->log_addr = a.log_guest_addr;
+	 * 在以下使用vhost_virtqueue->log_addr:
+	 *   - drivers/vhost/vhost.c|2075| <<vq_log_access_ok>> vq_log_used_access_ok(vq, log_base, vq->log_used, vq->log_addr);
+	 *   - drivers/vhost/vhost.c|2658| <<log_used>> return log_write(vq->log_base, vq->log_addr + used_offset, len);
+	 *
+	 * called by:
+	 *   - drivers/vhost/vhost.c|2401| <<log_write_hva>> r = log_write(vq->log_base, u->start + start - u->addr, l);
+	 *   - drivers/vhost/vhost.c|2426| <<log_used>> return log_write(vq->log_base, vq->log_addr + used_offset, len);
+	 *   - drivers/vhost/vhost.c|2486| <<vhost_log_write>> r = log_write(vq->log_base, log[i].addr, l);
+	 */
 	if (!vq->iotlb)
 		return log_write(vq->log_base, vq->log_addr + used_offset, len);
 
+	/*
+	 * called by:
+	 *   - drivers/vhost/vhost.c|1228| <<vhost_copy_to_user>> ret = translate_desc(vq,
+	 *             (u64)(uintptr_t)to, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+	 *             VHOST_ACCESS_WO);
+	 *   - drivers/vhost/vhost.c|1263| <<vhost_copy_from_user>> ret = translate_desc(vq,
+	 *             (u64)(uintptr_t)from, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+	 *             VHOST_ACCESS_RO);
+	 *   - drivers/vhost/vhost.c|1288| <<__vhost_get_user_slow>> ret = translate_desc(vq,
+	 *             (u64)(uintptr_t)addr, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+	 *             VHOST_ACCESS_RO);
+	 *   - drivers/vhost/vhost.c|2359| <<log_used>> ret = translate_desc(vq,
+	 *             (uintptr_t)vq->used + used_offset, len, iov, 64, VHOST_ACCESS_WO);
+	 *   - drivers/vhost/vhost.c|2563| <<get_indirect>> ret = translate_desc(vq,
+	 *             vhost64_to_cpu(vq, indirect->addr), len, vq->indirect, UIO_MAXIOV,
+	 *             VHOST_ACCESS_RO);
+	 *   - drivers/vhost/vhost.c|2604| <<get_indirect>> ret = translate_desc(vq,
+	 *             vhost64_to_cpu(vq, desc.addr), vhost32_to_cpu(vq, desc.len),
+	 *             iov + iov_count, iov_size - iov_count, access);
+	 *   - drivers/vhost/vhost.c|2742| <<vhost_get_vq_desc>> ret = translate_desc(vq,
+	 *             vhost64_to_cpu(vq, desc.addr), vhost32_to_cpu(vq, desc.len),
+	 *             iov + iov_count, iov_size - iov_count, access);
+	 */
 	ret = translate_desc(vq, (uintptr_t)vq->used + used_offset,
 			     len, iov, 64, VHOST_ACCESS_WO);
 	if (ret < 0)
 		return ret;
 
 	for (i = 0; i < ret; i++) {
+		/*
+		 * called by:
+		 *   - drivers/vhost/vhost.c|2457| <<log_used>> ret = log_write_hva(vq, (uintptr_t)iov[i].iov_base,
+		 *   - drivers/vhost/vhost.c|2476| <<vhost_log_write>> r = log_write_hva(vq, (uintptr_t)iov[i].iov_base,
+		 */
 		ret = log_write_hva(vq,	(uintptr_t)iov[i].iov_base,
 				    iov[i].iov_len);
 		if (ret)
@@ -2304,6 +2926,10 @@ static int log_used(struct vhost_virtqueue *vq, u64 used_offset, u64 len)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|1352| <<handle_rx>> vhost_log_write(vq, vq_log, log, vhost_len, vq->iov, in);
+ */
 int vhost_log_write(struct vhost_virtqueue *vq, struct vhost_log *log,
 		    unsigned int log_num, u64 len, struct iovec *iov, int count)
 {
@@ -2314,6 +2940,11 @@ int vhost_log_write(struct vhost_virtqueue *vq, struct vhost_log *log,
 
 	if (vq->iotlb) {
 		for (i = 0; i < count; i++) {
+			/*
+			 * called by:
+			 *   - drivers/vhost/vhost.c|2457| <<log_used>> ret = log_write_hva(vq, (uintptr_t)iov[i].iov_base,
+			 *   - drivers/vhost/vhost.c|2476| <<vhost_log_write>> r = log_write_hva(vq, (uintptr_t)iov[i].iov_base,
+			 */
 			r = log_write_hva(vq, (uintptr_t)iov[i].iov_base,
 					  iov[i].iov_len);
 			if (r < 0)
@@ -2324,6 +2955,24 @@ int vhost_log_write(struct vhost_virtqueue *vq, struct vhost_log *log,
 
 	for (i = 0; i < log_num; ++i) {
 		u64 l = min(log[i].len, len);
+		/*
+		 * 在以下设置vhost_virtqueue->log_base:
+		 *   - drivers/vhost/vhost.c|544| <<vhost_vq_reset>> vq->log_base = NULL;
+		 *   - drivers/vhost/vhost.c|2499| <<vhost_dev_ioctl(VHOST_SET_LOG_BASE)>> vq->log_base = base;
+		 * 在以下使用vhost_virtqueue->log_base:
+		 *   - drivers/vhost/vhost.c|1360| <<memory_access_ok>> ok = vq_memory_access_ok(d->vqs[i]->log_base, umem, log);
+		 *   - drivers/vhost/vhost.c|2082| <<vhost_vq_access_ok>> if (!vq_log_access_ok(vq, vq->log_base))
+		 *   - drivers/vhost/vhost.c|2222| <<vhost_vring_set_addr>> if (!vq_log_used_access_ok(vq, vq->log_base,
+		 *             a.flags & (0x1 << VHOST_VRING_F_LOG), a.log_guest_addr))
+		 *   - drivers/vhost/vhost.c|2620| <<log_write_hva>> r = log_write(vq->log_base, u->start + start - u->addr, l);
+		 *   - drivers/vhost/vhost.c|2658| <<log_used>> return log_write(vq->log_base, vq->log_addr + used_offset, len);
+		 *   - drivers/vhost/vhost.c|2738| <<vhost_log_write>> r = log_write(vq->log_base, log[i].addr, l);
+		 *
+		 * called by:
+		 *   - drivers/vhost/vhost.c|2401| <<log_write_hva>> r = log_write(vq->log_base, u->start + start - u->addr, l);
+		 *   - drivers/vhost/vhost.c|2426| <<log_used>> return log_write(vq->log_base, vq->log_addr + used_offset, len);
+		 *   - drivers/vhost/vhost.c|2486| <<vhost_log_write>> r = log_write(vq->log_base, log[i].addr, l);
+		 */
 		r = log_write(vq->log_base, log[i].addr, l);
 		if (r < 0)
 			return r;
@@ -2340,16 +2989,40 @@ int vhost_log_write(struct vhost_virtqueue *vq, struct vhost_log *log,
 }
 EXPORT_SYMBOL_GPL(vhost_log_write);
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2615| <<vhost_vq_init_access>> r = vhost_update_used_flags(vq);
+ *   - drivers/vhost/vhost.c|3338| <<vhost_enable_notify>> r = vhost_update_used_flags(vq);
+ *   - drivers/vhost/vhost.c|3394| <<vhost_disable_notify>> r = vhost_update_used_flags(vq);
+ */
 static int vhost_update_used_flags(struct vhost_virtqueue *vq)
 {
 	void __user *used;
 	if (vhost_put_used_flags(vq))
 		return -EFAULT;
+	/*
+	 * 在以下设置vhost_virtqueue->log_used:
+	 *   - drivers/vhost/vhost.c|539| <<vhost_vq_reset>> vq->log_used = false;
+	 *   - drivers/vhost/vhost.c|2228| <<vhost_vring_set_addr>> vq->log_used = !!(a.flags & (0x1 << VHOST_VRING_F_LOG));
+	 * 在以下使用vhost_virtqueue->log_used:
+	 *   - drivers/vhost/vhost.c|2075| <<vq_log_access_ok>> vq_log_used_access_ok(vq, log_base, vq->log_used, vq->log_addr);
+	 *   - drivers/vhost/vhost.c|2765| <<vhost_update_used_flags>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|2793| <<vhost_update_avail_event>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|3331| <<__vhost_add_used_n>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|3395| <<vhost_add_used_n>> if (unlikely(vq->log_used)) {
+	 */
 	if (unlikely(vq->log_used)) {
 		/* Make sure the flag is seen before log. */
 		smp_wmb();
 		/* Log used flag write. */
 		used = &vq->used->flags;
+		/*
+		 * called by:
+		 *   - drivers/vhost/vhost.c|2512| <<vhost_update_used_flags>> log_used(vq, (used - (void __user *)vq->used),
+		 *   - drivers/vhost/vhost.c|2530| <<vhost_update_avail_event>> log_used(vq, (used - (void __user *)vq->used),
+		 *   - drivers/vhost/vhost.c|3040| <<__vhost_add_used_n>> log_used(vq, ((void __user *)used - (void __user *)vq->used),
+		 *   - drivers/vhost/vhost.c|3097| <<vhost_add_used_n>> log_used(vq, offsetof(struct vring_used, idx),
+		 */
 		log_used(vq, (used - (void __user *)vq->used),
 			 sizeof vq->used->flags);
 		if (vq->log_ctx)
@@ -2358,16 +3031,38 @@ static int vhost_update_used_flags(struct vhost_virtqueue *vq)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|3387| <<vhost_enable_notify>> r = vhost_update_avail_event(vq);
+ */
 static int vhost_update_avail_event(struct vhost_virtqueue *vq)
 {
 	if (vhost_put_avail_event(vq))
 		return -EFAULT;
+	/*
+	 * 在以下设置vhost_virtqueue->log_used:
+	 *   - drivers/vhost/vhost.c|539| <<vhost_vq_reset>> vq->log_used = false;
+	 *   - drivers/vhost/vhost.c|2228| <<vhost_vring_set_addr>> vq->log_used = !!(a.flags & (0x1 << VHOST_VRING_F_LOG));
+	 * 在以下使用vhost_virtqueue->log_used:
+	 *   - drivers/vhost/vhost.c|2075| <<vq_log_access_ok>> vq_log_used_access_ok(vq, log_base, vq->log_used, vq->log_addr);
+	 *   - drivers/vhost/vhost.c|2765| <<vhost_update_used_flags>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|2793| <<vhost_update_avail_event>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|3331| <<__vhost_add_used_n>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|3395| <<vhost_add_used_n>> if (unlikely(vq->log_used)) {
+	 */
 	if (unlikely(vq->log_used)) {
 		void __user *used;
 		/* Make sure the event is seen before log. */
 		smp_wmb();
 		/* Log avail event write */
 		used = vhost_avail_event(vq);
+		/*
+		 * called by:
+		 *   - drivers/vhost/vhost.c|2512| <<vhost_update_used_flags>> log_used(vq, (used - (void __user *)vq->used),
+		 *   - drivers/vhost/vhost.c|2530| <<vhost_update_avail_event>> log_used(vq, (used - (void __user *)vq->used),
+		 *   - drivers/vhost/vhost.c|3040| <<__vhost_add_used_n>> log_used(vq, ((void __user *)used - (void __user *)vq->used),
+		 *   - drivers/vhost/vhost.c|3097| <<vhost_add_used_n>> log_used(vq, offsetof(struct vring_used, idx),
+		 */
 		log_used(vq, (used - (void __user *)vq->used),
 			 sizeof *vhost_avail_event(vq));
 		if (vq->log_ctx)
@@ -2376,6 +3071,14 @@ static int vhost_update_avail_event(struct vhost_virtqueue *vq)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|1658| <<vhost_net_set_backend>> r = vhost_vq_init_access(vq);
+ *   - drivers/vhost/scsi.c|2285| <<vhost_scsi_set_endpoint>> vhost_vq_init_access(vq);
+ *   - drivers/vhost/test.c|213| <<vhost_test_run>> r = vhost_vq_init_access(&n->vqs[index]);
+ *   - drivers/vhost/test.c|306| <<vhost_test_set_backend>> r = vhost_vq_init_access(vq);
+ *   - drivers/vhost/vsock.c|643| <<vhost_vsock_start>> ret = vhost_vq_init_access(vq);
+ */
 int vhost_vq_init_access(struct vhost_virtqueue *vq)
 {
 	__virtio16 last_used_idx;
@@ -2387,6 +3090,12 @@ int vhost_vq_init_access(struct vhost_virtqueue *vq)
 
 	vhost_init_is_le(vq);
 
+	/*
+	 * called by:
+	 *   - drivers/vhost/vhost.c|2615| <<vhost_vq_init_access>> r = vhost_update_used_flags(vq);
+	 *   - drivers/vhost/vhost.c|3338| <<vhost_enable_notify>> r = vhost_update_used_flags(vq);
+	 *   - drivers/vhost/vhost.c|3394| <<vhost_disable_notify>> r = vhost_update_used_flags(vq);
+	 */
 	r = vhost_update_used_flags(vq);
 	if (r)
 		goto err;
@@ -2411,6 +3120,29 @@ int vhost_vq_init_access(struct vhost_virtqueue *vq)
 }
 EXPORT_SYMBOL_GPL(vhost_vq_init_access);
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|1228| <<vhost_copy_to_user>> ret = translate_desc(vq,
+ *             (u64)(uintptr_t)to, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+ *             VHOST_ACCESS_WO);
+ *   - drivers/vhost/vhost.c|1263| <<vhost_copy_from_user>> ret = translate_desc(vq,
+ *             (u64)(uintptr_t)from, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+ *             VHOST_ACCESS_RO);
+ *   - drivers/vhost/vhost.c|1288| <<__vhost_get_user_slow>> ret = translate_desc(vq,
+ *             (u64)(uintptr_t)addr, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+ *             VHOST_ACCESS_RO);
+ *   - drivers/vhost/vhost.c|2359| <<log_used>> ret = translate_desc(vq,
+ *             (uintptr_t)vq->used + used_offset, len, iov, 64, VHOST_ACCESS_WO);
+ *   - drivers/vhost/vhost.c|2563| <<get_indirect>> ret = translate_desc(vq,
+ *             vhost64_to_cpu(vq, indirect->addr), len, vq->indirect, UIO_MAXIOV,
+ *             VHOST_ACCESS_RO);
+ *   - drivers/vhost/vhost.c|2604| <<get_indirect>> ret = translate_desc(vq,
+ *             vhost64_to_cpu(vq, desc.addr), vhost32_to_cpu(vq, desc.len),
+ *             iov + iov_count, iov_size - iov_count, access);
+ *   - drivers/vhost/vhost.c|2742| <<vhost_get_vq_desc>> ret = translate_desc(vq,
+ *             vhost64_to_cpu(vq, desc.addr), vhost32_to_cpu(vq, desc.len),
+ *             iov + iov_count, iov_size - iov_count, access);
+ */
 static int translate_desc(struct vhost_virtqueue *vq, u64 addr, u32 len,
 			  struct iovec iov[], int iov_size, int access)
 {
@@ -2459,6 +3191,11 @@ static int translate_desc(struct vhost_virtqueue *vq, u64 addr, u32 len,
 /* Each buffer in the virtqueues is actually a chain of descriptors.  This
  * function returns the next descriptor in the chain,
  * or -1U if we're at the end. */
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2796| <<get_indirect>> } while ((i = next_desc(vq, &desc)) != -1);
+ *   - drivers/vhost/vhost.c|2961| <<vhost_get_vq_desc>> } while ((i = next_desc(vq, &desc)) != -1);
+ */
 static unsigned next_desc(struct vhost_virtqueue *vq, struct vring_desc *desc)
 {
 	unsigned int next;
@@ -2472,6 +3209,10 @@ static unsigned next_desc(struct vhost_virtqueue *vq, struct vring_desc *desc)
 	return next;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2841| <<vhost_get_vq_desc>> ret = get_indirect(vq, iov, iov_size,
+ */
 static int get_indirect(struct vhost_virtqueue *vq,
 			struct iovec iov[], unsigned int iov_size,
 			unsigned int *out_num, unsigned int *in_num,
@@ -2493,6 +3234,29 @@ static int get_indirect(struct vhost_virtqueue *vq,
 		return -EINVAL;
 	}
 
+	/*
+	 * called by:
+	 *   - drivers/vhost/vhost.c|1228| <<vhost_copy_to_user>> ret = translate_desc(vq,
+	 *             (u64)(uintptr_t)to, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+	 *             VHOST_ACCESS_WO);
+	 *   - drivers/vhost/vhost.c|1263| <<vhost_copy_from_user>> ret = translate_desc(vq,
+	 *             (u64)(uintptr_t)from, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+	 *             VHOST_ACCESS_RO);
+	 *   - drivers/vhost/vhost.c|1288| <<__vhost_get_user_slow>> ret = translate_desc(vq,
+	 *             (u64)(uintptr_t)addr, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+	 *             VHOST_ACCESS_RO);
+	 *   - drivers/vhost/vhost.c|2359| <<log_used>> ret = translate_desc(vq,
+	 *             (uintptr_t)vq->used + used_offset, len, iov, 64, VHOST_ACCESS_WO);
+	 *   - drivers/vhost/vhost.c|2563| <<get_indirect>> ret = translate_desc(vq,
+	 *             vhost64_to_cpu(vq, indirect->addr), len, vq->indirect, UIO_MAXIOV,
+	 *             VHOST_ACCESS_RO);
+	 *   - drivers/vhost/vhost.c|2604| <<get_indirect>> ret = translate_desc(vq,
+	 *             vhost64_to_cpu(vq, desc.addr), vhost32_to_cpu(vq, desc.len),
+	 *             iov + iov_count, iov_size - iov_count, access);
+	 *   - drivers/vhost/vhost.c|2742| <<vhost_get_vq_desc>> ret = translate_desc(vq,
+	 *             vhost64_to_cpu(vq, desc.addr), vhost32_to_cpu(vq, desc.len),
+	 *             iov + iov_count, iov_size - iov_count, access);
+	 */
 	ret = translate_desc(vq, vhost64_to_cpu(vq, indirect->addr), len, vq->indirect,
 			     UIO_MAXIOV, VHOST_ACCESS_RO);
 	if (unlikely(ret < 0)) {
@@ -2534,6 +3298,29 @@ static int get_indirect(struct vhost_virtqueue *vq,
 		else
 			access = VHOST_ACCESS_RO;
 
+		/*
+		 * called by:
+		 *   - drivers/vhost/vhost.c|1228| <<vhost_copy_to_user>> ret = translate_desc(vq,
+		 *             (u64)(uintptr_t)to, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+		 *             VHOST_ACCESS_WO);
+		 *   - drivers/vhost/vhost.c|1263| <<vhost_copy_from_user>> ret = translate_desc(vq,
+		 *             (u64)(uintptr_t)from, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+		 *             VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|1288| <<__vhost_get_user_slow>> ret = translate_desc(vq,
+		 *             (u64)(uintptr_t)addr, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+		 *             VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|2359| <<log_used>> ret = translate_desc(vq,
+		 *             (uintptr_t)vq->used + used_offset, len, iov, 64, VHOST_ACCESS_WO);
+		 *   - drivers/vhost/vhost.c|2563| <<get_indirect>> ret = translate_desc(vq,
+		 *             vhost64_to_cpu(vq, indirect->addr), len, vq->indirect, UIO_MAXIOV,
+		 *             VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|2604| <<get_indirect>> ret = translate_desc(vq,
+		 *             vhost64_to_cpu(vq, desc.addr), vhost32_to_cpu(vq, desc.len),
+		 *             iov + iov_count, iov_size - iov_count, access);
+		 *   - drivers/vhost/vhost.c|2742| <<vhost_get_vq_desc>> ret = translate_desc(vq,
+		 *             vhost64_to_cpu(vq, desc.addr), vhost32_to_cpu(vq, desc.len),
+		 *             iov + iov_count, iov_size - iov_count, access);
+		 */
 		ret = translate_desc(vq, vhost64_to_cpu(vq, desc.addr),
 				     vhost32_to_cpu(vq, desc.len), iov + iov_count,
 				     iov_size - iov_count, access);
@@ -2573,6 +3360,25 @@ static int get_indirect(struct vhost_virtqueue *vq,
  * This function returns the descriptor number found, or vq->num (which is
  * never a valid descriptor number) if none was found.  A negative code is
  * returned on error. */
+/*
+ * called by:
+ *   - drivers/vhost/net.c|583| <<vhost_net_tx_get_vq_desc>> int r = vhost_get_vq_desc(
+ *                tvq, tvq->iov, ARRAY_SIZE(tvq->iov), out_num, in_num, NULL, NULL);
+ *   - drivers/vhost/net.c|595| <<vhost_net_tx_get_vq_desc>> r = vhost_get_vq_desc(
+ *                tvq, tvq->iov, ARRAY_SIZE(tvq->iov), out_num, in_num, NULL, NULL);
+ *   - drivers/vhost/net.c|1041| <<get_rx_bufs>> r = vhost_get_vq_desc(
+ *                vq, vq->iov + seg, ARRAY_SIZE(vq->iov) - seg, &out, &in, log, log_num);
+ *   - drivers/vhost/scsi.c|477| <<vhost_scsi_do_evt_work>> head = vhost_get_vq_desc(
+ *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+ *   - drivers/vhost/scsi.c|957| <<vhost_scsi_get_desc>> vc->head = vhost_get_vq_desc(
+ *                vq, vq->iov, ARRAY_SIZE(vq->iov), &vc->out, &vc->in, NULL, NULL);
+ *   - drivers/vhost/test.c|61| <<handle_vq>> head = vhost_get_vq_desc(
+ *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+ *   - drivers/vhost/vsock.c|127| <<vhost_transport_do_send_pkt>> head = vhost_get_vq_desc(
+ *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+ *   - drivers/vhost/vsock.c|509| <<vhost_vsock_handle_tx_kick>> head = vhost_get_vq_desc(
+ *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+ */
 int vhost_get_vq_desc(struct vhost_virtqueue *vq,
 		      struct iovec iov[], unsigned int iov_size,
 		      unsigned int *out_num, unsigned int *in_num,
@@ -2637,6 +3443,9 @@ int vhost_get_vq_desc(struct vhost_virtqueue *vq,
 			return -EFAULT;
 		}
 		if (desc.flags & cpu_to_vhost16(vq, VRING_DESC_F_INDIRECT)) {
+			/*
+			 * 只在此处调用
+			 */
 			ret = get_indirect(vq, iov, iov_size,
 					   out_num, in_num,
 					   log, log_num, &desc);
@@ -2653,6 +3462,29 @@ int vhost_get_vq_desc(struct vhost_virtqueue *vq,
 			access = VHOST_ACCESS_WO;
 		else
 			access = VHOST_ACCESS_RO;
+		/*
+		 * called by:
+		 *   - drivers/vhost/vhost.c|1228| <<vhost_copy_to_user>> ret = translate_desc(vq,
+		 *             (u64)(uintptr_t)to, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+		 *             VHOST_ACCESS_WO);
+		 *   - drivers/vhost/vhost.c|1263| <<vhost_copy_from_user>> ret = translate_desc(vq,
+		 *             (u64)(uintptr_t)from, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+		 *             VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|1288| <<__vhost_get_user_slow>> ret = translate_desc(vq,
+		 *             (u64)(uintptr_t)addr, size, vq->iotlb_iov, ARRAY_SIZE(vq->iotlb_iov),
+		 *             VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|2359| <<log_used>> ret = translate_desc(vq,
+		 *             (uintptr_t)vq->used + used_offset, len, iov, 64, VHOST_ACCESS_WO);
+		 *   - drivers/vhost/vhost.c|2563| <<get_indirect>> ret = translate_desc(vq,
+		 *             vhost64_to_cpu(vq, indirect->addr), len, vq->indirect, UIO_MAXIOV,
+		 *             VHOST_ACCESS_RO);
+		 *   - drivers/vhost/vhost.c|2604| <<get_indirect>> ret = translate_desc(vq,
+		 *             vhost64_to_cpu(vq, desc.addr), vhost32_to_cpu(vq, desc.len),
+		 *             iov + iov_count, iov_size - iov_count, access);
+		 *   - drivers/vhost/vhost.c|2742| <<vhost_get_vq_desc>> ret = translate_desc(vq,
+		 *             vhost64_to_cpu(vq, desc.addr), vhost32_to_cpu(vq, desc.len),
+		 *             iov + iov_count, iov_size - iov_count, access);
+		 */
 		ret = translate_desc(vq, vhost64_to_cpu(vq, desc.addr),
 				     vhost32_to_cpu(vq, desc.len), iov + iov_count,
 				     iov_size - iov_count, access);
@@ -2693,6 +3525,17 @@ int vhost_get_vq_desc(struct vhost_virtqueue *vq,
 }
 EXPORT_SYMBOL_GPL(vhost_get_vq_desc);
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|831| <<handle_tx_copy>> vhost_discard_vq_desc(vq, 1);
+ *   - drivers/vhost/net.c|852| <<handle_tx_copy>> vhost_discard_vq_desc(vq, 1);
+ *   - drivers/vhost/net.c|960| <<handle_tx_zerocopy>> vhost_discard_vq_desc(vq, 1);
+ *   - drivers/vhost/net.c|1138| <<get_rx_bufs>> vhost_discard_vq_desc(vq, headcount);
+ *   - drivers/vhost/net.c|1245| <<handle_rx>> vhost_discard_vq_desc(vq, headcount);
+ *   - drivers/vhost/net.c|1269| <<handle_rx>> vhost_discard_vq_desc(vq, headcount);
+ *
+ * 把vhost_virtqueue->last_avail_idx减少n
+ */
 /* Reverse the effect of vhost_get_vq_desc. Useful for error handling. */
 void vhost_discard_vq_desc(struct vhost_virtqueue *vq, int n)
 {
@@ -2702,6 +3545,14 @@ EXPORT_SYMBOL_GPL(vhost_discard_vq_desc);
 
 /* After we've used one of their buffers, we tell them about it.  We'll then
  * want to notify the guest, using eventfd. */
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|851| <<vhost_scsi_complete_cmd_work>> vhost_add_used(cmd->tvc_vq, cmd->tvc_vq_desc, 0);
+ *   - drivers/vhost/vhost.c|3122| <<vhost_add_used_and_signal>> vhost_add_used(vq, head, len);
+ *   - drivers/vhost/vhost.h|214| <<vhost_add_used_and_signal>> int vhost_add_used(struct vhost_virtqueue *, unsigned int head, int len);
+ *   - drivers/vhost/vsock.c|235| <<vhost_transport_do_send_pkt>> vhost_add_used(vq, head, sizeof(*hdr) + payload_len);
+ *   - drivers/vhost/vsock.c|581| <<vhost_vsock_handle_tx_kick>> vhost_add_used(vq, head, 0);
+ */
 int vhost_add_used(struct vhost_virtqueue *vq, unsigned int head, int len)
 {
 	struct vring_used_elem heads = {
@@ -2709,10 +3560,20 @@ int vhost_add_used(struct vhost_virtqueue *vq, unsigned int head, int len)
 		cpu_to_vhost32(vq, len)
 	};
 
+	/*
+	 * called by:
+	 *   - drivers/vhost/vhost.c|2997| <<vhost_add_used>> return vhost_add_used_n(vq, &heads, 1);
+	 *   - drivers/vhost/vhost.c|3140| <<vhost_add_used_and_signal_n>> vhost_add_used_n(vq, heads, count);
+	 */
 	return vhost_add_used_n(vq, &heads, 1);
 }
 EXPORT_SYMBOL_GPL(vhost_add_used);
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|3043| <<vhost_add_used_n>> r = __vhost_add_used_n(vq, heads, n);
+ *   - drivers/vhost/vhost.c|3049| <<vhost_add_used_n>> r = __vhost_add_used_n(vq, heads, count);
+ */
 static int __vhost_add_used_n(struct vhost_virtqueue *vq,
 			    struct vring_used_elem *heads,
 			    unsigned count)
@@ -2727,9 +3588,27 @@ static int __vhost_add_used_n(struct vhost_virtqueue *vq,
 		vq_err(vq, "Failed to write used");
 		return -EFAULT;
 	}
+	/*
+	 * 在以下设置vhost_virtqueue->log_used:
+	 *   - drivers/vhost/vhost.c|539| <<vhost_vq_reset>> vq->log_used = false;
+	 *   - drivers/vhost/vhost.c|2228| <<vhost_vring_set_addr>> vq->log_used = !!(a.flags & (0x1 << VHOST_VRING_F_LOG));
+	 * 在以下使用vhost_virtqueue->log_used:
+	 *   - drivers/vhost/vhost.c|2075| <<vq_log_access_ok>> vq_log_used_access_ok(vq, log_base, vq->log_used, vq->log_addr);
+	 *   - drivers/vhost/vhost.c|2765| <<vhost_update_used_flags>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|2793| <<vhost_update_avail_event>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|3331| <<__vhost_add_used_n>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|3395| <<vhost_add_used_n>> if (unlikely(vq->log_used)) {
+	 */
 	if (unlikely(vq->log_used)) {
 		/* Make sure data is seen before log. */
 		smp_wmb();
+		/*
+		 * called by:
+		 *   - drivers/vhost/vhost.c|2512| <<vhost_update_used_flags>> log_used(vq, (used - (void __user *)vq->used),
+		 *   - drivers/vhost/vhost.c|2530| <<vhost_update_avail_event>> log_used(vq, (used - (void __user *)vq->used),
+		 *   - drivers/vhost/vhost.c|3040| <<__vhost_add_used_n>> log_used(vq, ((void __user *)used - (void __user *)vq->used),
+		 *   - drivers/vhost/vhost.c|3097| <<vhost_add_used_n>> log_used(vq, offsetof(struct vring_used, idx),
+		 */
 		/* Log used ring entry write. */
 		log_used(vq, ((void __user *)used - (void __user *)vq->used),
 			 count * sizeof *used);
@@ -2745,6 +3624,11 @@ static int __vhost_add_used_n(struct vhost_virtqueue *vq,
 	return 0;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|2997| <<vhost_add_used>> return vhost_add_used_n(vq, &heads, 1);
+ *   - drivers/vhost/vhost.c|3140| <<vhost_add_used_and_signal_n>> vhost_add_used_n(vq, heads, count);
+ */
 /* After we've used one of their buffers, we tell them about it.  We'll then
  * want to notify the guest, using eventfd. */
 int vhost_add_used_n(struct vhost_virtqueue *vq, struct vring_used_elem *heads,
@@ -2755,12 +3639,22 @@ int vhost_add_used_n(struct vhost_virtqueue *vq, struct vring_used_elem *heads,
 	start = vq->last_used_idx & (vq->num - 1);
 	n = vq->num - start;
 	if (n < count) {
+		/*
+		 * called by:
+		 *   - drivers/vhost/vhost.c|3043| <<vhost_add_used_n>> r = __vhost_add_used_n(vq, heads, n);
+		 *   - drivers/vhost/vhost.c|3049| <<vhost_add_used_n>> r = __vhost_add_used_n(vq, heads, count);
+		 */
 		r = __vhost_add_used_n(vq, heads, n);
 		if (r < 0)
 			return r;
 		heads += n;
 		count -= n;
 	}
+	/*
+	 * called by:
+	 *   - drivers/vhost/vhost.c|3043| <<vhost_add_used_n>> r = __vhost_add_used_n(vq, heads, n);
+	 *   - drivers/vhost/vhost.c|3049| <<vhost_add_used_n>> r = __vhost_add_used_n(vq, heads, count);
+	 */
 	r = __vhost_add_used_n(vq, heads, count);
 
 	/* Make sure buffer is written before we update index. */
@@ -2769,9 +3663,27 @@ int vhost_add_used_n(struct vhost_virtqueue *vq, struct vring_used_elem *heads,
 		vq_err(vq, "Failed to increment used idx");
 		return -EFAULT;
 	}
+	/*
+	 * 在以下设置vhost_virtqueue->log_used:
+	 *   - drivers/vhost/vhost.c|539| <<vhost_vq_reset>> vq->log_used = false;
+	 *   - drivers/vhost/vhost.c|2228| <<vhost_vring_set_addr>> vq->log_used = !!(a.flags & (0x1 << VHOST_VRING_F_LOG));
+	 * 在以下使用vhost_virtqueue->log_used:
+	 *   - drivers/vhost/vhost.c|2075| <<vq_log_access_ok>> vq_log_used_access_ok(vq, log_base, vq->log_used, vq->log_addr);
+	 *   - drivers/vhost/vhost.c|2765| <<vhost_update_used_flags>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|2793| <<vhost_update_avail_event>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|3331| <<__vhost_add_used_n>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|3395| <<vhost_add_used_n>> if (unlikely(vq->log_used)) {
+	 */
 	if (unlikely(vq->log_used)) {
 		/* Make sure used idx is seen before log. */
 		smp_wmb();
+		/*
+		 * called by:
+		 *   - drivers/vhost/vhost.c|2512| <<vhost_update_used_flags>> log_used(vq, (used - (void __user *)vq->used),
+		 *   - drivers/vhost/vhost.c|2530| <<vhost_update_avail_event>> log_used(vq, (used - (void __user *)vq->used),
+		 *   - drivers/vhost/vhost.c|3040| <<__vhost_add_used_n>> log_used(vq, ((void __user *)used - (void __user *)vq->used),
+		 *   - drivers/vhost/vhost.c|3097| <<vhost_add_used_n>> log_used(vq, offsetof(struct vring_used, idx),
+		 */
 		/* Log used index update. */
 		log_used(vq, offsetof(struct vring_used, idx),
 			 sizeof vq->used->idx);
@@ -2782,6 +3694,10 @@ int vhost_add_used_n(struct vhost_virtqueue *vq, struct vring_used_elem *heads,
 }
 EXPORT_SYMBOL_GPL(vhost_add_used_n);
 
+/*
+ * called by:
+ *   - drivers/vhost/vhost.c|3147| <<vhost_signal>> if (vq->call_ctx.ctx && vhost_notify(dev, vq))
+ */
 static bool vhost_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 {
 	__u16 old, new;
@@ -2819,35 +3735,88 @@ static bool vhost_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 	return vring_need_event(vhost16_to_cpu(vq, event), new, old);
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/scsi.c|859| <<vhost_scsi_complete_cmd_work>> vhost_signal(&svq->vs->dev, &svq->vq);
+ *   - drivers/vhost/vhost.c|3167| <<vhost_add_used_and_signal>> vhost_signal(dev, vq);
+ *   - drivers/vhost/vhost.c|3182| <<vhost_add_used_and_signal_n>> vhost_signal(dev, vq);
+ *   - drivers/vhost/vsock.c|270| <<vhost_transport_do_send_pkt>> vhost_signal(&vsock->dev, vq);
+ *   - drivers/vhost/vsock.c|587| <<vhost_vsock_handle_tx_kick>> vhost_signal(&vsock->dev, vq);
+ */
 /* This actually signals the guest, using eventfd. */
 void vhost_signal(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 {
+	/*
+	 * 只在此处调用vhost_notify()
+	 */
 	/* Signal the Guest tell them we used something up. */
 	if (vq->call_ctx.ctx && vhost_notify(dev, vq))
 		eventfd_signal(vq->call_ctx.ctx);
 }
 EXPORT_SYMBOL_GPL(vhost_signal);
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|969| <<handle_tx_zerocopy>> vhost_add_used_and_signal(&net->dev, vq, head, 0);
+ *   - drivers/vhost/scsi.c|529| <<vhost_scsi_do_evt_work>> vhost_add_used_and_signal(&vs->dev, vq, head, 0);
+ *   - drivers/vhost/scsi.c|969| <<vhost_scsi_send_bad_target>> vhost_add_used_and_signal(&vs->dev, vq, head, 0);
+ *   - drivers/vhost/scsi.c|1331| <<vhost_scsi_send_tmf_resp>> vhost_add_used_and_signal(&vs->dev, vq, vq_desc, 0);
+ *   - drivers/vhost/scsi.c|1430| <<vhost_scsi_send_an_resp>> vhost_add_used_and_signal(&vs->dev, vq, vc->head, 0);
+ *   - drivers/vhost/test.c|87| <<handle_vq>> vhost_add_used_and_signal(&n->dev, vq, head, 0);
+ */
 /* And here's the combo meal deal.  Supersize me! */
 void vhost_add_used_and_signal(struct vhost_dev *dev,
 			       struct vhost_virtqueue *vq,
 			       unsigned int head, int len)
 {
 	vhost_add_used(vq, head, len);
+	/*
+	 * called by:
+	 *   - drivers/vhost/scsi.c|859| <<vhost_scsi_complete_cmd_work>> vhost_signal(&svq->vs->dev, &svq->vq);
+	 *   - drivers/vhost/vhost.c|3167| <<vhost_add_used_and_signal>> vhost_signal(dev, vq);
+	 *   - drivers/vhost/vhost.c|3182| <<vhost_add_used_and_signal_n>> vhost_signal(dev, vq);
+	 *   - drivers/vhost/vsock.c|270| <<vhost_transport_do_send_pkt>> vhost_signal(&vsock->dev, vq);
+	 *   - drivers/vhost/vsock.c|587| <<vhost_vsock_handle_tx_kick>> vhost_signal(&vsock->dev, vq);
+	 */
 	vhost_signal(dev, vq);
 }
 EXPORT_SYMBOL_GPL(vhost_add_used_and_signal);
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|376| <<vhost_zerocopy_signal_used>> vhost_add_used_and_signal_n(vq->dev, vq,
+ *   - drivers/vhost/net.c|460| <<vhost_net_signal_used>> vhost_add_used_and_signal_n(dev, vq, vq->heads, nvq->done_idx);
+ */
 /* multi-buffer version of vhost_add_used_and_signal */
 void vhost_add_used_and_signal_n(struct vhost_dev *dev,
 				 struct vhost_virtqueue *vq,
 				 struct vring_used_elem *heads, unsigned count)
 {
+	/*
+	 * called by:
+	 *   - drivers/vhost/vhost.c|2997| <<vhost_add_used>> return vhost_add_used_n(vq, &heads, 1);
+	 *   - drivers/vhost/vhost.c|3140| <<vhost_add_used_and_signal_n>> vhost_add_used_n(vq, heads, count);
+	 */
 	vhost_add_used_n(vq, heads, count);
+	/*
+	 * called by:
+	 *   - drivers/vhost/scsi.c|859| <<vhost_scsi_complete_cmd_work>> vhost_signal(&svq->vs->dev, &svq->vq);
+	 *   - drivers/vhost/vhost.c|3167| <<vhost_add_used_and_signal>> vhost_signal(dev, vq);
+	 *   - drivers/vhost/vhost.c|3182| <<vhost_add_used_and_signal_n>> vhost_signal(dev, vq);
+	 *   - drivers/vhost/vsock.c|270| <<vhost_transport_do_send_pkt>> vhost_signal(&vsock->dev, vq);
+	 *   - drivers/vhost/vsock.c|587| <<vhost_vsock_handle_tx_kick>> vhost_signal(&vsock->dev, vq);
+	 */
 	vhost_signal(dev, vq);
 }
 EXPORT_SYMBOL_GPL(vhost_add_used_and_signal_n);
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|515| <<vhost_net_busy_poll_try_queue>> if (!vhost_vq_avail_empty(&net->dev, vq)) {
+ *   - drivers/vhost/net.c|557| <<vhost_net_busy_poll>> !vhost_vq_avail_empty(&net->dev, rvq)) ||
+ *   - drivers/vhost/net.c|558| <<vhost_net_busy_poll>> !vhost_vq_avail_empty(&net->dev, tvq))
+ *   - drivers/vhost/net.c|695| <<tx_can_batch>> !vhost_vq_avail_empty(vq->dev, vq);
+ */
 /* return true if we're sure that avaiable ring is empty */
 bool vhost_vq_avail_empty(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 {
@@ -2863,6 +3832,20 @@ bool vhost_vq_avail_empty(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 }
 EXPORT_SYMBOL_GPL(vhost_vq_avail_empty);
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|517| <<vhost_net_busy_poll_try_queue>> } else if (unlikely(vhost_enable_notify(&net->dev, vq))) {
+ *   - drivers/vhost/net.c|569| <<vhost_net_busy_poll>> vhost_enable_notify(&net->dev, rvq);
+ *   - drivers/vhost/net.c|812| <<handle_tx_copy>> } else if (unlikely(vhost_enable_notify(&net->dev,
+ *   - drivers/vhost/net.c|928| <<handle_tx_zerocopy>> } else if (unlikely(vhost_enable_notify(&net->dev, vq))) {
+ *   - drivers/vhost/net.c|1251| <<handle_rx>> } else if (unlikely(vhost_enable_notify(&net->dev, vq))) {
+ *   - drivers/vhost/scsi.c|683| <<vhost_scsi_do_evt_work>> if (vhost_enable_notify(&vs->dev, vq))
+ *   - drivers/vhost/scsi.c|1265| <<vhost_scsi_get_desc>> if (unlikely(vhost_enable_notify(&vs->dev, vq))) {
+ *   - drivers/vhost/test.c|70| <<handle_vq>> if (unlikely(vhost_enable_notify(&n->dev, vq))) {
+ *   - drivers/vhost/vsock.c|123| <<vhost_transport_do_send_pkt>> vhost_enable_notify(&vsock->dev, vq);
+ *   - drivers/vhost/vsock.c|158| <<vhost_transport_do_send_pkt>> if (unlikely(vhost_enable_notify(&vsock->dev, vq))) {
+ *   - drivers/vhost/vsock.c|561| <<vhost_vsock_handle_tx_kick>> if (unlikely(vhost_enable_notify(&vsock->dev, vq))) {
+ */
 /* OK, now we need to know about added descriptors. */
 bool vhost_enable_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 {
@@ -2872,6 +3855,12 @@ bool vhost_enable_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 		return false;
 	vq->used_flags &= ~VRING_USED_F_NO_NOTIFY;
 	if (!vhost_has_feature(vq, VIRTIO_RING_F_EVENT_IDX)) {
+		/*
+		 * called by:
+		 *   - drivers/vhost/vhost.c|2615| <<vhost_vq_init_access>> r = vhost_update_used_flags(vq);
+		 *   - drivers/vhost/vhost.c|3338| <<vhost_enable_notify>> r = vhost_update_used_flags(vq);
+		 *   - drivers/vhost/vhost.c|3394| <<vhost_disable_notify>> r = vhost_update_used_flags(vq);
+		 */
 		r = vhost_update_used_flags(vq);
 		if (r) {
 			vq_err(vq, "Failed to enable notification at %p: %d\n",
@@ -2879,6 +3868,9 @@ bool vhost_enable_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 			return false;
 		}
 	} else {
+		/*
+		 * 只在此处调用
+		 */
 		r = vhost_update_avail_event(vq);
 		if (r) {
 			vq_err(vq, "Failed to update avail event index at %p: %d\n",
@@ -2899,6 +3891,26 @@ bool vhost_enable_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 }
 EXPORT_SYMBOL_GPL(vhost_enable_notify);
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|518| <<vhost_net_busy_poll_try_queue>> vhost_disable_notify(&net->dev, vq);
+ *   - drivers/vhost/net.c|541| <<vhost_net_busy_poll>> vhost_disable_notify(&net->dev, vq);
+ *   - drivers/vhost/net.c|814| <<handle_tx_copy>> vhost_disable_notify(&net->dev, vq);
+ *   - drivers/vhost/net.c|929| <<handle_tx_zerocopy>> vhost_disable_notify(&net->dev, vq);
+ *   - drivers/vhost/net.c|1025| <<handle_tx>> vhost_disable_notify(&net->dev, vq);
+ *   - drivers/vhost/net.c|1224| <<handle_rx>> vhost_disable_notify(&net->dev, vq);
+ *   - drivers/vhost/net.c|1254| <<handle_rx>> vhost_disable_notify(&net->dev, vq);
+ *   - drivers/vhost/scsi.c|655| <<vhost_scsi_do_evt_work>> vhost_disable_notify(&vs->dev, vq);
+ *   - drivers/vhost/scsi.c|1266| <<vhost_scsi_get_desc>> vhost_disable_notify(&vs->dev, vq);
+ *   - drivers/vhost/scsi.c|1390| <<vhost_scsi_handle_vq>> vhost_disable_notify(&vs->dev, vq);
+ *   - drivers/vhost/scsi.c|1845| <<vhost_scsi_ctl_handle_vq>> vhost_disable_notify(&vs->dev, vq);
+ *   - drivers/vhost/test.c|58| <<handle_vq>> vhost_disable_notify(&n->dev, vq);
+ *   - drivers/vhost/test.c|71| <<handle_vq>> vhost_disable_notify(&n->dev, vq);
+ *   - drivers/vhost/vsock.c|107| <<vhost_transport_do_send_pkt>> vhost_disable_notify(&vsock->dev, vq);
+ *   - drivers/vhost/vsock.c|159| <<vhost_transport_do_send_pkt>> vhost_disable_notify(&vsock->dev, vq);
+ *   - drivers/vhost/vsock.c|524| <<vhost_vsock_handle_tx_kick>> vhost_disable_notify(&vsock->dev, vq);
+ *   - drivers/vhost/vsock.c|562| <<vhost_vsock_handle_tx_kick>> vhost_disable_notify(&vsock->dev, vq);
+ */
 /* We don't need to be notified again. */
 void vhost_disable_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 {
@@ -2908,6 +3920,12 @@ void vhost_disable_notify(struct vhost_dev *dev, struct vhost_virtqueue *vq)
 		return;
 	vq->used_flags |= VRING_USED_F_NO_NOTIFY;
 	if (!vhost_has_feature(vq, VIRTIO_RING_F_EVENT_IDX)) {
+		/*
+		 * called by:
+		 *   - drivers/vhost/vhost.c|2615| <<vhost_vq_init_access>> r = vhost_update_used_flags(vq);
+		 *   - drivers/vhost/vhost.c|3338| <<vhost_enable_notify>> r = vhost_update_used_flags(vq);
+		 *   - drivers/vhost/vhost.c|3394| <<vhost_disable_notify>> r = vhost_update_used_flags(vq);
+		 */
 		r = vhost_update_used_flags(vq);
 		if (r)
 			vq_err(vq, "Failed to disable notification at %p: %d\n",
diff --git a/drivers/vhost/vhost.h b/drivers/vhost/vhost.h
index bb75a292d..af465121a 100644
--- a/drivers/vhost/vhost.h
+++ b/drivers/vhost/vhost.h
@@ -122,7 +122,26 @@ struct vhost_virtqueue {
 	bool signalled_used_valid;
 
 	/* Log writes to used structure. */
+	/*
+	 * 在以下设置vhost_virtqueue->log_used:
+	 *   - drivers/vhost/vhost.c|539| <<vhost_vq_reset>> vq->log_used = false;
+	 *   - drivers/vhost/vhost.c|2228| <<vhost_vring_set_addr>> vq->log_used = !!(a.flags & (0x1 << VHOST_VRING_F_LOG));
+	 * 在以下使用vhost_virtqueue->log_used:
+	 *   - drivers/vhost/vhost.c|2075| <<vq_log_access_ok>> vq_log_used_access_ok(vq, log_base, vq->log_used, vq->log_addr);
+	 *   - drivers/vhost/vhost.c|2765| <<vhost_update_used_flags>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|2793| <<vhost_update_avail_event>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|3331| <<__vhost_add_used_n>> if (unlikely(vq->log_used)) {
+	 *   - drivers/vhost/vhost.c|3395| <<vhost_add_used_n>> if (unlikely(vq->log_used)) {
+	 */
 	bool log_used;
+	/*
+	 * 在以下设置vhost_virtqueue->log_addr:
+	 *   - drivers/vhost/vhost.c|540| <<vhost_vq_reset>> vq->log_addr = -1ull;
+	 *   - drivers/vhost/vhost.c|2231| <<vhost_vring_set_addr>> vq->log_addr = a.log_guest_addr;
+	 * 在以下使用vhost_virtqueue->log_addr:
+	 *   - drivers/vhost/vhost.c|2075| <<vq_log_access_ok>> vq_log_used_access_ok(vq, log_base, vq->log_used, vq->log_addr);
+	 *   - drivers/vhost/vhost.c|2658| <<log_used>> return log_write(vq->log_base, vq->log_addr + used_offset, len);
+	 */
 	u64 log_addr;
 
 	struct iovec iov[UIO_MAXIOV];
@@ -136,6 +155,19 @@ struct vhost_virtqueue {
 	u64 acked_features;
 	u64 acked_backend_features;
 	/* Log write descriptors */
+	/*
+	 * 在以下设置vhost_virtqueue->log_base:
+	 *   - drivers/vhost/vhost.c|544| <<vhost_vq_reset>> vq->log_base = NULL;
+	 *   - drivers/vhost/vhost.c|2499| <<vhost_dev_ioctl(VHOST_SET_LOG_BASE)>> vq->log_base = base;
+	 * 在以下使用vhost_virtqueue->log_base:
+	 *   - drivers/vhost/vhost.c|1360| <<memory_access_ok>> ok = vq_memory_access_ok(d->vqs[i]->log_base, umem, log);
+	 *   - drivers/vhost/vhost.c|2082| <<vhost_vq_access_ok>> if (!vq_log_access_ok(vq, vq->log_base))
+	 *   - drivers/vhost/vhost.c|2222| <<vhost_vring_set_addr>> if (!vq_log_used_access_ok(vq, vq->log_base,
+	 *             a.flags & (0x1 << VHOST_VRING_F_LOG), a.log_guest_addr))
+	 *   - drivers/vhost/vhost.c|2620| <<log_write_hva>> r = log_write(vq->log_base, u->start + start - u->addr, l);
+	 *   - drivers/vhost/vhost.c|2658| <<log_used>> return log_write(vq->log_base, vq->log_addr + used_offset, len);
+	 *   - drivers/vhost/vhost.c|2738| <<vhost_log_write>> r = log_write(vq->log_base, log[i].addr, l);
+	 */
 	void __user *log_base;
 	struct vhost_log *log;
 	struct iovec log_iov[64];
@@ -147,6 +179,16 @@ struct vhost_virtqueue {
 	/* Ring endianness requested by userspace for cross-endian support. */
 	bool user_be;
 #endif
+	/*
+	 * 在以下使用vhost_virtqueue->busyloop_timeout:
+	 *   - drivers/vhost/net.c|577| <<vhost_net_busy_poll>> busyloop_timeout = poll_rx ?
+	 *             rvq->busyloop_timeout: tvq->busyloop_timeout;
+	 *   - drivers/vhost/net.c|638| <<vhost_net_tx_get_vq_desc>> if (r == tvq->num && tvq->busyloop_timeout) {
+	 *   - drivers/vhost/net.c|1100| <<vhost_net_rx_peek_head_len>> if (!len && rvq->busyloop_timeout) {
+	 *   - drivers/vhost/vhost.c|550| <<vhost_vq_reset>> vq->busyloop_timeout = 0;
+	 *   - drivers/vhost/vhost.c|2369| <<vhost_vring_ioctl(VHOST_SET_VRING_BUSYLOOP_TIMEOUT)>> vq->busyloop_timeout = s.num;
+	 *   - drivers/vhost/vhost.c|2373| <<vhost_vring_ioctl(VHOST_GET_VRING_BUSYLOOP_TIMEOUT)>> s.num = vq->busyloop_timeout;
+	 */
 	u32 busyloop_timeout;
 };
 
@@ -289,6 +331,27 @@ static inline void *vhost_vq_get_backend(struct vhost_virtqueue *vq)
 	return vq->private_data;
 }
 
+/*
+ * called by:
+ *   - drivers/vhost/net.c|1186| <<handle_rx>> vq_log = unlikely(vhost_has_feature(vq, VHOST_F_LOG_ALL)) ? 
+ *   - drivers/vhost/net.c|1188| <<handle_rx>> mergeable = vhost_has_feature(vq, VIRTIO_NET_F_MRG_RXBUF);
+ *   - drivers/vhost/scsi.c|1275| <<vhost_scsi_handle_vq>> bool t10_pi = vhost_has_feature(vq, VIRTIO_SCSI_F_T10_PI);
+ *   - drivers/vhost/scsi.c|2447| <<vhost_scsi_do_plug>> if (vhost_has_feature(vq, VIRTIO_SCSI_F_HOTPLUG))
+ *   - drivers/vhost/vdpa.c|701| <<vhost_vdpa_vring_ioctl>> if (vhost_has_feature(vq, VIRTIO_F_RING_PACKED)) {
+ *   - drivers/vhost/vdpa.c|740| <<vhost_vdpa_vring_ioctl>> if (vhost_has_feature(vq, VIRTIO_F_RING_PACKED)) {
+ *   - drivers/vhost/vhost.c|111| <<vhost_init_is_le>> vq->is_le = vhost_has_feature(vq, VIRTIO_F_VERSION_1) || !vq->user_be;
+ *   - drivers/vhost/vhost.c|131| <<vhost_init_is_le>> vq->is_le = vhost_has_feature(vq, VIRTIO_F_VERSION_1)
+ *   - drivers/vhost/vhost.c|513| <<vhost_get_avail_size>> vhost_has_feature(vq, VIRTIO_RING_F_EVENT_IDX) ? 2 : 0;
+ *   - drivers/vhost/vhost.c|522| <<vhost_get_used_size>> vhost_has_feature(vq, VIRTIO_RING_F_EVENT_IDX) ? 2 : 0;
+ *   - drivers/vhost/vhost.c|1131| <<memory_access_ok>> log = log_all || vhost_has_feature(d->vqs[i], VHOST_F_LOG_ALL);
+ *   - drivers/vhost/vhost.c|1779| <<vq_log_access_ok>> vhost_has_feature(vq, VHOST_F_LOG_ALL)) &&
+ *   - drivers/vhost/vhost.c|1992| <<vhost_vring_ioctl>> if (vhost_has_feature(vq, VIRTIO_F_RING_PACKED)) {
+ *   - drivers/vhost/vhost.c|2007| <<vhost_vring_ioctl>> if (vhost_has_feature(vq, VIRTIO_F_RING_PACKED))
+ *   - drivers/vhost/vhost.c|2814| <<vhost_notify>> if (vhost_has_feature(vq, VIRTIO_F_NOTIFY_ON_EMPTY) &&
+ *   - drivers/vhost/vhost.c|2818| <<vhost_notify>> if (!vhost_has_feature(vq, VIRTIO_RING_F_EVENT_IDX)) {
+ *   - drivers/vhost/vhost.c|2902| <<vhost_enable_notify>> if (!vhost_has_feature(vq, VIRTIO_RING_F_EVENT_IDX)) {
+ *   - drivers/vhost/vhost.c|2938| <<vhost_disable_notify>> if (!vhost_has_feature(vq, VIRTIO_RING_F_EVENT_IDX)) {
+ */
 static inline bool vhost_has_feature(struct vhost_virtqueue *vq, int bit)
 {
 	return vq->acked_features & (1ULL << bit);
diff --git a/drivers/vhost/vringh.c b/drivers/vhost/vringh.c
index 73e153f9b..11b9f8e39 100644
--- a/drivers/vhost/vringh.c
+++ b/drivers/vhost/vringh.c
@@ -1477,6 +1477,14 @@ EXPORT_SYMBOL(vringh_set_iotlb);
  * When you don't have to use riov and wiov anymore, you should clean up them
  * calling vringh_kiov_cleanup() to release the memory, even on error!
  */
+/*
+ * called by:
+ *   - drivers/vdpa/mlx5/net/mlx5_vnet.c|2388| <<mlx5_cvq_kick_handler>> err = vringh_getdesc_iotlb(&cvq->vring, &cvq->riov, &cvq->wiov, &cvq->head,
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim_blk.c|123| <<vdpasim_blk_handle_req>> ret = vringh_getdesc_iotlb(&vq->vring, &vq->out_iov, &vq->in_iov,
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim_net.c|144| <<vdpasim_handle_cvq>> err = vringh_getdesc_iotlb(&cvq->vring, &cvq->in_iov,
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim_net.c|220| <<vdpasim_net_work>> err = vringh_getdesc_iotlb(&txq->vring, &txq->out_iov, NULL,
+ *   - drivers/vdpa/vdpa_sim/vdpa_sim_net.c|240| <<vdpasim_net_work>> err = vringh_getdesc_iotlb(&rxq->vring, NULL, &rxq->in_iov,
+ */
 int vringh_getdesc_iotlb(struct vringh *vrh,
 			 struct vringh_kiov *riov,
 			 struct vringh_kiov *wiov,
diff --git a/drivers/vhost/vsock.c b/drivers/vhost/vsock.c
index 802153e23..c16c091d9 100644
--- a/drivers/vhost/vsock.c
+++ b/drivers/vhost/vsock.c
@@ -124,6 +124,25 @@ vhost_transport_do_send_pkt(struct vhost_vsock *vsock,
 			break;
 		}
 
+		/*
+		 * called by:
+		 *   - drivers/vhost/net.c|583| <<vhost_net_tx_get_vq_desc>> int r = vhost_get_vq_desc(
+		 *                tvq, tvq->iov, ARRAY_SIZE(tvq->iov), out_num, in_num, NULL, NULL);
+		 *   - drivers/vhost/net.c|595| <<vhost_net_tx_get_vq_desc>> r = vhost_get_vq_desc(
+		 *                tvq, tvq->iov, ARRAY_SIZE(tvq->iov), out_num, in_num, NULL, NULL);
+		 *   - drivers/vhost/net.c|1041| <<get_rx_bufs>> r = vhost_get_vq_desc(
+		 *                vq, vq->iov + seg, ARRAY_SIZE(vq->iov) - seg, &out, &in, log, log_num);
+		 *   - drivers/vhost/scsi.c|477| <<vhost_scsi_do_evt_work>> head = vhost_get_vq_desc(
+		 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+		 *   - drivers/vhost/scsi.c|957| <<vhost_scsi_get_desc>> vc->head = vhost_get_vq_desc(
+		 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &vc->out, &vc->in, NULL, NULL);
+		 *   - drivers/vhost/test.c|61| <<handle_vq>> head = vhost_get_vq_desc(
+		 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+		 *   - drivers/vhost/vsock.c|127| <<vhost_transport_do_send_pkt>> head = vhost_get_vq_desc(
+		 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+		 *   - drivers/vhost/vsock.c|509| <<vhost_vsock_handle_tx_kick>> head = vhost_get_vq_desc(
+		 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+		 */
 		head = vhost_get_vq_desc(vq, vq->iov, ARRAY_SIZE(vq->iov),
 					 &out, &in, NULL, NULL);
 		if (head < 0) {
@@ -247,6 +266,14 @@ vhost_transport_do_send_pkt(struct vhost_vsock *vsock,
 			virtio_transport_consume_skb_sent(skb, true);
 		}
 	} while(likely(!vhost_exceeds_weight(vq, ++pkts, total_len)));
+	/*
+	 * 在以下调用vhost_signal():
+	 *   - drivers/vhost/scsi.c|859| <<vhost_scsi_complete_cmd_work>> vhost_signal(&svq->vs->dev, &svq->vq);
+	 *   - drivers/vhost/vhost.c|3167| <<vhost_add_used_and_signal>> vhost_signal(dev, vq);
+	 *   - drivers/vhost/vhost.c|3182| <<vhost_add_used_and_signal_n>> vhost_signal(dev, vq);
+	 *   - drivers/vhost/vsock.c|270| <<vhost_transport_do_send_pkt>> vhost_signal(&vsock->dev, vq);
+	 *   - drivers/vhost/vsock.c|587| <<vhost_vsock_handle_tx_kick>> vhost_signal(&vsock->dev, vq);
+	 */
 	if (added)
 		vhost_signal(&vsock->dev, vq);
 
@@ -289,6 +316,15 @@ vhost_transport_send_pkt(struct sk_buff *skb)
 		atomic_inc(&vsock->queued_replies);
 
 	virtio_vsock_skb_queue_tail(&vsock->send_pkt_queue, skb);
+	/*
+	 * called by:
+	 *   - drivers/vhost/scsi.c|475| <<vhost_scsi_release_cmd>> if (!vhost_vq_work_queue(&svq->vq, &svq->completion_work))
+	 *   - drivers/vhost/scsi.c|1688| <<vhost_scsi_tmf_flush_work>> if (!vhost_vq_work_queue(vq, &tmf->vwork))
+	 *   - drivers/vhost/scsi.c|2022| <<vhost_scsi_send_evt>> if (!vhost_vq_work_queue(vq, &vs->vs_event_work))
+	 *   - drivers/vhost/vhost.c|357| <<vhost_poll_queue>> vhost_vq_work_queue(poll->vq, &poll->work);
+	 *   - drivers/vhost/vsock.c|319| <<vhost_transport_send_pkt>> vhost_vq_work_queue(&vsock->vqs[VSOCK_VQ_RX], &vsock->send_pkt_work);
+	 *   - drivers/vhost/vsock.c|662| <<vhost_vsock_start>> vhost_vq_work_queue(&vsock->vqs[VSOCK_VQ_RX], &vsock->send_pkt_work);
+	 */
 	vhost_vq_work_queue(&vsock->vqs[VSOCK_VQ_RX], &vsock->send_pkt_work);
 
 	rcu_read_unlock();
@@ -506,6 +542,25 @@ static void vhost_vsock_handle_tx_kick(struct vhost_work *work)
 			goto no_more_replies;
 		}
 
+		/*
+		 * called by:
+		 *   - drivers/vhost/net.c|583| <<vhost_net_tx_get_vq_desc>> int r = vhost_get_vq_desc(
+		 *                tvq, tvq->iov, ARRAY_SIZE(tvq->iov), out_num, in_num, NULL, NULL);
+		 *   - drivers/vhost/net.c|595| <<vhost_net_tx_get_vq_desc>> r = vhost_get_vq_desc(
+		 *                tvq, tvq->iov, ARRAY_SIZE(tvq->iov), out_num, in_num, NULL, NULL);
+		 *   - drivers/vhost/net.c|1041| <<get_rx_bufs>> r = vhost_get_vq_desc(
+		 *                vq, vq->iov + seg, ARRAY_SIZE(vq->iov) - seg, &out, &in, log, log_num);
+		 *   - drivers/vhost/scsi.c|477| <<vhost_scsi_do_evt_work>> head = vhost_get_vq_desc(
+		 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+		 *   - drivers/vhost/scsi.c|957| <<vhost_scsi_get_desc>> vc->head = vhost_get_vq_desc(
+		 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &vc->out, &vc->in, NULL, NULL);
+		 *   - drivers/vhost/test.c|61| <<handle_vq>> head = vhost_get_vq_desc(
+		 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+		 *   - drivers/vhost/vsock.c|127| <<vhost_transport_do_send_pkt>> head = vhost_get_vq_desc(
+		 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+		 *   - drivers/vhost/vsock.c|509| <<vhost_vsock_handle_tx_kick>> head = vhost_get_vq_desc(
+		 *                vq, vq->iov, ARRAY_SIZE(vq->iov), &out, &in, NULL, NULL);
+		 */
 		head = vhost_get_vq_desc(vq, vq->iov, ARRAY_SIZE(vq->iov),
 					 &out, &in, NULL, NULL);
 		if (head < 0)
@@ -545,6 +600,14 @@ static void vhost_vsock_handle_tx_kick(struct vhost_work *work)
 	} while(likely(!vhost_exceeds_weight(vq, ++pkts, total_len)));
 
 no_more_replies:
+	/*
+	 * 在以下使用vhost_signal():
+	 *   - drivers/vhost/scsi.c|859| <<vhost_scsi_complete_cmd_work>> vhost_signal(&svq->vs->dev, &svq->vq);
+	 *   - drivers/vhost/vhost.c|3167| <<vhost_add_used_and_signal>> vhost_signal(dev, vq);
+	 *   - drivers/vhost/vhost.c|3182| <<vhost_add_used_and_signal_n>> vhost_signal(dev, vq);
+	 *   - drivers/vhost/vsock.c|270| <<vhost_transport_do_send_pkt>> vhost_signal(&vsock->dev, vq);
+	 *   - drivers/vhost/vsock.c|587| <<vhost_vsock_handle_tx_kick>> vhost_signal(&vsock->dev, vq);
+	 */
 	if (added)
 		vhost_signal(&vsock->dev, vq);
 
@@ -586,6 +649,14 @@ static int vhost_vsock_start(struct vhost_vsock *vsock)
 
 		if (!vhost_vq_get_backend(vq)) {
 			vhost_vq_set_backend(vq, vsock);
+			/*
+			 * called by:
+			 *   - drivers/vhost/net.c|1658| <<vhost_net_set_backend>> r = vhost_vq_init_access(vq);
+			 *   - drivers/vhost/scsi.c|2285| <<vhost_scsi_set_endpoint>> vhost_vq_init_access(vq);
+			 *   - drivers/vhost/test.c|213| <<vhost_test_run>> r = vhost_vq_init_access(&n->vqs[index]);
+			 *   - drivers/vhost/test.c|306| <<vhost_test_set_backend>> r = vhost_vq_init_access(vq);
+			 *   - drivers/vhost/vsock.c|643| <<vhost_vsock_start>> ret = vhost_vq_init_access(vq);
+			 */
 			ret = vhost_vq_init_access(vq);
 			if (ret)
 				goto err_vq;
@@ -597,6 +668,15 @@ static int vhost_vsock_start(struct vhost_vsock *vsock)
 	/* Some packets may have been queued before the device was started,
 	 * let's kick the send worker to send them.
 	 */
+	/*
+	 * called by:
+	 *   - drivers/vhost/scsi.c|475| <<vhost_scsi_release_cmd>> if (!vhost_vq_work_queue(&svq->vq, &svq->completion_work))
+	 *   - drivers/vhost/scsi.c|1688| <<vhost_scsi_tmf_flush_work>> if (!vhost_vq_work_queue(vq, &tmf->vwork))
+	 *   - drivers/vhost/scsi.c|2022| <<vhost_scsi_send_evt>> if (!vhost_vq_work_queue(vq, &vs->vs_event_work))
+	 *   - drivers/vhost/vhost.c|357| <<vhost_poll_queue>> vhost_vq_work_queue(poll->vq, &poll->work);
+	 *   - drivers/vhost/vsock.c|319| <<vhost_transport_send_pkt>> vhost_vq_work_queue(&vsock->vqs[VSOCK_VQ_RX], &vsock->send_pkt_work);
+	 *   - drivers/vhost/vsock.c|662| <<vhost_vsock_start>> vhost_vq_work_queue(&vsock->vqs[VSOCK_VQ_RX], &vsock->send_pkt_work);
+	 */
 	vhost_vq_work_queue(&vsock->vqs[VSOCK_VQ_RX], &vsock->send_pkt_work);
 
 	mutex_unlock(&vsock->dev.mutex);
@@ -678,6 +758,22 @@ static int vhost_vsock_dev_open(struct inode *inode, struct file *file)
 	vsock->vqs[VSOCK_VQ_TX].handle_kick = vhost_vsock_handle_tx_kick;
 	vsock->vqs[VSOCK_VQ_RX].handle_kick = vhost_vsock_handle_rx_kick;
 
+	/*
+	 * called by:
+	 *   - drivers/vhost/net.c|1374| <<vhost_net_open>> vhost_dev_init(dev, vqs,
+	 *             VHOST_NET_VQ_MAX, UIO_MAXIOV + VHOST_NET_BATCH,
+	 *             HOST_NET_PKT_WEIGHT, VHOST_NET_WEIGHT, true, NULL);
+	 *   - drivers/vhost/scsi.c|2258| <<vhost_scsi_open>> vhost_dev_init(&vs->dev, vqs,
+	 *             nvqs, UIO_MAXIOV, VHOST_SCSI_WEIGHT, 0, true, NULL);
+	 *   - drivers/vhost/test.c|122| <<vhost_test_open>> vhost_dev_init(dev, vqs,
+	 *             VHOST_TEST_VQ_MAX, UIO_MAXIOV,
+	 *             VHOST_TEST_PKT_WEIGHT, VHOST_TEST_WEIGHT, true, NULL);
+	 *   - drivers/vhost/vdpa.c|1433| <<vhost_vdpa_open>> vhost_dev_init(dev, vqs,
+	 *             nvqs, 0, 0, 0, false, vhost_vdpa_process_iotlb_msg);
+	 *   - drivers/vhost/vsock.c|719| <<vhost_vsock_dev_open>> vhost_dev_init(&vsock->dev, vqs,
+	 *             ARRAY_SIZE(vsock->vqs), UIO_MAXIOV,
+	 *             VHOST_VSOCK_PKT_WEIGHT, VHOST_VSOCK_WEIGHT, true, NULL);
+	 */
 	vhost_dev_init(&vsock->dev, vqs, ARRAY_SIZE(vsock->vqs),
 		       UIO_MAXIOV, VHOST_VSOCK_PKT_WEIGHT,
 		       VHOST_VSOCK_WEIGHT, true, NULL);
diff --git a/drivers/virtio/virtio.c b/drivers/virtio/virtio.c
index b9095751e..0f89d713c 100644
--- a/drivers/virtio/virtio.c
+++ b/drivers/virtio/virtio.c
@@ -123,10 +123,22 @@ void virtio_check_driver_offered_feature(const struct virtio_device *vdev,
 }
 EXPORT_SYMBOL_GPL(virtio_check_driver_offered_feature);
 
+/*
+ * called by:
+ *   - drivers/virtio/virtio.c|149| <<virtio_config_changed>> __virtio_config_changed(dev);
+ *   - drivers/virtio/virtio.c|198| <<virtio_config_driver_enable>> __virtio_config_changed(dev);
+ *   - drivers/virtio/virtio.c|215| <<virtio_config_core_enable>> __virtio_config_changed(dev);
+ */
 static void __virtio_config_changed(struct virtio_device *dev)
 {
 	struct virtio_driver *drv = drv_to_virtio(dev->dev.driver);
 
+	/*
+	 * 在以下使用virtio_device->config_driver_disabled:
+	 *   - drivers/virtio/virtio.c|130| <<__virtio_config_changed>> if (!dev->config_core_enabled || dev->config_driver_disabled)
+	 *   - drivers/virtio/virtio.c|158| <<virtio_config_driver_disable>> dev->config_driver_disabled = true;
+	 *   - drivers/virtio/virtio.c|173| <<virtio_config_driver_enable>> dev->config_driver_disabled = false;
+	 */
 	if (!dev->config_core_enabled || dev->config_driver_disabled)
 		dev->config_change_pending = true;
 	else if (drv && drv->config_changed) {
@@ -135,6 +147,14 @@ static void __virtio_config_changed(struct virtio_device *dev)
 	}
 }
 
+/*
+ * called by:
+ *   - arch/um/drivers/virtio_uml.c|451| <<vu_req_interrupt>> virtio_config_changed(&vu_dev->vdev);
+ *   - drivers/s390/virtio/virtio_ccw.c|1217| <<virtio_ccw_int_handler>> virtio_config_changed(&vcdev->vdev);
+ *   - drivers/virtio/virtio_mmio.c|313| <<vm_interrupt>> virtio_config_changed(&vm_dev->vdev);
+ *   - drivers/virtio/virtio_pci_common.c|77| <<vp_config_changed>> virtio_config_changed(&vp_dev->vdev);
+ *   - drivers/virtio/virtio_vdpa.c|131| <<virtio_vdpa_config_cb>> virtio_config_changed(&vd_dev->vdev);
+ */
 void virtio_config_changed(struct virtio_device *dev)
 {
 	unsigned long flags;
@@ -152,9 +172,20 @@ EXPORT_SYMBOL_GPL(virtio_config_changed);
  * This is only allowed to be called by a driver and disabling can't
  * be nested.
  */
+/*
+ * called by:
+ *   - drivers/net/virtio_net.c|3657| <<virtnet_close>> virtio_config_driver_disable(vi->vdev);
+ *   - drivers/net/virtio_net.c|6874| <<virtnet_probe>> virtio_config_driver_disable(vi->vdev);
+ */
 void virtio_config_driver_disable(struct virtio_device *dev)
 {
 	spin_lock_irq(&dev->config_lock);
+	/*
+	 * 在以下使用virtio_device->config_driver_disabled:
+	 *   - drivers/virtio/virtio.c|130| <<__virtio_config_changed>> if (!dev->config_core_enabled || dev->config_driver_disabled)
+	 *   - drivers/virtio/virtio.c|158| <<virtio_config_driver_disable>> dev->config_driver_disabled = true;
+	 *   - drivers/virtio/virtio.c|173| <<virtio_config_driver_enable>> dev->config_driver_disabled = false;
+	 */
 	dev->config_driver_disabled = true;
 	spin_unlock_irq(&dev->config_lock);
 }
@@ -170,6 +201,12 @@ EXPORT_SYMBOL_GPL(virtio_config_driver_disable);
 void virtio_config_driver_enable(struct virtio_device *dev)
 {
 	spin_lock_irq(&dev->config_lock);
+	/*
+	 * 在以下使用virtio_device->config_driver_disabled:
+	 *   - drivers/virtio/virtio.c|130| <<__virtio_config_changed>> if (!dev->config_core_enabled || dev->config_driver_disabled)
+	 *   - drivers/virtio/virtio.c|158| <<virtio_config_driver_disable>> dev->config_driver_disabled = true;
+	 *   - drivers/virtio/virtio.c|173| <<virtio_config_driver_enable>> dev->config_driver_disabled = false;
+	 */
 	dev->config_driver_disabled = false;
 	if (dev->config_change_pending)
 		__virtio_config_changed(dev);
@@ -454,6 +491,16 @@ static int virtio_device_of_init(struct virtio_device *dev)
  *
  * Returns: 0 on suceess, -error on failure
  */
+/*
+ * called by:
+ *   - arch/um/drivers/virtio_uml.c|1252| <<virtio_uml_probe>> rc = register_virtio_device(&vu_dev->vdev);
+ *   - drivers/platform/mellanox/mlxbf-tmfifo.c|1233| <<mlxbf_tmfifo_create_vdev>> ret = register_virtio_device(&tm_vdev->vdev);
+ *   - drivers/remoteproc/remoteproc_virtio.c|446| <<rproc_add_virtio_dev>> ret = register_virtio_device(vdev);
+ *   - drivers/s390/virtio/virtio_ccw.c|1401| <<virtio_ccw_online>> ret = register_virtio_device(&vcdev->vdev);
+ *   - drivers/virtio/virtio_mmio.c|688| <<virtio_mmio_probe>> rc = register_virtio_device(&vm_dev->vdev);
+ *   - drivers/virtio/virtio_pci_common.c|723| <<virtio_pci_probe>> rc = register_virtio_device(&vp_dev->vdev);
+ *   - drivers/virtio/virtio_vdpa.c|512| <<virtio_vdpa_probe>> ret = register_virtio_device(&vd_dev->vdev);
+ */
 int register_virtio_device(struct virtio_device *dev)
 {
 	int err;
diff --git a/drivers/virtio/virtio_ring.c b/drivers/virtio/virtio_ring.c
index fdd2d2b07..c3d30eb6f 100644
--- a/drivers/virtio/virtio_ring.c
+++ b/drivers/virtio/virtio_ring.c
@@ -2297,6 +2297,37 @@ static inline int virtqueue_add(struct virtqueue *_vq,
  *
  * Returns zero or a negative error (ie. ENOSPC, ENOMEM, EIO).
  */
+/*
+ * called by:
+ *   - arch/um/drivers/virt-pci.c|135| <<um_pci_send_cmd>> ret = virtqueue_add_sgs(dev->cmd_vq, sgs_list,
+ *   - drivers/block/virtio_blk.c|158| <<virtblk_add_req>> return virtqueue_add_sgs(vq, sgs, num_out, num_in, vbr, GFP_ATOMIC);
+ *   - drivers/crypto/virtio/virtio_crypto_akcipher_algs.c|256| <<__virtio_crypto_akcipher_do_req>> ret = virtqueue_add_sgs(data_vq->vq, sgs, num_out, num_in, vc_req, GFP_ATOMIC);
+ *   - drivers/crypto/virtio/virtio_crypto_core.c|59| <<virtio_crypto_ctrl_vq_request>> err = virtqueue_add_sgs(vcrypto->ctrl_vq, sgs, out_sgs, in_sgs, vc_ctrl_req, GFP_ATOMIC);
+ *   - drivers/crypto/virtio/virtio_crypto_skcipher_algs.c|449| <<__virtio_crypto_skcipher_do_req>> err = virtqueue_add_sgs(data_vq->vq, sgs, num_out,
+ *   - drivers/firmware/arm_scmi/transports/virtio.c|524| <<virtio_send_message>> rc = virtqueue_add_sgs(vioch->vqueue, sgs, 1, 1, msg, GFP_ATOMIC);
+ *   - drivers/gpio/gpio-virtio.c|93| <<_virtio_gpio_req>> ret = virtqueue_add_sgs(vgpio->request_vq, sgs, 1, 1, line, GFP_KERNEL);
+ *   - drivers/gpio/gpio-virtio.c|222| <<virtio_gpio_irq_prepare>> ret = virtqueue_add_sgs(vgpio->event_vq, sgs, 1, 1, irq_line, GFP_ATOMIC);
+ *   - drivers/gpu/drm/virtio/virtgpu_vq.c|357| <<virtio_gpu_queue_ctrl_sgs>> ret = virtqueue_add_sgs(vq, sgs, outcnt, incnt, vbuf, GFP_ATOMIC);
+ *   - drivers/gpu/drm/virtio/virtgpu_vq.c|466| <<virtio_gpu_queue_cursor>> ret = virtqueue_add_sgs(vq, sgs, outcnt, 0, vbuf, GFP_ATOMIC);
+ *   - drivers/i2c/busses/i2c-virtio.c|100| <<virtio_i2c_prepare_reqs>> if (virtqueue_add_sgs(vq, sgs, outcnt, incnt, &reqs[i], GFP_KERNEL)) {
+ *   - drivers/iommu/virtio-iommu.c|247| <<__viommu_add_req>> ret = virtqueue_add_sgs(vq, sg, 1, 1, req, GFP_ATOMIC);
+ *   - drivers/iommu/virtio-iommu.c|251| <<__viommu_add_req>> ret = virtqueue_add_sgs(vq, sg, 1, 1, req, GFP_ATOMIC);
+ *   - drivers/net/virtio_net.c|3461| <<virtnet_send_command_reply>> ret = virtqueue_add_sgs(vi->cvq, sgs, out_num, in_num, vi, GFP_ATOMIC);
+ *   - drivers/nvdimm/nd_virtio.c|78| <<virtio_pmem_flush>> while ((err = virtqueue_add_sgs(vpmem->req_vq, sgs, 1, 1, req_data,
+ *   - drivers/scsi/virtio_scsi.c|471| <<__virtscsi_add_cmd>> return virtqueue_add_sgs(vq, sgs, out_num, in_num, cmd, GFP_ATOMIC);
+ *   - drivers/virtio/virtio_mem.c|1405| <<virtio_mem_send_request>> rc = virtqueue_add_sgs(vm->vq, sgs, 1, 1, vm, GFP_KERNEL);
+ *   - drivers/virtio/virtio_pci_modern.c|93| <<virtqueue_exec_admin_cmd>> ret = virtqueue_add_sgs(vq, sgs, out_num, in_num, cmd, GFP_KERNEL);
+ *   - fs/fuse/virtio_fs.c|1441| <<virtio_fs_enqueue_req>> ret = virtqueue_add_sgs(vq, sgs, out_sgs, in_sgs, req, GFP_ATOMIC);
+ *   - net/9p/trans_virtio.c|281| <<p9_virtio_request>> err = virtqueue_add_sgs(chan->vq, sgs, out_sgs, in_sgs, req,
+ *   - net/9p/trans_virtio.c|509| <<p9_virtio_zc_request>> err = virtqueue_add_sgs(chan->vq, sgs, out_sgs, in_sgs, req,
+ *   - net/vmw_vsock/virtio_transport.c|143| <<virtio_transport_send_skb>> ret = virtqueue_add_sgs(vq, sgs, out_sg, in_sg, skb, gfp);
+ *   - net/vmw_vsock/virtio_transport.c|326| <<virtio_vsock_rx_fill>> ret = virtqueue_add_sgs(vq, &p, 0, 1, skb, GFP_KERNEL);
+ *   - sound/virtio/virtio_card.c|41| <<virtsnd_event_send>> if (virtqueue_add_sgs(vqueue, psgs, 0, 1, event, gfp) || !notify)
+ *   - sound/virtio/virtio_ctl_msg.c|151| <<virtsnd_ctl_msg_send>> rc = virtqueue_add_sgs(queue->vqueue, psgs, nouts, nins, msg,
+ *   - sound/virtio/virtio_pcm_msg.c|234| <<virtsnd_pcm_msg_send>> rc = virtqueue_add_sgs(vqueue, psgs, 2, 1, msg,
+ *   - sound/virtio/virtio_pcm_msg.c|237| <<virtsnd_pcm_msg_send>> rc = virtqueue_add_sgs(vqueue, psgs, 1, 2, msg,
+ *   - tools/virtio/vringh_test.c|517| <<main>> err = virtqueue_add_sgs(vq, sgs, 1, 1, &err, GFP_KERNEL);
+ */
 int virtqueue_add_sgs(struct virtqueue *_vq,
 		      struct scatterlist *sgs[],
 		      unsigned int out_sgs,
diff --git a/drivers/virtio/virtio_vdpa.c b/drivers/virtio/virtio_vdpa.c
index 1f60c9d5c..85fa1133d 100644
--- a/drivers/virtio/virtio_vdpa.c
+++ b/drivers/virtio/virtio_vdpa.c
@@ -108,6 +108,22 @@ static bool virtio_vdpa_notify(struct virtqueue *vq)
 	struct vdpa_device *vdpa = vd_get_vdpa(vq->vdev);
 	const struct vdpa_config_ops *ops = vdpa->config;
 
+	/*
+	 * 在以下调用vdpa_config_ops->kick_vq:
+	 *   - drivers/vhost/vdpa.c|173| <<handle_vq_kick>> ops->kick_vq(v->vdpa, vq - v->vqs);
+	 *   - drivers/virtio/virtio_vdpa.c|111| <<virtio_vdpa_notify>> ops->kick_vq(vdpa, vq->index);
+	 * 在以下设置vdpa_config_ops->kick_vq:
+	 *   - drivers/vdpa/alibaba/eni_vdpa.c|434| <<global>> .kick_vq = eni_vdpa_kick_vq,
+	 *   - drivers/vdpa/ifcvf/ifcvf_main.c|650| <<global>> .kick_vq = ifcvf_vdpa_kick_vq,
+	 *   - drivers/vdpa/mlx5/net/mlx5_vnet.c|3656| <<global>> .kick_vq = mlx5_vdpa_kick_vq,
+	 *   - drivers/vdpa/octeon_ep/octep_vdpa_main.c|344| <<global>> .kick_vq = octep_vdpa_kick_vq,
+	 *   - drivers/vdpa/pds/vdpa_dev.c|581| <<global>> .kick_vq = pds_vdpa_kick_vq,
+	 *   - drivers/vdpa/solidrun/snet_main.c|529| <<global>> .kick_vq = snet_kick_vq,
+	 *   - drivers/vdpa/vdpa_sim/vdpa_sim.c|774| <<global>> .kick_vq = vdpasim_kick_vq,
+	 *   - drivers/vdpa/vdpa_sim/vdpa_sim.c|815| <<global>> .kick_vq = vdpasim_kick_vq,
+	 *   - drivers/vdpa/vdpa_user/vduse_dev.c|787| <<global>> .kick_vq = vduse_vdpa_kick_vq,
+	 *   - drivers/vdpa/virtio_pci/vp_vdpa.c|474| <<global>> .kick_vq = vp_vdpa_kick_vq,
+	 */
 	ops->kick_vq(vdpa, vq->index);
 
 	return true;
@@ -461,6 +477,10 @@ virtio_vdpa_get_vq_affinity(struct virtio_device *vdev, int index)
 	return NULL;
 }
 
+/*
+ * called by:
+ *   - drivers/virtio/virtio_vdpa.c|502| <<virtio_vdpa_probe>> vd_dev->vdev.config = &virtio_vdpa_config_ops;
+ */
 static const struct virtio_config_ops virtio_vdpa_config_ops = {
 	.get		= virtio_vdpa_get,
 	.set		= virtio_vdpa_set,
diff --git a/include/linux/sched.h b/include/linux/sched.h
index 64934e083..ce62cbdfe 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -548,6 +548,49 @@ struct sched_entity {
 
 	struct list_head		group_node;
 	unsigned char			on_rq;
+	/*
+	 * 在以下设置sched_entity->sched_delayed:
+	 *   - kernel/sched/fair.c|5374| <<set_delayed>> se->sched_delayed = 1;
+	 *   - kernel/sched/fair.c|5386| <<clear_delayed>> se->sched_delayed = 0;
+	 * 在以下使用sched_entity->sched_delayed:
+	 *   - include/linux/sched.h|2164| <<task_is_runnable>> return p->on_rq && !p->se.sched_delayed;
+	 *   - kernel/sched/core.c|270| <<sched_core_enqueue>> if (p->se.sched_delayed)
+	 *   - kernel/sched/core.c|283| <<sched_core_dequeue>> if (p->se.sched_delayed)
+	 *   - kernel/sched/core.c|1757| <<uclamp_rq_inc>> if (p->se.sched_delayed)
+	 *   - kernel/sched/core.c|1784| <<uclamp_rq_dec>> if (p->se.sched_delayed)
+	 *   - kernel/sched/core.c|3784| <<ttwu_runnable>> if (p->se.sched_delayed)
+	 *   - kernel/sched/core.c|4190| <<try_to_wake_up>> SCHED_WARN_ON(p->se.sched_delayed);
+	 *   - kernel/sched/core.c|4484| <<__sched_fork>> SCHED_WARN_ON(p->se.sched_delayed);
+	 *   - kernel/sched/core.c|7213| <<rt_mutex_setprio>> if (prev_class != next_class && p->se.sched_delayed)
+	 *   - kernel/sched/ext.c|4969| <<scx_ops_disable_workfn>> if (old_class != new_class && p->se.sched_delayed)
+	 *   - kernel/sched/ext.c|5687| <<scx_ops_enable>> if (old_class != new_class && p->se.sched_delayed)
+	 *   - kernel/sched/fair.c|5412| <<dequeue_entity>> SCHED_WARN_ON(!se->sched_delayed);
+	 *   - kernel/sched/fair.c|5422| <<dequeue_entity>> SCHED_WARN_ON(delay && se->sched_delayed);
+	 *   - kernel/sched/fair.c|5546| <<pick_next_entity>> SCHED_WARN_ON(cfs_rq->next->sched_delayed);
+	 *   - kernel/sched/fair.c|5551| <<pick_next_entity>> if (se->sched_delayed) {
+	 *   - kernel/sched/fair.c|5887| <<throttle_cfs_rq>> if (se->sched_delayed)
+	 *   - kernel/sched/fair.c|5986| <<unthrottle_cfs_rq>> if (se->sched_delayed) {
+	 *   - kernel/sched/fair.c|6853| <<requeue_delayed_entity>> SCHED_WARN_ON(!se->sched_delayed);
+	 *   - kernel/sched/fair.c|6896| <<enqueue_task_fair>> if (!(p->se.sched_delayed &&
+	 *            (task_on_rq_migrating(p) || (flags & ENQUEUE_RESTORE))))
+	 *   - kernel/sched/fair.c|6913| <<enqueue_task_fair>> h_nr_delayed = !!se->sched_delayed;
+	 *   - kernel/sched/fair.c|6917| <<enqueue_task_fair>> if (se->sched_delayed)
+	 *   - kernel/sched/fair.c|7033| <<dequeue_entities>> h_nr_delayed = !!se->sched_delayed;
+	 *   - kernel/sched/fair.c|7134| <<dequeue_task_fair>> if (!(p->se.sched_delayed &&
+	 *            (task_on_rq_migrating(p) || (flags & DEQUEUE_SAVE))))
+	 *   - kernel/sched/fair.c|8629| <<task_dead_fair>> if (se->sched_delayed) {
+	 *   - kernel/sched/fair.c|8634| <<task_dead_fair>> if (se->sched_delayed) {
+	 *   - kernel/sched/fair.c|8719| <<check_preempt_wakeup_fair>> if (sched_feat(NEXT_BUDDY) &&
+	 *            !(wake_flags & WF_FORK) && !pse->sched_delayed) {
+	 *   - kernel/sched/fair.c|13127| <<switched_to_fair>> SCHED_WARN_ON(p->se.sched_delayed);
+	 *   - kernel/sched/fair.c|13162| <<__set_next_task_fair>> SCHED_WARN_ON(se->sched_delayed);
+	 *   - kernel/sched/fair.c|13307| <<unregister_fair_sched_group>> if (se->sched_delayed) {
+	 *   - kernel/sched/fair.c|13309| <<unregister_fair_sched_group>> if (se->sched_delayed) {
+	 *   - kernel/sched/sched.h|916| <<se_runnable>> if (se->sched_delayed)
+	 *   - kernel/sched/sched.h|933| <<se_runnable>> if (se->sched_delayed)
+	 *   - kernel/sched/stats.h|141| <<psi_enqueue>> if (p->se.sched_delayed) {
+	 *   - kernel/sched/syscalls.c|712| <<__sched_setscheduler>> if (prev_class != next_class && p->se.sched_delayed)
+	 */
 	unsigned char			sched_delayed;
 	unsigned char			rel_deadline;
 	unsigned char			custom_slice;
diff --git a/include/linux/skbuff.h b/include/linux/skbuff.h
index 58009fa66..0d1e4e600 100644
--- a/include/linux/skbuff.h
+++ b/include/linux/skbuff.h
@@ -938,6 +938,16 @@ struct sk_buff {
 				nohdr:1,
 				fclone:2,
 				peeked:1,
+				/*
+				 * 在以下设置sk_buff->head_frag:
+				 *   - net/core/skbuff.c|494| <<build_skb>> skb->head_frag = 1;
+				 *   - net/core/skbuff.c|516| <<build_skb_around>> skb->head_frag = 1;
+				 *   - net/core/skbuff.c|562| <<napi_build_skb>> skb->head_frag = 1;
+				 *   - net/core/skbuff.c|780| <<__netdev_alloc_skb>> skb->head_frag = 1;
+				 *   - net/core/skbuff.c|868| <<napi_alloc_skb>> skb->head_frag = 1;
+				 *   - net/core/skbuff.c|6696| <<pskb_carve_inside_header>> skb->head_frag = 0;
+				 *   - net/core/skbuff.c|6829| <<pskb_carve_inside_nonlinear>> skb->head_frag = 0;
+				 */
 				head_frag:1,
 				pfmemalloc:1,
 				pp_recycle:1; /* page_pool recycle indicator */
diff --git a/include/linux/vdpa.h b/include/linux/vdpa.h
index 2e7a30fe6..0531202e8 100644
--- a/include/linux/vdpa.h
+++ b/include/linux/vdpa.h
@@ -374,6 +374,22 @@ struct vdpa_config_ops {
 			      u16 idx, u64 desc_area, u64 driver_area,
 			      u64 device_area);
 	void (*set_vq_num)(struct vdpa_device *vdev, u16 idx, u32 num);
+	/*
+	 * 在以下调用vdpa_config_ops->kick_vq:
+	 *   - drivers/vhost/vdpa.c|173| <<handle_vq_kick>> ops->kick_vq(v->vdpa, vq - v->vqs);
+	 *   - drivers/virtio/virtio_vdpa.c|111| <<virtio_vdpa_notify>> ops->kick_vq(vdpa, vq->index);
+	 * 在以下设置vdpa_config_ops->kick_vq:
+	 *   - drivers/vdpa/alibaba/eni_vdpa.c|434| <<global>> .kick_vq = eni_vdpa_kick_vq,
+	 *   - drivers/vdpa/ifcvf/ifcvf_main.c|650| <<global>> .kick_vq = ifcvf_vdpa_kick_vq,
+	 *   - drivers/vdpa/mlx5/net/mlx5_vnet.c|3656| <<global>> .kick_vq = mlx5_vdpa_kick_vq,
+	 *   - drivers/vdpa/octeon_ep/octep_vdpa_main.c|344| <<global>> .kick_vq = octep_vdpa_kick_vq,
+	 *   - drivers/vdpa/pds/vdpa_dev.c|581| <<global>> .kick_vq = pds_vdpa_kick_vq,
+	 *   - drivers/vdpa/solidrun/snet_main.c|529| <<global>> .kick_vq = snet_kick_vq,
+	 *   - drivers/vdpa/vdpa_sim/vdpa_sim.c|774| <<global>> .kick_vq = vdpasim_kick_vq,
+	 *   - drivers/vdpa/vdpa_sim/vdpa_sim.c|815| <<global>> .kick_vq = vdpasim_kick_vq,
+	 *   - drivers/vdpa/vdpa_user/vduse_dev.c|787| <<global>> .kick_vq = vduse_vdpa_kick_vq,
+	 *   - drivers/vdpa/virtio_pci/vp_vdpa.c|474| <<global>> .kick_vq = vp_vdpa_kick_vq,
+	 */
 	void (*kick_vq)(struct vdpa_device *vdev, u16 idx);
 	void (*kick_vq_with_data)(struct vdpa_device *vdev, u32 data);
 	void (*set_vq_cb)(struct vdpa_device *vdev, u16 idx,
@@ -464,6 +480,17 @@ struct vdpa_device *__vdpa_alloc_device(struct device *parent,
  *
  * Return allocated data structure or ERR_PTR upon error
  */
+/*
+ * called by:
+ *   - drivers/vdpa/alibaba/eni_vdpa.c|480| <<eni_vdpa_probe>> eni_vdpa = vdpa_alloc_device(struct eni_vdpa, vdpa,
+ *   - drivers/vdpa/ifcvf/ifcvf_main.c|707| <<ifcvf_vdpa_dev_add>> adapter = vdpa_alloc_device(struct ifcvf_adapter, vdpa,
+ *   - drivers/vdpa/mlx5/net/mlx5_vnet.c|3879| <<mlx5_vdpa_dev_add>> ndev = vdpa_alloc_device(struct mlx5_vdpa_net, mvdev.vdev, mdev->device, &mgtdev->vdpa_ops,
+ *   - drivers/vdpa/octeon_ep/octep_vdpa_main.c|475| <<octep_vdpa_dev_add>> oct_vdpa = vdpa_alloc_device(struct octep_vdpa, vdpa, &pdev->dev, &octep_vdpa_ops, 1, 1,
+ *   - drivers/vdpa/pds/vdpa_dev.c|634| <<pds_vdpa_dev_add>> pdsv = vdpa_alloc_device(struct pds_vdpa_device, vdpa_dev,
+ *   - drivers/vdpa/solidrun/snet_main.c|1012| <<snet_vdpa_probe_vf>> snet = vdpa_alloc_device(struct snet, vdpa, &pdev->dev, &snet_config_ops, 1, 1, NULL,
+ *   - drivers/vdpa/vdpa_user/vduse_dev.c|2010| <<vduse_dev_init_vdpa>> vdev = vdpa_alloc_device(struct vduse_vdpa, vdpa, dev->dev,
+ *   - drivers/vdpa/virtio_pci/vp_vdpa.c|504| <<vp_vdpa_dev_add>> vp_vdpa = vdpa_alloc_device(struct vp_vdpa, vdpa,
+ */
 #define vdpa_alloc_device(dev_struct, member, parent, config, ngroups, nas, \
 			  name, use_va) \
 			  container_of((__vdpa_alloc_device( \
diff --git a/include/linux/virtio.h b/include/linux/virtio.h
index dd88682e2..c5e2f38c8 100644
--- a/include/linux/virtio.h
+++ b/include/linux/virtio.h
@@ -150,6 +150,12 @@ struct virtio_device {
 	int index;
 	bool failed;
 	bool config_core_enabled;
+	/*
+	 * 在以下使用virtio_device->config_driver_disabled:
+	 *   - drivers/virtio/virtio.c|130| <<__virtio_config_changed>> if (!dev->config_core_enabled || dev->config_driver_disabled)
+	 *   - drivers/virtio/virtio.c|158| <<virtio_config_driver_disable>> dev->config_driver_disabled = true;
+	 *   - drivers/virtio/virtio.c|173| <<virtio_config_driver_enable>> dev->config_driver_disabled = false;
+	 */
 	bool config_driver_disabled;
 	bool config_change_pending;
 	spinlock_t config_lock;
diff --git a/include/target/target_core_base.h b/include/target/target_core_base.h
index 97099a5e3..d75090871 100644
--- a/include/target/target_core_base.h
+++ b/include/target/target_core_base.h
@@ -725,6 +725,21 @@ struct se_dev_attrib {
 	u32		max_unmap_block_desc_count;
 	u32		unmap_granularity;
 	u32		unmap_granularity_alignment;
+	/*
+	 * 在以下使用se_dev_attrib->max_write_same_len:
+	 *   - drivers/target/target_core_configfs.c|595| <<global>> DEF_CONFIGFS_ATTRIB_SHOW(max_write_same_len);
+	 *   - drivers/target/target_core_configfs.c|618| <<global>> DEF_CONFIGFS_ATTRIB_STORE_U32(max_write_same_len);
+	 *   - drivers/target/target_core_configfs.c|1318| <<global>> CONFIGFS_ATTR(, max_write_same_len);
+	 *   - drivers/target/target_core_device.c|775| <<target_alloc_device>> dev->dev_attrib.max_write_same_len = DA_MAX_WRITE_SAME_LEN;
+	 *   - drivers/target/target_core_file.c|174| <<fd_configure_device>> dev->dev_attrib.max_write_same_len = 0xFFFF;
+	 *   - drivers/target/target_core_file.c|192| <<fd_configure_device>> dev->dev_attrib.max_write_same_len = 0x1000;
+	 *   - drivers/target/target_core_iblock.c|143| <<iblock_configure_device>> dev->dev_attrib.max_write_same_len = max_write_zeroes_sectors;
+	 *   - drivers/target/target_core_iblock.c|145| <<iblock_configure_device>> dev->dev_attrib.max_write_same_len = 0xFFFF;
+	 *   - drivers/target/target_core_sbc.c|294| <<sbc_setup_write_same>> if (sectors > cmd->se_dev->dev_attrib.max_write_same_len) {
+	 *   - drivers/target/target_core_sbc.c|296| <<sbc_setup_write_same>> pr_warn("WRITE_SAME sectors: %u exceeds max_write_same_len: %u\n",
+	 *                    sectors, cmd->se_dev->dev_attrib.max_write_same_len);
+	 *   - drivers/target/target_core_spc.c|599| <<spc_emulate_evpd_b0>> put_unaligned_be64(dev->dev_attrib.max_write_same_len, &buf[36]);
+	 */
 	u32		max_write_same_len;
 	u8		submit_type;
 	struct se_device *da_dev;
diff --git a/include/uapi/linux/vhost_types.h b/include/uapi/linux/vhost_types.h
index d7656908f..16964ba19 100644
--- a/include/uapi/linux/vhost_types.h
+++ b/include/uapi/linux/vhost_types.h
@@ -164,6 +164,17 @@ struct vhost_vdpa_iova_range {
 };
 
 /* Feature bits */
+/*
+ * 在以下使用VHOST_F_LOG_ALL:
+ *   - drivers/vhost/vhost.h|302| <<global>> (1ULL << VHOST_F_LOG_ALL) |
+ *   - drivers/vhost/net.c|1315| <<handle_rx>> vq_log = unlikely(vhost_has_feature(vq, VHOST_F_LOG_ALL)) ?
+ *   - drivers/vhost/net.c|1859| <<vhost_net_set_features>> if ((features & (1 << VHOST_F_LOG_ALL)) &&
+ *   - drivers/vhost/scsi.c|2516| <<vhost_scsi_set_features>> if ((features & (1 << VHOST_F_LOG_ALL)) &&
+ *   - drivers/vhost/test.c|270| <<vhost_test_set_features>> if ((features & (1 << VHOST_F_LOG_ALL)) &&
+ *   - drivers/vhost/vhost.c|1398| <<memory_access_ok>> log = log_all || vhost_has_feature(d->vqs[i], VHOST_F_LOG_ALL);
+ *   - drivers/vhost/vhost.c|2151| <<vq_log_access_ok>> vhost_has_feature(vq, VHOST_F_LOG_ALL)) &&
+ *   - drivers/vhost/vsock.c|902| <<vhost_vsock_set_features>> if ((features & (1 << VHOST_F_LOG_ALL)) &&
+ */
 /* Log all write descriptors. Can be changed while device is active. */
 #define VHOST_F_LOG_ALL 26
 /* vhost-net should add virtio_net_hdr for RX, and strip for TX packets. */
diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c
index 26958431d..c1e6d6059 100644
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -5369,6 +5369,10 @@ static void clear_buddies(struct cfs_rq *cfs_rq, struct sched_entity *se)
 
 static __always_inline void return_cfs_rq_runtime(struct cfs_rq *cfs_rq);
 
+/*
+ * called by:
+ *   - kernel/sched/fair.c|5427| <<dequeue_entity>> set_delayed(se);
+ */
 static void set_delayed(struct sched_entity *se)
 {
 	se->sched_delayed = 1;
@@ -5381,6 +5385,11 @@ static void set_delayed(struct sched_entity *se)
 	}
 }
 
+/*
+ * called by:
+ *   - kernel/sched/fair.c|5398| <<finish_delayed_dequeue_entity>> clear_delayed(se);
+ *   - kernel/sched/fair.c|6871| <<requeue_delayed_entity>> clear_delayed(se);
+ */
 static void clear_delayed(struct sched_entity *se)
 {
 	se->sched_delayed = 0;
@@ -5421,9 +5430,22 @@ dequeue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se, int flags)
 
 		SCHED_WARN_ON(delay && se->sched_delayed);
 
+		/*
+		 * 注释:
+		 * Delay dequeueing tasks until they get selected or woken.
+		 *
+		 * By delaying the dequeue for non-eligible tasks, they remain in the
+		 * competition and can burn off their negative lag. When they get selected
+		 * they'll have positive lag by definition.
+		 *
+		 * DELAY_ZERO clips the lag on dequeue (or wakeup) to 0.
+		 */
 		if (sched_feat(DELAY_DEQUEUE) && delay &&
 		    !entity_eligible(cfs_rq, se)) {
 			update_load_avg(cfs_rq, se, 0);
+			/*
+			 * 只在此处调用
+			 */
 			set_delayed(se);
 			return false;
 		}
diff --git a/kernel/vhost_task.c b/kernel/vhost_task.c
index 8800f5acc..02c226e5b 100644
--- a/kernel/vhost_task.c
+++ b/kernel/vhost_task.c
@@ -115,6 +115,14 @@ EXPORT_SYMBOL_GPL(vhost_task_stop);
  * failure. The returned task is inactive, and the caller must fire it up
  * through vhost_task_start().
  */
+/*
+ * called by:
+ *   - arch/x86/kvm/mmu/mmu.c|7420| <<kvm_mmu_post_init_vm>> kvm->arch.nx_huge_page_recovery_thread =
+ *            vhost_task_create(kvm_nx_huge_page_recovery_worker,
+ *                              kvm_nx_huge_page_recovery_worker_kill, kvm, "kvm-nx-lpage-recovery");
+ * drivers/vhost/vhost.c|701| <<vhost_worker_create>> vtsk = vhost_task_create(vhost_run_work_list,
+ *            vhost_worker_killed, worker, name);
+ */
 struct vhost_task *vhost_task_create(bool (*fn)(void *),
 				     void (*handle_sigkill)(void *), void *arg,
 				     const char *name)
diff --git a/lib/iov_iter.c b/lib/iov_iter.c
index 9ec806f98..6c8e5f6bc 100644
--- a/lib/iov_iter.c
+++ b/lib/iov_iter.c
@@ -159,6 +159,41 @@ size_t fault_in_iov_iter_writeable(const struct iov_iter *i, size_t size)
 }
 EXPORT_SYMBOL(fault_in_iov_iter_writeable);
 
+/*
+ * called by:
+ *   - drivers/acpi/pfr_update.c|458| <<pfru_write>> iov_iter_init(&iter, ITER_SOURCE, &iov, 1, len);
+ *   - drivers/fsi/fsi-sbefifo.c|845| <<sbefifo_user_read>> iov_iter_init(&resp_iter, ITER_DEST, &resp_iov, 1, len); 
+ *   - drivers/net/ppp/ppp_generic.c|486| <<ppp_read>> iov_iter_init(&to, ITER_DEST, &iov, 1, count); 
+ *   - drivers/vhost/net.c|704| <<init_iov_iter>> iov_iter_init(iter, ITER_SOURCE, vq->iov, out, len);
+ *   - drivers/vhost/net.c|1357| <<handle_rx>> iov_iter_init(&msg.msg_iter, ITER_DEST, vq->iov, 1, 1);
+ *   - drivers/vhost/net.c|1364| <<handle_rx>> iov_iter_init(&msg.msg_iter, ITER_DEST, vq->iov, in, vhost_len);
+ *   - drivers/vhost/scsi.c|854| <<vhost_scsi_complete_cmd_work>> iov_iter_init(&iov_iter, ITER_DEST,
+ *             cmd->tvc_resp_iov, cmd->tvc_in_iovs, sizeof(v_rsp));
+ *   - drivers/vhost/scsi.c|1307| <<vhost_scsi_get_desc>> iov_iter_init(&vc->out_iter, ITER_SOURCE,
+ *             vq->iov, vc->out, vc->out_size);
+ *   - drivers/vhost/scsi.c|1481| <<vhost_scsi_handle_vq>> iov_iter_init(&in_iter, ITER_DEST,
+ *             &vq->iov[vc.out], vc.in, vc.rsp_size + exp_data_len);
+ *   - drivers/vhost/scsi.c|1634| <<vhost_scsi_send_tmf_resp>> iov_iter_init(&iov_iter, ITER_DEST,
+ *             resp_iov, in_iovs, sizeof(rsp));
+ *   - drivers/vhost/scsi.c|1841| <<vhost_scsi_send_an_resp>> iov_iter_init(&iov_iter, ITER_DEST,
+ *             &vq->iov[vc->out], vc->in, sizeof(rsp));
+ *   - drivers/vhost/vhost.c|1423| <<vhost_copy_to_user>> iov_iter_init(&t, ITER_DEST,
+ *             vq->iotlb_iov, ret, size);
+ *   - drivers/vhost/vhost.c|1485| <<vhost_copy_from_user>> iov_iter_init(&f, ITER_SOURCE,
+ *             vq->iotlb_iov, ret, size);
+ *   - drivers/vhost/vhost.c|3007| <<get_indirect>> iov_iter_init(&from, ITER_SOURCE,
+ *             vq->indirect, ret, len);
+ *   - drivers/vhost/vringh.c|1204| <<copy_from_iotlb>> iov_iter_init(&iter, ITER_SOURCE, ivec.iov.iovec, ret, translated);
+ *   - drivers/vhost/vringh.c|1250| <<copy_to_iotlb>> iov_iter_init(&iter, ITER_DEST, ivec.iov.iovec, ret, translated);
+ *   - drivers/vhost/vsock.c|178| <<vhost_transport_do_send_pkt>> iov_iter_init(&iov_iter, ITER_DEST, &vq->iov[out], in, iov_len);
+ *   - drivers/vhost/vsock.c|388| <<vhost_vsock_alloc_skb>> iov_iter_init(&iov_iter, ITER_SOURCE, vq->iov, out, len);
+ *   - fs/fuse/ioctl.c|328| <<fuse_do_ioctl>> iov_iter_init(&ii, ITER_SOURCE, in_iov, in_iovs, in_size);
+ *   - fs/fuse/ioctl.c|395| <<fuse_do_ioctl>> iov_iter_init(&ii, ITER_DEST, out_iov, out_iovs, transferred);
+ *   - fs/seq_file.c|159| <<seq_read>> iov_iter_init(&iter, ITER_DEST, &iov, 1, size);
+ *   - io_uring/net.c|639| <<io_send>> iov_iter_init(&kmsg->msg.msg_iter, ITER_SOURCE, arg.iovs, ret, arg.out_len);
+ *   - io_uring/net.c|1108| <<io_recv_buf_select>> iov_iter_init(&kmsg->msg.msg_iter, ITER_DEST, arg.iovs, ret, arg.out_len);
+ *   - lib/iov_iter.c|1487| <<__import_iovec>> iov_iter_init(i, type, iov, nr_segs, total_len);
+ */
 void iov_iter_init(struct iov_iter *i, unsigned int direction,
 			const struct iovec *iov, unsigned long nr_segs,
 			size_t count)
diff --git a/net/core/skbuff.c b/net/core/skbuff.c
index 6841e61a6..cd6523271 100644
--- a/net/core/skbuff.c
+++ b/net/core/skbuff.c
@@ -4688,6 +4688,16 @@ EXPORT_SYMBOL_GPL(skb_segment_list);
  *	a pointer to the first in a list of new skbs for the segments.
  *	In case of error it returns ERR_PTR(err).
  */
+/*
+ * called by:
+ *   - lib/test_bpf.c|15096| <<test_skb_segment_single>> segs = skb_segment(skb, test->features);
+ *   - net/core/net_test.c|229| <<gso_test_func>> segs = skb_segment(skb, features);
+ *   - net/ipv4/tcp_offload.c|176| <<tcp_gso_segment>> segs = skb_segment(skb, features);
+ *   - net/ipv4/udp_offload.c|327| <<__udp_gso_segment>> segs = skb_segment(gso_skb, features);
+ *   - net/ipv4/udp_offload.c|468| <<udp4_ufo_fragment>> segs = skb_segment(skb, features);
+ *   - net/ipv6/udp_offload.c|109| <<udp6_ufo_fragment>> segs = skb_segment(skb, features);
+ *   - net/sctp/offload.c|72| <<sctp_gso_segment>> segs = skb_segment(skb, (features | NETIF_F_HW_CSUM) & ~NETIF_F_SG);
+ */
 struct sk_buff *skb_segment(struct sk_buff *head_skb,
 			    netdev_features_t features)
 {
diff --git a/virt/lib/irqbypass.c b/virt/lib/irqbypass.c
index 28fda42e4..5e7bfcef8 100644
--- a/virt/lib/irqbypass.c
+++ b/virt/lib/irqbypass.c
@@ -22,6 +22,29 @@
 MODULE_LICENSE("GPL v2");
 MODULE_DESCRIPTION("IRQ bypass manager utility module");
 
+/*
+ * 注释:
+ * When a physical I/O device is assigned to a virtual machine through
+ * facilities like VFIO and KVM, the interrupt for the device generally
+ * bounces through the host system before being injected into the VM.
+ * However, hardware technologies exist that often allow the host to be
+ * bypassed for some of these scenarios.  Intel Posted Interrupts allow
+ * the specified physical edge interrupts to be directly injected into a
+ * guest when delivered to a physical processor while the vCPU is
+ * running.  ARM IRQ Forwarding allows forwarded physical interrupts to
+ * be directly deactivated by the guest.
+ *
+ * The IRQ bypass manager here is meant to provide the shim to connect
+ * interrupt producers, generally the host physical device driver, with
+ * interrupt consumers, generally the hypervisor, in order to configure
+ * these bypass mechanism.  To do this, we base the connection on a
+ * shared, opaque token.  For KVM-VFIO this is expected to be an
+ * eventfd_ctx since this is the connection we already use to connect an
+ * eventfd to an irqfd on the in-kernel path.  When a producer and
+ * consumer with matching tokens is found, callbacks via both registered
+ * participants allow the bypass facilities to be automatically enabled.
+ */
+
 static LIST_HEAD(producers);
 static LIST_HEAD(consumers);
 static DEFINE_MUTEX(lock);
-- 
2.39.5 (Apple Git-154)

