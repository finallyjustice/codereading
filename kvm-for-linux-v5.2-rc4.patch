From f366ed4aa55238ab9ad90ec8cbee16d7cb8de811 Mon Sep 17 00:00:00 2001
From: Dongli Zhang <dongli.zhang0129@gmail.com>
Date: Fri, 21 Jun 2019 15:45:02 +0800
Subject: [PATCH 1/1] kvm for linux v5.2-rc4

Signed-off-by: Dongli Zhang <dongli.zhang0129@gmail.com>
---
 arch/x86/include/asm/kvm_host.h |   6 +++
 arch/x86/kernel/crash.c         |  12 +++++
 arch/x86/kvm/cpuid.c            |   5 ++
 arch/x86/kvm/cpuid.h            |   9 ++++
 arch/x86/kvm/i8254.c            |  41 ++++++++++++++++
 arch/x86/kvm/lapic.c            |  27 +++++++++++
 arch/x86/kvm/mmu.c              |   9 ++++
 arch/x86/kvm/vmx/vmcs12.h       |   1 +
 arch/x86/kvm/vmx/vmx.c          |  75 +++++++++++++++++++++++++++++
 arch/x86/kvm/x86.c              |  74 +++++++++++++++++++++++++++++
 virt/kvm/async_pf.c             |  13 +++++
 virt/kvm/eventfd.c              |   4 ++
 virt/kvm/irqchip.c              |  26 ++++++++++
 virt/kvm/kvm_main.c             | 103 ++++++++++++++++++++++++++++++++++++++++
 14 files changed, 405 insertions(+)

diff --git a/arch/x86/include/asm/kvm_host.h b/arch/x86/include/asm/kvm_host.h
index 450d69a..bad74a9 100644
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@ -1062,6 +1062,12 @@ struct kvm_x86_ops {
 	 */
 	void (*tlb_flush_gva)(struct kvm_vcpu *vcpu, gva_t addr);
 
+	/*
+	 * called by:
+	 *   - arch/x86/kvm/x86.c|7996| <<vcpu_enter_guest>> kvm_x86_ops->run(vcpu);
+	 *
+	 * vmx: vmx_vcpu_run()
+	 */
 	void (*run)(struct kvm_vcpu *vcpu);
 	int (*handle_exit)(struct kvm_vcpu *vcpu);
 	void (*skip_emulated_instruction)(struct kvm_vcpu *vcpu);
diff --git a/arch/x86/kernel/crash.c b/arch/x86/kernel/crash.c
index 576b2e1..bbd3702 100644
--- a/arch/x86/kernel/crash.c
+++ b/arch/x86/kernel/crash.c
@@ -54,15 +54,27 @@ struct crash_memmap_data {
  *
  * protected by rcu.
  */
+/*
+ * called by:
+ *   - arch/x86/kernel/crash.c|66| <<cpu_crash_vmclear_loaded_vmcss>> do_vmclear_operation = rcu_dereference(crash_vmclear_loaded_vmcss);
+ *   - arch/x86/kvm/vmx/vmx.c|7748| <<vmx_exit>> RCU_INIT_POINTER(crash_vmclear_loaded_vmcss, NULL);
+ *   - arch/x86/kvm/vmx/vmx.c|7834| <<vmx_init>> rcu_assign_pointer(crash_vmclear_loaded_vmcss,
+ */
 crash_vmclear_fn __rcu *crash_vmclear_loaded_vmcss = NULL;
 EXPORT_SYMBOL_GPL(crash_vmclear_loaded_vmcss);
 unsigned long crash_zero_bytes;
 
+/*
+ * called by:
+ *   - arch/x86/kernel/crash.c|89| <<kdump_nmi_callback>> cpu_crash_vmclear_loaded_vmcss();
+ *   - arch/x86/kernel/crash.c|156| <<native_machine_crash_shutdown>> cpu_crash_vmclear_loaded_vmcss();
+ */
 static inline void cpu_crash_vmclear_loaded_vmcss(void)
 {
 	crash_vmclear_fn *do_vmclear_operation = NULL;
 
 	rcu_read_lock();
+	/* 在vmx_init()中设置为 crash_vmclear_local_loaded_vmcss() */
 	do_vmclear_operation = rcu_dereference(crash_vmclear_loaded_vmcss);
 	if (do_vmclear_operation)
 		do_vmclear_operation();
diff --git a/arch/x86/kvm/cpuid.c b/arch/x86/kvm/cpuid.c
index e18a9f9..e2af392 100644
--- a/arch/x86/kvm/cpuid.c
+++ b/arch/x86/kvm/cpuid.c
@@ -956,6 +956,11 @@ bool kvm_cpuid(struct kvm_vcpu *vcpu, u32 *eax, u32 *ebx,
 }
 EXPORT_SYMBOL_GPL(kvm_cpuid);
 
+/*
+ * called by:
+ *   - arch/x86/kvm/svm.c|3904| <<cpuid_interception>> return kvm_emulate_cpuid(&svm->vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|4832| <<handle_cpuid>> return kvm_emulate_cpuid(vcpu);
+ */
 int kvm_emulate_cpuid(struct kvm_vcpu *vcpu)
 {
 	u32 eax, ebx, ecx, edx;
diff --git a/arch/x86/kvm/cpuid.h b/arch/x86/kvm/cpuid.h
index 9a327d5..a4a71cd 100644
--- a/arch/x86/kvm/cpuid.h
+++ b/arch/x86/kvm/cpuid.h
@@ -156,11 +156,20 @@ static inline int guest_cpuid_stepping(struct kvm_vcpu *vcpu)
 	return x86_stepping(best->eax);
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/x86.c|2695| <<kvm_set_msr_common>> !supports_cpuid_fault(vcpu)))
+ */
 static inline bool supports_cpuid_fault(struct kvm_vcpu *vcpu)
 {
 	return vcpu->arch.msr_platform_info & MSR_PLATFORM_INFO_CPUID_FAULT;
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/cpuid.c|963| <<kvm_emulate_cpuid>> if (cpuid_fault_enabled(vcpu) && !kvm_require_cpl(vcpu, 0))
+ *   - arch/x86/kvm/x86.c|2688| <<kvm_set_msr_common>> cpuid_fault_enabled(vcpu)))
+ */
 static inline bool cpuid_fault_enabled(struct kvm_vcpu *vcpu)
 {
 	return vcpu->arch.msr_misc_features_enables &
diff --git a/arch/x86/kvm/i8254.c b/arch/x86/kvm/i8254.c
index 4a6dc54..eecc067 100644
--- a/arch/x86/kvm/i8254.c
+++ b/arch/x86/kvm/i8254.c
@@ -40,6 +40,10 @@
 #include "i8254.h"
 #include "x86.h"
 
+/*
+ * https://wiki.osdev.org/Programmable_Interval_Timer
+ */
+
 #ifndef CONFIG_X86_64
 #define mod_64(x, y) ((x) - (y) * div64_u64(x, y))
 #else
@@ -51,6 +55,10 @@
 #define RW_STATE_WORD0 3
 #define RW_STATE_WORD1 4
 
+/*
+ * called by:
+ *   - arch/x86/kvm/i8254.c|585| <<speaker_ioport_write>> pit_set_gate(pit, 2, val & 1);
+ */
 static void pit_set_gate(struct kvm_pit *pit, int channel, u32 val)
 {
 	struct kvm_kpit_channel_state *c = &pit->pit_state.channels[channel];
@@ -308,6 +316,11 @@ void kvm_pit_set_reinject(struct kvm_pit *pit, bool reinject)
 	atomic_set(&ps->reinject, reinject);
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/i8254.c|381| <<pit_load_count>> create_pit_timer(pit, val, 0);
+ *   - arch/x86/kvm/i8254.c|385| <<pit_load_count>> create_pit_timer(pit, val, 1);
+ */
 static void create_pit_timer(struct kvm_pit *pit, u32 val, int is_period)
 {
 	struct kvm_kpit_state *ps = &pit->pit_state;
@@ -351,6 +364,15 @@ static void create_pit_timer(struct kvm_pit *pit, u32 val, int is_period)
 		      HRTIMER_MODE_ABS);
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/i8254.c|404| <<kvm_pit_load_count>> pit_load_count(pit, channel, val);
+ *   - arch/x86/kvm/i8254.c|407| <<kvm_pit_load_count>> pit_load_count(pit, channel, val);
+ *   - arch/x86/kvm/i8254.c|483| <<pit_ioport_write>> pit_load_count(pit, addr, val);
+ *   - arch/x86/kvm/i8254.c|486| <<pit_ioport_write>> pit_load_count(pit, addr, val << 8);
+ *   - arch/x86/kvm/i8254.c|493| <<pit_ioport_write>> pit_load_count(pit, addr, s->write_latch | (val << 8));
+ *   - arch/x86/kvm/i8254.c|624| <<kvm_pit_reset>> pit_load_count(pit, i, 0);
+ */
 static void pit_load_count(struct kvm_pit *pit, int channel, u32 val)
 {
 	struct kvm_kpit_state *ps = &pit->pit_state;
@@ -389,6 +411,11 @@ static void pit_load_count(struct kvm_pit *pit, int channel, u32 val)
 	}
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/x86.c|4430| <<kvm_vm_ioctl_set_pit>> kvm_pit_load_count(pit, i, ps->channels[i].count, 0);
+ *   - arch/x86/kvm/x86.c|4462| <<kvm_vm_ioctl_set_pit2>> kvm_pit_load_count(pit, i, pit->pit_state.channels[i].count,
+ */
 void kvm_pit_load_count(struct kvm_pit *pit, int channel, u32 val,
 		int hpet_legacy_start)
 {
@@ -645,6 +672,12 @@ static const struct kvm_io_device_ops speaker_dev_ops = {
 	.write    = speaker_ioport_write,
 };
 
+/*
+ * called by:
+ *   - arch/x86/kvm/x86.c|4738| <<kvm_arch_vm_ioctl>> kvm->arch.vpit = kvm_create_pit(kvm, u.pit_config.flags);
+ *
+ * vm的dev: kvm_vm_fops->kvm_vm_ioctl()-->kvm_arch_vm_ioctl()::KVM_CREATE_PIT(KVM_CREATE_PIT2)
+ */
 struct kvm_pit *kvm_create_pit(struct kvm *kvm, u32 flags)
 {
 	struct kvm_pit *pit;
@@ -689,6 +722,14 @@ struct kvm_pit *kvm_create_pit(struct kvm *kvm, u32 flags)
 
 	mutex_lock(&kvm->slots_lock);
 	kvm_iodevice_init(&pit->dev, &pit_dev_ops);
+	/*
+	 * KVM_PIT_BASE_ADDRESS是0x40
+	 *
+	 * 0x40   Channel 0 data port (read/write)
+	 * 0x41   Channel 1 data port (read/write)
+	 * 0x42   Channel 2 data port (read/write)
+	 * 0x43   Mode/Command register (write only, a read is ignored)
+	 */
 	ret = kvm_io_bus_register_dev(kvm, KVM_PIO_BUS, KVM_PIT_BASE_ADDRESS,
 				      KVM_PIT_MEM_LENGTH, &pit->dev);
 	if (ret < 0)
diff --git a/arch/x86/kvm/lapic.c b/arch/x86/kvm/lapic.c
index 4924f83..06d27d5 100644
--- a/arch/x86/kvm/lapic.c
+++ b/arch/x86/kvm/lapic.c
@@ -102,7 +102,26 @@ static inline int __apic_test_and_clear_vector(int vec, void *bitmap)
 	return __test_and_clear_bit(VEC_POS(vec), (bitmap) + REG_POS(vec));
 }
 
+/*
+ * used by:
+ *   - arch/x86/kvm/lapic.c|2055| <<kvm_free_lapic>> static_key_slow_dec_deferred(&apic_hw_disabled);
+ *   - arch/x86/kvm/lapic.c|2132| <<kvm_lapic_set_base>> static_key_slow_dec_deferred(&apic_hw_disabled);
+ *   - arch/x86/kvm/lapic.c|2134| <<kvm_lapic_set_base>> static_key_slow_inc(&apic_hw_disabled.key);
+ *   - arch/x86/kvm/lapic.c|2762| <<kvm_lapic_init>> jump_label_rate_limit(&apic_hw_disabled, HZ);
+ *   - arch/x86/kvm/lapic.c|2768| <<kvm_lapic_exit>> static_key_deferred_flush(&apic_hw_disabled);
+ *   - arch/x86/kvm/lapic.h|170| <<kvm_apic_hw_enabled>> if (static_key_false(&apic_hw_disabled.key))
+ */
 struct static_key_deferred apic_hw_disabled __read_mostly;
+/*
+ * used by:
+ *   - arch/x86/kvm/lapic.c|256| <<apic_set_spiv>> static_key_slow_dec_deferred(&apic_sw_disabled);
+ *   - arch/x86/kvm/lapic.c|258| <<apic_set_spiv>> static_key_slow_inc(&apic_sw_disabled.key);
+ *   - arch/x86/kvm/lapic.c|2058| <<kvm_free_lapic>> static_key_slow_dec_deferred(&apic_sw_disabled);
+ *   - arch/x86/kvm/lapic.c|2329| <<kvm_create_lapic>> static_key_slow_inc(&apic_sw_disabled.key);
+ *   - arch/x86/kvm/lapic.c|2763| <<kvm_lapic_init>> jump_label_rate_limit(&apic_sw_disabled, HZ);
+ *   - arch/x86/kvm/lapic.c|2769| <<kvm_lapic_exit>> static_key_deferred_flush(&apic_sw_disabled);
+ *   - arch/x86/kvm/lapic.h|179| <<kvm_apic_sw_enabled>> if (static_key_false(&apic_sw_disabled.key))
+ */
 struct static_key_deferred apic_sw_disabled __read_mostly;
 
 static inline int apic_enabled(struct kvm_lapic *apic)
@@ -2756,6 +2775,10 @@ void kvm_apic_accept_events(struct kvm_vcpu *vcpu)
 	}
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/x86.c|7052| <<kvm_arch_init>> kvm_lapic_init();
+ */
 void kvm_lapic_init(void)
 {
 	/* do not patch jump label more than once per second */
@@ -2763,6 +2786,10 @@ void kvm_lapic_init(void)
 	jump_label_rate_limit(&apic_sw_disabled, HZ);
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/x86.c|7076| <<kvm_arch_exit>> kvm_lapic_exit();
+ */
 void kvm_lapic_exit(void)
 {
 	static_key_deferred_flush(&apic_hw_disabled);
diff --git a/arch/x86/kvm/mmu.c b/arch/x86/kvm/mmu.c
index 1e9ba81..da38b2c 100644
--- a/arch/x86/kvm/mmu.c
+++ b/arch/x86/kvm/mmu.c
@@ -452,6 +452,11 @@ static bool check_mmio_spte(struct kvm_vcpu *vcpu, u64 spte)
  *  - Setting either @accessed_mask or @dirty_mask requires setting both
  *  - At least one of @accessed_mask or @acc_track_mask must be set
  */
+/*
+ * called by:
+ *   - arch/x86/kvm/vmx/vmx.c|5262| <<vmx_enable_tdp>> kvm_mmu_set_mask_ptes(VMX_EPT_READABLE_MASK,
+ *   - arch/x86/kvm/x86.c|7046| <<kvm_arch_init>> kvm_mmu_set_mask_ptes(PT_USER_MASK, PT_ACCESSED_MASK,
+ */
 void kvm_mmu_set_mask_ptes(u64 user_mask, u64 accessed_mask,
 		u64 dirty_mask, u64 nx_mask, u64 x_mask, u64 p_mask,
 		u64 acc_track_mask, u64 me_mask)
@@ -5998,6 +6003,10 @@ static void mmu_destroy_caches(void)
 	kmem_cache_destroy(mmu_page_header_cache);
 }
 
+/*
+ * called by only:
+ *   - arch/x86/kvm/x86.c|7034| <<kvm_arch_init>> r = kvm_mmu_module_init();
+ */
 int kvm_mmu_module_init(void)
 {
 	int ret = -ENOMEM;
diff --git a/arch/x86/kvm/vmx/vmcs12.h b/arch/x86/kvm/vmx/vmcs12.h
index 3a74242..350cb9e8 100644
--- a/arch/x86/kvm/vmx/vmcs12.h
+++ b/arch/x86/kvm/vmx/vmcs12.h
@@ -218,6 +218,7 @@ struct __packed vmcs12 {
 	BUILD_BUG_ON_MSG(offsetof(struct vmcs12, field) != (loc),	\
 		"Offset of " #field " in struct vmcs12 has changed.")
 
+/* 只被vmx_init()调用 */
 static inline void vmx_check_vmcs12_offsets(void)
 {
 	CHECK_OFFSET(hdr, 0);
diff --git a/arch/x86/kvm/vmx/vmx.c b/arch/x86/kvm/vmx/vmx.c
index b93e36d..fa83b62 100644
--- a/arch/x86/kvm/vmx/vmx.c
+++ b/arch/x86/kvm/vmx/vmx.c
@@ -67,12 +67,37 @@
 MODULE_AUTHOR("Qumranet");
 MODULE_LICENSE("GPL");
 
+/*
+ * 进入的核心函数是vmx_vcpu_run()-->__vmx_vcpu_run()
+ *
+ * vcpu的dev: kvm_vcpu_fops->unlock_ioctl = kvm_vcpu_ioctl()
+ *  -> KVM_RUN::kvm_arch_vcpu_ioctl_run()
+ *      -> vcpu_run()
+ *          -> vcpu_enter_guest()
+ *              -> kvm_x86_ops->run = vmx_vcpu_run()
+ *                  -> arch/x86/kvm/vmx/vmenter.S:__vmx_vcpu_run()
+ *                      -> arch/x86/kvm/vmx/vmenter.S:vmx_vmenter
+ *                          -> 调用vmresume或者vmlaunch指令
+ *              -> kvm_x86_ops->handle_exit = vmx_handle_exit()
+ *                  -> kvm_vmx_exit_handlers[exit_reason](vcpu)
+ *                      -> 比如EXIT_REASON_IO_INSTRUCTION是handle_io()
+ *                         比如EXIT_REASON_EPT_MISCONFIG是handle_ept_misconfig()
+ *                         比如EXIT_REASON_EPT_VIOLATION是handle_ept_violation()
+ */
+
 static const struct x86_cpu_id vmx_cpu_id[] = {
 	X86_FEATURE_MATCH(X86_FEATURE_VMX),
 	{}
 };
 MODULE_DEVICE_TABLE(x86cpu, vmx_cpu_id);
 
+/*
+ * 不考虑nested vmx的情况下在以下使用:
+ *   - arch/x86/kvm/vmx/vmx.c|3436| <<allocate_vpid>> if (!enable_vpid)
+ *   - arch/x86/kvm/vmx/vmx.c|3450| <<free_vpid>> if (!enable_vpid || vpid == 0)
+ *   - arch/x86/kvm/vmx/vmx.c|7475| <<hardware_setup>> enable_vpid = 0;
+ *   - arch/x86/kvm/vmx/vmx.h|505| <<__vmx_flush_tlb>> if (enable_ept && (invalidate_gpa || !enable_vpid)) {
+ */
 bool __read_mostly enable_vpid = 1;
 module_param_named(vpid, enable_vpid, bool, 0444);
 
@@ -82,6 +107,10 @@ module_param_named(vnmi, enable_vnmi, bool, S_IRUGO);
 bool __read_mostly flexpriority_enabled = 1;
 module_param_named(flexpriority, flexpriority_enabled, bool, S_IRUGO);
 
+/*
+ * 只在一处可能修改:
+ *   - arch/x86/kvm/vmx/vmx.c|7481| <<hardware_setup>> enable_ept = 0;
+ */
 bool __read_mostly enable_ept = 1;
 module_param_named(ept, enable_ept, bool, S_IRUGO);
 
@@ -89,15 +118,43 @@ bool __read_mostly enable_unrestricted_guest = 1;
 module_param_named(unrestricted_guest,
 			enable_unrestricted_guest, bool, S_IRUGO);
 
+/*
+ * used by:
+ *   - arch/x86/kvm/vmx/nested.c|5631| <<nested_vmx_setup_ctls_msrs>> if (enable_ept_ad_bits) {
+ *   - arch/x86/kvm/vmx/vmx.c|2851| <<construct_eptp>> if (enable_ept_ad_bits &&
+ *   - arch/x86/kvm/vmx/vmx.c|5267| <<vmx_enable_tdp>> enable_ept_ad_bits ? VMX_EPT_ACCESS_BIT : 0ull,
+ *   - arch/x86/kvm/vmx/vmx.c|5268| <<vmx_enable_tdp>> enable_ept_ad_bits ? VMX_EPT_DIRTY_BIT : 0ull,
+ *   - arch/x86/kvm/vmx/vmx.c|7484| <<hardware_setup>> enable_ept_ad_bits = 0;
+ *   - arch/x86/kvm/vmx/vmx.c|7548| <<hardware_setup>> if (!enable_ept || !enable_ept_ad_bits || !cpu_has_vmx_pml())
+ */
 bool __read_mostly enable_ept_ad_bits = 1;
 module_param_named(eptad, enable_ept_ad_bits, bool, S_IRUGO);
 
+/*
+ * used by:
+ *   - arch/x86/kvm/vmx/vmx.c|1370| <<emulation_required>> return emulate_invalid_guest_state && !guest_state_valid(vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|2558| <<fix_pmode_seg>> if (!emulate_invalid_guest_state) {
+ *   - arch/x86/kvm/vmx/vmx.c|2623| <<fix_rmode_seg>> if (!emulate_invalid_guest_state) {
+ *   - arch/x86/kvm/vmx/vmx.c|6249| <<vmx_has_emulated_msr>> return enable_unrestricted_guest || emulate_invalid_guest_state;
+ */
 static bool __read_mostly emulate_invalid_guest_state = true;
 module_param(emulate_invalid_guest_state, bool, S_IRUGO);
 
+/*
+ * used only by:
+ *   - arch/x86/kvm/vmx/vmx.c|5001| <<handle_apic_access>> if (likely(fasteoi)) {
+ */
 static bool __read_mostly fasteoi = 1;
 module_param(fasteoi, bool, S_IRUGO);
 
+/*
+ * used by:
+ *   - arch/x86/kvm/vmx/vmx.c|3550| <<vmx_msr_bitmap_mode>> if (enable_apicv && kvm_vcpu_apicv_active(vcpu))
+ *   - arch/x86/kvm/vmx/vmx.c|3622| <<vmx_get_enable_apicv>> return enable_apicv;
+ *   - arch/x86/kvm/vmx/vmx.c|6764| <<vmx_check_processor_compat>> enable_apicv);
+ *   - arch/x86/kvm/vmx/vmx.c|7527| <<hardware_setup>> enable_apicv = 0;
+ *   - arch/x86/kvm/vmx/vmx.c|7583| <<hardware_setup>> vmx_capability.ept, enable_apicv);
+ */
 static bool __read_mostly enable_apicv = 1;
 module_param(enable_apicv, bool, S_IRUGO);
 
@@ -4827,6 +4884,9 @@ static void vmx_set_dr7(struct kvm_vcpu *vcpu, unsigned long val)
 	vmcs_writel(GUEST_DR7, val);
 }
 
+/*
+ * kvm_vmx_exit_handlers[EXIT_REASON_CPUID] = handle_cpuid()
+ */
 static int handle_cpuid(struct kvm_vcpu *vcpu)
 {
 	return kvm_emulate_cpuid(vcpu);
@@ -5471,6 +5531,12 @@ static int handle_encls(struct kvm_vcpu *vcpu)
  * may resume.  Otherwise they set the kvm_run parameter to indicate what needs
  * to be done to userspace and return 0.
  */
+/*
+ * used by:
+ *   - arch/x86/kvm/vmx/vmx.c|5867| <<vmx_handle_exit>> && kvm_vmx_exit_handlers[exit_reason])
+ *   - arch/x86/kvm/vmx/vmx.c|5868| <<vmx_handle_exit>> return kvm_vmx_exit_handlers[exit_reason](vcpu);
+ *   - arch/x86/kvm/vmx/vmx.c|7576| <<hardware_setup>> r = nested_vmx_hardware_setup(kvm_vmx_exit_handlers);
+ */
 static int (*kvm_vmx_exit_handlers[])(struct kvm_vcpu *vcpu) = {
 	[EXIT_REASON_EXCEPTION_NMI]           = handle_exception,
 	[EXIT_REASON_EXTERNAL_INTERRUPT]      = handle_external_interrupt,
@@ -5771,6 +5837,9 @@ void dump_vmcs(void)
  * The guest has exited.  See if we can fix it or if we need userspace
  * assistance.
  */
+/*
+ * struct kvm_x86_ops vmx_x86_ops.handle_exit = vmx_handle_exit()
+ */
 static int vmx_handle_exit(struct kvm_vcpu *vcpu)
 {
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
@@ -6384,6 +6453,12 @@ void vmx_update_host_rsp(struct vcpu_vmx *vmx, unsigned long host_rsp)
 
 bool __vmx_vcpu_run(struct vcpu_vmx *vmx, unsigned long *regs, bool launched);
 
+/*
+ * called by:
+ *   - arch/x86/kvm/x86.c|7996| <<vcpu_enter_guest>> kvm_x86_ops->run(vcpu);
+ *
+ * struct kvm_x86_ops vmx_x86_ops.run = vmx_vcpu_run()
+ */
 static void vmx_vcpu_run(struct kvm_vcpu *vcpu)
 {
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index 83aefd7..170fa8f 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -1531,6 +1531,13 @@ static atomic_t kvm_guest_has_master_clock = ATOMIC_INIT(0);
 #endif
 
 static DEFINE_PER_CPU(unsigned long, cpu_tsc_khz);
+/*
+ * used by:
+ *   - arch/x86/kvm/x86.c|6846| <<kvm_timer_init>> max_tsc_khz = tsc_khz;
+ *   - arch/x86/kvm/x86.c|6857| <<kvm_timer_init>> max_tsc_khz = policy.cpuinfo.max_freq;
+ *   - arch/x86/kvm/x86.c|6863| <<kvm_timer_init>> pr_debug("kvm: max_tsc_khz = %ld\n", max_tsc_khz);
+ *   - arch/x86/kvm/x86.c|9157| <<kvm_arch_vcpu_init>> kvm_set_tsc_khz(vcpu, max_tsc_khz);
+ */
 static unsigned long max_tsc_khz;
 
 static u32 adjust_tsc_khz(u32 khz, s32 ppm)
@@ -3151,6 +3158,12 @@ int kvm_vm_ioctl_check_extension(struct kvm *kvm, long ext)
 
 }
 
+/*
+ * called by:
+ *   - virt/kvm/kvm_main.c|3520| <<kvm_dev_ioctl>> return kvm_arch_dev_ioctl(filp, ioctl, arg);
+ *
+ * 处理kvm的dev的kvm_chardev_ops的kvm_dev_ioctl()的剩余的命令
+ */
 long kvm_arch_dev_ioctl(struct file *filp,
 			unsigned int ioctl, unsigned long arg)
 {
@@ -4632,6 +4645,12 @@ int kvm_vm_ioctl_enable_cap(struct kvm *kvm,
 	return r;
 }
 
+/*
+ * called by:
+ *   - virt/kvm/kvm_main.c|3436| <<kvm_vm_ioctl>> r = kvm_arch_vm_ioctl(filp, ioctl, arg);
+ *
+ * vm的dev: kvm_vm_fops->kvm_vm_ioctl()-->kvm_arch_vm_ioctl()
+ */
 long kvm_arch_vm_ioctl(struct file *filp,
 		       unsigned int ioctl, unsigned long arg)
 {
@@ -6841,6 +6860,10 @@ static int kvmclock_cpu_online(unsigned int cpu)
 	return 0;
 }
 
+/*
+ * called only by:
+ *   - arch/x86/kvm/x86.c|7049| <<kvm_arch_init>> kvm_timer_init();
+ */
 static void kvm_timer_init(void)
 {
 	max_tsc_khz = tsc_khz;
@@ -6983,6 +7006,10 @@ static struct notifier_block pvclock_gtod_notifier = {
 };
 #endif
 
+/*
+ * called by only:
+ *   - virt/kvm/kvm_main.c|4233| <<kvm_init>> r = kvm_arch_init(opaque);
+ */
 int kvm_arch_init(void *opaque)
 {
 	int r;
@@ -7752,6 +7779,12 @@ EXPORT_SYMBOL_GPL(__kvm_request_immediate_exit);
  * exiting to the userspace.  Otherwise, the value will be returned to the
  * userspace.
  */
+/*
+ * called by:
+ *   - arch/x86/kvm/x86.c|8128| <<vcpu_run>> r = vcpu_enter_guest(vcpu);
+ *
+ * vcpu的dev: kvm_vcpu_fops->kvm_vcpu_ioctl()::KVM_RUN-->kvm_arch_vcpu_ioctl_run()-->vcpu_run()-->vcpu_enter_guest()
+ */
 static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 {
 	int r;
@@ -7972,6 +8005,12 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 		vcpu->arch.switch_db_regs &= ~KVM_DEBUGREG_RELOAD;
 	}
 
+	/*
+	 * called only by:
+	 *   - arch/x86/kvm/x86.c|7996| <<vcpu_enter_guest>> kvm_x86_ops->run(vcpu);
+	 *
+	 * vmx: vmx_vcpu_run()
+	 */
 	kvm_x86_ops->run(vcpu);
 
 	/*
@@ -8032,6 +8071,12 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 		kvm_lapic_sync_from_vapic(vcpu);
 
 	vcpu->arch.gpa_available = false;
+	/*
+	 * called only by:
+	 *   - arch/x86/kvm/x86.c|8060| <<vcpu_enter_guest>> r = kvm_x86_ops->handle_exit(vcpu);
+	 *
+	 * vmx: vmx_handle_exit()
+	 */
 	r = kvm_x86_ops->handle_exit(vcpu);
 	return r;
 
@@ -8043,6 +8088,10 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 	return r;
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/x86.c|8122| <<vcpu_run>> r = vcpu_block(kvm, vcpu);
+ */
 static inline int vcpu_block(struct kvm *kvm, struct kvm_vcpu *vcpu)
 {
 	if (!kvm_arch_vcpu_runnable(vcpu) &&
@@ -8086,6 +8135,12 @@ static inline bool kvm_vcpu_running(struct kvm_vcpu *vcpu)
 		!vcpu->arch.apf.halted);
 }
 
+/*
+ * called by:
+ *   - arch/x86/kvm/x86.c|8328| <<kvm_arch_vcpu_ioctl_run>> r = vcpu_run(vcpu);
+ *
+ * vcpu的dev: kvm_vcpu_fops->kvm_vcpu_ioctl()::KVM_RUN-->kvm_arch_vcpu_ioctl_run()-->vcpu_run()
+ */
 static int vcpu_run(struct kvm_vcpu *vcpu)
 {
 	int r;
@@ -8248,6 +8303,12 @@ static void kvm_put_guest_fpu(struct kvm_vcpu *vcpu)
 	trace_kvm_fpu(0);
 }
 
+/*
+ * called by:
+ *   - virt/kvm/kvm_main.c|2814| <<kvm_vcpu_ioctl>> r = kvm_arch_vcpu_ioctl_run(vcpu, vcpu->run);
+ *
+ * vcpu的dev: kvm_vcpu_fops->kvm_vcpu_ioctl()::KVM_RUN-->kvm_arch_vcpu_ioctl_run()
+ */
 int kvm_arch_vcpu_ioctl_run(struct kvm_vcpu *vcpu, struct kvm_run *kvm_run)
 {
 	int r;
@@ -8835,6 +8896,12 @@ void kvm_arch_vcpu_free(struct kvm_vcpu *vcpu)
 	free_cpumask_var(wbinvd_dirty_mask);
 }
 
+/*
+ * called by:
+ *   - virt/kvm/kvm_main.c|2691| <<kvm_vm_ioctl_create_vcpu>> vcpu = kvm_arch_vcpu_create(kvm, id);
+ *
+ *  vm的dev: kvm_vm_fops->kvm_vm_ioctl()::KVM_CREATE_VCPU-->kvm_vm_ioctl_create_vcpu()-->kvm_arch_vcpu_create()
+ */
 struct kvm_vcpu *kvm_arch_vcpu_create(struct kvm *kvm,
 						unsigned int id)
 {
@@ -8850,6 +8917,9 @@ struct kvm_vcpu *kvm_arch_vcpu_create(struct kvm *kvm,
 	return vcpu;
 }
 
+/*
+ * vm的dev: kvm_vm_fops->kvm_vm_ioctl()::KVM_CREATE_VCPU-->kvm_vm_ioctl_create_vcpu()-->kvm_arch_vcpu_setup()
+ */
 int kvm_arch_vcpu_setup(struct kvm_vcpu *vcpu)
 {
 	vcpu->arch.arch_capabilities = kvm_get_arch_capabilities();
@@ -9082,6 +9152,10 @@ int kvm_arch_hardware_setup(void)
 {
 	int r;
 
+	/*
+	 * vmx: hardware_setup()
+	 * svm: svm_hardware_setup()
+	 */
 	r = kvm_x86_ops->hardware_setup();
 	if (r != 0)
 		return r;
diff --git a/virt/kvm/async_pf.c b/virt/kvm/async_pf.c
index 110cbe3..29484a9 100644
--- a/virt/kvm/async_pf.c
+++ b/virt/kvm/async_pf.c
@@ -44,6 +44,19 @@ static inline void kvm_async_page_present_async(struct kvm_vcpu *vcpu,
 #endif
 }
 
+/*
+ * used by:
+ *   - virt/kvm/async_pf.c|51| <<kvm_async_pf_init>> async_pf_cache = KMEM_CACHE(kvm_async_pf, 0);
+ *   - virt/kvm/async_pf.c|53| <<kvm_async_pf_init>> if (!async_pf_cache)
+ *   - virt/kvm/async_pf.c|61| <<kvm_async_pf_deinit>> kmem_cache_destroy(async_pf_cache);
+ *   - virt/kvm/async_pf.c|62| <<kvm_async_pf_deinit>> async_pf_cache = NULL;
+ *   - virt/kvm/async_pf.c|141| <<kvm_clear_async_pf_completion_queue>> kmem_cache_free(async_pf_cache, work);
+ *   - virt/kvm/async_pf.c|152| <<kvm_clear_async_pf_completion_queue>> kmem_cache_free(async_pf_cache, work);
+ *   - virt/kvm/async_pf.c|176| <<kvm_check_async_pf_completion>> kmem_cache_free(async_pf_cache, work);
+ *   - virt/kvm/async_pf.c|194| <<kvm_setup_async_pf>> work = kmem_cache_zalloc(async_pf_cache, GFP_NOWAIT | __GFP_NOWARN);
+ *   - virt/kvm/async_pf.c|223| <<kvm_setup_async_pf>> kmem_cache_free(async_pf_cache, work);
+ *   - virt/kvm/async_pf.c|234| <<kvm_async_pf_wakeup_all>> work = kmem_cache_zalloc(async_pf_cache, GFP_ATOMIC);
+ */
 static struct kmem_cache *async_pf_cache;
 
 int kvm_async_pf_init(void)
diff --git a/virt/kvm/eventfd.c b/virt/kvm/eventfd.c
index 3972a956..19e8965 100644
--- a/virt/kvm/eventfd.c
+++ b/virt/kvm/eventfd.c
@@ -642,6 +642,10 @@ void kvm_irq_routing_update(struct kvm *kvm)
  * aggregated from all vm* instances. We need our own isolated
  * queue to ease flushing work items when a VM exits.
  */
+/*
+ * called by:
+ *   - virt/kvm/kvm_main.c|4252| <<kvm_init>> r = kvm_irqfd_init();
+ */
 int kvm_irqfd_init(void)
 {
 	irqfd_cleanup_wq = alloc_workqueue("kvm-irqfd-cleanup", 0, 0);
diff --git a/virt/kvm/irqchip.c b/virt/kvm/irqchip.c
index 2e6fc7c..b705eb7 100644
--- a/virt/kvm/irqchip.c
+++ b/virt/kvm/irqchip.c
@@ -19,6 +19,11 @@
 #include <trace/events/kvm.h>
 #include "irq.h"
 
+/*
+ * called by:
+ *   - virt/kvm/eventfd.c|261| <<irqfd_update>> n_entries = kvm_irq_map_gsi(kvm, entries, irqfd->gsi);
+ *   - virt/kvm/irqchip.c|84| <<kvm_set_irq>> i = kvm_irq_map_gsi(kvm, irq_set, irq);
+ */
 int kvm_irq_map_gsi(struct kvm *kvm,
 		    struct kvm_kernel_irq_routing_entry *entries, int gsi)
 {
@@ -46,6 +51,10 @@ int kvm_irq_map_chip_pin(struct kvm *kvm, unsigned irqchip, unsigned pin)
 	return irq_rt->chip[irqchip][pin];
 }
 
+/*
+ * called by:
+ *   - virt/kvm/kvm_main.c|3282| <<kvm_vm_ioctl>> r = kvm_send_userspace_msi(kvm, &msi);
+ */
 int kvm_send_userspace_msi(struct kvm *kvm, struct kvm_msi *msi)
 {
 	struct kvm_kernel_irq_routing_entry route;
@@ -68,6 +77,17 @@ int kvm_send_userspace_msi(struct kvm *kvm, struct kvm_msi *msi)
  *  = 0   Interrupt was coalesced (previous irq is still pending)
  *  > 0   Number of CPUs interrupt was delivered to
  */
+/*
+ * x86下调用:
+ *   - arch/x86/kvm/i8254.c|250| <<pit_do_work>> kvm_set_irq(kvm, pit->irq_source_id, 0, 1, false);
+ *   - arch/x86/kvm/i8254.c|251| <<pit_do_work>> kvm_set_irq(kvm, pit->irq_source_id, 0, 0, false);
+ *   - arch/x86/kvm/x86.c|4553| <<kvm_vm_ioctl_irq_line>> irq_event->status = kvm_set_irq(kvm, KVM_USERSPACE_IRQ_SOURCE_ID,
+ *   - virt/kvm/eventfd.c|61| <<irqfd_inject>> kvm_set_irq(kvm, KVM_USERSPACE_IRQ_SOURCE_ID, irqfd->gsi, 1,
+ *   - virt/kvm/eventfd.c|63| <<irqfd_inject>> kvm_set_irq(kvm, KVM_USERSPACE_IRQ_SOURCE_ID, irqfd->gsi, 0,
+ *   - virt/kvm/eventfd.c|66| <<irqfd_inject>> kvm_set_irq(kvm, KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID,
+ *   - virt/kvm/eventfd.c|87| <<irqfd_resampler_ack>> kvm_set_irq(kvm, KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID,
+ *   - virt/kvm/eventfd.c|112| <<irqfd_resampler_shutdown>> kvm_set_irq(kvm, KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID,
+ */
 int kvm_set_irq(struct kvm *kvm, int irq_source_id, u32 irq, int level,
 		bool line_status)
 {
@@ -166,6 +186,12 @@ bool __weak kvm_arch_can_set_irq_routing(struct kvm *kvm)
 	return true;
 }
 
+/*
+ * x86下调用:
+ *   - arch/x86/kvm/irq_comm.c|379| <<kvm_setup_default_irq_routing>> return kvm_set_irq_routing(kvm, default_routing,
+ *   - arch/x86/kvm/irq_comm.c|387| <<kvm_setup_empty_irq_routing>> return kvm_set_irq_routing(kvm, empty_routing, 0, 0);
+ *   - virt/kvm/kvm_main.c|3338| <<kvm_vm_ioctl>> r = kvm_set_irq_routing(kvm, entries, routing.nr,
+ */
 int kvm_set_irq_routing(struct kvm *kvm,
 			const struct kvm_irq_routing_entry *ue,
 			unsigned nr,
diff --git a/virt/kvm/kvm_main.c b/virt/kvm/kvm_main.c
index ca54b09..cc23749 100644
--- a/virt/kvm/kvm_main.c
+++ b/virt/kvm/kvm_main.c
@@ -72,6 +72,12 @@
 MODULE_AUTHOR("Qumranet");
 MODULE_LICENSE("GPL");
 
+/*
+ * kvm的dev  : kvm_chardev_ops
+ * vm的dev   : kvm_vm_fops
+ * vcpu的dev : kvm_vcpu_fops
+ */
+
 /* Architectures should define their poll value according to the halt latency */
 unsigned int halt_poll_ns = KVM_HALT_POLL_NS_DEFAULT;
 module_param(halt_poll_ns, uint, 0644);
@@ -100,6 +106,23 @@ EXPORT_SYMBOL_GPL(halt_poll_ns_shrink);
 
 DEFINE_SPINLOCK(kvm_lock);
 static DEFINE_RAW_SPINLOCK(kvm_count_lock);
+/*
+ * used by:
+ *   - arch/x86/kvm/mmu.c|5944| <<mmu_shrink_scan>> list_for_each_entry(kvm, &vm_list, vm_list) {
+ *   - arch/x86/kvm/mmu.c|5980| <<mmu_shrink_scan>> list_move_tail(&kvm->vm_list, &vm_list);
+ *   - arch/x86/kvm/x86.c|6725| <<kvm_hyperv_tsc_notifier>> list_for_each_entry(kvm, &vm_list, vm_list)
+ *   - arch/x86/kvm/x86.c|6735| <<kvm_hyperv_tsc_notifier>> list_for_each_entry(kvm, &vm_list, vm_list) {
+ *   - arch/x86/kvm/x86.c|6802| <<__kvmclock_cpufreq_notifier>> list_for_each_entry(kvm, &vm_list, vm_list) {
+ *   - arch/x86/kvm/x86.c|6968| <<pvclock_gtod_update_fn>> list_for_each_entry(kvm, &vm_list, vm_list)
+ *   - arch/x86/kvm/x86.c|9022| <<kvm_arch_hardware_enable>> list_for_each_entry(kvm, &vm_list, vm_list) {
+ *   - arch/x86/kvm/x86.c|9074| <<kvm_arch_hardware_enable>> list_for_each_entry(kvm, &vm_list, vm_list) {
+ *   - virt/kvm/kvm_main.c|699| <<kvm_create_vm>> list_add(&kvm->vm_list, &vm_list);
+ *   - virt/kvm/kvm_main.c|747| <<kvm_destroy_vm>> list_del(&kvm->vm_list);
+ *   - virt/kvm/kvm_main.c|4072| <<vm_stat_get>> list_for_each_entry(kvm, &vm_list, vm_list) {
+ *   - virt/kvm/kvm_main.c|4091| <<vm_stat_clear>> list_for_each_entry(kvm, &vm_list, vm_list) {
+ *   - virt/kvm/kvm_main.c|4111| <<vcpu_stat_get>> list_for_each_entry(kvm, &vm_list, vm_list) {
+ *   - virt/kvm/kvm_main.c|4130| <<vcpu_stat_clear>> list_for_each_entry(kvm, &vm_list, vm_list) {
+ */
 LIST_HEAD(vm_list);
 
 static cpumask_var_t cpus_hardware_enabled;
@@ -626,6 +649,12 @@ static int kvm_create_vm_debugfs(struct kvm *kvm, int fd)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - virt/kvm/kvm_main.c|3443| <<kvm_dev_ioctl_create_vm>> kvm = kvm_create_vm(type);
+ *
+ * kvm的dev: kvm_chardev_ops->kvm_dev_ioctl()::KVM_CREATE_VM->kvm_dev_ioctl_create_vm()->kvm_create_vm()
+ */
 static struct kvm *kvm_create_vm(unsigned long type)
 {
 	int r, i;
@@ -774,6 +803,9 @@ void kvm_put_kvm(struct kvm *kvm)
 EXPORT_SYMBOL_GPL(kvm_put_kvm);
 
 
+/*
+ * struct file_operations kvm_vm_fops.release = kvm_vm_release()
+ */
 static int kvm_vm_release(struct inode *inode, struct file *filp)
 {
 	struct kvm *kvm = filp->private_data;
@@ -2317,6 +2349,11 @@ static int kvm_vcpu_check_block(struct kvm_vcpu *vcpu)
 /*
  * The vCPU has executed a HLT instruction with in-kernel mode enabled.
  */
+/*
+ * called by:
+ *   - arch/x86/kvm/x86.c|8072| <<vcpu_block>> kvm_vcpu_block(vcpu);
+ *   - arch/x86/kvm/x86.c|8285| <<kvm_arch_vcpu_ioctl_run>> kvm_vcpu_block(vcpu);
+ */
 void kvm_vcpu_block(struct kvm_vcpu *vcpu)
 {
 	ktime_t start, cur;
@@ -2573,6 +2610,11 @@ static int kvm_vcpu_release(struct inode *inode, struct file *filp)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - virt/kvm/kvm_main.c|2592| <<create_vcpu_fd>> return anon_inode_getfd(name, &kvm_vcpu_fops, vcpu, O_RDWR | O_CLOEXEC);
+ *   - virt/kvm/kvm_main.c|4302| <<kvm_init>> kvm_vcpu_fops.owner = module;
+ */
 static struct file_operations kvm_vcpu_fops = {
 	.release        = kvm_vcpu_release,
 	.unlocked_ioctl = kvm_vcpu_ioctl,
@@ -2584,6 +2626,12 @@ static struct file_operations kvm_vcpu_fops = {
 /*
  * Allocates an inode for the vcpu.
  */
+/*
+ * called by:
+ *   - virt/kvm/kvm_main.c|2701| <<kvm_vm_ioctl_create_vcpu>> r = create_vcpu_fd(vcpu);
+ *
+ * 设置vcpu的dev为kvm_vcpu_fops
+ */
 static int create_vcpu_fd(struct kvm_vcpu *vcpu)
 {
 	char name[8 + 1 + ITOA_MAX_LEN + 1];
@@ -2621,6 +2669,14 @@ static int kvm_create_vcpu_debugfs(struct kvm_vcpu *vcpu)
 /*
  * Creates some virtual cpus.  Good luck creating more than one.
  */
+/*
+ * called by:
+ *   - virt/kvm/kvm_main.c|3229| <<kvm_vm_ioctl>> r = kvm_vm_ioctl_create_vcpu(kvm, arg);
+ *
+ * vm的dev: kvm_vm_fops->kvm_vm_ioctl()::KVM_CREATE_VCPU
+ *
+ * 这个函数会用create_vcpu_fd()设置vcpu的dev为kvm_vcpu_fops
+ */
 static int kvm_vm_ioctl_create_vcpu(struct kvm *kvm, u32 id)
 {
 	int r;
@@ -2664,6 +2720,9 @@ static int kvm_vm_ioctl_create_vcpu(struct kvm *kvm, u32 id)
 
 	/* Now it's all set up, let userspace reach it */
 	kvm_get_kvm(kvm);
+	/*
+	 * 设置vcpu的dev为kvm_vcpu_fops
+	 */
 	r = create_vcpu_fd(vcpu);
 	if (r < 0) {
 		kvm_put_kvm(kvm);
@@ -2706,6 +2765,11 @@ static int kvm_vcpu_ioctl_set_sigmask(struct kvm_vcpu *vcpu, sigset_t *sigset)
 	return 0;
 }
 
+/*
+ * struct file_operations kvm_vcpu_fops.unlocked_ioctl = kvm_vcpu_ioctl()
+ *
+ * vcpu的dev: kvm_vcpu_fops->kvm_vcpu_ioctl()
+ */
 static long kvm_vcpu_ioctl(struct file *filp,
 			   unsigned int ioctl, unsigned long arg)
 {
@@ -3181,6 +3245,11 @@ static int kvm_vm_ioctl_enable_cap_generic(struct kvm *kvm,
 	}
 }
 
+/*
+ * struct file_operations kvm_vm_fops.unlocked_ioctl = kvm_vm_ioctl()
+ *
+ * vm的dev: kvm_vm_fops->kvm_vm_ioctl()
+ */
 static long kvm_vm_ioctl(struct file *filp,
 			   unsigned int ioctl, unsigned long arg)
 {
@@ -3411,6 +3480,11 @@ static long kvm_vm_compat_ioctl(struct file *filp,
 }
 #endif
 
+/*
+ * used by:
+ *   - virt/kvm/kvm_main.c|3439| <<kvm_dev_ioctl_create_vm>> file = anon_inode_getfile("kvm-vm", &kvm_vm_fops, kvm, O_RDWR);
+ *   - virt/kvm/kvm_main.c|4301| <<kvm_init>> kvm_vm_fops.owner = module;
+ */
 static struct file_operations kvm_vm_fops = {
 	.release        = kvm_vm_release,
 	.unlocked_ioctl = kvm_vm_ioctl,
@@ -3418,6 +3492,14 @@ static struct file_operations kvm_vm_fops = {
 	KVM_COMPAT(kvm_vm_compat_ioctl),
 };
 
+/*
+ * called by:
+ *   - virt/kvm/kvm_main.c|3498| <<kvm_dev_ioctl>> r = kvm_dev_ioctl_create_vm(arg);
+ *
+ * kvm的dev: kvm_chardev_ops->kvm_dev_ioctl()::KVM_CREATE_VM
+ *
+ * 在这个函数会设置vm的dev为kvm_vm_fops
+ */
 static int kvm_dev_ioctl_create_vm(unsigned long type)
 {
 	int r;
@@ -3436,6 +3518,9 @@ static int kvm_dev_ioctl_create_vm(unsigned long type)
 	if (r < 0)
 		goto put_kvm;
 
+	/*
+	 * 设置vm的dev!!
+	 */
 	file = anon_inode_getfile("kvm-vm", &kvm_vm_fops, kvm, O_RDWR);
 	if (IS_ERR(file)) {
 		put_unused_fd(r);
@@ -3464,6 +3549,11 @@ static int kvm_dev_ioctl_create_vm(unsigned long type)
 	return r;
 }
 
+/*
+ * struct file_operations kvm_chardev_ops.unlocked_ioctl = kvm_dev_ioctl()
+ *
+ * kvm的dev: kvm_chardev_ops->kvm_dev_ioctl()
+ */
 static long kvm_dev_ioctl(struct file *filp,
 			  unsigned int ioctl, unsigned long arg)
 {
@@ -3504,6 +3594,9 @@ static long kvm_dev_ioctl(struct file *filp,
 	return r;
 }
 
+/*
+ * struct miscdevice kvm_dev.fops = kvm_chardev_ops
+ */
 static struct file_operations kvm_chardev_ops = {
 	.unlocked_ioctl = kvm_dev_ioctl,
 	.llseek		= noop_llseek,
@@ -4110,6 +4203,11 @@ static const struct file_operations *stat_fops[] = {
 	[KVM_STAT_VM]   = &vm_stat_fops,
 };
 
+/*
+ * called by:
+ *   - virt/kvm/kvm_main.c|743| <<kvm_destroy_vm>> kvm_uevent_notify_change(KVM_EVENT_DESTROY_VM, kvm);
+ *   - virt/kvm/kvm_main.c|3485| <<kvm_dev_ioctl_create_vm>> kvm_uevent_notify_change(KVM_EVENT_CREATE_VM, kvm);
+ */
 static void kvm_uevent_notify_change(unsigned int type, struct kvm *kvm)
 {
 	struct kobj_uevent_env *env;
@@ -4224,6 +4322,11 @@ static void kvm_sched_out(struct preempt_notifier *pn,
 	kvm_arch_vcpu_put(vcpu);
 }
 
+/*
+ * x86下调用:
+ *   - arch/x86/kvm/svm.c|7290| <<svm_init>> return kvm_init(&svm_x86_ops, sizeof(struct vcpu_svm),
+ *   - arch/x86/kvm/vmx/vmx.c|7813| <<vmx_init>> r = kvm_init(&vmx_x86_ops, sizeof(struct vcpu_vmx),
+ */
 int kvm_init(void *opaque, unsigned vcpu_size, unsigned vcpu_align,
 		  struct module *module)
 {
-- 
2.7.4

