Xen Hotplug Overview
===============================================================================

Xen hotplug includes memory hotplug and cpu hotplug. 

The xen memory hotplug source code is at:
linux/drivers/xen/balloon.c
linux/drivers/xen/xen-balloon.c

The xen cpu hotplug source code is at:
linux/drivers/xen/cpu_hotplug.c


Memory Hotplug
===============================================================================

xl usage: xl mem-set domid new-memory
xm usage: xm mem-set domname new-memory

There is information in sysfs at: /sys/bus/xen_memory/devices/xen_memory0/

    memory = ""
     target = "2097152"

balloon_stats.current_pages is the current pages used by guest.
balloon_stats.target_pages is the pages available to guest. Function
balloon_process() is used as handler for delayed work balloon_worker.  Xenwatch
watches at xenstore node "memory/target" with handler watch_target().  This
handler would set balloon_stats.target_pages and push balloon_worker to run.
Since balloon_stats.target_pages is different with balloon_stats.current_pages
now, the kernel would either increase or decrease memory. Memory pages are
added to guest via XENMEM_populate_physmap, and removed from guest via
XENMEM_decrease_reservation.


CPU Hotplug
===============================================================================

xl usage: xl vcpu-set domid vcpu-count
xm usage: xm vcpu-set domname vcpu-count

Xen cpu hotplug is closely based on the linux cpu hotplug in
linux/kernel/cpu.c. Xen hotplug notifies the cpu status to linux cpu hotplug
via cpu_up() or cpu_down(). Xen cpu hotplug is responsible to set vcpu possible
and present. Linux cpu hotplug is responsible to set vcpu as on/off. 

The following masks are basic of xen cpu hotplug.

*cpu_possible_mask*: Bitmap of possible CPUs that can ever be available in the
system. This is used to allocate some boot time memory for per_cpu variables
that aren't designed to grow/shrink as CPUs are made available or removed.
Once set during boot time discovery phase, the map is static, i.e no bits are
added or removed anytime.  Trimming it accurately for your system needs upfront
can save some boot time memory. See below for how we use heuristics in x86_64
case to keep this under check.

*cpu_online_mask*: Bitmap of all CPUs currently online. Its set in __cpu_up()
after a cpu is available for kernel scheduling and ready to receive interrupts
from devices. Its cleared when a cpu is brought down using __cpu_disable(),
before which all OS services including interrupts are migrated to another
target CPU.

*cpu_present_mask*: Bitmap of CPUs currently present in the system. Not all of
them may be online. When physical hotplug is processed by the relevant
subsystem (e.g ACPI) can change and new bit either be added or removed from the
map depending on the event is hot-add/hot-remove. There are currently no
locking rules as of now. Typical usage is to init topology during boot, at
which time hotplug is disabled.

In a nutshell, *cpu_possible_mask* indicates the maximum possible vcpu the
guest can support, that is, the "maxvcpus" set in vm.cfg or the list of vcpu in
xenstore (either online or offline in xenstore). *cpu_present_mask* indicates
if the current vcpu is shown in xenstore as online. Keep in mind that the vcpu
is online in xenstore does not indicate that the vcpu is online to linux.

The status of each guest vcpu is represented by a corresponding entry in
xenstore, e.g.:

    cpu = ""
     0 = ""
      availability = "online"
     1 = ""
      availability = "online"

Just in the case above, both vcpu 0 and vcpu 1 are online.

The entry function to initiate cpu hotplug is setup_vcpu_hotplug_event(). This
function set xenwatch handler (handle_vcpu_hotplug_event()) at xenstore node
"cpu".
