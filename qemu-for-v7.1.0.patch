From c36c2ea7050de9f9cf9255da9c60e463eba41c9a Mon Sep 17 00:00:00 2001
From: Dongli Zhang <dongli.zhang0129@gmail.com>
Date: Wed, 5 Apr 2023 23:28:38 -0700
Subject: [PATCH 1/1] qemu for v7.1.0

Signed-off-by: Dongli Zhang <dongli.zhang0129@gmail.com>
---
 accel/accel-common.c                  |   3 +
 accel/kvm/kvm-accel-ops.c             |   4 +
 accel/kvm/kvm-all.c                   | 152 ++++++++++++
 block.c                               | 343 ++++++++++++++++++++++++++
 block/accounting.c                    |  34 +++
 block/aio_task.c                      |  47 ++++
 block/block-backend.c                 | 288 +++++++++++++++++++++
 block/commit.c                        |  14 ++
 block/file-posix.c                    |  72 ++++++
 block/io.c                            | 157 ++++++++++++
 block/io_uring.c                      |   6 +
 block/iscsi.c                         | 253 +++++++++++++++++++
 block/linux-aio.c                     | 106 ++++++++
 block/mirror.c                        |  80 ++++++
 block/qcow2-cluster.c                 |   9 +
 block/qcow2.c                         |  52 ++++
 block/raw-format.c                    |   4 +
 block/snapshot.c                      |   9 +
 blockdev.c                            |  94 +++++++
 blockjob.c                            |  86 +++++++
 chardev/char-fe.c                     |  37 +++
 chardev/char-io.c                     |  25 ++
 chardev/char.c                        |   6 +
 hw/acpi/core.c                        |  10 +
 hw/acpi/cpu.c                         |   4 +
 hw/acpi/cpu_hotplug.c                 |   4 +
 hw/acpi/ich9.c                        |  38 +++
 hw/acpi/pci.c                         |   6 +
 hw/acpi/pcihp.c                       | 112 +++++++++
 hw/acpi/piix4.c                       |  30 +++
 hw/block/dataplane/virtio-blk.c       | 123 +++++++++
 hw/block/virtio-blk.c                 | 206 ++++++++++++++++
 hw/core/loader.c                      |  85 +++++++
 hw/core/qdev-properties-system.c      |  20 ++
 hw/core/qdev.c                        |  54 ++++
 hw/core/reset.c                       |  13 +
 hw/i386/acpi-build.c                  |  38 +++
 hw/i386/fw_cfg.c                      |   4 +
 hw/i386/intel_iommu.c                 |  19 ++
 hw/i386/pc.c                          |  24 ++
 hw/i386/x86.c                         |   4 +
 hw/net/virtio-net.c                   |  29 +++
 hw/pci/pci_host.c                     |  19 ++
 hw/scsi/scsi-disk.c                   |  25 ++
 hw/scsi/vhost-scsi-common.c           |  20 ++
 hw/scsi/vhost-scsi.c                  |   6 +
 hw/scsi/virtio-scsi-dataplane.c       |  70 ++++++
 hw/scsi/virtio-scsi.c                 |  93 +++++++
 hw/vfio/common.c                      |   6 +
 hw/virtio/vhost.c                     |  38 +++
 hw/virtio/virtio-bus.c                |  82 ++++++
 hw/virtio/virtio-pci.c                |  55 +++++
 hw/virtio/virtio.c                    | 248 +++++++++++++++++++
 include/block/block_int-common.h      |   8 +
 include/exec/memory.h                 |  46 ++++
 include/hw/core/accel-cpu.h           |  10 +
 include/hw/core/cpu.h                 |  11 +
 include/hw/loader.h                   |   8 +
 include/hw/qdev-core.h                |  13 +
 include/hw/virtio/vhost-scsi-common.h |   6 +
 include/hw/virtio/virtio-bus.h        |  30 +++
 include/hw/virtio/virtio-pci.h        |  44 ++++
 include/hw/virtio/virtio-scsi.h       |  39 +++
 include/hw/virtio/virtio.h            |  22 ++
 include/sysemu/accel-ops.h            |  20 ++
 io/channel.c                          |  27 ++
 iothread.c                            |   4 +
 job.c                                 |  74 ++++++
 monitor/hmp.c                         |  35 +++
 net/dump.c                            |   8 +
 qga/commands-posix.c                  |  28 +++
 qom/object.c                          |  29 +++
 softmmu/cpus.c                        |  53 ++++
 softmmu/memory.c                      | 258 +++++++++++++++++++
 softmmu/physmem.c                     |  18 ++
 softmmu/runstate.c                    |  10 +
 softmmu/vl.c                          |  14 ++
 target/i386/cpu-dump.c                |   8 +
 target/i386/cpu.c                     | 210 ++++++++++++++++
 target/i386/cpu.h                     |  98 ++++++++
 target/i386/host-cpu.c                |  27 ++
 target/i386/kvm/kvm-cpu.c             |  10 +
 target/i386/kvm/kvm.c                 | 293 ++++++++++++++++++++++
 target/i386/machine.c                 |  10 +
 ui/spice-core.c                       |   5 +
 util/aio-posix.c                      |  77 ++++++
 util/aio-wait.c                       |  17 ++
 util/async.c                          |   4 +
 util/coroutine-sigaltstack.c          |   4 +
 util/log.c                            |  29 +++
 util/main-loop.c                      |  33 +++
 util/qemu-config.c                    |   3 +
 util/qemu-coroutine.c                 |  53 ++++
 util/qemu-option.c                    |  29 +++
 util/qemu-thread-common.h             |   5 +
 util/qemu-thread-posix.c              |   6 +
 util/qsp.c                            |   7 +
 util/readline.c                       |  49 ++++
 util/thread-pool.c                    |  56 +++++
 99 files changed, 5214 insertions(+)

diff --git a/accel/accel-common.c b/accel/accel-common.c
index 50035bda5..5312af961 100644
--- a/accel/accel-common.c
+++ b/accel/accel-common.c
@@ -124,6 +124,9 @@ bool accel_cpu_realizefn(CPUState *cpu, Error **errp)
     CPUClass *cc = CPU_GET_CLASS(cpu);
 
     if (cc->accel_cpu && cc->accel_cpu->cpu_realizefn) {
+        /*
+	 * kvm_cpu_realizefn()
+	 */
         return cc->accel_cpu->cpu_realizefn(cpu, errp);
     }
     return true;
diff --git a/accel/kvm/kvm-accel-ops.c b/accel/kvm/kvm-accel-ops.c
index c4244a23c..21a98283f 100644
--- a/accel/kvm/kvm-accel-ops.c
+++ b/accel/kvm/kvm-accel-ops.c
@@ -24,6 +24,10 @@
 
 #include "kvm-cpus.h"
 
+/*
+ * 在以下使用kvm_vcpu_thread_fn():
+ *   - accel/kvm/kvm-accel-ops.c|73| <<kvm_start_vcpu_thread>> qemu_thread_create(cpu->thread, thread_name, kvm_vcpu_thread_fn,
+ */
 static void *kvm_vcpu_thread_fn(void *arg)
 {
     CPUState *cpu = arg;
diff --git a/accel/kvm/kvm-all.c b/accel/kvm/kvm-all.c
index 8d81ab74d..48e765bfb 100644
--- a/accel/kvm/kvm-all.c
+++ b/accel/kvm/kvm-all.c
@@ -441,6 +441,10 @@ void kvm_destroy_vcpu(CPUState *cpu)
     }
 }
 
+/*
+ * called by:
+ *   - accel/kvm/kvm-all.c|474| <<kvm_init_vcpu>> ret = kvm_get_vcpu(s, kvm_arch_vcpu_id(cpu));
+ */
 static int kvm_get_vcpu(KVMState *s, unsigned long vcpu_id)
 {
     struct KVMParkedVcpu *cpu;
@@ -459,6 +463,10 @@ static int kvm_get_vcpu(KVMState *s, unsigned long vcpu_id)
     return kvm_vm_ioctl(s, KVM_CREATE_VCPU, (void *)vcpu_id);
 }
 
+/*
+ * called by:
+ *   - accel/kvm/kvm-accel-ops.c|40| <<kvm_vcpu_thread_fn>> r = kvm_init_vcpu(cpu, &error_fatal);
+ */
 int kvm_init_vcpu(CPUState *cpu, Error **errp)
 {
     KVMState *s = kvm_state;
@@ -1148,6 +1156,22 @@ static MemoryListener kvm_coalesced_pio_listener = {
     .coalesced_io_del = kvm_coalesce_pio_del,
 };
 
+/*
+ * 一些例子:
+ *   - accel/kvm/kvm-all.c|1178| <<kvm_vm_check_extension>> ret = kvm_check_extension(s, extension);
+ *   - accel/kvm/kvm-all.c|1341| <<kvm_check_extension_list>> if (!kvm_check_extension(s, list->value)) {
+ *   - accel/kvm/kvm-all.c|1745| <<kvm_init_irq_routing>> gsi_count = kvm_check_extension(s, KVM_CAP_IRQ_ROUTING) - 1;
+ *   - accel/kvm/kvm-all.c|2150| <<kvm_irqchip_add_hv_sint_route>> if (!kvm_check_extension(s, KVM_CAP_HYPERV_SYNIC)) {
+ *   - accel/kvm/kvm-all.c|2259| <<kvm_irqchip_create>> if (kvm_check_extension(s, KVM_CAP_IRQCHIP)) {
+ *   - accel/kvm/kvm-all.c|2261| <<kvm_irqchip_create>> } else if (kvm_check_extension(s, KVM_CAP_S390_IRQCHIP)) {
+ *   - accel/kvm/kvm-all.c|2311| <<kvm_max_vcpus>> int ret = kvm_check_extension(s, KVM_CAP_MAX_VCPUS);
+ *   - accel/kvm/kvm-all.c|2317| <<kvm_max_vcpu_id>> int ret = kvm_check_extension(s, KVM_CAP_MAX_VCPU_ID);
+ *   - accel/kvm/kvm-all.c|2402| <<kvm_init>> kvm_immediate_exit = kvm_check_extension(s, KVM_CAP_IMMEDIATE_EXIT);
+ *   - target/i386/kvm/kvm.c|1812| <<kvm_arch_init_vcpu>> has_xsave2 = kvm_check_extension(cs->kvm_state, KVM_CAP_XSAVE2);
+ *   - target/i386/kvm/kvm.c|1825| <<kvm_arch_init_vcpu>> r = kvm_check_extension(cs->kvm_state, KVM_CAP_GET_TSC_KHZ) ?
+ *   - target/i386/kvm/kvm.c|2131| <<kvm_arch_init_vcpu>> && kvm_check_extension(cs->kvm_state, KVM_CAP_MCE) > 0) {
+ *   - target/i386/kvm/kvm.c|2334| <<kvm_get_supported_feature_msrs>> if (!kvm_check_extension(s, KVM_CAP_GET_MSR_FEATURES)) {
+ */
 int kvm_check_extension(KVMState *s, unsigned int extension)
 {
     int ret;
@@ -1160,6 +1184,30 @@ int kvm_check_extension(KVMState *s, unsigned int extension)
     return ret;
 }
 
+/*
+ * called by:
+ *   - accel/kvm/kvm-all.c|2305| <<kvm_recommended_vcpus>> int ret = kvm_vm_check_extension(s, KVM_CAP_NR_VCPUS);
+ *   - accel/kvm/kvm-all.c|2503| <<kvm_init>> ret = kvm_vm_check_extension(s, KVM_CAP_DIRTY_LOG_RING);
+ *   - accel/kvm/kvm-all.c|2656| <<kvm_init>> s->sync_mmu = !!kvm_vm_check_extension(kvm_state, KVM_CAP_SYNC_MMU);
+ *   - target/i386/kvm/kvm.c|185| <<kvm_has_smm>> return kvm_vm_check_extension(kvm_state, KVM_CAP_X86_SMM);
+ *   - target/i386/kvm/kvm.c|5281| <<__kvm_enable_sgx_provisioning>> if (!kvm_vm_check_extension(s, KVM_CAP_SGX_ATTRIBUTE)) {
+ *   - target/ppc/kvm.c|104| <<kvmppc_is_pr>> return kvm_vm_check_extension(ks, KVM_CAP_PPC_GET_PVINFO) != 0;
+ *   - target/ppc/kvm.c|116| <<kvm_arch_init>> cap_ppc_smt_possible = kvm_vm_check_extension(s, KVM_CAP_PPC_SMT_POSSIBLE);
+ *   - target/ppc/kvm.c|120| <<kvm_arch_init>> cap_spapr_vfio = kvm_vm_check_extension(s, KVM_CAP_SPAPR_TCE_VFIO);
+ *   - target/ppc/kvm.c|129| <<kvm_arch_init>> cap_htab_fd = kvm_vm_check_extension(s, KVM_CAP_PPC_HTAB_FD);
+ *   - target/ppc/kvm.c|131| <<kvm_arch_init>> cap_ppc_smt = kvm_vm_check_extension(s, KVM_CAP_PPC_SMT);
+ *   - target/ppc/kvm.c|132| <<kvm_arch_init>> cap_htm = kvm_vm_check_extension(s, KVM_CAP_PPC_HTM);
+ *   - target/ppc/kvm.c|133| <<kvm_arch_init>> cap_mmu_radix = kvm_vm_check_extension(s, KVM_CAP_PPC_MMU_RADIX);
+ *   - target/ppc/kvm.c|134| <<kvm_arch_init>> cap_mmu_hash_v3 = kvm_vm_check_extension(s, KVM_CAP_PPC_MMU_HASH_V3);
+ *   - target/ppc/kvm.c|135| <<kvm_arch_init>> cap_xive = kvm_vm_check_extension(s, KVM_CAP_PPC_IRQ_XIVE);
+ *   - target/ppc/kvm.c|136| <<kvm_arch_init>> cap_resize_hpt = kvm_vm_check_extension(s, KVM_CAP_SPAPR_RESIZE_HPT);
+ *   - target/ppc/kvm.c|138| <<kvm_arch_init>> cap_ppc_nested_kvm_hv = kvm_vm_check_extension(s, KVM_CAP_PPC_NESTED_HV);
+ *   - target/ppc/kvm.c|140| <<kvm_arch_init>> cap_fwnmi = kvm_vm_check_extension(s, KVM_CAP_PPC_FWNMI);
+ *   - target/ppc/kvm.c|155| <<kvm_arch_init>> cap_rpt_invalidate = kvm_vm_check_extension(s, KVM_CAP_PPC_RPT_INVALIDATE);
+ *   - target/ppc/kvm.c|1972| <<kvmppc_get_pvinfo>> if (kvm_vm_check_extension(cs->kvm_state, KVM_CAP_PPC_GET_PVINFO) &&
+ *   - target/ppc/kvm.c|2292| <<kvmppc_reset_htab>> if (kvm_vm_check_extension(kvm_state, KVM_CAP_PPC_ALLOC_HTAB)) {
+ *   - target/ppc/kvm.c|2488| <<kvmppc_get_cpu_characteristics>> ret = kvm_vm_check_extension(s, KVM_CAP_PPC_GET_CPU_CHAR);
+ */
 int kvm_vm_check_extension(KVMState *s, unsigned int extension)
 {
     int ret;
@@ -2683,6 +2731,25 @@ void kvm_set_sigmask_len(KVMState *s, unsigned int sigmask_len)
     s->sigmask_len = sigmask_len;
 }
 
+/*
+ * (gdb) bt
+ * #0  0x00007f1e2f36554d in __lll_lock_wait () at /lib64/libpthread.so.0
+ * #1  0x00007f1e2f360e9b in _L_lock_883 () at /lib64/libpthread.so.0
+ * #2  0x00007f1e2f360d68 in pthread_mutex_lock () at /lib64/libpthread.so.0
+ * #3  0x000055cf31836820 in qemu_mutex_lock_impl (mutex=0x55cf320fac20 <qemu_global_mutex>, file=0x55cf319e3d1d "../softmmu/physmem.c", line=2765) at ../util/qemu-thread-posix.c:88
+ * #4  0x000055cf313b6d44 in qemu_mutex_lock_iothread_impl (file=0x55cf319e3d1d "../softmmu/physmem.c", line=2765) at ../softmmu/cpus.c:502
+ * #5  0x000055cf315baa3e in prepare_mmio_access (mr=0x55cf3431d0c0) at ../softmmu/physmem.c:2765
+ * #6  0x000055cf315badf6 in flatview_read_continue (fv=0x7f1c98167720, addr=1017, attrs=..., ptr=0x7f1e31f86000, len=1, addr1=1, l=1, mr=0x55cf3431d0c0) at ../softmmu/physmem.c:2890
+ * #7  0x000055cf315bafc1 in flatview_read (fv=0x7f1c98167720, addr=1017, attrs=..., buf=0x7f1e31f86000, len=1) at ../softmmu/physmem.c:2934
+ * #8  0x000055cf315bb04a in address_space_read_full (as=0x55cf32102a40 <address_space_io>, addr=1017, attrs=..., buf=0x7f1e31f86000, len=1) at ../softmmu/physmem.c:2947
+ * #9  0x000055cf315bb16e in address_space_rw (as=0x55cf32102a40 <address_space_io>, addr=1017, attrs=..., buf=0x7f1e31f86000, len=1, is_write=false) at ../softmmu/physmem.c:2975
+ * #10 0x000055cf31652e3b in kvm_handle_io (port=1017, attrs=..., data=0x7f1e31f86000, direction=0, size=1, count=1) at ../accel/kvm/kvm-all.c:2693
+ * #11 0x000055cf316535b5 in kvm_cpu_exec (cpu=0x55cf3397f120) at ../accel/kvm/kvm-all.c:2944
+ * #12 0x000055cf31656282 in kvm_vcpu_thread_fn (arg=0x55cf3397f120) at ../accel/kvm/kvm-accel-ops.c:49
+ * #13 0x000055cf318374d9 in qemu_thread_start (args=0x55cf3398ec40) at ../util/qemu-thread-posix.c:504
+ * #14 0x00007f1e2f35eea5 in start_thread () at /lib64/libpthread.so.0
+ * #15 0x00007f1e2f0879fd in clone () at /lib64/libc.so.6
+ */
 static void kvm_handle_io(uint16_t port, MemTxAttrs attrs, void *data, int direction,
                           int size, uint32_t count)
 {
@@ -2697,8 +2764,22 @@ static void kvm_handle_io(uint16_t port, MemTxAttrs attrs, void *data, int direc
     }
 }
 
+/*
+ * 处理KVM_EXIT_INTERNAL_ERROR:
+ *   - accel/kvm/kvm-all.c|3084| <<kvm_cpu_exec>> ret = kvm_handle_internal_error(cpu, run);
+ */
 static int kvm_handle_internal_error(CPUState *cpu, struct kvm_run *run)
 {
+    /*
+     * struct kvm_run *run:
+     *     // KVM_EXIT_INTERNAL_ERROR
+     *     struct {
+     *         __u32 suberror;
+     *         // Available with KVM_CAP_INTERNAL_ERROR_DATA:
+     *         __u32 ndata;
+     *         __u64 data[16];
+     *     } internal;
+     */
     fprintf(stderr, "KVM internal error. Suberror: %d\n",
             run->internal.suberror);
 
@@ -2760,6 +2841,10 @@ bool kvm_cpu_check_are_resettable(void)
     return kvm_arch_cpu_check_are_resettable();
 }
 
+/*
+ * 在以下使用do_kvm_cpu_synchronize_state():
+ *   - accel/kvm/kvm-all.c|2774| <<kvm_cpu_synchronize_state>> run_on_cpu(cpu, do_kvm_cpu_synchronize_state, RUN_ON_CPU_NULL);
+ */
 static void do_kvm_cpu_synchronize_state(CPUState *cpu, run_on_cpu_data arg)
 {
     if (!cpu->vcpu_dirty) {
@@ -2768,6 +2853,20 @@ static void do_kvm_cpu_synchronize_state(CPUState *cpu, run_on_cpu_data arg)
     }
 }
 
+/*
+ * 在以下使用和调用kvm_cpu_synchronize_state():
+ *   - accel/kvm/kvm-accel-ops.c|96| <<kvm_accel_ops_class_init>> ops->synchronize_state = kvm_cpu_synchronize_state;
+ *   - accel/kvm/kvm-all.c|3039| <<kvm_cpu_exec>> kvm_cpu_synchronize_state(cpu);
+ *   - accel/stubs/kvm-stub.c|35| <<kvm_cpu_synchronize_state>> void kvm_cpu_synchronize_state(CPUState *cpu)
+ *   - target/arm/kvm64.c|1455| <<kvm_arch_on_sigbus_vcpu>> kvm_cpu_synchronize_state(c);
+ *   - target/arm/kvm64.c|1525| <<kvm_arm_handle_debug>> kvm_cpu_synchronize_state(cs);
+ *   - target/i386/kvm/kvm.c|4824| <<kvm_arch_process_async_events>> kvm_cpu_synchronize_state(cs);
+ *   - target/i386/kvm/kvm.c|4843| <<kvm_arch_process_async_events>> kvm_cpu_synchronize_state(cs);
+ *   - target/i386/kvm/kvm.c|4861| <<kvm_arch_process_async_events>> kvm_cpu_synchronize_state(cs);
+ *   - target/i386/kvm/kvm.c|4866| <<kvm_arch_process_async_events>> kvm_cpu_synchronize_state(cs);
+ *   - target/i386/kvm/kvm.c|5204| <<kvm_arch_stop_on_emulation_error>> kvm_cpu_synchronize_state(cs);
+ *   - target/s390x/kvm/kvm.c|1967| <<kvm_arch_handle_exit>> kvm_cpu_synchronize_state(cs);
+ */
 void kvm_cpu_synchronize_state(CPUState *cpu)
 {
     if (!cpu->vcpu_dirty) {
@@ -2775,17 +2874,49 @@ void kvm_cpu_synchronize_state(CPUState *cpu)
     }
 }
 
+/*
+ * (gdb) bt
+ * #0  do_kvm_cpu_synchronize_post_reset (cpu=0x555556aa6f30, arg=...) at ../accel/kvm/kvm-all.c:2780
+ * #1  0x0000555555821f77 in process_queued_cpu_work (cpu=0x555556aa6f30) at ../cpus-common.c:351
+ * #2  0x0000555555a717d4 in qemu_wait_io_event_common (cpu=0x555556aa6f30) at ../softmmu/cpus.c:411
+ * #3  0x0000555555a71865 in qemu_wait_io_event (cpu=0x555556aa6f30) at ../softmmu/cpus.c:435
+ * #4  0x0000555555d1105f in kvm_vcpu_thread_fn (arg=0x555556aa6f30) at ../accel/kvm/kvm-accel-ops.c:54
+ * #5  0x0000555555eec56f in qemu_thread_start (args=0x555556ab6b70) at ../util/qemu-thread-posix.c:504
+ * #6  0x00007ffff55eeea5 in start_thread () at /lib64/libpthread.so.0
+ * #7  0x00007ffff53179fd in clone () at /lib64/libc.so.6
+ *
+ * 在以下使用do_kvm_cpu_synchronize_post_reset():
+ *   - accel/kvm/kvm-all.c|2786| <<kvm_cpu_synchronize_post_reset>> run_on_cpu(cpu, do_kvm_cpu_synchronize_post_reset, RUN_ON_CPU_NULL);
+ */
 static void do_kvm_cpu_synchronize_post_reset(CPUState *cpu, run_on_cpu_data arg)
 {
     kvm_arch_put_registers(cpu, KVM_PUT_RESET_STATE);
     cpu->vcpu_dirty = false;
 }
 
+/*
+ * (gdb) bt
+ * #0  kvm_cpu_synchronize_post_reset (cpu=0x555556aa6f30) at ../accel/kvm/kvm-all.c:2786
+ * #1  0x0000555555a711ea in cpu_synchronize_post_reset (cpu=0x555556aa6f30) at ../softmmu/cpus.c:177
+ * #2  0x0000555555a71066 in cpu_synchronize_all_post_reset () at ../softmmu/cpus.c:145
+ * #3  0x0000555555a798dd in qemu_system_reset (reason=SHUTDOWN_CAUSE_HOST_QMP_SYSTEM_RESET) at ../softmmu/runstate.c:451
+ * #4  0x0000555555a79f75 in main_loop_should_exit (status=0x7fffffffddc4) at ../softmmu/runstate.c:694]
+ * #5  0x0000555555a7a06a in qemu_main_loop () at ../softmmu/runstate.c:730
+ * #6  0x000055555581fe62 in qemu_main (argc=18, argv=0x7fffffffdf18, envp=0x0) at ../softmmu/main.c:38
+ * #7  0x000055555581fe94 in main (argc=18, argv=0x7fffffffdf18) at ../softmmu/main.c:47
+ *
+ * 在以下使用kvm_cpu_synchronize_post_reset():
+ *   - accel/kvm/kvm-accel-ops.c|94| <<kvm_accel_ops_class_init>> ops->synchronize_post_reset = kvm_cpu_synchronize_post_reset;
+ */
 void kvm_cpu_synchronize_post_reset(CPUState *cpu)
 {
     run_on_cpu(cpu, do_kvm_cpu_synchronize_post_reset, RUN_ON_CPU_NULL);
 }
 
+/*
+ * 在以下使用do_kvm_cpu_synchronize_post_init():
+ *   - accel/kvm/kvm-all.c|2924| <<kvm_cpu_synchronize_post_init>> run_on_cpu(cpu, do_kvm_cpu_synchronize_post_init, RUN_ON_CPU_NULL);
+ */
 static void do_kvm_cpu_synchronize_post_init(CPUState *cpu, run_on_cpu_data arg)
 {
     kvm_arch_put_registers(cpu, KVM_PUT_FULL_STATE);
@@ -2862,6 +2993,10 @@ static void kvm_eat_signals(CPUState *cpu)
     } while (sigismember(&chkset, SIG_IPI));
 }
 
+/*
+ * called by:
+ *   - accel/kvm/kvm-accel-ops.c|53| <<kvm_vcpu_thread_fn>> r = kvm_cpu_exec(cpu);
+ */
 int kvm_cpu_exec(CPUState *cpu)
 {
     struct kvm_run *run = cpu->kvm_run;
@@ -3589,6 +3724,10 @@ static void kvm_set_kvm_shadow_mem(Object *obj, Visitor *v,
     s->kvm_shadow_mem = value;
 }
 
+/*
+ * 只在以下使用kvm_set_kernel_irqchip():
+ *   - accel/kvm/kvm-all.c|3811| <<kvm_accel_class_init>> NULL, kvm_set_kernel_irqchip,
+ */
 static void kvm_set_kernel_irqchip(Object *obj, Visitor *v,
                                    const char *name, void *opaque,
                                    Error **errp)
@@ -3700,6 +3839,19 @@ static void kvm_accel_class_init(ObjectClass *oc, void *data)
     ac->has_memory = kvm_accel_has_memory;
     ac->allowed = &kvm_allowed;
 
+    /*
+     * 1258 ObjectProperty *
+     * 1259 object_class_property_add(ObjectClass *klass,
+     * 1260                           const char *name,
+     * 1261                           const char *type,
+     * 1262                           ObjectPropertyAccessor *get,
+     * 1263                           ObjectPropertyAccessor *set,
+     * 1264                           ObjectPropertyRelease *release,
+     * 1265                           void *opaque)
+     * 1266 {
+     *
+     * kvm_set_kernel_irqchip()在kvm_arch_init()之前执行
+     */
     object_class_property_add(oc, "kernel-irqchip", "on|off|split",
         NULL, kvm_set_kernel_irqchip,
         NULL, NULL);
diff --git a/block.c b/block.c
index bc85f46ee..0f271f687 100644
--- a/block.c
+++ b/block.c
@@ -522,6 +522,11 @@ typedef struct CreateCo {
     Error *err;
 } CreateCo;
 
+/*
+ * called by:
+ *   - block.c|564| <<bdrv_create>> bdrv_create_co_entry(&cco);
+ *   - block.c|566| <<bdrv_create>> co = qemu_coroutine_create(bdrv_create_co_entry, &cco);
+ */
 static void coroutine_fn bdrv_create_co_entry(void *opaque)
 {
     Error *local_err = NULL;
@@ -1559,6 +1564,10 @@ static void update_options_from_flags(QDict *options, int flags)
     }
 }
 
+/*
+ * called by:
+ *   - block.c|1614| <<bdrv_open_driver>> bdrv_assign_node_name(bs, node_name, &local_err);
+ */
 static void bdrv_assign_node_name(BlockDriverState *bs,
                                   const char *node_name,
                                   Error **errp)
@@ -1603,6 +1612,31 @@ out:
     g_free(gen_node_name);
 }
 
+/*
+ * (gdb) bt
+ * #0  bdrv_open_driver (bs=0x555556a95050, drv=0x555556783080 <bdrv_qcow2>, node_name=0x0, options=0x555556a9a360, open_flags=139266, errp=0x7fffffffd530) at ../block.c:1609
+ * #1  0x0000555555d66643 in bdrv_open_common (bs=0x555556a95050, file=0x555556aa16b0, options=0x555556a9a360, errp=0x7fffffffd530) at ../block.c:1923
+ * #2  0x0000555555d6ad0d in bdrv_open_inherit
+ *     (filename=0x555556a7a8b0 "ol7.qcow2", reference=0x0, options=0x555556a9a360, flags=8194, parent=0x0, child_class=0x0, child_role=0, errp=0x5555567dcc60 <error_fatal>)
+ *     at ../block.c:3992
+ * #3  0x0000555555d6b275 in bdrv_open (filename=0x555556a7a8b0 "ol7.qcow2", reference=0x0, options=0x555556a80070, flags=0, errp=0x5555567dcc60 <error_fatal>) at ../block.c:4087
+ * #4  0x0000555555d90243 in blk_new_open (filename=0x555556a7a8b0 "ol7.qcow2", reference=0x0, options=0x555556a80070, flags=0, errp=0x5555567dcc60 <error_fatal>)
+ *     at ../block/block-backend.c:454
+ * #5  0x0000555555d55adf in blockdev_init (file=0x555556a7a8b0 "ol7.qcow2", bs_opts=0x555556a80070, errp=0x5555567dcc60 <error_fatal>) at ../blockdev.c:592
+ * #6  0x0000555555d56a4a in drive_new (all_opts=0x555556851b00, block_default_type=IF_IDE, errp=0x5555567dcc60 <error_fatal>) at ../blockdev.c:981
+ * #7  0x0000555555a7bbc6 in drive_init_func (opaque=0x5555568faa78, opts=0x555556851b00, errp=0x5555567dcc60 <error_fatal>) at ../softmmu/vl.c:648
+ * #8  0x0000555555efb9da in qemu_opts_foreach (list=0x55555677df40 <qemu_drive_opts>, func=0x555555a7bb92 <drive_init_func>, opaque=0x5555568faa78, errp=0x5555567dcc60 <error_fatal>)
+ *     at ../util/qemu-option.c:1135
+ * #9  0x0000555555a7be06 in configure_blockdev (bdo_queue=0x5555566dd2f0 <bdo_queue>, machine_class=0x5555568fa9d0, snapshot=0) at ../softmmu/vl.c:707
+ * #10 0x0000555555a7fae6 in qemu_create_early_backends () at ../softmmu/vl.c:1887
+ * #11 0x0000555555a83a7c in qemu_init (argc=30, argv=0x7fffffffdd98, envp=0x0) at ../softmmu/vl.c:3522
+ * #12 0x00005555558210ed in qemu_main (argc=30, argv=0x7fffffffdd98, envp=0x0) at ../softmmu/main.c:37
+ * #13 0x0000555555821124 in main (argc=30, argv=0x7fffffffdd98) at ../softmmu/main.c:47
+ *
+ * called by:
+ *   - block.c|1712| <<bdrv_new_open_driver_opts>> ret = bdrv_open_driver(bs, drv, node_name, bs->options, flags, errp);
+ *   - block.c|1932| <<bdrv_open_common>> ret = bdrv_open_driver(bs, drv, node_name, options, open_flags, errp);
+ */
 static int bdrv_open_driver(BlockDriverState *bs, BlockDriver *drv,
                             const char *node_name, QDict *options,
                             int open_flags, Error **errp)
@@ -2836,6 +2870,108 @@ uint64_t bdrv_qapi_perm_to_blk_perm(BlockPermission qapi_perm)
  * free the BdrvChild themselves (this may be important in a
  * transactional context, where it may only be freed on commit).
  */
+/*
+ * 一个例子
+ * (gdb) bt
+ * #0  bdrv_replace_child_noperm (childp=0x7fffffffd7d0, new_bs=0x555556e5ea00, free_empty_child=false) at ../block.c:2843
+ * #1  0x0000555555c0090e in bdrv_replace_child_tran (childp=<optimized out>, new_bs=<optimized out>, tran=<optimized out>, free_empty_child=<optimized out>) at ../block.c:2444
+ * #2  0x0000555555c00b93 in bdrv_replace_node_noperm (from=from@entry=0x5555567f2e30, to=to@entry=0x555556e5ea00, auto_skip=auto_skip@entry=true, tran=tran@entry=0x555556c293b0,
+ *     errp=errp@entry=0x7fffffffd8e8) at ../block.c:5208
+ * #3  0x0000555555c08085 in bdrv_append (bs_new=0x555556e5ea00, bs_top=0x5555567f2e30, errp=errp@entry=0x7fffffffd8e8) at ../block.c:5343
+ * #4  0x0000555555bf4a96 in external_snapshot_prepare (common=0x555556ffff60, errp=0x7fffffffd8e8) at ../blockdev.c:1568
+ * #5  0x0000555555bf8488 in qmp_transaction (dev_list=dev_list@entry=0x7fffffffd960, has_props=has_props@entry=false, props=0x5555571513b0,
+ *     props@entry=0x0, errp=errp@entry=0x7fffffffda28) at ../blockdev.c:2358
+ * #6  0x0000555555bf86d7 in blockdev_do_action (errp=0x7fffffffda28, action=0x7fffffffd950) at ../blockdev.c:1042
+ * #7  qmp_blockdev_snapshot_sync (has_device=<optimized out>, device=<optimized out>, has_node_name=<optimized out>, node_name=<optimized out>, snapshot_file=<optimized out>,
+ *         has_snapshot_node_name=<optimized out>, snapshot_node_name=0x5555565c7ee0 "over01", has_format=false, format=0x0, has_mode=false, mode=NEW_IMAGE_MODE_EXISTING,
+ *         errp=0x7fffffffda28) at ../blockdev.c:1070
+ * #8  0x0000555555cc146d in qmp_marshal_blockdev_snapshot_sync (args=<optimized out>, ret=<optimized out>, errp=0x7ffff7fcbea0) at qapi/qapi-commands-block-core.c:280
+ * #9  0x0000555555d232e9 in do_qmp_dispatch_bh (opaque=0x7ffff7fcbeb0) at ../qapi/qmp-dispatch.c:128
+ * #10 0x0000555555d3fea4 in aio_bh_call (bh=0x55555710b0b0) at ../util/async.c:178
+ * #11 aio_bh_poll (ctx=ctx@entry=0x5555565cac80) at ../util/async.c:178
+ * #12 0x0000555555d2cb3e in aio_dispatch (ctx=0x5555565cac80) at ../util/aio-posix.c:421
+ * #13 0x0000555555d3fb0e in aio_ctx_dispatch (source=<optimized out>, callback=<optimized out>, user_data=<optimized out>) at ../util/async.c:320
+ * #14 0x00007ffff6c40119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #15 0x0000555555d4bdc0 in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #16 os_host_main_loop_wait (timeout=0) at ../util/main-loop.c:320
+ * #17 main_loop_wait (nonblocking=nonblocking@entry=0) at ../util/main-loop.c:596
+ * #18 0x00005555559d1181 in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #19 0x0000555555825f5c in qemu_main (argc=<optimized out>, argv=<optimized out>, envp=<optimized out>) at ../softmmu/main.c:38
+ * #20 0x00007ffff501d555 in __libc_start_main () at /lib64/libc.so.6
+ * #21 0x0000555555825e8a in _start () at ../softmmu/main.c:47
+ *
+ * (gdb) bt
+ * #0  bdrv_replace_child_noperm (childp=0x7fffffffd550, new_bs=0x5555567f2e30, free_empty_child=true) at ../block.c:2843
+ * #1  0x0000555555c075e6 in bdrv_attach_child_common (child_bs=child_bs@entry=0x5555567f2e30, child_name=child_name@entry=0x555555e23630 "target",
+ *    child_class=child_class@entry=0x5555561822c0 <child_job>, child_role=child_role@entry=0, perm=perm@entry=0, shared_perm=shared_perm@entry=15,
+ *    opaque=0x555556c29060, child=0x7fffffffd5f0, tran=0x555556d289d0, errp=0x5555565547f8 <error_abort>) at ../block.c:3055
+ * #2  0x0000555555c082c4 in bdrv_root_attach_child (child_bs=child_bs@entry=0x5555567f2e30, child_name=child_name@entry=0x555555e23630 "target",
+ *     child_class=child_class@entry=0x5555561822c0 <child_job>, child_role=child_role@entry=0, perm=perm@entry=0, shared_perm=shared_perm@entry=15,
+ *     opaque=0x555556c29060, errp=0x5555565547f8 <error_abort>) at ../block.c:3159
+ * #3  0x0000555555c0e94d in block_job_add_bdrv (job=job@entry=0x555556c29060, name=name@entry=0x555555e23630 "target", bs=bs@entry=0x5555567f2e30,
+ *     perm=perm@entry=0, shared_perm=shared_perm@entry=15, errp=0x5555565547f8 <error_abort>) at ../blockjob.c:238
+ * #4  0x0000555555c37cb8 in mirror_start_job (job_id=job_id@entry=0x55555710b800 "jobA", bs=bs@entry=0x555556e5ea00, creation_flags=creation_flags@entry=0,
+ *     target=target@entry=0x5555567f2e30, replaces=replaces@entry=0x0, speed=speed@entry=0, granularity=65536, buf_size=16777216,
+ *     backing_mode=MIRROR_LEAVE_BACKING_CHAIN, zero_target=false, on_source_error=BLOCKDEV_ON_ERROR_REPORT, on_target_error=BLOCKDEV_ON_ERROR_REPORT,
+ *     unmap=true, cb=0x0, opaque=0x0, driver=0x55555618f200 <commit_active_job_driver>, is_none_mode=false, base=0x5555567f2e30,
+ *     auto_complete=false, filter_node_name=0x0, is_mirror=false, copy_mode=MIRROR_COPY_MODE_BACKGROUND, errp=0x7fffffffd8e0) at ../block/mirror.c:1773
+ * #5  0x0000555555c3a941 in commit_active_start (job_id=job_id@entry=0x55555710b800 "jobA", bs=bs@entry=0x555556e5ea00, base=base@entry=0x5555567f2e30,
+ *     creation_flags=creation_flags@entry=0, speed=speed@entry=0, on_error=on_error@entry=BLOCKDEV_ON_ERROR_REPORT, filter_node_name=0x0, cb=0x0, opaque=0x0,
+ *     auto_complete=false, errp=0x7fffffffd8e0) at ../block/mirror.c:1905
+ * #6  0x0000555555bf94e2 in qmp_block_commit (has_job_id=<optimized out>, job_id=0x55555710b800 "jobA", device=<optimized out>,
+ *     has_base_node=<optimized out>, base_node=0x0, has_base=<optimized out>, base=0x0, has_top_node=false, top_node=0x0, has_top=false, top=0x0,
+ *     has_backing_file=false, backing_file=0x0, has_speed=false, speed=0, has_on_error=false, on_error=BLOCKDEV_ON_ERROR_REPORT, has_filter_node_name=false,
+ *     filter_node_name=0x0, has_auto_finalize=false, auto_finalize=false, has_auto_dismiss=false, auto_dismiss=false, errp=0x7fffffffd9e8) at ../blockdev.c:2769
+ * #7  0x0000555555cc1f07 in qmp_marshal_block_commit (args=<optimized out>, ret=<optimized out>, errp=0x7ffff7fcbea0) at qapi/qapi-commands-block-core.c:409
+ * #8  0x0000555555d232e9 in do_qmp_dispatch_bh (opaque=0x7ffff7fcbeb0) at ../qapi/qmp-dispatch.c:128
+ * #9  0x0000555555d3fea4 in aio_bh_call (bh=0x555556dbd4d0) at ../util/async.c:178
+ * #10 aio_bh_poll (ctx=ctx@entry=0x5555565cac80) at ../util/async.c:178
+ * #11 0x0000555555d2cb3e in aio_dispatch (ctx=0x5555565cac80) at ../util/aio-posix.c:421
+ * #12 0x0000555555d3fb0e in aio_ctx_dispatch (source=<optimized out>, callback=<optimized out>, user_data=<optimized out>) at ../util/async.c:320
+ * #13 0x00007ffff6c40119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #14 0x0000555555d4bdc0 in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #15 os_host_main_loop_wait (timeout=0) at ../util/main-loop.c:320
+ * #16 main_loop_wait (nonblocking=nonblocking@entry=0) at ../util/main-loop.c:596
+ * #17 0x00005555559d1181 in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #18 0x0000555555825f5c in qemu_main (argc=<optimized out>, argv=<optimized out>, envp=<optimized out>) at ../softmmu/main.c:38
+ * #19 0x00007ffff501d555 in __libc_start_main () at /lib64/libc.so.6
+ * #20 0x0000555555825e8a in _start () at ../softmmu/main.c:47
+ *
+ * (gdb) bt
+ * #0  bdrv_replace_child_noperm (childp=0x7fffffffd9f8, new_bs=0x0, free_empty_child=true) at ../block.c:2843
+ * #1  0x0000555555c063c7 in bdrv_detach_child (childp=0x7fffffffd9f8) at ../block.c:3118
+ * #2  bdrv_root_unref_child (child=<optimized out>) at ../block.c:3230
+ * #3  0x0000555555c06661 in bdrv_unref_child (child=0x555556b87ad0, parent=0x555556e5ea00) at ../block.c:3309
+ * #4  bdrv_close (bs=0x555556e5ea00) at ../block.c:4940
+ * #5  bdrv_delete (bs=0x555556e5ea00) at ../block.c:5404
+ * #6  bdrv_unref (bs=0x555556e5ea00) at ../block.c:6919
+ * #7  0x0000555555c37150 in mirror_exit_common (job=0x555556c29060) at ../block/mirror.c:781
+ * #8  0x0000555555c1103e in job_prepare (job=0x555556c29060) at ../job.c:837
+ * #9  job_txn_apply (fn=<optimized out>, job=0x555556c29060) at ../job.c:158
+ * #10 job_do_finalize (job=0x555556c29060) at ../job.c:854
+ * #11 0x0000555555c11522 in job_exit (opaque=0x555556c29060) at ../job.c:941
+ * #12 0x0000555555d3fea4 in aio_bh_call (bh=0x555557085390) at ../util/async.c:178
+ * #13 aio_bh_poll (ctx=ctx@entry=0x5555565cac80) at ../util/async.c:178
+ * #14 0x0000555555d2cb3e in aio_dispatch (ctx=0x5555565cac80) at ../util/aio-posix.c:421
+ * #15 0x0000555555d3fb0e in aio_ctx_dispatch (source=<optimized out>, callback=<optimized out>, user_data=<optimized out>) at ../util/async.c:320
+ * #16 0x00007ffff6c40119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #17 0x0000555555d4bdc0 in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #18 os_host_main_loop_wait (timeout=0) at ../util/main-loop.c:320
+ * #19 main_loop_wait (nonblocking=nonblocking@entry=0) at ../util/main-loop.c:596
+ * #20 0x00005555559d1181 in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #21 0x0000555555825f5c in qemu_main (argc=<optimized out>, argv=<optimized out>, envp=<optimized out>) at ../softmmu/main.c:38
+ * #22 0x00007ffff501d555 in __libc_start_main () at /lib64/libc.so.6
+ * #23 0x0000555555825e8a in _start () at ../softmmu/main.c:47
+ *
+ * called by:
+ *   - block.c|2384| <<bdrv_replace_child_abort>> bdrv_replace_child_noperm(&s->child, s->old_bs, true);
+ *   - block.c|2448| <<bdrv_replace_child_tran>> bdrv_replace_child_noperm(childp, new_bs, false);
+ *   - block.c|2959| <<bdrv_attach_child_common_abort>> bdrv_replace_child_noperm(s->child, NULL, false);
+ *   - block.c|3059| <<bdrv_attach_child_common>> bdrv_replace_child_noperm(&new_child, child_bs, true);
+ *   - block.c|3227| <<bdrv_detach_child>> bdrv_replace_child_noperm(childp, NULL, true);
+ *
+ * 核心思想是把BdrvChild->bs = new_bs;
+ */
 static void bdrv_replace_child_noperm(BdrvChild **childp,
                                       BlockDriverState *new_bs,
                                       bool free_empty_child)
@@ -2876,6 +3012,9 @@ static void bdrv_replace_child_noperm(BdrvChild **childp,
         QLIST_REMOVE(child, next_parent);
     }
 
+    /*
+     * 核心的一行
+     */
     child->bs = new_bs;
     if (!new_bs) {
         *childp = NULL;
@@ -2938,6 +3077,9 @@ typedef struct BdrvAttachChildCommonState {
     AioContext *old_child_ctx;
 } BdrvAttachChildCommonState;
 
+/*
+ * TransactionActionDrv bdrv_attach_child_common_drv.abort = bdrv_attach_child_common_abort()
+ */
 static void bdrv_attach_child_common_abort(void *opaque)
 {
     BdrvAttachChildCommonState *s = opaque;
@@ -2976,6 +3118,10 @@ static void bdrv_attach_child_common_abort(void *opaque)
     bdrv_child_free(child);
 }
 
+/*
+ * 在以下使用bdrv_attach_child_common_drv:
+ *   - block.c|3179| <<bdrv_attach_child_common>> tran_add(tran, &bdrv_attach_child_common_drv, s);
+ */
 static TransactionActionDrv bdrv_attach_child_common_drv = {
     .abort = bdrv_attach_child_common_abort,
     .clean = g_free,
@@ -2992,6 +3138,15 @@ static TransactionActionDrv bdrv_attach_child_common_drv = {
  *
  * Function doesn't update permissions, caller is responsible for this.
  */
+/*
+ * called by:
+ *   - block.c|3320| <<bdrv_attach_child_noperm>> ret = bdrv_attach_child_common(child_bs, child_name, child_class,
+ *   - block.c|3382| <<bdrv_root_attach_child>> ret = bdrv_attach_child_common(child_bs, child_name, child_class,
+ *
+ * 返回的结果是倒数第三个参数
+ * 核心思想是分配新的BdrvChild, 设置BdrvChild->bs=child_bs,
+ * 作为倒数第三个参数返回
+ */
 static int bdrv_attach_child_common(BlockDriverState *child_bs,
                                     const char *child_name,
                                     const BdrvChildClass *child_class,
@@ -3052,6 +3207,9 @@ static int bdrv_attach_child_common(BlockDriverState *child_bs,
     }
 
     bdrv_ref(child_bs);
+    /*
+     * 核心思想是把new_child->bs = child_bs;
+     */
     bdrv_replace_child_noperm(&new_child, child_bs, true);
     /* child_bs was non-NULL, so new_child must not have been freed */
     assert(new_child != NULL);
@@ -3075,6 +3233,111 @@ static int bdrv_attach_child_common(BlockDriverState *child_bs,
  *
  * Function doesn't update permissions, caller is responsible for this.
  */
+/*
+ * main thread
+ * (gdb) bt
+ * #0  bdrv_attach_child_noperm (parent_bs=0x55f93d710410, child_bs=0x55f93c9d4cb0, child_name=0x55f93b201894 "file", child_class=0x55f93b518d80 <child_of_bds>, child_role=19
+ * #1  0x000055f93ae88dc5 in bdrv_attach_child (parent_bs=0x55f93d710410, child_bs=0x55f93c9d4cb0, child_name=0x55f93b201894 "file"
+ * #2  0x000055f93ae89ccd in bdrv_open_child (filename=0x0, options=0x55f93d0f3400, bdref_key=0x55f93b201894 "file", parent=0x55f93d710410,
+ * #3  0x000055f93aef6428 in qcow2_open (bs=0x55f93d710410, options=0x55f93d0f3400, flags=8710, errp=0x7fb60a977aa0) at ../block/qcow2.c:1897
+ * #4  0x000055f93ae85919 in bdrv_open_driver (bs=0x55f93d710410, drv=0x55f93b899080 <bdrv_qcow2>, node_name=0x0, options=0x55f93d0f3400, open_flags=8710, errp=0x7fb60a977bb0) at ../block.c:1627
+ * #5  0x000055f93ae8636b in bdrv_open_common (bs=0x55f93d710410, file=0x55f93d04ce00, options=0x55f93d0f3400, errp=0x7fb60a977bb0) at ../block.c:1923
+ * #6  0x000055f93ae8aa35 in bdrv_open_inherit (filename=0x0, reference=0x0, options=0x55f93d0f3400, flags=8710, parent=0x0, child_class=0x0, child_role=0, errp=0x7fb60a977f38) at ../block.c:3992
+ * #7  0x000055f93ae8af9d in bdrv_open (filename=0x0, reference=0x0, options=0x55f93ce12200, flags=518, errp=0x7fb60a977f38) at ../block.c:4087
+ * #8  0x000055f93aeaff6b in blk_new_open (filename=0x0, reference=0x0, options=0x55f93ce12200, flags=518, errp=0x7fb60a977f38) at ../block/block-backend.c:454
+ * #9  0x000055f93aefa6ef in qcow2_co_create (create_options=0x55f93d1db260, errp=0x7fb60a977f38) at ../block/qcow2.c:3701
+ * #10 0x000055f93aefaef1 in qcow2_co_create_opts (drv=0x55f93b899080 <bdrv_qcow2>, filename=0x55f93d0ea620 "/tmp/overlay01.qcow2", opts=0x55f93d3b7ae0, errp=0x7fb60a977f38) at ../block/qcow2.c:3916
+ * #11 0x000055f93ae8339b in bdrv_create_co_entry (opaque=0x7ffdc69cca60) at ../block.c:534
+ * #12 0x000055f93b023abd in coroutine_trampoline (i0=1024266240, i1=22009) at ../util/coroutine-ucontext.c:177
+ * #13 0x00007fb610f44190 in __start_context () at /lib64/libc.so.6
+ * #14 0x00007ffdc69cc280 in  ()
+ * #15 0x0000000000000000 in  ()
+ *
+ * (gdb) bt
+ * #0  bdrv_attach_child_noperm (parent_bs=0x55f93c9d4cb0, child_bs=0x55f93d710410, child_name=0x55f93b201894 "file",
+ * #1  0x000055f93ae88dc5 in bdrv_attach_child (parent_bs=0x55f93c9d4cb0, child_bs=0x55f93d710410, child_name=0x55f93b201894 "file"
+ * #2  0x000055f93ae89ccd in bdrv_open_child (filename=0x0, options=0x55f93d124d50, bdref_key=0x55f93b201894 "file", parent=0x55f93c9d4cb0
+ * #3  0x000055f93aef6428 in qcow2_open (bs=0x55f93c9d4cb0, options=0x55f93d124d50, flags=8226, errp=0x7ffdc69cc930) at ../block/qcow2.c:1897
+ * #4  0x000055f93ae85919 in bdrv_open_driver (bs=0x55f93c9d4cb0, drv=0x55f93b899080 <bdrv_qcow2>, node_name=0x55f93c951970 "over01", options=0x55f93d124d50, open_flags=8226, errp=0x7ffdc69cca40)
+ * #5  0x000055f93ae8636b in bdrv_open_common (bs=0x55f93c9d4cb0, file=0x55f93d24fc20, options=0x55f93d124d50, errp=0x7ffdc69cca40) at ../block.c:1923
+ * #6  0x000055f93ae8aa35 in bdrv_open_inherit (filename=0x55f93d124cf0 "/tmp/overlay01.qcow2", reference=0x0, options=0x55f93d124d50, flags=8482, parent=0x0, child_class=0x0,
+ * #7  0x000055f93ae8af9d in bdrv_open (filename=0x55f93d124cf0 "/tmp/overlay01.qcow2", reference=0x0, options=0x55f93d24ec00, flags=8482, errp=0x7ffdc69ccc78) at ../block.c:4087
+ * #8  0x000055f93ae77b92 in external_snapshot_prepare (common=0x55f93d04f320, errp=0x7ffdc69ccc78) at ../blockdev.c:1535
+ * #9  0x000055f93ae79583 in qmp_transaction (dev_list=0x7ffdc69cccf0, has_props=false, props=0x55f93c932010, errp=0x7ffdc69cce48) at ../blockdev.c:2358
+ * #10 0x000055f93ae7697e in blockdev_do_action (action=0x7ffdc69ccd70, errp=0x7ffdc69cce48) at ../blockdev.c:1042
+ * #11 0x000055f93ae76a9a in qmp_blockdev_snapshot_sync (has_device=false, device=0x0, has_node_name=true, node_name=0x55f93d0ae920 "drive01",
+ *     snapshot_file=0x55f93d124cf0 "/tmp/overlay01.qcow2", has_snapshot_node_name=true, snapshot_node_name=0x55f93d3b9fc0 "over01", has_format=false, format=0x0,
+ *     has_mode=false, mode=NEW_IMAGE_MODE_EXISTING, errp=0x7ffdc69cce48) at ../blockdev.c:1070
+ * #12 0x000055f93af8345a in qmp_marshal_blockdev_snapshot_sync (args=0x7fb600003ad0, ret=0x7fb613cb5d98, errp=0x7fb613cb5d90) at qapi/qapi-commands-block-core.c:280
+ * #13 0x000055f93affb4fb in do_qmp_dispatch_bh (opaque=0x7fb613cb5e30) at ../qapi/qmp-dispatch.c:128
+ * #14 0x000055f93b020dcc in aio_bh_call (bh=0x55f93d1140f0) at ../util/async.c:150
+ * #15 0x000055f93b020ed6 in aio_bh_poll (ctx=0x55f93c71fd40) at ../util/async.c:178
+ * #16 0x000055f93b00816b in aio_dispatch (ctx=0x55f93c71fd40) at ../util/aio-posix.c:421
+ * #17 0x000055f93b021307 in aio_ctx_dispatch (source=0x55f93c71fd40, callback=0x0, user_data=0x0) at ../util/async.c:320
+ * #18 0x00007fb612923119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #19 0x000055f93b033010 in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #20 0x000055f93b03308a in os_host_main_loop_wait (timeout=0) at ../util/main-loop.c:320
+ * #21 0x000055f93b03318f in main_loop_wait (nonblocking=0) at ../util/main-loop.c:596
+ * #22 0x000055f93ab9b05e in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #23 0x000055f93a940e62 in qemu_main (argc=32, argv=0x7ffdc69cd2b8, envp=0x0) at ../softmmu/main.c:38
+ * #24 0x000055f93a940e94 in main (argc=32, argv=0x7ffdc69cd2b8) at ../softmmu/main.c:47
+ *
+ * (gdb) bt
+ * #0  bdrv_attach_child_noperm (parent_bs=0x55f93c9d4cb0, child_bs=0x55f93c9495d0, child_name=0x55f93b1e8ff0 "backing", child_class=0x55f93b518d80 <child_of_bds>, child_role=8
+ * #1  0x000055f93ae8dc6a in bdrv_append (bs_new=0x55f93c9d4cb0, bs_top=0x55f93c9495d0, errp=0x7ffdc69ccc78) at ../block.c:5336
+ * #2  0x000055f93ae77d06 in external_snapshot_prepare (common=0x55f93d04f320, errp=0x7ffdc69ccc78) at ../blockdev.c:1568
+ * #3  0x000055f93ae79583 in qmp_transaction (dev_list=0x7ffdc69cccf0, has_props=false, props=0x55f93c932010, errp=0x7ffdc69cce48) at ../blockdev.c:2358
+ * #4  0x000055f93ae7697e in blockdev_do_action (action=0x7ffdc69ccd70, errp=0x7ffdc69cce48) at ../blockdev.c:1042
+ * #5  0x000055f93ae76a9a in qmp_blockdev_snapshot_sync (has_device=false, device=0x0, has_node_name=true, node_name=0x55f93d0ae920 "drive01",
+ *     snapshot_file=0x55f93d124cf0 "/tmp/overlay01.qcow2", has_snapshot_node_name=true, snapshot_node_name=0x55f93d3b9fc0 "over01", has_format=false, format=0x0,
+ *     has_mode=false, mode=NEW_IMAGE_MODE_EXISTING, errp=0x7ffdc69cce48) at ../blockdev.c:1070
+ * #6  0x000055f93af8345a in qmp_marshal_blockdev_snapshot_sync (args=0x7fb600003ad0, ret=0x7fb613cb5d98, errp=0x7fb613cb5d90) at qapi/qapi-commands-block-core.c:280
+ * #7  0x000055f93affb4fb in do_qmp_dispatch_bh (opaque=0x7fb613cb5e30) at ../qapi/qmp-dispatch.c:128
+ * #8  0x000055f93b020dcc in aio_bh_call (bh=0x55f93d1140f0) at ../util/async.c:150
+ * #9  0x000055f93b020ed6 in aio_bh_poll (ctx=0x55f93c71fd40) at ../util/async.c:178
+ * #10 0x000055f93b00816b in aio_dispatch (ctx=0x55f93c71fd40) at ../util/aio-posix.c:421
+ * #11 0x000055f93b021307 in aio_ctx_dispatch (source=0x55f93c71fd40, callback=0x0, user_data=0x0) at ../util/async.c:320
+ * #12 0x00007fb612923119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #13 0x000055f93b033010 in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #14 0x000055f93b03308a in os_host_main_loop_wait (timeout=0) at ../util/main-loop.c:320
+ * #15 0x000055f93b03318f in main_loop_wait (nonblocking=0) at ../util/main-loop.c:596
+ * #16 0x000055f93ab9b05e in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #17 0x000055f93a940e62 in qemu_main (argc=32, argv=0x7ffdc69cd2b8, envp=0x0) at ../softmmu/main.c:38
+ * #18 0x000055f93a940e94 in main (argc=32, argv=0x7ffdc69cd2b8) at ../softmmu/main.c:47
+ *
+ * (gdb) bt
+ * #0  bdrv_attach_child_noperm (parent_bs=0x55f93d480410, child_bs=0x55f93c9d4cb0, child_name=0x55f93b1e8ff0 "backing", child_class=0x55f93b518d80 <child_of_bds>, child_role=20,
+ * #1  0x000055f93ae8dc6a in bdrv_append (bs_new=0x55f93d480410, bs_top=0x55f93c9d4cb0, errp=0x7ffdc69ccc90) at ../block.c:5336
+ * #2  0x000055f93aece199 in mirror_start_job (job_id=0x55f93d3b9fc0 "jobA", bs=0x55f93c9d4cb0, creation_flags=0, target=0x55f93c9495d0,
+ *     replaces=0x0, speed=0, granularity=65536, buf_size=16777216, backing_mode=MIRROR_LEAVE_BACKING_CHAIN, zero_target=false,
+ *     on_source_error=BLOCKDEV_ON_ERROR_REPORT, on_target_error=BLOCKDEV_ON_ERROR_REPORT, unmap=true, cb=0x0, opaque=0x0,
+ *     driver=0x55f93b525480 <commit_active_job_driver>, is_none_mode=false, base=0x55f93c9495d0, auto_complete=false, filter_node_name=0x0,
+ *     is_mirror=false, copy_mode=MIRROR_COPY_MODE_BACKGROUND, errp=0x7ffdc69ccc90) at ../block/mirror.c:1655
+ * #3  0x000055f93aecea50 in commit_active_start (job_id=0x55f93d3b9fc0 "jobA", bs=0x55f93c9d4cb0, base=0x55f93c9495d0, creation_flags=0, speed=0,
+ *     on_error=BLOCKDEV_ON_ERROR_REPORT, filter_node_name=0x0, cb=0x0, opaque=0x0, auto_complete=false, errp=0x7ffdc69ccc90) at ../block/mirror.c:1905
+ * #4  0x000055f93ae7a82c in qmp_block_commit (has_job_id=true, job_id=0x55f93d3b9fc0 "jobA", device=0x55f93d0ae920 "over01", has_base_node=false,
+ *     base_node=0x0, has_base=false, base=0x0, has_top_node=false, top_node=0x0, has_top=false, top=0x0, has_backing_file=false, backing_file=0x0,
+ *     has_speed=false, speed=0, has_on_error=false, on_error=BLOCKDEV_ON_ERROR_REPORT, has_filter_node_name=false, filter_node_name=0x0,
+ *     has_auto_finalize=false, auto_finalize=false, has_auto_dismiss=false, auto_dismiss=false, errp=0x7ffdc69ccdf8) at ../blockdev.c:2769
+ * #5  0x000055f93af83ce0 in qmp_marshal_block_commit (args=0x7fb600003a70, ret=0x7fb613cb5d98, errp=0x7fb613cb5d90) at qapi/qapi-commands-block-core.c:409
+ * #6  0x000055f93affb4fb in do_qmp_dispatch_bh (opaque=0x7fb613cb5e30) at ../qapi/qmp-dispatch.c:128
+ * #7  0x000055f93b020dcc in aio_bh_call (bh=0x55f93d1140f0) at ../util/async.c:150
+ * #8  0x000055f93b020ed6 in aio_bh_poll (ctx=0x55f93c71fd40) at ../util/async.c:178
+ * #9  0x000055f93b00816b in aio_dispatch (ctx=0x55f93c71fd40) at ../util/aio-posix.c:421
+ * #10 0x000055f93b021307 in aio_ctx_dispatch (source=0x55f93c71fd40, callback=0x0, user_data=0x0) at ../util/async.c:320
+ * #11 0x00007fb612923119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #12 0x000055f93b033010 in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #13 0x000055f93b03308a in os_host_main_loop_wait (timeout=0) at ../util/main-loop.c:320
+ * #14 0x000055f93b03318f in main_loop_wait (nonblocking=0) at ../util/main-loop.c:596
+ * #15 0x000055f93ab9b05e in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #16 0x000055f93a940e62 in qemu_main (argc=32, argv=0x7ffdc69cd2b8, envp=0x0) at ../softmmu/main.c:38
+ * #17 0x000055f93a940e94 in main (argc=32, argv=0x7ffdc69cd2b8) at ../softmmu/main.c:47
+ *
+ * called by:
+ *   - block.c|3207| <<bdrv_attach_child>> ret = bdrv_attach_child_noperm(parent_bs, child_bs, child_name, child_class,
+ *   - block.c|3425| <<bdrv_set_file_or_backing_noperm>> ret = bdrv_attach_child_noperm(parent_bs, child_bs,
+ *   - block.c|5342| <<bdrv_append>> ret = bdrv_attach_child_noperm(bs_new, bs_top, "backing",
+ */
 static int bdrv_attach_child_noperm(BlockDriverState *parent_bs,
                                     BlockDriverState *child_bs,
                                     const char *child_name,
@@ -3100,6 +3363,15 @@ static int bdrv_attach_child_noperm(BlockDriverState *parent_bs,
     bdrv_child_perm(parent_bs, child_bs, NULL, child_role, NULL,
                     perm, shared_perm, &perm, &shared_perm);
 
+    /*
+     * called by:
+     *   - block.c|3320| <<bdrv_attach_child_noperm>> ret = bdrv_attach_child_common(child_bs, child_name, child_class,
+     *   - block.c|3382| <<bdrv_root_attach_child>> ret = bdrv_attach_child_common(child_bs, child_name, child_class,
+     *
+     * 返回的结果是倒数第三个参数
+     * 核心思想是分配新的BdrvChild, 设置BdrvChild->bs=child_bs,
+     * 作为倒数第三个参数返回
+     */
     ret = bdrv_attach_child_common(child_bs, child_name, child_class,
                                    child_role, perm, shared_perm, parent_bs,
                                    child, tran, errp);
@@ -3110,11 +3382,18 @@ static int bdrv_attach_child_noperm(BlockDriverState *parent_bs,
     return 0;
 }
 
+/*
+ * called by:
+ *   - block.c|3467| <<bdrv_root_unref_child>> bdrv_detach_child(&child);
+ */
 static void bdrv_detach_child(BdrvChild **childp)
 {
     BlockDriverState *old_bs = (*childp)->bs;
 
     GLOBAL_STATE_CODE();
+    /*
+     * 核心思想是把BdrvChild->bs = new_bs (NULL);
+     */
     bdrv_replace_child_noperm(childp, NULL, true);
 
     if (old_bs) {
@@ -3143,6 +3422,12 @@ static void bdrv_detach_child(BdrvChild **childp)
  * The caller must hold the AioContext lock @child_bs, but not that of @ctx
  * (unless @child_bs is already in @ctx).
  */
+/*
+ * called by:
+ *   - block/block-backend.c|460| <<blk_new_open>> blk->root = bdrv_root_attach_child(bs, "root", &child_root,
+ *   - block/block-backend.c|907| <<blk_insert_bs>> blk->root = bdrv_root_attach_child(bs, "root", &child_root,
+ *   - blockjob.c|280| <<block_job_add_bdrv>> c = bdrv_root_attach_child(bs, name, &child_job, 0, perm, shared_perm, job,
+ */
 BdrvChild *bdrv_root_attach_child(BlockDriverState *child_bs,
                                   const char *child_name,
                                   const BdrvChildClass *child_class,
@@ -3156,6 +3441,11 @@ BdrvChild *bdrv_root_attach_child(BlockDriverState *child_bs,
 
     GLOBAL_STATE_CODE();
 
+    /*
+     * 返回的结果是倒数第三个参数
+     * 核心思想是分配新的BdrvChild, 设置BdrvChild->bs=child_bs,
+     * 作为倒数第三个参数返回
+     */
     ret = bdrv_attach_child_common(child_bs, child_name, child_class,
                                    child_role, perm, shared_perm, opaque,
                                    &child, tran, errp);
@@ -3185,6 +3475,13 @@ out:
  * If @parent_bs and @child_bs are in different AioContexts, the caller must
  * hold the AioContext lock for @child_bs, but not for @parent_bs.
  */
+/*
+ * 除了unit test的调用:
+ *   - block.c|3932| <<bdrv_open_child>> return bdrv_attach_child(parent, bs, bdref_key, child_class, child_role,
+ *   - block/quorum.c|1086| <<quorum_add_child>> child = bdrv_attach_child(bs, child_bs, indexstr, &child_of_bds,
+ *   - block/replication.c|556| <<replication_start>> s->hidden_disk = bdrv_attach_child(bs, hidden_disk->bs, "hidden disk",
+ *   - block/replication.c|566| <<replication_start>> s->secondary_disk = bdrv_attach_child(bs, secondary_disk->bs,
+ */
 BdrvChild *bdrv_attach_child(BlockDriverState *parent_bs,
                              BlockDriverState *child_bs,
                              const char *child_name,
@@ -3220,6 +3517,12 @@ out:
 }
 
 /* Callers must ensure that child->frozen is false. */
+/*
+ * called by:
+ *   - block.c|3574| <<bdrv_unref_child>> bdrv_root_unref_child(child); 
+ *   - block/block-backend.c|900| <<blk_remove_bs>> bdrv_root_unref_child(root);
+ *   - blockjob.c|203| <<block_job_remove_all_bdrv>> bdrv_root_unref_child(c);
+ */
 void bdrv_root_unref_child(BdrvChild *child)
 {
     BlockDriverState *child_bs;
@@ -4378,6 +4681,12 @@ void bdrv_reopen_queue_free(BlockReopenQueue *bs_queue)
  *
  * To be called from the main thread, with all other AioContexts unlocked.
  */
+/*
+ * called by:
+ *   - block.c|4785| <<bdrv_reopen>> ret = bdrv_reopen_multiple(queue, errp);
+ *   - block/replication.c|401| <<reopen_backing_file>> bdrv_reopen_multiple(reopen_queue, errp);
+ *   - blockdev.c|3690| <<qmp_blockdev_reopen>> bdrv_reopen_multiple(queue, errp);
+ */
 int bdrv_reopen_multiple(BlockReopenQueue *bs_queue, Error **errp)
 {
     int ret = -1;
@@ -4489,6 +4798,11 @@ cleanup:
     return ret;
 }
 
+/*
+ * called by:
+ *   - block.c|4804| <<bdrv_reopen_set_read_only>> return bdrv_reopen(bs, opts, true, errp);
+ *   - qemu-io-cmds.c|2212| <<reopen_f>> bdrv_reopen(bs, opts, true, &local_err);
+ */
 int bdrv_reopen(BlockDriverState *bs, QDict *opts, bool keep_old_opts,
                 Error **errp)
 {
@@ -5185,6 +5499,11 @@ static int bdrv_replace_node_noperm(BlockDriverState *from,
     assert(to != NULL);
     GLOBAL_STATE_CODE();
 
+    /*
+     * BlockDriverState *from:
+     * -> QLIST_HEAD(, BdrvChild) children;
+     * -> QLIST_HEAD(, BdrvChild) parents;
+     */
     QLIST_FOREACH_SAFE(c, &from->parents, next_parent, next) {
         assert(c->bs == from);
         if (!should_update_child(c, to)) {
@@ -5323,6 +5642,17 @@ int bdrv_drop_filter(BlockDriverState *bs, Error **errp)
  *
  * This function does not create any image files.
  */
+/*
+ * called by:
+ *   - block.c|3991| <<bdrv_append_temp_snapshot>> ret = bdrv_append(bs_snapshot, bs, errp);
+ *   - block/commit.c|321| <<commit_start>> ret = bdrv_append(commit_top_bs, top, errp);
+ *   - block/mirror.c|1709| <<mirror_start_job>> ret = bdrv_append(mirror_top_bs, bs, errp);
+ *   - blockdev.c|1645| <<external_snapshot_prepare>> ret = bdrv_append(state->new_bs, state->old_bs, errp);
+ *   - tests/unit/test-bdrv-drain.c|1486| <<test_append_to_drained>> bdrv_append(overlay, base, &error_abort);
+ *   - tests/unit/test-bdrv-graph-mod.c|139| <<test_update_perm_tree>> ret = bdrv_append(filter, bs, NULL);
+ *   - tests/unit/test-bdrv-graph-mod.c|204| <<test_should_update_child>> bdrv_append(filter, bs, &error_abort);
+ *   - tests/unit/test-bdrv-graph-mod.c|385| <<test_append_greedy_filter>> bdrv_append(fl, base, &error_abort);
+ */
 int bdrv_append(BlockDriverState *bs_new, BlockDriverState *bs_top,
                 Error **errp)
 {
@@ -5495,6 +5825,19 @@ int coroutine_fn bdrv_co_check(BlockDriverState *bs,
  *            image file header
  * -ENOTSUP - format driver doesn't support changing the backing file
  */
+/*
+ * (gdb) bt
+ * #0  bdrv_change_backing_file
+ *     (bs=0x555556e21600, backing_file=backing_file@entry=0x555557203870 "test01.qcow2", backing_fmt=backing_fmt@entry=0x555555eb56c9 "qcow2", require=require@entry=false)
+ *     at ../block.c:5501
+ * #1  0x0000555555c57dbc in qcow2_co_create (create_options=0x555556b4c0f0, errp=errp@entry=0x7ffe3e9b7fa0) at ../block/qcow2.c:3749
+ * #2  0x0000555555c585e2 in qcow2_co_create_opts (drv=<optimized out>, filename=<optimized out>, opts=<optimized out>, errp=0x7ffe3e9b7fa0) at ../block/qcow2.c:3916
+ * #3  0x0000555555bff227 in bdrv_create_co_entry (opaque=0x7fffffffd740) at ../block.c:534
+ * #4  0x0000555555d41c2b in coroutine_trampoline (i0=<optimized out>, i1=<optimized out>) at ../util/coroutine-ucontext.c:177
+ * #5  0x00007ffff5043190 in __start_context () at /lib64/libc.so.6
+ * #6  0x00007ffe5fdfdac0 in  ()
+ * #7  0x0000000000000000 in  ()
+ */
 int bdrv_change_backing_file(BlockDriverState *bs, const char *backing_file,
                              const char *backing_fmt, bool require)
 {
diff --git a/block/accounting.c b/block/accounting.c
index 2030851d7..965ea1c08 100644
--- a/block/accounting.c
+++ b/block/accounting.c
@@ -223,6 +223,40 @@ static void block_account_one_io(BlockAcctStats *stats, BlockAcctCookie *cookie,
     cookie->type = BLOCK_ACCT_NONE;
 }
 
+/*
+ * called by:
+ *   - hw/block/dataplane/xen-block.c|304| <<xen_block_complete_aio>> block_acct_done(blk_get_stats(dataplane->blk), &request->acct);
+ *   - hw/block/virtio-blk.c|154| <<virtio_blk_rw_complete>> block_acct_done(blk_get_stats(s->blk), &req->acct);
+ *   - hw/block/virtio-blk.c|173| <<virtio_blk_flush_complete>> block_acct_done(blk_get_stats(s->blk), &req->acct);
+ *   - hw/block/virtio-blk.c|196| <<virtio_blk_discard_write_zeroes_complete>> block_acct_done(blk_get_stats(s->blk), &req->acct);
+ *   - hw/ide/ahci.c|1019| <<ncq_finish>> block_acct_done(blk_get_stats(ncq_tfs->drive->port.ifs[0].blk),
+ *   - hw/ide/atapi.c|118| <<cd_read_sector_sync>> block_acct_done(blk_get_stats(s->blk), &s->acct);
+ *   - hw/ide/atapi.c|138| <<cd_read_sector_cb>> block_acct_done(blk_get_stats(s->blk), &s->acct);
+ *   - hw/ide/atapi.c|415| <<ide_atapi_cmd_read_dma_cb>> block_acct_done(blk_get_stats(s->blk), &s->acct);
+ *   - hw/ide/core.c|457| <<ide_issue_trim_cb>> block_acct_done(blk_get_stats(s->blk), &s->acct);
+ *   - hw/ide/core.c|764| <<ide_sector_read_cb>> block_acct_done(blk_get_stats(s->blk), &s->acct);
+ *   - hw/ide/core.c|968| <<ide_dma_cb>> block_acct_done(blk_get_stats(s->blk), &s->acct);
+ *   - hw/ide/core.c|1026| <<ide_sector_write_cb>> block_acct_done(blk_get_stats(s->blk), &s->acct);
+ *   - hw/ide/core.c|1104| <<ide_flush_cb>> block_acct_done(blk_get_stats(s->blk), &s->acct);
+ *   - hw/ide/macio.c|128| <<pmac_ide_atapi_transfer_cb>> block_acct_done(blk_get_stats(s->blk), &s->acct);
+ *   - hw/ide/macio.c|212| <<pmac_ide_transfer_cb>> block_acct_done(blk_get_stats(s->blk), &s->acct);
+ *   - hw/nvme/ctrl.c|2025| <<nvme_rw_complete_cb>> block_acct_done(stats, acct);
+ *   - hw/nvme/ctrl.c|2112| <<nvme_verify_cb>> block_acct_done(stats, acct);
+ *   - hw/nvme/ctrl.c|2258| <<nvme_compare_mdata_cb>> block_acct_done(stats, acct);
+ *   - hw/nvme/ctrl.c|2324| <<nvme_compare_data_cb>> block_acct_done(stats, acct);
+ *   - hw/nvme/ctrl.c|2638| <<nvme_copy_bh>> block_acct_done(stats, &iocb->acct.read);
+ *   - hw/nvme/ctrl.c|2639| <<nvme_copy_bh>> block_acct_done(stats, &iocb->acct.write);
+ *   - hw/scsi/scsi-disk.c|283| <<scsi_aio_complete>> block_acct_done(blk_get_stats(s->qdev.conf.blk), &r->acct);
+ *   - hw/scsi/scsi-disk.c|367| <<scsi_dma_complete>> block_acct_done(blk_get_stats(s->qdev.conf.blk), &r->acct);
+ *   - hw/scsi/scsi-disk.c|403| <<scsi_read_complete>> block_acct_done(blk_get_stats(s->qdev.conf.blk), &r->acct);
+ *   - hw/scsi/scsi-disk.c|456| <<scsi_do_read_cb>> block_acct_done(blk_get_stats(s->qdev.conf.blk), &r->acct);
+ *   - hw/scsi/scsi-disk.c|540| <<scsi_write_complete>> block_acct_done(blk_get_stats(s->qdev.conf.blk), &r->acct);
+ *   - hw/scsi/scsi-disk.c|1748| <<scsi_unmap_complete>> block_acct_done(blk_get_stats(s->qdev.conf.blk), &r->acct);
+ *   - hw/scsi/scsi-disk.c|1826| <<scsi_write_same_complete>> block_acct_done(blk_get_stats(s->qdev.conf.blk), &r->acct);
+ *   - qemu-io-cmds.c|1374| <<aio_write_done>> block_acct_done(blk_get_stats(ctx->blk), &ctx->acct);
+ *   - qemu-io-cmds.c|1416| <<aio_read_done>> block_acct_done(blk_get_stats(ctx->blk), &ctx->acct);
+ *   - qemu-io-cmds.c|1693| <<aio_flush_f>> block_acct_done(blk_get_stats(blk), &cookie);
+ */
 void block_acct_done(BlockAcctStats *stats, BlockAcctCookie *cookie)
 {
     block_account_one_io(stats, cookie, false);
diff --git a/block/aio_task.c b/block/aio_task.c
index 9bd17ea2c..17f8254e6 100644
--- a/block/aio_task.c
+++ b/block/aio_task.c
@@ -30,10 +30,34 @@ struct AioTaskPool {
     Coroutine *main_co;
     int status;
     int max_busy_tasks;
+    /*
+     * 在以下使用AioTaskPool->busy_tasks:
+     *   - block/aio_task.c|55| <<aio_task_co>> assert(pool->busy_tasks < pool->max_busy_tasks);
+     *   - block/aio_task.c|56| <<aio_task_co>> pool->busy_tasks++;
+     *   - block/aio_task.c|60| <<aio_task_co>> pool->busy_tasks--;
+     *   - block/aio_task.c|76| <<aio_task_pool_wait_one>> assert(pool->busy_tasks > 0);
+     *   - block/aio_task.c|83| <<aio_task_pool_wait_one>> assert(pool->busy_tasks < pool->max_busy_tasks);
+     *   - block/aio_task.c|88| <<aio_task_pool_wait_slot>> if (pool->busy_tasks < pool->max_busy_tasks) {
+     *   - block/aio_task.c|97| <<aio_task_pool_wait_all>> while (pool->busy_tasks > 0) {
+     *   - block/aio_task.c|143| <<aio_task_pool_empty>> return pool->busy_tasks == 0;
+     */
     int busy_tasks;
     bool waiting;
 };
 
+/*
+ * Thread 3 "IO iothread01" hit Breakpoint 1, aio_task_co (opaque=0x7f68a800f360) at ../block/aio_task.c:39
+ * 39	    AioTask *task = opaque;
+ * (gdb) bt
+ * #0  aio_task_co (opaque=0x7f68a800f360) at ../block/aio_task.c:39
+ * #1  0x0000561926f76ab8 in coroutine_trampoline (i0=-1476375376, i1=32616) at ../util/coroutine-ucontext.c:177
+ * #2  0x00007f68b318c190 in __start_context () at /lib64/libc.so.6
+ * #3  0x00007f68ad13acf0 in  ()
+ * #4  0x0000000000000000 in  ()
+ *
+ * 在以下使用aio_task_co():
+ *   - block/aio_task.c|94| <<aio_task_pool_start_task>> qemu_coroutine_enter(qemu_coroutine_create(aio_task_co, task));
+ */
 static void coroutine_fn aio_task_co(void *opaque)
 {
     AioTask *task = opaque;
@@ -79,13 +103,36 @@ void coroutine_fn aio_task_pool_wait_slot(AioTaskPool *pool)
     aio_task_pool_wait_one(pool);
 }
 
+/*
+ * called by:
+ *   - block/block-copy.c|790| <<block_copy_dirty_clusters>> aio_task_pool_wait_all(aio);
+ *   - block/qcow2.c|2396| <<qcow2_co_preadv_part>> aio_task_pool_wait_all(aio);
+ *   - block/qcow2.c|2699| <<qcow2_co_pwritev_part>> aio_task_pool_wait_all(aio);
+ *   - block/qcow2.c|4731| <<qcow2_co_pwritev_compressed_part>> aio_task_pool_wait_all(aio);
+ */
 void coroutine_fn aio_task_pool_wait_all(AioTaskPool *pool)
 {
+    /*
+     * 在以下使用AioTaskPool->busy_tasks:
+     *   - block/aio_task.c|55| <<aio_task_co>> assert(pool->busy_tasks < pool->max_busy_tasks);
+     *   - block/aio_task.c|56| <<aio_task_co>> pool->busy_tasks++;
+     *   - block/aio_task.c|60| <<aio_task_co>> pool->busy_tasks--;
+     *   - block/aio_task.c|76| <<aio_task_pool_wait_one>> assert(pool->busy_tasks > 0);
+     *   - block/aio_task.c|83| <<aio_task_pool_wait_one>> assert(pool->busy_tasks < pool->max_busy_tasks);
+     *   - block/aio_task.c|88| <<aio_task_pool_wait_slot>> if (pool->busy_tasks < pool->max_busy_tasks) {
+     *   - block/aio_task.c|97| <<aio_task_pool_wait_all>> while (pool->busy_tasks > 0) {
+     *   - block/aio_task.c|143| <<aio_task_pool_empty>> return pool->busy_tasks == 0;
+     */
     while (pool->busy_tasks > 0) {
         aio_task_pool_wait_one(pool);
     }
 }
 
+/*
+ * called by:
+ *   - block/block-copy.c|450| <<block_copy_task_run>> aio_task_pool_start_task(pool, &task->task);
+ *   - block/qcow2.c|2255| <<qcow2_add_task>> aio_task_pool_start_task(pool, &task->task);
+ */
 void coroutine_fn aio_task_pool_start_task(AioTaskPool *pool, AioTask *task)
 {
     aio_task_pool_wait_slot(pool);
diff --git a/block/block-backend.c b/block/block-backend.c
index d4a5df2ac..968744f67 100644
--- a/block/block-backend.c
+++ b/block/block-backend.c
@@ -45,6 +45,10 @@ typedef struct BlockBackendAioNotifier {
 struct BlockBackend {
     char *name;
     int refcnt;
+    /*
+     * 感觉BdrvChild->next挂的是file的
+     * BdrvChild->bs->children是overlay下面的原始的BdrvChild
+     */
     BdrvChild *root;
     AioContext *ctx;
     DriveInfo *legacy_dinfo;    /* null unless created by drive_new() */
@@ -110,6 +114,13 @@ static void drive_info_del(DriveInfo *dinfo);
 static BlockBackend *bdrv_first_blk(BlockDriverState *bs);
 
 /* All BlockBackends. Protected by BQL. */
+/*
+ * 在以下使用block_backends:
+ *   - block/block-backend.c|117| <<QTAILQ_HEAD>> static QTAILQ_HEAD(, BlockBackend) block_backends =
+ *   - block/block-backend.c|381| <<blk_new>> QTAILQ_INSERT_TAIL(&block_backends, blk, link);
+ *   - block/block-backend.c|493| <<blk_delete>> QTAILQ_REMOVE(&block_backends, blk, link);
+ *   - block/block-backend.c|555| <<blk_all_next>> : QTAILQ_FIRST(&block_backends);
+ */
 static QTAILQ_HEAD(, BlockBackend) block_backends =
     QTAILQ_HEAD_INITIALIZER(block_backends);
 
@@ -389,6 +400,23 @@ BlockBackend *blk_new(AioContext *ctx, uint64_t perm, uint64_t shared_perm)
  *
  * Return the new BlockBackend on success, null on failure.
  */
+/*
+ * callled by:
+ *   - block/crypto.c|327| <<block_crypto_co_create_generic>> blk = blk_new_with_bs(bs, BLK_PERM_WRITE | BLK_PERM_RESIZE, BLK_PERM_ALL,
+ *   - block/parallels.c|573| <<parallels_co_create>> blk = blk_new_with_bs(bs, BLK_PERM_WRITE | BLK_PERM_RESIZE, BLK_PERM_ALL,
+ *   - block/qcow.c|841| <<qcow_co_create>> qcow_blk = blk_new_with_bs(bs, BLK_PERM_WRITE | BLK_PERM_RESIZE,
+ *   - block/qcow2-snapshot.c|789| <<qcow2_snapshot_goto>> BlockBackend *blk = blk_new_with_bs(bs, BLK_PERM_RESIZE, BLK_PERM_ALL,
+ *   - block/qcow2.c|3658| <<qcow2_co_create>> blk = blk_new_with_bs(bs, BLK_PERM_WRITE | BLK_PERM_RESIZE, BLK_PERM_ALL,
+ *   - block/qcow2.c|5837| <<qcow2_amend_options>> BlockBackend *blk = blk_new_with_bs(bs, BLK_PERM_RESIZE, BLK_PERM_ALL,
+ *   - block/qed.c|663| <<bdrv_qed_co_create>> blk = blk_new_with_bs(bs, BLK_PERM_WRITE | BLK_PERM_RESIZE, BLK_PERM_ALL,
+ *   - block/stream.c|319| <<stream_start>> s->blk = blk_new_with_bs(cor_filter_bs, BLK_PERM_CONSISTENT_READ,
+ *   - block/vdi.c|808| <<vdi_co_do_create>> blk = blk_new_with_bs(bs_file, BLK_PERM_WRITE | BLK_PERM_RESIZE,
+ *   - block/vhdx.c|2000| <<vhdx_co_create>> blk = blk_new_with_bs(bs, BLK_PERM_WRITE | BLK_PERM_RESIZE, BLK_PERM_ALL,
+ *   - block/vmdk.c|2801| <<vmdk_co_create_cb>> blk = blk_new_with_bs(bs,
+ *   - block/vpc.c|1013| <<vpc_co_create>> blk = blk_new_with_bs(bs, BLK_PERM_WRITE | BLK_PERM_RESIZE, BLK_PERM_ALL,
+ *   - blockdev.c|2523| <<qmp_block_resize>> blk = blk_new_with_bs(bs, BLK_PERM_RESIZE, BLK_PERM_ALL, errp);
+ *   - qemu-img.c|1096| <<img_commit>> old_backing_blk = blk_new_with_bs(bs, BLK_PERM_WRITE, BLK_PERM_ALL,
+ */
 BlockBackend *blk_new_with_bs(BlockDriverState *bs, uint64_t perm,
                               uint64_t shared_perm, Error **errp)
 {
@@ -416,6 +444,25 @@ BlockBackend *blk_new_with_bs(BlockDriverState *bs, uint64_t perm,
  * though, so callers of this function have to be able to specify @filename and
  * @flags.
  */
+/*
+ * called by:
+ *   - block.c|700| <<bdrv_co_create_opts_simple>> blk = blk_new_open(filename, NULL, options,
+ *   - block/qcow2.c|3741| <<qcow2_co_create>> blk = blk_new_open(NULL, NULL, options,
+ *   - block/qcow2.c|3822| <<qcow2_co_create>> blk = blk_new_open(NULL, NULL, options,
+ *   - block/vmdk.c|2300| <<vmdk_create_extent>> blk = blk_new_open(filename, NULL, NULL,
+ *   - block/vmdk.c|2519| <<vmdk_co_do_create>> backing = blk_new_open(full_backing, NULL, NULL,
+ *   - blockdev.c|592| <<blockdev_init>> blk = blk_new_open(file, NULL, bs_opts, bdrv_flags, errp);
+ *   - qemu-img.c|375| <<img_open_opts>> blk = blk_new_open(NULL, NULL, options, flags, &local_err);
+ *   - qemu-img.c|404| <<img_open_file>> blk = blk_new_open(filename, NULL, options, flags, &local_err);
+ *   - qemu-img.c|3667| <<img_rebase>> blk_new_backing = blk_new_open(out_real_path, NULL,
+ *   - qemu-io.c|108| <<openfile>> qemuio_blk = blk_new_open(name, NULL, opts, flags, &local_err);
+ *   - qemu-nbd.c|1053| <<main>> blk = blk_new_open(NULL, NULL, options, flags, &local_err);
+ *   - qemu-nbd.c|1059| <<main>> blk = blk_new_open(srcpath, NULL, options, flags, &local_err);
+ *   - tests/unit/test-image-locking.c|43| <<open_image>> blk = blk_new_open(path, NULL, options, BDRV_O_RDWR, &local_err);
+ *   - tests/unit/test-replication.c|189| <<start_primary>> blk = blk_new_open(NULL, NULL, qdict, BDRV_O_RDWR, &error_abort);
+ *   - tests/unit/test-replication.c|309| <<start_secondary>> blk = blk_new_open(NULL, NULL, qdict, BDRV_O_RDWR, &error_abort);
+ *   - tests/unit/test-replication.c|335| <<start_secondary>> blk = blk_new_open(NULL, NULL, qdict, BDRV_O_RDWR, &error_abort);
+ */
 BlockBackend *blk_new_open(const char *filename, const char *reference,
                            QDict *options, int flags, Error **errp)
 {
@@ -755,6 +802,11 @@ BlockBackend *blk_by_name(const char *name)
 /*
  * Return the BlockDriverState attached to @blk if any, else null.
  */
+/*
+ * BlockBackend *blk:
+ * -> BdrvChild *root;
+ *    -> BlockDriverState *bs;
+ */
 BlockDriverState *blk_bs(BlockBackend *blk)
 {
     IO_CODE();
@@ -899,6 +951,36 @@ void blk_remove_bs(BlockBackend *blk)
 /*
  * Associates a new BlockDriverState with @blk.
  */
+/*
+ * (gdb) bt
+ * #0  blk_insert_bs (blk=blk@entry=0x555556facc80, bs=bs@entry=0x555556e5ea00, errp=errp@entry=0x7ffe38047fa0) at ../block/block-backend.c:904
+ * #1  0x0000555555c26f84 in blk_new_with_bs (bs=bs@entry=0x555556e5ea00, perm=perm@entry=10, shared_perm=shared_perm@entry=15, errp=errp@entry=0x7ffe38047fa0)
+ *     at ../block/block-backend.c:399
+ * #2  0x0000555555c57aea in qcow2_co_create (create_options=0x555557000340, errp=errp@entry=0x7ffe38047fa0) at ../block/qcow2.c:3618
+ * #3  0x0000555555c585e2 in qcow2_co_create_opts (drv=<optimized out>, filename=<optimized out>, opts=<optimized out>, errp=0x7ffe38047fa0) at ../block/qcow2.c:3916
+ * #4  0x0000555555bff227 in bdrv_create_co_entry (opaque=0x7fffffffd740) at ../block.c:534
+ * #5  0x0000555555d41c2b in coroutine_trampoline (i0=<optimized out>, i1=<optimized out>) at ../util/coroutine-ucontext.c:177
+ * #6  0x00007ffff5043190 in __start_context () at /lib64/libc.so.6
+ * #7  0x00007fffec903ac0 in  ()
+ * #8  0x0000000000000000 in  ()
+ *
+ * 非test的调用:
+ *   - block.c|4253| <<bdrv_open_inherit>> blk_insert_bs(file, file_bs, &local_err);
+ *   - block/block-backend.c|403| <<blk_new_with_bs>> if (blk_insert_bs(blk, bs, errp) < 0) {
+ *   - block/commit.c|386| <<commit_start>> ret = blk_insert_bs(s->base, base, errp);
+ *   - block/commit.c|395| <<commit_start>> ret = blk_insert_bs(s->top, top, errp);
+ *   - block/commit.c|483| <<bdrv_commit>> ret = blk_insert_bs(src, bs, &local_err);
+ *   - block/commit.c|500| <<bdrv_commit>> ret = blk_insert_bs(backing, backing_file_bs, &local_err);
+ *   - block/export/export.c|161| <<blk_exp_add>> ret = blk_insert_bs(blk, bs, errp);
+ *   - block/mirror.c|1787| <<mirror_start_job>> ret = blk_insert_bs(s->target, target, errp);
+ *   - block/monitor/block-hmp-cmds.c|590| <<hmp_qemu_io>> ret = blk_insert_bs(blk, bs, &err);
+ *   - block/qapi-sysemu.c|263| <<qmp_blockdev_insert_anon_medium>> ret = blk_insert_bs(blk, bs, errp);
+ *   - hw/core/qdev-properties-system.c|148| <<set_drive_helper>> ret = blk_insert_bs(blk, bs, errp);
+ *   - migration/block.c|453| <<init_blk_migration>> ret = blk_insert_bs(bmds->blk, bs, &local_err);
+ *   - qemu-img.c|3607| <<img_rebase>> ret = blk_insert_bs(blk_old_backing, base_bs,
+ *   - qemu-img.c|3658| <<img_rebase>> ret = blk_insert_bs(blk_new_backing, prefix_chain_bs,
+ *   - qemu-nbd.c|1076| <<main>> blk_insert_bs(blk, bs, &error_fatal);
+ */
 int blk_insert_bs(BlockBackend *blk, BlockDriverState *bs, Error **errp)
 {
     ThrottleGroupMember *tgm = &blk->public.throttle_group_member;
@@ -1050,6 +1132,21 @@ BlockBackend *blk_by_dev(void *dev)
  * @opaque is the opaque argument to pass to the callbacks.
  * This is for use by device models.
  */
+/*
+ * called by:
+ *   - block/export/vduse-blk.c|332| <<vduse_blk_exp_create>> blk_set_dev_ops(exp->blk, &vduse_block_ops, exp);
+ *   - block/export/vduse-blk.c|350| <<vduse_blk_exp_delete>> blk_set_dev_ops(exp->blk, NULL, NULL);
+ *   - hw/block/fdc.c|547| <<floppy_drive_realize>> blk_set_dev_ops(drive->blk, &fd_block_ops, drive);
+ *   - hw/block/swim.c|236| <<swim_drive_realize>> blk_set_dev_ops(drive->blk, &swim_block_ops, drive);
+ *   - hw/block/virtio-blk.c|1436| <<virtio_blk_device_realize>> blk_set_dev_ops(s->blk, &virtio_block_ops, s);
+ *   - hw/block/xen-block.c|245| <<xen_block_realize>> blk_set_dev_ops(blk, &xen_block_dev_ops, blockdev);
+ *   - hw/ide/core.c|2550| <<ide_init_drive>> blk_set_dev_ops(blk, &ide_cd_block_ops, s);
+ *   - hw/ide/core.c|2560| <<ide_init_drive>> blk_set_dev_ops(blk, &ide_hd_block_ops, s);
+ *   - hw/scsi/scsi-disk.c|2498| <<scsi_realize>> blk_set_dev_ops(s->qdev.conf.blk, &scsi_disk_removable_block_ops, s);
+ *   - hw/scsi/scsi-disk.c|2500| <<scsi_realize>> blk_set_dev_ops(s->qdev.conf.blk, &scsi_disk_block_ops, s);
+ *   - hw/sd/sd.c|2180| <<sd_realize>> blk_set_dev_ops(sd->blk, &sd_block_ops, sd);
+ *   - nbd/server.c|1785| <<nbd_export_create>> blk_set_dev_ops(blk, &nbd_block_ops, exp);
+ */
 void blk_set_dev_ops(BlockBackend *blk, const BlockDevOps *ops,
                      void *opaque)
 {
@@ -1279,6 +1376,22 @@ static void coroutine_fn blk_wait_while_drained(BlockBackend *blk)
     }
 }
 
+/*
+ * Thread 3 "IO iothread01" hit Breakpoint 1, qcow2_co_preadv_part (bs=0x556b47200d40, offset=4811128832, bytes=4096, qiov=0x7fbc540096a8, qiov_offset=0, flags=0) at ../block/qcow2.c:2320
+ * 2320 {
+ * (gdb) bt
+ * #0  qcow2_co_preadv_part (bs=0x556b47200d40, offset=4811128832, bytes=4096, qiov=0x7fbc540096a8, qiov_offset=0, flags=0) at ../block/qcow2.c:2320
+ * #1  0x0000556b45012226 in bdrv_driver_preadv (bs=0x556b47200d40, offset=4811128832, bytes=4096, qiov=0x7fbc540096a8, qiov_offset=0, flags=0) at ../block/io.c:1150
+ * #2  0x0000556b4501340b in bdrv_aligned_preadv (child=0x556b4720da20, req=0x7fbaa6df4e00, offset=4811128832, bytes=4096, align=1, qiov=0x7fbc540096a8, qiov_offset=0, flags=0)
+ *     at ../block/io.c:1548
+ * #3  0x0000556b45013e42 in bdrv_co_preadv_part (child=0x556b4720da20, offset=4811128832, bytes=4096, qiov=0x7fbc540096a8, qiov_offset=0, flags=0) at ../block/io.c:1821
+ * #4  0x0000556b4500105b in blk_co_do_preadv_part (blk=0x556b472009f0, offset=4811128832, bytes=4096, qiov=0x7fbc540096a8, qiov_offset=0, flags=0) at ../block/block-backend.c:1311
+ * #5  0x0000556b450017cf in blk_aio_read_entry (opaque=0x7fbc5400bfc0) at ../block/block-backend.c:1556
+ * #6  0x0000556b45178ab8 in coroutine_trampoline (i0=1409340320, i1=32700) at ../util/coroutine-ucontext.c:177
+ * #7  0x00007fbc5f21e190 in __start_context () at /lib64/libc.so.6
+ * #8  0x00007fbc591cccf0 in  ()
+ * #9  0x0000000000000000 in  ()
+ */
 /* To be called between exactly one pair of blk_inc/dec_in_flight() */
 static int coroutine_fn
 blk_co_do_preadv_part(BlockBackend *blk, int64_t offset, int64_t bytes,
@@ -1354,6 +1467,11 @@ int coroutine_fn blk_co_preadv_part(BlockBackend *blk, int64_t offset,
 }
 
 /* To be called between exactly one pair of blk_inc/dec_in_flight() */
+/*
+ * called by:
+ *   - block/block-backend.c|1436| <<blk_co_pwritev_part>> ret = blk_co_do_pwritev_part(blk, offset, bytes, qiov, qiov_offset, flags);
+ *   - block/block-backend.c|1667| <<blk_aio_write_entry>> rwco->ret = blk_co_do_pwritev_part(rwco->blk, rwco->offset, acb->bytes,
+ */
 static int coroutine_fn
 blk_co_do_pwritev_part(BlockBackend *blk, int64_t offset, int64_t bytes,
                        QEMUIOVector *qiov, size_t qiov_offset,
@@ -1365,6 +1483,11 @@ blk_co_do_pwritev_part(BlockBackend *blk, int64_t offset, int64_t bytes,
 
     blk_wait_while_drained(blk);
 
+    /*
+     * BlockBackend *blk:
+     * -> BdrvChild *root;
+     *    -> BlockDriverState *bs;
+     */
     /* Call blk_bs() only after waiting, the graph may have changed */
     bs = blk_bs(blk);
     trace_blk_co_pwritev(blk, bs, offset, bytes, flags);
@@ -1385,6 +1508,11 @@ blk_co_do_pwritev_part(BlockBackend *blk, int64_t offset, int64_t bytes,
         flags |= BDRV_REQ_FUA;
     }
 
+    /*
+     * BlockBackend *blk:
+     * -> BdrvChild *root;
+     *    -> BlockDriverState *bs;
+     */
     ret = bdrv_co_pwritev_part(blk->root, offset, bytes, qiov, qiov_offset,
                                flags);
     bdrv_dec_in_flight(bs);
@@ -1482,6 +1610,13 @@ typedef struct BlkAioEmAIOCB {
     BlockAIOCB common;
     BlkRwCo rwco;
     int64_t bytes;
+    /*
+     * 在以下使用BlkAioEmAIOCB->has_returned:
+     *   - block/block-backend.c|1531| <<blk_aio_complete>> if (acb->has_returned) {
+     *   - block/block-backend.c|1545| <<blk_aio_complete_bh>> assert(acb->has_returned);
+     *   - block/block-backend.c|1568| <<blk_aio_prwv>> acb->has_returned = false;
+     *   - block/block-backend.c|1573| <<blk_aio_prwv>> acb->has_returned = true;
+     */
     bool has_returned;
 } BlkAioEmAIOCB;
 
@@ -1497,8 +1632,24 @@ static const AIOCBInfo blk_aio_em_aiocb_info = {
     .get_aio_context    = blk_aio_em_aiocb_get_aio_context,
 };
 
+/*
+ * called by:
+ *   - block/block-backend.c|1533| <<blk_aio_complete_bh>> blk_aio_complete(acb);
+ *   - block/block-backend.c|1588| <<blk_aio_read_entry>> blk_aio_complete(acb);
+ *   - block/block-backend.c|1605| <<blk_aio_write_entry>> blk_aio_complete(acb);
+ *   - block/block-backend.c|1790| <<blk_aio_ioctl_entry>> blk_aio_complete(acb);
+ *   - block/block-backend.c|1823| <<blk_aio_pdiscard_entry>> blk_aio_complete(acb);
+ *   - block/block-backend.c|1867| <<blk_aio_flush_entry>> blk_aio_complete(acb);
+ */
 static void blk_aio_complete(BlkAioEmAIOCB *acb)
 {
+    /*
+     * 在以下使用BlkAioEmAIOCB->has_returned:
+     *   - block/block-backend.c|1531| <<blk_aio_complete>> if (acb->has_returned) {
+     *   - block/block-backend.c|1545| <<blk_aio_complete_bh>> assert(acb->has_returned);
+     *   - block/block-backend.c|1568| <<blk_aio_prwv>> acb->has_returned = false;
+     *   - block/block-backend.c|1573| <<blk_aio_prwv>> acb->has_returned = true;
+     */
     if (acb->has_returned) {
         acb->common.cb(acb->common.opaque, acb->rwco.ret);
         blk_dec_in_flight(acb->rwco.blk);
@@ -1506,6 +1657,10 @@ static void blk_aio_complete(BlkAioEmAIOCB *acb)
     }
 }
 
+/*
+ * 在以下使用blk_aio_complete_bh():
+ *   - block/block-backend.c|1563| <<blk_aio_prwv>> replay_bh_schedule_oneshot_event(blk_get_aio_context(blk), blk_aio_complete_bh, acb);
+ */
 static void blk_aio_complete_bh(void *opaque)
 {
     BlkAioEmAIOCB *acb = opaque;
@@ -1513,12 +1668,36 @@ static void blk_aio_complete_bh(void *opaque)
     blk_aio_complete(acb);
 }
 
+/*
+ * called by:
+ *   - block/block-backend.c|1640| <<blk_aio_pwrite_zeroes>> return blk_aio_prwv(blk, offset, bytes, NULL, blk_aio_write_entry,
+ *   - block/block-backend.c|1735| <<blk_aio_preadv>> return blk_aio_prwv(blk, offset, qiov->size, qiov,
+ *   - block/block-backend.c|1766| <<blk_aio_pwritev>> return blk_aio_prwv(blk, offset, qiov->size, qiov,
+ *   - block/block-backend.c|1824| <<blk_aio_ioctl>> return blk_aio_prwv(blk, req, 0, buf, blk_aio_ioctl_entry, 0, cb, opaque);
+ *   - block/block-backend.c|1858| <<blk_aio_pdiscard>> return blk_aio_prwv(blk, offset, bytes, NULL, blk_aio_pdiscard_entry, 0,
+ *   - block/block-backend.c|1901| <<blk_aio_flush>> return blk_aio_prwv(blk, 0, 0, NULL, blk_aio_flush_entry, 0, cb, opaque);
+ */
 static BlockAIOCB *blk_aio_prwv(BlockBackend *blk, int64_t offset,
                                 int64_t bytes,
                                 void *iobuf, CoroutineEntry co_entry,
                                 BdrvRequestFlags flags,
                                 BlockCompletionFunc *cb, void *opaque)
 {
+    /*
+     * 一个co_entry的例子: blk_aio_read_entry()
+     * 一个cb的例子: virtio_blk_rw_complete()
+     *
+     * BlkAioEmAIOCB *acb;
+     * -> BlockAIOCB common;
+     *    -> const AIOCBInfo *aiocb_info;
+     *    -> BlockDriverState *bs;
+     *    -> BlockCompletionFunc *cb;
+     *    -> void *opaque;
+     *    -> int refcnt;
+     * -> BlkRwCo rwco;
+     * -> int64_t bytes;
+     * -> bool has_returned;
+     */
     BlkAioEmAIOCB *acb;
     Coroutine *co;
 
@@ -1535,6 +1714,11 @@ static BlockAIOCB *blk_aio_prwv(BlockBackend *blk, int64_t offset,
     acb->has_returned = false;
 
     co = qemu_coroutine_create(co_entry, acb);
+    /*
+     * BlockBackend *blk:
+     * -> BdrvChild *root;
+     *    -> BlockDriverState *bs;
+     */
     bdrv_coroutine_enter(blk_bs(blk), co);
 
     acb->has_returned = true;
@@ -1546,6 +1730,16 @@ static BlockAIOCB *blk_aio_prwv(BlockBackend *blk, int64_t offset,
     return &acb->common;
 }
 
+/*
+ * Thread 3 "IO iothread01" hit Breakpoint 1, blk_aio_read_entry (opaque=0x7f9e140011a0) at ../block/block-backend.c:1551
+ * 1551	    BlkAioEmAIOCB *acb = opaque;
+ * (gdb) bt
+ * #0  blk_aio_read_entry (opaque=0x7f9e140011a0) at ../block/block-backend.c:1551
+ * #1  0x0000564a1495aabd in coroutine_trampoline (i0=335562864, i1=32670) at ../util/coroutine-ucontext.c:177
+ * #2  0x00007f9e2085e190 in __start_context () at /lib64/libc.so.6
+ * #3  0x00007f9e1ac92c40 in  ()
+ * #4  0x0000000000000000 in  ()
+ */
 static void blk_aio_read_entry(void *opaque)
 {
     BlkAioEmAIOCB *acb = opaque;
@@ -1558,6 +1752,11 @@ static void blk_aio_read_entry(void *opaque)
     blk_aio_complete(acb);
 }
 
+/*
+ * 在以下使用blk_aio_write_entry():
+ *   - block/block-backend.c|1604| <<blk_aio_pwrite_zeroes>> return blk_aio_prwv(blk, offset, bytes, NULL, blk_aio_write_entry,
+ *   - block/block-backend.c|1731| <<blk_aio_pwritev>> blk_aio_write_entry, flags, cb, opaque);
+ */
 static void blk_aio_write_entry(void *opaque)
 {
     BlkAioEmAIOCB *acb = opaque;
@@ -1609,6 +1808,61 @@ int64_t blk_nb_sectors(BlockBackend *blk)
     return bdrv_nb_sectors(blk_bs(blk));
 }
 
+/*
+ * (gdb) bt
+ * #0  blk_aio_preadv (blk=0x560c43bf4420, offset=8609107968, qiov=0x7f9a7800e670, flags=0, cb=0x560c42152042 <dma_blk_cb>, opaque=0x7f9a7800e610) at ../block/block-backend.c:1617
+ * #1  0x0000560c420a1dcd in scsi_dma_readv (offset=8609107968, iov=0x7f9a7800e670, cb=0x560c42152042 <dma_blk_cb>, cb_opaque=0x7f9a7800e610, opaque=0x7f9a780027d0) at ../hw/scsi/scsi-disk.c:3059
+ * #2  0x0000560c421523e8 in dma_blk_cb (opaque=0x7f9a7800e610, ret=0) at ../softmmu/dma-helpers.c:178
+ * #3  0x0000560c42152664 in dma_blk_io
+ *     (ctx=0x560c43bf1270, sg=0x7f9a7800dc68, offset=8609107968, align=512, io_func=0x560c420a1d58 <scsi_dma_readv>, io_func_opaque=0x7f9a780027d0, cb=0x560c4209adb9 <scsi_dma_complete>, opaque=0x7f9a780027d0, dir=DMA_DIRECTION_FROM_DEVICE) at ../softmmu/dma-helpers.c:242
+ * #4  0x0000560c4209b278 in scsi_do_read (r=0x7f9a780027d0, ret=0) at ../hw/scsi/scsi-disk.c:427
+ * #5  0x0000560c4209b645 in scsi_read_data (req=0x7f9a780027d0) at ../hw/scsi/scsi-disk.c:499
+ * #6  0x0000560c42096f8b in scsi_req_continue (req=0x7f9a780027d0) at ../hw/scsi/scsi-bus.c:1395
+ * #7  0x0000560c422d7a44 in virtio_scsi_handle_cmd_req_submit (s=0x560c448d0e10, req=0x7f9a7800dc20) at ../hw/scsi/virtio-scsi.c:719
+ * #8  0x0000560c422d7c98 in virtio_scsi_handle_cmd_vq (s=0x560c448d0e10, vq=0x560c448d9838) at ../hw/scsi/virtio-scsi.c:761
+ * #9  0x0000560c422d7d16 in virtio_scsi_handle_cmd (vdev=0x560c448d0e10, vq=0x560c448d9838) at ../hw/scsi/virtio-scsi.c:775
+ * #10 0x0000560c42305448 in virtio_queue_notify_vq (vq=0x560c448d9838) at ../hw/virtio/virtio.c:2365
+ * #11 0x0000560c42308566 in virtio_queue_host_notifier_read (n=0x560c448d98ac) at ../hw/virtio/virtio.c:3612
+ * #12 0x0000560c425c4f68 in aio_dispatch_handler (ctx=0x560c43bf1270, node=0x7f98e805d400) at ../util/aio-posix.c:369
+ * #13 0x0000560c425c505c in aio_dispatch_ready_handlers (ctx=0x560c43bf1270, ready_list=0x7f9a7ff6d880) at ../util/aio-posix.c:399
+ * #14 0x0000560c425c5ac6 in aio_poll (ctx=0x560c43bf1270, blocking=true) at ../util/aio-posix.c:713
+ * #15 0x0000560c4243ab66 in iothread_run (opaque=0x560c43bf0f00) at ../iothread.c:67
+ * #16 0x0000560c425ca4de in qemu_thread_start (args=0x560c43bf18e0) at ../util/qemu-thread-posix.c:504
+ * #17 0x00007f9a85ec5ea5 in start_thread () at /lib64/libpthread.so.0
+ * #18 0x00007f9a85bee9fd in clone () at /lib64/libc.so.6
+ *
+ * (gdb) info threads
+ *   Id   Target Id                                           Frame
+ *   1    Thread 0x7f9a888aac80 (LWP 23424) "qemu-system-x86" 0x00007f9a85be3d8f in ppoll () from /lib64/libc.so.6
+ *   2    Thread 0x7f9a8076f700 (LWP 23425) "qemu-system-x86" 0x00007f9a85be8d19 in syscall () from /lib64/libc.so.6
+ * * 3    Thread 0x7f9a7ff6e700 (LWP 23426) "IO iothread01"   blk_aio_preadv (blk=0x560c43bf4420, offset=8609107968, qiov=0x7f9a7800e670, flags=0, cb=0x560c42152042 <dma_blk_cb>, opaque=0x7f9a7800e610)
+ *     at ../block/block-backend.c:1617
+ *   4    Thread 0x7f9a7ea05700 (LWP 23431) "CPU 0/KVM"       0x00007f9a85be5397 in ioctl () from /lib64/libc.so.6
+ *   5    Thread 0x7f9a7e204700 (LWP 23432) "CPU 1/KVM"       0x00007f9a85be5397 in ioctl () from /lib64/libc.so.6
+ *   6    Thread 0x7f9a7da03700 (LWP 23433) "CPU 2/KVM"       0x00007f9a85be5397 in ioctl () from /lib64/libc.so.6
+ *   7    Thread 0x7f9a7d202700 (LWP 23434) "CPU 3/KVM"       0x00007f9a85be5397 in ioctl () from /lib64/libc.so.6
+ *
+ * 一些调用的例子:
+ *   - hw/block/dataplane/xen-block.c|381| <<xen_block_do_aio>> blk_aio_preadv(dataplane->blk, request->start, &request->v, 0,
+ *   - hw/block/virtio-blk.c|430| <<submit_requests>> blk_aio_preadv(blk, sector_num << BDRV_SECTOR_BITS, qiov, 0,
+ *   - hw/ide/core.c|700| <<ide_buffered_readv>> aioreq = blk_aio_preadv(s->blk, sector_num << BDRV_SECTOR_BITS,
+ *   - hw/nvme/ctrl.c|1317| <<nvme_blk_read>> req->aiocb = blk_aio_preadv(blk, offset, &req->sg.iov, 0, cb, req);
+ *   - hw/nvme/ctrl.c|2163| <<nvme_verify_mdata_in_cb>> req->aiocb = blk_aio_preadv(blk, offset, &ctx->mdata.iov, 0,
+ *   - hw/nvme/ctrl.c|2319| <<nvme_compare_data_cb>> req->aiocb = blk_aio_preadv(blk, offset, &ctx->mdata.iov, 0,
+ *   - hw/nvme/ctrl.c|2570| <<nvme_verify>> req->aiocb = blk_aio_preadv(ns->blkconf.blk, offset, &ctx->data.iov, 0,
+ *   - hw/nvme/ctrl.c|2930| <<nvme_copy_in_cb>> iocb->aiocb = blk_aio_preadv(ns->blkconf.blk, nvme_moff(ns, slba),
+ *   - hw/nvme/ctrl.c|2993| <<nvme_copy_cb>> iocb->aiocb = blk_aio_preadv(ns->blkconf.blk, nvme_l2b(ns, slba),
+ *   - hw/nvme/ctrl.c|3158| <<nvme_compare>> req->aiocb = blk_aio_preadv(blk, offset, &ctx->data.iov, 0,
+ *   - hw/nvme/dif.c|506| <<nvme_dif_rw_mdata_in_cb>> req->aiocb = blk_aio_preadv(blk, offset, &ctx->mdata.iov, 0,
+ *   - hw/nvme/dif.c|655| <<nvme_dif_rw>> req->aiocb = blk_aio_preadv(ns->blkconf.blk, offset, &ctx->data.iov, 0,
+ *   - hw/scsi/scsi-disk.c|3084| <<scsi_dma_readv>> return blk_aio_preadv(s->qdev.conf.blk, offset, iov, 0, cb, cb_opaque);
+ *   - migration/block.c|336| <<mig_save_device_bulk>> blk->aiocb = blk_aio_preadv(bb, cur_sector * BDRV_SECTOR_SIZE, &blk->qiov,
+ *   - migration/block.c|561| <<mig_save_device_dirty>> blk->aiocb = blk_aio_preadv(bmds->blk,
+ *   - qemu-img.c|4339| <<bench_cb>> acb = blk_aio_preadv(b->blk, offset, b->qiov, 0, bench_cb, b);
+ *   - qemu-io-cmds.c|681| <<do_aio_readv>> blk_aio_preadv(blk, offset, qiov, 0, aio_rw_done, &async_ret);
+ *   - qemu-io-cmds.c|1535| <<aio_read_f>> blk_aio_preadv(blk, ctx->offset, &ctx->qiov, 0, aio_read_done, ctx);
+ *   - softmmu/dma-helpers.c|253| <<dma_blk_read_io_func>> return blk_aio_preadv(blk, offset, iov, 0, cb, cb_opaque);
+ */
 BlockAIOCB *blk_aio_preadv(BlockBackend *blk, int64_t offset,
                            QEMUIOVector *qiov, BdrvRequestFlags flags,
                            BlockCompletionFunc *cb, void *opaque)
@@ -1619,6 +1873,27 @@ BlockAIOCB *blk_aio_preadv(BlockBackend *blk, int64_t offset,
                         blk_aio_read_entry, flags, cb, opaque);
 }
 
+/*
+ * called by:
+ *   - hw/block/dataplane/xen-block.c|396| <<xen_block_do_aio>> blk_aio_pwritev(dataplane->blk, request->start, &request->v, 0,
+ *   - hw/block/m25p80.c|546| <<flash_sync_page>> blk_aio_pwritev(s->blk, page * s->pi->page_size, iov, 0,
+ *   - hw/block/m25p80.c|562| <<flash_sync_area>> blk_aio_pwritev(s->blk, off, iov, 0, blk_sync_complete, iov);
+ *   - hw/block/virtio-blk.c|424| <<submit_requests>> blk_aio_pwritev(blk, sector_num << BDRV_SECTOR_BITS, qiov, 0,
+ *   - hw/ide/core.c|1086| <<ide_sector_write>> s->pio_aiocb = blk_aio_pwritev(s->blk, sector_num << BDRV_SECTOR_BITS,
+ *   - hw/nvme/ctrl.c|1330| <<nvme_blk_write>> req->aiocb = blk_aio_pwritev(blk, offset, &req->sg.iov, 0, cb, req);
+ *   - hw/nvme/ctrl.c|2791| <<nvme_copy_out_cb>> iocb->aiocb = blk_aio_pwritev(ns->blkconf.blk, nvme_moff(ns, iocb->slba),
+ *   - hw/nvme/ctrl.c|2885| <<nvme_copy_in_completed_cb>> iocb->aiocb = blk_aio_pwritev(ns->blkconf.blk, nvme_l2b(ns, iocb->slba),
+ *   - hw/nvme/dif.c|530| <<nvme_dif_rw_mdata_out_cb>> req->aiocb = blk_aio_pwritev(blk, offset, &ctx->mdata.iov, 0,
+ *   - hw/nvme/dif.c|701| <<nvme_dif_rw>> req->aiocb = blk_aio_pwritev(ns->blkconf.blk, offset, &ctx->data.iov, 0,
+ *   - hw/scsi/scsi-disk.c|1838| <<scsi_write_same_complete>> r->req.aiocb = blk_aio_pwritev(s->qdev.conf.blk,
+ *   - hw/scsi/scsi-disk.c|1912| <<scsi_disk_emulate_write_same>> r->req.aiocb = blk_aio_pwritev(s->qdev.conf.blk,
+ *   - hw/scsi/scsi-disk.c|3069| <<scsi_dma_writev>> return blk_aio_pwritev(s->qdev.conf.blk, offset, iov, 0, cb, cb_opaque);
+ *   - qemu-img.c|4337| <<bench_cb>> acb = blk_aio_pwritev(b->blk, offset, b->qiov, 0, bench_cb, b);
+ *   - qemu-io-cmds.c|695| <<do_aio_writev>> blk_aio_pwritev(blk, offset, qiov, flags, aio_rw_done, &async_ret);
+ *   - qemu-io-cmds.c|1681| <<aio_write_f>> blk_aio_pwritev(blk, ctx->offset, &ctx->qiov, flags, aio_write_done,
+ *   - softmmu/dma-helpers.c|271| <<dma_blk_write_io_func>> return blk_aio_pwritev(blk, offset, iov, 0, cb, cb_opaque);
+ *   - tests/unit/test-replication.c|113| <<test_blk_write>> blk_aio_pwritev(blk, offset, &qiov, 0, blk_rw_done, &async_ret);
+ */
 BlockAIOCB *blk_aio_pwritev(BlockBackend *blk, int64_t offset,
                             QEMUIOVector *qiov, BdrvRequestFlags flags,
                             BlockCompletionFunc *cb, void *opaque)
@@ -1795,6 +2070,13 @@ void blk_drain(BlockBackend *blk)
     }
 }
 
+/*
+ * called by:
+ *   - hw/scsi/megasas.c|1464| <<megasas_cache_flush>> blk_drain_all();
+ *   - hw/scsi/virtio-scsi-dataplane.c|252| <<virtio_scsi_dataplane_stop>> blk_drain_all();
+ *   - qemu-io-cmds.c|1692| <<aio_flush_f>> blk_drain_all();
+ *   - tests/unit/test-block-backend.c|67| <<test_drain_all_aio_error>> blk_drain_all();
+ */
 void blk_drain_all(void)
 {
     BlockBackend *blk = NULL;
@@ -2121,6 +2403,12 @@ void blk_op_unblock_all(BlockBackend *blk, Error *reason)
 
 AioContext *blk_get_aio_context(BlockBackend *blk)
 {
+    /*
+     * BlockBackend *blk:
+     * -> BdrvChild *root;
+     *    -> BlockDriverState *bs;
+     *       -> AioContext *aio_context;
+     */
     BlockDriverState *bs = blk_bs(blk);
     IO_CODE();
 
diff --git a/block/commit.c b/block/commit.c
index 38571510c..c7aedc910 100644
--- a/block/commit.c
+++ b/block/commit.c
@@ -231,6 +231,11 @@ static void bdrv_commit_top_child_perm(BlockDriverState *bs, BdrvChild *c,
 
 /* Dummy node that provides consistent read to its users without requiring it
  * from its backing file and that allows writes on the backing file chain. */
+/*
+ * 在以下使用bdrv_commit_top:
+ *   - block/commit.c|302| <<commit_start>> commit_top_bs = bdrv_new_open_driver(&bdrv_commit_top, filter_node_name, 0,
+ *   - block/commit.c|480| <<bdrv_commit>> commit_top_bs = bdrv_new_open_driver(&bdrv_commit_top, NULL, BDRV_O_RDWR,
+ */
 static BlockDriver bdrv_commit_top = {
     .format_name                = "commit_top",
     .bdrv_co_preadv             = bdrv_commit_top_preadv,
@@ -240,6 +245,10 @@ static BlockDriver bdrv_commit_top = {
     .is_filter                  = true,
 };
 
+/*
+ * called by:
+ *   - blockdev.c|2776| <<qmp_block_commit>> commit_start(has_job_id ? job_id : NULL, bs, base_bs, top_bs, job_flags,
+ */
 void commit_start(const char *job_id, BlockDriverState *bs,
                   BlockDriverState *base, BlockDriverState *top,
                   int creation_flags, int64_t speed,
@@ -421,6 +430,11 @@ fail:
 #define COMMIT_BUF_SIZE (2048 * BDRV_SECTOR_SIZE)
 
 /* commit COW file into the raw image */
+/*
+ * called by:
+ *   - block/block-backend.c|2604| <<blk_commit_all>> ret = bdrv_commit(unfiltered_bs);
+ *   - block/monitor/block-hmp-cmds.c|225| <<hmp_commit>> ret = bdrv_commit(bs);
+ */
 int bdrv_commit(BlockDriverState *bs)
 {
     BlockBackend *src, *backing;
diff --git a/block/file-posix.c b/block/file-posix.c
index 48cd09662..95ccc5bde 100644
--- a/block/file-posix.c
+++ b/block/file-posix.c
@@ -159,6 +159,13 @@ typedef struct BDRVRawState {
     bool use_linux_io_uring:1;
     int page_cache_inconsistent; /* errno from fdatasync failure */
     bool has_fallocate;
+    /*
+     * 在以下使用BDRVRawState->needs_alignment:
+     *   - block/file-posix.c|393| <<raw_probe_alignment>> if (bdrv_is_sg(bs) || !s->needs_alignment) {
+     *   - block/file-posix.c|800| <<raw_open_common>> s->needs_alignment = raw_needs_alignment(bs);
+     *   - block/file-posix.c|1274| <<raw_refresh_limits>> s->needs_alignment = raw_needs_alignment(bs);
+     *   - block/file-posix.c|2087| <<raw_co_prw>> if (s->needs_alignment && !bdrv_qiov_is_aligned(bs, qiov)) {
+     */
     bool needs_alignment;
     bool force_alignment;
     bool drop_cache;
@@ -816,6 +823,48 @@ fail:
     return ret;
 }
 
+/*
+ * (gdb) bt
+ * #0  raw_open (bs=0x555556a75390, options=0x555556a79860, flags=8226, errp=0x7fffffffd790) at ../block/file-posix.c:822
+ * #1  0x0000555555d65bbc in bdrv_open_driver (bs=0x555556a75390, drv=0x555556787600 <bdrv_file>, node_name=0x555556a7a8b0 "file01",
+ *     options=0x555556a79860, open_flags=8226, errp=0x7fffffffd8a0) at ../block.c:1625
+ * #2  0x0000555555d66643 in bdrv_open_common (bs=0x555556a75390, file=0x0, options=0x555556a79860, errp=0x7fffffffd8a0) at ../block.c:1923
+ * #3  0x0000555555d6ad0d in bdrv_open_inherit (filename=0x0, reference=0x0, options=0x555556a79860, flags=40962, parent=0x0, child_class=0x0, child_role=0,
+ *     errp=0x5555567dcc60 <error_fatal>) at ../block.c:3992
+ * #4  0x0000555555d6b275 in bdrv_open (filename=0x0, reference=0x0, options=0x555556a73080, flags=0, errp=0x5555567dcc60 <error_fatal>) at ../block.c:4087
+ * #5  0x0000555555d55ecb in bds_tree_init (bs_opts=0x555556a73080, errp=0x5555567dcc60 <error_fatal>) at ../blockdev.c:659
+ * #6  0x0000555555d5ca7d in qmp_blockdev_add (options=0x555556854a00, errp=0x5555567dcc60 <error_fatal>) at ../blockdev.c:3545
+ * #7  0x0000555555a7bd70 in configure_blockdev (bdo_queue=0x5555566dd2f0 <bdo_queue>, machine_class=0x5555568fa9d0, snapshot=0) at ../softmmu/vl.c:698
+ * #8  0x0000555555a7fae6 in qemu_create_early_backends () at ../softmmu/vl.c:1887
+ * #9  0x0000555555a83a7c in qemu_init (argc=30, argv=0x7fffffffdd98, envp=0x0) at ../softmmu/vl.c:3522
+ * #10 0x00005555558210ed in qemu_main (argc=30, argv=0x7fffffffdd98, envp=0x0) at ../softmmu/main.c:37
+ * #11 0x0000555555821124 in main (argc=30, argv=0x7fffffffdd98) at ../softmmu/main.c:47
+ *
+ * (gdb) bt
+ * #0  raw_open (bs=0x555556a9c3a0, options=0x555556aa16b0, flags=155650, errp=0x7fffffffd220) at ../block/file-posix.c:822
+ * #1  0x0000555555d65bbc in bdrv_open_driver (bs=0x555556a9c3a0, drv=0x555556787600 <bdrv_file>, node_name=0x0, options=0x555556aa16b0, open_flags=155650,
+ *     errp=0x7fffffffd330) at ../block.c:1625
+ * #2  0x0000555555d66643 in bdrv_open_common (bs=0x555556a9c3a0, file=0x0, options=0x555556aa16b0, errp=0x7fffffffd330) at ../block.c:1923
+ * #3  0x0000555555d6ad0d in bdrv_open_inherit (filename=0x555556a7a8b0 "ol7.qcow2", reference=0x0, options=0x555556aa16b0, flags=40962, parent=0x555556a95050,
+ *     child_class=0x555556402ba0 <child_of_bds>, child_role=19, errp=0x7fffffffd530) at ../block.c:3992
+ * #4  0x0000555555d69eb9 in bdrv_open_child_bs (filename=0x555556a7a8b0 "ol7.qcow2", options=0x555556a9a360, bdref_key=0x5555560d0678 "file", parent=0x555556a95050,
+ *     child_class=0x555556402ba0 <child_of_bds>, child_role=19, allow_none=true, errp=0x7fffffffd530) at ../block.c:3625
+ * #5  0x0000555555d6aabc in bdrv_open_inherit (filename=0x555556a7a8b0 "ol7.qcow2", reference=0x0, options=0x555556a9a360, flags=8194, parent=0x0,
+ *     child_class=0x0, child_role=0, errp=0x5555567dcc60 <error_fatal>) at ../block.c:3939
+ * #6  0x0000555555d6b275 in bdrv_open (filename=0x555556a7a8b0 "ol7.qcow2", reference=0x0, options=0x555556a80070, flags=0, errp=0x5555567dcc60 <error_fatal>) at ../block.c:4087
+ * #7  0x0000555555d90243 in blk_new_open (filename=0x555556a7a8b0 "ol7.qcow2", reference=0x0, options=0x555556a80070, flags=0, errp=0x5555567dcc60 <error_fatal>)
+ *     at ../block/block-backend.c:454
+ * #8  0x0000555555d55adf in blockdev_init (file=0x555556a7a8b0 "ol7.qcow2", bs_opts=0x555556a80070, errp=0x5555567dcc60 <error_fatal>) at ../blockdev.c:592
+ * #9  0x0000555555d56a4a in drive_new (all_opts=0x555556851b00, block_default_type=IF_IDE, errp=0x5555567dcc60 <error_fatal>) at ../blockdev.c:981
+ * #10 0x0000555555a7bbc6 in drive_init_func (opaque=0x5555568faa78, opts=0x555556851b00, errp=0x5555567dcc60 <error_fatal>) at ../softmmu/vl.c:648
+ * #11 0x0000555555efb9da in qemu_opts_foreach (list=0x55555677df40 <qemu_drive_opts>, func=0x555555a7bb92 <drive_init_func>, opaque=0x5555568faa78, errp=0x5555567dcc60 <error_fatal>)
+ *     at ../util/qemu-option.c:1135
+ * #12 0x0000555555a7be06 in configure_blockdev (bdo_queue=0x5555566dd2f0 <bdo_queue>, machine_class=0x5555568fa9d0, snapshot=0) at ../softmmu/vl.c:707
+ * #13 0x0000555555a7fae6 in qemu_create_early_backends () at ../softmmu/vl.c:1887
+ * #14 0x0000555555a83a7c in qemu_init (argc=30, argv=0x7fffffffdd98, envp=0x0) at ../softmmu/vl.c:3522
+ * #15 0x00005555558210ed in qemu_main (argc=30, argv=0x7fffffffdd98, envp=0x0) at ../softmmu/main.c:37
+ * #16 0x0000555555821124 in main (argc=30, argv=0x7fffffffdd98) at ../softmmu/main.c:47
+ */
 static int raw_open(BlockDriverState *bs, QDict *options, int flags,
                     Error **errp)
 {
@@ -2053,14 +2102,37 @@ out:
     return result;
 }
 
+/*
+ * called by:
+ *   - block/file-posix.c|2117| <<raw_co_prw>> return raw_thread_pool_submit(bs, handle_aiocb_rw, &acb);
+ *   - block/file-posix.c|2192| <<raw_co_flush_to_disk>> return raw_thread_pool_submit(bs, handle_aiocb_flush, &acb);
+ *   - block/file-posix.c|2254| <<raw_regular_truncate>> return raw_thread_pool_submit(bs, handle_aiocb_truncate, &acb);
+ *   - block/file-posix.c|3004| <<raw_do_pdiscard>> ret = raw_thread_pool_submit(bs, handle_aiocb_discard, &acb);
+ *   - block/file-posix.c|3079| <<raw_do_pwrite_zeroes>> return raw_thread_pool_submit(bs, handler, &acb);
+ *   - block/file-posix.c|3290| <<raw_co_copy_range_to>> return raw_thread_pool_submit(bs, handle_aiocb_copy_range, &acb);
+ *   - block/file-posix.c|3636| <<hdev_co_ioctl>> return raw_thread_pool_submit(bs, handle_aiocb_ioctl, &acb);
+ */
 static int coroutine_fn raw_thread_pool_submit(BlockDriverState *bs,
                                                ThreadPoolFunc func, void *arg)
 {
     /* @bs can be NULL, bdrv_get_aio_context() returns the main context then */
     ThreadPool *pool = aio_get_thread_pool(bdrv_get_aio_context(bs));
+    /*
+     * called by:
+     *   - block/file-posix.c|2061| <<raw_thread_pool_submit>> return thread_pool_submit_co(pool, func, arg);
+     *   - block/qcow2-threads.c|54| <<qcow2_co_process>> ret = thread_pool_submit_co(pool, func, arg);
+     *   - scsi/pr-manager.c|65| <<pr_manager_execute>> return thread_pool_submit_co(pool, pr_manager_worker, &data);
+     *   - scsi/qemu-pr-helper.c|195| <<do_sgio>> r = thread_pool_submit_co(pool, do_sgio_worker, &data);
+     *   - tests/unit/test-thread-pool.c|81| <<co_test_cb>> thread_pool_submit_co(pool, worker_cb, data);
+     */
     return thread_pool_submit_co(pool, func, arg);
 }
 
+/*
+ * called by:
+ *   - block/file-posix.c|2124| <<raw_co_preadv>> return raw_co_prw(bs, offset, bytes, qiov, QEMU_AIO_READ);
+ *   - block/file-posix.c|2132| <<raw_co_pwritev>> return raw_co_prw(bs, offset, bytes, qiov, QEMU_AIO_WRITE);
+ */
 static int coroutine_fn raw_co_prw(BlockDriverState *bs, uint64_t offset,
                                    uint64_t bytes, QEMUIOVector *qiov, int type)
 {
diff --git a/block/io.c b/block/io.c
index 0a8cbefe8..fa3af2825 100644
--- a/block/io.c
+++ b/block/io.c
@@ -1127,6 +1127,28 @@ static void bdrv_co_io_em_complete(void *opaque, int ret)
     aio_co_wake(co->coroutine);
 }
 
+/*
+ * Thread 3 "IO iothread01" hit Breakpoint 1, qcow2_co_preadv_part (bs=0x556b47200d40, offset=4811128832, bytes=4096, qiov=0x7fbc540096a8, qiov_offset=0, flags=0) at ../block/qcow2.c:2320
+ * 2320 {
+ * (gdb) bt
+ * #0  qcow2_co_preadv_part (bs=0x556b47200d40, offset=4811128832, bytes=4096, qiov=0x7fbc540096a8, qiov_offset=0, flags=0) at ../block/qcow2.c:2320
+ * #1  0x0000556b45012226 in bdrv_driver_preadv (bs=0x556b47200d40, offset=4811128832, bytes=4096, qiov=0x7fbc540096a8, qiov_offset=0, flags=0) at ../block/io.c:1150
+ * #2  0x0000556b4501340b in bdrv_aligned_preadv (child=0x556b4720da20, req=0x7fbaa6df4e00, offset=4811128832, bytes=4096, align=1, qiov=0x7fbc540096a8, qiov_offset=0, flags=0)
+ *     at ../block/io.c:1548
+ * #3  0x0000556b45013e42 in bdrv_co_preadv_part (child=0x556b4720da20, offset=4811128832, bytes=4096, qiov=0x7fbc540096a8, qiov_offset=0, flags=0) at ../block/io.c:1821
+ * #4  0x0000556b4500105b in blk_co_do_preadv_part (blk=0x556b472009f0, offset=4811128832, bytes=4096, qiov=0x7fbc540096a8, qiov_offset=0, flags=0) at ../block/block-backend.c:1311
+ * #5  0x0000556b450017cf in blk_aio_read_entry (opaque=0x7fbc5400bfc0) at ../block/block-backend.c:1556
+ * #6  0x0000556b45178ab8 in coroutine_trampoline (i0=1409340320, i1=32700) at ../util/coroutine-ucontext.c:177
+ * #7  0x00007fbc5f21e190 in __start_context () at /lib64/libc.so.6
+ * #8  0x00007fbc591cccf0 in  ()
+ * #9  0x0000000000000000 in  ()
+ *
+ * called by:
+ *   - block/io.c|1420| <<bdrv_co_do_copy_on_readv>> ret = bdrv_driver_preadv(bs, cluster_offset, pnum,
+ *   - block/io.c|1459| <<bdrv_co_do_copy_on_readv>> ret = bdrv_driver_preadv(bs, offset + progress,
+ *   - block/io.c|1551| <<bdrv_aligned_preadv>> ret = bdrv_driver_preadv(bs, offset, bytes, qiov, qiov_offset, flags);
+ *   - block/io.c|1562| <<bdrv_aligned_preadv>> ret = bdrv_driver_preadv(bs, offset + bytes - bytes_remaining,
+ */
 static int coroutine_fn bdrv_driver_preadv(BlockDriverState *bs,
                                            int64_t offset, int64_t bytes,
                                            QEMUIOVector *qiov,
@@ -1146,6 +1168,9 @@ static int coroutine_fn bdrv_driver_preadv(BlockDriverState *bs,
         return -ENOMEDIUM;
     }
 
+    /*
+     * qcow2_co_preadv_part()
+     */
     if (drv->bdrv_co_preadv_part) {
         return drv->bdrv_co_preadv_part(bs, offset, bytes, qiov, qiov_offset,
                                         flags);
@@ -1156,11 +1181,17 @@ static int coroutine_fn bdrv_driver_preadv(BlockDriverState *bs,
         qiov = &local_qiov;
     }
 
+    /*
+     * raw_co_preadv()
+     */
     if (drv->bdrv_co_preadv) {
         ret = drv->bdrv_co_preadv(bs, offset, bytes, qiov, flags);
         goto out;
     }
 
+    /*
+     * null_aio_preadv()
+     */
     if (drv->bdrv_aio_preadv) {
         BlockAIOCB *acb;
         CoroutineIOCompletion co = {
@@ -1187,6 +1218,9 @@ static int coroutine_fn bdrv_driver_preadv(BlockDriverState *bs,
     assert(bytes <= BDRV_REQUEST_MAX_BYTES);
     assert(drv->bdrv_co_readv);
 
+    /*
+     * 比如iscsi_co_readv()
+     */
     ret = drv->bdrv_co_readv(bs, sector_num, nb_sectors, qiov);
 
 out:
@@ -1197,6 +1231,66 @@ out:
     return ret;
 }
 
+/*
+ * (gdb) bt
+ * #0  bdrv_driver_pwritev (bs=0x5555575242b0, offset=327680, bytes=1048576, qiov=0x555556c53f98, qiov_offset=0, flags=0) at ../block/io.c:1205
+ * #1  0x0000555555da5c65 in bdrv_aligned_pwritev (child=0x55555730d0c0, req=0x7ffe5dfff5c0, offset=327680, bytes=1048576, align=512, qiov=0x555556c53f98, qiov_offset=0, flags=0) at ../block/io.c:2097
+ * #2  0x0000555555da656e in bdrv_co_pwritev_part (child=0x55555730d0c0, offset=327680, bytes=1048576, qiov=0x555556c53f98, qiov_offset=0, flags=0) at ../block/io.c:2289
+ * #3  0x0000555555dd7f08 in qcow2_co_pwritev_task (bs=0x555556b06f00, host_offset=327680, offset=0, bytes=1048576, qiov=0x555556c53f98, qiov_offset=0, l2meta=0x0) at ../block/qcow2.c:2567
+ * #4  0x0000555555dd8036 in qcow2_co_pwritev_task_entry (task=0x7ffe5dfff7c0) at ../block/qcow2.c:2597
+ * #5  0x0000555555dd73d8 in qcow2_add_task
+ *     (bs=0x555556b06f00, pool=0x0, func=0x555555dd7fab <qcow2_co_pwritev_task_entry>, subcluster_type=QCOW2_SUBCLUSTER_UNALLOCATED_PLAIN, host_offset=327680, offset=0, bytes=1048576,
+ *     qiov=0x555556c53f98, qiov_offset=0, l2meta=0x0) at ../block/qcow2.c:2252
+ * #6  0x0000555555dd820b in qcow2_co_pwritev_part (bs=0x555556b06f00, offset=0, bytes=1048576, qiov=0x555556c53f98, qiov_offset=0, flags=0) at ../block/qcow2.c:2648
+ * #7  0x0000555555da3578 in bdrv_driver_pwritev (bs=0x555556b06f00, offset=0, bytes=1048576, qiov=0x555556c53f98, qiov_offset=0, flags=0) at ../block/io.c:1221
+ * #8  0x0000555555da5c65 in bdrv_aligned_pwritev (child=0x5555574b0df0, req=0x7ffe5dfffa80, offset=0, bytes=1048576, align=1, qiov=0x555556c53f98, qiov_offset=0, flags=0) at ../block/io.c:2097
+ * #9  0x0000555555da656e in bdrv_co_pwritev_part (child=0x5555574b0df0, offset=0, bytes=1048576, qiov=0x555556c53f98, qiov_offset=0, flags=0) at ../block/io.c:2289
+ * #10 0x0000555555da61f8 in bdrv_co_pwritev (child=0x5555574b0df0, offset=0, bytes=1048576, qiov=0x555556c53f98, flags=0) at ../block/io.c:2206
+ * #11 0x0000555555dade7e in bdrv_mirror_top_do_write (bs=0x555556c4fc10, method=MIRROR_METHOD_COPY, offset=0, bytes=1048576, qiov=0x555556c53f98, flags=0) at ../block/mirror.c:1426
+ * #12 0x0000555555dae047 in bdrv_mirror_top_pwritev (bs=0x555556c4fc10, offset=0, bytes=1048576, qiov=0x555556c53f98, flags=0) at ../block/mirror.c:1482
+ * #13 0x0000555555da3616 in bdrv_driver_pwritev (bs=0x555556c4fc10, offset=0, bytes=1048576, qiov=0x555556c53f98, qiov_offset=0, flags=0) at ../block/io.c:1233
+ * #14 0x0000555555da5c65 in bdrv_aligned_pwritev (child=0x555557777050, req=0x7ffe5dfffe00, offset=0, bytes=1048576, align=1, qiov=0x555556c53f98, qiov_offset=0, flags=0) at ../block/io.c:2097
+ * #15 0x0000555555da656e in bdrv_co_pwritev_part (child=0x555557777050, offset=0, bytes=1048576, qiov=0x555556c53f98, qiov_offset=0, flags=0) at ../block/io.c:2289
+ * #16 0x0000555555d922b8 in blk_co_do_pwritev_part (blk=0x555557776d00, offset=0, bytes=1048576, qiov=0x555556c53f98, qiov_offset=0, flags=0) at ../block/block-backend.c:1388
+ * #17 0x0000555555d9287f in blk_aio_write_entry (opaque=0x5555573b59c0) at ../block/block-backend.c:1568
+ * #18 0x0000555555f09ab8 in coroutine_trampoline (i0=-466619824, i1=32767) at ../util/coroutine-ucontext.c:177
+ * #19 0x00007ffff5043190 in __start_context () at /lib64/libc.so.6
+ * #20 0x00007fffed905970 in  ()
+ * #21 0x0000000000000000 in  ()
+ *
+ * (gdb) bt
+ * #0  bdrv_driver_pwritev (bs=0x555556a75390, offset=2424832, bytes=1048576, qiov=0x5555572770f8, qiov_offset=0, flags=0) at ../block/io.c:1205
+ * #1  0x0000555555da5c65 in bdrv_aligned_pwritev (child=0x555556a81170, req=0x7ffe470f7830, offset=2424832, bytes=1048576, align=512, qiov=0x5555572770f8, qiov_offset=0, flags=0) at ../block/io.c:2097
+ * #2  0x0000555555da656e in bdrv_co_pwritev_part (child=0x555556a81170, offset=2424832, bytes=1048576, qiov=0x5555572770f8, qiov_offset=0, flags=0) at ../block/io.c:2289
+ * #3  0x0000555555dd7f08 in qcow2_co_pwritev_task (bs=0x555556a7ae40, host_offset=2424832, offset=0, bytes=1048576, qiov=0x5555572770f8, qiov_offset=0, l2meta=0x0) at ../block/qcow2.c:2567
+ * #4  0x0000555555dd8036 in qcow2_co_pwritev_task_entry (task=0x7ffe470f7a30) at ../block/qcow2.c:2597
+ * #5  0x0000555555dd73d8 in qcow2_add_task (bs=0x555556a7ae40, pool=0x0, func=0x555555dd7fab <qcow2_co_pwritev_task_entry>, subcluster_type=QCOW2_SUBCLUSTER_UNALLOCATED_PLAIN,
+ *     host_offset=2424832, offset=0, bytes=1048576, qiov=0x5555572770f8, qiov_offset=0, l2meta=0x0) at ../block/qcow2.c:2252
+ * #6  0x0000555555dd820b in qcow2_co_pwritev_part (bs=0x555556a7ae40, offset=0, bytes=1048576, qiov=0x5555572770f8, qiov_offset=0, flags=0) at ../block/qcow2.c:2648
+ * #7  0x0000555555da3578 in bdrv_driver_pwritev (bs=0x555556a7ae40, offset=0, bytes=1048576, qiov=0x5555572770f8, qiov_offset=0, flags=0) at ../block/io.c:1221
+ * #8  0x0000555555da5c65 in bdrv_aligned_pwritev (child=0x5555572ebdc0, req=0x7ffe470f7cf0, offset=0, bytes=1048576, align=1, qiov=0x5555572770f8, qiov_offset=0, flags=0) at ../block/io.c:2097
+ * #9  0x0000555555da656e in bdrv_co_pwritev_part (child=0x5555572ebdc0, offset=0, bytes=1048576, qiov=0x5555572770f8, qiov_offset=0, flags=0) at ../block/io.c:2289
+ * #10 0x0000555555d922b8 in blk_co_do_pwritev_part (blk=0x5555575a8e20, offset=0, bytes=1048576, qiov=0x5555572770f8, qiov_offset=0, flags=0) at ../block/block-backend.c:1388
+ * #11 0x0000555555d9231e in blk_co_pwritev_part (blk=0x5555575a8e20, offset=0, bytes=1048576, qiov=0x5555572770f8, qiov_offset=0, flags=0) at ../block/block-backend.c:1403
+ * #12 0x0000555555d923fb in blk_co_pwritev (blk=0x5555575a8e20, offset=0, bytes=1048576, qiov=0x5555572770f8, flags=0) at ../block/block-backend.c:1425
+ * #13 0x0000555555daa883 in mirror_read_complete (op=0x5555572770f0, ret=0) at ../block/mirror.c:258
+ * #14 0x0000555555dab040 in mirror_co_read (opaque=0x5555572770f0) at ../block/mirror.c:398
+ * #15 0x0000555555f09ab8 in coroutine_trampoline (i0=1476416400, i1=32766) at ../util/coroutine-ucontext.c:177
+ * #16 0x00007ffff5043190 in __start_context () at /lib64/libc.so.6
+ * #17 0x00007fffed104a30 in  ()
+ * #18 0x0000000000000000 in  ()
+ *
+ * called by:
+ *   - block/io.c|1518| <<bdrv_co_do_copy_on_readv>> ret = bdrv_driver_pwritev(bs, cluster_offset, pnum,
+ *   - block/io.c|2034| <<bdrv_co_do_pwrite_zeroes>> ret = bdrv_driver_pwritev(bs, offset, num, &qiov, 0, write_flags);
+ *   - block/io.c|2217| <<bdrv_aligned_pwritev>> ret = bdrv_driver_pwritev(bs, offset, bytes, qiov, qiov_offset, flags);
+ *   - block/io.c|2232| <<bdrv_aligned_pwritev>> ret = bdrv_driver_pwritev(bs, offset + bytes - bytes_remaining,
+ *
+ * 下面的例子是virtio-blk的
+ * BlockBackend *blk:
+ * -> BdrvChild *root;
+ *    -> BlockDriverState *bs;
+ */
 static int coroutine_fn bdrv_driver_pwritev(BlockDriverState *bs,
                                             int64_t offset, int64_t bytes,
                                             QEMUIOVector *qiov,
@@ -1478,6 +1572,12 @@ err:
  * handles copy on read, zeroing after EOF, and fragmentation of large
  * reads; any other features must be implemented by the caller.
  */
+/*
+ * called by:
+ *   - block/io.c|1673| <<bdrv_padding_rmw_read>> ret = bdrv_aligned_preadv(child, req, req->overlap_offset, bytes,
+ *   - block/io.c|1694| <<bdrv_padding_rmw_read>> ret = bdrv_aligned_preadv(
+ *   - block/io.c|1824| <<bdrv_co_preadv_part>> ret = bdrv_aligned_preadv(child, &req, offset, bytes,
+ */
 static int coroutine_fn bdrv_aligned_preadv(BdrvChild *child,
     BdrvTrackedRequest *req, int64_t offset, int64_t bytes,
     int64_t align, QEMUIOVector *qiov, size_t qiov_offset, int flags)
@@ -1770,6 +1870,24 @@ int coroutine_fn bdrv_co_preadv(BdrvChild *child,
     return bdrv_co_preadv_part(child, offset, bytes, qiov, 0, flags);
 }
 
+/*
+ * called by:
+ *   - block/block-backend.c|1331| <<blk_co_do_preadv_part>> ret = bdrv_co_preadv_part(blk->root, offset, bytes, qiov, qiov_offset,
+ *   - block/copy-before-write.c|275| <<cbw_co_preadv_snapshot>> ret = bdrv_co_preadv_part(file, offset, cur_bytes,
+ *   - block/copy-on-read.c|142| <<cor_co_preadv_part>> return bdrv_co_preadv_part(bs->file, offset, bytes, qiov, qiov_offset,
+ *   - block/copy-on-read.c|167| <<cor_co_preadv_part>> ret = bdrv_co_preadv_part(bs->file, offset, n, qiov, qiov_offset,
+ *   - block/filter-compress.c|71| <<compress_co_preadv_part>> return bdrv_co_preadv_part(bs->file, offset, bytes, qiov, qiov_offset,
+ *   - block/io.c|1804| <<bdrv_co_preadv>> return bdrv_co_preadv_part(child, offset, bytes, qiov, 0, flags);
+ *   - block/preallocate.c|233| <<preallocate_co_preadv_part>> return bdrv_co_preadv_part(bs->file, offset, bytes, qiov, qiov_offset,
+ *   - block/qcow2.c|2290| <<qcow2_co_preadv_task>> return bdrv_co_preadv_part(bs->backing, offset, bytes,
+ *   - block/qcow2.c|2308| <<qcow2_co_preadv_task>> return bdrv_co_preadv_part(s->data_file, host_offset,
+ *
+ * BlockBackend:
+ * -> char *name;
+ * -> int refcnt;
+ * -> BdrvChild *root;
+ * -> AioContext *ctx;
+ */
 int coroutine_fn bdrv_co_preadv_part(BdrvChild *child,
     int64_t offset, int64_t bytes,
     QEMUIOVector *qiov, size_t qiov_offset,
@@ -2045,11 +2163,36 @@ bdrv_co_write_req_finish(BdrvChild *child, int64_t offset, int64_t bytes,
  * Forwards an already correctly aligned write request to the BlockDriver,
  * after possibly fragmenting it.
  */
+/*
+ * called by:
+ *   - block/io.c|2277| <<bdrv_co_do_zero_pwritev>> ret = bdrv_aligned_pwritev(child, req, aligned_offset, write_bytes,
+ *   - block/io.c|2293| <<bdrv_co_do_zero_pwritev>> ret = bdrv_aligned_pwritev(child, req, offset, aligned_bytes, align,
+ *   - block/io.c|2307| <<bdrv_co_do_zero_pwritev>> ret = bdrv_aligned_pwritev(child, req, offset, align, align,
+ *   - block/io.c|2409| <<bdrv_co_pwritev_part>> ret = bdrv_aligned_pwritev(child, &req, offset, bytes, align,
+ *
+ * 下面的例子是virtio-blk的
+ * BlockBackend *blk:
+ * -> BdrvChild *root;
+ *    -> BlockDriverState *bs;
+ */
 static int coroutine_fn bdrv_aligned_pwritev(BdrvChild *child,
     BdrvTrackedRequest *req, int64_t offset, int64_t bytes,
     int64_t align, QEMUIOVector *qiov, size_t qiov_offset,
     BdrvRequestFlags flags)
 {
+    /*
+     * struct BdrvChild {
+     *     BlockDriverState *bs;
+     *     char *name;
+     *     const BdrvChildClass *klass;
+     *     BdrvChildRole role;
+     *     void *opaque;
+     *     ... ...
+     *    QLIST_ENTRY(BdrvChild) next;
+     *    QLIST_ENTRY(BdrvChild) next_parent;
+     * };
+     *
+     */
     BlockDriverState *bs = child->bs;
     BlockDriver *drv = bs->drv;
     int ret;
@@ -2206,6 +2349,20 @@ int coroutine_fn bdrv_co_pwritev(BdrvChild *child,
     return bdrv_co_pwritev_part(child, offset, bytes, qiov, 0, flags);
 }
 
+/*
+ * called by:
+ *   - block/block-backend.c|1431| <<blk_co_do_pwritev_part>> ret = bdrv_co_pwritev_part(blk->root, offset, bytes, qiov, qiov_offset,
+ *   - block/copy-on-read.c|190| <<cor_co_pwritev_part>> return bdrv_co_pwritev_part(bs->file, offset, bytes, qiov, qiov_offset,
+ *   - block/filter-compress.c|83| <<compress_co_pwritev_part>> return bdrv_co_pwritev_part(bs->file, offset, bytes, qiov, qiov_offset,
+ *   - block/io.c|2326| <<bdrv_co_pwritev>> return bdrv_co_pwritev_part(child, offset, bytes, qiov, 0, flags);
+ *   - block/preallocate.c|369| <<preallocate_co_pwritev_part>> return bdrv_co_pwritev_part(bs->file, offset, bytes, qiov, qiov_offset,
+ *   - block/qcow2.c|2607| <<qcow2_co_pwritev_task>> ret = bdrv_co_pwritev_part(s->data_file, host_offset,
+ *
+ * 下面的例子是virtio-blk的
+ * BlockBackend *blk:
+ * -> BdrvChild *root;
+ *    -> BlockDriverState *bs;
+ */
 int coroutine_fn bdrv_co_pwritev_part(BdrvChild *child,
     int64_t offset, int64_t bytes, QEMUIOVector *qiov, size_t qiov_offset,
     BdrvRequestFlags flags)
diff --git a/block/io_uring.c b/block/io_uring.c
index a1760152e..512a9c2ce 100644
--- a/block/io_uring.c
+++ b/block/io_uring.c
@@ -218,6 +218,12 @@ end:
     qemu_bh_cancel(s->completion_bh);
 }
 
+/*
+ * called by:
+ *   - block/io_uring.c|271| <<luring_process_completions_and_submit>> ioq_submit(s);
+ *   - block/io_uring.c|324| <<luring_io_unplug>> ioq_submit(s);
+ *   - block/io_uring.c|371| <<luring_do_submit>> ret = ioq_submit(s);
+ */
 static int ioq_submit(LuringState *s)
 {
     int ret = 0;
diff --git a/block/iscsi.c b/block/iscsi.c
index d707d0b35..78a69da77 100644
--- a/block/iscsi.c
+++ b/block/iscsi.c
@@ -70,7 +70,25 @@ typedef struct IscsiLun {
     int block_size;
     uint64_t num_blocks;
     int events;
+    /*
+     * 在以下使用IscsiLun->nop_timer:
+     *   - block/iscsi.c|1523| <<iscsi_nop_timed_event>> timer_mod(iscsilun->nop_timer, qemu_clock_get_ms(QEMU_CLOCK_REALTIME) + NOP_INTERVAL);
+     *   - block/iscsi.c|1643| <<iscsi_detach_aio_context>> if (iscsilun->nop_timer) {
+     *   - block/iscsi.c|1644| <<iscsi_detach_aio_context>> timer_free(iscsilun->nop_timer);
+     *   - block/iscsi.c|1645| <<iscsi_detach_aio_context>> iscsilun->nop_timer = NULL;
+     *   - block/iscsi.c|1662| <<iscsi_attach_aio_context>> iscsilun->nop_timer = aio_timer_new(iscsilun->aio_context,
+     *   - block/iscsi.c|1665| <<iscsi_attach_aio_context>> timer_mod(iscsilun->nop_timer,
+     */
     QEMUTimer *nop_timer;
+    /*
+     * 在以下使用IscsiLun->event_timer:
+     *   - block/iscsi.c|467| <<iscsi_timed_check_events>> timer_mod(iscsilun->event_timer,
+     *   - block/iscsi.c|1647| <<iscsi_detach_aio_context>> if (iscsilun->event_timer) {
+     *   - block/iscsi.c|1648| <<iscsi_detach_aio_context>> timer_free(iscsilun->event_timer);
+     *   - block/iscsi.c|1649| <<iscsi_detach_aio_context>> iscsilun->event_timer = NULL;
+     *   - block/iscsi.c|1670| <<iscsi_attach_aio_context>> iscsilun->event_timer = aio_timer_new(iscsilun->aio_context,
+     *   - block/iscsi.c|1673| <<iscsi_attach_aio_context>> timer_mod(iscsilun->event_timer,
+     */
     QEMUTimer *event_timer;
     QemuMutex mutex;
     struct scsi_inquiry_logical_block_provisioning lbp;
@@ -101,6 +119,13 @@ typedef struct IscsiLun {
     bool lbprz;
     bool dpofua;
     bool has_write_same;
+    /*
+     * 在以下使用IscsiLun->request_timed_out:
+     *   - block/iscsi.c|263| <<iscsi_co_generic_cb>> iTask->iscsilun->request_timed_out = true;
+     *   - block/iscsi.c|384| <<iscsi_timed_check_events>> if (iscsilun->request_timed_out) {
+     *   - block/iscsi.c|385| <<iscsi_timed_check_events>> iscsilun->request_timed_out = false;
+     *   - block/iscsi.c|1428| <<iscsi_nop_timed_event>> iscsilun->request_timed_out = true;
+     */
     bool request_timed_out;
 } IscsiLun;
 
@@ -179,6 +204,10 @@ iscsi_schedule_bh(IscsiAIOCB *acb)
 
 #endif
 
+/*
+ * 在以下使用iscsi_co_generic_bh_cb():
+ *   - block/iscsi.c|379| <<iscsi_co_generic_cb>> replay_bh_schedule_oneshot_event(iTask->iscsilun->aio_context, iscsi_co_generic_bh_cb, iTask);
+ */
 static void iscsi_co_generic_bh_cb(void *opaque)
 {
     struct IscsiTask *iTask = opaque;
@@ -187,6 +216,10 @@ static void iscsi_co_generic_bh_cb(void *opaque)
     aio_co_wake(iTask->co);
 }
 
+/*
+ * 在以下使用iscsi_retry_timer_expired():
+ *   - block/iscsi.c|267| <<iscsi_co_generic_cb>> aio_timer_init(iTask->iscsilun->aio_context, &iTask->retry_timer, QEMU_CLOCK_REALTIME,SCALE_MS, iscsi_retry_timer_expired, iTask);
+ */
 static void iscsi_retry_timer_expired(void *opaque)
 {
     struct IscsiTask *iTask = opaque;
@@ -231,7 +264,70 @@ static int iscsi_translate_sense(struct scsi_sense *sense)
                                sense->ascq & 0xFF);
 }
 
+/*
+ * libiscsi的代码.
+ *
+ * 32 static void
+ * 33 iscsi_scsi_response_cb(struct iscsi_context *iscsi, int status,
+ * 34                        void *command_data _U_, void *private_data)
+ * 35 {
+ * 36         struct iscsi_scsi_cbdata *scsi_cbdata =
+ * 37           (struct iscsi_scsi_cbdata *)private_data;
+ * 38
+ * 39         switch (status) {
+ * 40         case SCSI_STATUS_RESERVATION_CONFLICT:
+ * 41         case SCSI_STATUS_CHECK_CONDITION:
+ * 42         case SCSI_STATUS_GOOD:
+ * 43         case SCSI_STATUS_BUSY:
+ * 44         case SCSI_STATUS_ERROR:
+ * 45         case SCSI_STATUS_CANCELLED:
+ * 46                 scsi_cbdata->callback(iscsi, status, scsi_cbdata->task,
+ * 47                                       scsi_cbdata->private_data);
+ * 48                 return;
+ * 49         default:
+ * 50                 iscsi_set_error(iscsi, "Cant handle  scsi status %d yet.",
+ * 51                                 status);
+ * 52                 scsi_cbdata->callback(iscsi, SCSI_STATUS_ERROR, scsi_cbdata->task,
+ * 53                                       scsi_cbdata->private_data);
+ * 54         }
+ * 55 }
+ */
 /* Called (via iscsi_service) with QemuMutex held.  */
+/*
+ * (gdb) bt
+ * #0  iscsi_co_generic_cb (iscsi=0x55cba77d2570, status=0, command_data=0x55cba77a0740, opaque=0x7f61ea8688c0) at ../block/iscsi.c:239
+ * #1  0x00007f6a6d4dc7af in iscsi_process_scsi_data_in () at /usr/lib64/iscsi/libiscsi.so.2
+ * #2  0x00007f6a6d4db73b in iscsi_process_pdu () at /usr/lib64/iscsi/libiscsi.so.2
+ * #3  0x00007f6a6d4e3a4b in iscsi_service () at /usr/lib64/iscsi/libiscsi.so.2
+ * #4  0x000055cba694566b in iscsi_process_read (arg=0x55cba77d2440) at ../block/iscsi.c:403
+ * #5  0x000055cba6a08f63 in aio_dispatch_handler (ctx=0x55cba7581b10, node=0x55cba77d3220) at ../util/aio-posix.c:369
+ * #6  0x000055cba6a0911c in aio_dispatch_handlers (ctx=0x55cba7581b10) at ../util/aio-posix.c:412
+ * #7  0x000055cba6a09172 in aio_dispatch (ctx=0x55cba7581b10) at ../util/aio-posix.c:422
+ * #8  0x000055cba6a22302 in aio_ctx_dispatch (source=0x55cba7581b10, callback=0x0, user_data=0x0) at ../util/async.c:320
+ * #9  0x00007f6a6dfa6119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #10 0x000055cba6a3400b in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #11 0x000055cba6a34085 in os_host_main_loop_wait (timeout=190000000) at ../util/main-loop.c:320
+ * #12 0x000055cba6a3418a in main_loop_wait (nonblocking=0) at ../util/main-loop.c:596
+ * #13 0x000055cba65962ee in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #14 0x000055cba633c0f2 in qemu_main (argc=28, argv=0x7fff2f77d258, envp=0x0) at ../softmmu/main.c:38
+ * #15 0x000055cba633c124 in main (argc=28, argv=0x7fff2f77d258) at ../softmmu/main.c:47
+ *
+ * called by:
+ *   - block/iscsi.c|647| <<iscsi_co_writev>> iscsi_co_generic_cb, &iTask,
+ *   - block/iscsi.c|653| <<iscsi_co_writev>> iscsi_co_generic_cb, &iTask,
+ *   - block/iscsi.c|660| <<iscsi_co_writev>> iscsi_co_generic_cb, &iTask);
+ *   - block/iscsi.c|665| <<iscsi_co_writev>> iscsi_co_generic_cb, &iTask);
+ *   - block/iscsi.c|743| <<iscsi_co_block_status>> lba, 8 + 16, iscsi_co_generic_cb,
+ *   - block/iscsi.c|879| <<iscsi_co_readv>> iscsi_co_generic_cb, &iTask,
+ *   - block/iscsi.c|886| <<iscsi_co_readv>> iscsi_co_generic_cb, &iTask,
+ *   - block/iscsi.c|893| <<iscsi_co_readv>> iscsi_co_generic_cb, &iTask);
+ *   - block/iscsi.c|899| <<iscsi_co_readv>> iscsi_co_generic_cb, &iTask);
+ *   - block/iscsi.c|942| <<iscsi_co_flush>> 0, iscsi_co_generic_cb, &iTask) == NULL) {
+ *   - block/iscsi.c|1185| <<iscsi_co_pdiscard>> iscsi_co_generic_cb, &iTask) == NULL) {
+ *   - block/iscsi.c|1279| <<iscsi_co_pwrite_zeroes>> 0, 0, iscsi_co_generic_cb, &iTask);
+ *   - block/iscsi.c|1289| <<iscsi_co_pwrite_zeroes>> 0, 0, iscsi_co_generic_cb, &iTask);
+ *   - block/iscsi.c|2392| <<iscsi_co_copy_range_to>> iscsi_task.task, iscsi_co_generic_cb,
+ */
 static void
 iscsi_co_generic_cb(struct iscsi_context *iscsi, int status,
                         void *command_data, void *opaque)
@@ -262,6 +358,9 @@ iscsi_co_generic_cb(struct iscsi_context *iscsi, int status,
                              " (retry #%u in %u ms): %s",
                              iTask->retries, retry_time,
                              iscsi_get_error(iscsi));
+                /*
+		 * 只在此处使用iscsi_retry_timer_expired()
+		 */
                 aio_timer_init(iTask->iscsilun->aio_context,
                                &iTask->retry_timer, QEMU_CLOCK_REALTIME,
                                SCALE_MS, iscsi_retry_timer_expired, iTask);
@@ -351,11 +450,36 @@ static const AIOCBInfo iscsi_aiocb_info = {
 static void iscsi_process_read(void *arg);
 static void iscsi_process_write(void *arg);
 
+/*
+ * 335 int
+ * 336 iscsi_which_events(struct iscsi_context *iscsi)
+ * 337 {
+ * 338         int events = iscsi->is_connected ? POLLIN : POLLOUT;
+ * 339
+ * 340         if (iscsi->outqueue_current != NULL || (iscsi->outqueue != NULL && iscsi_serial32_compare(iscsi->outqueue->cmdsn, iscsi->maxcmdsn) <= 0)) {
+ * 341                 events |= POLLOUT;
+ * 342         }
+ * 343         return events;
+ * 344 }
+ */
 /* Called with QemuMutex held.  */
+/*
+ * called by:
+ *   - block/iscsi.c|435| <<iscsi_timed_check_events>> iscsi_set_events(iscsilun);
+ *   - block/iscsi.c|450| <<iscsi_process_read>> iscsi_set_events(iscsilun);
+ *   - block/iscsi.c|462| <<iscsi_process_write>> iscsi_set_events(iscsilun);
+ *   - block/iscsi.c|650| <<iscsi_co_wait_for_task>> iscsi_set_events(iscsilun);
+ *   - block/iscsi.c|1176| <<iscsi_aio_ioctl>> iscsi_set_events(iscsilun);
+ *   - block/iscsi.c|1481| <<iscsi_nop_timed_event>> iscsi_set_events(iscsilun);
+ *   - block/iscsi.c|1616| <<iscsi_attach_aio_context>> iscsi_set_events(iscsilun);
+ */
 static void
 iscsi_set_events(IscsiLun *iscsilun)
 {
     struct iscsi_context *iscsi = iscsilun->iscsi;
+    /*
+     * 返回POLLIN和POLLOUT的组合
+     */
     int ev = iscsi_which_events(iscsi);
 
     if (ev != iscsilun->events) {
@@ -369,14 +493,51 @@ iscsi_set_events(IscsiLun *iscsilun)
     }
 }
 
+/*
+ * (gdb) bt
+ * #0  0x00007fcdac0c2ccd in poll () at /lib64/libc.so.6
+ * #1  0x00007fcdad152ab9 in event_loop () at /usr/lib64/iscsi/libiscsi.so.2
+ * #2  0x00007fcdad152c28 in iscsi_full_connect_sync () at /usr/lib64/iscsi/libiscsi.so.2
+ * #3  0x00007fcdad145712 in iscsi_reconnect () at /usr/lib64/iscsi/libiscsi.so.2
+ * #4  0x00005562768b15a3 in iscsi_timed_check_events (opaque=0x5562784d9560) at ../block/iscsi.c:382
+ * #5  0x00005562769a610f in timerlist_run_timers (timer_list=0x556278288ec0) at ../util/qemu-timer.c:576
+ * #6  0x00005562769a6265 in timerlistgroup_run_timers (tlg=0x556278288d58) at ../util/qemu-timer.c:615
+ * #7  0x00005562769751a2 in aio_dispatch (ctx=0x556278288ba0) at ../util/aio-posix.c:426
+ * #8  0x000055627698e302 in aio_ctx_dispatch (source=0x556278288ba0, callback=0x0, user_data=0x0) at ../util/async.c:320
+ * #9  0x00007fcdadc14119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #10 0x00005562769a000b in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #11 0x00005562769a0085 in os_host_main_loop_wait (timeout=147000000) at ../util/main-loop.c:320
+ * #12 0x00005562769a018a in main_loop_wait (nonblocking=0) at ../util/main-loop.c:596
+ * #13 0x00005562765022ee in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #14 0x00005562762a80f2 in qemu_main (argc=28, argv=0x7ffd0bd2bd08, envp=0x0) at ../softmmu/main.c:38
+ * #15 0x00005562762a8124 in main (argc=28, argv=0x7ffd0bd2bd08) at ../softmmu/main.c:47
+ */
 static void iscsi_timed_check_events(void *opaque)
 {
     IscsiLun *iscsilun = opaque;
 
     WITH_QEMU_LOCK_GUARD(&iscsilun->mutex) {
+        /*
+	 * 在以下使用iscsi_service():
+	 *   - block/iscsi.c|471| <<iscsi_timed_check_events>> iscsi_service(iscsilun->iscsi, 0);
+	 *   - block/iscsi.c|496| <<iscsi_process_read>> iscsi_service(iscsi, POLLIN);
+	 *   - block/iscsi.c|508| <<iscsi_process_write>> iscsi_service(iscsi, POLLOUT);
+	 *
+	 * Called to process the events when events become available for the iscsi
+	 * file descriptor.
+	 *
+	 * 处理完了每一个request在libiscsi调用iscsi_co_generic_cb()
+	 */
         /* check for timed out requests */
         iscsi_service(iscsilun->iscsi, 0);
 
+        /*
+	 * 在以下使用IscsiLun->request_timed_out:
+         *   - block/iscsi.c|263| <<iscsi_co_generic_cb>> iTask->iscsilun->request_timed_out = true;
+         *   - block/iscsi.c|384| <<iscsi_timed_check_events>> if (iscsilun->request_timed_out) {
+         *   - block/iscsi.c|385| <<iscsi_timed_check_events>> iscsilun->request_timed_out = false;
+         *   - block/iscsi.c|1428| <<iscsi_nop_timed_event>> iscsilun->request_timed_out = true;
+	 */
         if (iscsilun->request_timed_out) {
             iscsilun->request_timed_out = false;
             iscsi_reconnect(iscsilun->iscsi);
@@ -389,6 +550,15 @@ static void iscsi_timed_check_events(void *opaque)
         iscsi_set_events(iscsilun);
     }
 
+    /*
+     * 在以下使用IscsiLun->event_timer:
+     *   - block/iscsi.c|467| <<iscsi_timed_check_events>> timer_mod(iscsilun->event_timer,
+     *   - block/iscsi.c|1647| <<iscsi_detach_aio_context>> if (iscsilun->event_timer) {
+     *   - block/iscsi.c|1648| <<iscsi_detach_aio_context>> timer_free(iscsilun->event_timer);
+     *   - block/iscsi.c|1649| <<iscsi_detach_aio_context>> iscsilun->event_timer = NULL;
+     *   - block/iscsi.c|1670| <<iscsi_attach_aio_context>> iscsilun->event_timer = aio_timer_new(iscsilun->aio_context,
+     *   - block/iscsi.c|1673| <<iscsi_attach_aio_context>> timer_mod(iscsilun->event_timer,
+     */
     timer_mod(iscsilun->event_timer,
               qemu_clock_get_ms(QEMU_CLOCK_REALTIME) + EVENT_INTERVAL);
 }
@@ -400,6 +570,12 @@ iscsi_process_read(void *arg)
     struct iscsi_context *iscsi = iscsilun->iscsi;
 
     qemu_mutex_lock(&iscsilun->mutex);
+    /*
+     * 在以下使用iscsi_service():
+     *   - block/iscsi.c|471| <<iscsi_timed_check_events>> iscsi_service(iscsilun->iscsi, 0);
+     *   - block/iscsi.c|496| <<iscsi_process_read>> iscsi_service(iscsi, POLLIN);
+     *   - block/iscsi.c|508| <<iscsi_process_write>> iscsi_service(iscsi, POLLOUT);
+     */
     iscsi_service(iscsi, POLLIN);
     iscsi_set_events(iscsilun);
     qemu_mutex_unlock(&iscsilun->mutex);
@@ -412,6 +588,12 @@ iscsi_process_write(void *arg)
     struct iscsi_context *iscsi = iscsilun->iscsi;
 
     qemu_mutex_lock(&iscsilun->mutex);
+    /*
+     * 在以下使用iscsi_service():
+     *   - block/iscsi.c|471| <<iscsi_timed_check_events>> iscsi_service(iscsilun->iscsi, 0);
+     *   - block/iscsi.c|496| <<iscsi_process_read>> iscsi_service(iscsi, POLLIN);
+     *   - block/iscsi.c|508| <<iscsi_process_write>> iscsi_service(iscsi, POLLOUT);
+     */
     iscsi_service(iscsi, POLLOUT);
     iscsi_set_events(iscsilun);
     qemu_mutex_unlock(&iscsilun->mutex);
@@ -587,6 +769,16 @@ static inline bool iscsi_allocmap_is_valid(IscsiLun *iscsilun,
                                offset / iscsilun->cluster_size) == size);
 }
 
+/*
+ * called by:
+ *   - block/iscsi.c|662| <<iscsi_co_writev>> iscsi_co_wait_for_task(&iTask, iscsilun);
+ *   - block/iscsi.c|734| <<iscsi_co_block_status>> iscsi_co_wait_for_task(&iTask, iscsilun);
+ *   - block/iscsi.c|896| <<iscsi_co_readv>> iscsi_co_wait_for_task(&iTask, iscsilun);
+ *   - block/iscsi.c|933| <<iscsi_co_flush>> iscsi_co_wait_for_task(&iTask, iscsilun);
+ *   - block/iscsi.c|1176| <<iscsi_co_pdiscard>> iscsi_co_wait_for_task(&iTask, iscsilun);
+ *   - block/iscsi.c|1282| <<iscsi_co_pwrite_zeroes>> iscsi_co_wait_for_task(&iTask, iscsilun);
+ *   - block/iscsi.c|2385| <<iscsi_co_copy_range_to>> iscsi_co_wait_for_task(&iscsi_task, dst_lun);
+ */
 static void coroutine_fn iscsi_co_wait_for_task(IscsiTask *iTask,
                                                 IscsiLun *iscsilun)
 {
@@ -1404,21 +1596,64 @@ static char *get_initiator_name(QemuOpts *opts)
     return iscsi_name;
 }
 
+/*
+ * (gdb) bt
+ * #0  iscsi_nop_timed_event (opaque=0x5562784d9560) at ../block/iscsi.c:1408
+ * #1  0x00005562769a610f in timerlist_run_timers (timer_list=0x556278288ec0) at ../util/qemu-timer.c:576
+ * #2  0x00005562769a6265 in timerlistgroup_run_timers (tlg=0x556278288d58) at ../util/qemu-timer.c:615
+ * #3  0x00005562769751a2 in aio_dispatch (ctx=0x556278288ba0) at ../util/aio-posix.c:426
+ * #4  0x000055627698e302 in aio_ctx_dispatch (source=0x556278288ba0, callback=0x0, user_data=0x0) at ../util/async.c:320
+ * #5  0x00007fcdadc14119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #6  0x00005562769a000b in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #7  0x00005562769a0085 in os_host_main_loop_wait (timeout=493486878) at ../util/main-loop.c:320
+ * #8  0x00005562769a018a in main_loop_wait (nonblocking=0) at ../util/main-loop.c:596
+ * #9  0x00005562765022ee in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #10 0x00005562762a80f2 in qemu_main (argc=28, argv=0x7ffd0bd2bd08, envp=0x0) at ../softmmu/main.c:38
+ * #11 0x00005562762a8124 in main (argc=28, argv=0x7ffd0bd2bd08) at ../softmmu/main.c:47
+ *
+ * called by:
+ *   - block/iscsi.c|1575| <<iscsi_attach_aio_context>> iscsi_nop_timed_event, iscsilun);
+ *
+ * 在iscsi_attach_aio_context()中的使用:
+ * 1661     // Set up a timer for sending out iSCSI NOPs
+ * 1662     iscsilun->nop_timer = aio_timer_new(iscsilun->aio_context,
+ * 1663                                         QEMU_CLOCK_REALTIME, SCALE_MS,
+ * 1664                                         iscsi_nop_timed_event, iscsilun);
+ * 1665     timer_mod(iscsilun->nop_timer,
+ * 1666               qemu_clock_get_ms(QEMU_CLOCK_REALTIME) + NOP_INTERVAL);
+ */
 static void iscsi_nop_timed_event(void *opaque)
 {
     IscsiLun *iscsilun = opaque;
 
     QEMU_LOCK_GUARD(&iscsilun->mutex);
+    /*
+     * 检查有几个iscsi nop还没收到回复
+     */
     if (iscsi_get_nops_in_flight(iscsilun->iscsi) >= MAX_NOP_FAILURES) {
         error_report("iSCSI: NOP timeout. Reconnecting...");
+        /*
+	 * 在以下使用IscsiLun->request_timed_out:
+         *   - block/iscsi.c|263| <<iscsi_co_generic_cb>> iTask->iscsilun->request_timed_out = true;
+         *   - block/iscsi.c|384| <<iscsi_timed_check_events>> if (iscsilun->request_timed_out) {
+         *   - block/iscsi.c|385| <<iscsi_timed_check_events>> iscsilun->request_timed_out = false;
+         *   - block/iscsi.c|1428| <<iscsi_nop_timed_event>> iscsilun->request_timed_out = true;
+	 */
         iscsilun->request_timed_out = true;
     } else if (iscsi_nop_out_async(iscsilun->iscsi, NULL, NULL, 0, NULL) != 0) {
+        /*
+	 * iscsi_nop_out_async()发送nop
+	 */
         error_report("iSCSI: failed to sent NOP-Out. Disabling NOP messages.");
         return;
     }
 
     timer_mod(iscsilun->nop_timer, qemu_clock_get_ms(QEMU_CLOCK_REALTIME) + NOP_INTERVAL);
     iscsi_set_events(iscsilun);
+
+    /*
+     * 在libiscsi的iscsi_create_context()设置了很多debug
+     */
 }
 
 static void iscsi_readcapacity_sync(IscsiLun *iscsilun, Error **errp)
@@ -1555,6 +1790,15 @@ static void iscsi_attach_aio_context(BlockDriverState *bs,
     iscsilun->aio_context = new_context;
     iscsi_set_events(iscsilun);
 
+    /*
+     * 在以下使用IscsiLun->nop_timer:
+     *   - block/iscsi.c|1523| <<iscsi_nop_timed_event>> timer_mod(iscsilun->nop_timer, qemu_clock_get_ms(QEMU_CLOCK_REALTIME) + NOP_INTERVAL);
+     *   - block/iscsi.c|1643| <<iscsi_detach_aio_context>> if (iscsilun->nop_timer) {
+     *   - block/iscsi.c|1644| <<iscsi_detach_aio_context>> timer_free(iscsilun->nop_timer);
+     *   - block/iscsi.c|1645| <<iscsi_detach_aio_context>> iscsilun->nop_timer = NULL;
+     *   - block/iscsi.c|1662| <<iscsi_attach_aio_context>> iscsilun->nop_timer = aio_timer_new(iscsilun->aio_context,
+     *   - block/iscsi.c|1665| <<iscsi_attach_aio_context>> timer_mod(iscsilun->nop_timer,
+     */
     /* Set up a timer for sending out iSCSI NOPs */
     iscsilun->nop_timer = aio_timer_new(iscsilun->aio_context,
                                         QEMU_CLOCK_REALTIME, SCALE_MS,
@@ -1562,6 +1806,15 @@ static void iscsi_attach_aio_context(BlockDriverState *bs,
     timer_mod(iscsilun->nop_timer,
               qemu_clock_get_ms(QEMU_CLOCK_REALTIME) + NOP_INTERVAL);
 
+    /*
+     * 在以下使用IscsiLun->event_timer:
+     *   - block/iscsi.c|467| <<iscsi_timed_check_events>> timer_mod(iscsilun->event_timer,
+     *   - block/iscsi.c|1647| <<iscsi_detach_aio_context>> if (iscsilun->event_timer) {
+     *   - block/iscsi.c|1648| <<iscsi_detach_aio_context>> timer_free(iscsilun->event_timer);
+     *   - block/iscsi.c|1649| <<iscsi_detach_aio_context>> iscsilun->event_timer = NULL;
+     *   - block/iscsi.c|1670| <<iscsi_attach_aio_context>> iscsilun->event_timer = aio_timer_new(iscsilun->aio_context,
+     *   - block/iscsi.c|1673| <<iscsi_attach_aio_context>> timer_mod(iscsilun->event_timer,
+     */
     /* Set up a timer for periodic calls to iscsi_set_events and to
      * scan for command timeout */
     iscsilun->event_timer = aio_timer_new(iscsilun->aio_context,
diff --git a/block/linux-aio.c b/block/linux-aio.c
index d2cfb7f52..8b0ef0b70 100644
--- a/block/linux-aio.c
+++ b/block/linux-aio.c
@@ -75,6 +75,11 @@ static inline ssize_t io_event_ret(struct io_event *ev)
 /*
  * Completes an AIO request.
  */
+/*
+ * called by:
+ *   - block/linux-aio.c|220| <<qemu_laio_process_completions>> qemu_laio_process_completion(laiocb);
+ *   - block/linux-aio.c|334| <<ioq_submit>> qemu_laio_process_completion(aiocb);
+ */
 static void qemu_laio_process_completion(struct qemu_laiocb *laiocb)
 {
     int ret;
@@ -198,6 +203,11 @@ io_getevents_advance_and_peek(io_context_t ctx,
  * can be called again in a nested event loop.  When there are no events left
  * to complete the BH is being canceled.
  */
+/*
+ * called by:
+ *   - block/linux-aio.c|269| <<qemu_laio_process_completions_and_submit>> qemu_laio_process_completions(s);
+ *   - block/linux-aio.c|375| <<ioq_submit>> qemu_laio_process_completions(s);
+ */
 static void qemu_laio_process_completions(LinuxAioState *s)
 {
     struct io_event *events;
@@ -230,6 +240,34 @@ static void qemu_laio_process_completions(LinuxAioState *s)
     s->event_idx = 0;
 }
 
+/*
+ * (gdb) bt
+ * #0  qemu_laio_process_completions_and_submit (s=0x7ffe580f74e0) at ../block/linux-aio.c:235
+ * #1  0x0000555555e21c41 in qemu_laio_completion_cb (e=0x7ffe580f74f0) at ../block/linux-aio.c:256
+ * #2  0x0000555555ee6f68 in aio_dispatch_handler (ctx=0x555556a67590, node=0x7ffe580f7540) at ../util/aio-posix.c:369
+ * #3  0x0000555555ee705c in aio_dispatch_ready_handlers (ctx=0x555556a67590, ready_list=0x7fffef696880) at ../util/aio-posix.c:399
+ * #4  0x0000555555ee7ac6 in aio_poll (ctx=0x555556a67590, blocking=true) at ../util/aio-posix.c:713
+ * #5  0x0000555555d5cb66 in iothread_run (opaque=0x555556a67220) at ../iothread.c:67
+ * #6  0x0000555555eec4de in qemu_thread_start (args=0x555556a67c00) at ../util/qemu-thread-posix.c:504
+ * #7  0x00007ffff55eeea5 in start_thread () at /lib64/libpthread.so.0
+ * #8  0x00007ffff53179fd in clone () at /lib64/libc.so.6
+ *
+ * (gdb) bt
+ * #0  qemu_laio_process_completions_and_submit (s=0x7ffe580f74e0) at ../block/linux-aio.c:235
+ * #1  0x0000555555e21ce1 in qemu_laio_poll_ready (opaque=0x7ffe580f74f0) at ../block/linux-aio.c:274
+ * #2  0x0000555555ee6ef1 in aio_dispatch_handler (ctx=0x555556a67590, node=0x7ffe580f7540) at ../util/aio-posix.c:356
+ * #3  0x0000555555ee705c in aio_dispatch_ready_handlers (ctx=0x555556a67590, ready_list=0x7fffef696880) at ../util/aio-posix.c:399
+ * #4  0x0000555555ee7ac6 in aio_poll (ctx=0x555556a67590, blocking=true) at ../util/aio-posix.c:713
+ * #5  0x0000555555d5cb66 in iothread_run (opaque=0x555556a67220) at ../iothread.c:67
+ * #6  0x0000555555eec4de in qemu_thread_start (args=0x555556a67c00) at ../util/qemu-thread-posix.c:504
+ * #7  0x00007ffff55eeea5 in start_thread () at /lib64/libpthread.so.0
+ * #8  0x00007ffff53179fd in clone () at /lib64/libc.so.6
+ *
+ * called by:
+ *   - block/linux-aio.c|248| <<qemu_laio_completion_bh>> qemu_laio_process_completions_and_submit(s);
+ *   - block/linux-aio.c|256| <<qemu_laio_completion_cb>> qemu_laio_process_completions_and_submit(s);
+ *   - block/linux-aio.c|274| <<qemu_laio_poll_ready>> qemu_laio_process_completions_and_submit(s);
+ */
 static void qemu_laio_process_completions_and_submit(LinuxAioState *s)
 {
     aio_context_acquire(s->aio_context);
@@ -257,6 +295,10 @@ static void qemu_laio_completion_cb(EventNotifier *e)
     }
 }
 
+/*
+ * 在以下使用qemu_laio_poll_cb():
+ *   - block/linux-aio.c|458| <<laio_attach_aio_context>> aio_set_event_notifier(new_context, &s->e, false, qemu_laio_completion_cb, qemu_laio_poll_cb, qemu_laio_poll_ready);
+ */
 static bool qemu_laio_poll_cb(void *opaque)
 {
     EventNotifier *e = opaque;
@@ -283,6 +325,12 @@ static void ioq_init(LaioQueue *io_q)
     io_q->blocked = false;
 }
 
+/*
+ * called by:
+ *   - block/linux-aio.c|245| <<qemu_laio_process_completions_and_submit>> ioq_submit(s);
+ *   - block/linux-aio.c|387| <<laio_io_unplug>> ioq_submit(s);
+ *   - block/linux-aio.c|418| <<laio_do_submit>> ioq_submit(s);
+ */
 static void ioq_submit(LinuxAioState *s)
 {
     int ret, len;
@@ -302,6 +350,9 @@ static void ioq_submit(LinuxAioState *s)
             }
         }
 
+	/*
+	 * 唯一调用io_submit()的地方
+	 */
         ret = io_submit(s->ctx, len, iocbs);
         if (ret == -EAGAIN) {
             break;
@@ -411,6 +462,53 @@ static int laio_do_submit(int fd, struct qemu_laiocb *laiocb, off_t offset,
     return 0;
 }
 
+/*
+ * Thread 3 "IO iothread01" hit Breakpoint 2, laio_co_submit (bs=0x561927f41620, s=0x7f67140f7430, fd=16, offset=414973952, qiov=0x7f6718de2c80, type=1, dev_max_batch=0)
+ *     at ../block/linux-aio.c:417
+ * 417	{
+ * (gdb) bt
+ * #0  laio_co_submit (bs=0x561927f41620, s=0x7f67140f7430, fd=16, offset=414973952, qiov=0x7f6718de2c80, type=1, dev_max_batch=0) at ../block/linux-aio.c:417
+ * #1  0x0000561926e85065 in raw_co_prw (bs=0x561927f41620, offset=414973952, bytes=24576, qiov=0x7f6718de2c80, type=1) at ../block/file-posix.c:2091
+ * #2  0x0000561926e85141 in raw_co_preadv (bs=0x561927f41620, offset=414973952, bytes=24576, qiov=0x7f6718de2c80, flags=0) at ../block/file-posix.c:2116
+ * #3  0x0000561926e102a3 in bdrv_driver_preadv (bs=0x561927f41620, offset=414973952, bytes=24576, qiov=0x7f6718de2c80, qiov_offset=53248, flags=0) at ../block/io.c:1160
+ * #4  0x0000561926e1140b in bdrv_aligned_preadv (child=0x561927f40430, req=0x7f6718de2dd0, offset=414973952, bytes=24576, align=512, qiov=0x7f68a8007a78, qiov_offset=53248, flags=0) at ../block/io.c:1548
+ * #5  0x0000561926e11e42 in bdrv_co_preadv_part (child=0x561927f40430, offset=414973952, bytes=24576, qiov=0x7f68a8007a78, qiov_offset=53248, flags=0) at ../block/io.c:1821
+ * #6  0x0000561926e445d2 in qcow2_co_preadv_task (bs=0x561927f39f50, subc_type=QCOW2_SUBCLUSTER_NORMAL, host_offset=414973952, offset=2218917888, bytes=24576, qiov=0x7f68a8007a78, qiov_offset=53248) at ../block/qcow2.c:2294
+ * #7  0x0000561926e44685 in qcow2_co_preadv_task_entry (task=0x7f68a800f360) at ../block/qcow2.c:2310
+ * #8  0x0000561926df5402 in aio_task_co (opaque=0x7f68a800f360) at ../block/aio_task.c:45
+ * #9  0x0000561926f76ab8 in coroutine_trampoline (i0=-1476375376, i1=32616) at ../util/coroutine-ucontext.c:177
+ * #10 0x00007f68b318c190 in __start_context () at /lib64/libc.so.6
+ * #11 0x00007f68ad13acf0 in  ()
+ * #12 0x0000000000000000 in  ()
+ *
+ *
+ * Thread 3 "IO iothread01" hit Breakpoint 1, laio_co_submit (bs=0x55c3ba450610, s=0x7fdf9c0790c0, fd=16, offset=7490646016, qiov=0x7fe12c008f58, type=2, dev_max_batch=0)
+ *     at ../block/linux-aio.c:417
+ * 417	{
+ * (gdb) bt
+ * #0  laio_co_submit (bs=0x55c3ba450610, s=0x7fdf9c0790c0, fd=16, offset=7490646016, qiov=0x7fe12c008f58, type=2, dev_max_batch=0) at ../block/linux-aio.c:417
+ * #1  0x000055c3b79c2065 in raw_co_prw (bs=0x55c3ba450610, offset=7490646016, bytes=4096, qiov=0x7fe12c008f58, type=2) at ../block/file-posix.c:2091
+ * #2  0x000055c3b79c21a2 in raw_co_pwritev (bs=0x55c3ba450610, offset=7490646016, bytes=4096, qiov=0x7fe12c008f58, flags=0) at ../block/file-posix.c:2124
+ * #3  0x000055c3b794d616 in bdrv_driver_pwritev (bs=0x55c3ba450610, offset=7490646016, bytes=4096, qiov=0x7fe12c008f58, qiov_offset=0, flags=0) at ../block/io.c:1233
+ * #4  0x000055c3b794fc65 in bdrv_aligned_pwritev (child=0x55c3ba456fe0, req=0x7fdf8a8e8940, offset=7490646016, bytes=4096, align=512, qiov=0x7fe12c008f58, qiov_offset=0, flags=0) at ../block/io.c:2097
+ * #5  0x000055c3b795056e in bdrv_co_pwritev_part (child=0x55c3ba456fe0, offset=7490646016, bytes=4096, qiov=0x7fe12c008f58, qiov_offset=0, flags=0) at ../block/io.c:2289
+ * #6  0x000055c3b7981f08 in qcow2_co_pwritev_task (bs=0x55c3ba448f40, host_offset=7490646016, offset=4810682368, bytes=4096, qiov=0x7fe12c008f58, qiov_offset=0, l2meta=0x0) at ../block/qcow2.c:2567
+ * #7  0x000055c3b7982036 in qcow2_co_pwritev_task_entry (task=0x7fdf8a8e8b40) at ../block/qcow2.c:2597
+ * #8  0x000055c3b79813d8 in qcow2_add_task (bs=0x55c3ba448f40, pool=0x0, func=0x55c3b7981fab <qcow2_co_pwritev_task_entry>, subcluster_type=QCOW2_SUBCLUSTER_UNALLOCATED_PLAIN, host_offset=7490646016, offset=4810682368, bytes=4096, qiov=0x7fe12c008f58, qiov_offset=0, l2meta=0x0) at ../block/qcow2.c:2252
+ * #9  0x000055c3b798220b in qcow2_co_pwritev_part (bs=0x55c3ba448f40, offset=4810682368, bytes=4096, qiov=0x7fe12c008f58, qiov_offset=0, flags=0) at ../block/qcow2.c:2648
+ * #10 0x000055c3b794d578 in bdrv_driver_pwritev (bs=0x55c3ba448f40, offset=4810682368, bytes=4096, qiov=0x7fe12c008f58, qiov_offset=0, flags=0) at ../block/io.c:1221
+ * #11 0x000055c3b794fc65 in bdrv_aligned_pwritev (child=0x55c3ba455bc0, req=0x7fdf8a8e8e00, offset=4810682368, bytes=4096, align=1, qiov=0x7fe12c008f58, qiov_offset=0, flags=0) at ../block/io.c:2097
+ * #12 0x000055c3b795056e in bdrv_co_pwritev_part (child=0x55c3ba455bc0, offset=4810682368, bytes=4096, qiov=0x7fe12c008f58, qiov_offset=0, flags=0) at ../block/io.c:2289
+ * #13 0x000055c3b793c2b8 in blk_co_do_pwritev_part (blk=0x55c3ba448bf0, offset=4810682368, bytes=4096, qiov=0x7fe12c008f58, qiov_offset=0, flags=0) at ../block/block-backend.c:1388
+ * #14 0x000055c3b793c87f in blk_aio_write_entry (opaque=0x7fe12c009be0) at ../block/block-backend.c:1568
+ * #15 0x000055c3b7ab3ab8 in coroutine_trampoline (i0=738215856, i1=32737) at ../util/coroutine-ucontext.c:177
+ * #16 0x00007fe138c0b190 in __start_context () at /lib64/libc.so.6
+ * #17 0x00007fe132bb9cf0 in  ()
+ * #18 0x0000000000000000 in  ()
+ *
+ * called by:
+ *   - block/file-posix.c|2099| <<raw_co_prw>> return laio_co_submit(bs, aio, s->fd, offset, qiov, type,
+ */
 int coroutine_fn laio_co_submit(BlockDriverState *bs, LinuxAioState *s, int fd,
                                 uint64_t offset, QEMUIOVector *qiov, int type,
                                 uint64_t dev_max_batch)
@@ -443,6 +541,10 @@ void laio_detach_aio_context(LinuxAioState *s, AioContext *old_context)
     s->aio_context = NULL;
 }
 
+/*
+ * called by:
+ *   - util/async.c|410| <<aio_setup_linux_aio>> laio_attach_aio_context(ctx->linux_aio, ctx);
+ */
 void laio_attach_aio_context(LinuxAioState *s, AioContext *new_context)
 {
     s->aio_context = new_context;
@@ -453,6 +555,10 @@ void laio_attach_aio_context(LinuxAioState *s, AioContext *new_context)
                            qemu_laio_poll_ready);
 }
 
+/*
+ * called by:
+ *   - util/async.c|408| <<aio_setup_linux_aio>> ctx->linux_aio = laio_init(errp);
+ */
 LinuxAioState *laio_init(Error **errp)
 {
     int rc;
diff --git a/block/mirror.c b/block/mirror.c
index 3c4ab1159..f9778d6c2 100644
--- a/block/mirror.c
+++ b/block/mirror.c
@@ -427,6 +427,17 @@ static void coroutine_fn mirror_co_discard(void *opaque)
     mirror_write_complete(op, ret);
 }
 
+/*
+ * (gdb) bt
+ * #0  mirror_perform (s=0x555556b0b1f0, offset=5242880, bytes=1048576, mirror_method=MIRROR_METHOD_COPY) at ../block/mirror.c:432
+ * #1  0x0000555555dabc1d in mirror_iteration (s=0x555556b0b1f0) at ../block/mirror.c:593
+ * #2  0x0000555555dace9a in mirror_run (job=0x555556b0b1f0, errp=0x555556b0b2a8) at ../block/mirror.c:1027
+ * #3  0x0000555555d78099 in job_co_entry (opaque=0x555556b0b1f0) at ../job.c:965
+ * #4  0x0000555555f09ab8 in coroutine_trampoline (i0=1342197936, i1=32766) at ../util/coroutine-ucontext.c:177
+ * #5  0x00007ffff5043190 in __start_context () at /lib64/libc.so.6
+ * #6  0x00007fffec903a30 in  ()
+ * #7  0x0000000000000000 in  ()
+ */
 static unsigned mirror_perform(MirrorBlockJob *s, int64_t offset,
                                unsigned bytes, MirrorMethod mirror_method)
 {
@@ -473,6 +484,10 @@ static unsigned mirror_perform(MirrorBlockJob *s, int64_t offset,
     return bytes_handled;
 }
 
+/*
+ * called by:
+ *   - block/mirror.c|1043| <<mirror_run>> delay_ns = mirror_iteration(s);
+ */
 static uint64_t coroutine_fn mirror_iteration(MirrorBlockJob *s)
 {
     BlockDriverState *source = s->mirror_top_bs->backing->bs;
@@ -644,6 +659,11 @@ static void coroutine_fn mirror_wait_for_all_io(MirrorBlockJob *s)
  * for .prepare, returns 0 on success and -errno on failure.
  * for .abort cases, denoted by abort = true, MUST return 0.
  */
+/*
+ * called by:
+ *   - block/mirror.c|788| <<mirror_prepare>> return mirror_exit_common(job);
+ *   - block/mirror.c|793| <<mirror_abort>> int ret = mirror_exit_common(job);
+ */
 static int mirror_exit_common(Job *job)
 {
     MirrorBlockJob *s = container_of(job, MirrorBlockJob, common.job);
@@ -1235,6 +1255,10 @@ static const BlockJobDriver commit_active_job_driver = {
     .drained_poll           = mirror_drained_poll,
 };
 
+/*
+ * called by:
+ *   - block/mirror.c|1465| <<bdrv_mirror_top_do_write>> do_sync_target_write(s->job, method, offset, bytes, qiov, flags);
+ */
 static void coroutine_fn
 do_sync_target_write(MirrorBlockJob *job, MirrorMethod method,
                      uint64_t offset, uint64_t bytes,
@@ -1413,6 +1437,9 @@ static int coroutine_fn bdrv_mirror_top_do_write(BlockDriverState *bs,
     int ret = 0;
     bool copy_to_target;
 
+    /*
+     * copy mode可以是MIRROR_COPY_MODE_BACKGROUND
+     */
     copy_to_target = s->job->ret >= 0 &&
                      !job_is_cancelled(&s->job->common.job) &&
                      s->job->copy_mode == MIRROR_COPY_MODE_WRITE_BLOCKING;
@@ -1453,9 +1480,31 @@ out:
     return ret;
 }
 
+/*
+ * (gdb) bt
+ * #0  bdrv_mirror_top_pwritev (bs=0x55cb1a64d410, offset=279934976, bytes=27136, qiov=0x7f588001f268, flags=0) at ../block/mirror.c:1458
+ * #1  0x000055cb18ac433e in bdrv_driver_pwritev (bs=0x55cb1a64d410, offset=279934976, bytes=27136, qiov=0x7f588001f268, qiov_offset=0, flags=0) at ../block/io.c:1233
+ * #2  0x000055cb18ac698d in bdrv_aligned_pwritev (child=0x55cb1a811fb0, req=0x7f55c85cce00, offset=279934976, bytes=27136, align=1, qiov=0x7f588001f268, qiov_offset=0, flags=0) at ../block/io.c:2097
+ * #3  0x000055cb18ac7296 in bdrv_co_pwritev_part (child=0x55cb1a811fb0, offset=279934976, bytes=27136, qiov=0x7f588001f268, qiov_offset=0, flags=0) at ../block/io.c:2289
+ * #4  0x000055cb18ab2fe0 in blk_co_do_pwritev_part (blk=0x55cb1a811c60, offset=279934976, bytes=27136, qiov=0x7f588001f268, qiov_offset=0, flags=0) at ../block/block-backend.c:1388
+ * #5  0x000055cb18ab35a7 in blk_aio_write_entry (opaque=0x7f588001e8b0) at ../block/block-backend.c:1568
+ * #6  0x000055cb18c24abd in coroutine_trampoline (i0=-2147322768, i1=32600) at ../util/coroutine-ucontext.c:177
+ * #7  0x00007f588c7e0190 in __start_context () at /lib64/libc.so.6
+ * #8  0x00007f5886c14cf0 in  ()
+ * #9  0x0000000000000000 in  ()
+ *
+ * BlockDriver bdrv_mirror_top.bdrv_co_pwritev = bdrv_mirror_top_pwritev()
+ */
 static int coroutine_fn bdrv_mirror_top_pwritev(BlockDriverState *bs,
     int64_t offset, int64_t bytes, QEMUIOVector *qiov, BdrvRequestFlags flags)
 {
+    /*
+     * typedef struct MirrorBDSOpaque {
+     *     MirrorBlockJob *job;
+     *     bool stop;
+     *     bool is_commit;
+     * } MirrorBDSOpaque;
+     */
     MirrorBDSOpaque *s = bs->opaque;
     QEMUIOVector bounce_qiov;
     void *bounce_buf;
@@ -1580,6 +1629,13 @@ static BlockDriver bdrv_mirror_top = {
     .is_filter                  = true,
 };
 
+/*
+ * called by:
+ *   - block/mirror.c|1900| <<mirror_start>> mirror_start_job(job_id, bs, creation_flags, target, replaces,
+ *   - block/mirror.c|1927| <<commit_active_start>> job = mirror_start_job(
+ *
+ * target算是base吧
+ */
 static BlockJob *mirror_start_job(
                              const char *job_id, BlockDriverState *bs,
                              int creation_flags, BlockDriverState *target,
@@ -1646,6 +1702,13 @@ static BlockJob *mirror_start_job(
     mirror_top_bs->supported_write_flags = BDRV_REQ_WRITE_UNCHANGED;
     mirror_top_bs->supported_zero_flags = BDRV_REQ_WRITE_UNCHANGED |
                                           BDRV_REQ_NO_FALLBACK;
+    /*
+     * typedef struct MirrorBDSOpaque {
+     *     MirrorBlockJob *job;
+     *     bool stop;
+     *     bool is_commit;
+     * } MirrorBDSOpaque;
+     */
     bs_opaque = g_new0(MirrorBDSOpaque, 1);
     mirror_top_bs->opaque = bs_opaque;
 
@@ -1851,6 +1914,10 @@ fail:
     return NULL;
 }
 
+/*
+ * called by:
+ *   - blockdev.c|3152| <<blockdev_mirror_common>> mirror_start(job_id, bs, target,
+ */
 void mirror_start(const char *job_id, BlockDriverState *bs,
                   BlockDriverState *target, const char *replaces,
                   int creation_flags, int64_t speed,
@@ -1882,6 +1949,12 @@ void mirror_start(const char *job_id, BlockDriverState *bs,
                      filter_node_name, true, copy_mode, errp);
 }
 
+/*
+ * called by:
+ *   - block/replication.c|740| <<replication_stop>> s->commit_job = commit_active_start(
+ *   - blockdev.c|2846| <<qmp_block_commit>> commit_active_start(job_id, top_bs, base_bs, job_flags, speed, on_error,
+ *   - qemu-img.c|1070| <<img_commit>> commit_active_start("commit", bs, base_bs, JOB_DEFAULT, rate_limit,
+ */
 BlockJob *commit_active_start(const char *job_id, BlockDriverState *bs,
                               BlockDriverState *base, int creation_flags,
                               int64_t speed, BlockdevOnError on_error,
@@ -1902,6 +1975,13 @@ BlockJob *commit_active_start(const char *job_id, BlockDriverState *bs,
         }
     }
 
+    /*
+     * 在以下使用MIRROR_COPY_MODE_BACKGROUND:
+     *   - block/mirror.c|1065| <<mirror_run>> if (s->copy_mode != MIRROR_COPY_MODE_BACKGROUND) {
+     *   - block/mirror.c|1974| <<commit_active_start>> filter_node_name, false, MIRROR_COPY_MODE_BACKGROUND,
+     *   - blockdev.c|3081| <<blockdev_mirror_common>> copy_mode = MIRROR_COPY_MODE_BACKGROUND;
+     *   - tests/unit/test-block-iothread.c|758| <<test_propagate_mirror>> false, "filter_node", MIRROR_COPY_MODE_BACKGROUND,
+     */
     job = mirror_start_job(
                      job_id, bs, creation_flags, base, NULL, speed, 0, 0,
                      MIRROR_LEAVE_BACKING_CHAIN, false,
diff --git a/block/qcow2-cluster.c b/block/qcow2-cluster.c
index fd32316d6..223233091 100644
--- a/block/qcow2-cluster.c
+++ b/block/qcow2-cluster.c
@@ -582,6 +582,15 @@ static int coroutine_fn do_perform_cow_write(BlockDriverState *bs,
  *
  * Returns 0 on success, -errno in error cases.
  */
+/*
+ * called by:
+ *   - block/qcow2.c|2096| <<qcow2_co_block_status>> ret = qcow2_get_host_offset(bs, offset, &bytes, &host_offset, &type);
+ *   - block/qcow2.c|2361| <<qcow2_co_preadv_part>> ret = qcow2_get_host_offset(bs, offset, &cur_bytes,
+ *   - block/qcow2.c|4022| <<qcow2_co_pwrite_zeroes>> ret = qcow2_get_host_offset(bs, offset, &nr, &off, &type);
+ *   - block/qcow2.c|4096| <<qcow2_co_copy_range_from>> ret = qcow2_get_host_offset(bs, src_offset, &cur_bytes,
+ *   - block/qcow2.c|5343| <<qcow2_has_compressed_clusters>> ret = qcow2_get_host_offset(bs, offset, &cur_bytes, &host_offset,
+ *   - block/qcow2.h|908| <<qcow2_signal_corruption>> int qcow2_get_host_offset(BlockDriverState *bs, uint64_t offset,
+ */
 int qcow2_get_host_offset(BlockDriverState *bs, uint64_t offset,
                           unsigned int *bytes, uint64_t *host_offset,
                           QCow2SubclusterType *subcluster_type)
diff --git a/block/qcow2.c b/block/qcow2.c
index c6c6692fb..97b896152 100644
--- a/block/qcow2.c
+++ b/block/qcow2.c
@@ -2217,6 +2217,12 @@ typedef struct Qcow2AioTask {
 } Qcow2AioTask;
 
 static coroutine_fn int qcow2_co_preadv_task_entry(AioTask *task);
+/*
+ * called by:
+ *   - block/qcow2.c|2354| <<qcow2_co_preadv_part>> ret = qcow2_add_task(bs, aio, qcow2_co_preadv_task_entry, type,
+ *   - block/qcow2.c|2648| <<qcow2_co_pwritev_part>> ret = qcow2_add_task(bs, aio, qcow2_co_pwritev_task_entry, 0,
+ *   - block/qcow2.c|4693| <<qcow2_co_pwritev_compressed_part>> ret = qcow2_add_task(bs, aio, qcow2_co_pwritev_compressed_task_entry,
+ */
 static coroutine_fn int qcow2_add_task(BlockDriverState *bs,
                                        AioTaskPool *pool,
                                        AioTaskFunc func,
@@ -2257,6 +2263,10 @@ static coroutine_fn int qcow2_add_task(BlockDriverState *bs,
     return 0;
 }
 
+/*
+ * called by:
+ *   - block/qcow2.c|2316| <<qcow2_co_preadv_task_entry>> return qcow2_co_preadv_task(t->bs, t->subcluster_type,
+ */
 static coroutine_fn int qcow2_co_preadv_task(BlockDriverState *bs,
                                              QCow2SubclusterType subc_type,
                                              uint64_t host_offset,
@@ -2277,6 +2287,18 @@ static coroutine_fn int qcow2_co_preadv_task(BlockDriverState *bs,
         assert(bs->backing); /* otherwise handled in qcow2_co_preadv_part */
 
         BLKDBG_EVENT(bs->file, BLKDBG_READ_BACKING_AIO);
+        /*
+	 * called by:
+	 *   - block/block-backend.c|1331| <<blk_co_do_preadv_part>> ret = bdrv_co_preadv_part(blk->root, offset, bytes, qiov, qiov_offset,
+	 *   - block/copy-before-write.c|275| <<cbw_co_preadv_snapshot>> ret = bdrv_co_preadv_part(file, offset, cur_bytes,
+	 *   - block/copy-on-read.c|142| <<cor_co_preadv_part>> return bdrv_co_preadv_part(bs->file, offset, bytes, qiov, qiov_offset,
+	 *   - block/copy-on-read.c|167| <<cor_co_preadv_part>> ret = bdrv_co_preadv_part(bs->file, offset, n, qiov, qiov_offset,
+	 *   - block/filter-compress.c|71| <<compress_co_preadv_part>> return bdrv_co_preadv_part(bs->file, offset, bytes, qiov, qiov_offset,
+	 *   - block/io.c|1804| <<bdrv_co_preadv>> return bdrv_co_preadv_part(child, offset, bytes, qiov, 0, flags);
+	 *   - block/preallocate.c|233| <<preallocate_co_preadv_part>> return bdrv_co_preadv_part(bs->file, offset, bytes, qiov, qiov_offset,
+	 *   - block/qcow2.c|2290| <<qcow2_co_preadv_task>> return bdrv_co_preadv_part(bs->backing, offset, bytes,
+	 *   - block/qcow2.c|2308| <<qcow2_co_preadv_task>> return bdrv_co_preadv_part(s->data_file, host_offset,
+	 */
         return bdrv_co_preadv_part(bs->backing, offset, bytes,
                                    qiov, qiov_offset, 0);
 
@@ -2291,6 +2313,10 @@ static coroutine_fn int qcow2_co_preadv_task(BlockDriverState *bs,
         }
 
         BLKDBG_EVENT(bs->file, BLKDBG_READ_AIO);
+	/*
+	 * BDRVQcow2State:
+	 * -> BdrvChild *data_file;
+	 */
         return bdrv_co_preadv_part(s->data_file, host_offset,
                                    bytes, qiov, qiov_offset, 0);
 
@@ -2301,6 +2327,11 @@ static coroutine_fn int qcow2_co_preadv_task(BlockDriverState *bs,
     g_assert_not_reached();
 }
 
+/*
+ * called by:
+ *   - block/qcow2.c|2253| <<qcow2_add_task>> func == qcow2_co_preadv_task_entry ? "read" : "write",
+ *   - block/qcow2.c|2381| <<qcow2_co_preadv_part>> ret = qcow2_add_task(bs, aio, qcow2_co_preadv_task_entry, type,
+ */
 static coroutine_fn int qcow2_co_preadv_task_entry(AioTask *task)
 {
     Qcow2AioTask *t = container_of(task, Qcow2AioTask, task);
@@ -2312,6 +2343,24 @@ static coroutine_fn int qcow2_co_preadv_task_entry(AioTask *task)
                                 t->qiov, t->qiov_offset);
 }
 
+/*
+ * Thread 3 "IO iothread01" hit Breakpoint 1, qcow2_co_preadv_part (bs=0x556b47200d40, offset=4811128832, bytes=4096, qiov=0x7fbc540096a8, qiov_offset=0, flags=0) at ../block/qcow2.c:2320
+ * 2320	{
+ * (gdb) bt
+ * #0  qcow2_co_preadv_part (bs=0x556b47200d40, offset=4811128832, bytes=4096, qiov=0x7fbc540096a8, qiov_offset=0, flags=0) at ../block/qcow2.c:2320
+ * #1  0x0000556b45012226 in bdrv_driver_preadv (bs=0x556b47200d40, offset=4811128832, bytes=4096, qiov=0x7fbc540096a8, qiov_offset=0, flags=0) at ../block/io.c:1150
+ * #2  0x0000556b4501340b in bdrv_aligned_preadv (child=0x556b4720da20, req=0x7fbaa6df4e00, offset=4811128832, bytes=4096, align=1, qiov=0x7fbc540096a8, qiov_offset=0, flags=0)
+ *     at ../block/io.c:1548
+ * #3  0x0000556b45013e42 in bdrv_co_preadv_part (child=0x556b4720da20, offset=4811128832, bytes=4096, qiov=0x7fbc540096a8, qiov_offset=0, flags=0) at ../block/io.c:1821
+ * #4  0x0000556b4500105b in blk_co_do_preadv_part (blk=0x556b472009f0, offset=4811128832, bytes=4096, qiov=0x7fbc540096a8, qiov_offset=0, flags=0) at ../block/block-backend.c:1311
+ * #5  0x0000556b450017cf in blk_aio_read_entry (opaque=0x7fbc5400bfc0) at ../block/block-backend.c:1556
+ * #6  0x0000556b45178ab8 in coroutine_trampoline (i0=1409340320, i1=32700) at ../util/coroutine-ucontext.c:177
+ * #7  0x00007fbc5f21e190 in __start_context () at /lib64/libc.so.6
+ * #8  0x00007fbc591cccf0 in  ()
+ * #9  0x0000000000000000 in  ()
+ *
+ * BlockDriver bdrv_qcow2.bdrv_co_preadv_part = qcow2_co_preadv_part()
+ */
 static coroutine_fn int qcow2_co_preadv_part(BlockDriverState *bs,
                                              int64_t offset, int64_t bytes,
                                              QEMUIOVector *qiov,
@@ -2351,6 +2400,9 @@ static coroutine_fn int qcow2_co_preadv_part(BlockDriverState *bs,
             if (!aio && cur_bytes != bytes) {
                 aio = aio_task_pool_new(QCOW2_MAX_WORKERS);
             }
+            /*
+	     * AioTaskPool *aio = NULL;
+	     */
             ret = qcow2_add_task(bs, aio, qcow2_co_preadv_task_entry, type,
                                  host_offset, offset, cur_bytes,
                                  qiov, qiov_offset, NULL);
diff --git a/block/raw-format.c b/block/raw-format.c
index 69fd650ea..982a153a5 100644
--- a/block/raw-format.c
+++ b/block/raw-format.c
@@ -265,6 +265,10 @@ static int coroutine_fn raw_co_pwritev(BlockDriverState *bs, int64_t offset,
         goto fail;
     }
 
+    /*
+     * BlockDriverState *bs:
+     * -> BdrvChild *file;
+     */
     BLKDBG_EVENT(bs->file, BLKDBG_WRITE_AIO);
     ret = bdrv_co_pwritev(bs->file, offset, bytes, qiov, flags);
 
diff --git a/block/snapshot.c b/block/snapshot.c
index d6f53c306..4876cd7a6 100644
--- a/block/snapshot.c
+++ b/block/snapshot.c
@@ -219,6 +219,15 @@ int bdrv_can_snapshot(BlockDriverState *bs)
     return 1;
 }
 
+/*
+ * called by:
+ *   - block/snapshot.c|234| <<bdrv_snapshot_create>> return drv->bdrv_snapshot_create(bs, sn_info);
+ *   - block/snapshot.c|237| <<bdrv_snapshot_create>> return bdrv_snapshot_create(fallback_bs, sn_info);
+ *   - block/snapshot.c|706| <<bdrv_all_create_snapshot>> ret = bdrv_snapshot_create(bs, sn);
+ *   - block/snapshot.c|709| <<bdrv_all_create_snapshot>> ret = bdrv_snapshot_create(bs, sn);
+ *   - blockdev.c|1362| <<internal_snapshot_prepare>> ret1 = bdrv_snapshot_create(bs, sn);
+ *   - qemu-img.c|3418| <<img_snapshot>> ret = bdrv_snapshot_create(bs, &sn);
+ */
 int bdrv_snapshot_create(BlockDriverState *bs,
                          QEMUSnapshotInfo *sn_info)
 {
diff --git a/blockdev.c b/blockdev.c
index 9230888e3..943739f3b 100644
--- a/blockdev.c
+++ b/blockdev.c
@@ -1042,6 +1042,27 @@ static void blockdev_do_action(TransactionAction *action, Error **errp)
     qmp_transaction(&list, false, NULL, errp);
 }
 
+/*
+ * blockdev-snapshot-sync node-name=drive01 snapshot-file=/tmp/overlay01.qcow2 snapshot-node-name=over01
+ *
+ * (gdb) bt
+ * #0  qmp_blockdev_snapshot_sync (has_device=false, device=0x0, has_node_name=true, node_name=0x556c8fb16a90 "drive01",
+ *     snapshot_file=0x556c8fbf3be0 "/tmp/overlay01.qcow2", has_snapshot_node_name=true, snapshot_node_name=0x556c8fb93fe0 "over01",
+ *     has_format=false, format=0x0, has_mode=false, mode=NEW_IMAGE_MODE_EXISTING, errp=0x7ffccc4ddf18) at ../blockdev.c:1052
+ * #1  0x0000556c8d20945a in qmp_marshal_blockdev_snapshot_sync (args=0x7f2d60003ad0, ret=0x7f2d7d430d98, errp=0x7f2d7d430d90) at qapi/qapi-commands-block-core.c:280
+ * #2  0x0000556c8d2814fb in do_qmp_dispatch_bh (opaque=0x7f2d7d430e30) at ../qapi/qmp-dispatch.c:128
+ * #3  0x0000556c8d2a6dcc in aio_bh_call (bh=0x556c90235f30) at ../util/async.c:150
+ * #4  0x0000556c8d2a6ed6 in aio_bh_poll (ctx=0x556c8f904d40) at ../util/async.c:178
+ * #5  0x0000556c8d28e16b in aio_dispatch (ctx=0x556c8f904d40) at ../util/aio-posix.c:421
+ * #6  0x0000556c8d2a7307 in aio_ctx_dispatch (source=0x556c8f904d40, callback=0x0, user_data=0x0) at ../util/async.c:320
+ * #7  0x00007f2d7c09e119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #8  0x0000556c8d2b9010 in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #9  0x0000556c8d2b908a in os_host_main_loop_wait (timeout=0) at ../util/main-loop.c:320
+ * #10 0x0000556c8d2b918f in main_loop_wait (nonblocking=0) at ../util/main-loop.c:596
+ * #11 0x0000556c8ce2105e in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #12 0x0000556c8cbc6e62 in qemu_main (argc=32, argv=0x7ffccc4de388, envp=0x0) at ../softmmu/main.c:38
+ * #13 0x0000556c8cbc6e94 in main (argc=32, argv=0x7ffccc4de388) at ../softmmu/main.c:47
+ */
 void qmp_blockdev_snapshot_sync(bool has_device, const char *device,
                                 bool has_node_name, const char *node_name,
                                 const char *snapshot_file,
@@ -1406,6 +1427,28 @@ typedef struct ExternalSnapshotState {
     bool overlay_appended;
 } ExternalSnapshotState;
 
+/*
+ * blockdev-snapshot-sync node-name=drive01 snapshot-file=/tmp/overlay01.qcow2 snapshot-node-name=over01
+ *
+ * (gdb) bt
+ * #0  qmp_blockdev_snapshot_sync (has_device=false, device=0x0, has_node_name=true, node_name=0x556c8fb16a90 "drive01",
+ *     snapshot_file=0x556c8fbf3be0 "/tmp/overlay01.qcow2", has_snapshot_node_name=true, snapshot_node_name=0x556c8fb93fe0 "over01",
+ *     has_format=false, format=0x0, has_mode=false, mode=NEW_IMAGE_MODE_EXISTING, errp=0x7ffccc4ddf18) at ../blockdev.c:1052
+ * #1  0x0000556c8d20945a in qmp_marshal_blockdev_snapshot_sync (args=0x7f2d60003ad0, ret=0x7f2d7d430d98, errp=0x7f2d7d430d90) at qapi/qapi-commands-block-core.c:280
+ * #2  0x0000556c8d2814fb in do_qmp_dispatch_bh (opaque=0x7f2d7d430e30) at ../qapi/qmp-dispatch.c:128
+ * #3  0x0000556c8d2a6dcc in aio_bh_call (bh=0x556c90235f30) at ../util/async.c:150
+ * #4  0x0000556c8d2a6ed6 in aio_bh_poll (ctx=0x556c8f904d40) at ../util/async.c:178
+ * #5  0x0000556c8d28e16b in aio_dispatch (ctx=0x556c8f904d40) at ../util/aio-posix.c:421
+ * #6  0x0000556c8d2a7307 in aio_ctx_dispatch (source=0x556c8f904d40, callback=0x0, user_data=0x0) at ../util/async.c:320
+ * #7  0x00007f2d7c09e119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #8  0x0000556c8d2b9010 in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #9  0x0000556c8d2b908a in os_host_main_loop_wait (timeout=0) at ../util/main-loop.c:320
+ * #10 0x0000556c8d2b918f in main_loop_wait (nonblocking=0) at ../util/main-loop.c:596
+ * #11 0x0000556c8ce2105e in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #12 0x0000556c8cbc6e62 in qemu_main (argc=32, argv=0x7ffccc4de388, envp=0x0) at ../softmmu/main.c:38
+ * #13 0x0000556c8cbc6e94 in main (argc=32, argv=0x7ffccc4de388) at ../softmmu/main.c:47
+ */
+
 static void external_snapshot_prepare(BlkActionState *common,
                                       Error **errp)
 {
@@ -1440,6 +1483,22 @@ static void external_snapshot_prepare(BlkActionState *common,
         break;
     case TRANSACTION_ACTION_KIND_BLOCKDEV_SNAPSHOT_SYNC:
         {
+            /*
+	     * qmp_blockdev_snapshot_sync()的data的一个例子
+	     * BlockdevSnapshotSync snapshot = {
+             *     .has_device = has_device,
+	     *     .device = (char *) device,
+	     *     .has_node_name = has_node_name,
+	     *     .node_name = (char *) node_name,
+	     *     .snapshot_file = (char *) snapshot_file,
+	     *     .has_snapshot_node_name = has_snapshot_node_name,
+	     *     .snapshot_node_name = (char *) snapshot_node_name,
+	     *     .has_format = has_format,
+	     *     .format = (char *) format,
+	     *     .has_mode = has_mode,
+	     *     .mode = mode,
+	     * };
+	     */
             BlockdevSnapshotSync *s = action->u.blockdev_snapshot_sync.data;
             device = s->has_device ? s->device : NULL;
             node_name = s->has_node_name ? s->node_name : NULL;
@@ -1456,6 +1515,9 @@ static void external_snapshot_prepare(BlkActionState *common,
         return;
     }
 
+    /*
+     * ExternalSnapshotState *state
+     */
     state->old_bs = bdrv_lookup_bs(device, node_name, errp);
     if (!state->old_bs) {
         return;
@@ -1532,6 +1594,9 @@ static void external_snapshot_prepare(BlkActionState *common,
         qdict_put_str(options, "driver", format);
     }
 
+    /*
+     * 返回BlockDriverState
+     */
     state->new_bs = bdrv_open(new_image_file, snapshot_ref, options, flags,
                               errp);
     /* We will manually add the backing_hd field to the bs later */
@@ -1565,6 +1630,18 @@ static void external_snapshot_prepare(BlkActionState *common,
         goto out;
     }
 
+    /*
+     * Add new bs contents at the top of an image chain while the chain is
+     * live, while keeping required fields on the top layer.
+     *
+     * This will modify the BlockDriverState fields, and swap contents
+     * between bs_new and bs_top. Both bs_new and bs_top are modified.
+     *
+     * bs_new must not be attached to a BlockBackend and must not have backing
+     * child.
+     *
+     * This function does not create any image files.
+     */
     ret = bdrv_append(state->new_bs, state->old_bs, errp);
     if (ret < 0) {
         goto out;
@@ -2721,6 +2798,9 @@ void qmp_block_commit(bool has_job_id, const char *job_id, const char *device,
 
     assert(bdrv_get_aio_context(base_bs) == aio_context);
 
+    /*
+     * BlockDriverState *base_bs, *top_bs;
+     */
     for (iter = top_bs; iter != bdrv_filter_or_cow_bs(base_bs);
          iter = bdrv_filter_or_cow_bs(iter))
     {
@@ -2947,6 +3027,11 @@ void qmp_blockdev_backup(BlockdevBackup *backup, Error **errp)
 /* Parameter check and block job starting for drive mirroring.
  * Caller should hold @device and @target's aio context (must be the same).
  **/
+/*
+ * called by:
+ *   - blockdev.c|3297| <<qmp_drive_mirror>> blockdev_mirror_common(arg->has_job_id ? arg->job_id : NULL, bs, target_bs,
+ *   - blockdev.c|3368| <<qmp_blockdev_mirror>> blockdev_mirror_common(has_job_id ? job_id : NULL, bs, target_bs,
+ */
 static void blockdev_mirror_common(const char *job_id, BlockDriverState *bs,
                                    BlockDriverState *target,
                                    bool has_replaces, const char *replaces,
@@ -3660,6 +3745,10 @@ out:
     aio_context_release(aio_context);
 }
 
+/*
+ * called by:
+ *   - blockdev.c|3779| <<qmp_x_blockdev_change>> p_child = bdrv_find_child(parent_bs, child);
+ */
 static BdrvChild *bdrv_find_child(BlockDriverState *parent_bs,
                                   const char *child_name)
 {
@@ -3782,6 +3871,11 @@ void qmp_x_blockdev_set_iothread(const char *node_name, StrOrNull *iothread,
     aio_context_release(old_context);
 }
 
+/*
+ * 在以下使用qemu_common_drive_opts:
+ *   - blockdev.c|483| <<blockdev_init>> opts = qemu_opts_create(&qemu_common_drive_opts, id, 1, errp);
+ *   - softmmu/vl.c|2633| <<qemu_init>> qemu_add_drive_opts(&qemu_common_drive_opts);
+ */
 QemuOptsList qemu_common_drive_opts = {
     .name = "drive",
     .head = QTAILQ_HEAD_INITIALIZER(qemu_common_drive_opts.head),
diff --git a/blockjob.c b/blockjob.c
index 4868453d7..18f9c8f13 100644
--- a/blockjob.c
+++ b/blockjob.c
@@ -221,6 +221,48 @@ bool block_job_has_bdrv(BlockJob *job, BlockDriverState *bs)
     return false;
 }
 
+/*
+ * (gdb) bt
+ * #0  block_job_add_bdrv (job=0x563526791c30, name=0x5635241c4cc0 "main node", bs=0x563526663740, perm=1, shared_perm=7, errp=0x7ffdb00dbd68) at ../blockjob.c:229
+ * #1  0x0000563523e6e693 in block_job_create
+ *     (job_id=0x56352669eb30 "drive01", driver=0x5635244fe400 <mirror_job_driver>, txn=0x0, bs=0x563526663740, perm=1, shared_perm=7, speed=0, flags=0, cb=0x0, opaque=0x0, errp=0x7ffdb00dbd68) at ../blockjob.c:483
+ * #2  0x0000563523ea7209 in mirror_start_job
+ *     (job_id=0x0, bs=0x563526692110, creation_flags=0, target=0x56352743e410, replaces=0x0, speed=0, granularity=65536, buf_size=16777216, backing_mode=MIRROR_SOURCE_BACKING_CHAIN, zero_target=false, on_source_error=BLOCKDEV_ON_ERROR_REPORT, on_target_error=BLOCKDEV_ON_ERROR_REPORT, unmap=true, cb=0x0, opaque=0x0, driver=0x5635244fe400 <mirror_job_driver>, is_none_mode=false, base=0x0, auto_complete=false, filter_node_name=0x0, is_mirror=true, copy_mode=MIRROR_COPY_MODE_BACKGROUND, errp=0x7ffdb00dbd68) at ../block/mirror.c:1664
+#3  0x0000563523ea7962 in mirror_start
+ *     (job_id=0x0, bs=0x563526692110, target=0x56352743e410, replaces=0x0, creation_flags=0, speed=0, granularity=0, buf_size=0, mode=MIRROR_SYNC_MODE_FULL, backing_mode=MIRROR_SOURCE_BACKING_CHAIN, zero_target=false, on_source_error=BLOCKDEV_ON_ERROR_REPORT, on_target_error=BLOCKDEV_ON_ERROR_REPORT, unmap=true, filter_node_name=0x0, copy_mode=MIRROR_COPY_MODE_BACKGROUND, errp=0x7ffdb00dbd68) at ../block/mirror.c:1878
+ * #4  0x0000563523e544fe in blockdev_mirror_common
+ *     (job_id=0x0, bs=0x563526692110, target=0x56352743e410, has_replaces=false, replaces=0x0, sync=MIRROR_SYNC_MODE_FULL, backing_mode=MIRROR_SOURCE_BACKING_CHAIN, zero_target=false, has_speed=false, speed=0, has_granularity=false, granularity=0, has_buf_size=false, buf_size=0, has_on_source_error=false, on_source_error=BLOCKDEV_ON_ERROR_REPORT, has_on_target_error=false, on_target_error=BLOCKDEV_ON_ERROR_REPORT, has_unmap=false, unmap=true, has_filter_node_name=false, filter_node_name=0x0, has_copy_mode=false, copy_mode=MIRROR_COPY_MODE_BACKGROUND, has_auto_finalize=false, auto_finalize=false, has_auto_dismiss=false, auto_dismiss=false, errp=0x7ffdb00dbd68) at ../blockdev.c:3072
+ * #5  0x0000563523e54c3b in qmp_drive_mirror (arg=0x7ffdb00dbd80, errp=0x7ffdb00dbd68) at ../blockdev.c:3217
+ * #6  0x0000563523b675ff in hmp_drive_mirror (mon=0x56352644b670, qdict=0x563526e17600) at ../block/monitor/block-hmp-cmds.c:256
+ * #7  0x0000563523bc6c3e in handle_hmp_command_exec (mon=0x56352644b670, cmd=0x5635247f33b0 <hmp_cmds+2320>, qdict=0x563526e17600) at ../monitor/hmp.c:1103
+ * #8  0x0000563523bc6e6b in handle_hmp_command (mon=0x56352644b670, cmdline=0x5635266ca0fd "drive01 mytest01.qcow2") at ../monitor/hmp.c:1155
+ * #9  0x0000563523bc4384 in monitor_command_cb (opaque=0x56352644b670, cmdline=0x5635266ca0f0 "drive_mirror drive01 mytest01.qcow2", readline_opaque=0x0) at ../monitor/hmp.c:49
+ * #10 0x00005635240135dd in readline_handle_byte (rs=0x5635266ca0f0, ch=13) at ../util/readline.c:411
+ * #11 0x0000563523bc79a8 in monitor_read (opaque=0x56352644b670, buf=0x7ffdb00dc080 "\r\300\r\260\375\177", size=1) at ../monitor/hmp.c:1393
+ * #12 0x0000563523f2b613 in qemu_chr_be_write_impl (s=0x56352666d040, buf=0x7ffdb00dc080 "\r\300\r\260\375\177", len=1) at ../chardev/char.c:201
+ * #13 0x0000563523f2b677 in qemu_chr_be_write (s=0x56352666d040, buf=0x7ffdb00dc080 "\r\300\r\260\375\177", len=1) at ../chardev/char.c:213
+ * #14 0x0000563523f2e0a4 in fd_chr_read (chan=0x56352666dfa0, cond=G_IO_IN, opaque=0x56352666d040) at ../chardev/char-fd.c:72
+ * #15 0x0000563523e2d5b4 in qio_channel_fd_source_dispatch (source=0x563526e2cb00, callback=0x563523f2df7a <fd_chr_read>, user_data=0x56352666d040) at ../io/channel-watch.c:84
+ * #16 0x00007feb17b65119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #17 0x000056352400c010 in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #18 0x000056352400c08a in os_host_main_loop_wait (timeout=499000000) at ../util/main-loop.c:320
+ * #19 0x000056352400c18f in main_loop_wait (nonblocking=0) at ../util/main-loop.c:596
+ * #20 0x0000563523b7405e in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #21 0x0000563523919e62 in qemu_main (argc=30, argv=0x7ffdb00dd368, envp=0x0) at ../softmmu/main.c:38
+ * #22 0x0000563523919e94 in main (argc=30, argv=0x7ffdb00dd368) at ../softmmu/main.c:47
+ *
+ * called by:
+ *   - block/backup.c|492| <<backup_job_create>> block_job_add_bdrv(&job->common, "target", target, 0, BLK_PERM_ALL,
+ *   - block/commit.c|356| <<commit_start>> ret = block_job_add_bdrv(&s->common, "intermediate node", iter, 0,
+ *   - block/commit.c|368| <<commit_start>> ret = block_job_add_bdrv(&s->common, "base", base, 0, BLK_PERM_ALL, errp);
+ *   - block/mirror.c|1764| <<mirror_start_job>> ret = block_job_add_bdrv(&s->common, "source", bs, 0,
+ *   - block/mirror.c|1773| <<mirror_start_job>> block_job_add_bdrv(&s->common, "target", target, 0, BLK_PERM_ALL,
+ *   - block/mirror.c|1810| <<mirror_start_job>> ret = block_job_add_bdrv(&s->common, "intermediate node", iter, 0,
+ *   - block/stream.c|336| <<stream_start>> if (block_job_add_bdrv(&s->common, "active node", bs, 0,
+ *   - block/stream.c|354| <<stream_start>> ret = block_job_add_bdrv(&s->common, "intermediate node", iter, 0,
+ *   - blockjob.c|483| <<block_job_create>> ret = block_job_add_bdrv(job, "main node", bs, perm, shared_perm, errp);
+ *   - tests/unit/test-bdrv-drain.c|921| <<test_blockjob_common_drain_node>> block_job_add_bdrv(job, "target", target, 0, BLK_PERM_ALL, &error_abort);
+ */
 int block_job_add_bdrv(BlockJob *job, const char *name, BlockDriverState *bs,
                        uint64_t perm, uint64_t shared_perm, Error **errp)
 {
@@ -438,6 +480,41 @@ static void block_job_event_ready(Notifier *n, void *opaque)
  * declared in blockjob_int.h.
  */
 
+/*
+ * * (gdb) bt
+ * #0  block_job_add_bdrv (job=0x563526791c30, name=0x5635241c4cc0 "main node", bs=0x563526663740, perm=1, shared_perm=7, errp=0x7ffdb00dbd68) at ../blockjob.c:229
+ * #1  0x0000563523e6e693 in block_job_create
+ *     (job_id=0x56352669eb30 "drive01", driver=0x5635244fe400 <mirror_job_driver>, txn=0x0, bs=0x563526663740, perm=1, shared_perm=7, speed=0, flags=0, cb=0x0, opaque=0x0, errp=0x7ffdb00dbd68) at ../blockjob.c:483
+ * #2  0x0000563523ea7209 in mirror_start_job
+ *     (job_id=0x0, bs=0x563526692110, creation_flags=0, target=0x56352743e410, replaces=0x0, speed=0, granularity=65536, buf_size=16777216, backing_mode=MIRROR_SOURCE_BACKING_CHAIN, zero_target=false, on_source_error=BLOCKDEV_ON_ERROR_REPORT, on_target_error=BLOCKDEV_ON_ERROR_REPORT, unmap=true, cb=0x0, opaque=0x0, driver=0x5635244fe400 <mirror_job_driver>, is_none_mode=false, base=0x0, auto_complete=false, filter_node_name=0x0, is_mirror=true, copy_mode=MIRROR_COPY_MODE_BACKGROUND, errp=0x7ffdb00dbd68) at ../block/mirror.c:1664
+ * #3  0x0000563523ea7962 in mirror_start
+ *     (job_id=0x0, bs=0x563526692110, target=0x56352743e410, replaces=0x0, creation_flags=0, speed=0, granularity=0, buf_size=0, mode=MIRROR_SYNC_MODE_FULL, backing_mode=MIRROR_SOURCE_BACKING_CHAIN, zero_target=false, on_source_error=BLOCKDEV_ON_ERROR_REPORT, on_target_error=BLOCKDEV_ON_ERROR_REPORT, unmap=true, filter_node_name=0x0, copy_mode=MIRROR_COPY_MODE_BACKGROUND, errp=0x7ffdb00dbd68) at ../block/mirror.c:1878
+ * #4  0x0000563523e544fe in blockdev_mirror_common (job_id=0x0, bs=0x563526692110, target=0x56352743e410, has_replaces=false, replaces=0x0, sync=MIRROR_SYNC_MODE_FULL, backing_mode=MIRROR_SOURCE_BACKING_CHAIN, zero_target=false, has_speed=false, speed=0, has_granularity=false, granularity=0, has_buf_size=false, buf_size=0, has_on_source_error=false, on_source_error=BLOCKDEV_ON_ERROR_REPORT, has_on_target_error=false, on_target_error=BLOCKDEV_ON_ERROR_REPORT, has_unmap=false, unmap=true, has_filter_node_name=false, filter_node_name=0x0, has_copy_mode=false, copy_mode=MIRROR_COPY_MODE_BACKGROUND, has_auto_finalize=false, auto_finalize=false, has_auto_dismiss=false, auto_dismiss=false, errp=0x7ffdb00dbd68) at ../blockdev.c:3072
+ * #5  0x0000563523e54c3b in qmp_drive_mirror (arg=0x7ffdb00dbd80, errp=0x7ffdb00dbd68) at ../blockdev.c:3217
+ * #6  0x0000563523b675ff in hmp_drive_mirror (mon=0x56352644b670, qdict=0x563526e17600) at ../block/monitor/block-hmp-cmds.c:256
+ * #7  0x0000563523bc6c3e in handle_hmp_command_exec (mon=0x56352644b670, cmd=0x5635247f33b0 <hmp_cmds+2320>, qdict=0x563526e17600) at ../monitor/hmp.c:1103
+ * #8  0x0000563523bc6e6b in handle_hmp_command (mon=0x56352644b670, cmdline=0x5635266ca0fd "drive01 mytest01.qcow2") at ../monitor/hmp.c:1155
+ * #9  0x0000563523bc4384 in monitor_command_cb (opaque=0x56352644b670, cmdline=0x5635266ca0f0 "drive_mirror drive01 mytest01.qcow2", readline_opaque=0x0) at ../monitor/hmp.c:49
+ * #10 0x00005635240135dd in readline_handle_byte (rs=0x5635266ca0f0, ch=13) at ../util/readline.c:411
+ * #11 0x0000563523bc79a8 in monitor_read (opaque=0x56352644b670, buf=0x7ffdb00dc080 "\r\300\r\260\375\177", size=1) at ../monitor/hmp.c:1393
+ * #12 0x0000563523f2b613 in qemu_chr_be_write_impl (s=0x56352666d040, buf=0x7ffdb00dc080 "\r\300\r\260\375\177", len=1) at ../chardev/char.c:201
+ * #13 0x0000563523f2b677 in qemu_chr_be_write (s=0x56352666d040, buf=0x7ffdb00dc080 "\r\300\r\260\375\177", len=1) at ../chardev/char.c:213
+ * #14 0x0000563523f2e0a4 in fd_chr_read (chan=0x56352666dfa0, cond=G_IO_IN, opaque=0x56352666d040) at ../chardev/char-fd.c:72
+ * #15 0x0000563523e2d5b4 in qio_channel_fd_source_dispatch (source=0x563526e2cb00, callback=0x563523f2df7a <fd_chr_read>, user_data=0x56352666d040) at ../io/channel-watch.c:84
+ * #16 0x00007feb17b65119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #17 0x000056352400c010 in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #18 0x000056352400c08a in os_host_main_loop_wait (timeout=499000000) at ../util/main-loop.c:320
+ * #19 0x000056352400c18f in main_loop_wait (nonblocking=0) at ../util/main-loop.c:596
+ * #20 0x0000563523b7405e in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #21 0x0000563523919e62 in qemu_main (argc=30, argv=0x7ffdb00dd368, envp=0x0) at ../softmmu/main.c:38
+ * #22 0x0000563523919e94 in main (argc=30, argv=0x7ffdb00dd368) at ../softmmu/main.c:47
+ *
+ * called by:
+ *   - block/backup.c|467| <<backup_job_create>> job = block_job_create(job_id, &backup_job_driver, txn, cbw,
+ *   - block/commit.c|282| <<commit_start>> s = block_job_create(job_id, &commit_job_driver, NULL, bs, 0, BLK_PERM_ALL,
+ *   - block/mirror.c|1664| <<mirror_start_job>> s = block_job_create(job_id, driver, NULL, mirror_top_bs,
+ *   - block/stream.c|312| <<stream_start>> s = block_job_create(job_id, &stream_job_driver, NULL, cor_filter_bs,
+ */
 void *block_job_create(const char *job_id, const BlockJobDriver *driver,
                        JobTxn *txn, BlockDriverState *bs, uint64_t perm,
                        uint64_t shared_perm, int64_t speed, int flags,
@@ -451,6 +528,15 @@ void *block_job_create(const char *job_id, const BlockJobDriver *driver,
         job_id = bdrv_get_device_name(bs);
     }
 
+    /*
+     * called by:
+     *   - block/amend.c|127| <<qmp_x_blockdev_amend>> s = job_create(job_id, &blockdev_amend_job_driver, NULL,
+     *   - block/create.c|90| <<qmp_blockdev_create>> s = job_create(job_id, &blockdev_create_job_driver, NULL,
+     *   - blockjob.c|531| <<block_job_create>> job = job_create(job_id, &driver->job_driver, txn, bdrv_get_aio_context(bs),
+     *   - migration/savevm.c|3257| <<qmp_snapshot_save>> s = job_create(job_id, &snapshot_save_job_driver, NULL,
+     *   - migration/savevm.c|3279| <<qmp_snapshot_load>> s = job_create(job_id, &snapshot_load_job_driver, NULL,
+     *   - migration/savevm.c|3300| <<qmp_snapshot_delete>> s = job_create(job_id, &snapshot_delete_job_driver, NULL,
+     */
     job = job_create(job_id, &driver->job_driver, txn, bdrv_get_aio_context(bs),
                      flags, cb, opaque, errp);
     if (job == NULL) {
diff --git a/chardev/char-fe.c b/chardev/char-fe.c
index 7789f7be9..88fa97ee7 100644
--- a/chardev/char-fe.c
+++ b/chardev/char-fe.c
@@ -31,6 +31,26 @@
 #include "chardev/char-io.h"
 #include "chardev-internal.h"
 
+/*
+ * called by:
+ *   - chardev/char-mux.c|49| <<mux_chr_write>> ret = qemu_chr_fe_write(&d->chr, buf, len);
+ *   - chardev/char-mux.c|78| <<mux_chr_write>> ret += qemu_chr_fe_write(&d->chr, buf + i, 1);
+ *   - hw/char/cadence_uart.c|317| <<cadence_uart_xmit>> ret = qemu_chr_fe_write(&s->chr, s->tx_fifo, s->tx_count);
+ *   - hw/char/cmsdk-apb-uart.c|205| <<uart_transmit>> ret = qemu_chr_fe_write(&s->chr, &s->txbuf, 1);
+ *   - hw/char/ibex_uart.c|161| <<ibex_uart_xmit>> ret = qemu_chr_fe_write(&s->chr, s->tx_fifo, s->tx_level);
+ *   - hw/char/nrf51_uart.c|86| <<uart_transmit>> r = qemu_chr_fe_write(&s->chr, &c, 1);
+ *   - hw/char/riscv_htif.c|149| <<htif_handle_tohost_write>> qemu_chr_fe_write(&htifstate->chr, (uint8_t *)&payload, 1);
+ *   - hw/char/serial.c|259| <<serial_xmit>> int rc = qemu_chr_fe_write(&s->chr, &s->tsr, 1);
+ *   - hw/char/sifive_uart.c|113| <<sifive_uart_write>> qemu_chr_fe_write(&s->chr, &ch, 1);
+ *   - hw/char/virtio-console.c|63| <<flush_buf>> ret = qemu_chr_fe_write(&vcon->chr, buf, len);
+ *   - hw/char/xen_console.c|153| <<xencons_send>> len = qemu_chr_fe_write(&con->chr,
+ *   - hw/display/vhost-user-gpu.c|135| <<vhost_user_gpu_send_msg>> qemu_chr_fe_write(&g->vhost_chr, (uint8_t *)msg,
+ *   - hw/ipmi/ipmi_bmc_extern.c|109| <<continue_send>> ret = qemu_chr_fe_write(&ibe->chr, ibe->outbuf + ibe->outpos,
+ *   - hw/rdma/rdma_backend.c|247| <<rdmacm_mux_send>> rc = qemu_chr_fe_write(backend_dev->rdmacm_mux.chr_be,
+ *   - hw/usb/redirect.c|305| <<usbredir_write>> r = qemu_chr_fe_write(&dev->cs, data, count);
+ *   - monitor/monitor.c|186| <<monitor_flush_locked>> rc = qemu_chr_fe_write(&mon->chr, (const uint8_t *) buf, len);
+ *   - target/riscv/kvm.c|465| <<kvm_riscv_handle_sbi>> qemu_chr_fe_write(serial_hd(0)->be, &ch, sizeof(ch));
+ */
 int qemu_chr_fe_write(CharBackend *be, const uint8_t *buf, int len)
 {
     Chardev *s = be->chr;
@@ -42,6 +62,23 @@ int qemu_chr_fe_write(CharBackend *be, const uint8_t *buf, int len)
     return qemu_chr_write(s, buf, len, false);
 }
 
+/*
+ * 部分调用的例子:
+ *   - backends/rng-egd.c|46| <<rng_egd_request_entropy>> qemu_chr_fe_write_all(&s->chr, header, sizeof(header));
+ *   - backends/tpm/tpm_emulator.c|134| <<tpm_emulator_ctrlcmd>> n = qemu_chr_fe_write_all(dev, buf, n);
+ *   - backends/tpm/tpm_emulator.c|777| <<tpm_emulator_set_state_blob>> n = qemu_chr_fe_write_all(&tpm_emu->ctrl_chr, tsb->buffer, tsb->size);
+ *   - chardev/char-fe.c|192| <<qemu_chr_fe_printf>> qemu_chr_fe_write_all(be, (uint8_t *)buf, strlen(buf));
+ *   - chardev/char-mux.c|74| <<mux_chr_write>> qemu_chr_fe_write_all(&d->chr,
+ *   - gdbstub.c|588| <<put_buffer>> qemu_chr_fe_write_all(&gdbserver_state.chr, buf, len);
+ *   - hw/char/bcm2835_aux.c|177| <<bcm2835_aux_write>> qemu_chr_fe_write_all(&s->chr, &ch, 1);
+ *   - hw/char/debugcon.c|66| <<debugcon_ioport_write>> qemu_chr_fe_write_all(&s->chr, &ch, 1);
+ *   - hw/char/exynos4210_uart.c|437| <<exynos4210_uart_write>> qemu_chr_fe_write_all(&s->chr, &ch, 1);
+ *   - hw/char/imx_serial.c|205| <<imx_serial_write>> qemu_chr_fe_write_all(&s->chr, &ch, 1);
+ *   - hw/char/parallel.c|142| <<parallel_ioport_write_sw>> qemu_chr_fe_write_all(&s->chr, &s->dataw, 1);
+ *   - hw/char/pl011.c|208| <<pl011_write>> qemu_chr_fe_write_all(&s->chr, &ch, 1);
+ *   - hw/usb/dev-serial.c|498| <<usb_serial_handle_data>> qemu_chr_fe_write_all(&s->cs, iov->iov_base, iov->iov_len);
+ *   - hw/virtio/vhost-user.c|486| <<vhost_user_write>> ret = qemu_chr_fe_write_all(chr, (const uint8_t *) msg, size);
+ */
 int qemu_chr_fe_write_all(CharBackend *be, const uint8_t *buf, int len)
 {
     Chardev *s = be->chr;
diff --git a/chardev/char-io.c b/chardev/char-io.c
index 4451128cb..7638c4540 100644
--- a/chardev/char-io.c
+++ b/chardev/char-io.c
@@ -109,6 +109,31 @@ void remove_fd_in_watch(Chardev *chr)
     }
 }
 
+/*
+ * (gdb) bt
+ * #0  io_channel_send_full (ioc=0x555556a69b60, buf=0x5555579c9c1c, len=1, fds=0x0, nfds=0) at ../chardev/char-io.c:115
+ * #1  0x0000555555e29926 in io_channel_send (ioc=0x555556a69b60, buf=0x5555579c9c1c, len=1) at ../chardev/char-io.c:146
+ * #2  0x0000555555e33f78 in fd_chr_write (chr=0x555556a69a50, buf=0x5555579c9c1c " ", len=1) at ../chardev/char-fd.c:45
+ * #3  0x0000555555e31377 in qemu_chr_write_buffer (s=0x555556a69a50, buf=0x5555579c9c1c " ", len=1, offset=0x7fffed89a4d0, write_all=false) at ../chardev/char.c:121
+ * #4  0x0000555555e3151f in qemu_chr_write (s=0x555556a69a50, buf=0x5555579c9c1c " ", len=1, write_all=false) at ../chardev/char.c:173
+ * #5  0x0000555555e28747 in qemu_chr_fe_write (be=0x5555579c9c38, buf=0x5555579c9c1c " ", len=1) at ../chardev/char-fe.c:42
+ * #6  0x0000555555896e91 in serial_xmit (s=0x5555579c9b80) at ../hw/char/serial.c:259
+ * #7  0x00005555558972ed in serial_ioport_write (opaque=0x5555579c9b80, addr=0, val=32, size=1) at ../hw/char/serial.c:359
+ * #8  0x0000555555c650a3 in memory_region_write_accessor (mr=0x5555579c9cf0, addr=0, value=0x7fffed89a6a8, size=1, shift=0, mask=255, attrs=...) at ../softmmu/memory.c:492
+ * #9  0x0000555555c652e7 in access_with_adjusted_size (addr=0, value=0x7fffed89a6a8, size=1, access_size_min=1, access_size_max=1, access_fn=
+ *     0x555555c64fad <memory_region_write_accessor>, mr=0x5555579c9cf0, attrs=...) at ../softmmu/memory.c:554
+ * #10 0x0000555555c683dd in memory_region_dispatch_write (mr=0x5555579c9cf0, addr=0, data=32, op=MO_8, attrs=...) at ../softmmu/memory.c:1514
+ * #11 0x0000555555c758f6 in flatview_write_continue (fv=0x7ffe582f9c00, addr=1016, attrs=..., ptr=0x7ffff7ff3000, len=1, addr1=0, l=1, mr=0x5555579c9cf0) at ../softmmu/physmem.c:2825
+ * #12 0x0000555555c75a59 in flatview_write (fv=0x7ffe582f9c00, addr=1016, attrs=..., buf=0x7ffff7ff3000, len=1) at ../softmmu/physmem.c:2867
+ * #13 0x0000555555c75e09 in address_space_write (as=0x5555567b3420 <address_space_io>, addr=1016, attrs=..., buf=0x7ffff7ff3000, len=1) at ../softmmu/physmem.c:2963
+ * #14 0x0000555555c75e76 in address_space_rw (as=0x5555567b3420 <address_space_io>, addr=1016, attrs=..., buf=0x7ffff7ff3000, len=1, is_write=true) at ../softmmu/physmem.c:2973
+ * #15 0x0000555555d0db63 in kvm_handle_io (port=1016, attrs=..., data=0x7ffff7ff3000, direction=1, size=1, count=1) at ../accel/kvm/kvm-all.c:2693
+ * #16 0x0000555555d0e2dd in kvm_cpu_exec (cpu=0x555556ac7090) at ../accel/kvm/kvm-all.c:2944
+ * #17 0x0000555555d10faa in kvm_vcpu_thread_fn (arg=0x555556ac7090) at ../accel/kvm/kvm-accel-ops.c:49
+ * #18 0x0000555555eec4de in qemu_thread_start (args=0x555556ad66b0) at ../util/qemu-thread-posix.c:504
+ * #19 0x00007ffff55eeea5 in start_thread () at /lib64/libpthread.so.0
+ * #20 0x00007ffff53179fd in clone () at /lib64/libc.so.6
+ */
 int io_channel_send_full(QIOChannel *ioc,
                          const void *buf, size_t len,
                          int *fds, size_t nfds)
diff --git a/chardev/char.c b/chardev/char.c
index 0169d8dde..c88933147 100644
--- a/chardev/char.c
+++ b/chardev/char.c
@@ -158,6 +158,12 @@ static int qemu_chr_write_buffer(Chardev *s,
     return res;
 }
 
+/*
+ * called by:
+ *   - chardev/char-fe.c|62| <<qemu_chr_fe_write>> return qemu_chr_write(s, buf, len, false);
+ *   - chardev/char-fe.c|73| <<qemu_chr_fe_write_all>> return qemu_chr_write(s, buf, len, true);
+ *   - include/chardev/char.h|227| <<qemu_chr_write_all>> #define qemu_chr_write_all(s, buf, len) qemu_chr_write(s, buf, len, true)
+ */
 int qemu_chr_write(Chardev *s, const uint8_t *buf, int len, bool write_all)
 {
     int offset = 0;
diff --git a/hw/acpi/core.c b/hw/acpi/core.c
index 3e811bf03..a9a49eacc 100644
--- a/hw/acpi/core.c
+++ b/hw/acpi/core.c
@@ -719,6 +719,16 @@ void acpi_send_gpe_event(ACPIREGS *ar, qemu_irq irq,
     acpi_update_sci(ar, irq);
 }
 
+/*
+ * called by:
+ *   - hw/acpi/core.c|719| <<acpi_send_gpe_event>> acpi_update_sci(ar, irq);
+ *   - hw/acpi/ich9.c|55| <<ich9_pm_update_sci_fn>> acpi_update_sci(&pm->acpi_regs, pm->irq);
+ *   - hw/acpi/ich9.c|69| <<ich9_gpe_writeb>> acpi_update_sci(&pm->acpi_regs, pm->irq);
+ *   - hw/acpi/ich9.c|288| <<pm_reset>> acpi_update_sci(&pm->acpi_regs, pm->irq);
+ *   - hw/acpi/piix4.c|70| <<pm_tmr_timer>> acpi_update_sci(&s->ar, s->irq);
+ *   - hw/acpi/piix4.c|309| <<piix4_pm_reset>> acpi_update_sci(&s->ar, s->irq);
+ *   - hw/acpi/piix4.c|528| <<gpe_writeb>> acpi_update_sci(&s->ar, s->irq);
+ */
 void acpi_update_sci(ACPIREGS *regs, qemu_irq irq)
 {
     int sci_level, pm1a_sts;
diff --git a/hw/acpi/cpu.c b/hw/acpi/cpu.c
index 3646dbfe6..d330cfee3 100644
--- a/hw/acpi/cpu.c
+++ b/hw/acpi/cpu.c
@@ -338,6 +338,10 @@ const VMStateDescription vmstate_cpu_hotplug = {
 #define CPU_EJECT_EVENT   "CEJ0"
 #define CPU_FW_EJECT_EVENT "CEJF"
 
+/*
+ * called by:
+ *  - hw/i386/acpi-build.c|1545| <<build_dsdt>> build_cpus_aml(dsdt, machine, opts, pm->cpu_hp_io_base,
+ */
 void build_cpus_aml(Aml *table, MachineState *machine, CPUHotplugFeatures opts,
                     hwaddr io_base,
                     const char *res_root,
diff --git a/hw/acpi/cpu_hotplug.c b/hw/acpi/cpu_hotplug.c
index 53654f863..748544b1c 100644
--- a/hw/acpi/cpu_hotplug.c
+++ b/hw/acpi/cpu_hotplug.c
@@ -46,6 +46,10 @@ static void cpu_status_write(void *opaque, hwaddr addr, uint64_t data,
     }
 }
 
+/*
+ * 在以下使用AcpiCpuHotplug_ops:
+ *   - hw/acpi/cpu_hotplug.c|86| <<legacy_acpi_cpu_hotplug_init>> memory_region_init_io(&gpe_cpu->io, owner, &AcpiCpuHotplug_ops,
+ */
 static const MemoryRegionOps AcpiCpuHotplug_ops = {
     .read = cpu_status_read,
     .write = cpu_status_write,
diff --git a/hw/acpi/ich9.c b/hw/acpi/ich9.c
index bd9bbade7..d85b729bd 100644
--- a/hw/acpi/ich9.c
+++ b/hw/acpi/ich9.c
@@ -260,6 +260,10 @@ const VMStateDescription vmstate_ich9_pm = {
     }
 };
 
+/*
+ * called by:
+ *   - hw/acpi/ich9.c|335| <<ich9_pm_init>> qemu_register_reset(pm_reset, pm);
+ */
 static void pm_reset(void *opaque)
 {
     ICH9LPCPMRegs *pm = opaque;
@@ -377,6 +381,32 @@ static bool ich9_pm_get_cpu_hotplug_legacy(Object *obj, Error **errp)
     return s->pm.cpu_hotplug_legacy;
 }
 
+/*
+ * (gdb) bt
+ * #0  ich9_pm_set_cpu_hotplug_legacy (obj=0x55555707a3e0, value=false, errp=0x5555567d1638 <error_abort>) at ../hw/acpi/ich9.c:383
+ * #1  0x0000555555d2a9a0 in property_set_bool (obj=0x55555707a3e0, v=0x7ff7e8122720, name=0x555555f9c793 "cpu-hotplug-legacy", opaque=0x555557081250, errp=0x5555567d1638 <error_abort>) at ../qom/object.c:2273
+ * #2  0x0000555555d289e7 in object_property_set (obj=0x55555707a3e0, name=0x555555f9c793 "cpu-hotplug-legacy", v=0x7ff7e8122720, errp=0x5555567d1638 <error_abort>) at ../qom/object.c:1408
+ * #3  0x0000555555d2cd92 in object_property_set_qobject (obj=0x55555707a3e0, name=0x555555f9c793 "cpu-hotplug-legacy", value=0x7ff7e8037f90, errp=0x5555567d1638 <error_abort>) at ../qom/qom-qobject.c:28
+ * #4  0x0000555555d28d4c in object_property_set_bool (obj=0x55555707a3e0, name=0x555555f9c793 "cpu-hotplug-legacy", value=false, errp=0x5555567d1638 <error_abort>) at ../qom/object.c:1477
+ * #5  0x000055555586006e in cpu_status_write (opaque=0x55555707b6d0, addr=0, data=0, size=1) at ../hw/acpi/cpu_hotplug.c:44
+ * #6  0x0000555555c650a3 in memory_region_write_accessor (mr=0x55555707b6e0, addr=0, value=0x7ff7ee6b96a8, size=1, shift=0, mask=255, attrs=...) at ../softmmu/memory.c:492
+ * #7  0x0000555555c652e7 in access_with_adjusted_size (addr=0, value=0x7ff7ee6b96a8, size=1, access_size_min=1, access_size_max=4, access_fn=
+ *     0x555555c64fad <memory_region_write_accessor>, mr=0x55555707b6e0, attrs=...) at ../softmmu/memory.c:554
+ * #8  0x0000555555c683dd in memory_region_dispatch_write (mr=0x55555707b6e0, addr=0, data=0, op=MO_8, attrs=...) at ../softmmu/memory.c:1514
+ * #9  0x0000555555c758f6 in flatview_write_continue (fv=0x7ff7e81b55c0, addr=3288, attrs=..., ptr=0x7ffff7ff3000, len=4, addr1=0, l=1, mr=0x55555707b6e0) at ../softmmu/physmem.c:2825
+ * #10 0x0000555555c75a59 in flatview_write (fv=0x7ff7e81b55c0, addr=3288, attrs=..., buf=0x7ffff7ff3000, len=4) at ../softmmu/physmem.c:2867
+ * #11 0x0000555555c75e09 in address_space_write (as=0x5555567b3420 <address_space_io>, addr=3288, attrs=..., buf=0x7ffff7ff3000, len=4) at ../softmmu/physmem.c:2963
+ * #12 0x0000555555c75e76 in address_space_rw (as=0x5555567b3420 <address_space_io>, addr=3288, attrs=..., buf=0x7ffff7ff3000, len=4, is_write=true) at ../softmmu/physmem.c:2973
+ * #13 0x0000555555d0db63 in kvm_handle_io (port=3288, attrs=..., data=0x7ffff7ff3000, direction=1, size=4, count=1) at ../accel/kvm/kvm-all.c:2693
+ * #14 0x0000555555d0e2dd in kvm_cpu_exec (cpu=0x555556aac970) at ../accel/kvm/kvm-all.c:2944
+ * #15 0x0000555555d10faa in kvm_vcpu_thread_fn (arg=0x555556aac970) at ../accel/kvm/kvm-accel-ops.c:49
+ * #16 0x0000555555eec4de in qemu_thread_start (args=0x555556abc580) at ../util/qemu-thread-posix.c:504
+ * #17 0x00007ffff55eeea5 in start_thread () at /lib64/libpthread.so.0
+ * #18 0x00007ffff53179fd in clone () at /lib64/libc.so.6
+ *
+ * 在以下使用ich9_pm_set_cpu_hotplug_legacy():
+ *   - hw/acpi/ich9.c|460| <<ich9_pm_add_properties>> object_property_add_bool(obj, "cpu-hotplug-legacy", ich9_pm_get_cpu_hotplug_legacy, ich9_pm_set_cpu_hotplug_legacy);
+ */
 static void ich9_pm_set_cpu_hotplug_legacy(Object *obj, bool value,
                                            Error **errp)
 {
@@ -530,6 +560,14 @@ void ich9_pm_device_unplug_request_cb(HotplugHandler *hotplug_dev,
 {
     ICH9LPCState *lpc = ICH9_LPC_DEVICE(hotplug_dev);
 
+    /*
+     * ICH9LPCState *lpc:
+     * -> ICH9LPCPMRegs pm;
+     *    -> bool cpu_hotplug_legacy;
+     *    -> AcpiCpuHotplug gpe_cpu;
+     *    -> CPUHotplugState cpuhp_state;
+     */
+
     if (lpc->pm.acpi_memory_hotplug.is_enabled &&
         object_dynamic_cast(OBJECT(dev), TYPE_PC_DIMM)) {
         acpi_memory_unplug_request_cb(hotplug_dev,
diff --git a/hw/acpi/pci.c b/hw/acpi/pci.c
index 20b70dcd8..4414990e4 100644
--- a/hw/acpi/pci.c
+++ b/hw/acpi/pci.c
@@ -32,6 +32,12 @@
  * PCI Firmware Specification, Revision 3.0
  * 4.1.2 MCFG Table Description.
  */
+/*
+ * called by:
+ *   - hw/arm/virt-acpi-build.c|968| <<virt_acpi_build>> build_mcfg(tables_blob, tables->linker, &mcfg, vms->oem_id,
+ *   - hw/i386/acpi-build.c|2608| <<acpi_build>> build_mcfg(tables_blob, tables->linker, &mcfg, x86ms->oem_id,
+ *   - hw/loongarch/acpi-build.c|459| <<acpi_build>> build_mcfg(tables_blob, tables->linker, &mcfg, lams->oem_id,
+ */
 void build_mcfg(GArray *table_data, BIOSLinker *linker, AcpiMcfgInfo *info,
                 const char *oem_id, const char *oem_table_id)
 {
diff --git a/hw/acpi/pcihp.c b/hw/acpi/pcihp.c
index 84d75e6b8..ae282c5d3 100644
--- a/hw/acpi/pcihp.c
+++ b/hw/acpi/pcihp.c
@@ -200,6 +200,11 @@ static bool acpi_pcihp_pc_no_hotplug(AcpiPciHpState *s, PCIDevice *dev)
            pci_is_vf(dev);
 }
 
+/*
+ * 在以下使用acpi_pcihp_eject_slot():
+ *   - hw/acpi/pcihp.c|258| <<acpi_pcihp_update_hotplug_bus>> acpi_pcihp_eject_slot(s, bsel, s->acpi_pcihp_pci_status[bsel].down);
+ *   - hw/acpi/pcihp.c|520| <<pci_write(PCI_EJ_BASE)>> acpi_pcihp_eject_slot(s, s->hotplug_select, data);
+ */
 static void acpi_pcihp_eject_slot(AcpiPciHpState *s, unsigned bsel, unsigned slots)
 {
     HotplugHandler *hotplug_ctrl;
@@ -248,6 +253,10 @@ static void acpi_pcihp_eject_slot(AcpiPciHpState *s, unsigned bsel, unsigned slo
     }
 }
 
+/*
+ * called by:
+ *   - hw/acpi/pcihp.c|282| <<acpi_pcihp_update>> acpi_pcihp_update_hotplug_bus(s, i);
+ */
 static void acpi_pcihp_update_hotplug_bus(AcpiPciHpState *s, int bsel)
 {
     BusChild *kid, *next;
@@ -274,6 +283,10 @@ static void acpi_pcihp_update_hotplug_bus(AcpiPciHpState *s, int bsel)
     }
 }
 
+/*
+ * called by:
+ *   - hw/acpi/pcihp.c|292| <<acpi_pcihp_reset>> acpi_pcihp_update(s);
+ */
 static void acpi_pcihp_update(AcpiPciHpState *s)
 {
     int i;
@@ -283,6 +296,100 @@ static void acpi_pcihp_update(AcpiPciHpState *s)
     }
 }
 
+/*
+ * i440fx system_reset循序调用以下.
+ *
+ * (gdb) bt
+ * #0  acpi_pcihp_reset (s=0x55555768a510, acpihp_root_off=false) at ../hw/acpi/pcihp.c:288
+ * #1  0x000055555586b70d in piix4_pm_reset (dev=0x555557689210) at ../hw/acpi/piix4.c:308
+ * #2  0x0000555555d218cb in device_transitional_reset (obj=0x555557689210) at ../hw/core/qdev.c:823
+ * #3  0x0000555555d23536 in resettable_phase_hold (obj=0x555557689210, opaque=0x0, type=RESET_TYPE_COLD) at ../hw/core/resettable.c:182
+ * #4  0x0000555555d1c74c in bus_reset_child_foreach (obj=0x555556c22de0, cb=0x555555d23408 <resettable_phase_hold>, opaque=0x0, type=RESET_TYPE_COLD)
+ *     at ../hw/core/bus.c:97
+ * #5  0x0000555555d2323d in resettable_child_foreach
+ *     (rc=0x555556899f60, obj=0x555556c22de0, cb=0x555555d23408 <resettable_phase_hold>, opaque=0x0, type=RESET_TYPE_COLD) at ../hw/core/resettable.c:96
+ * #6  0x0000555555d234bc in resettable_phase_hold (obj=0x555556c22de0, opaque=0x0, type=RESET_TYPE_COLD) at ../hw/core/resettable.c:173
+ * #7  0x0000555555d205e3 in device_reset_child_foreach (obj=0x555556b03e70, cb=0x555555d23408 <resettable_phase_hold>, opaque=0x0, type=RESET_TYPE_COLD)
+ *     at ../hw/core/qdev.c:317
+ * #8  0x0000555555d2323d in resettable_child_foreach
+ *     (rc=0x555556951180, obj=0x555556b03e70, cb=0x555555d23408 <resettable_phase_hold>, opaque=0x0, type=RESET_TYPE_COLD) at ../hw/core/resettable.c:96
+ * #9  0x0000555555d234bc in resettable_phase_hold (obj=0x555556b03e70, opaque=0x0, type=RESET_TYPE_COLD) at ../hw/core/resettable.c:173
+ * #10 0x0000555555d1c74c in bus_reset_child_foreach (obj=0x555556a5bd10, cb=0x555555d23408 <resettable_phase_hold>, opaque=0x0, type=RESET_TYPE_COLD)
+ *     at ../hw/core/bus.c:97
+ * #11 0x0000555555d2323d in resettable_child_foreach
+ *     (rc=0x555556998150, obj=0x555556a5bd10, cb=0x555555d23408 <resettable_phase_hold>, opaque=0x0, type=RESET_TYPE_COLD) at ../hw/core/resettable.c:96
+ * #12 0x0000555555d234bc in resettable_phase_hold (obj=0x555556a5bd10, opaque=0x0, type=RESET_TYPE_COLD) at ../hw/core/resettable.c:173
+ * #13 0x0000555555d230ee in resettable_assert_reset (obj=0x555556a5bd10, type=RESET_TYPE_COLD) at ../hw/core/resettable.c:60
+ * #14 0x0000555555d23032 in resettable_reset (obj=0x555556a5bd10, type=RESET_TYPE_COLD) at ../hw/core/resettable.c:45
+ * #15 0x0000555555d23873 in resettable_cold_reset_fn (opaque=0x555556a5bd10) at ../hw/core/resettable.c:269
+ * #16 0x0000555555d21d7a in qemu_devices_reset () at ../hw/core/reset.c:69
+ * #17 0x0000555555b4d08c in pc_machine_reset (machine=0x555556a526e0) at ../hw/i386/pc.c:1851
+ * #18 0x0000555555a798ac in qemu_system_reset (reason=SHUTDOWN_CAUSE_HOST_QMP_SYSTEM_RESET) at ../softmmu/runstate.c:444
+ * #19 0x0000555555a79f75 in main_loop_should_exit (status=0x7fffffffdc04) at ../softmmu/runstate.c:694
+ * #20 0x0000555555a7a06a in qemu_main_loop () at ../softmmu/runstate.c:730
+ * #21 0x000055555581fe62 in qemu_main (argc=32, argv=0x7fffffffdd58, envp=0x0) at ../softmmu/main.c:38
+ * #22 0x000055555581fe94 in main (argc=32, argv=0x7fffffffdd58) at ../softmmu/main.c:47
+ *
+ * (gdb) bt
+ * #0  acpi_pcihp_reset (s=0x55555768a510, acpihp_root_off=false) at ../hw/acpi/pcihp.c:288
+ * #1  0x000055555586b70d in piix4_pm_reset (dev=0x555557689210) at ../hw/acpi/piix4.c:308
+ * #2  0x0000555555d218cb in device_transitional_reset (obj=0x555557689210) at ../hw/core/qdev.c:823
+ * #3  0x0000555555d23536 in resettable_phase_hold (obj=0x555557689210, opaque=0x0, type=RESET_TYPE_COLD) at ../hw/core/resettable.c:182
+ * #4  0x0000555555d1c74c in bus_reset_child_foreach (obj=0x555556c22de0, cb=0x555555d23408 <resettable_phase_hold>, opaque=0x0, type=RESET_TYPE_COLD)
+ *     at ../hw/core/bus.c:97
+ * #5  0x0000555555d2323d in resettable_child_foreach
+ *     (rc=0x555556899f60, obj=0x555556c22de0, cb=0x555555d23408 <resettable_phase_hold>, opaque=0x0, type=RESET_TYPE_COLD) at ../hw/core/resettable.c:96
+ * #6  0x0000555555d234bc in resettable_phase_hold (obj=0x555556c22de0, opaque=0x0, type=RESET_TYPE_COLD) at ../hw/core/resettable.c:173
+ * #7  0x0000555555d205e3 in device_reset_child_foreach (obj=0x555556b03e70, cb=0x555555d23408 <resettable_phase_hold>, opaque=0x0, type=RESET_TYPE_COLD)
+ *     at ../hw/core/qdev.c:317
+ * #8  0x0000555555d2323d in resettable_child_foreach
+ *     (rc=0x555556951180, obj=0x555556b03e70, cb=0x555555d23408 <resettable_phase_hold>, opaque=0x0, type=RESET_TYPE_COLD) at ../hw/core/resettable.c:96
+ * #9  0x0000555555d234bc in resettable_phase_hold (obj=0x555556b03e70, opaque=0x0, type=RESET_TYPE_COLD) at ../hw/core/resettable.c:173
+ * #10 0x0000555555d1c74c in bus_reset_child_foreach (obj=0x555556a5bd10, cb=0x555555d23408 <resettable_phase_hold>, opaque=0x0, type=RESET_TYPE_COLD)
+ *     at ../hw/core/bus.c:97
+ * #11 0x0000555555d2323d in resettable_child_foreach
+ *     (rc=0x555556998150, obj=0x555556a5bd10, cb=0x555555d23408 <resettable_phase_hold>, opaque=0x0, type=RESET_TYPE_COLD) at ../hw/core/resettable.c:96
+ * #12 0x0000555555d234bc in resettable_phase_hold (obj=0x555556a5bd10, opaque=0x0, type=RESET_TYPE_COLD) at ../hw/core/resettable.c:173
+ * #13 0x0000555555d230ee in resettable_assert_reset (obj=0x555556a5bd10, type=RESET_TYPE_COLD) at ../hw/core/resettable.c:60
+ * #14 0x0000555555d23032 in resettable_reset (obj=0x555556a5bd10, type=RESET_TYPE_COLD) at ../hw/core/resettable.c:45
+ * #15 0x0000555555d23873 in resettable_cold_reset_fn (opaque=0x555556a5bd10) at ../hw/core/resettable.c:269
+ * #16 0x0000555555d21d7a in qemu_devices_reset () at ../hw/core/reset.c:69
+ * #17 0x0000555555b4d08c in pc_machine_reset (machine=0x555556a526e0) at ../hw/i386/pc.c:1851
+ * #18 0x0000555555a798ac in qemu_system_reset (reason=SHUTDOWN_CAUSE_GUEST_RESET) at ../softmmu/runstate.c:444
+ * #19 0x0000555555a79f75 in main_loop_should_exit (status=0x7fffffffdc04) at ../softmmu/runstate.c:694
+ * #20 0x0000555555a7a06a in qemu_main_loop () at ../softmmu/runstate.c:730
+ * #21 0x000055555581fe62 in qemu_main (argc=32, argv=0x7fffffffdd58, envp=0x0) at ../softmmu/main.c:38
+ * #22 0x000055555581fe94 in main (argc=32, argv=0x7fffffffdd58) at ../softmmu/main.c:47
+ *
+ *
+ * 在q35 system_reset的时候
+ *
+ * (gdb) bt
+ * #0  acpi_pcihp_reset (s=0x55555708b130, acpihp_root_off=true) at ../hw/acpi/pcihp.c:288
+ * #1  0x000055555586f0cc in pm_reset (opaque=0x55555708a790) at ../hw/acpi/ich9.c:281
+ * #2  0x0000555555d21d7a in qemu_devices_reset () at ../hw/core/reset.c:69
+ * #3  0x0000555555b4d08c in pc_machine_reset (machine=0x555556a528f0) at ../hw/i386/pc.c:1851
+ * #4  0x0000555555a798ac in qemu_system_reset (reason=SHUTDOWN_CAUSE_HOST_QMP_SYSTEM_RESET) at ../softmmu/runstate.c:444
+ * #5  0x0000555555a79f75 in main_loop_should_exit (status=0x7fffffffdbb4) at ../softmmu/runstate.c:694
+ * #6  0x0000555555a7a06a in qemu_main_loop () at ../softmmu/runstate.c:730
+ * #7  0x000055555581fe62 in qemu_main (argc=36, argv=0x7fffffffdd08, envp=0x0) at ../softmmu/main.c:38
+ * #8  0x000055555581fe94 in main (argc=36, argv=0x7fffffffdd08) at ../softmmu/main.c:47
+ *
+ * (gdb) bt
+ * #0  acpi_pcihp_reset (s=0x55555708b130, acpihp_root_off=true) at ../hw/acpi/pcihp.c:288
+ * #1  0x000055555586f0cc in pm_reset (opaque=0x55555708a790) at ../hw/acpi/ich9.c:281
+ * #2  0x0000555555d21d7a in qemu_devices_reset () at ../hw/core/reset.c:69
+ * #3  0x0000555555b4d08c in pc_machine_reset (machine=0x555556a528f0) at ../hw/i386/pc.c:1851
+ * #4  0x0000555555a798ac in qemu_system_reset (reason=SHUTDOWN_CAUSE_GUEST_RESET) at ../softmmu/runstate.c:444
+ * #5  0x0000555555a79f75 in main_loop_should_exit (status=0x7fffffffdbb4) at ../softmmu/runstate.c:694
+ * #6  0x0000555555a7a06a in qemu_main_loop () at ../softmmu/runstate.c:730
+ * #7  0x000055555581fe62 in qemu_main (argc=36, argv=0x7fffffffdd08, envp=0x0) at ../softmmu/main.c:38
+ * #8  0x000055555581fe94 in main (argc=36, argv=0x7fffffffdd08) at ../softmmu/main.c:47
+ *
+ * called by:
+ *   - hw/acpi/ich9.c|281| <<pm_reset>> acpi_pcihp_reset(&pm->acpi_pci_hotplug, true);
+ *   - hw/acpi/piix4.c|308| <<piix4_pm_reset>> acpi_pcihp_reset(&s->acpi_pci_hotplug, !s->use_acpi_root_pci_hotplug);
+ */
 void acpi_pcihp_reset(AcpiPciHpState *s, bool acpihp_root_off)
 {
     if (acpihp_root_off) {
@@ -538,6 +645,11 @@ static const MemoryRegionOps acpi_pcihp_io_ops = {
     },
 };
 
+/*
+ * called by:
+ *   - hw/acpi/ich9.c|323| <<ich9_pm_init>> acpi_pcihp_init(OBJECT(lpc_pci),
+ *   - hw/acpi/piix4.c|565| <<piix4_acpi_system_hot_add_init>> acpi_pcihp_init(OBJECT(s), &s->acpi_pci_hotplug, bus, parent,
+ */
 void acpi_pcihp_init(Object *owner, AcpiPciHpState *s, PCIBus *root_bus,
                      MemoryRegion *address_space_io, bool bridges_enabled,
                      uint16_t io_base)
diff --git a/hw/acpi/piix4.c b/hw/acpi/piix4.c
index 0a81f1ad9..7d75ec0f2 100644
--- a/hw/acpi/piix4.c
+++ b/hw/acpi/piix4.c
@@ -279,6 +279,10 @@ static const VMStateDescription vmstate_acpi = {
     }
 };
 
+/*
+ * 在以下使用piix4_pm_reset():
+ *   - hw/acpi/piix4.c|630| <<piix4_pm_class_init>> dc->reset = piix4_pm_reset;
+ */
 static void piix4_pm_reset(DeviceState *dev)
 {
     PIIX4PMState *s = PIIX4_PM(dev);
@@ -542,6 +546,32 @@ static bool piix4_get_cpu_hotplug_legacy(Object *obj, Error **errp)
     return s->cpu_hotplug_legacy;
 }
 
+/*
+ * (gdb) bt
+ * #0  piix4_set_cpu_hotplug_legacy (obj=0x55555776d210, value=false, errp=0x5555567d3638 <error_abort>) at ../hw/acpi/piix4.c:551
+ * #1  0x0000555555d2a9e5 in property_set_bool (obj=0x55555776d210, v=0x7ffe64000910, name=0x555555f9c800 "cpu-hotplug-legacy", opaque=0x555557844a40, errp=0x5555567d3638 <error_abort>) at ../qom/object.c:2273
+ * #2  0x0000555555d28a2c in object_property_set (obj=0x55555776d210, name=0x555555f9c800 "cpu-hotplug-legacy", v=0x7ffe64000910, errp=0x5555567d3638 <error_abort>) at ../qom/object.c:1408
+ * #3  0x0000555555d2cdd7 in object_property_set_qobject (obj=0x55555776d210, name=0x555555f9c800 "cpu-hotplug-legacy", value=0x7ffe640008f0, errp=0x5555567d3638 <error_abort>) at ../qom/qom-qobject.c:28
+ * #4  0x0000555555d28d91 in object_property_set_bool (obj=0x55555776d210, name=0x555555f9c800 "cpu-hotplug-legacy", value=false, errp=0x5555567d3638 <error_abort>) at ../qom/object.c:1477
+ * #5  0x000055555586006e in cpu_status_write (opaque=0x55555776f250, addr=0, data=0, size=1) at ../hw/acpi/cpu_hotplug.c:44
+ * #6  0x0000555555c650e8 in memory_region_write_accessor (mr=0x55555776f260, addr=0, value=0x7ffe6d7fc6a8, size=1, shift=0, mask=255, attrs=...) at ../softmmu/memory.c:492
+ * #7  0x0000555555c6532c in access_with_adjusted_size (addr=0, value=0x7ffe6d7fc6a8, size=1, access_size_min=1, access_size_max=4, access_fn=
+ *                        0x555555c64ff2 <memory_region_write_accessor>, mr=0x55555776f260, attrs=...) at ../softmmu/memory.c:554
+ * #8  0x0000555555c68422 in memory_region_dispatch_write (mr=0x55555776f260, addr=0, data=0, op=MO_8, attrs=...) at ../softmmu/memory.c:1514
+ * #9  0x0000555555c7593b in flatview_write_continue (fv=0x7ffe682fa420, addr=44800, attrs=..., ptr=0x7ffff7fed000, len=4, addr1=0, l=1, mr=0x55555776f260) at ../softmmu/physmem.c:2825
+ * #10 0x0000555555c75a9e in flatview_write (fv=0x7ffe682fa420, addr=44800, attrs=..., buf=0x7ffff7fed000, len=4) at ../softmmu/physmem.c:2867
+ * #11 0x0000555555c75e4e in address_space_write (as=0x5555567b5420 <address_space_io>, addr=44800, attrs=..., buf=0x7ffff7fed000, len=4) at ../softmmu/physmem.c:2963
+ * #12 0x0000555555c75ebb in address_space_rw (as=0x5555567b5420 <address_space_io>, addr=44800, attrs=..., buf=0x7ffff7fed000, len=4, is_write=true) at ../softmmu/physmem.c:2973
+ * #13 0x0000555555d0dba8 in kvm_handle_io (port=44800, attrs=..., data=0x7ffff7fed000, direction=1, size=4, count=1) at ../accel/kvm/kvm-all.c:2693
+ * #14 0x0000555555d0e322 in kvm_cpu_exec (cpu=0x555556af1d60) at ../accel/kvm/kvm-all.c:2944
+ * #15 0x0000555555d10fef in kvm_vcpu_thread_fn (arg=0x555556af1d60) at ../accel/kvm/kvm-accel-ops.c:49
+ * #16 0x0000555555eec523 in qemu_thread_start (args=0x555556b01170) at ../util/qemu-thread-posix.c:504
+ * #17 0x00007ffff55eeea5 in start_thread () at /lib64/libpthread.so.0
+ * #18 0x00007ffff53179fd in clone () at /lib64/libc.so.6
+ *
+ * 在以下使用piix4_set_cpu_hotplug_legacy():
+ *   - hw/acpi/piix4.c|599| <<piix4_acpi_system_hot_add_init>> object_property_add_bool(OBJECT(s), "cpu-hotplug-legacy", piix4_get_cpu_hotplug_legacy, piix4_set_cpu_hotplug_legacy);
+ */
 static void piix4_set_cpu_hotplug_legacy(Object *obj, bool value, Error **errp)
 {
     PIIX4PMState *s = PIIX4_PM(obj);
diff --git a/hw/block/dataplane/virtio-blk.c b/hw/block/dataplane/virtio-blk.c
index 26f965cab..ad64bcda5 100644
--- a/hw/block/dataplane/virtio-blk.c
+++ b/hw/block/dataplane/virtio-blk.c
@@ -26,6 +26,129 @@
 #include "hw/virtio/virtio-bus.h"
 #include "qom/object_interfaces.h"
 
+/*
+ * 启动的时候先 (猜测是BIOS)
+ *
+ * (gdb) bt
+ * #0  virtio_blk_data_plane_start (vdev=0x5555578a0020) at ../hw/block/dataplane/virtio-blk.c:159
+ * #1  0x0000555555a4e32d in virtio_bus_start_ioeventfd (bus=0x55555789ff98) at ../hw/virtio/virtio-bus.c:236
+ * #2  0x0000555555a4fb32 in virtio_pci_start_ioeventfd (proxy=0x555557897c60) at ../hw/virtio/virtio-pci.c:290
+ * #3  0x0000555555a51fd2 in virtio_pci_common_write (opaque=0x555557897c60, addr=20, val=15, size=1) at ../hw/virtio/virtio-pci.c:1302
+ * #4  0x0000555555c650a3 in memory_region_write_accessor (mr=0x555557898790, addr=20, value=0x7fffed7a96e8, size=1, shift=0, mask=255, attrs=...) at ../softmmu/memory.c:492
+ * #5  0x0000555555c652e7 in access_with_adjusted_size (addr=20, value=0x7fffed7a96e8, size=1, access_size_min=1, access_size_max=4, access_fn=0x555555c64fad <memory_region_write_accessor>,
+ *                        mr=0x555557898790, attrs=...) at ../softmmu/memory.c:554
+ * #6  0x0000555555c683dd in memory_region_dispatch_write (mr=0x555557898790, addr=20, data=15, op=MO_8, attrs=...) at ../softmmu/memory.c:1514
+ * #7  0x0000555555c758f6 in flatview_write_continue (fv=0x7ffe5815c3e0, addr=4261412884, attrs=..., ptr=0x7ffff7ff2028, len=1, addr1=20, l=1, mr=0x555557898790) at ../softmmu/physmem.c:2825
+ * #8  0x0000555555c75a59 in flatview_write (fv=0x7ffe5815c3e0, addr=4261412884, attrs=..., buf=0x7ffff7ff2028, len=1) at ../softmmu/physmem.c:2867
+ * #9  0x0000555555c75e09 in address_space_write (as=0x5555567b3480 <address_space_memory>, addr=4261412884, attrs=..., buf=0x7ffff7ff2028, len=1) at ../softmmu/physmem.c:2963
+ * #10 0x0000555555c75e76 in address_space_rw (as=0x5555567b3480 <address_space_memory>, addr=4261412884, attrs=..., buf=0x7ffff7ff2028, len=1, is_write=true) at ../softmmu/physmem.c:2973
+ * #11 0x0000555555d0e32a in kvm_cpu_exec (cpu=0x555556ac6d40) at ../accel/kvm/kvm-all.c:2954
+ * #12 0x0000555555d10faa in kvm_vcpu_thread_fn (arg=0x555556ac6d40) at ../accel/kvm/kvm-accel-ops.c:49
+ * #13 0x0000555555eec4de in qemu_thread_start (args=0x555556ad63c0) at ../util/qemu-thread-posix.c:504
+ * #14 0x00007ffff55eeea5 in start_thread () at /lib64/libpthread.so.0
+ * #15 0x00007ffff53179fd in clone () at /lib64/libc.so.6
+ *
+ * 猜测下面两个是kernel
+ *
+ * (gdb) bt
+ * #0  virtio_blk_data_plane_stop (vdev=0x5555578a0020) at ../hw/block/dataplane/virtio-blk.c:305
+ * #1  0x0000555555a4e3bc in virtio_bus_stop_ioeventfd (bus=0x55555789ff98) at ../hw/virtio/virtio-bus.c:259
+ * #2  0x0000555555a4fb53 in virtio_pci_stop_ioeventfd (proxy=0x555557897c60) at ../hw/virtio/virtio-pci.c:295
+ * #3  0x0000555555a51fa5 in virtio_pci_common_write (opaque=0x555557897c60, addr=20, val=0, size=1) at ../hw/virtio/virtio-pci.c:1296
+ * #4  0x0000555555c650a3 in memory_region_write_accessor (mr=0x555557898790, addr=20, value=0x7fffed7a96e8, size=1, shift=0, mask=255, attrs=...) at ../softmmu/memory.c:492
+ * #5  0x0000555555c652e7 in access_with_adjusted_size (addr=20, value=0x7fffed7a96e8, size=1, access_size_min=1, access_size_max=4, access_fn=0x555555c64fad <memory_region_write_accessor>,
+ *                        mr=0x555557898790, attrs=...) at ../softmmu/memory.c:554
+ * #6  0x0000555555c683dd in memory_region_dispatch_write (mr=0x555557898790, addr=20, data=0, op=MO_8, attrs=...) at ../softmmu/memory.c:1514
+ * #7  0x0000555555c758f6 in flatview_write_continue (fv=0x7ffe5466d660, addr=4261412884, attrs=..., ptr=0x7ffff7ff2028, len=1, addr1=20, l=1, mr=0x555557898790) at ../softmmu/physmem.c:2825
+ * #8  0x0000555555c75a59 in flatview_write (fv=0x7ffe5466d660, addr=4261412884, attrs=..., buf=0x7ffff7ff2028, len=1) at ../softmmu/physmem.c:2867
+ * #9  0x0000555555c75e09 in address_space_write (as=0x5555567b3480 <address_space_memory>, addr=4261412884, attrs=..., buf=0x7ffff7ff2028, len=1) at ../softmmu/physmem.c:2963
+ * #10 0x0000555555c75e76 in address_space_rw (as=0x5555567b3480 <address_space_memory>, addr=4261412884, attrs=..., buf=0x7ffff7ff2028, len=1, is_write=true) at ../softmmu/physmem.c:2973
+ * #11 0x0000555555d0e32a in kvm_cpu_exec (cpu=0x555556ac6d40) at ../accel/kvm/kvm-all.c:2954
+ * #12 0x0000555555d10faa in kvm_vcpu_thread_fn (arg=0x555556ac6d40) at ../accel/kvm/kvm-accel-ops.c:49
+ * #13 0x0000555555eec4de in qemu_thread_start (args=0x555556ad63c0) at ../util/qemu-thread-posix.c:504
+ * #14 0x00007ffff55eeea5 in start_thread () at /lib64/libpthread.so.0
+ * #15 0x00007ffff53179fd in clone () at /lib64/libc.so.6
+ *
+ * (gdb) bt
+ * #0  virtio_blk_data_plane_start (vdev=0x5555578a0020) at ../hw/block/dataplane/virtio-blk.c:159
+ * #1  0x0000555555a4e32d in virtio_bus_start_ioeventfd (bus=0x55555789ff98) at ../hw/virtio/virtio-bus.c:236
+ * #2  0x0000555555a4fb32 in virtio_pci_start_ioeventfd (proxy=0x555557897c60) at ../hw/virtio/virtio-pci.c:290
+ * #3  0x0000555555a51fd2 in virtio_pci_common_write (opaque=0x555557897c60, addr=20, val=15, size=1) at ../hw/virtio/virtio-pci.c:1302
+ * #4  0x0000555555c650a3 in memory_region_write_accessor (mr=0x555557898790, addr=20, value=0x7fffecfa86e8, size=1, shift=0, mask=255, attrs=...) at ../softmmu/memory.c:492
+ * #5  0x0000555555c652e7 in access_with_adjusted_size (addr=20, value=0x7fffecfa86e8, size=1, access_size_min=1, access_size_max=4, access_fn=0x555555c64fad <memory_region_write_accessor>,
+ *                        mr=0x555557898790, attrs=...) at ../softmmu/memory.c:554
+ * #6  0x0000555555c683dd in memory_region_dispatch_write (mr=0x555557898790, addr=20, data=15, op=MO_8, attrs=...) at ../softmmu/memory.c:1514
+ * #7  0x0000555555c758f6 in flatview_write_continue (fv=0x7ffe5816c250, addr=4261412884, attrs=..., ptr=0x7ffff7fef028, len=1, addr1=20, l=1, mr=0x555557898790) at ../softmmu/physmem.c:2825
+ * #8  0x0000555555c75a59 in flatview_write (fv=0x7ffe5816c250, addr=4261412884, attrs=..., buf=0x7ffff7fef028, len=1) at ../softmmu/physmem.c:2867
+ * #9  0x0000555555c75e09 in address_space_write (as=0x5555567b3480 <address_space_memory>, addr=4261412884, attrs=..., buf=0x7ffff7fef028, len=1) at ../softmmu/physmem.c:2963
+ * #10 0x0000555555c75e76 in address_space_rw (as=0x5555567b3480 <address_space_memory>, addr=4261412884, attrs=..., buf=0x7ffff7fef028, len=1, is_write=true) at ../softmmu/physmem.c:2973
+ * #11 0x0000555555d0e32a in kvm_cpu_exec (cpu=0x555556b01db0) at ../accel/kvm/kvm-all.c:2954
+ * #12 0x0000555555d10faa in kvm_vcpu_thread_fn (arg=0x555556b01db0) at ../accel/kvm/kvm-accel-ops.c:49
+ * #13 0x0000555555eec4de in qemu_thread_start (args=0x555556b11070) at ../util/qemu-thread-posix.c:504
+ * #14 0x00007ffff55eeea5 in start_thread () at /lib64/libpthread.so.0
+ * #15 0x00007ffff53179fd in clone () at /lib64/libc.so.6
+ *
+ * 调用stop的时候
+ *
+ * (gdb) bt
+ * #0  virtio_blk_data_plane_stop (vdev=0x5555578a0020) at ../hw/block/dataplane/virtio-blk.c:305
+ * #1  0x0000555555a4e3bc in virtio_bus_stop_ioeventfd (bus=0x55555789ff98) at ../hw/virtio/virtio-bus.c:259
+ * #2  0x0000555555a4fb53 in virtio_pci_stop_ioeventfd (proxy=0x555557897c60) at ../hw/virtio/virtio-pci.c:295
+ * #3  0x0000555555a518b6 in virtio_pci_vmstate_change (d=0x555557897c60, running=false) at ../hw/virtio/virtio-pci.c:1108
+ * #4  0x0000555555c29613 in virtio_vmstate_change (opaque=0x5555578a0020, running=false, state=RUN_STATE_PAUSED) at ../hw/virtio/virtio.c:3241
+ * #5  0x0000555555a79695 in vm_state_notify (running=false, state=RUN_STATE_PAUSED) at ../softmmu/runstate.c:334
+ * #6  0x0000555555a713d6 in do_vm_stop (state=RUN_STATE_PAUSED, send_stop=true) at ../softmmu/cpus.c:262
+ * #7  0x0000555555a720e2 in vm_stop (state=RUN_STATE_PAUSED) at ../softmmu/cpus.c:667
+ * #8  0x0000555555ace18c in qmp_stop (errp=0x0) at ../monitor/qmp-cmds.c:97
+ * #9  0x0000555555ac55f0 in hmp_stop (mon=0x555556845690, qdict=0x555557170620) at ../monitor/hmp-cmds.c:916
+ * #10 0x0000555555accc3e in handle_hmp_command_exec (mon=0x555556845690, cmd=0x5555566fa850 <hmp_cmds+7600>, qdict=0x555557170620) at ../monitor/hmp.c:1103
+ * #11 0x0000555555acce6b in handle_hmp_command (mon=0x555556845690, cmdline=0x555556ac41d4 "") at ../monitor/hmp.c:1155
+ * #12 0x0000555555aca384 in monitor_command_cb (opaque=0x555556845690, cmdline=0x555556ac41d0 "stop", readline_opaque=0x0) at ../monitor/hmp.c:49
+ * #13 0x0000555555f195dd in readline_handle_byte (rs=0x555556ac41d0, ch=13) at ../util/readline.c:411
+ * #14 0x0000555555acd9a8 in monitor_read (opaque=0x555556845690, buf=0x7fffffffca60 "\r\320\377\377\377\177", size=1) at ../monitor/hmp.c:1393
+ * #15 0x0000555555e31613 in qemu_chr_be_write_impl (s=0x555556a67330, buf=0x7fffffffca60 "\r\320\377\377\377\177", len=1) at ../chardev/char.c:201
+ * #16 0x0000555555e31677 in qemu_chr_be_write (s=0x555556a67330, buf=0x7fffffffca60 "\r\320\377\377\377\177", len=1) at ../chardev/char.c:213
+ * #17 0x0000555555e340a4 in fd_chr_read (chan=0x555556a68290, cond=G_IO_IN, opaque=0x555556a67330) at ../chardev/char-fd.c:72
+ * #18 0x0000555555d335b4 in qio_channel_fd_source_dispatch (source=0x55555711f340, callback=0x555555e33f7a <fd_chr_read>, user_data=0x555556a67330) at ../io/channel-watch.c:84
+ * #19 0x00007ffff6c40119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #20 0x0000555555f12010 in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #21 0x0000555555f1208a in os_host_main_loop_wait (timeout=499000000) at ../util/main-loop.c:320
+ * #22 0x0000555555f1218f in main_loop_wait (nonblocking=0) at ../util/main-loop.c:596
+ * #23 0x0000555555a7a05e in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #24 0x000055555581fe62 in qemu_main (argc=32, argv=0x7fffffffdd48, envp=0x0) at ../softmmu/main.c:38
+ * #25 0x000055555581fe94 in main (argc=32, argv=0x7fffffffdd48) at ../softmmu/main.c:47
+ *
+ * 调用start的时候
+ *
+ * (gdb) bt
+ * #0  virtio_blk_data_plane_start (vdev=0x5555578a0020) at ../hw/block/dataplane/virtio-blk.c:159
+ * #1  0x0000555555a4e32d in virtio_bus_start_ioeventfd (bus=0x55555789ff98) at ../hw/virtio/virtio-bus.c:236
+ * #2  0x0000555555a4fb32 in virtio_pci_start_ioeventfd (proxy=0x555557897c60) at ../hw/virtio/virtio-pci.c:290
+ * #3  0x0000555555a518a8 in virtio_pci_vmstate_change (d=0x555557897c60, running=true) at ../hw/virtio/virtio-pci.c:1106
+ * #4  0x0000555555c29613 in virtio_vmstate_change (opaque=0x5555578a0020, running=true, state=RUN_STATE_RUNNING) at ../hw/virtio/virtio.c:3241
+ * #5  0x0000555555a79646 in vm_state_notify (running=true, state=RUN_STATE_RUNNING) at ../softmmu/runstate.c:330
+ * #6  0x0000555555a7218a in vm_prepare_start (step_pending=false) at ../softmmu/cpus.c:708
+ * #7  0x0000555555a721b3 in vm_start () at ../softmmu/cpus.c:714
+ * #8  0x0000555555ace34f in qmp_cont (errp=0x7fffffffc800) at ../monitor/qmp-cmds.c:157
+ * #9  0x0000555555ac5c06 in hmp_cont (mon=0x555556845690, qdict=0x555557170620) at ../monitor/hmp-cmds.c:1045
+ * #10 0x0000555555accc3e in handle_hmp_command_exec (mon=0x555556845690, cmd=0x5555566f9130 <hmp_cmds+1680>, qdict=0x555557170620) at ../monitor/hmp.c:1103
+ * #11 0x0000555555acce6b in handle_hmp_command (mon=0x555556845690, cmdline=0x555556ac41d4 "") at ../monitor/hmp.c:1155
+ * #12 0x0000555555aca384 in monitor_command_cb (opaque=0x555556845690, cmdline=0x555556ac41d0 "cont", readline_opaque=0x0) at ../monitor/hmp.c:49
+ * #13 0x0000555555f195dd in readline_handle_byte (rs=0x555556ac41d0, ch=13) at ../util/readline.c:411
+ * #14 0x0000555555acd9a8 in monitor_read (opaque=0x555556845690, buf=0x7fffffffca60 "\r\320\377\377\377\177", size=1) at ../monitor/hmp.c:1393
+ * #15 0x0000555555e31613 in qemu_chr_be_write_impl (s=0x555556a67330, buf=0x7fffffffca60 "\r\320\377\377\377\177", len=1) at ../chardev/char.c:201
+ * #16 0x0000555555e31677 in qemu_chr_be_write (s=0x555556a67330, buf=0x7fffffffca60 "\r\320\377\377\377\177", len=1) at ../chardev/char.c:213
+ * #17 0x0000555555e340a4 in fd_chr_read (chan=0x555556a68290, cond=G_IO_IN, opaque=0x555556a67330) at ../chardev/char-fd.c:72
+ * #18 0x0000555555d335b4 in qio_channel_fd_source_dispatch (source=0x55555711f340, callback=0x555555e33f7a <fd_chr_read>, user_data=0x555556a67330) at ../io/channel-watch.c:84
+ * #19 0x00007ffff6c40119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #20 0x0000555555f12010 in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #21 0x0000555555f1208a in os_host_main_loop_wait (timeout=499000000) at ../util/main-loop.c:320
+ * #22 0x0000555555f1218f in main_loop_wait (nonblocking=0) at ../util/main-loop.c:596
+ * #23 0x0000555555a7a05e in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #24 0x000055555581fe62 in qemu_main (argc=32, argv=0x7fffffffdd48, envp=0x0) at ../softmmu/main.c:38
+ * #25 0x000055555581fe94 in main (argc=32, argv=0x7fffffffdd48) at ../softmmu/main.c:47
+ */
+
 struct VirtIOBlockDataPlane {
     bool starting;
     bool stopping;
diff --git a/hw/block/virtio-blk.c b/hw/block/virtio-blk.c
index e9ba752f6..4525da87d 100644
--- a/hw/block/virtio-blk.c
+++ b/hw/block/virtio-blk.c
@@ -115,6 +115,34 @@ static int virtio_blk_handle_rw_error(VirtIOBlockReq *req, int error,
     return action != BLOCK_ERROR_ACTION_IGNORE;
 }
 
+/*
+ * Thread 3 "IO iothread01" hit Breakpoint 1, blk_aio_complete_bh (opaque=0x7fffe8002800) at ../block/block-backend.c:1511
+ * 1511	    BlkAioEmAIOCB *acb = opaque;
+ * (gdb) bt
+ * #0  blk_aio_complete_bh (opaque=0x7fffe8002800) at ../block/block-backend.c:1511
+ * #1  0x0000555555effdcc in aio_bh_call (bh=0x7fffe8005e20) at ../util/async.c:150
+ * #2  0x0000555555effed6 in aio_bh_poll (ctx=0x555556a67590) at ../util/async.c:178
+ * #3  0x0000555555ee7aa5 in aio_poll (ctx=0x555556a67590, blocking=true) at ../util/aio-posix.c:712
+ * #4  0x0000555555d5cb66 in iothread_run (opaque=0x555556a67220) at ../iothread.c:67
+ * #5  0x0000555555eec4de in qemu_thread_start (args=0x555556a67c00) at ../util/qemu-thread-posix.c:504
+ * #6  0x00007ffff55eeea5 in start_thread () at /lib64/libpthread.so.0
+ * #7  0x00007ffff53179fd in clone () at /lib64/libc.so.6
+ *
+ * Thread 3 "IO iothread01" hit Breakpoint 2, virtio_blk_rw_complete (opaque=0x7fffe80026c0, ret=0) at ../hw/block/virtio-blk.c:120
+ * 120	    VirtIOBlockReq *next = opaque;
+ * (gdb) bt
+ * #0  virtio_blk_rw_complete (opaque=0x7fffe80026c0, ret=0) at ../hw/block/virtio-blk.c:120
+ * #1  0x0000555555d912e6 in blk_aio_complete (acb=0x7fffe8002800) at ../block/block-backend.c:1503
+ * #2  0x0000555555d915ba in blk_aio_write_entry (opaque=0x7fffe8002800) at ../block/block-backend.c:1570
+ * #3  0x0000555555f02abd in coroutine_trampoline (i0=-402628976, i1=32767) at ../util/coroutine-ucontext.c:177
+ * #4  0x00007ffff5261190 in __start_context () at /lib64/libc.so.6
+ * #5  0x00007fffef695cf0 in  ()
+ * #6  0x0000000000000000 in  ()
+ *
+ * 在以下使用virtio_blk_rw_complete():
+ *   - hw/block/virtio-blk.c|431| <<submit_requests>> blk_aio_pwritev(blk, sector_num << BDRV_SECTOR_BITS, qiov, 0, virtio_blk_rw_complete, mrb->reqs[start]);
+ *   - hw/block/virtio-blk.c|437| <<submit_requests>> blk_aio_preadv(blk, sector_num << BDRV_SECTOR_BITS, qiov, 0, virtio_blk_rw_complete, mrb->reqs[start]);
+ */
 static void virtio_blk_rw_complete(void *opaque, int ret)
 {
     VirtIOBlockReq *next = opaque;
@@ -384,6 +412,27 @@ static void virtio_blk_handle_scsi(VirtIOBlockReq *req)
     }
 }
 
+/*
+ * (gdb) bt
+ * #0  submit_requests (blk=0x55555774d840, mrb=0x7fffef696650, start=0, num_reqs=4, niov=512) at ../hw/block/virtio-blk.c:390
+ * #1  0x0000555555bc6563 in virtio_blk_submit_multireq (blk=0x55555774d840, mrb=0x7fffef696650) at ../hw/block/virtio-blk.c:497
+ * #2  0x0000555555bc72e5 in virtio_blk_handle_vq (s=0x5555577489b0, vq=0x555557753d58) at ../hw/block/virtio-blk.c:799
+ * #3  0x0000555555bc739b in virtio_blk_handle_output (vdev=0x5555577489b0, vq=0x555557753d58) at ../hw/block/virtio-blk.c:819
+ * #4  0x0000555555c27448 in virtio_queue_notify_vq (vq=0x555557753d58) at ../hw/virtio/virtio.c:2365
+ * #5  0x0000555555c2a566 in virtio_queue_host_notifier_read (n=0x555557753dcc) at ../hw/virtio/virtio.c:3612
+ * #6  0x0000555555ee6f68 in aio_dispatch_handler (ctx=0x555556a67590, node=0x7ffe4805c8f0) at ../util/aio-posix.c:369
+ * #7  0x0000555555ee705c in aio_dispatch_ready_handlers (ctx=0x555556a67590, ready_list=0x7fffef696880) at ../util/aio-posix.c:399
+ * #8  0x0000555555ee7ac6 in aio_poll (ctx=0x555556a67590, blocking=true) at ../util/aio-posix.c:713
+ * #9  0x0000555555d5cb66 in iothread_run (opaque=0x555556a67220) at ../iothread.c:67
+ * #10 0x0000555555eec4de in qemu_thread_start (args=0x555556a67c00) at ../util/qemu-thread-posix.c:504
+ * #11 0x00007ffff55eeea5 in start_thread () at /lib64/libpthread.so.0
+ * #12 0x00007ffff53179fd in clone () at /lib64/libc.so.6
+ *
+ * called by:
+ *   - hw/block/virtio-blk.c|460| <<virtio_blk_submit_multireq>> submit_requests(blk, mrb, 0, 1, -1);
+ *   - hw/block/virtio-blk.c|484| <<virtio_blk_submit_multireq>> submit_requests(blk, mrb, start, num_reqs, niov);
+ *   - hw/block/virtio-blk.c|500| <<virtio_blk_submit_multireq>> submit_requests(blk, mrb, start, num_reqs, niov);
+ */
 static inline void submit_requests(BlockBackend *blk, MultiReqBuffer *mrb,
                                    int start, int num_reqs, int niov)
 {
@@ -424,6 +473,9 @@ static inline void submit_requests(BlockBackend *blk, MultiReqBuffer *mrb,
         blk_aio_pwritev(blk, sector_num << BDRV_SECTOR_BITS, qiov, 0,
                         virtio_blk_rw_complete, mrb->reqs[start]);
     } else {
+        /*
+	 * QEMUIOVector *qiov:
+	 */
         blk_aio_preadv(blk, sector_num << BDRV_SECTOR_BITS, qiov, 0,
                        virtio_blk_rw_complete, mrb->reqs[start]);
     }
@@ -447,6 +499,13 @@ static int multireq_compare(const void *a, const void *b)
     }
 }
 
+/*
+ * called by:
+ *   - hw/block/virtio-blk.c|515| <<virtio_blk_handle_flush>> virtio_blk_submit_multireq(s->blk, mrb);
+ *   - hw/block/virtio-blk.c|695| <<virtio_blk_handle_request>> virtio_blk_submit_multireq(s->blk, mrb);
+ *   - hw/block/virtio-blk.c|802| <<virtio_blk_handle_vq>> virtio_blk_submit_multireq(s->blk, &mrb);
+ *   - hw/block/virtio-blk.c|851| <<virtio_blk_process_queued_requests>> virtio_blk_submit_multireq(s->blk, &mrb);
+ */
 static void virtio_blk_submit_multireq(BlockBackend *blk, MultiReqBuffer *mrb)
 {
     int i = 0, start = 0, num_reqs = 0, niov = 0, nb_sectors = 0;
@@ -614,6 +673,11 @@ err:
     return err_status;
 }
 
+/*
+ * called by:
+ *   - hw/block/virtio-blk.c|806| <<virtio_blk_handle_vq>> if (virtio_blk_handle_request(req, &mrb)) {
+ *   - hw/block/virtio-blk.c|861| <<virtio_blk_process_queued_requests>> if (virtio_blk_handle_request(req, &mrb)) {
+ */
 static int virtio_blk_handle_request(VirtIOBlockReq *req, MultiReqBuffer *mrb)
 {
     uint32_t type;
@@ -768,12 +832,23 @@ static int virtio_blk_handle_request(VirtIOBlockReq *req, MultiReqBuffer *mrb)
     return 0;
 }
 
+/*
+ * called by:
+ *   - hw/block/virtio-blk.c|835| <<virtio_blk_handle_output>> virtio_blk_handle_vq(s, vq);
+ */
 void virtio_blk_handle_vq(VirtIOBlock *s, VirtQueue *vq)
 {
     VirtIOBlockReq *req;
     MultiReqBuffer mrb = {};
     bool suppress_notifications = virtio_queue_get_notification(vq);
 
+    /*
+     * VirtIOBlock *s:
+     * -> VirtIODevice parent_obj;
+     * -> BlockBackend *blk;
+     *    -> BdrvChild *root;
+     *    -> AioContext *ctx;
+     */
     aio_context_acquire(blk_get_aio_context(s->blk));
     blk_io_plug(s->blk);
 
@@ -803,6 +878,86 @@ void virtio_blk_handle_vq(VirtIOBlock *s, VirtQueue *vq)
     aio_context_release(blk_get_aio_context(s->blk));
 }
 
+/*
+ * 正常没有backup的例子
+ * (gdb) p *s->blk->root->bs
+ * $7 = {open_flags = 8226, encrypted = false, sg = false, probed = false, force_share = false, implicit = false,
+ *   drv = 0x5555564fef00 <bdrv_qcow2>, opaque = 0x5555567fb080, aio_context = 0x5555565cac80, aio_notifiers = {lh_first = 0x0},
+ *   walking_aio_notifiers = false, filename = "test01.qcow2", '\000' <repeats 4083 times>, backing_file = '\000' <repeats 4095 times>,
+ *   auto_backing_file = '\000' <repeats 4095 times>, backing_format = '\000' <repeats 15 times>, full_open_options = 0x0,
+ *   exact_filename = "test01.qcow2", '\000' <repeats 4083 times>, backing = 0x0, file = 0x5555567f9150, bl = {request_alignment = 1,
+ *     max_pdiscard = 0, pdiscard_alignment = 65536, max_pwrite_zeroes = 0, pwrite_zeroes_alignment = 65536, opt_transfer = 0,
+ *     max_transfer = 0, max_hw_transfer = 0, max_hw_iov = 0, min_mem_alignment = 512, opt_mem_alignment = 4096, max_iov = 1024},
+ *   supported_read_flags = 0, supported_write_flags = 0, supported_zero_flags = 260, supported_truncate_flags = 2,
+ *   node_name = "drive01", '\000' <repeats 24 times>, node_list = {tqe_next = 0x555556814390, tqe_circ = {tql_next = 0x555556814390,
+ *       tql_prev = 0x5555567f1478}}, bs_list = {tqe_next = 0x55555680d050, tqe_circ = {tql_next = 0x55555680d050,
+ *       tql_prev = 0x5555567f1488}}, monitor_list = {tqe_next = 0x0, tqe_circ = {tql_next = 0x0, tql_prev = 0x5555567f1498}}, refcnt = 2,
+ *   op_blockers = {{lh_first = 0x0} <repeats 16 times>}, inherits_from = 0x0, children = {lh_first = 0x5555567f9150}, parents = {
+ *     lh_first = 0x5555574eef50}, options = 0x5555567f1850, explicit_options = 0x5555567f7110,
+ *   detect_zeroes = BLOCKDEV_DETECT_ZEROES_OPTIONS_OFF, backing_blocker = 0x0, total_sectors = 2097152, write_threshold_offset = 0,
+ *   dirty_bitmap_mutex = {lock = {__data = {__lock = 0, __count = 0, __owner = 0, __nusers = 0, __kind = 0, __spins = 0, __elision = 0,
+ *         __list = {__prev = 0x0, __next = 0x0}}, __size = '\000' <repeats 39 times>, __align = 0}, initialized = true}, dirty_bitmaps = {
+ *     lh_first = 0x0}, wr_highest_offset = {value = 0}, copy_on_read = 0, in_flight = 0, serialising_in_flight = 0, io_plugged = 0,
+ *   enable_write_cache = 0, quiesce_counter = 0, recursive_quiesce_counter = 0, write_gen = 0, reqs_lock = {locked = 0, ctx = 0x0,
+ *     from_push = {slh_first = 0x0}, to_pop = {slh_first = 0x0}, handoff = 0, sequence = 0, holder = 0x0}, tracked_requests = {
+ *     lh_first = 0x0}, flush_queue = {entries = {sqh_first = 0x0, sqh_last = 0x5555567f70b0}}, active_flush_req = false, flushed_gen = 0,
+ *   never_freeze = false, bsc_modify_lock = {locked = 0, ctx = 0x0, from_push = {slh_first = 0x0}, to_pop = {slh_first = 0x0},
+ *     handoff = 0, sequence = 0, holder = 0x0}, block_status_cache = 0x5555567f2950}
+ *
+ *
+ * (gdb) p *s->blk->root->bs
+ * $10 = {open_flags = 8226, encrypted = false, sg = false, probed = false, force_share = false, implicit = false,
+ *   drv = 0x5555564fef00 <bdrv_qcow2>, opaque = 0x555556c3a000, aio_context = 0x5555565cac80, aio_notifiers = {lh_first = 0x0},
+ *   walking_aio_notifiers = false, filename = "/tmp/overlay01.qcow2", '\000' <repeats 4075 times>,
+ *   backing_file = "test01.qcow2", '\000' <repeats 4083 times>, auto_backing_file = "test01.qcow2", '\000' <repeats 4083 times>,
+ *   backing_format = "qcow2\000\000\000\000\000\000\000\000\000\000", full_open_options = 0x0,
+ *   exact_filename = "/tmp/overlay01.qcow2", '\000' <repeats 4075 times>, backing = 0x555556d0aa10, file = 0x555556a08610, bl = {
+ *     request_alignment = 1, max_pdiscard = 0, pdiscard_alignment = 65536, max_pwrite_zeroes = 0, pwrite_zeroes_alignment = 65536,
+ *     opt_transfer = 0, max_transfer = 0, max_hw_transfer = 0, max_hw_iov = 0, min_mem_alignment = 512, opt_mem_alignment = 4096,
+ *     max_iov = 1024}, supported_read_flags = 0, supported_write_flags = 0, supported_zero_flags = 260, supported_truncate_flags = 2,
+ *   node_name = "over01", '\000' <repeats 25 times>, node_list = {tqe_next = 0x0, tqe_circ = {tql_next = 0x0, tql_prev = 0x555556e256e8}},
+ *   bs_list = {tqe_next = 0x555556e21600, tqe_circ = {tql_next = 0x555556e21600, tql_prev = 0x555556818488}}, monitor_list = {
+ *     tqe_next = 0x0, tqe_circ = {tql_next = 0x0, tql_prev = 0x0}}, refcnt = 1, op_blockers = {{lh_first = 0x0} <repeats 16 times>},
+ *   inherits_from = 0x0, children = {lh_first = 0x555556d0aa10}, parents = {lh_first = 0x5555574eef50}, options = 0x5555575bd000,
+ *   explicit_options = 0x555556e19890, detect_zeroes = BLOCKDEV_DETECT_ZEROES_OPTIONS_OFF, backing_blocker = 0x55555712d020,
+ *   total_sectors = 2097152, write_threshold_offset = 0, dirty_bitmap_mutex = {lock = {__data = {__lock = 0, __count = 0, __owner = 0,
+ *         __nusers = 0, __kind = 0, __spins = 0, __elision = 0, __list = {__prev = 0x0, __next = 0x0}},
+ *       __size = '\000' <repeats 39 times>, __align = 0}, initialized = true}, dirty_bitmaps = {lh_first = 0x0}, wr_highest_offset = {
+ *     value = 0}, copy_on_read = 0, in_flight = 0, serialising_in_flight = 0, io_plugged = 0, enable_write_cache = 0, quiesce_counter = 0,
+ *   recursive_quiesce_counter = 0, write_gen = 0, reqs_lock = {locked = 0, ctx = 0x0, from_push = {slh_first = 0x0}, to_pop = {
+ *       slh_first = 0x0}, handoff = 0, sequence = 0, holder = 0x0}, tracked_requests = {lh_first = 0x0}, flush_queue = {entries = {
+ *       sqh_first = 0x0, sqh_last = 0x555556e62c80}}, active_flush_req = false, flushed_gen = 0, never_freeze = false, bsc_modify_lock = {
+ *     locked = 0, ctx = 0x0, from_push = {slh_first = 0x0}, to_pop = {slh_first = 0x0}, handoff = 0, sequence = 0, holder = 0x0},
+ *   block_status_cache = 0x555557445e50}
+ *
+ * (gdb) p *s->blk->root->bs
+$3 = {open_flags = 2, encrypted = false, sg = false, probed = false, force_share = false, implicit = true, drv = 0x5555564fd880 <bdrv_mirror_top>, 
+  opaque = 0x555557263640, aio_context = 0x5555565cac80, aio_notifiers = {lh_first = 0x0}, walking_aio_notifiers = false, 
+  filename = '\000' <repeats 4095 times>, backing_file = '\000' <repeats 4095 times>, auto_backing_file = '\000' <repeats 4095 times>, 
+  backing_format = '\000' <repeats 15 times>, full_open_options = 0x0, exact_filename = '\000' <repeats 4095 times>, backing = 0x5555569d1330, 
+  file = 0x0, bl = {request_alignment = 1, max_pdiscard = 0, pdiscard_alignment = 0, max_pwrite_zeroes = 0, pwrite_zeroes_alignment = 0, 
+    opt_transfer = 0, max_transfer = 0, max_hw_transfer = 0, max_hw_iov = 0, min_mem_alignment = 512, opt_mem_alignment = 4096, max_iov = 1024}, 
+  supported_read_flags = 0, supported_write_flags = 64, supported_zero_flags = 320, supported_truncate_flags = 0, 
+  node_name = "#block619", '\000' <repeats 22 times>, node_list = {tqe_next = 0x0, tqe_circ = {tql_next = 0x0, tql_prev = 0x555556e62ae8}}, 
+  bs_list = {tqe_next = 0x0, tqe_circ = {tql_next = 0x0, tql_prev = 0x555556e256f8}}, monitor_list = {tqe_next = 0x0, tqe_circ = {tql_next = 0x0, 
+      tql_prev = 0x0}}, refcnt = 2, op_blockers = {{lh_first = 0x555556f37490}, {lh_first = 0x55555746fe50}, {lh_first = 0x555556d0aa10}, {
+      lh_first = 0x55555746fe70}, {lh_first = 0x555556c1cde0}, {lh_first = 0x0}, {lh_first = 0x555556c1cdc0}, {lh_first = 0x555556f374d0}, {
+      lh_first = 0x555556d0aa60}, {lh_first = 0x555556d63b70}, {lh_first = 0x555556efb000}, {lh_first = 0x555556efafe0}, {lh_first = 0x555556ddb040}, 
+    {lh_first = 0x555557536fe0}, {lh_first = 0x555557536fc0}, {lh_first = 0x555557308800}}, inherits_from = 0x0, children = {
+    lh_first = 0x5555569d1330}, parents = {lh_first = 0x555556d28530}, options = 0x5555567f7110, explicit_options = 0x555556fb9800, 
+  detect_zeroes = BLOCKDEV_DETECT_ZEROES_OPTIONS_OFF, backing_blocker = 0x0, total_sectors = 2097152, write_threshold_offset = 0, 
+  dirty_bitmap_mutex = {lock = {__data = {__lock = 0, __count = 0, __owner = 0, __nusers = 0, __kind = 0, __spins = 0, __elision = 0, __list = {
+          __prev = 0x0, __next = 0x0}}, __size = '\000' <repeats 39 times>, __align = 0}, initialized = true}, dirty_bitmaps = {lh_first = 0x0}, 
+  wr_highest_offset = {value = 0}, copy_on_read = 0, in_flight = 0, serialising_in_flight = 0, io_plugged = 0, enable_write_cache = 0, 
+  quiesce_counter = 0, recursive_quiesce_counter = 0, write_gen = 0, reqs_lock = {locked = 0, ctx = 0x0, from_push = {slh_first = 0x0}, to_pop = {
+      slh_first = 0x0}, handoff = 0, sequence = 0, holder = 0x0}, tracked_requests = {lh_first = 0x0}, flush_queue = {entries = {sqh_first = 0x0, 
+      sqh_last = 0x555556882ff0}}, active_flush_req = false, flushed_gen = 0, never_freeze = true, bsc_modify_lock = {locked = 0, ctx = 0x0, 
+    from_push = {slh_first = 0x0}, to_pop = {slh_first = 0x0}, handoff = 0, sequence = 0, holder = 0x0}, block_status_cache = 0x5555567f2870}
+ */
+/*
+ * 在以下使用virtio_blk_handle_output():
+ *   - hw/block/virtio-blk.c|1245| <<virtio_blk_device_realize>> virtio_add_queue(vdev, conf->queue_size, virtio_blk_handle_output);
+ */
 static void virtio_blk_handle_output(VirtIODevice *vdev, VirtQueue *vq)
 {
     VirtIOBlock *s = (VirtIOBlock *)vdev;
@@ -819,6 +974,32 @@ static void virtio_blk_handle_output(VirtIODevice *vdev, VirtQueue *vq)
     virtio_blk_handle_vq(s, vq);
 }
 
+/*
+ * (gdb) bt
+ * #0  virtio_blk_process_queued_requests (s=0x55555789fd40, is_bh=false) at ../hw/block/virtio-blk.c:823
+ * #1  0x0000555555bcaedc in virtio_blk_data_plane_start (vdev=0x55555789fd40) at ../hw/block/dataplane/virtio-blk.c:241
+ * #2  0x0000555555a4e32d in virtio_bus_start_ioeventfd (bus=0x55555789fcb8) at ../hw/virtio/virtio-bus.c:236
+ * #3  0x0000555555a4fb32 in virtio_pci_start_ioeventfd (proxy=0x555557897980) at ../hw/virtio/virtio-pci.c:290
+ * #4  0x0000555555a51fd2 in virtio_pci_common_write (opaque=0x555557897980, addr=20, val=15, size=1) at ../hw/virtio/virtio-pci.c:1302
+ * #5  0x0000555555c650a3 in memory_region_write_accessor (mr=0x5555578984b0, addr=20, value=0x7fffed7a96e8, size=1, shift=0, mask=255, attrs=...) at ../softmmu/memory.c:492
+ * #6  0x0000555555c652e7 in access_with_adjusted_size (addr=20, value=0x7fffed7a96e8, size=1, access_size_min=1, access_size_max=4, access_fn=
+ *     0x555555c64fad <memory_region_write_accessor>, mr=0x5555578984b0, attrs=...) at ../softmmu/memory.c:554
+ * #7  0x0000555555c683dd in memory_region_dispatch_write (mr=0x5555578984b0, addr=20, data=15, op=MO_8, attrs=...) at ../softmmu/memory.c:1514
+ * #8  0x0000555555c758f6 in flatview_write_continue (fv=0x7ffe5849ca90, addr=4261412884, attrs=..., ptr=0x7ffff7ff2028, len=1, addr1=20, l=1, mr=0x5555578984b0) at ../softmmu/physmem.c:2825
+ * #9  0x0000555555c75a59 in flatview_write (fv=0x7ffe5849ca90, addr=4261412884, attrs=..., buf=0x7ffff7ff2028, len=1) at ../softmmu/physmem.c:2867
+ * #10 0x0000555555c75e09 in address_space_write (as=0x5555567b3480 <address_space_memory>, addr=4261412884, attrs=..., buf=0x7ffff7ff2028, len=1) at ../softmmu/physmem.c:2963
+ * #11 0x0000555555c75e76 in address_space_rw (as=0x5555567b3480 <address_space_memory>, addr=4261412884, attrs=..., buf=0x7ffff7ff2028, len=1, is_write=true) at ../softmmu/physmem.c:2973
+ * #12 0x0000555555d0e32a in kvm_cpu_exec (cpu=0x555556ac6d40) at ../accel/kvm/kvm-all.c:2954
+ * #13 0x0000555555d10faa in kvm_vcpu_thread_fn (arg=0x555556ac6d40) at ../accel/kvm/kvm-accel-ops.c:49
+ * #14 0x0000555555eec4de in qemu_thread_start (args=0x555556ad6620) at ../util/qemu-thread-posix.c:504
+ * #15 0x00007ffff55eeea5 in start_thread () at /lib64/libpthread.so.0
+ * #16 0x00007ffff53179fd in clone () at /lib64/libc.so.6
+ *
+ * called by:
+ *   - hw/block/dataplane/virtio-blk.c|241| <<virtio_blk_data_plane_start>> virtio_blk_process_queued_requests(vblk, false);
+ *   - hw/block/dataplane/virtio-blk.c|279| <<virtio_blk_data_plane_start>> virtio_blk_process_queued_requests(vblk, false);
+ *   - hw/block/virtio-blk.c|879| <<virtio_blk_dma_restart_bh>> virtio_blk_process_queued_requests(s, true);
+ */
 void virtio_blk_process_queued_requests(VirtIOBlock *s, bool is_bh)
 {
     VirtIOBlockReq *req = s->rq;
@@ -845,6 +1026,13 @@ void virtio_blk_process_queued_requests(VirtIOBlock *s, bool is_bh)
     }
 
     if (mrb.num_reqs) {
+        /*
+	 * called by:
+	 *   - hw/block/virtio-blk.c|515| <<virtio_blk_handle_flush>> virtio_blk_submit_multireq(s->blk, mrb);
+	 *   - hw/block/virtio-blk.c|695| <<virtio_blk_handle_request>> virtio_blk_submit_multireq(s->blk, mrb);
+	 *   - hw/block/virtio-blk.c|802| <<virtio_blk_handle_vq>> virtio_blk_submit_multireq(s->blk, &mrb);
+	 *   - hw/block/virtio-blk.c|851| <<virtio_blk_process_queued_requests>> virtio_blk_submit_multireq(s->blk, &mrb);
+	 */
         virtio_blk_submit_multireq(s->blk, &mrb);
     }
     if (is_bh) {
@@ -853,6 +1041,10 @@ void virtio_blk_process_queued_requests(VirtIOBlock *s, bool is_bh)
     aio_context_release(blk_get_aio_context(s->conf.conf.blk));
 }
 
+/*
+ * 在以下使用virtio_blk_dma_restart_bh():
+ *   - hw/block/virtio-blk.c|899| <<virtio_blk_dma_restart_cb>> s->bh = aio_bh_new(blk_get_aio_context(s->conf.conf.blk), virtio_blk_dma_restart_bh, s);
+ */
 static void virtio_blk_dma_restart_bh(void *opaque)
 {
     VirtIOBlock *s = opaque;
@@ -863,6 +1055,10 @@ static void virtio_blk_dma_restart_bh(void *opaque)
     virtio_blk_process_queued_requests(s, true);
 }
 
+/*
+ * 在以下使用virtio_blk_dma_restart_cb():
+ *   - hw/block/virtio-blk.c|1245| <<virtio_blk_device_realize>> s->change = qemu_add_vm_change_state_handler(virtio_blk_dma_restart_cb, s);
+ */
 static void virtio_blk_dma_restart_cb(void *opaque, bool running,
                                       RunState state)
 {
@@ -1139,10 +1335,20 @@ static void virtio_blk_device_realize(DeviceState *dev, Error **errp)
 {
     VirtIODevice *vdev = VIRTIO_DEVICE(dev);
     VirtIOBlock *s = VIRTIO_BLK(dev);
+    /*
+     * 在set_drive()设置
+     */
     VirtIOBlkConf *conf = &s->conf;
     Error *err = NULL;
     unsigned i;
 
+    /*
+     * VirtIOBlkConf *conf:
+     * -> BlockConf conf;
+     *    -> BlockBackend *blk;
+     *
+     * 在set_drive()设置
+     */
     if (!conf->conf.blk) {
         error_setg(errp, "drive property not set");
         return;
diff --git a/hw/core/loader.c b/hw/core/loader.c
index 054883073..73bade68c 100644
--- a/hw/core/loader.c
+++ b/hw/core/loader.c
@@ -953,6 +953,26 @@ static void fw_cfg_resized(const char *id, uint64_t length, void *host)
     }
 }
 
+/*
+ * (gdb) bt
+ * #0  rom_set_mr (rom=0x555557188600, owner=0x555556be1650, name=0x7fffffffd960 "/rom@etc/acpi/tables", ro=true) at ../hw/core/loader.c:960
+ * #1  0x00005555558a2438 in rom_add_blob
+ *     (name=0x55555606e4db "etc/acpi/tables", blob=0x5555570cfdc0, len=131072, max_len=2097152, addr=18446744073709551615, fw_file_name=0x55555606e4db "etc/acpi/tables", fw_callback=0x555555b5778d <acpi_build_update>, callback_opaque=0x555556a589a0, as=0x0, read_only=true) at ../hw/core/loader.c:1102
+ * #2  0x000055555585c9a0 in acpi_add_rom_blob (update=0x555555b5778d <acpi_build_update>, opaque=0x555556a589a0, blob=0x555556847ac0, name=0x55555606e4db "etc/acpi/tables") at ../hw/acpi/utils.c:46
+ * #3  0x0000555555b579ab in acpi_setup () at ../hw/i386/acpi-build.c:2805
+ * #4  0x0000555555b4a2f7 in pc_machine_done (notifier=0x555556a51dc8, data=0x0) at ../hw/i386/pc.c:758
+ * #5  0x0000555555ef1e2b in notifier_list_notify (list=0x5555567aac38 <machine_init_done_notifiers>, data=0x0) at ../util/notify.c:39
+ * #6  0x00005555558a76c4 in qdev_machine_creation_done () at ../hw/core/machine.c:1448
+ * #7  0x0000555555a8018b in qemu_machine_creation_done () at ../softmmu/vl.c:2554
+ * #8  0x0000555555a80287 in qmp_x_exit_preconfig (errp=0x5555567d1640 <error_fatal>) at ../softmmu/vl.c:2583
+ * #9  0x0000555555a8290d in qemu_init (argc=24, argv=0x7fffffffde88, envp=0x0) at ../softmmu/vl.c:3584
+ * #10 0x000055555581fe5d in qemu_main (argc=24, argv=0x7fffffffde88, envp=0x0) at ../softmmu/main.c:37
+ * #11 0x000055555581fe94 in main (argc=24, argv=0x7fffffffde88) at ../softmmu/main.c:47
+ *
+ * called by:
+ *   - hw/core/loader.c|1055| <<rom_add_file>> data = rom_set_mr(rom, OBJECT(fw_cfg), devpath, true);
+ *   - hw/core/loader.c|1111| <<rom_add_blob>> data = rom_set_mr(rom, OBJECT(fw_cfg), devpath, read_only);
+ */
 static void *rom_set_mr(Rom *rom, Object *owner, const char *name, bool ro)
 {
     void *data;
@@ -971,6 +991,55 @@ static void *rom_set_mr(Rom *rom, Object *owner, const char *name, bool ro)
     return data;
 }
 
+/*
+ * (gdb) bt
+ * #0  rom_add_file (file=0x555556a67360 "bios-256k.bin", fw_dir=0x0, addr=4294705152, bootindex=-1, option_rom=false, mr=0x0, as=0x0) at ../hw/core/loader.c:978
+ * #1  0x0000555555b25e6c in x86_bios_rom_init (ms=0x555556a51be0, default_firmware=0x55555606d8b6 "bios.bin", rom_memory=0x555556aff740, isapc_ram_fw=false) at ../hw/i386/x86.c:1167
+ * #2  0x0000555555b4df6c in pc_system_firmware_init (pcms=0x555556a51be0, rom_memory=0x555556aff740) at ../hw/i386/pc_sysfw.c:232
+ * #3  0x0000555555b4b0c0 in pc_memory_init (pcms=0x555556a51be0, system_memory=0x555556a5b9a0, rom_memory=0x555556aff740, ram_memory=0x7fffffffd9d8, pci_hole64_size=34359738368) at ../hw/i386/pc.c:1085
+ * #4  0x0000555555b363f7 in pc_q35_init (machine=0x555556a51be0) at ../hw/i386/pc_q35.c:217
+ * #5  0x0000555555b36c4c in pc_init_v7_1 (machine=0x555556a51be0) at ../hw/i386/pc_q35.c:382
+ * #6  0x00005555558a75be in machine_run_board_init (machine=0x555556a51be0, mem_path=0x0, errp=0x5555567d1640 <error_fatal>) at ../hw/core/machine.c:1400
+ * #7  0x0000555555a8000c in qemu_init_board () at ../softmmu/vl.c:2485
+ * #8  0x0000555555a8027d in qmp_x_exit_preconfig (errp=0x5555567d1640 <error_fatal>) at ../softmmu/vl.c:2581
+ * #9  0x0000555555a8290d in qemu_init (argc=24, argv=0x7fffffffde88, envp=0x0) at ../softmmu/vl.c:3584
+ * #10 0x000055555581fe5d in qemu_main (argc=24, argv=0x7fffffffde88, envp=0x0) at ../softmmu/main.c:37
+ * #11 0x000055555581fe94 in main (argc=24, argv=0x7fffffffde88) at ../softmmu/main.c:47
+ *
+ * (gdb) bt
+ * #0  rom_add_file (file=0x555556061d76 "kvmvapic.bin", fw_dir=0x555555fa9414 "genroms", addr=0, bootindex=-1, option_rom=true, mr=0x0, as=0x0) at ../hw/core/loader.c:978
+ * #1  0x00005555558a25f9 in rom_add_option (file=0x555556061d76 "kvmvapic.bin", bootindex=-1) at ../hw/core/loader.c:1150
+ * #2  0x0000555555b4b2f3 in pc_memory_init (pcms=0x555556a51be0, system_memory=0x555556a5b9a0, rom_memory=0x555556aff740, ram_memory=0x7fffffffd9d8, pci_hole64_size=34359738368) at ../hw/i386/pc.c:1125
+ * #3  0x0000555555b363f7 in pc_q35_init (machine=0x555556a51be0) at ../hw/i386/pc_q35.c:217
+ * #4  0x0000555555b36c4c in pc_init_v7_1 (machine=0x555556a51be0) at ../hw/i386/pc_q35.c:382
+ * #5  0x00005555558a75be in machine_run_board_init (machine=0x555556a51be0, mem_path=0x0, errp=0x5555567d1640 <error_fatal>) at ../hw/core/machine.c:1400
+ * #6  0x0000555555a8000c in qemu_init_board () at ../softmmu/vl.c:2485
+ * #7  0x0000555555a8027d in qmp_x_exit_preconfig (errp=0x5555567d1640 <error_fatal>) at ../softmmu/vl.c:2581
+ * #8  0x0000555555a8290d in qemu_init (argc=24, argv=0x7fffffffde88, envp=0x0) at ../softmmu/vl.c:3584
+ * #9  0x000055555581fe5d in qemu_main (argc=24, argv=0x7fffffffde88, envp=0x0) at ../softmmu/main.c:37
+ * #10 0x000055555581fe94 in main (argc=24, argv=0x7fffffffde88) at ../softmmu/main.c:47
+ *
+ * (gdb) bt
+ * #0  rom_add_file (file=0x555556062ad6 "linuxboot_dma.bin", fw_dir=0x555555fa9414 "genroms", addr=0, bootindex=0, option_rom=true, mr=0x0, as=0x0) at ../hw/core/loader.c:978
+ * #1  0x00005555558a25f9 in rom_add_option (file=0x555556062ad6 "linuxboot_dma.bin", bootindex=0) at ../hw/core/loader.c:1150
+ * #2  0x0000555555b4b2f3 in pc_memory_init (pcms=0x555556a51be0, system_memory=0x555556a5b9a0, rom_memory=0x555556aff740, ram_memory=0x7fffffffd9d8, pci_hole64_size=34359738368) at ../hw/i386/pc.c:1125
+ * #3  0x0000555555b363f7 in pc_q35_init (machine=0x555556a51be0) at ../hw/i386/pc_q35.c:217
+ * #4  0x0000555555b36c4c in pc_init_v7_1 (machine=0x555556a51be0) at ../hw/i386/pc_q35.c:382
+ * #5  0x00005555558a75be in machine_run_board_init (machine=0x555556a51be0, mem_path=0x0, errp=0x5555567d1640 <error_fatal>) at ../hw/core/machine.c:1400
+ * #6  0x0000555555a8000c in qemu_init_board () at ../softmmu/vl.c:2485
+ * #7  0x0000555555a8027d in qmp_x_exit_preconfig (errp=0x5555567d1640 <error_fatal>) at ../softmmu/vl.c:2581
+ * #8  0x0000555555a8290d in qemu_init (argc=24, argv=0x7fffffffde88, envp=0x0) at ../softmmu/vl.c:3584
+ * #9  0x000055555581fe5d in qemu_main (argc=24, argv=0x7fffffffde88, envp=0x0) at ../softmmu/main.c:37
+ * #10 0x000055555581fe94 in main (argc=24, argv=0x7fffffffde88) at ../softmmu/main.c:47
+ *
+ * called by:
+ *   - hw/core/loader.c|1145| <<rom_add_vga>> return rom_add_file(file, "vgaroms", 0, -1, true, NULL, NULL);
+ *   - hw/core/loader.c|1150| <<rom_add_option>> return rom_add_file(file, "genroms", 0, bootindex, true, NULL, NULL);
+ *   - include/hw/loader.h|328| <<rom_add_file_fixed>> rom_add_file(_f, NULL, _a, _i, false, NULL, NULL)
+ *   - include/hw/loader.h|332| <<rom_add_file_mr>> rom_add_file(_f, NULL, 0, _i, false, _mr, NULL)
+ *   - include/hw/loader.h|334| <<rom_add_file_as>> rom_add_file(_f, NULL, 0, _i, false, NULL, _as)
+ *   - include/hw/loader.h|336| <<rom_add_file_fixed_as>> rom_add_file(_f, NULL, _a, _i, false, NULL, _as)
+ */
 ssize_t rom_add_file(const char *file, const char *fw_dir,
                      hwaddr addr, int32_t bootindex,
                      bool option_rom, MemoryRegion *mr,
@@ -991,6 +1060,10 @@ ssize_t rom_add_file(const char *file, const char *fw_dir,
 
     rom = g_malloc0(sizeof(*rom));
     rom->name = g_strdup(file);
+    /*
+     * (gdb) p rom->path
+     * $2 = 0x555556b599f0 "/home/zhang/kvm/qemu-7.1.0/build/qemu-bundle/usr/local/share/qemu/bios-256k.bin"
+     */
     rom->path = qemu_find_file(QEMU_FILE_TYPE_BIOS, rom->name);
     rom->as = as;
     if (rom->path == NULL) {
@@ -1008,7 +1081,13 @@ ssize_t rom_add_file(const char *file, const char *fw_dir,
         rom->fw_dir  = g_strdup(fw_dir);
         rom->fw_file = g_strdup(file);
     }
+    /*
+     * 0xfffc0000
+     */
     rom->addr     = addr;
+    /*
+     * 256k
+     */
     rom->romsize  = lseek(fd, 0, SEEK_END);
     if (rom->romsize == -1) {
         fprintf(stderr, "rom: file %-20s: get size error: %s\n",
@@ -1027,6 +1106,9 @@ ssize_t rom_add_file(const char *file, const char *fw_dir,
     }
     close(fd);
     rom_insert(rom);
+    /*
+     * q35简单的测试都是0
+     */
     if (rom->fw_file && fw_cfg) {
         const char *basename;
         char fw_file_name[FW_CFG_MAX_FILE_PATH];
@@ -1050,6 +1132,9 @@ ssize_t rom_add_file(const char *file, const char *fw_dir,
 
         fw_cfg_add_file(fw_cfg, fw_file_name, data, rom->romsize);
     } else {
+        /*
+         * q35简单的测试是0
+         */
         if (mr) {
             rom->mr = mr;
             snprintf(devpath, sizeof(devpath), "/rom@%s", file);
diff --git a/hw/core/qdev-properties-system.c b/hw/core/qdev-properties-system.c
index a91f60567..d9b8499d9 100644
--- a/hw/core/qdev-properties-system.c
+++ b/hw/core/qdev-properties-system.c
@@ -182,6 +182,26 @@ fail:
     g_free(str);
 }
 
+/*
+ * (gdb) bt
+ * #0  set_drive (obj=0x555557767e20, v=0x55555776cb40, name=0x555557768c00 "drive", opaque=0x5555566eaac0 <virtio_blk_properties>, errp=0x7fffffffd900) at ../hw/core/qdev-properties-system.c:188
+ * #1  0x0000555555d1d343 in field_prop_set (obj=0x555557767e20, v=0x55555776cb40, name=0x555557768c00 "drive", opaque=0x5555566eaac0 <virtio_blk_properties>, errp=0x7fffffffd900)
+ *                        at ../hw/core/qdev-properties.c:86
+ * #2  0x0000555555d289e7 in object_property_set (obj=0x555557767e20, name=0x555557768c00 "drive", v=0x55555776cb40, errp=0x7fffffffd900) at ../qom/object.c:1408
+ * #3  0x0000555555d2b8fe in property_set_alias (obj=0x55555775fa60, v=0x55555776c960, name=0x55555776c8f0 "drive", opaque=0x5555577683d0, errp=0x7fffffffd900) at ../qom/object.c:2714
+ * #4  0x0000555555d289e7 in object_property_set (obj=0x55555775fa60, name=0x55555776c8f0 "drive", v=0x55555776c960, errp=0x7fffffffd900) at ../qom/object.c:1408
+ * #5  0x0000555555d2bf71 in object_set_properties_from_qdict (obj=0x55555775fa60, qdict=0x55555776b880, v=0x55555776c960, errp=0x7fffffffd900) at ../qom/object_interfaces.c:55
+ * #6  0x0000555555d2c057 in object_set_properties_from_keyval (obj=0x55555775fa60, qdict=0x55555776b880, from_json=false, errp=0x7fffffffd900) at ../qom/object_interfaces.c:73
+ * #7  0x0000555555a77660 in qdev_device_add_from_qdict (opts=0x55555775ea40, from_json=false, errp=0x7fffffffd900) at ../softmmu/qdev-monitor.c:708
+ * #8  0x0000555555a7772c in qdev_device_add (opts=0x555556847560, errp=0x5555567d1640 <error_fatal>) at ../softmmu/qdev-monitor.c:733
+ * #9  0x0000555555a7cc07 in device_init_func (opaque=0x0, opts=0x555556847560, errp=0x5555567d1640 <error_fatal>) at ../softmmu/vl.c:1142
+ * #10 0x0000555555ef49df in qemu_opts_foreach (list=0x5555566d20e0 <qemu_device_opts>, func=0x555555a7cbe0 <device_init_func>, opaque=0x0, errp=0x5555567d1640 <error_fatal>) at ../util/qemu-option.c:1135
+ * #11 0x0000555555a800c7 in qemu_create_cli_devices () at ../softmmu/vl.c:2514
+ * #12 0x0000555555a80282 in qmp_x_exit_preconfig (errp=0x5555567d1640 <error_fatal>) at ../softmmu/vl.c:2582
+ * #13 0x0000555555a8290d in qemu_init (argc=32, argv=0x7fffffffdd58, envp=0x0) at ../softmmu/vl.c:3584
+ * #14 0x000055555581fe5d in qemu_main (argc=32, argv=0x7fffffffdd58, envp=0x0) at ../softmmu/main.c:37
+ * #15 0x000055555581fe94 in main (argc=32, argv=0x7fffffffdd58) at ../softmmu/main.c:47
+ */
 static void set_drive(Object *obj, Visitor *v, const char *name, void *opaque,
                       Error **errp)
 {
diff --git a/hw/core/qdev.c b/hw/core/qdev.c
index 0806d8fca..eccef5c1a 100644
--- a/hw/core/qdev.c
+++ b/hw/core/qdev.c
@@ -56,6 +56,43 @@ static void bus_free_bus_child(BusChild *kid)
     g_free(kid);
 }
 
+/*
+ * (gdb) bt
+ * #0  bus_remove_child (bus=0x5555571e3f58, child=0x5555571e3fe0) at ../hw/core/qdev.c:60
+ * #1  0x0000555555d217b5 in device_unparent (obj=0x5555571e3fe0) at ../hw/core/qdev.c:779
+ * #2  0x0000555555d29795 in object_finalize_child_property (obj=0x5555571dbc20, name=0x5555568469c0 "virtio-backend", opaque=0x5555571e3fe0)
+ *     at ../qom/object.c:1732
+ * #3  0x0000555555d271ac in object_property_del_child (obj=0x5555571dbc20, child=0x5555571e3fe0) at ../qom/object.c:649
+ * #4  0x0000555555d27287 in object_unparent (obj=0x5555571e3fe0) at ../qom/object.c:668
+ * #5  0x0000555555d1ca3a in bus_unparent (obj=0x5555571e3f58) at ../hw/core/bus.c:148
+ * #6  0x0000555555d29795 in object_finalize_child_property (obj=0x5555571dbc20, name=0x555556df1290 "virtio-bus", opaque=0x5555571e3f58) at ../qom/object.c:1732
+ * #7  0x0000555555d271ac in object_property_del_child (obj=0x5555571dbc20, child=0x5555571e3f58) at ../qom/object.c:649
+ * #8  0x0000555555d27287 in object_unparent (obj=0x5555571e3f58) at ../qom/object.c:668
+ * #9  0x0000555555d21786 in device_unparent (obj=0x5555571dbc20) at ../hw/core/qdev.c:776
+ * #10 0x0000555555d29795 in object_finalize_child_property (obj=0x555556a52c00, name=0x555557125170 "vnic01", opaque=0x5555571dbc20) at ../qom/object.c:1732
+ * #11 0x0000555555d271ac in object_property_del_child (obj=0x555556a52c00, child=0x5555571dbc20) at ../qom/object.c:649
+ * #12 0x0000555555d27287 in object_unparent (obj=0x5555571dbc20) at ../qom/object.c:668
+ * #13 0x000055555586da8a in acpi_pcihp_eject_slot (s=0x55555768a510, bsel=0, slots=16) at ../hw/acpi/pcihp.c:244
+ * #14 0x000055555586e50c in pci_write (opaque=0x55555768a510, addr=8, data=16, size=4) at ../hw/acpi/pcihp.c:520
+ * #15 0x0000555555c650a3 in memory_region_write_accessor (mr=0x55555768b120, addr=8, value=0x7fffed4a06a8, size=4, shift=0, mask=4294967295, attrs=...)
+ *     at ../softmmu/memory.c:492
+ * #16 0x0000555555c652e7 in access_with_adjusted_size (addr=8, value=0x7fffed4a06a8, size=4, access_size_min=1, access_size_max=4, access_fn=
+ *     0x555555c64fad <memory_region_write_accessor>, mr=0x55555768b120, attrs=...) at ../softmmu/memory.c:554
+ * #17 0x0000555555c683dd in memory_region_dispatch_write (mr=0x55555768b120, addr=8, data=16, op=MO_32, attrs=...) at ../softmmu/memory.c:1514
+ * #18 0x0000555555c758f6 in flatview_write_continue (fv=0x7ffddc009460, addr=44552, attrs=..., ptr=0x7ffff7fed000, len=4, addr1=8, l=4, mr=0x55555768b120)
+ *     at ../softmmu/physmem.c:2825
+ * #19 0x0000555555c75a59 in flatview_write (fv=0x7ffddc009460, addr=44552, attrs=..., buf=0x7ffff7fed000, len=4) at ../softmmu/physmem.c:2867
+ * #20 0x0000555555c75e09 in address_space_write (as=0x5555567b3420 <address_space_io>, addr=44552, attrs=..., buf=0x7ffff7fed000, len=4)
+ *     at ../softmmu/physmem.c:2963
+ * #21 0x0000555555c75e76 in address_space_rw (as=0x5555567b3420 <address_space_io>, addr=44552, attrs=..., buf=0x7ffff7fed000, len=4, is_write=true)
+ *     at ../softmmu/physmem.c:2973
+ * #22 0x0000555555d0db63 in kvm_handle_io (port=44552, attrs=..., data=0x7ffff7fed000, direction=1, size=4, count=1) at ../accel/kvm/kvm-all.c:2693
+ * #23 0x0000555555d0e2dd in kvm_cpu_exec (cpu=0x555556ae3cb0) at ../accel/kvm/kvm-all.c:2944
+ * #24 0x0000555555d10faa in kvm_vcpu_thread_fn (arg=0x555556ae3cb0) at ../accel/kvm/kvm-accel-ops.c:49
+ * #25 0x0000555555eec4de in qemu_thread_start (args=0x555556af2de0) at ../util/qemu-thread-posix.c:504
+ * #26 0x00007ffff55eeea5 in start_thread () at /lib64/libpthread.so.0
+ * #27 0x00007ffff53179fd in clone () at /lib64/libc.so.6
+ */
 static void bus_remove_child(BusState *bus, DeviceState *child)
 {
     BusChild *kid;
@@ -720,6 +757,23 @@ static void device_post_init(Object *obj)
 }
 
 /* Unlink device from bus and free the structure.  */
+/*
+ * (gdb) bt
+ * #0  device_finalize (obj=0x5555571e3fe0) at ../hw/core/qdev.c:727
+ * #1  0x0000555555d272b8 in object_deinit (obj=0x5555571e3fe0, type=0x55555683a5f0) at ../qom/object.c:675
+ * #2  0x0000555555d272e6 in object_deinit (obj=0x5555571e3fe0, type=0x55555682f140) at ../qom/object.c:679
+ * #3  0x0000555555d272e6 in object_deinit (obj=0x5555571e3fe0, type=0x55555682dee0) at ../qom/object.c:679
+ * #4  0x0000555555d2732a in object_finalize (data=0x5555571e3fe0) at ../qom/object.c:689
+ * #5  0x0000555555d28147 in object_unref (objptr=0x5555571e3fe0) at ../qom/object.c:1192
+ * #6  0x0000555555d1fbc2 in bus_free_bus_child (kid=0x555556df11f0) at ../hw/core/qdev.c:55
+ * #7  0x0000555555ef6fe1 in call_rcu_thread (opaque=0x0) at ../util/rcu.c:284
+ * #8  0x0000555555eec4de in qemu_thread_start (args=0x5555567e7e80) at ../util/qemu-thread-posix.c:504
+ * #9  0x00007ffff55eeea5 in start_thread () at /lib64/libpthread.so.0
+ * #10 0x00007ffff53179fd in clone () at /lib64/libc.so.6
+ *
+ * 在以下使用device_finalize():
+ *   - hw/core/qdev.c|954| <<global>> .instance_finalize = device_finalize,
+ */
 static void device_finalize(Object *obj)
 {
     NamedGPIOList *ngl, *next;
diff --git a/hw/core/reset.c b/hw/core/reset.c
index 36be82c49..ea444e4d2 100644
--- a/hw/core/reset.c
+++ b/hw/core/reset.c
@@ -60,6 +60,19 @@ void qemu_unregister_reset(QEMUResetHandler *func, void *opaque)
     }
 }
 
+/*
+ * called by:
+ *   - hw/arm/aspeed.c|1357| <<fby35_reset>> qemu_devices_reset();
+ *   - hw/arm/mps2-tz.c|1252| <<mps2_machine_reset>> qemu_devices_reset();
+ *   - hw/hppa/machine.c|419| <<hppa_machine_reset>> qemu_devices_reset();
+ *   - hw/i386/microvm.c|483| <<microvm_machine_reset>> qemu_devices_reset();
+ *   - hw/i386/pc.c|1851| <<pc_machine_reset>> qemu_devices_reset();
+ *   - hw/ppc/pegasos2.c|258| <<pegasos2_machine_reset>> qemu_devices_reset();
+ *   - hw/ppc/pnv.c|582| <<pnv_reset>> qemu_devices_reset();
+ *   - hw/ppc/spapr.c|1652| <<spapr_machine_reset>> qemu_devices_reset();
+ *   - hw/s390x/s390-virtio-ccw.c|430| <<s390_machine_reset>> qemu_devices_reset();
+ *   - softmmu/runstate.c|446| <<qemu_system_reset>> qemu_devices_reset();
+ */
 void qemu_devices_reset(void)
 {
     QEMUResetEntry *re, *nre;
diff --git a/hw/i386/acpi-build.c b/hw/i386/acpi-build.c
index 0355bd3dd..ec22ce3ea 100644
--- a/hw/i386/acpi-build.c
+++ b/hw/i386/acpi-build.c
@@ -213,6 +213,20 @@ static Object *object_resolve_type_unambiguous(const char *typename)
     return o;
 }
 
+/*
+ * (gdb) bt
+#0  acpi_get_pm_info (machine=0x555556a51aa0, pm=0x7fffffffda20) at ../hw/i386/acpi-build.c:218
+#1  0x0000555555b56b1c in acpi_build (tables=0x7fffffffdb50, machine=0x555556a51aa0) at ../hw/i386/acpi-build.c:2484
+#2  0x0000555555b5798d in acpi_setup () at ../hw/i386/acpi-build.c:2802
+#3  0x0000555555b4a2f7 in pc_machine_done (notifier=0x555556a51c88, data=0x0) at ../hw/i386/pc.c:758
+#4  0x0000555555ef1e2b in notifier_list_notify (list=0x5555567aac38 <machine_init_done_notifiers>, data=0x0) at ../util/notify.c:39
+#5  0x00005555558a76c4 in qdev_machine_creation_done () at ../hw/core/machine.c:1448
+#6  0x0000555555a8018b in qemu_machine_creation_done () at ../softmmu/vl.c:2554
+#7  0x0000555555a80287 in qmp_x_exit_preconfig (errp=0x5555567d1640 <error_fatal>) at ../softmmu/vl.c:2583
+#8  0x0000555555a8290d in qemu_init (argc=15, argv=0x7fffffffdf58, envp=0x0) at ../softmmu/vl.c:3584
+#9  0x000055555581fe5d in qemu_main (argc=15, argv=0x7fffffffdf58, envp=0x0) at ../softmmu/main.c:37
+#10 0x000055555581fe94 in main (argc=15, argv=0x7fffffffdf58) at ../softmmu/main.c:47
+ */
 static void acpi_get_pm_info(MachineState *machine, AcpiPmInfo *pm)
 {
     Object *piix = object_resolve_type_unambiguous(TYPE_PIIX4_PM);
@@ -1429,6 +1443,10 @@ static void build_acpi0017(Aml *table)
     aml_append(table, scope);
 }
 
+/*
+ * called by:
+ *   - hw/i386/acpi-build.c|2529| <<acpi_build>> build_dsdt(tables_blob, tables->linker, &pm, &misc,
+ */
 static void
 build_dsdt(GArray *table_data, BIOSLinker *linker,
            AcpiPmInfo *pm, AcpiMiscInfo *misc,
@@ -1930,6 +1948,10 @@ build_tpm_tcpa(GArray *table_data, BIOSLinker *linker, GArray *tcpalog,
  * ACPI spec, Revision 3.0
  * 5.2.15 System Resource Affinity Table (SRAT)
  */
+/*
+ * called by:
+ *   - hw/i386/acpi-build.c|2581| <<acpi_build>> build_srat(tables_blob, tables->linker, machine)
+ */
 static void
 build_srat(GArray *table_data, BIOSLinker *linker, MachineState *machine)
 {
@@ -2460,6 +2482,11 @@ static bool acpi_get_mcfg(AcpiMcfgInfo *mcfg)
     return true;
 }
 
+/*
+ * called by:
+ *   - hw/i386/acpi-build.c|2741| <<acpi_build_update>> acpi_build(&tables, MACHINE(qdev_get_machine()));
+ *   - hw/i386/acpi-build.c|2802| <<acpi_setup>> acpi_build(&tables, MACHINE(pcms));
+ */
 static
 void acpi_build(AcpiBuildTables *tables, MachineState *machine)
 {
@@ -2725,6 +2752,13 @@ static void acpi_ram_update(MemoryRegion *mr, GArray *data)
     memory_region_set_dirty(mr, 0, size);
 }
 
+/*
+ * called by:
+ *   - hw/i386/acpi-build.c|2818| <<acpi_setup>> build_state->table_mr = acpi_add_rom_blob(acpi_build_update, build_state, tables.table_data, ACPI_BUILD_TABLE_FILE);
+ *   - hw/i386/acpi-build.c|2824| <<acpi_setup>> acpi_add_rom_blob(acpi_build_update, build_state, tables.linker->cmd_blob, ACPI_BUILD_LOADER_FILE);
+ *   - hw/i386/acpi-build.c|2859| <<acpi_setup>> acpi_build_update, NULL, build_state, acpi_build_update, NULL, build_state, build_state->rsdp, rsdp_size, true);
+ *   - hw/i386/acpi-build.c|2864| <<acpi_setup>> build_state->rsdp_mr = acpi_add_rom_blob(acpi_build_update, build_state, tables.rsdp, ACPI_BUILD_RSDP_FILE);
+ */
 static void acpi_build_update(void *build_opaque)
 {
     AcpiBuildState *build_state = build_opaque;
@@ -2768,6 +2802,10 @@ static const VMStateDescription vmstate_acpi_build = {
     },
 };
 
+/*
+ * called by:
+ *   - hw/i386/pc.c|758| <<pc_machine_done>> acpi_setup();
+ */
 void acpi_setup(void)
 {
     PCMachineState *pcms = PC_MACHINE(qdev_get_machine());
diff --git a/hw/i386/fw_cfg.c b/hw/i386/fw_cfg.c
index a283785a8..964c30edb 100644
--- a/hw/i386/fw_cfg.c
+++ b/hw/i386/fw_cfg.c
@@ -48,6 +48,10 @@ const char *fw_cfg_arch_key_name(uint16_t key)
     return NULL;
 }
 
+/*
+ * called by:
+ *   - hw/i386/pc.c|760| <<pc_machine_done>> fw_cfg_build_smbios(MACHINE(pcms), x86ms->fw_cfg);
+ */
 void fw_cfg_build_smbios(MachineState *ms, FWCfgState *fw_cfg)
 {
 #ifdef CONFIG_SMBIOS
diff --git a/hw/i386/intel_iommu.c b/hw/i386/intel_iommu.c
index 2162394e0..a05f0889f 100644
--- a/hw/i386/intel_iommu.c
+++ b/hw/i386/intel_iommu.c
@@ -1590,6 +1590,13 @@ static bool vtd_as_pt_enabled(VTDAddressSpace *as)
 }
 
 /* Return whether the device is using IOMMU translation. */
+/*
+ * called by:
+ *   - hw/i386/intel_iommu.c|1645| <<vtd_switch_address_space_all>> vtd_switch_address_space(vtd_bus->dev_as[i]);
+ *   - hw/i386/intel_iommu.c|1705| <<vtd_pt_enable_fast_path>> if (vtd_switch_address_space(vtd_as) == false) {
+ *   - hw/i386/intel_iommu.c|1950| <<vtd_context_device_invalidate>> vtd_switch_address_space(vtd_as);
+ *   - hw/i386/intel_iommu.c|3505| <<vtd_find_add_as>> vtd_switch_address_space(vtd_dev_as);
+ */
 static bool vtd_switch_address_space(VTDAddressSpace *as)
 {
     bool use_iommu;
@@ -3425,6 +3432,13 @@ static const MemoryRegionOps vtd_mem_ir_ops = {
     },
 };
 
+/*
+ * called by:
+ *   - hw/i386/intel_iommu.c|3798| <<vtd_host_dma_iommu>> vtd_as = vtd_find_add_as(s, bus, devfn);
+ *
+ * 注释: Find the VTD Address space associated with the given bus pointer,
+ * create a new one if none exists
+ */
 VTDAddressSpace *vtd_find_add_as(IntelIOMMUState *s, PCIBus *bus, int devfn)
 {
     uintptr_t key = (uintptr_t)bus;
@@ -3788,6 +3802,11 @@ static void vtd_reset(DeviceState *dev)
     vtd_address_space_refresh_all(s);
 }
 
+/*
+ * called by:
+ *   - hw/i386/intel_iommu.c|3905| <<vtd_realize>> pci_setup_iommu(bus, vtd_host_dma_iommu, dev);
+ *   - hw/i386/intel_iommu.c|3907| <<vtd_realize>> x86ms->ioapic_as = vtd_host_dma_iommu(bus, s, Q35_PSEUDO_DEVFN_IOAPIC);
+ */
 static AddressSpace *vtd_host_dma_iommu(PCIBus *bus, void *opaque, int devfn)
 {
     IntelIOMMUState *s = opaque;
diff --git a/hw/i386/pc.c b/hw/i386/pc.c
index 7280c02ce..7183f0e11 100644
--- a/hw/i386/pc.c
+++ b/hw/i386/pc.c
@@ -1566,6 +1566,30 @@ static void pc_machine_device_plug_cb(HotplugHandler *hotplug_dev,
     }
 }
 
+/*
+ * (gdb) bt
+#0  pc_machine_device_unplug_request_cb (hotplug_dev=0x555556a52070, dev=0x555556d97000, errp=0x7fffffffc8a8) at ../hw/i386/pc.c:1572
+#1  0x0000555555d25375 in hotplug_handler_unplug_request (plug_handler=0x555556a52070, plugged_dev=0x555556d97000, errp=0x7fffffffc8a8) at ../hw/core/hotplug.c:45
+#2  0x0000555555a7800e in qdev_unplug (dev=0x555556d97000, errp=0x7fffffffc938) at ../softmmu/qdev-monitor.c:933
+#3  0x0000555555a7810e in qmp_device_del (id=0x555556d901e0 "core4", errp=0x7fffffffc938) at ../softmmu/qdev-monitor.c:955
+#4  0x0000555555a781cb in hmp_device_del (mon=0x5555568465b0, qdict=0x55555749ceb0) at ../softmmu/qdev-monitor.c:972
+#5  0x0000555555accc3e in handle_hmp_command_exec (mon=0x5555568465b0, cmd=0x5555566f9270 <hmp_cmds+2000>, qdict=0x55555749ceb0) at ../monitor/hmp.c:1103
+#6  0x0000555555acce6b in handle_hmp_command (mon=0x5555568465b0, cmdline=0x555556aa1f1b "core4") at ../monitor/hmp.c:1155
+#7  0x0000555555aca384 in monitor_command_cb (opaque=0x5555568465b0, cmdline=0x555556aa1f10 "device_del core4", readline_opaque=0x0) at ../monitor/hmp.c:49
+#8  0x0000555555f195dd in readline_handle_byte (rs=0x555556aa1f10, ch=13) at ../util/readline.c:411
+#9  0x0000555555acd9a8 in monitor_read (opaque=0x5555568465b0, buf=0x7fffffffcba0 "\r\321\377\377\377\177", size=1) at ../monitor/hmp.c:1393
+#10 0x0000555555e31613 in qemu_chr_be_write_impl (s=0x555556a66900, buf=0x7fffffffcba0 "\r\321\377\377\377\177", len=1) at ../chardev/char.c:201
+#11 0x0000555555e31677 in qemu_chr_be_write (s=0x555556a66900, buf=0x7fffffffcba0 "\r\321\377\377\377\177", len=1) at ../chardev/char.c:213
+#12 0x0000555555e340a4 in fd_chr_read (chan=0x555556a669c0, cond=G_IO_IN, opaque=0x555556a66900) at ../chardev/char-fd.c:72
+#13 0x0000555555d335b4 in qio_channel_fd_source_dispatch (source=0x555556d8ba30, callback=0x555555e33f7a <fd_chr_read>, user_data=0x555556a66900) at ../io/channel-watch.c:84
+#14 0x00007ffff6c40119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+#15 0x0000555555f12010 in glib_pollfds_poll () at ../util/main-loop.c:297
+#16 0x0000555555f1208a in os_host_main_loop_wait (timeout=499000000) at ../util/main-loop.c:320
+#17 0x0000555555f1218f in main_loop_wait (nonblocking=0) at ../util/main-loop.c:596
+#18 0x0000555555a7a05e in qemu_main_loop () at ../softmmu/runstate.c:734
+#19 0x000055555581fe62 in qemu_main (argc=24, argv=0x7fffffffde88, envp=0x0) at ../softmmu/main.c:38
+#20 0x000055555581fe94 in main (argc=24, argv=0x7fffffffde88) at ../softmmu/main.c:47
+ */
 static void pc_machine_device_unplug_request_cb(HotplugHandler *hotplug_dev,
                                                 DeviceState *dev, Error **errp)
 {
diff --git a/hw/i386/x86.c b/hw/i386/x86.c
index 050eedc0c..53f16d9a8 100644
--- a/hw/i386/x86.c
+++ b/hw/i386/x86.c
@@ -92,6 +92,10 @@ uint32_t x86_cpu_apic_id_from_index(X86MachineState *x86ms,
 }
 
 
+/*
+ * called by:
+ *   - hw/i386/x86.c|144| <<x86_cpus_init>> x86_cpu_new(x86ms, possible_cpus->cpus[i].arch_id, &error_fatal);
+ */
 void x86_cpu_new(X86MachineState *x86ms, int64_t apic_id, Error **errp)
 {
     Object *cpu = object_new(MACHINE(x86ms)->cpu_type);
diff --git a/hw/net/virtio-net.c b/hw/net/virtio-net.c
index dd0d056fd..daff0d791 100644
--- a/hw/net/virtio-net.c
+++ b/hw/net/virtio-net.c
@@ -1171,6 +1171,30 @@ static void virtio_net_disable_rss(VirtIONet *n)
     virtio_net_detach_epbf_rss(n);
 }
 
+/*
+ * (gdb) bt
+ * #0  virtio_net_attach_ebpf_to_backend (nic=0x5555578316c0, prog_fd=-1) at ../hw/net/virtio-net.c:1239
+ * #1  0x0000555555c18bf2 in virtio_net_detach_epbf_rss (n=0x555557806ed0) at ../hw/net/virtio-net.c:1281
+ * #2  0x0000555555c18a19 in virtio_net_disable_rss (n=0x555557806ed0) at ../hw/net/virtio-net.c:1234
+ * #3  0x0000555555c192cb in virtio_net_handle_mq (n=0x555557806ed0, cmd=0 '\000', iov=0x7ffee8270bd0, iov_cnt=1) at ../hw/net/virtio-net.c:1448
+ * #4  0x0000555555c19617 in virtio_net_handle_ctrl_iov (vdev=0x555557806ed0, in_sg=0x7ffee825c3a0, in_num=1, out_sg=0x7ffee825c3b0, out_num=1) at ../hw/net/virtio-net.c:1525
+ * #5  0x0000555555c19710 in virtio_net_handle_ctrl (vdev=0x555557806ed0, vq=0x7fffef86f4d0) at ../hw/net/virtio-net.c:1548
+ * #6  0x0000555555c519f4 in virtio_queue_notify (vdev=0x555557806ed0, n=8) at ../hw/virtio/virtio.c:2867
+ * #7  0x0000555555a60b0c in virtio_pci_notify_write (opaque=0x5555577feb10, addr=32, val=8, size=2) at ../hw/virtio/virtio-pci.c:1436
+ * #8  0x0000555555c9b042 in memory_region_write_accessor (mr=0x5555577ff9a0, addr=32, value=0x7ffeef7fe6e8, size=2, shift=0, mask=65535, attrs=...) at ../softmmu/memory.c:493
+ * #9  0x0000555555c9b286 in access_with_adjusted_size (addr=32, value=0x7ffeef7fe6e8, size=2, access_size_min=1, access_size_max=4, access_fn=
+ *     0x555555c9af4c <memory_region_write_accessor>, mr=0x5555577ff9a0, attrs=...) at ../softmmu/memory.c:555
+ * #10 0x0000555555c9e37d in memory_region_dispatch_write (mr=0x5555577ff9a0, addr=32, data=8, op=MO_16, attrs=...) at ../softmmu/memory.c:1515
+ * #11 0x0000555555cabbac in flatview_write_continue (fv=0x7ffee02ab0a0, addr=4261425184, attrs=..., ptr=0x7ffff7ff2028, len=2, addr1=32, l=2, mr=0x5555577ff9a0) at ../softmmu/physmem.c:2825
+ * #12 0x0000555555cabd0f in flatview_write (fv=0x7ffee02ab0a0, addr=4261425184, attrs=..., buf=0x7ffff7ff2028, len=2) at ../softmmu/physmem.c:2867
+ * #13 0x0000555555cac0bf in address_space_write (as=0x5555567deb00 <address_space_memory>, addr=4261425184, attrs=..., buf=0x7ffff7ff2028, len=2) at ../softmmu/physmem.c:2963
+ * #14 0x0000555555cac12c in address_space_rw (as=0x5555567deb00 <address_space_memory>, addr=4261425184, attrs=..., buf=0x7ffff7ff2028, len=2, is_write=true) at ../softmmu/physmem.c:2973
+ * #15 0x0000555555d3e37a in kvm_cpu_exec (cpu=0x555556b1b370) at ../accel/kvm/kvm-all.c:2900
+ * #16 0x0000555555d4104e in kvm_vcpu_thread_fn (arg=0x555556b1b370) at ../accel/kvm/kvm-accel-ops.c:51
+ * #17 0x0000555555f21924 in qemu_thread_start (args=0x555556b23120) at ../util/qemu-thread-posix.c:505
+ * #18 0x00007ffff5c05ea5 in start_thread () at /lib64/libpthread.so.0
+ * #19 0x00007ffff592eb2d in clone () at /lib64/libc.so.6
+ */
 static bool virtio_net_attach_ebpf_to_backend(NICState *nic, int prog_fd)
 {
     NetClientState *nc = qemu_get_peer(qemu_get_queue(nic), 0);
@@ -1234,6 +1258,11 @@ static void virtio_net_unload_ebpf(VirtIONet *n)
     ebpf_rss_unload(&n->ebpf_rss);
 }
 
+/*
+ * called by:
+ *   - hw/net/virtio-net.c|1387| <<virtio_net_handle_mq>> queue_pairs = virtio_net_handle_rss(n, iov, iov_cnt, false);
+ *   - hw/net/virtio-net.c|1391| <<virtio_net_handle_mq>> queue_pairs = virtio_net_handle_rss(n, iov, iov_cnt, true);
+ */
 static uint16_t virtio_net_handle_rss(VirtIONet *n,
                                       struct iovec *iov,
                                       unsigned int iov_cnt,
diff --git a/hw/pci/pci_host.c b/hw/pci/pci_host.c
index eaf217ff5..e3c195c58 100644
--- a/hw/pci/pci_host.c
+++ b/hw/pci/pci_host.c
@@ -138,6 +138,25 @@ uint32_t pci_data_read(PCIBus *s, uint32_t addr, unsigned len)
                                        PCI_CONFIG_SPACE_SIZE, len);
 }
 
+/*
+ * (gdb) bt
+ * #0  pci_host_config_write (opaque=0x5555569fa470, addr=0, val=2147487744, len=4) at hw/pci/pci_host.c:147
+ * #1  0x00005555558812ab in memory_region_write_accessor (mr=0x5555569fa780, addr=0, value=0x7fffecdb1698, size=4, shift=0, mask=4294967295, attrs=...) at /home/zhang/kvm/test/git-qemu/memory.c:483
+ * #2  0x000055555588149d in access_with_adjusted_size (addr=0, value=0x7fffecdb1698, size=4, access_size_min=1, access_size_max=4,
+ *     access_fn=0x5555558811e7 <memory_region_write_accessor>, mr=0x5555569fa780, attrs=...) at /home/zhang/kvm/test/git-qemu/memory.c:544
+ * #3  0x0000555555884420 in memory_region_dispatch_write (mr=0x5555569fa780, addr=0, data=2147487744, op=MO_32, attrs=...) at /home/zhang/kvm/test/git-qemu/memory.c:1476
+ * #4  0x0000555555822977 in flatview_write_continue (fv=0x7fffc801dbd0, addr=3320, attrs=..., buf=0x7ffff7ff0000 "", len=4, addr1=0, l=4, mr=0x5555569fa780)
+ *     at /home/zhang/kvm/test/git-qemu/exec.c:3134
+ * #5  0x0000555555822abc in flatview_write (fv=0x7fffc801dbd0, addr=3320, attrs=..., buf=0x7ffff7ff0000 "", len=4) at /home/zhang/kvm/test/git-qemu/exec.c:3174
+ * #6  0x0000555555822e07 in address_space_write (as=0x555556629360 <address_space_io>, addr=3320, attrs=..., buf=0x7ffff7ff0000 "", len=4) at /home/zhang/kvm/test/git-qemu/exec.c:3264
+ * #7  0x0000555555822e74 in address_space_rw (as=0x555556629360 <address_space_io>, addr=3320, attrs=..., buf=0x7ffff7ff0000 "", len=4, is_write=true) at /home/zhang/kvm/test/git-qemu/exec.c:3274
+ * #8  0x000055555589e484 in kvm_handle_io (port=3320, attrs=..., data=0x7ffff7ff0000, direction=1, size=4, count=1) at /home/zhang/kvm/test/git-qemu/accel/kvm/kvm-all.c:2155
+ * #9  0x000055555589ebf6 in kvm_cpu_exec (cpu=0x5555568697f0) at /home/zhang/kvm/test/git-qemu/accel/kvm/kvm-all.c:2401
+ * #10 0x00005555558724a9 in qemu_kvm_cpu_thread_fn (arg=0x5555568697f0) at /home/zhang/kvm/test/git-qemu/cpus.c:1318
+ * #11 0x0000555555e1fa78 in qemu_thread_start (args=0x555556886f30) at util/qemu-thread-posix.c:519
+ * #12 0x00007ffff4d87ea5 in start_thread () from /lib64/libpthread.so.0
+ * #13 0x00007ffff4ab09fd in clone () from /lib64/libc.so.6
+ */
 static void pci_host_config_write(void *opaque, hwaddr addr,
                                   uint64_t val, unsigned len)
 {
diff --git a/hw/scsi/scsi-disk.c b/hw/scsi/scsi-disk.c
index efee6739f..46d0af5c8 100644
--- a/hw/scsi/scsi-disk.c
+++ b/hw/scsi/scsi-disk.c
@@ -3049,6 +3049,31 @@ static void scsi_block_update_sense(SCSIRequest *req)
 }
 #endif
 
+/*
+ * (gdb) bt
+ * #0  scsi_dma_readv (offset=0, iov=0x556278515540, cb=0x5562764fc2d2 <dma_blk_cb>, cb_opaque=0x5562785154e0, opaque=0x556278b255c0) at ../hw/scsi/scsi-disk.c:3056
+ * #1  0x00005562764fc678 in dma_blk_cb (opaque=0x5562785154e0, ret=0) at ../softmmu/dma-helpers.c:178
+ * #2  0x00005562764fc8f4 in dma_blk_io (ctx=0x556278288ba0, sg=0x556278c03e48, offset=0, align=512, io_func=0x55627644bfe8 <scsi_dma_readv>, io_func_opaque=0x556278b255c0, cb=0x556276445049 <scsi_dma_complete>, opaque=0x556278b255c0, dir=DMA_DIRECTION_FROM_DEVICE) at ../softmmu/dma-helpers.c:242
+ * #3  0x0000556276445508 in scsi_do_read (r=0x556278b255c0, ret=0) at ../hw/scsi/scsi-disk.c:427
+ * #4  0x00005562764458d5 in scsi_read_data (req=0x556278b255c0) at ../hw/scsi/scsi-disk.c:499
+ * #5  0x000055627644121b in scsi_req_continue (req=0x556278b255c0) at ../hw/scsi/scsi-bus.c:1395
+ * #6  0x0000556276681d1c in virtio_scsi_handle_cmd_req_submit (s=0x556279197110, req=0x556278c03e00) at ../hw/scsi/virtio-scsi.c:719
+ * #7  0x0000556276681f70 in virtio_scsi_handle_cmd_vq (s=0x556279197110, vq=0x55627919fa78) at ../hw/scsi/virtio-scsi.c:761
+ * #8  0x0000556276681fee in virtio_scsi_handle_cmd (vdev=0x556279197110, vq=0x55627919fa78) at ../hw/scsi/virtio-scsi.c:775
+ * #9  0x00005562766af720 in virtio_queue_notify_vq (vq=0x55627919fa78) at ../hw/virtio/virtio.c:2365
+ * #10 0x00005562766b283e in virtio_queue_host_notifier_read (n=0x55627919faec) at ../hw/virtio/virtio.c:3612
+ * #11 0x0000556276974f63 in aio_dispatch_handler (ctx=0x556278288ba0, node=0x7fcc18008f60) at ../util/aio-posix.c:369
+ * #12 0x000055627697511c in aio_dispatch_handlers (ctx=0x556278288ba0) at ../util/aio-posix.c:412
+ * #13 0x0000556276975172 in aio_dispatch (ctx=0x556278288ba0) at ../util/aio-posix.c:422
+ * #14 0x000055627698e302 in aio_ctx_dispatch (source=0x556278288ba0, callback=0x0, user_data=0x0) at ../util/async.c:320
+ * #15 0x00007fcdadc14119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #16 0x00005562769a000b in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #17 0x00005562769a0085 in os_host_main_loop_wait (timeout=2000000) at ../util/main-loop.c:320
+ * #18 0x00005562769a018a in main_loop_wait (nonblocking=0) at ../util/main-loop.c:596
+ * #19 0x00005562765022ee in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #20 0x00005562762a80f2 in qemu_main (argc=28, argv=0x7ffd0bd2bd08, envp=0x0) at ../softmmu/main.c:38
+ * #21 0x00005562762a8124 in main (argc=28, argv=0x7ffd0bd2bd08) at ../softmmu/main.c:47
+ */
 static
 BlockAIOCB *scsi_dma_readv(int64_t offset, QEMUIOVector *iov,
                            BlockCompletionFunc *cb, void *cb_opaque,
diff --git a/hw/scsi/vhost-scsi-common.c b/hw/scsi/vhost-scsi-common.c
index 767f827e5..321cd9922 100644
--- a/hw/scsi/vhost-scsi-common.c
+++ b/hw/scsi/vhost-scsi-common.c
@@ -127,9 +127,29 @@ uint64_t vhost_scsi_common_get_features(VirtIODevice *vdev, uint64_t features,
     /* Turn on predefined features supported by this device */
     features |= vsc->host_features;
 
+    /*
+     * vhost scsi的
+     * static const int kernel_feature_bits[] = {
+     *     VIRTIO_F_NOTIFY_ON_EMPTY,
+     *     VIRTIO_RING_F_INDIRECT_DESC,
+     *     VIRTIO_RING_F_EVENT_IDX,
+     *     VIRTIO_SCSI_F_HOTPLUG,
+     *     VHOST_INVALID_FEATURE_BIT
+     * };
+     *
+     * 在以下使用VHostSCSICommon->feature_bits:
+     *   - hw/scsi/vhost-scsi-common.c|130| <<vhost_scsi_common_get_features>> return vhost_get_features(&vsc->dev, vsc->feature_bits, features);
+     *   - hw/scsi/vhost-scsi.c|325| <<vhost_scsi_instance_init>> vsc->feature_bits = kernel_feature_bits;
+     *   - hw/scsi/vhost-user-scsi.c|215| <<vhost_user_scsi_instance_init>> vsc->feature_bits = user_feature_bits;
+     */
     return vhost_get_features(&vsc->dev, vsc->feature_bits, features);
 }
 
+/*
+ * 在以下使用vhost_scsi_common_set_config():
+ *   - hw/scsi/vhost-scsi.c|315| <<vhost_scsi_class_init>> vdc->set_config = vhost_scsi_common_set_config;
+ *   - hw/scsi/vhost-user-scsi.c|205| <<vhost_user_scsi_class_init>> vdc->set_config = vhost_scsi_common_set_config;
+ */
 void vhost_scsi_common_set_config(VirtIODevice *vdev, const uint8_t *config)
 {
     VirtIOSCSIConfig *scsiconf = (VirtIOSCSIConfig *)config;
diff --git a/hw/scsi/vhost-scsi.c b/hw/scsi/vhost-scsi.c
index 305906817..e1792d213 100644
--- a/hw/scsi/vhost-scsi.c
+++ b/hw/scsi/vhost-scsi.c
@@ -322,6 +322,12 @@ static void vhost_scsi_instance_init(Object *obj)
 {
     VHostSCSICommon *vsc = VHOST_SCSI_COMMON(obj);
 
+    /*
+     * 在以下使用VHostSCSICommon->feature_bits:
+     *   - hw/scsi/vhost-scsi-common.c|130| <<vhost_scsi_common_get_features>> return vhost_get_features(&vsc->dev, vsc->feature_bits, features);
+     *   - hw/scsi/vhost-scsi.c|325| <<vhost_scsi_instance_init>> vsc->feature_bits = kernel_feature_bits;
+     *   - hw/scsi/vhost-user-scsi.c|215| <<vhost_user_scsi_instance_init>> vsc->feature_bits = user_feature_bits;
+     */
     vsc->feature_bits = kernel_feature_bits;
 
     device_add_bootindex_property(obj, &vsc->bootindex, "bootindex", NULL,
diff --git a/hw/scsi/virtio-scsi-dataplane.c b/hw/scsi/virtio-scsi-dataplane.c
index 20bb91766..1927c9600 100644
--- a/hw/scsi/virtio-scsi-dataplane.c
+++ b/hw/scsi/virtio-scsi-dataplane.c
@@ -22,6 +22,12 @@
 #include "hw/virtio/virtio-access.h"
 
 /* Context: QEMU global mutex held */
+/*
+ * called by:
+ *   - hw/scsi/virtio-scsi.c|1067| <<virtio_scsi_device_realize>> virtio_scsi_dataplane_setup(s, errp);
+ *
+ * 核心思想是设置VirtIOSCSI->ctx (类型struct AioContext *)
+ */
 void virtio_scsi_dataplane_setup(VirtIOSCSI *s, Error **errp)
 {
     VirtIOSCSICommon *vs = VIRTIO_SCSI_COMMON(s);
@@ -40,15 +46,31 @@ void virtio_scsi_dataplane_setup(VirtIOSCSI *s, Error **errp)
             error_setg(errp, "ioeventfd is required for iothread");
             return;
         }
+        /*
+         * struct VirtIOSCSI:
+         * -> VirtIOSCSICommon parent_obj;
+         *    -> VirtIODevice parent_obj;
+	 * -> AioContext *ctx;
+         */
         s->ctx = iothread_get_aio_context(vs->conf.iothread);
     } else {
         if (!virtio_device_ioeventfd_enabled(vdev)) {
             return;
         }
+        /*
+	 * 返回qemu_aio_context
+	 * static AioContext *qemu_aio_context;
+	 */
         s->ctx = qemu_get_aio_context();
     }
 }
 
+/*
+ * called by:
+ *   - hw/scsi/virtio-scsi-dataplane.c|130| <<virtio_scsi_dataplane_start>> rc = virtio_scsi_set_host_notifier(s, vs->ctrl_vq, 0);
+ *   - hw/scsi/virtio-scsi-dataplane.c|136| <<virtio_scsi_dataplane_start>> rc = virtio_scsi_set_host_notifier(s, vs->event_vq, 1);
+ *   - hw/scsi/virtio-scsi-dataplane.c|144| <<virtio_scsi_dataplane_start>> rc = virtio_scsi_set_host_notifier(s, vs->cmd_vqs[i], i + 2);
+ */
 static int virtio_scsi_set_host_notifier(VirtIOSCSI *s, VirtQueue *vq, int n)
 {
     BusState *qbus = BUS(qdev_get_parent_bus(DEVICE(s)));
@@ -59,6 +81,18 @@ static int virtio_scsi_set_host_notifier(VirtIOSCSI *s, VirtQueue *vq, int n)
     if (rc != 0) {
         fprintf(stderr, "virtio-scsi: Failed to set host notifier (%d)\n",
                 rc);
+        /*
+         * 在以下设置VirtIOSCSI->dataplane_fenced:
+         *   - hw/scsi/virtio-scsi-dataplane.c|62| <<virtio_scsi_set_host_notifier>> s->dataplane_fenced = true;
+         *   - hw/scsi/virtio-scsi-dataplane.c|177| <<virtio_scsi_dataplane_start>> s->dataplane_fenced = true;
+         *   - hw/scsi/virtio-scsi-dataplane.c|198| <<virtio_scsi_dataplane_stop>> s->dataplane_fenced = false;
+         * 在以下使用VirtIOSCSI->dataplane_fenced:
+         *   - hw/scsi/virtio-scsi-dataplane.c|100| <<virtio_scsi_dataplane_start>> s->dataplane_fenced) {
+         *   - hw/scsi/virtio-scsi-dataplane.c|197| <<virtio_scsi_dataplane_stop>> if (s->dataplane_fenced) {
+         *   - hw/scsi/virtio-scsi.c|113| <<virtio_scsi_complete_req>> if (s->dataplane_started && !s->dataplane_fenced) {
+         *   - hw/scsi/virtio-scsi.c|524| <<virtio_scsi_defer_to_dataplane>> return !s->dataplane_fenced;
+         *   - hw/scsi/virtio-scsi.c|940| <<virtio_scsi_hotplug>> if (s->ctx && !s->dataplane_fenced) {
+	 */
         s->dataplane_fenced = true;
         return rc;
     }
@@ -67,6 +101,10 @@ static int virtio_scsi_set_host_notifier(VirtIOSCSI *s, VirtQueue *vq, int n)
 }
 
 /* Context: BH in IOThread */
+/*
+ * called by:
+ *   - hw/scsi/virtio-scsi-dataplane.c|249| <<virtio_scsi_dataplane_stop>> aio_wait_bh_oneshot(s->ctx, virtio_scsi_dataplane_stop_bh, s);
+ */
 static void virtio_scsi_dataplane_stop_bh(void *opaque)
 {
     VirtIOSCSI *s = opaque;
@@ -81,14 +119,28 @@ static void virtio_scsi_dataplane_stop_bh(void *opaque)
 }
 
 /* Context: QEMU global mutex held */
+/*
+ * 在以下设置VirtioDeviceClass->start_ioeventfd:
+ *   - hw/scsi/virtio-scsi.c|1146| <<virtio_scsi_class_init>> vdc->start_ioeventfd = virtio_scsi_dataplane_start;
+ */
 int virtio_scsi_dataplane_start(VirtIODevice *vdev)
 {
     int i;
     int rc;
     int vq_init_count = 0;
+    /*
+     * VirtIODevice *vdev:
+     * -> DeviceState parent_obj;
+     *    -> BusState *parent_bus;
+     */
     BusState *qbus = qdev_get_parent_bus(DEVICE(vdev));
     VirtioBusClass *k = VIRTIO_BUS_GET_CLASS(qbus);
     VirtIOSCSICommon *vs = VIRTIO_SCSI_COMMON(vdev);
+    /*
+     * struct VirtIOSCSI:
+     * -> VirtIOSCSICommon parent_obj;
+     *    -> VirtIODevice parent_obj;
+     */
     VirtIOSCSI *s = VIRTIO_SCSI(vdev);
 
     if (s->dataplane_started ||
@@ -100,6 +152,12 @@ int virtio_scsi_dataplane_start(VirtIODevice *vdev)
     s->dataplane_starting = true;
 
     /* Set up guest notifier (irq) */
+    /*
+     * 在以下设置VirtioBusClass->set_guest_notifiers:
+     *   - hw/s390x/virtio-ccw.c|1276| <<virtio_ccw_bus_class_init>> k->set_guest_notifiers = virtio_ccw_set_guest_notifiers;
+     *   - hw/virtio/virtio-mmio.c|839| <<virtio_mmio_bus_class_init>> k->set_guest_notifiers = virtio_mmio_set_guest_notifiers;
+     *   - hw/virtio/virtio-pci.c|2240| <<virtio_pci_bus_class_init>> k->set_guest_notifiers = virtio_pci_set_guest_notifiers;
+     */
     rc = k->set_guest_notifiers(qbus->parent, vs->conf.num_queues + 2, true);
     if (rc != 0) {
         error_report("virtio-scsi: Failed to set guest notifiers (%d), "
@@ -168,6 +226,12 @@ fail_host_notifiers:
     for (i = 0; i < vq_init_count; i++) {
         virtio_bus_cleanup_host_notifier(VIRTIO_BUS(qbus), i);
     }
+    /*
+     * 在以下设置VirtioBusClass->set_guest_notifiers:
+     *   - hw/s390x/virtio-ccw.c|1276| <<virtio_ccw_bus_class_init>> k->set_guest_notifiers = virtio_ccw_set_guest_notifiers;
+     *   - hw/virtio/virtio-mmio.c|839| <<virtio_mmio_bus_class_init>> k->set_guest_notifiers = virtio_mmio_set_guest_notifiers;
+     *   - hw/virtio/virtio-pci.c|2240| <<virtio_pci_bus_class_init>> k->set_guest_notifiers = virtio_pci_set_guest_notifiers;
+     */
     k->set_guest_notifiers(qbus->parent, vs->conf.num_queues + 2, false);
 fail_guest_notifiers:
     s->dataplane_fenced = true;
@@ -224,6 +288,12 @@ void virtio_scsi_dataplane_stop(VirtIODevice *vdev)
     }
 
     /* Clean up guest notifier (irq) */
+    /*
+     * 在以下设置VirtioBusClass->set_guest_notifiers:
+     *   - hw/s390x/virtio-ccw.c|1276| <<virtio_ccw_bus_class_init>> k->set_guest_notifiers = virtio_ccw_set_guest_notifiers;
+     *   - hw/virtio/virtio-mmio.c|839| <<virtio_mmio_bus_class_init>> k->set_guest_notifiers = virtio_mmio_set_guest_notifiers;
+     *   - hw/virtio/virtio-pci.c|2240| <<virtio_pci_bus_class_init>> k->set_guest_notifiers = virtio_pci_set_guest_notifiers;
+     */
     k->set_guest_notifiers(qbus->parent, vs->conf.num_queues + 2, false);
     s->dataplane_stopping = false;
     s->dataplane_started = false;
diff --git a/hw/scsi/virtio-scsi.c b/hw/scsi/virtio-scsi.c
index 4141dddd5..137e760ac 100644
--- a/hw/scsi/virtio-scsi.c
+++ b/hw/scsi/virtio-scsi.c
@@ -296,6 +296,10 @@ static inline void virtio_scsi_ctx_check(VirtIOSCSI *s, SCSIDevice *d)
 /* Return 0 if the request is ready to be completed and return to guest;
  * -EINPROGRESS if the request is submitted and will be completed later, in the
  *  case of async cancellation. */
+/*
+ * called by:
+ *   - hw/scsi/virtio-scsi.c|467| <<virtio_scsi_handle_ctrl_req>> r = virtio_scsi_do_tmf(s, req);
+ */
 static int virtio_scsi_do_tmf(VirtIOSCSI *s, VirtIOSCSIReq *req)
 {
     SCSIDevice *d = virtio_scsi_device_get(s, req->req.tmf.lun);
@@ -667,6 +671,10 @@ static void virtio_scsi_fail_cmd_req(VirtIOSCSIReq *req)
     virtio_scsi_complete_cmd_req(req);
 }
 
+/*
+ * called by:
+ *   - hw/scsi/virtio-scsi.c|747| <<virtio_scsi_handle_cmd_vq>> ret = virtio_scsi_handle_cmd_req_prepare(s, req);
+ */
 static int virtio_scsi_handle_cmd_req_prepare(VirtIOSCSI *s, VirtIOSCSIReq *req)
 {
     VirtIOSCSICommon *vs = &s->parent_obj;
@@ -712,6 +720,76 @@ static int virtio_scsi_handle_cmd_req_prepare(VirtIOSCSI *s, VirtIOSCSIReq *req)
     return 0;
 }
 
+/*
+ * (gdb) bt
+ * #0  dma_blk_cb (opaque=0x5562785154e0, ret=0) at ../softmmu/dma-helpers.c:114
+ * #1  0x00005562764fc8f4 in dma_blk_io (ctx=0x556278288ba0, sg=0x556278c03e48, offset=0, align=512, io_func=0x55627644bfe8 <scsi_dma_readv>, io_func_opaque=0x556278b255c0, cb=0x556276445049 <scsi_dma_complete>, opaque=0x556278b255c0, dir=DMA_DIRECTION_FROM_DEVICE) at ../softmmu/dma-helpers.c:242
+ * #2  0x0000556276445508 in scsi_do_read (r=0x556278b255c0, ret=0) at ../hw/scsi/scsi-disk.c:427
+ * #3  0x00005562764458d5 in scsi_read_data (req=0x556278b255c0) at ../hw/scsi/scsi-disk.c:499
+ * #4  0x000055627644121b in scsi_req_continue (req=0x556278b255c0) at ../hw/scsi/scsi-bus.c:1395
+ * #5  0x0000556276681d1c in virtio_scsi_handle_cmd_req_submit (s=0x556279197110, req=0x556278c03e00) at ../hw/scsi/virtio-scsi.c:719
+ * #6  0x0000556276681f70 in virtio_scsi_handle_cmd_vq (s=0x556279197110, vq=0x55627919fa78) at ../hw/scsi/virtio-scsi.c:761
+ * #7  0x0000556276681fee in virtio_scsi_handle_cmd (vdev=0x556279197110, vq=0x55627919fa78) at ../hw/scsi/virtio-scsi.c:775
+ * #8  0x00005562766af720 in virtio_queue_notify_vq (vq=0x55627919fa78) at ../hw/virtio/virtio.c:2365
+ * #9  0x00005562766b283e in virtio_queue_host_notifier_read (n=0x55627919faec) at ../hw/virtio/virtio.c:3612
+ * #10 0x0000556276974f63 in aio_dispatch_handler (ctx=0x556278288ba0, node=0x7fcc18008f60) at ../util/aio-posix.c:369
+ * #11 0x000055627697511c in aio_dispatch_handlers (ctx=0x556278288ba0) at ../util/aio-posix.c:412
+ * #12 0x0000556276975172 in aio_dispatch (ctx=0x556278288ba0) at ../util/aio-posix.c:422
+ * #13 0x000055627698e302 in aio_ctx_dispatch (source=0x556278288ba0, callback=0x0, user_data=0x0) at ../util/async.c:320
+ * #14 0x00007fcdadc14119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #15 0x00005562769a000b in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #16 0x00005562769a0085 in os_host_main_loop_wait (timeout=2000000) at ../util/main-loop.c:320
+ * #17 0x00005562769a018a in main_loop_wait (nonblocking=0) at ../util/main-loop.c:596
+ * #18 0x00005562765022ee in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #19 0x00005562762a80f2 in qemu_main (argc=28, argv=0x7ffd0bd2bd08, envp=0x0) at ../softmmu/main.c:38
+ * #20 0x00005562762a8124 in main (argc=28, argv=0x7ffd0bd2bd08) at ../softmmu/main.c:47
+ *
+ * (gdb) bt
+ * #0  scsi_dma_readv (offset=0, iov=0x556278515540, cb=0x5562764fc2d2 <dma_blk_cb>, cb_opaque=0x5562785154e0, opaque=0x556278b255c0) at ../hw/scsi/scsi-disk.c:3056
+ * #1  0x00005562764fc678 in dma_blk_cb (opaque=0x5562785154e0, ret=0) at ../softmmu/dma-helpers.c:178
+ * #2  0x00005562764fc8f4 in dma_blk_io (ctx=0x556278288ba0, sg=0x556278c03e48, offset=0, align=512, io_func=0x55627644bfe8 <scsi_dma_readv>, io_func_opaque=0x556278b255c0, cb=0x556276445049 <scsi_dma_compl     ete>, opaque=0x556278b255c0, dir=DMA_DIRECTION_FROM_DEVICE) at ../softmmu/dma-helpers.c:242
+ * #3  0x0000556276445508 in scsi_do_read (r=0x556278b255c0, ret=0) at ../hw/scsi/scsi-disk.c:427
+ * #4  0x00005562764458d5 in scsi_read_data (req=0x556278b255c0) at ../hw/scsi/scsi-disk.c:499
+ * #5  0x000055627644121b in scsi_req_continue (req=0x556278b255c0) at ../hw/scsi/scsi-bus.c:1395
+ * #6  0x0000556276681d1c in virtio_scsi_handle_cmd_req_submit (s=0x556279197110, req=0x556278c03e00) at ../hw/scsi/virtio-scsi.c:719
+ * #7  0x0000556276681f70 in virtio_scsi_handle_cmd_vq (s=0x556279197110, vq=0x55627919fa78) at ../hw/scsi/virtio-scsi.c:761
+ * #8  0x0000556276681fee in virtio_scsi_handle_cmd (vdev=0x556279197110, vq=0x55627919fa78) at ../hw/scsi/virtio-scsi.c:775
+ * #9  0x00005562766af720 in virtio_queue_notify_vq (vq=0x55627919fa78) at ../hw/virtio/virtio.c:2365
+ * #10 0x00005562766b283e in virtio_queue_host_notifier_read (n=0x55627919faec) at ../hw/virtio/virtio.c:3612
+ * #11 0x0000556276974f63 in aio_dispatch_handler (ctx=0x556278288ba0, node=0x7fcc18008f60) at ../util/aio-posix.c:369
+ * #12 0x000055627697511c in aio_dispatch_handlers (ctx=0x556278288ba0) at ../util/aio-posix.c:412
+ * #13 0x0000556276975172 in aio_dispatch (ctx=0x556278288ba0) at ../util/aio-posix.c:422
+ * #14 0x000055627698e302 in aio_ctx_dispatch (source=0x556278288ba0, callback=0x0, user_data=0x0) at ../util/async.c:320
+ * #15 0x00007fcdadc14119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #16 0x00005562769a000b in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #17 0x00005562769a0085 in os_host_main_loop_wait (timeout=2000000) at ../util/main-loop.c:320
+ * #18 0x00005562769a018a in main_loop_wait (nonblocking=0) at ../util/main-loop.c:596
+ * #19 0x00005562765022ee in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #20 0x00005562762a80f2 in qemu_main (argc=28, argv=0x7ffd0bd2bd08, envp=0x0) at ../softmmu/main.c:38
+ * #21 0x00005562762a8124 in main (argc=28, argv=0x7ffd0bd2bd08) at ../softmmu/main.c:47
+ *
+ * (gdb) bt
+ * #0  blk_aio_preadv (blk=0x560c43bf4420, offset=8609107968, qiov=0x7f9a7800e670, flags=0, cb=0x560c42152042 <dma_blk_cb>, opaque=0x7f9a7800e610) at ../block/block-backend.c:1617
+ * #1  0x0000560c420a1dcd in scsi_dma_readv (offset=8609107968, iov=0x7f9a7800e670, cb=0x560c42152042 <dma_blk_cb>, cb_opaque=0x7f9a7800e610, opaque=0x7f9a780027d0) at ../hw/scsi/scsi-disk.c:3059
+ * #2  0x0000560c421523e8 in dma_blk_cb (opaque=0x7f9a7800e610, ret=0) at ../softmmu/dma-helpers.c:178
+ * #3  0x0000560c42152664 in dma_blk_io
+ *     (ctx=0x560c43bf1270, sg=0x7f9a7800dc68, offset=8609107968, align=512, io_func=0x560c420a1d58 <scsi_dma_readv>, io_func_opaque=0x7f9a780027d0, cb=0x560c4209adb9 <scsi_dma_complete>, opaque=0x7f9a78002     7d0, dir=DMA_DIRECTION_FROM_DEVICE) at ../softmmu/dma-helpers.c:242
+ * #4  0x0000560c4209b278 in scsi_do_read (r=0x7f9a780027d0, ret=0) at ../hw/scsi/scsi-disk.c:427
+ * #5  0x0000560c4209b645 in scsi_read_data (req=0x7f9a780027d0) at ../hw/scsi/scsi-disk.c:499
+ * #6  0x0000560c42096f8b in scsi_req_continue (req=0x7f9a780027d0) at ../hw/scsi/scsi-bus.c:1395
+ * #7  0x0000560c422d7a44 in virtio_scsi_handle_cmd_req_submit (s=0x560c448d0e10, req=0x7f9a7800dc20) at ../hw/scsi/virtio-scsi.c:719
+ * #8  0x0000560c422d7c98 in virtio_scsi_handle_cmd_vq (s=0x560c448d0e10, vq=0x560c448d9838) at ../hw/scsi/virtio-scsi.c:761
+ * #9  0x0000560c422d7d16 in virtio_scsi_handle_cmd (vdev=0x560c448d0e10, vq=0x560c448d9838) at ../hw/scsi/virtio-scsi.c:775
+ * #10 0x0000560c42305448 in virtio_queue_notify_vq (vq=0x560c448d9838) at ../hw/virtio/virtio.c:2365
+ * #11 0x0000560c42308566 in virtio_queue_host_notifier_read (n=0x560c448d98ac) at ../hw/virtio/virtio.c:3612
+ * #12 0x0000560c425c4f68 in aio_dispatch_handler (ctx=0x560c43bf1270, node=0x7f98e805d400) at ../util/aio-posix.c:369
+ * #13 0x0000560c425c505c in aio_dispatch_ready_handlers (ctx=0x560c43bf1270, ready_list=0x7f9a7ff6d880) at ../util/aio-posix.c:399
+ * #14 0x0000560c425c5ac6 in aio_poll (ctx=0x560c43bf1270, blocking=true) at ../util/aio-posix.c:713
+ * #15 0x0000560c4243ab66 in iothread_run (opaque=0x560c43bf0f00) at ../iothread.c:67
+ * #16 0x0000560c425ca4de in qemu_thread_start (args=0x560c43bf18e0) at ../util/qemu-thread-posix.c:504
+ * #17 0x00007f9a85ec5ea5 in start_thread () at /lib64/libpthread.so.0
+ * #18 0x00007f9a85bee9fd in clone () at /lib64/libc.so.6
+ */
 static void virtio_scsi_handle_cmd_req_submit(VirtIOSCSI *s, VirtIOSCSIReq *req)
 {
     SCSIRequest *sreq = req->sreq;
@@ -722,6 +800,10 @@ static void virtio_scsi_handle_cmd_req_submit(VirtIOSCSI *s, VirtIOSCSIReq *req)
     scsi_req_unref(sreq);
 }
 
+/*
+ * called by:
+ *   - hw/scsi/virtio-scsi.c|779| <<virtio_scsi_handle_cmd>> virtio_scsi_handle_cmd_vq(s, vq);
+ */
 static void virtio_scsi_handle_cmd_vq(VirtIOSCSI *s, VirtQueue *vq)
 {
     VirtIOSCSIReq *req, *next;
@@ -838,6 +920,13 @@ static void virtio_scsi_reset(VirtIODevice *vdev)
     s->events_dropped = false;
 }
 
+/*
+ * called by:
+ *   - hw/scsi/virtio-scsi.c|893| <<virtio_scsi_handle_event_vq>> virtio_scsi_push_event(s, NULL, VIRTIO_SCSI_T_NO_EVENT, 0);
+ *   - hw/scsi/virtio-scsi.c|918| <<virtio_scsi_change>> virtio_scsi_push_event(s, dev, VIRTIO_SCSI_T_PARAM_CHANGE,
+ *   - hw/scsi/virtio-scsi.c|955| <<virtio_scsi_hotplug>> virtio_scsi_push_event(s, sd,
+ *   - hw/scsi/virtio-scsi.c|972| <<virtio_scsi_hotunplug>> virtio_scsi_push_event(s, sd,
+ */
 static void virtio_scsi_push_event(VirtIOSCSI *s, SCSIDevice *dev,
                                    uint32_t event, uint32_t reason)
 {
@@ -928,6 +1017,10 @@ static void virtio_scsi_pre_hotplug(HotplugHandler *hotplug_dev,
     sd->hba_supports_iothread = true;
 }
 
+/*
+ * 在以下使用virtio_scsi_hotplug():
+ *   - hw/scsi/virtio-scsi.c|1149| <<virtio_scsi_class_init>> hc->plug = virtio_scsi_hotplug;
+ */
 static void virtio_scsi_hotplug(HotplugHandler *hotplug_dev, DeviceState *dev,
                                 Error **errp)
 {
diff --git a/hw/vfio/common.c b/hw/vfio/common.c
index ace9562a9..edf47d91f 100644
--- a/hw/vfio/common.c
+++ b/hw/vfio/common.c
@@ -491,6 +491,12 @@ static int vfio_dma_unmap(VFIOContainer *container,
     return 0;
 }
 
+/*
+ * called by:
+ *   - hw/vfio/common.c|695| <<vfio_iommu_map_notify>> ret = vfio_dma_map(container, iova,
+ *   - hw/vfio/common.c|757| <<vfio_ram_discard_notify_populate>> ret = vfio_dma_map(vrdl->container, iova, next - start,
+ *   - hw/vfio/common.c|1088| <<vfio_listener_region_add>> ret = vfio_dma_map(container, iova, int128_get64(llsize),
+ */
 static int vfio_dma_map(VFIOContainer *container, hwaddr iova,
                         ram_addr_t size, void *vaddr, bool readonly)
 {
diff --git a/hw/virtio/vhost.c b/hw/virtio/vhost.c
index f758f177b..4e20c9a32 100644
--- a/hw/virtio/vhost.c
+++ b/hw/virtio/vhost.c
@@ -1282,6 +1282,10 @@ static int vhost_virtqueue_set_busyloop_timeout(struct vhost_dev *dev,
     return 0;
 }
 
+/*
+ * 在以下使用vhost_virtqueue_error_notifier():
+ *   - hw/virtio/vhost.c|1333| <<vhost_virtqueue_init>> event_notifier_set_handler(&vq->error_notifier, vhost_virtqueue_error_notifier);
+ */
 static void vhost_virtqueue_error_notifier(EventNotifier *n)
 {
     struct vhost_virtqueue *vq = container_of(n, struct vhost_virtqueue,
@@ -1502,6 +1506,18 @@ void vhost_dev_cleanup(struct vhost_dev *hdev)
 /* Stop processing guest IO notifications in qemu.
  * Start processing them in vhost in kernel.
  */
+/*
+ * called by:
+ *   - backends/cryptodev-vhost.c|92| <<cryptodev_vhost_start_one>> r = vhost_dev_enable_notifiers(&crypto->dev, dev);
+ *   - backends/vhost-user.c|76| <<vhost_user_backend_start>> ret = vhost_dev_enable_notifiers(&b->dev, b->vdev);
+ *   - hw/block/vhost-user-blk.c|132| <<vhost_user_blk_start>> ret = vhost_dev_enable_notifiers(&s->dev, vdev);
+ *   - hw/net/vhost_net.c|247| <<vhost_net_start_one>> r = vhost_dev_enable_notifiers(&net->dev, dev);
+ *   - hw/scsi/vhost-scsi-common.c|42| <<vhost_scsi_common_start>> ret = vhost_dev_enable_notifiers(&vsc->dev, vdev);
+ *   - hw/virtio/vhost-user-fs.c|64| <<vuf_start>> ret = vhost_dev_enable_notifiers(&fs->vhost_dev, vdev);
+ *   - hw/virtio/vhost-user-i2c.c|34| <<vu_i2c_start>> ret = vhost_dev_enable_notifiers(&i2c->vhost_dev, vdev);
+ *   - hw/virtio/vhost-user-rng.c|32| <<vu_rng_start>> ret = vhost_dev_enable_notifiers(&rng->vhost_dev, vdev);
+ *   - hw/virtio/vhost-vsock-common.c|58| <<vhost_vsock_common_start>> ret = vhost_dev_enable_notifiers(&vvc->vhost_dev, vdev);
+ */
 int vhost_dev_enable_notifiers(struct vhost_dev *hdev, VirtIODevice *vdev)
 {
     BusState *qbus = BUS(qdev_get_parent_bus(DEVICE(vdev)));
@@ -1598,12 +1614,34 @@ void vhost_virtqueue_mask(struct vhost_dev *hdev, VirtIODevice *vdev, int n,
     }
 }
 
+/*
+ * 在以下使用vhost_get_features():
+ *   - hw/block/vhost-user-blk.c|272| <<vhost_user_blk_get_features>> return vhost_get_features(&s->dev, user_feature_bits, features);
+ *   - hw/net/vhost_net.c|114| <<vhost_net_get_features>> return vhost_get_features(&net->dev, vhost_net_get_feature_bits(net),
+ *   - hw/scsi/vhost-scsi-common.c|136| <<vhost_scsi_common_get_features>> return vhost_get_features(&vsc->dev, vsc->feature_bits, features);
+ *   - hw/virtio/vhost-user-fs.c|148| <<vuf_get_features>> return vhost_get_features(&fs->vhost_dev, user_feature_bits, features);
+ *   - hw/virtio/vhost-user-i2c.c|119| <<vu_i2c_get_features>> return vhost_get_features(&i2c->vhost_dev, feature_bits, requested_features);
+ *   - hw/virtio/vhost-user-vsock.c|84| <<vuv_get_features>> features = vhost_get_features(&vvc->vhost_dev, user_feature_bits, features);
+ *   - hw/virtio/vhost-vsock-common.c|35| <<vhost_vsock_common_get_features>> features = vhost_get_features(&vvc->vhost_dev, feature_bits, features);
+ *   - hw/virtio/vhost.c|1378| <<vhost_dev_init>> r = hdev->vhost_ops->vhost_get_features(hdev, &features);
+ */
 uint64_t vhost_get_features(struct vhost_dev *hdev, const int *feature_bits,
                             uint64_t features)
 {
+    /*
+     * feature_bits是一个地址
+     * *bit就是一个值, value
+     */
     const int *bit = feature_bits;
+    /*
+     * 一直到*bit这个value不等于0xff ...
+     */
     while (*bit != VHOST_INVALID_FEATURE_BIT) {
         uint64_t bit_mask = (1ULL << *bit);
+        /*
+	 * #define VIRTIO_F_VERSION_1 32
+	 * hex is 0x20
+	 */
         if (!(hdev->features & bit_mask)) {
             features &= ~bit_mask;
         }
diff --git a/hw/virtio/virtio-bus.c b/hw/virtio/virtio-bus.c
index 896feb37a..a3310b616 100644
--- a/hw/virtio/virtio-bus.c
+++ b/hw/virtio/virtio-bus.c
@@ -40,6 +40,10 @@ do { printf("virtio_bus: " fmt , ## __VA_ARGS__); } while (0)
 #endif
 
 /* A VirtIODevice is being plugged */
+/*
+ * called by:
+ *   - hw/virtio/virtio.c|3763| <<virtio_device_realize>> virtio_bus_device_plugged(vdev, &err);
+ */
 void virtio_bus_device_plugged(VirtIODevice *vdev, Error **errp)
 {
     DeviceState *qdev = DEVICE(vdev);
@@ -53,6 +57,10 @@ void virtio_bus_device_plugged(VirtIODevice *vdev, Error **errp)
 
     DPRINTF("%s: plug device.\n", qbus->name);
 
+    /*
+     * virtio_pci_pre_plugged()
+     * 根据是否modern为vdev->host_features添加VIRTIO_F_VERSION_1
+     */
     if (klass->pre_plugged != NULL) {
         klass->pre_plugged(qbus->parent, &local_err);
         if (local_err) {
@@ -63,6 +71,13 @@ void virtio_bus_device_plugged(VirtIODevice *vdev, Error **errp)
 
     /* Get the features of the plugged device. */
     assert(vdc->get_features != NULL);
+    /*
+     * 一些例子:
+     *   - hw/net/virtio-net.c|3778| <<virtio_net_class_init>> vdc->get_features = virtio_net_get_features;
+     *   - hw/scsi/vhost-scsi.c|314| <<vhost_scsi_class_init>> vdc->get_features = vhost_scsi_common_get_features;
+     *   - hw/scsi/vhost-user-scsi.c|204| <<vhost_user_scsi_class_init>> vdc->get_features = vhost_scsi_common_get_features;
+     *   - hw/scsi/virtio-scsi.c|1155| <<virtio_scsi_class_init>> vdc->get_features = virtio_scsi_get_features;
+     */
     vdev->host_features = vdc->get_features(vdev, vdev->host_features,
                                             &local_err);
     if (local_err) {
@@ -70,6 +85,11 @@ void virtio_bus_device_plugged(VirtIODevice *vdev, Error **errp)
         return;
     }
 
+    /*
+     * 在以下:
+     *   - hw/s390x/virtio-ccw.c|1282| <<virtio_ccw_bus_class_init>> k->device_plugged = virtio_ccw_device_plugged;
+     *   - hw/virtio/virtio-pci.c|2252| <<virtio_pci_bus_class_init>> k->device_plugged = virtio_pci_device_plugged;
+     */
     if (klass->device_plugged != NULL) {
         klass->device_plugged(qbus->parent, &local_err);
     }
@@ -99,6 +119,12 @@ void virtio_bus_device_plugged(VirtIODevice *vdev, Error **errp)
 }
 
 /* Reset the virtio_bus */
+/*
+ * called by:
+ *   - hw/s390x/virtio-ccw.c|256| <<virtio_ccw_reset_virtio>> virtio_bus_reset(&dev->bus);
+ *   - hw/virtio/virtio-mmio.c|75| <<virtio_mmio_soft_reset>> virtio_bus_reset(&proxy->bus);
+ *   - hw/virtio/virtio-pci.c|1979| <<virtio_pci_reset>> virtio_bus_reset(bus);
+ */
 void virtio_bus_reset(VirtioBusState *bus)
 {
     VirtIODevice *vdev = virtio_bus_get_device(bus);
@@ -111,6 +137,10 @@ void virtio_bus_reset(VirtioBusState *bus)
 }
 
 /* A VirtIODevice is being unplugged */
+/*
+ * called by:
+ *   - hw/virtio/virtio.c|3781| <<virtio_device_unrealize>> virtio_bus_device_unplugged(vdev);
+ */
 void virtio_bus_device_unplugged(VirtIODevice *vdev)
 {
     DeviceState *qdev = DEVICE(vdev);
@@ -273,6 +303,22 @@ bool virtio_bus_ioeventfd_enabled(VirtioBusState *bus)
  * This function switches ioeventfd on/off in the device.
  * The caller must set or clear the handlers for the EventNotifier.
  */
+/*
+ * called by:
+ *   - hw/block/dataplane/virtio-blk.c|198| <<virtio_blk_data_plane_start>> r = virtio_bus_set_host_notifier(VIRTIO_BUS(qbus), i, true);
+ *   - hw/block/dataplane/virtio-blk.c|204| <<virtio_blk_data_plane_start>> virtio_bus_set_host_notifier(VIRTIO_BUS(qbus), i, false);
+ *   - hw/block/dataplane/virtio-blk.c|264| <<virtio_blk_data_plane_start>> virtio_bus_set_host_notifier(VIRTIO_BUS(qbus), i, false);
+ *   - hw/block/dataplane/virtio-blk.c|341| <<virtio_blk_data_plane_stop>> virtio_bus_set_host_notifier(VIRTIO_BUS(qbus), i, false);
+ *   - hw/scsi/virtio-scsi-dataplane.c|58| <<virtio_scsi_set_host_notifier>> rc = virtio_bus_set_host_notifier(VIRTIO_BUS(qbus), n, true);
+ *   - hw/scsi/virtio-scsi-dataplane.c|173| <<virtio_scsi_dataplane_start>> virtio_bus_set_host_notifier(VIRTIO_BUS(qbus), i, false);
+ *   - hw/scsi/virtio-scsi-dataplane.c|227| <<virtio_scsi_dataplane_stop>> virtio_bus_set_host_notifier(VIRTIO_BUS(qbus), i, false);
+ *   - hw/virtio/vhost.c|1520| <<vhost_dev_enable_notifiers>> r = virtio_bus_set_host_notifier(VIRTIO_BUS(qbus), hdev->vq_index + i,
+ *   - hw/virtio/vhost.c|1531| <<vhost_dev_enable_notifiers>> e = virtio_bus_set_host_notifier(VIRTIO_BUS(qbus), hdev->vq_index + i,
+ *   - hw/virtio/vhost.c|1555| <<vhost_dev_disable_notifiers>> r = virtio_bus_set_host_notifier(VIRTIO_BUS(qbus), hdev->vq_index + i,
+ *   - hw/virtio/virtio.c|3769| <<virtio_device_start_ioeventfd_impl>> r = virtio_bus_set_host_notifier(qbus, n, true);
+ *   - hw/virtio/virtio.c|3798| <<virtio_device_start_ioeventfd_impl>> r = virtio_bus_set_host_notifier(qbus, n, false);
+ *   - hw/virtio/virtio.c|3841| <<virtio_device_stop_ioeventfd_impl>> r = virtio_bus_set_host_notifier(qbus, n, false);
+ */
 int virtio_bus_set_host_notifier(VirtioBusState *bus, int n, bool assign)
 {
     VirtIODevice *vdev = virtio_bus_get_device(bus);
@@ -287,12 +333,33 @@ int virtio_bus_set_host_notifier(VirtioBusState *bus, int n, bool assign)
     }
 
     if (assign) {
+        /*
+	 * EventNotifier *notifier
+	 * -> int rfd;
+	 * -> int wfd;
+	 * -> bool initialized;
+	 */
         r = event_notifier_init(notifier, 1);
         if (r < 0) {
             error_report("%s: unable to init event notifier: %s (%d)",
                          __func__, strerror(-r), r);
             return r;
         }
+        /*
+	 * 在以下设置VirtioBusClass->ioeventfd_assign:
+         *   - hw/s390x/virtio-ccw.c|1285| <<virtio_ccw_bus_class_init>> k->ioeventfd_assign = virtio_ccw_ioeventfd_assign;
+         *   - hw/virtio/virtio-mmio.c|841| <<virtio_mmio_bus_class_init>> k->ioeventfd_assign = virtio_mmio_ioeventfd_assign;
+         *   - hw/virtio/virtio-pci.c|2229| <<virtio_pci_bus_class_init>> k->ioeventfd_assign = virtio_pci_ioeventfd_assign;
+         * 在以下使用VirtioBusClass->ioeventfd_assign:
+         *   - hw/block/dataplane/virtio-blk.c|95| <<virtio_blk_data_plane_create>> if (!k->set_guest_notifiers || !k->ioeventfd_assign) {
+         *   - hw/scsi/virtio-scsi-dataplane.c|39| <<virtio_scsi_dataplane_setup>> if (!k->set_guest_notifiers || !k->ioeventfd_assign) {
+         *   - hw/virtio/virtio-bus.c|194| <<virtio_bus_grab_ioeventfd>> if (!k->ioeventfd_assign) {
+         *   - hw/virtio/virtio-bus.c|227| <<virtio_bus_start_ioeventfd>> if (!k->ioeventfd_assign || !k->ioeventfd_enabled(proxy)) {
+         *   - hw/virtio/virtio-bus.c|269| <<virtio_bus_ioeventfd_enabled>> return k->ioeventfd_assign && k->ioeventfd_enabled(proxy);
+         *   - hw/virtio/virtio-bus.c|301| <<virtio_bus_set_host_notifier>> if (!k->ioeventfd_assign) {
+         *   - hw/virtio/virtio-bus.c|312| <<virtio_bus_set_host_notifier>> r = k->ioeventfd_assign(proxy, notifier, n, true);
+         *   - hw/virtio/virtio-bus.c|318| <<virtio_bus_set_host_notifier>> k->ioeventfd_assign(proxy, notifier, n, false);
+         */
         r = k->ioeventfd_assign(proxy, notifier, n, true);
         if (r < 0) {
             error_report("%s: unable to assign ioeventfd: %d", __func__, r);
@@ -309,6 +376,21 @@ int virtio_bus_set_host_notifier(VirtioBusState *bus, int n, bool assign)
     return r;
 }
 
+/*
+ * called by:
+ *   - hw/block/dataplane/virtio-blk.c|214| <<virtio_blk_data_plane_start>> virtio_bus_cleanup_host_notifier(VIRTIO_BUS(qbus), j);
+ *   - hw/block/dataplane/virtio-blk.c|270| <<virtio_blk_data_plane_start>> virtio_bus_cleanup_host_notifier(VIRTIO_BUS(qbus), i);
+ *   - hw/block/dataplane/virtio-blk.c|351| <<virtio_blk_data_plane_stop>> virtio_bus_cleanup_host_notifier(VIRTIO_BUS(qbus), i);
+ *   - hw/scsi/virtio-scsi-dataplane.c|217| <<virtio_scsi_dataplane_start>> virtio_bus_cleanup_host_notifier(VIRTIO_BUS(qbus), i);
+ *   - hw/scsi/virtio-scsi-dataplane.c|271| <<virtio_scsi_dataplane_stop>> virtio_bus_cleanup_host_notifier(VIRTIO_BUS(qbus), i);
+ *   - hw/virtio/vhost.c|1537| <<vhost_dev_enable_notifiers>> virtio_bus_cleanup_host_notifier(VIRTIO_BUS(qbus), hdev->vq_index + i);
+ *   - hw/virtio/vhost.c|1561| <<vhost_dev_disable_notifiers>> virtio_bus_cleanup_host_notifier(VIRTIO_BUS(qbus), hdev->vq_index + i);
+ *   - hw/virtio/virtio-bus.c|315| <<virtio_bus_set_host_notifier>> virtio_bus_cleanup_host_notifier(bus, n);
+ *   - hw/virtio/virtio.c|3818| <<virtio_device_start_ioeventfd_impl>> virtio_bus_cleanup_host_notifier(qbus, i);
+ *   - hw/virtio/virtio.c|3861| <<virtio_device_stop_ioeventfd_impl>> virtio_bus_cleanup_host_notifier(qbus, n);
+ *
+ * Tell the bus that the ioeventfd handler is no longer required.
+ */
 void virtio_bus_cleanup_host_notifier(VirtioBusState *bus, int n)
 {
     VirtIODevice *vdev = virtio_bus_get_device(bus);
diff --git a/hw/virtio/virtio-pci.c b/hw/virtio/virtio-pci.c
index a50c5a57d..516a705ab 100644
--- a/hw/virtio/virtio-pci.c
+++ b/hw/virtio/virtio-pci.c
@@ -228,6 +228,21 @@ static inline int virtio_pci_queue_mem_mult(struct VirtIOPCIProxy *proxy)
         QEMU_VIRTIO_PCI_QUEUE_MEM_MULT : 4;
 }
 
+/*
+ * 在以下设置VirtioBusClass->ioeventfd_assign:
+ *   - hw/s390x/virtio-ccw.c|1285| <<virtio_ccw_bus_class_init>> k->ioeventfd_assign = virtio_ccw_ioeventfd_assign;
+ *   - hw/virtio/virtio-mmio.c|841| <<virtio_mmio_bus_class_init>> k->ioeventfd_assign = virtio_mmio_ioeventfd_assign;
+ *   - hw/virtio/virtio-pci.c|2229| <<virtio_pci_bus_class_init>> k->ioeventfd_assign = virtio_pci_ioeventfd_assign;
+ * 在以下使用VirtioBusClass->ioeventfd_assign:
+ *   - hw/block/dataplane/virtio-blk.c|95| <<virtio_blk_data_plane_create>> if (!k->set_guest_notifiers || !k->ioeventfd_assign) {
+ *   - hw/scsi/virtio-scsi-dataplane.c|39| <<virtio_scsi_dataplane_setup>> if (!k->set_guest_notifiers || !k->ioeventfd_assign) {
+ *   - hw/virtio/virtio-bus.c|194| <<virtio_bus_grab_ioeventfd>> if (!k->ioeventfd_assign) {
+ *   - hw/virtio/virtio-bus.c|227| <<virtio_bus_start_ioeventfd>> if (!k->ioeventfd_assign || !k->ioeventfd_enabled(proxy)) {
+ *   - hw/virtio/virtio-bus.c|269| <<virtio_bus_ioeventfd_enabled>> return k->ioeventfd_assign && k->ioeventfd_enabled(proxy);
+ *   - hw/virtio/virtio-bus.c|301| <<virtio_bus_set_host_notifier>> if (!k->ioeventfd_assign) {
+ *   - hw/virtio/virtio-bus.c|312| <<virtio_bus_set_host_notifier>> r = k->ioeventfd_assign(proxy, notifier, n, true);
+ *   - hw/virtio/virtio-bus.c|318| <<virtio_bus_set_host_notifier>> k->ioeventfd_assign(proxy, notifier, n, false);
+ */
 static int virtio_pci_ioeventfd_assign(DeviceState *d, EventNotifier *notifier,
                                        int n, bool assign)
 {
@@ -251,6 +266,10 @@ static int virtio_pci_ioeventfd_assign(DeviceState *d, EventNotifier *notifier,
                 memory_region_add_eventfd(modern_mr, modern_addr, 0,
                                           false, n, notifier);
             } else {
+                /*
+		 * 核心思想就是制作MemoryRegionIoeventfd给MemoryRegion->ioeventfds[i]
+                 * 可能会g_realloc()
+		 */
                 memory_region_add_eventfd(modern_mr, modern_addr, 2,
                                           false, n, notifier);
             }
@@ -1189,6 +1208,14 @@ static uint64_t virtio_pci_common_read(void *opaque, hwaddr addr,
         if (proxy->dfselect <= 1) {
             VirtioDeviceClass *vdc = VIRTIO_DEVICE_GET_CLASS(vdev);
 
+            /*
+	     * 在以下使用ViriioDevice->legacy_features:
+             *   - hw/net/virtio-net.c|3785| <<virtio_net_class_init>> vdc->legacy_features |= (0x1 << VIRTIO_NET_F_GSO);
+             *   - hw/s390x/virtio-ccw.c|389| <<virtio_ccw_cb>> (vdev->host_features & ~vdc->legacy_features);
+             *   - hw/virtio/virtio-mmio.c|170| <<virtio_mmio_read>> return (vdev->host_features & ~vdc->legacy_features)
+             *   - hw/virtio/virtio-pci.c|1211| <<virtio_pci_common_read>> val = (vdev->host_features & ~vdc->legacy_features) >>
+             *   - hw/virtio/virtio.c|3959| <<virtio_device_class_init>> vdc->legacy_features |= VIRTIO_LEGACY_FEATURES;
+	     */
             val = (vdev->host_features & ~vdc->legacy_features) >>
                 (32 * proxy->dfselect);
         }
@@ -1477,6 +1504,10 @@ static void virtio_pci_device_write(void *opaque, hwaddr addr,
     }
 }
 
+/*
+ * called by:
+ *   - hw/virtio/virtio-pci.c|1744| <<virtio_pci_device_plugged>> virtio_pci_modern_regions_init(proxy, vdev->name);
+ */
 static void virtio_pci_modern_regions_init(VirtIOPCIProxy *proxy,
                                            const char *vdev_name)
 {
@@ -1609,6 +1640,10 @@ static void virtio_pci_modern_io_region_unmap(VirtIOPCIProxy *proxy,
                                 &region->mr);
 }
 
+/*
+ * 在以下使用virtio_pci_pre_plugged():
+ *   - hw/virtio/virtio-pci.c|2259| <<virtio_pci_bus_class_init>> k->pre_plugged = virtio_pci_pre_plugged;
+ */
 static void virtio_pci_pre_plugged(DeviceState *d, Error **errp)
 {
     VirtIOPCIProxy *proxy = VIRTIO_PCI(d);
@@ -1622,6 +1657,13 @@ static void virtio_pci_pre_plugged(DeviceState *d, Error **errp)
 }
 
 /* This is called by virtio-bus just after the device is plugged. */
+/*
+ * called by:
+ *   - hw/virtio/virtio-bus.c|93| <<virtio_bus_device_plugged>> klass->device_plugged(qbus->parent, &local_err);
+ *
+ * 在以下使用virtio_pci_device_plugged():
+ *   - hw/virtio/virtio-pci.c|2252| <<virtio_pci_bus_class_init>> k->device_plugged = virtio_pci_device_plugged;
+ */
 static void virtio_pci_device_plugged(DeviceState *d, Error **errp)
 {
     VirtIOPCIProxy *proxy = VIRTIO_PCI(d);
@@ -1650,6 +1692,15 @@ static void virtio_pci_device_plugged(DeviceState *d, Error **errp)
         }
     }
 
+    /*
+     * 在以下使用VirtIOPCIProxy->disable_modern:
+     *   - hw/virtio/virtio-pci.c|2078| <<global>> DEFINE_PROP_BOOL("disable-modern", VirtIOPCIProxy, disable_modern, false),
+     *   - hw/virtio/virtio-pci.c|2102| <<virtio_pci_transitional_instance_init>> proxy->disable_modern = false;
+     *   - hw/virtio/virtio-pci.c|2110| <<virtio_pci_non_transitional_instance_init>> proxy->disable_modern = false;
+     *   - include/hw/virtio/virtio-pci.h|163| <<virtio_pci_modern>> return !proxy->disable_modern;
+     *   - include/hw/virtio/virtio-pci.h|173| <<virtio_pci_force_virtio_1>> proxy->disable_modern = false;
+     *   - include/hw/virtio/virtio-pci.h|179| <<virtio_pci_disable_modern>> proxy->disable_modern = true;
+     */
     modern = virtio_pci_modern(proxy);
 
     config = proxy->pci_dev.config;
@@ -2195,6 +2246,10 @@ unsigned virtio_pci_optimal_num_queues(unsigned fixed_queues)
 
 /* virtio-pci-bus */
 
+/*
+ * called by:
+ *   - hw/virtio/virtio-pci.c|1978| <<virtio_pci_realize>> virtio_pci_bus_new(&proxy->bus, sizeof(proxy->bus), proxy);
+ */
 static void virtio_pci_bus_new(VirtioBusState *bus, size_t bus_size,
                                VirtIOPCIProxy *dev)
 {
diff --git a/hw/virtio/virtio.c b/hw/virtio/virtio.c
index 5d607aeaa..751ee697a 100644
--- a/hw/virtio/virtio.c
+++ b/hw/virtio/virtio.c
@@ -101,10 +101,34 @@ struct VirtQueue
 
     /* Next head to pop */
     uint16_t last_avail_idx;
+    /*
+     * 在以下使用VirtQueue->last_avail_wrap_counter:
+     *   - w/virtio/virtio.c|2697| <<global>> VMSTATE_BOOL(last_avail_wrap_counter, struct VirtQueue),
+     *   - hw/virtio/virtio.c|694| <<virtio_queue_packed_empty_rcu>> return !is_desc_avail(desc.flags, vq->last_avail_wrap_counter);
+     *   - hw/virtio/virtio.c|762| <<virtqueue_packed_rewind>> vq->last_avail_wrap_counter ^= 1;
+     *   - hw/virtio/virtio.c|1182| <<virtqueue_packed_get_avail_bytes>> wrap_counter = vq->last_avail_wrap_counter;
+     *   - hw/virtio/virtio.c|1706| <<virtqueue_packed_pop>> vq->last_avail_wrap_counter ^= 1;
+     *   - hw/virtio/virtio.c|1710| <<virtqueue_packed_pop>> vq->shadow_avail_wrap_counter = vq->last_avail_wrap_counter;
+     *   - hw/virtio/virtio.c|1764| <<virtqueue_packed_drop_all>> if (!is_desc_avail(desc.flags, vq->last_avail_wrap_counter)) {
+     *   - hw/virtio/virtio.c|1782| <<virtqueue_packed_drop_all>> vq->last_avail_wrap_counter ^= 1;
+     *   - hw/virtio/virtio.c|2059| <<virtio_reset>> vdev->vq[i].last_avail_wrap_counter = true;
+     *   - hw/virtio/virtio.c|3174| <<virtio_load>> vdev->vq[i].last_avail_wrap_counter;
+     *   - hw/virtio/virtio.c|3400| <<virtio_queue_packed_get_last_avail_idx>> avail |= ((uint16_t)vdev->vq[n].last_avail_wrap_counter) << 15;
+     *   - hw/virtio/virtio.c|3429| <<virtio_queue_packed_set_last_avail_idx>> vq->last_avail_wrap_counter =
+     */
     bool last_avail_wrap_counter;
 
     /* Last avail_idx read from VQ. */
     uint16_t shadow_avail_idx;
+    /*
+     * 在以下使用VirtQueue->shadow_avail_wrap_counter:
+     *   - hw/virtio/virtio.c|523| <<virtio_queue_packed_set_notification>> off_wrap = vq->shadow_avail_idx | vq->shadow_avail_wrap_counter << 15;
+     *   - hw/virtio/virtio.c|1278| <<virtqueue_packed_get_avail_bytes>> vq->shadow_avail_wrap_counter = wrap_counter;
+     *   - hw/virtio/virtio.c|1725| <<virtqueue_packed_pop>> vq->shadow_avail_wrap_counter = vq->last_avail_wrap_counter;
+     *   - hw/virtio/virtio.c|2075| <<virtio_reset>> vdev->vq[i].shadow_avail_wrap_counter = true;
+     *   - hw/virtio/virtio.c|3188| <<virtio_load>> vdev->vq[i].shadow_avail_wrap_counter = vdev->vq[i].last_avail_wrap_counter;
+     *   - hw/virtio/virtio.c|3445| <<virtio_queue_packed_set_last_avail_idx>> vq->shadow_avail_wrap_counter = !!(idx & 0x8000);
+     */
     bool shadow_avail_wrap_counter;
 
     uint16_t used_idx;
@@ -124,9 +148,46 @@ struct VirtQueue
     unsigned int inuse;
 
     uint16_t vector;
+    /*
+     * 在以下使用VirtQueue->handle_output:
+     *   - hw/virtio/virtio.c|2478| <<virtio_queue_notify_vq>> if (vq->vring.desc && vq->handle_output) {
+     *   - hw/virtio/virtio.c|2486| <<virtio_queue_notify_vq>> vq->handle_output(vdev, vq);
+     *   - hw/virtio/virtio.c|2513| <<virtio_queue_notify>> } else if (vq->handle_output) {
+     *   - hw/virtio/virtio.c|2514| <<virtio_queue_notify>> vq->handle_output(vdev, vq);
+     *   - hw/virtio/virtio.c|2561| <<virtio_add_queue>> vdev->vq[i].handle_output = handle_output;
+     *   - hw/virtio/virtio.c|2571| <<virtio_delete_queue>> vq->handle_output = NULL;
+     */
     VirtIOHandleOutput handle_output;
     VirtIODevice *vdev;
+    /*
+     * 在以使用VirtQueue->guest_notifier:
+     *   - hw/virtio/virtio.c|2707| <<virtio_notify_irqfd>> event_notifier_set(&vq->guest_notifier);
+     *   - hw/virtio/virtio.c|3697| <<virtio_queue_guest_notifier_read>> VirtQueue *vq = container_of(n, VirtQueue, guest_notifier);
+     *   - hw/virtio/virtio.c|3707| <<virtio_queue_set_guest_notifier_fd_handler>> event_notifier_set_handler(&vq->guest_notifier,
+     *   - hw/virtio/virtio.c|3710| <<virtio_queue_set_guest_notifier_fd_handler>> event_notifier_set_handler(&vq->guest_notifier, NULL);
+     *   - hw/virtio/virtio.c|3715| <<virtio_queue_set_guest_notifier_fd_handler>> virtio_queue_guest_notifier_read(&vq->guest_notifier);
+     *   - hw/virtio/virtio.c|3721| <<virtio_queue_get_guest_notifier>> return &vq->guest_notifier;
+     */
     EventNotifier guest_notifier;
+    /*
+     * 在以下使用VirtQueue->host_notifier:
+     *   - hw/virtio/virtio.c|2512| <<virtio_queue_notify>> event_notifier_set(&vq->host_notifier);
+     *   - hw/virtio/virtio.c|3726| <<virtio_queue_host_notifier_aio_poll_begin>> VirtQueue *vq = container_of(n, VirtQueue, host_notifier);
+     *   - hw/virtio/virtio.c|3734| <<virtio_queue_host_notifier_aio_poll>> VirtQueue *vq = container_of(n, VirtQueue, host_notifier);
+     *   - hw/virtio/virtio.c|3741| <<virtio_queue_host_notifier_aio_poll_ready>> VirtQueue *vq = container_of(n, VirtQueue, host_notifier);
+     *   - hw/virtio/virtio.c|3748| <<virtio_queue_host_notifier_aio_poll_end>> VirtQueue *vq = container_of(n, VirtQueue, host_notifier);
+     *   - hw/virtio/virtio.c|3756| <<virtio_queue_aio_attach_host_notifier>> aio_set_event_notifier(ctx, &vq->host_notifier, true,
+     *   - hw/virtio/virtio.c|3760| <<virtio_queue_aio_attach_host_notifier>> aio_set_event_notifier_poll(ctx, &vq->host_notifier,
+     *   - hw/virtio/virtio.c|3773| <<virtio_queue_aio_attach_host_notifier_no_poll>> aio_set_event_notifier(ctx, &vq->host_notifier, true,
+     *   - hw/virtio/virtio.c|3787| <<virtio_queue_aio_detach_host_notifier>> aio_set_event_notifier(ctx, &vq->host_notifier, true, NULL, NULL, NULL);
+     *   - hw/virtio/virtio.c|3790| <<virtio_queue_aio_detach_host_notifier>> virtio_queue_host_notifier_read(&vq->host_notifier);
+     *   - hw/virtio/virtio.c|3803| <<virtio_queue_host_notifier_read>> VirtQueue *vq = container_of(n, VirtQueue, host_notifier);
+     *   - hw/virtio/virtio.c|3811| <<virtio_queue_get_host_notifier>> return &vq->host_notifier;
+     *   - hw/virtio/virtio.c|3967| <<virtio_device_start_ioeventfd_impl>> event_notifier_set_handler(&vq->host_notifier,
+     *   - hw/virtio/virtio.c|3977| <<virtio_device_start_ioeventfd_impl>> event_notifier_set(&vq->host_notifier);
+     *   - hw/virtio/virtio.c|3990| <<virtio_device_start_ioeventfd_impl>> event_notifier_set_handler(&vq->host_notifier, NULL);
+     *   - hw/virtio/virtio.c|4033| <<virtio_device_stop_ioeventfd_impl>> event_notifier_set_handler(&vq->host_notifier, NULL);
+     */
     EventNotifier host_notifier;
     bool host_notifier_enabled;
     QLIST_ENTRY(VirtQueue) node;
@@ -488,6 +549,10 @@ static void virtio_queue_split_set_notification(VirtQueue *vq, int enable)
     }
 }
 
+/*
+ * called by:
+ *   - hw/virtio/virtio.c|562| <<virtio_queue_set_notification>> virtio_queue_packed_set_notification(vq, enable);
+ */
 static void virtio_queue_packed_set_notification(VirtQueue *vq, int enable)
 {
     uint16_t off_wrap;
@@ -502,6 +567,10 @@ static void virtio_queue_packed_set_notification(VirtQueue *vq, int enable)
 
     vring_packed_event_read(vq->vdev, &caches->used, &e);
 
+    /*
+     * disable: 设置VRING_PACKED_EVENT_FLAG_DISABLE
+     * enable:  设置VRING_PACKED_EVENT_FLAG_DESC或者VRING_PACKED_EVENT_FLAG_ENABLE
+     */
     if (!enable) {
         e.flags = VRING_PACKED_EVENT_FLAG_DISABLE;
     } else if (virtio_vdev_has_feature(vq->vdev, VIRTIO_RING_F_EVENT_IDX)) {
@@ -526,6 +595,35 @@ bool virtio_queue_get_notification(VirtQueue *vq)
     return vq->notification;
 }
 
+/*
+ * called by:
+ *   - hw/block/virtio-blk.c|782| <<virtio_blk_handle_vq>> virtio_queue_set_notification(vq, 0);
+ *   - hw/block/virtio-blk.c|794| <<virtio_blk_handle_vq>> virtio_queue_set_notification(vq, 1);
+ *   - hw/net/virtio-net.c|414| <<virtio_net_set_status>> virtio_queue_set_notification(q->tx_vq, 1);
+ *   - hw/net/virtio-net.c|1542| <<virtio_net_has_buffers>> virtio_queue_set_notification(q->rx_vq, 1);
+ *   - hw/net/virtio-net.c|1555| <<virtio_net_has_buffers>> virtio_queue_set_notification(q->rx_vq, 0);
+ *   - hw/net/virtio-net.c|2535| <<virtio_net_tx_complete>> virtio_queue_set_notification(q->tx_vq, 1);
+ *   - hw/net/virtio-net.c|2552| <<virtio_net_flush_tx>> virtio_queue_set_notification(q->tx_vq, 0);
+ *   - hw/net/virtio-net.c|2618| <<virtio_net_flush_tx>> virtio_queue_set_notification(q->tx_vq, 0);
+ *   - hw/net/virtio-net.c|2652| <<virtio_net_handle_tx_timer>> virtio_queue_set_notification(vq, 1);
+ *   - hw/net/virtio-net.c|2662| <<virtio_net_handle_tx_timer>> virtio_queue_set_notification(vq, 0);
+ *   - hw/net/virtio-net.c|2684| <<virtio_net_handle_tx_bh>> virtio_queue_set_notification(vq, 0);
+ *   - hw/net/virtio-net.c|2707| <<virtio_net_tx_timer>> virtio_queue_set_notification(q->tx_vq, 1);
+ *   - hw/net/virtio-net.c|2749| <<virtio_net_tx_bh>> virtio_queue_set_notification(q->tx_vq, 1);
+ *   - hw/net/virtio-net.c|2754| <<virtio_net_tx_bh>> virtio_queue_set_notification(q->tx_vq, 0);
+ *   - hw/scsi/virtio-scsi.c|735| <<virtio_scsi_handle_cmd_vq>> virtio_queue_set_notification(vq, 0);
+ *   - hw/scsi/virtio-scsi.c|756| <<virtio_scsi_handle_cmd_vq>> virtio_queue_set_notification(vq, 1);
+ *   - hw/virtio/vhost-shadow-virtqueue.c|293| <<vhost_handle_guest_kick>> virtio_queue_set_notification(svq->vq, false);
+ *   - hw/virtio/vhost-shadow-virtqueue.c|335| <<vhost_handle_guest_kick>> virtio_queue_set_notification(svq->vq, true);
+ *   - hw/virtio/virtio-balloon.c|563| <<virtio_ballloon_get_free_page_hints>> virtio_queue_set_notification(vq, 0);
+ *   - hw/virtio/virtio-balloon.c|573| <<virtio_ballloon_get_free_page_hints>> virtio_queue_set_notification(vq, 1);
+ *   - hw/virtio/virtio-crypto.c|912| <<virtio_crypto_dataq_bh>> virtio_queue_set_notification(q->dataq, 1);
+ *   - hw/virtio/virtio-crypto.c|919| <<virtio_crypto_dataq_bh>> virtio_queue_set_notification(q->dataq, 0);
+ *   - hw/virtio/virtio-crypto.c|934| <<virtio_crypto_handle_dataq_bh>> virtio_queue_set_notification(vq, 0);
+ *   - hw/virtio/virtio.c|1782| <<virtqueue_packed_drop_all>> virtio_queue_set_notification(vq, 0);
+ *   - hw/virtio/virtio.c|3578| <<virtio_queue_host_notifier_aio_poll_begin>> virtio_queue_set_notification(vq, 0);
+ *   - hw/virtio/virtio.c|3601| <<virtio_queue_host_notifier_aio_poll_end>> virtio_queue_set_notification(vq, 1);
+ */
 void virtio_queue_set_notification(VirtQueue *vq, int enable)
 {
     vq->notification = enable;
@@ -938,6 +1036,13 @@ static void virtqueue_packed_flush(VirtQueue *vq, unsigned int count)
     }
 }
 
+/*
+ * called by:
+ *   - hw/net/virtio-net.c|1924| <<virtio_net_receive_rcu>> virtqueue_flush(q->rx_vq, i);
+ *   - hw/virtio/vhost-shadow-virtqueue.c|473| <<vhost_svq_flush>> virtqueue_flush(vq, i);
+ *   - hw/virtio/vhost-shadow-virtqueue.c|479| <<vhost_svq_flush>> virtqueue_flush(vq, i);
+ *   - hw/virtio/virtio.c|1021| <<virtqueue_push>> virtqueue_flush(vq, 1);
+ */
 void virtqueue_flush(VirtQueue *vq, unsigned int count)
 {
     if (virtio_device_disabled(vq->vdev)) {
@@ -952,6 +1057,42 @@ void virtqueue_flush(VirtQueue *vq, unsigned int count)
     }
 }
 
+/*
+ * called by:
+ *   - hw/9pfs/virtio-9p-device.c|38| <<virtio_9p_push_and_notify>> virtqueue_push(v->vq, elem, pdu->size);
+ *   - hw/block/virtio-blk.c|86| <<virtio_blk_req_complete>> virtqueue_push(req->vq, &req->elem, req->in_len);
+ *   - hw/char/virtio-serial-bus.c|125| <<write_to_port>> virtqueue_push(vq, elem, len);
+ *   - hw/char/virtio-serial-bus.c|145| <<discard_vq_data>> virtqueue_push(vq, elem, 0);
+ *   - hw/char/virtio-serial-bus.c|207| <<do_flush_queued_data>> virtqueue_push(vq, port->elem, 0);
+ *   - hw/char/virtio-serial-bus.c|242| <<send_control_msg>> virtqueue_push(vq, elem, len);
+ *   - hw/char/virtio-serial-bus.c|491| <<control_out>> virtqueue_push(vq, elem, 0);
+ *   - hw/display/virtio-gpu.c|181| <<virtio_gpu_ctrl_response>> virtqueue_push(cmd->vq, &cmd->elem, s);
+ *   - hw/display/virtio-gpu.c|1131| <<virtio_gpu_handle_cursor>> virtqueue_push(vq, elem, 0);
+ *   - hw/input/virtio-input.c|65| <<virtio_input_send>> virtqueue_push(vinput->evt, elem, len);
+ *   - hw/input/virtio-input.c|97| <<virtio_input_handle_sts>> virtqueue_push(vinput->sts, elem, len);
+ *   - hw/net/virtio-net.c|1522| <<virtio_net_handle_ctrl>> virtqueue_push(vq, elem, written);
+ *   - hw/net/virtio-net.c|2558| <<virtio_net_tx_complete>> virtqueue_push(q->tx_vq, q->async_tx.elem, 0);
+ *   - hw/net/virtio-net.c|2653| <<virtio_net_flush_tx>> virtqueue_push(q->tx_vq, elem, 0);
+ *   - hw/scsi/virtio-scsi.c|112| <<virtio_scsi_complete_req>> virtqueue_push(vq, &req->elem, req->qsgl.size + req->resp_iov.size);
+ *   - hw/virtio/vhost-shadow-virtqueue.c|441| <<vhost_svq_push_elem>> virtqueue_push(svq->vq, elem, len);
+ *   - hw/virtio/vhost-vsock-common.c|165| <<vhost_vsock_common_send_transport_reset>> virtqueue_push(vq, elem, sizeof(event));
+ *   - hw/virtio/virtio-balloon.c|235| <<balloon_stats_poll_cb>> virtqueue_push(s->svq, s->stats_vq_elem, 0);
+ *   - hw/virtio/virtio-balloon.c|384| <<virtio_balloon_handle_report>> virtqueue_push(vq, elem, 0);
+ *   - hw/virtio/virtio-balloon.c|442| <<virtio_balloon_handle_output>> virtqueue_push(vq, elem, 0);
+ *   - hw/virtio/virtio-balloon.c|463| <<virtio_balloon_receive_stats>> virtqueue_push(vq, s->stats_vq_elem, 0);
+ *   - hw/virtio/virtio-balloon.c|549| <<get_free_page_hints>> virtqueue_push(vq, elem, 0);
+ *   - hw/virtio/virtio-crypto.c|366| <<virtio_crypto_handle_ctrl>> virtqueue_push(vq, elem, sizeof(input));
+ *   - hw/virtio/virtio-crypto.c|384| <<virtio_crypto_handle_ctrl>> virtqueue_push(vq, elem, sizeof(status));
+ *   - hw/virtio/virtio-crypto.c|399| <<virtio_crypto_handle_ctrl>> virtqueue_push(vq, elem, sizeof(input));
+ *   - hw/virtio/virtio-crypto.c|530| <<virtio_crypto_req_complete>> virtqueue_push(req->vq, &req->elem, req->in_len);
+ *   - hw/virtio/virtio-iommu.c|793| <<virtio_iommu_handle_command>> virtqueue_push(vq, elem, sz);
+ *   - hw/virtio/virtio-iommu.c|837| <<virtio_iommu_report_fault>> virtqueue_push(vq, elem, sz);
+ *   - hw/virtio/virtio-mem.c|414| <<virtio_mem_send_response>> virtqueue_push(vq, elem, sizeof(*resp));
+ *   - hw/virtio/virtio-pmem.c|61| <<done_cb>> virtqueue_push(req_data->pmem->rq_vq, &req_data->elem, len);
+ *   - hw/virtio/virtio-rng.c|81| <<chr_read>> virtqueue_push(vrng->vq, elem, len);
+ *   - hw/virtio/virtio.c|1842| <<virtqueue_packed_drop_all>> virtqueue_push(vq, &elem, 0);
+ *   - hw/virtio/virtio.c|1875| <<virtqueue_split_drop_all>> virtqueue_push(vq, &elem, 0);
+ */
 void virtqueue_push(VirtQueue *vq, const VirtQueueElement *elem,
                     unsigned int len)
 {
@@ -1585,6 +1726,10 @@ err_undo_map:
     goto done;
 }
 
+/*
+ * called by:
+ *   - hw/virtio/virtio.c|1745| <<virtqueue_pop>> return virtqueue_packed_pop(vq, sz);
+ */
 static void *virtqueue_packed_pop(VirtQueue *vq, size_t sz)
 {
     unsigned int i, max;
@@ -1937,6 +2082,14 @@ void qemu_put_virtqueue_element(VirtIODevice *vdev, QEMUFile *f,
 }
 
 /* virtio device */
+/*
+ * called by:
+ *   - hw/virtio/virtio.c|2064| <<virtio_update_irq>> virtio_notify_vector(vdev, VIRTIO_NO_VECTOR);
+ *   - hw/virtio/virtio.c|2158| <<virtio_reset>> virtio_notify_vector(vdev, vdev->config_vector);
+ *   - hw/virtio/virtio.c|2691| <<virtio_irq>> virtio_notify_vector(vq->vdev, vq->vector);
+ *   - hw/virtio/virtio.c|2713| <<virtio_notify_config>> virtio_notify_vector(vdev, vdev->config_vector);
+ *   - hw/virtio/virtio.c|3214| <<virtio_load>> virtio_notify_vector(vdev, VIRTIO_NO_VECTOR);
+ */
 static void virtio_notify_vector(VirtIODevice *vdev, uint16_t vector)
 {
     BusState *qbus = qdev_get_parent_bus(DEVICE(vdev));
@@ -2352,6 +2505,11 @@ void virtio_queue_set_align(VirtIODevice *vdev, int n, int align)
     }
 }
 
+/*
+ * called by:
+ *   - hw/virtio/virtio.c|3673| <<virtio_queue_host_notifier_aio_poll_ready>> virtio_queue_notify_vq(vq);
+ *   - hw/virtio/virtio.c|3727| <<virtio_queue_host_notifier_read>> virtio_queue_notify_vq(vq);
+ */
 static void virtio_queue_notify_vq(VirtQueue *vq)
 {
     if (vq->vring.desc && vq->handle_output) {
@@ -2362,6 +2520,15 @@ static void virtio_queue_notify_vq(VirtQueue *vq)
         }
 
         trace_virtio_queue_notify(vdev, vq - vdev->vq, vq);
+        /*
+	 * 在以下使用VirtQueue->handle_output:
+	 *   - hw/virtio/virtio.c|2478| <<virtio_queue_notify_vq>> if (vq->vring.desc && vq->handle_output) {
+	 *   - hw/virtio/virtio.c|2486| <<virtio_queue_notify_vq>> vq->handle_output(vdev, vq);
+	 *   - hw/virtio/virtio.c|2513| <<virtio_queue_notify>> } else if (vq->handle_output) {
+	 *   - hw/virtio/virtio.c|2514| <<virtio_queue_notify>> vq->handle_output(vdev, vq);
+	 *   - hw/virtio/virtio.c|2561| <<virtio_add_queue>> vdev->vq[i].handle_output = handle_output;
+	 *   - hw/virtio/virtio.c|2571| <<virtio_delete_queue>> vq->handle_output = NULL;
+	 */
         vq->handle_output(vdev, vq);
 
         if (unlikely(vdev->start_on_kick)) {
@@ -2370,6 +2537,14 @@ static void virtio_queue_notify_vq(VirtQueue *vq)
     }
 }
 
+/*
+ * called by:
+ *   - hw/s390x/s390-virtio-ccw.c|135| <<virtio_ccw_hcall_notify>> virtio_queue_notify(virtio_ccw_get_vdev(sch), queue);
+ *   - hw/virtio/virtio-mmio.c|410| <<virtio_mmio_write>> virtio_queue_notify(vdev, value);
+ *   - hw/virtio/virtio-pci.c|345| <<virtio_ioport_write>> virtio_queue_notify(vdev, val);
+ *   - hw/virtio/virtio-pci.c|1417| <<virtio_pci_notify_write>> virtio_queue_notify(vdev, queue);
+ *   - hw/virtio/virtio-pci.c|1431| <<virtio_pci_notify_write_pio>> virtio_queue_notify(vdev, queue);
+ */
 void virtio_queue_notify(VirtIODevice *vdev, int n)
 {
     VirtQueue *vq = &vdev->vq[n];
@@ -2382,6 +2557,15 @@ void virtio_queue_notify(VirtIODevice *vdev, int n)
     if (vq->host_notifier_enabled) {
         event_notifier_set(&vq->host_notifier);
     } else if (vq->handle_output) {
+        /*
+	 * 在以下使用VirtQueue->handle_output:
+	 *   - hw/virtio/virtio.c|2478| <<virtio_queue_notify_vq>> if (vq->vring.desc && vq->handle_output) {
+	 *   - hw/virtio/virtio.c|2486| <<virtio_queue_notify_vq>> vq->handle_output(vdev, vq);
+	 *   - hw/virtio/virtio.c|2513| <<virtio_queue_notify>> } else if (vq->handle_output) {
+	 *   - hw/virtio/virtio.c|2514| <<virtio_queue_notify>> vq->handle_output(vdev, vq);
+	 *   - hw/virtio/virtio.c|2561| <<virtio_add_queue>> vdev->vq[i].handle_output = handle_output;
+	 *   - hw/virtio/virtio.c|2571| <<virtio_delete_queue>> vq->handle_output = NULL;
+	 */
         vq->handle_output(vdev, vq);
 
         if (unlikely(vdev->start_on_kick)) {
@@ -2543,6 +2727,12 @@ static bool virtio_should_notify(VirtIODevice *vdev, VirtQueue *vq)
     }
 }
 
+/*
+ * called by:
+ *   - hw/block/dataplane/virtio-blk.c|178| <<virtio_blk_data_plane_notify>> virtio_notify_irqfd(s->vdev, vq);
+ *   - hw/block/dataplane/virtio-blk.c|199| <<notify_guest_bh>> virtio_notify_irqfd(s->vdev, vq);
+ *   - hw/scsi/virtio-scsi.c|114| <<virtio_scsi_complete_req>> virtio_notify_irqfd(vdev, vq);
+ */
 void virtio_notify_irqfd(VirtIODevice *vdev, VirtQueue *vq)
 {
     WITH_RCU_READ_LOCK_GUARD() {
@@ -2572,12 +2762,37 @@ void virtio_notify_irqfd(VirtIODevice *vdev, VirtQueue *vq)
     event_notifier_set(&vq->guest_notifier);
 }
 
+/*
+ * called by:
+ *   - hw/virtio/virtio.c|2703| <<virtio_notify>> virtio_irq(vq);
+ *   - hw/virtio/virtio.c|3634| <<virtio_queue_guest_notifier_read>> virtio_irq(vq);
+ */
 static void virtio_irq(VirtQueue *vq)
 {
     virtio_set_isr(vq->vdev, 0x1);
     virtio_notify_vector(vq->vdev, vq->vector);
 }
 
+/*
+ * 部分在以下使用virtio_notify():
+ *   - hw/9pfs/virtio-9p-device.c|43| <<virtio_9p_push_and_notify>> virtio_notify(VIRTIO_DEVICE(v), v->vq);
+ *   - hw/block/virtio-blk.c|90| <<virtio_blk_req_complete>> virtio_notify(vdev, req->vq);
+ *   - hw/char/virtio-serial-bus.c|129| <<write_to_port>> virtio_notify(VIRTIO_DEVICE(port->vser), vq);
+ *   - hw/char/virtio-serial-bus.c|148| <<discard_vq_data>> virtio_notify(vdev, vq);
+ *   - hw/char/virtio-serial-bus.c|211| <<do_flush_queued_data>> virtio_notify(vdev, vq);
+ *   - hw/char/virtio-serial-bus.c|243| <<send_control_msg>> virtio_notify(VIRTIO_DEVICE(vser), vq);
+ *   - hw/char/virtio-serial-bus.c|495| <<control_out>> virtio_notify(vdev, vq);
+ *   - hw/display/virtio-gpu.c|182| <<virtio_gpu_ctrl_response>> virtio_notify(VIRTIO_DEVICE(g), cmd->vq);
+ *   - hw/display/virtio-gpu.c|1132| <<virtio_gpu_handle_cursor>> virtio_notify(vdev, vq);
+ *   - hw/input/virtio-input.c|68| <<virtio_input_send>> virtio_notify(VIRTIO_DEVICE(vinput), vinput->evt);
+ *   - hw/input/virtio-input.c|100| <<virtio_input_handle_sts>> virtio_notify(vdev, vinput->sts);
+ *   - hw/net/virtio-net.c|360| <<virtio_net_drop_tx_queue_data>> virtio_notify(vdev, vq);
+ *   - hw/net/virtio-net.c|1523| <<virtio_net_handle_ctrl>> virtio_notify(vdev, vq);
+ *   - hw/net/virtio-net.c|1925| <<virtio_net_receive_rcu>> virtio_notify(vdev, q->rx_vq);
+ *   - hw/net/virtio-net.c|2559| <<virtio_net_tx_complete>> virtio_notify(vdev, q->tx_vq);
+ *   - hw/net/virtio-net.c|2654| <<virtio_net_flush_tx>> virtio_notify(vdev, q->tx_vq);
+ *   - hw/scsi/virtio-scsi.c|116| <<virtio_scsi_complete_req>> virtio_notify(vdev, vq);
+ */
 void virtio_notify(VirtIODevice *vdev, VirtQueue *vq)
 {
     WITH_RCU_READ_LOCK_GUARD() {
@@ -2590,6 +2805,24 @@ void virtio_notify(VirtIODevice *vdev, VirtQueue *vq)
     virtio_irq(vq);
 }
 
+/*
+ * called by:
+ *   - hw/block/vhost-user-blk.c|110| <<vhost_user_blk_handle_config_change>> virtio_notify_config(dev->vdev);
+ *   - hw/block/virtio-blk.c|1239| <<virtio_resize_cb>> virtio_notify_config(vdev);
+ *   - hw/char/virtio-serial-bus.c|1004| <<virtser_port_device_plug>> virtio_notify_config(VIRTIO_DEVICE(hotplug_dev));
+ *   - hw/display/virtio-gpu-base.c|69| <<virtio_gpu_notify_event>> virtio_notify_config(&g->parent_obj);
+ *   - hw/input/vhost-user-input.c|78| <<vhost_input_set_config>> virtio_notify_config(vdev);
+ *   - hw/input/virtio-input.c|183| <<virtio_input_set_config>> virtio_notify_config(vdev);
+ *   - hw/net/virtio-net.c|211| <<virtio_net_announce_notify>> virtio_notify_config(vdev);
+ *   - hw/net/virtio-net.c|433| <<virtio_net_set_link_status>> virtio_notify_config(vdev);
+ *   - hw/virtio/vhost-user-vsock.c|46| <<vuv_handle_config_change>> virtio_notify_config(dev->vdev);
+ *   - hw/virtio/virtio-balloon.c|599| <<virtio_balloon_free_page_start>> virtio_notify_config(vdev);
+ *   - hw/virtio/virtio-balloon.c|619| <<virtio_balloon_free_page_stop>> virtio_notify_config(vdev);
+ *   - hw/virtio/virtio-balloon.c|632| <<virtio_balloon_free_page_done>> virtio_notify_config(vdev);
+ *   - hw/virtio/virtio-balloon.c|824| <<virtio_balloon_to_target>> virtio_notify_config(vdev);
+ *   - hw/virtio/virtio-mem.c|1131| <<virtio_mem_set_requested_size>> virtio_notify_config(VIRTIO_DEVICE(vmem));
+ *   - hw/virtio/virtio.c|3775| <<virtio_error>> virtio_notify_config(vdev);
+ */
 void virtio_notify_config(VirtIODevice *vdev)
 {
     if (!(vdev->status & VIRTIO_CONFIG_S_DRIVER_OK))
@@ -3597,6 +3830,13 @@ void virtio_queue_aio_attach_host_notifier_no_poll(VirtQueue *vq, AioContext *ct
                            NULL, NULL);
 }
 
+/*
+ * called by:
+ *   - hw/block/dataplane/virtio-blk.c|298| <<virtio_blk_data_plane_stop_bh>> virtio_queue_aio_detach_host_notifier(vq, s->ctx);
+ *   - hw/scsi/virtio-scsi-dataplane.c|76| <<virtio_scsi_dataplane_stop_bh>> virtio_queue_aio_detach_host_notifier(vs->ctrl_vq, s->ctx);
+ *   - hw/scsi/virtio-scsi-dataplane.c|77| <<virtio_scsi_dataplane_stop_bh>> virtio_queue_aio_detach_host_notifier(vs->event_vq, s->ctx);
+ *   - hw/scsi/virtio-scsi-dataplane.c|79| <<virtio_scsi_dataplane_stop_bh>> virtio_queue_aio_detach_host_notifier(vs->cmd_vqs[i], s->ctx);
+ */
 void virtio_queue_aio_detach_host_notifier(VirtQueue *vq, AioContext *ctx)
 {
     aio_set_event_notifier(ctx, &vq->host_notifier, true, NULL, NULL, NULL);
@@ -3605,6 +3845,14 @@ void virtio_queue_aio_detach_host_notifier(VirtQueue *vq, AioContext *ctx)
     virtio_queue_host_notifier_read(&vq->host_notifier);
 }
 
+/*
+ * 在以下使用virtio_queue_host_notifier_read():
+ *   - hw/virtio/virtio-bus.c|403| <<virtio_bus_cleanup_host_notifier>> virtio_queue_host_notifier_read(notifier);
+ *   - hw/virtio/virtio.c|3749| <<virtio_queue_aio_attach_host_notifier>> virtio_queue_host_notifier_read,
+ *   - hw/virtio/virtio.c|3766| <<virtio_queue_aio_attach_host_notifier_no_poll>> virtio_queue_host_notifier_read,
+ *   - hw/virtio/virtio.c|3782| <<virtio_queue_aio_detach_host_notifier>> virtio_queue_host_notifier_read(&vq->host_notifier);
+ *   - hw/virtio/virtio.c|3952| <<virtio_device_start_ioeventfd_impl>> virtio_queue_host_notifier_read);
+ */
 void virtio_queue_host_notifier_read(EventNotifier *n)
 {
     VirtQueue *vq = container_of(n, VirtQueue, host_notifier);
diff --git a/include/block/block_int-common.h b/include/block/block_int-common.h
index 8947abab7..3bedd89a8 100644
--- a/include/block/block_int-common.h
+++ b/include/block/block_int-common.h
@@ -942,6 +942,10 @@ struct BdrvChildClass {
 
 extern const BdrvChildClass child_of_bds;
 
+/*
+ * 感觉BdrvChild->next挂的是file的
+ * BdrvChild->bs->children是overlay下面的原始的BdrvChild
+ */
 struct BdrvChild {
     BlockDriverState *bs;
     char *name;
@@ -1103,6 +1107,10 @@ struct BlockDriverState {
      * parent node of this node.
      */
     BlockDriverState *inherits_from;
+    /*
+     * 如果是snapshop, parents是自己, 是生成的snapshot, overlay的最上一次
+     * children是base
+     */
     QLIST_HEAD(, BdrvChild) children;
     QLIST_HEAD(, BdrvChild) parents;
 
diff --git a/include/exec/memory.h b/include/exec/memory.h
index bfb1de8ee..d652a7d75 100644
--- a/include/exec/memory.h
+++ b/include/exec/memory.h
@@ -758,6 +758,25 @@ struct MemoryRegion {
     QTAILQ_ENTRY(MemoryRegion) subregions_link;
     QTAILQ_HEAD(, CoalescedMemoryRange) coalesced;
     const char *name;
+    /*
+     * 在以下使用MemoryRegion->ioeventfd_nb:
+     *   - softmmu/memory.c|899| <<address_space_update_ioeventfds>> for (i = 0; i < fr->mr->ioeventfd_nb; ++i) {
+     *   - softmmu/memory.c|1545| <<memory_region_dispatch_write_eventfds>> for (i = 0; i < mr->ioeventfd_nb; i++) {
+     *   - softmmu/memory.c|2565| <<memory_region_add_eventfd>> for (i = 0; i < mr->ioeventfd_nb; ++i) {
+     *   - softmmu/memory.c|2570| <<memory_region_add_eventfd>> ++mr->ioeventfd_nb;
+     *   - softmmu/memory.c|2575| <<memory_region_add_eventfd>> sizeof(*mr->ioeventfds) * mr->ioeventfd_nb);
+     *   - softmmu/memory.c|2581| <<memory_region_add_eventfd>> sizeof(*mr->ioeventfds) * (mr->ioeventfd_nb-1 - i));
+     *   - softmmu/memory.c|2628| <<memory_region_del_eventfd>> for (i = 0; i < mr->ioeventfd_nb; ++i) {
+     *   - softmmu/memory.c|2633| <<memory_region_del_eventfd>> assert(i != mr->ioeventfd_nb);
+     *   - softmmu/memory.c|2635| <<memory_region_del_eventfd>> sizeof(*mr->ioeventfds) * (mr->ioeventfd_nb - (i+1)));
+     *   - softmmu/memory.c|2636| <<memory_region_del_eventfd>> --mr->ioeventfd_nb;
+     *   - softmmu/memory.c|2638| <<memory_region_del_eventfd>> sizeof(*mr->ioeventfds)*mr->ioeventfd_nb + 1);
+     * 在以下使用struct AddressSpace->ioeventfd_nb:
+     *   - softmmu/memory.c|878| <<address_space_update_ioeventfds>> ioeventfd_max = QEMU_ALIGN_UP(as->ioeventfd_nb, 4);
+     *   - softmmu/memory.c|921| <<address_space_update_ioeventfds>> as->ioeventfds, as->ioeventfd_nb);
+     *   - softmmu/memory.c|925| <<address_space_update_ioeventfds>> as->ioeventfd_nb = ioeventfd_nb;
+     *   - softmmu/memory.c|3126| <<address_space_init>> as->ioeventfd_nb = 0;
+     */
     unsigned ioeventfd_nb;
     MemoryRegionIoeventfd *ioeventfds;
     RamDiscardManager *rdm; /* Only for RAM */
@@ -1041,8 +1060,35 @@ struct AddressSpace {
     MemoryRegion *root;
 
     /* Accessed via RCU.  */
+    /*
+     * 在以下使用AddressSpace->current_map:
+     *   - include/exec/memory.h|1108| <<address_space_to_flatview>> return qatomic_rcu_read(&as->current_map);
+     *   - softmmu/memory.c|1144| <<address_space_set_flatview>> qatomic_rcu_set(&as->current_map, new_view);
+     *   - softmmu/memory.c|3144| <<address_space_init>> as->current_map = NULL;
+     *   - softmmu/memory.c|3158| <<do_address_space_destroy>> flatview_unref(as->current_map);
+     *   - tests/qtest/fuzz/generic_fuzz.c|294| <<get_io_address>> view = as->current_map;
+     */
     struct FlatView *current_map;
 
+    /*
+     * 在以下使用MemoryRegion->ioeventfd_nb:
+     *   - softmmu/memory.c|899| <<address_space_update_ioeventfds>> for (i = 0; i < fr->mr->ioeventfd_nb; ++i) {
+     *   - softmmu/memory.c|1545| <<memory_region_dispatch_write_eventfds>> for (i = 0; i < mr->ioeventfd_nb; i++) {
+     *   - softmmu/memory.c|2565| <<memory_region_add_eventfd>> for (i = 0; i < mr->ioeventfd_nb; ++i) {
+     *   - softmmu/memory.c|2570| <<memory_region_add_eventfd>> ++mr->ioeventfd_nb;
+     *   - softmmu/memory.c|2575| <<memory_region_add_eventfd>> sizeof(*mr->ioeventfds) * mr->ioeventfd_nb);
+     *   - softmmu/memory.c|2581| <<memory_region_add_eventfd>> sizeof(*mr->ioeventfds) * (mr->ioeventfd_nb-1 - i));
+     *   - softmmu/memory.c|2628| <<memory_region_del_eventfd>> for (i = 0; i < mr->ioeventfd_nb; ++i) {
+     *   - softmmu/memory.c|2633| <<memory_region_del_eventfd>> assert(i != mr->ioeventfd_nb);
+     *   - softmmu/memory.c|2635| <<memory_region_del_eventfd>> sizeof(*mr->ioeventfds) * (mr->ioeventfd_nb - (i+1)));
+     *   - softmmu/memory.c|2636| <<memory_region_del_eventfd>> --mr->ioeventfd_nb;
+     *   - softmmu/memory.c|2638| <<memory_region_del_eventfd>> sizeof(*mr->ioeventfds)*mr->ioeventfd_nb + 1);
+     * 在以下使用struct AddressSpace->ioeventfd_nb:
+     *   - softmmu/memory.c|878| <<address_space_update_ioeventfds>> ioeventfd_max = QEMU_ALIGN_UP(as->ioeventfd_nb, 4);
+     *   - softmmu/memory.c|921| <<address_space_update_ioeventfds>> as->ioeventfds, as->ioeventfd_nb);
+     *   - softmmu/memory.c|925| <<address_space_update_ioeventfds>> as->ioeventfd_nb = ioeventfd_nb;
+     *   - softmmu/memory.c|3126| <<address_space_init>> as->ioeventfd_nb = 0;
+     */
     int ioeventfd_nb;
     struct MemoryRegionIoeventfd *ioeventfds;
     QTAILQ_HEAD(, MemoryListener) listeners;
diff --git a/include/hw/core/accel-cpu.h b/include/hw/core/accel-cpu.h
index 5dbfd7995..7df34726b 100644
--- a/include/hw/core/accel-cpu.h
+++ b/include/hw/core/accel-cpu.h
@@ -20,6 +20,16 @@
  * subclasses in target/, or the accel implementation itself in accel/
  */
 
+/*
+ * 在以下使用TYPE_ACCEL_CPU:
+ *   - include/hw/core/accel-cpu.h|23| <<global>> #define TYPE_ACCEL_CPU "accel-" CPU_RESOLVING_TYPE
+ *   - accel/accel-common.c|133| <<global>> .name = TYPE_ACCEL_CPU,
+ *   - target/i386/hvf/hvf-cpu.c|87| <<global>> .parent = TYPE_ACCEL_CPU,
+ *   - target/i386/kvm/kvm-cpu.c|199| <<global>> .parent = TYPE_ACCEL_CPU,
+ *   - target/i386/tcg/tcg-cpu.c|152| <<global>> .parent = TYPE_ACCEL_CPU,
+ *   - include/hw/core/accel-cpu.h|24| <<ACCEL_CPU_NAME>> #define ACCEL_CPU_NAME(name) (name "-" TYPE_ACCEL_CPU)
+ *   - include/hw/core/accel-cpu.h|26| <<DECLARE_CLASS_CHECKERS>> DECLARE_CLASS_CHECKERS(AccelCPUClass, ACCEL_CPU, TYPE_ACCEL_CPU)
+ */
 #define TYPE_ACCEL_CPU "accel-" CPU_RESOLVING_TYPE
 #define ACCEL_CPU_NAME(name) (name "-" TYPE_ACCEL_CPU)
 typedef struct AccelCPUClass AccelCPUClass;
diff --git a/include/hw/core/cpu.h b/include/hw/core/cpu.h
index 500503da1..b871a8eea 100644
--- a/include/hw/core/cpu.h
+++ b/include/hw/core/cpu.h
@@ -353,6 +353,17 @@ struct CPUState {
     QemuMutex work_mutex;
     QSIMPLEQ_HEAD(, qemu_work_item) work_list;
 
+    /*
+     * 在以下CPUState->cpu_ases:
+     *   - softmmu/physmem.c|683| <<address_space_translate_for_iotlb>> qatomic_rcu_read(&cpu->cpu_ases[asidx].memory_dispatch);
+     *   - softmmu/physmem.c|772| <<cpu_address_space_init>> if (!cpu->cpu_ases) {
+     *   - softmmu/physmem.c|773| <<cpu_address_space_init>> cpu->cpu_ases = g_new0(CPUAddressSpace, cpu->num_ases);
+     *   - softmmu/physmem.c|776| <<cpu_address_space_init>> newas = &cpu->cpu_ases[asidx];
+     *   - softmmu/physmem.c|790| <<cpu_get_address_space>> return cpu->cpu_ases[asidx].as;
+     *   - softmmu/physmem.c|2596| <<iotlb_to_section>> CPUAddressSpace *cpuas = &cpu->cpu_ases[asidx];
+     *   - softmmu/physmem.c|3519| <<cpu_memory_rw_debug>> res = address_space_write_rom(cpu->cpu_ases[asidx].as, phys_addr,
+     *   - softmmu/physmem.c|3522| <<cpu_memory_rw_debug>> res = address_space_read(cpu->cpu_ases[asidx].as, phys_addr,
+     */
     CPUAddressSpace *cpu_ases;
     int num_ases;
     AddressSpace *as;
diff --git a/include/hw/loader.h b/include/hw/loader.h
index 70248e0da..6d7d6fc9e 100644
--- a/include/hw/loader.h
+++ b/include/hw/loader.h
@@ -324,6 +324,14 @@ void *rom_ptr(hwaddr addr, size_t size);
 void *rom_ptr_for_as(AddressSpace *as, hwaddr addr, size_t size);
 void hmp_info_roms(Monitor *mon, const QDict *qdict);
 
+/*
+ * called by:
+ *   - hw/i386/x86.c|1171| <<x86_bios_rom_init>> ret = rom_add_file_fixed(bios_name, (uint32_t)(-bios_size), -1);
+ *   - hw/ppc/sam460ex.c|127| <<sam460ex_load_uboot>> rom_add_file_fixed(UBOOT_FILENAME,
+ *   - hw/rx/rx-gdbsim.c|110| <<rx_gdbsim_init>> rom_add_file_fixed(machine->firmware, RX62N_CFLASH_BASE, 0);
+ *   - hw/sparc64/niagara.c|91| <<add_rom_or_fail>> if (!qtest_enabled() && rom_add_file_fixed(file, addr, -1)) {
+ *   - hw/sparc64/niagara.c|146| <<niagara_init>> rom_add_file_fixed(blk_bs(blk)->filename, NIAGARA_VDISK_BASE, -1);
+ */
 #define rom_add_file_fixed(_f, _a, _i)          \
     rom_add_file(_f, NULL, _a, _i, false, NULL, NULL)
 #define rom_add_blob_fixed(_f, _b, _l, _a)      \
diff --git a/include/hw/qdev-core.h b/include/hw/qdev-core.h
index 785dd5a56..c08d75578 100644
--- a/include/hw/qdev-core.h
+++ b/include/hw/qdev-core.h
@@ -180,6 +180,19 @@ struct DeviceState {
     char *id;
     char *canonical_path;
     bool realized;
+    /*
+     * 在以下设置DeviceState->pending_deleted_event:
+     *   - hw/acpi/pcihp.c|245| <<acpi_pcihp_eject_slot>> qdev->pending_deleted_event = false;
+     *   - hw/acpi/pcihp.c|538| <<acpi_pcihp_device_unplug_request_cb>> pdev->qdev.pending_deleted_event = true;
+     *   - hw/core/qdev.c|644| <<device_set_realized>> dev->pending_deleted_event = false;
+     *   - hw/core/qdev.c|681| <<device_set_realized>> dev->pending_deleted_event = true;
+     *   - hw/pci/pcie.c|510| <<pcie_unplug_device>> dev->qdev.pending_deleted_event = false;
+     *   - hw/pci/pcie.c|567| <<pcie_cap_slot_unplug_request_cb>> dev->pending_deleted_event = true;
+     * 在以下使用DeviceState->pending_deleted_event:
+     *   - hw/core/qdev.c|798| <<device_finalize>> if (dev->pending_deleted_event) {
+     *   - hw/net/virtio-net.c|3697| <<primary_unplug_pending>> return primary ? primary->pending_deleted_event : false;
+     *   - softmmu/qdev-monitor.c|947| <<qmp_device_del>> if (dev->pending_deleted_event &&
+     */
     bool pending_deleted_event;
     int64_t pending_deleted_expires_ms;
     QDict *opts;
diff --git a/include/hw/virtio/vhost-scsi-common.h b/include/hw/virtio/vhost-scsi-common.h
index 18f115527..e681c9406 100644
--- a/include/hw/virtio/vhost-scsi-common.h
+++ b/include/hw/virtio/vhost-scsi-common.h
@@ -28,6 +28,12 @@ struct VHostSCSICommon {
     Error *migration_blocker;
 
     struct vhost_dev dev;
+    /*
+     * 在以下使用VHostSCSICommon->feature_bits:
+     *   - hw/scsi/vhost-scsi-common.c|130| <<vhost_scsi_common_get_features>> return vhost_get_features(&vsc->dev, vsc->feature_bits, features);
+     *   - hw/scsi/vhost-scsi.c|325| <<vhost_scsi_instance_init>> vsc->feature_bits = kernel_feature_bits;
+     *   - hw/scsi/vhost-user-scsi.c|215| <<vhost_user_scsi_instance_init>> vsc->feature_bits = user_feature_bits;
+     */
     const int *feature_bits;
     int32_t bootindex;
     int channel;
diff --git a/include/hw/virtio/virtio-bus.h b/include/hw/virtio/virtio-bus.h
index 7ab8c9dab..8181d3b8a 100644
--- a/include/hw/virtio/virtio-bus.h
+++ b/include/hw/virtio/virtio-bus.h
@@ -29,6 +29,15 @@
 #include "hw/virtio/virtio.h"
 #include "qom/object.h"
 
+/*
+ * 在以下使用TYPE_VIRTIO_BUS:
+ *   - hw/s390x/virtio-ccw.c|1290| <<global>> .parent = TYPE_VIRTIO_BUS,
+ *   - hw/virtio/virtio-bus.c|430| <<global>> .name = TYPE_VIRTIO_BUS,
+ *   - hw/virtio/virtio-mmio.c|851| <<global>> .parent = TYPE_VIRTIO_BUS,
+ *   - hw/virtio/virtio-pci.c|2264| <<global>> .parent = TYPE_VIRTIO_BUS,
+ *   - hw/virtio/virtio.c|3954| <<virtio_device_class_init>> dc->bus_type = TYPE_VIRTIO_BUS;
+ *   - include/hw/virtio/virtio-bus.h|36| <<DECLARE_OBJ_CHECKERS>> DECLARE_OBJ_CHECKERS(VirtioBusState, VirtioBusClass, VIRTIO_BUS, TYPE_VIRTIO_BUS)
+ */
 #define TYPE_VIRTIO_BUS "virtio-bus"
 typedef struct VirtioBusClass VirtioBusClass;
 typedef struct VirtioBusState VirtioBusState;
@@ -49,6 +58,12 @@ struct VirtioBusClass {
     int (*load_extra_state)(DeviceState *d, QEMUFile *f);
     bool (*has_extra_state)(DeviceState *d);
     bool (*query_guest_notifiers)(DeviceState *d);
+    /*
+     * 在以下设置VirtioBusClass->set_guest_notifiers:
+     *   - hw/s390x/virtio-ccw.c|1276| <<virtio_ccw_bus_class_init>> k->set_guest_notifiers = virtio_ccw_set_guest_notifiers;
+     *   - hw/virtio/virtio-mmio.c|839| <<virtio_mmio_bus_class_init>> k->set_guest_notifiers = virtio_mmio_set_guest_notifiers;
+     *   - hw/virtio/virtio-pci.c|2240| <<virtio_pci_bus_class_init>> k->set_guest_notifiers = virtio_pci_set_guest_notifiers;
+     */
     int (*set_guest_notifiers)(DeviceState *d, int nvqs, bool assign);
     int (*set_host_notifier_mr)(DeviceState *d, int n,
                                 MemoryRegion *mr, bool assign);
@@ -80,6 +95,21 @@ struct VirtioBusClass {
      * the device for queue number n. Returns an error value on
      * failure.
      */
+    /*
+     * 在以下设置VirtioBusClass->ioeventfd_assign:
+     *   - hw/s390x/virtio-ccw.c|1285| <<virtio_ccw_bus_class_init>> k->ioeventfd_assign = virtio_ccw_ioeventfd_assign;
+     *   - hw/virtio/virtio-mmio.c|841| <<virtio_mmio_bus_class_init>> k->ioeventfd_assign = virtio_mmio_ioeventfd_assign;
+     *   - hw/virtio/virtio-pci.c|2229| <<virtio_pci_bus_class_init>> k->ioeventfd_assign = virtio_pci_ioeventfd_assign;
+     * 在以下使用VirtioBusClass->ioeventfd_assign:
+     *   - hw/block/dataplane/virtio-blk.c|95| <<virtio_blk_data_plane_create>> if (!k->set_guest_notifiers || !k->ioeventfd_assign) {
+     *   - hw/scsi/virtio-scsi-dataplane.c|39| <<virtio_scsi_dataplane_setup>> if (!k->set_guest_notifiers || !k->ioeventfd_assign) {
+     *   - hw/virtio/virtio-bus.c|194| <<virtio_bus_grab_ioeventfd>> if (!k->ioeventfd_assign) {
+     *   - hw/virtio/virtio-bus.c|227| <<virtio_bus_start_ioeventfd>> if (!k->ioeventfd_assign || !k->ioeventfd_enabled(proxy)) {
+     *   - hw/virtio/virtio-bus.c|269| <<virtio_bus_ioeventfd_enabled>> return k->ioeventfd_assign && k->ioeventfd_enabled(proxy);
+     *   - hw/virtio/virtio-bus.c|301| <<virtio_bus_set_host_notifier>> if (!k->ioeventfd_assign) {
+     *   - hw/virtio/virtio-bus.c|312| <<virtio_bus_set_host_notifier>> r = k->ioeventfd_assign(proxy, notifier, n, true);
+     *   - hw/virtio/virtio-bus.c|318| <<virtio_bus_set_host_notifier>> k->ioeventfd_assign(proxy, notifier, n, false);
+     */
     int (*ioeventfd_assign)(DeviceState *d, EventNotifier *notifier,
                             int n, bool assign);
     /*
diff --git a/include/hw/virtio/virtio-pci.h b/include/hw/virtio/virtio-pci.h
index 2446dcd9a..34986d835 100644
--- a/include/hw/virtio/virtio-pci.h
+++ b/include/hw/virtio/virtio-pci.h
@@ -143,6 +143,15 @@ struct VirtIOPCIProxy {
     uint32_t modern_mem_bar_idx;
     int config_cap;
     uint32_t flags;
+    /*
+     * 在以下使用VirtIOPCIProxy->disable_modern:
+     *   - hw/virtio/virtio-pci.c|2078| <<global>> DEFINE_PROP_BOOL("disable-modern", VirtIOPCIProxy, disable_modern, false),
+     *   - hw/virtio/virtio-pci.c|2102| <<virtio_pci_transitional_instance_init>> proxy->disable_modern = false;
+     *   - hw/virtio/virtio-pci.c|2110| <<virtio_pci_non_transitional_instance_init>> proxy->disable_modern = false;
+     *   - include/hw/virtio/virtio-pci.h|163| <<virtio_pci_modern>> return !proxy->disable_modern;
+     *   - include/hw/virtio/virtio-pci.h|173| <<virtio_pci_force_virtio_1>> proxy->disable_modern = false;
+     *   - include/hw/virtio/virtio-pci.h|179| <<virtio_pci_disable_modern>> proxy->disable_modern = true;
+     */
     bool disable_modern;
     bool ignore_backend_features;
     OnOffAuto disable_legacy;
@@ -158,8 +167,28 @@ struct VirtIOPCIProxy {
     VirtioBusState bus;
 };
 
+/*
+ * called by:
+ *   - hw/virtio/virtio-pci.c|112| <<virtio_pci_modern_state_needed>> return virtio_pci_modern(proxy);
+ *   - hw/virtio/virtio-pci.c|253| <<virtio_pci_ioeventfd_assign>> bool modern = virtio_pci_modern(proxy);
+ *   - hw/virtio/virtio-pci.c|1094| <<virtio_pci_set_host_notifier_mr>> if (n >= VIRTIO_QUEUE_MAX || !virtio_pci_modern(proxy) ||
+ *   - hw/virtio/virtio-pci.c|1644| <<virtio_pci_pre_plugged>> if (virtio_pci_modern(proxy)) {
+ *   - hw/virtio/virtio-pci.c|1680| <<virtio_pci_device_plugged>> modern = virtio_pci_modern(proxy);
+ *   - hw/virtio/virtio-pci.c|1809| <<virtio_pci_device_unplugged>> bool modern = virtio_pci_modern(proxy);
+ *   - hw/virtio/virtio-pci.c|1885| <<virtio_pci_realize>> if (!virtio_pci_modern(proxy) && !virtio_pci_legacy(proxy)) {
+ *   - hw/virtio/virtio-pci.c|2042| <<virtio_pci_dc_realize>> virtio_pci_modern(proxy)) {
+ */
 static inline bool virtio_pci_modern(VirtIOPCIProxy *proxy)
 {
+    /*
+     * 在以下使用VirtIOPCIProxy->disable_modern:
+     *   - hw/virtio/virtio-pci.c|2078| <<global>> DEFINE_PROP_BOOL("disable-modern", VirtIOPCIProxy, disable_modern, false),
+     *   - hw/virtio/virtio-pci.c|2102| <<virtio_pci_transitional_instance_init>> proxy->disable_modern = false;
+     *   - hw/virtio/virtio-pci.c|2110| <<virtio_pci_non_transitional_instance_init>> proxy->disable_modern = false;
+     *   - include/hw/virtio/virtio-pci.h|163| <<virtio_pci_modern>> return !proxy->disable_modern;
+     *   - include/hw/virtio/virtio-pci.h|173| <<virtio_pci_force_virtio_1>> proxy->disable_modern = false;
+     *   - include/hw/virtio/virtio-pci.h|179| <<virtio_pci_disable_modern>> proxy->disable_modern = true;
+     */
     return !proxy->disable_modern;
 }
 
@@ -168,12 +197,27 @@ static inline bool virtio_pci_legacy(VirtIOPCIProxy *proxy)
     return proxy->disable_legacy == ON_OFF_AUTO_OFF;
 }
 
+/*
+ * called by:
+ *   - hw/display/virtio-vga.c|150| <<virtio_vga_base_realize>> virtio_pci_force_virtio_1(vpci_dev);
+ *   - hw/virtio/vhost-user-vsock-pci.c|45| <<vhost_user_vsock_pci_realize>> virtio_pci_force_virtio_1(vpci_dev);
+ *   - hw/virtio/vhost-vsock-pci.c|54| <<vhost_vsock_pci_realize>> virtio_pci_force_virtio_1(vpci_dev);
+ *   - hw/virtio/virtio-crypto-pci.c|57| <<virtio_crypto_pci_realize>> virtio_pci_force_virtio_1(vpci_dev);
+ *   - hw/virtio/virtio-input-pci.c|49| <<virtio_input_pci_realize>> virtio_pci_force_virtio_1(vpci_dev);
+ *   - hw/virtio/virtio-iommu-pci.c|65| <<virtio_iommu_pci_realize>> virtio_pci_force_virtio_1(vpci_dev);
+ *   - hw/virtio/virtio-mem-pci.c|25| <<virtio_mem_pci_realize>> virtio_pci_force_virtio_1(vpci_dev);
+ *   - hw/virtio/virtio-pmem-pci.c|25| <<virtio_pmem_pci_realize>> virtio_pci_force_virtio_1(vpci_dev);
+ */
 static inline void virtio_pci_force_virtio_1(VirtIOPCIProxy *proxy)
 {
     proxy->disable_modern = false;
     proxy->disable_legacy = ON_OFF_AUTO_ON;
 }
 
+/*
+ * called by:
+ *   - hw/virtio/virtio-pci.c|1669| <<virtio_pci_device_plugged>> virtio_pci_disable_modern(proxy);
+ */
 static inline void virtio_pci_disable_modern(VirtIOPCIProxy *proxy)
 {
     proxy->disable_modern = true;
diff --git a/include/hw/virtio/virtio-scsi.h b/include/hw/virtio/virtio-scsi.h
index a36aad9c8..5a0334c7f 100644
--- a/include/hw/virtio/virtio-scsi.h
+++ b/include/hw/virtio/virtio-scsi.h
@@ -85,9 +85,48 @@ struct VirtIOSCSI {
     /* Fields for dataplane below */
     AioContext *ctx; /* one iothread per virtio-scsi-pci for now */
 
+    /*
+     * 在以下设置VirtIOSCSI->dataplane_started:
+     *   - hw/scsi/virtio-scsi-dataplane.c|149| <<virtio_scsi_dataplane_start>> s->dataplane_started = true;
+     *   - hw/scsi/virtio-scsi-dataplane.c|179| <<virtio_scsi_dataplane_start>> s->dataplane_started = true;
+     *   - hw/scsi/virtio-scsi-dataplane.c|233| <<virtio_scsi_dataplane_stop>> s->dataplane_started = false;
+     *   - hw/scsi/virtio-scsi-dataplane.c|199| <<virtio_scsi_dataplane_stop>> s->dataplane_started = false;
+     * 在以下使用VirtIOSCSI->dataplane_started:
+     *   - hw/scsi/virtio-scsi-dataplane.c|98| <<virtio_scsi_dataplane_start>> if (s->dataplane_started ||
+     *   - hw/scsi/virtio-scsi-dataplane.c|192| <<virtio_scsi_dataplane_stop>> if (!s->dataplane_started || s->dataplane_stopping) {
+     *   - hw/scsi/virtio-scsi.c|113| <<virtio_scsi_complete_req>> if (s->dataplane_started && !s->dataplane_fenced) {
+     *   - hw/scsi/virtio-scsi.c|291| <<virtio_scsi_ctx_check>> if (s->dataplane_started && d && blk_is_available(d->conf.blk)) {
+     *   - hw/scsi/virtio-scsi.c|519| <<virtio_scsi_defer_to_dataplane>> if (!s->ctx || s->dataplane_started) {
+     *   - hw/scsi/virtio-scsi.c|831| <<virtio_scsi_reset>> assert(!s->dataplane_started);
+     */
     bool dataplane_started;
+    /*
+     * 在以下使用VirtIOSCSI->dataplane_starting:
+     *   - hw/scsi/virtio-scsi-dataplane.c|99| <<virtio_scsi_dataplane_start>> s->dataplane_starting ||
+     *   - hw/scsi/virtio-scsi-dataplane.c|104| <<virtio_scsi_dataplane_start>> s->dataplane_starting = true;
+     *   - hw/scsi/virtio-scsi-dataplane.c|148| <<virtio_scsi_dataplane_start>> s->dataplane_starting = false;
+     *   - hw/scsi/virtio-scsi-dataplane.c|178| <<virtio_scsi_dataplane_start>> s->dataplane_starting = false;
+     */
     bool dataplane_starting;
+    /*
+     * 在以下使用VirtIOSCSI->dataplane_stopping:
+     *   - hw/scsi/virtio-scsi-dataplane.c|192| <<virtio_scsi_dataplane_stop>> if (!s->dataplane_started || s->dataplane_stopping) {
+     *   - hw/scsi/virtio-scsi-dataplane.c|202| <<virtio_scsi_dataplane_stop>> s->dataplane_stopping = true;
+     *   - hw/scsi/virtio-scsi-dataplane.c|232| <<virtio_scsi_dataplane_stop>> s->dataplane_stopping = false;
+     */
     bool dataplane_stopping;
+    /*
+     * 在以下设置VirtIOSCSI->dataplane_fenced:
+     *   - hw/scsi/virtio-scsi-dataplane.c|62| <<virtio_scsi_set_host_notifier>> s->dataplane_fenced = true;
+     *   - hw/scsi/virtio-scsi-dataplane.c|177| <<virtio_scsi_dataplane_start>> s->dataplane_fenced = true;
+     *   - hw/scsi/virtio-scsi-dataplane.c|198| <<virtio_scsi_dataplane_stop>> s->dataplane_fenced = false;
+     * 在以下使用VirtIOSCSI->dataplane_fenced:
+     *   - hw/scsi/virtio-scsi-dataplane.c|100| <<virtio_scsi_dataplane_start>> s->dataplane_fenced) {
+     *   - hw/scsi/virtio-scsi-dataplane.c|197| <<virtio_scsi_dataplane_stop>> if (s->dataplane_fenced) {
+     *   - hw/scsi/virtio-scsi.c|113| <<virtio_scsi_complete_req>> if (s->dataplane_started && !s->dataplane_fenced) {
+     *   - hw/scsi/virtio-scsi.c|524| <<virtio_scsi_defer_to_dataplane>> return !s->dataplane_fenced;
+     *   - hw/scsi/virtio-scsi.c|940| <<virtio_scsi_hotplug>> if (s->ctx && !s->dataplane_fenced) {
+     */
     bool dataplane_fenced;
     uint32_t host_features;
 };
diff --git a/include/hw/virtio/virtio.h b/include/hw/virtio/virtio.h
index db1c0ddf6..f11953efb 100644
--- a/include/hw/virtio/virtio.h
+++ b/include/hw/virtio/virtio.h
@@ -86,6 +86,20 @@ struct VirtIODevice
     uint16_t queue_sel;
     uint64_t guest_features;
     uint64_t host_features;
+    /*
+     * 在以下使用VirtIODevice->backend_features:
+     *   - hw/block/vhost-user-blk.c|336| <<vhost_user_blk_connect>> s->dev.backend_features = 0;
+     *   - hw/net/vhost_net.c|130| <<vhost_net_ack_features>> net->dev.acked_features = net->dev.backend_features;
+     *   - hw/net/vhost_net.c|178| <<vhost_net_init>> net->dev.backend_features = qemu_has_vnet_hdr(options->net_backend)
+     *   - hw/net/vhost_net.c|183| <<vhost_net_init>> net->dev.backend_features = 0;
+     *   - hw/net/vhost_net.c|203| <<vhost_net_init>> if (~net->dev.features & net->dev.backend_features) {
+     *   - hw/net/vhost_net.c|206| <<vhost_net_init>> (uint64_t)(~net->dev.features & net->dev.backend_features));
+     *   - hw/net/virtio-net.c|750| <<virtio_net_get_features>> vdev->backend_features = features;
+     *   - hw/net/virtio-net.c|886| <<virtio_net_set_features>> !virtio_has_feature(vdev->backend_features, VIRTIO_NET_F_MTU)) {
+     *   - hw/scsi/vhost-scsi.c|220| <<vhost_scsi_realize>> vsc->dev.backend_features = 0;
+     *   - hw/scsi/vhost-user-scsi.c|121| <<vhost_user_scsi_realize>> vsc->dev.backend_features = 0;
+     *   - hw/virtio/vhost-user.c|2020| <<vhost_user_backend_init>> dev->backend_features |= 1ULL << VHOST_USER_F_PROTOCOL_FEATURES;
+     */
     uint64_t backend_features;
     size_t config_len;
     void *config;
@@ -134,6 +148,14 @@ struct VirtioDeviceClass {
      * that are only exposed on the legacy interface but not
      * the modern one.
      */
+    /*
+     * 在以下使用ViriioDevice->legacy_features:
+     *   - hw/net/virtio-net.c|3785| <<virtio_net_class_init>> vdc->legacy_features |= (0x1 << VIRTIO_NET_F_GSO);
+     *   - hw/s390x/virtio-ccw.c|389| <<virtio_ccw_cb>> (vdev->host_features & ~vdc->legacy_features);
+     *   - hw/virtio/virtio-mmio.c|170| <<virtio_mmio_read>> return (vdev->host_features & ~vdc->legacy_features)
+     *   - hw/virtio/virtio-pci.c|1211| <<virtio_pci_common_read>> val = (vdev->host_features & ~vdc->legacy_features) >>
+     *   - hw/virtio/virtio.c|3959| <<virtio_device_class_init>> vdc->legacy_features |= VIRTIO_LEGACY_FEATURES;
+     */
     uint64_t legacy_features;
     /* Test and clear event pending status.
      * Should be called after unmask to avoid losing events.
diff --git a/include/sysemu/accel-ops.h b/include/sysemu/accel-ops.h
index a0572ea87..66c1ec6a5 100644
--- a/include/sysemu/accel-ops.h
+++ b/include/sysemu/accel-ops.h
@@ -34,8 +34,28 @@ struct AccelOpsClass {
     void (*kick_vcpu_thread)(CPUState *cpu);
     bool (*cpu_thread_is_idle)(CPUState *cpu);
 
+    /*
+     * 在以下使用AcclOpsClass->synchronize_post_reset:
+     *   - accel/hvf/hvf-accel-ops.c|472| <<hvf_accel_ops_class_init>> ops->synchronize_post_reset = hvf_cpu_synchronize_post_reset;
+     *   - accel/kvm/kvm-accel-ops.c|94| <<kvm_accel_ops_class_init>> ops->synchronize_post_reset = kvm_cpu_synchronize_post_reset;
+     *   - softmmu/cpus.c|176| <<cpu_synchronize_post_reset>> if (cpus_accel->synchronize_post_reset) {
+     *   - softmmu/cpus.c|177| <<cpu_synchronize_post_reset>> cpus_accel->synchronize_post_reset(cpu);
+     *   - target/i386/hax/hax-accel-ops.c|84| <<hax_accel_ops_class_init>> ops->synchronize_post_reset = hax_cpu_synchronize_post_reset;
+     *   - target/i386/nvmm/nvmm-accel-ops.c|93| <<nvmm_accel_ops_class_init>> ops->synchronize_post_reset = nvmm_cpu_synchronize_post_reset;
+     *   - target/i386/whpx/whpx-accel-ops.c|99| <<whpx_accel_ops_class_init>> ops->synchronize_post_reset = whpx_cpu_synchronize_post_reset;
+     */
     void (*synchronize_post_reset)(CPUState *cpu);
     void (*synchronize_post_init)(CPUState *cpu);
+    /*
+     * 在以下使用AcclOpsClass->synchronize_state:
+     *   - accel/hvf/hvf-accel-ops.c|474| <<hvf_accel_ops_class_init>> ops->synchronize_state = hvf_cpu_synchronize_state;
+     *   - accel/kvm/kvm-accel-ops.c|96| <<kvm_accel_ops_class_init>> ops->synchronize_state = kvm_cpu_synchronize_state;
+     *   - softmmu/cpus.c|169| <<cpu_synchronize_state>> if (cpus_accel->synchronize_state) {
+     *   - softmmu/cpus.c|170| <<cpu_synchronize_state>> cpus_accel->synchronize_state(cpu);
+     *   - target/i386/hax/hax-accel-ops.c|86| <<hax_accel_ops_class_init>> ops->synchronize_state = hax_cpu_synchronize_state;
+     *   - target/i386/nvmm/nvmm-accel-ops.c|95| <<nvmm_accel_ops_class_init>> ops->synchronize_state = nvmm_cpu_synchronize_state;
+     *   - target/i386/whpx/whpx-accel-ops.c|101| <<whpx_accel_ops_class_init>> ops->synchronize_state = whpx_cpu_synchronize_state;
+     */
     void (*synchronize_state)(CPUState *cpu);
     void (*synchronize_pre_loadvm)(CPUState *cpu);
     void (*synchronize_pre_resume)(bool step_pending);
diff --git a/io/channel.c b/io/channel.c
index 0640941ac..325488edc 100644
--- a/io/channel.c
+++ b/io/channel.c
@@ -67,6 +67,33 @@ ssize_t qio_channel_readv_full(QIOChannel *ioc,
 }
 
 
+/*
+ * (gdb) bt
+ * #0  qio_channel_file_writev (ioc=0x555556a69b60, iov=0x7fffed89a3c0, niov=1, fds=0x0, nfds=0, flags=0, errp=0x0) at ../io/channel-file.c:120
+ * #1  0x0000555555d37451 in qio_channel_writev_full (ioc=0x555556a69b60, iov=0x7fffed89a3c0, niov=1, fds=0x0, nfds=0, flags=0, errp=0x0) at ../io/channel.c:100
+ * #2  0x0000555555e2987c in io_channel_send_full (ioc=0x555556a69b60, buf=0x5555579c9c1c, len=1, fds=0x0, nfds=0) at ../chardev/char-io.c:123
+ * #3  0x0000555555e29926 in io_channel_send (ioc=0x555556a69b60, buf=0x5555579c9c1c, len=1) at ../chardev/char-io.c:146
+ * #4  0x0000555555e33f78 in fd_chr_write (chr=0x555556a69a50, buf=0x5555579c9c1c " ", len=1) at ../chardev/char-fd.c:45
+ * #5  0x0000555555e31377 in qemu_chr_write_buffer (s=0x555556a69a50, buf=0x5555579c9c1c " ", len=1, offset=0x7fffed89a4d0, write_all=false) at ../chardev/char.c:121
+ * #6  0x0000555555e3151f in qemu_chr_write (s=0x555556a69a50, buf=0x5555579c9c1c " ", len=1, write_all=false) at ../chardev/char.c:173
+ * #7  0x0000555555e28747 in qemu_chr_fe_write (be=0x5555579c9c38, buf=0x5555579c9c1c " ", len=1) at ../chardev/char-fe.c:42
+ * #8  0x0000555555896e91 in serial_xmit (s=0x5555579c9b80) at ../hw/char/serial.c:259
+ * #9  0x00005555558972ed in serial_ioport_write (opaque=0x5555579c9b80, addr=0, val=32, size=1) at ../hw/char/serial.c:359
+ * #10 0x0000555555c650a3 in memory_region_write_accessor (mr=0x5555579c9cf0, addr=0, value=0x7fffed89a6a8, size=1, shift=0, mask=255, attrs=...) at ../softmmu/memory.c:492
+ * #11 0x0000555555c652e7 in access_with_adjusted_size (addr=0, value=0x7fffed89a6a8, size=1, access_size_min=1, access_size_max=1, access_fn=
+ *     0x555555c64fad <memory_region_write_accessor>, mr=0x5555579c9cf0, attrs=...) at ../softmmu/memory.c:554
+ * #12 0x0000555555c683dd in memory_region_dispatch_write (mr=0x5555579c9cf0, addr=0, data=32, op=MO_8, attrs=...) at ../softmmu/memory.c:1514
+ * #13 0x0000555555c758f6 in flatview_write_continue (fv=0x7ffe582f9c00, addr=1016, attrs=..., ptr=0x7ffff7ff3000, len=1, addr1=0, l=1, mr=0x5555579c9cf0) at ../softmmu/physmem.c:2825
+ * #14 0x0000555555c75a59 in flatview_write (fv=0x7ffe582f9c00, addr=1016, attrs=..., buf=0x7ffff7ff3000, len=1) at ../softmmu/physmem.c:2867
+ * #15 0x0000555555c75e09 in address_space_write (as=0x5555567b3420 <address_space_io>, addr=1016, attrs=..., buf=0x7ffff7ff3000, len=1) at ../softmmu/physmem.c:2963
+ * #16 0x0000555555c75e76 in address_space_rw (as=0x5555567b3420 <address_space_io>, addr=1016, attrs=..., buf=0x7ffff7ff3000, len=1, is_write=true) at ../softmmu/physmem.c:2973
+ * #17 0x0000555555d0db63 in kvm_handle_io (port=1016, attrs=..., data=0x7ffff7ff3000, direction=1, size=1, count=1) at ../accel/kvm/kvm-all.c:2693
+ * #18 0x0000555555d0e2dd in kvm_cpu_exec (cpu=0x555556ac7090) at ../accel/kvm/kvm-all.c:2944
+ * #19 0x0000555555d10faa in kvm_vcpu_thread_fn (arg=0x555556ac7090) at ../accel/kvm/kvm-accel-ops.c:49
+ * #20 0x0000555555eec4de in qemu_thread_start (args=0x555556ad66b0) at ../util/qemu-thread-posix.c:504
+ * #21 0x00007ffff55eeea5 in start_thread () at /lib64/libpthread.so.0
+ * #22 0x00007ffff53179fd in clone () at /lib64/libc.so.6
+ */
 ssize_t qio_channel_writev_full(QIOChannel *ioc,
                                 const struct iovec *iov,
                                 size_t niov,
diff --git a/iothread.c b/iothread.c
index 529194a56..253db1a3e 100644
--- a/iothread.c
+++ b/iothread.c
@@ -339,6 +339,10 @@ char *iothread_get_id(IOThread *iothread)
 
 AioContext *iothread_get_aio_context(IOThread *iothread)
 {
+    /*
+     * IOThread *iothread:
+     * -> AioContext *ctx;
+     */
     return iothread->ctx;
 }
 
diff --git a/job.c b/job.c
index 075c6f3a2..3549c584f 100644
--- a/job.c
+++ b/job.c
@@ -79,6 +79,11 @@ struct JobTxn {
  * job_enter. */
 static QemuMutex job_mutex;
 
+/*
+ * called by:
+ *   - job.c|453| <<job_enter_cond>> job_lock();
+ *   - job.c|484| <<job_do_yield>> job_lock();
+ */
 static void job_lock(void)
 {
     qemu_mutex_lock(&job_mutex);
@@ -176,6 +181,19 @@ bool job_is_internal(Job *job)
     return (job->id == NULL);
 }
 
+/*
+ * called by:
+ *   - job.c|357| <<job_create>> job_state_transition(job, JOB_STATUS_CREATED);
+ *   - job.c|514| <<job_pause_point>> job_state_transition(job, status == JOB_STATUS_READY
+ *   - job.c|520| <<job_pause_point>> job_state_transition(job, status);
+ *   - job.c|631| <<job_do_dismiss>> job_state_transition(job, JOB_STATUS_NULL);
+ *   - job.c|656| <<job_conclude>> job_state_transition(job, JOB_STATUS_CONCLUDED);
+ *   - job.c|671| <<job_update_rc>> job_state_transition(job, JOB_STATUS_ABORTING);
+ *   - job.c|873| <<job_transition_to_pending>> job_state_transition(job, JOB_STATUS_PENDING);
+ *   - job.c|882| <<job_transition_to_ready>> job_state_transition(job, JOB_STATUS_READY);
+ *   - job.c|891| <<job_completed_txn_success>> job_state_transition(job, JOB_STATUS_WAITING);
+ *   - job.c|993| <<job_start>> job_state_transition(job, JOB_STATUS_RUNNING);
+ */
 static void job_state_transition(Job *job, JobStatus s1)
 {
     JobStatus s0 = job->status;
@@ -309,6 +327,15 @@ static void job_sleep_timer_cb(void *opaque)
     job_enter(job);
 }
 
+/*
+ * called by:
+ *   - block/amend.c|127| <<qmp_x_blockdev_amend>> s = job_create(job_id, &blockdev_amend_job_driver, NULL,
+ *   - block/create.c|90| <<qmp_blockdev_create>> s = job_create(job_id, &blockdev_create_job_driver, NULL,
+ *   - blockjob.c|531| <<block_job_create>> job = job_create(job_id, &driver->job_driver, txn, bdrv_get_aio_context(bs),
+ *   - migration/savevm.c|3257| <<qmp_snapshot_save>> s = job_create(job_id, &snapshot_save_job_driver, NULL,
+ *   - migration/savevm.c|3279| <<qmp_snapshot_load>> s = job_create(job_id, &snapshot_load_job_driver, NULL,
+ *   - migration/savevm.c|3300| <<qmp_snapshot_delete>> s = job_create(job_id, &snapshot_delete_job_driver, NULL,
+ */
 void *job_create(const char *job_id, const JobDriver *driver, JobTxn *txn,
                  AioContext *ctx, int flags, BlockCompletionFunc *cb,
                  void *opaque, Error **errp)
@@ -364,6 +391,9 @@ void *job_create(const char *job_id, const JobDriver *driver, JobTxn *txn,
     /* Single jobs are modeled as single-job transactions for sake of
      * consolidating the job management logic */
     if (!txn) {
+        /*
+	 * 分配一个transaction
+	 */
         txn = job_txn_new();
         job_txn_add_job(txn, job);
         job_txn_unref(txn);
@@ -845,6 +875,11 @@ static int job_needs_finalize(Job *job)
     return !job->auto_finalize;
 }
 
+/*
+ * called by:
+ *   - job.c|898| <<job_finalize>> job_do_finalize(job);
+ *   - job.c|942| <<job_completed_txn_success>> job_do_finalize(job);
+ */
 static void job_do_finalize(Job *job)
 {
     int rc;
@@ -883,6 +918,10 @@ void job_transition_to_ready(Job *job)
     job_event_ready(job);
 }
 
+/*
+ * called by:
+ *   - job.c|921| <<job_completed>> job_completed_txn_success(job);
+ */
 static void job_completed_txn_success(Job *job)
 {
     JobTxn *txn = job->txn;
@@ -923,6 +962,10 @@ static void job_completed(Job *job)
 }
 
 /** Useful only as a type shim for aio_bh_schedule_oneshot. */
+/*
+ * 在以下使用job_exit():
+ *   - job.c|1002| <<job_co_entry>> aio_bh_schedule_oneshot(qemu_get_aio_context(), job_exit, job);
+ */
 static void job_exit(void *opaque)
 {
     Job *job = (Job *)opaque;
@@ -955,6 +998,10 @@ static void job_exit(void *opaque)
  * All jobs must allow a pause point before entering their job proper. This
  * ensures that jobs can be paused prior to being started, then resumed later.
  */
+/*
+ * 在以下使用job_co_entry():
+ *   - job.c|1023| <<job_start>> job->co = qemu_coroutine_create(job_co_entry, job);
+ */
 static void coroutine_fn job_co_entry(void *opaque)
 {
     Job *job = opaque;
@@ -968,6 +1015,20 @@ static void coroutine_fn job_co_entry(void *opaque)
     aio_bh_schedule_oneshot(qemu_get_aio_context(), job_exit, job);
 }
 
+/*
+ * called by:
+ *   - block/amend.c|144| <<qmp_x_blockdev_amend>> job_start(&s->common);
+ *   - block/commit.c|400| <<commit_start>> job_start(&s->common.job);
+ *   - block/create.c|100| <<qmp_blockdev_create>> job_start(&s->common);
+ *   - block/mirror.c|1852| <<mirror_start_job>> job_start(&s->common.job);
+ *   - block/replication.c|603| <<replication_start>> job_start(&s->backup_job->job);
+ *   - block/stream.c|370| <<stream_start>> job_start(&s->common.job);
+ *   - blockdev.c|1903| <<drive_backup_commit>> job_start(&state->job->job);
+ *   - blockdev.c|2004| <<blockdev_backup_commit>> job_start(&state->job->job);
+ *   - migration/savevm.c|3268| <<qmp_snapshot_save>> job_start(&s->common);
+ *   - migration/savevm.c|3290| <<qmp_snapshot_load>> job_start(&s->common);
+ *   - migration/savevm.c|3310| <<qmp_snapshot_delete>> job_start(&s->common);
+ */
 void job_start(Job *job)
 {
     assert(job && !job_started(job) && job->paused &&
@@ -1059,6 +1120,15 @@ int job_complete_sync(Job *job, Error **errp)
     return job_finish_sync(job, job_complete, errp);
 }
 
+/*
+ * called by:
+ *   - blockdev.c|3486| <<qmp_block_job_complete>> job_complete(&job->job, errp);
+ *   - job-qmp.c|103| <<qmp_job_complete>> job_complete(job, errp);
+ *   - job.c|1073| <<job_complete_sync>> return job_finish_sync(job, job_complete, errp);
+ *   - tests/unit/test-blockjob.c|336| <<test_cancel_pending>> job_complete(job, &error_abort);
+ *   - tests/unit/test-blockjob.c|362| <<test_cancel_concluded>> job_complete(job, &error_abort);
+ *   - tests/unit/test-blockjob.c|482| <<test_complete_in_standby>> job_complete(job, &error_abort);
+ */
 void job_complete(Job *job, Error **errp)
 {
     /* Should not be reachable via external interface for internal jobs */
@@ -1073,6 +1143,10 @@ void job_complete(Job *job, Error **errp)
         return;
     }
 
+    /*
+     * Job *job:
+     * -> const JobDriver *driver;
+     */
     job->driver->complete(job, errp);
 }
 
diff --git a/monitor/hmp.c b/monitor/hmp.c
index 15ca04735..ce000ecc0 100644
--- a/monitor/hmp.c
+++ b/monitor/hmp.c
@@ -274,6 +274,14 @@ static void help_cmd_dump(Monitor *mon, const HMPCommand *cmds,
     }
 }
 
+/*
+ * called by:
+ *   - monitor/misc.c|175| <<do_help_cmd>> help_cmd(mon, qdict_get_try_str(qdict, "name"));
+ *   - monitor/misc.c|217| <<hmp_trace_file>> help_cmd(mon, "trace-file");
+ *   - monitor/misc.c|224| <<hmp_info_help>> help_cmd(mon, "info");
+ *   - monitor/misc.c|440| <<hmp_log>> help_cmd(mon, "log");
+ *   - qemu-io-cmds.c|2498| <<init_qemuio_commands>> qemuio_add_command(&help_cmd);
+ */
 void help_cmd(Monitor *mon, const char *name)
 {
     char *args[MAX_ARGS];
@@ -1170,6 +1178,27 @@ void handle_hmp_command(MonitorHMP *mon, const char *cmdline)
     qobject_unref(qdict);
 }
 
+/*
+ * (gdb) bt
+ * #0  cmd_completion (mon=0x555556846620, name=0x5555574f6f60 "", list=0x55555609d9a2 "balloon") at ../monitor/hmp.c:1174
+ * #1  0x0000555555acd505 in monitor_find_completion_by_table (mon=0x555556846620, cmd_table=0x5555566f7740 <hmp_info_cmds>, args=0x7fffffffc9e8, nb_args=1) at ../monitor/hmp.c:1284
+ * #2  0x0000555555acd5a5 in monitor_find_completion_by_table (mon=0x555556846620, cmd_table=0x5555566f8aa0 <hmp_cmds>, args=0x7fffffffc9e0, nb_args=2) at ../monitor/hmp.c:1301
+ * #3  0x0000555555acd90d in monitor_find_completion (opaque=0x555556846620, cmdline=0x55555718d000 "info ") at ../monitor/hmp.c:1380
+ * #4  0x0000555555f1906b in readline_completion (rs=0x555556ac0f10) at ../util/readline.c:307
+ * #5  0x0000555555f19505 in readline_handle_byte (rs=0x555556ac0f10, ch=9) at ../util/readline.c:395
+ * #6  0x0000555555acd9a8 in monitor_read (opaque=0x555556846620, buf=0x7fffffffcbf0 "\t\322\377\377\377\177", size=1) at ../monitor/hmp.c:1393
+ * #7  0x0000555555e31613 in qemu_chr_be_write_impl (s=0x555556a66ab0, buf=0x7fffffffcbf0 "\t\322\377\377\377\177", len=1) at ../chardev/char.c:201
+ * #8  0x0000555555e31677 in qemu_chr_be_write (s=0x555556a66ab0, buf=0x7fffffffcbf0 "\t\322\377\377\377\177", len=1) at ../chardev/char.c:213
+ * #9  0x0000555555e340a4 in fd_chr_read (chan=0x555556a66bc0, cond=G_IO_IN, opaque=0x555556a66ab0) at ../chardev/char-fd.c:72
+ * #10 0x0000555555d335b4 in qio_channel_fd_source_dispatch (source=0x5555578075c0, callback=0x555555e33f7a <fd_chr_read>, user_data=0x555556a66ab0) at ../io/channel-watch.c:84
+ * #11 0x00007ffff6c40119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #12 0x0000555555f12010 in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #13 0x0000555555f1208a in os_host_main_loop_wait (timeout=1000000000) at ../util/main-loop.c:320
+ * #14 0x0000555555f1218f in main_loop_wait (nonblocking=0) at ../util/main-loop.c:596
+ * #15 0x0000555555a7a05e in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #16 0x000055555581fe62 in qemu_main (argc=20, argv=0x7fffffffded8, envp=0x0) at ../softmmu/main.c:38
+ * #17 0x000055555581fe94 in main (argc=20, argv=0x7fffffffded8) at ../softmmu/main.c:47
+ */
 static void cmd_completion(MonitorHMP *mon, const char *name, const char *list)
 {
     const char *p, *pstart;
@@ -1260,6 +1289,12 @@ static const char *next_arg_type(const char *typestr)
     return (p != NULL ? ++p : typestr);
 }
 
+/*
+ * called by:
+ *   - monitor/hmp.c|1330| <<monitor_find_completion_by_table>> monitor_find_completion_by_table(mon, cmd->sub_table,
+ *   - monitor/hmp.c|1374| <<monitor_find_completion_by_table>> monitor_find_completion_by_table(mon, cmd_table,
+ *   - monitor/hmp.c|1409| <<monitor_find_completion>> monitor_find_completion_by_table(mon, hmp_cmds, args, nb_args);
+ */
 static void monitor_find_completion_by_table(MonitorHMP *mon,
                                              const HMPCommand *cmd_table,
                                              char **args,
diff --git a/net/dump.c b/net/dump.c
index 6a63b1535..f7b45b63f 100644
--- a/net/dump.c
+++ b/net/dump.c
@@ -61,6 +61,10 @@ struct pcap_sf_pkthdr {
     uint32_t len;
 };
 
+/*
+ * called by:
+ *   - net/dump.c|157| <<filter_dump_receive_iov>> dump_receive_iov(&nfds->ds, iov, iovcnt);
+ */
 static ssize_t dump_receive_iov(DumpState *s, const struct iovec *iov, int cnt)
 {
     struct pcap_sf_pkthdr hdr;
@@ -148,6 +152,10 @@ struct NetFilterDumpState {
     uint32_t maxlen;
 };
 
+/*
+ * 在以下使用filter_dump_receive_iov():
+ *   - net/dump.c|246| <<filter_dump_class_init>> nfc->receive_iov = filter_dump_receive_iov;
+ */
 static ssize_t filter_dump_receive_iov(NetFilterState *nf, NetClientState *sndr,
                                        unsigned flags, const struct iovec *iov,
                                        int iovcnt, NetPacketSent *sent_cb)
diff --git a/qga/commands-posix.c b/qga/commands-posix.c
index 954efed01..c5ff4fd09 100644
--- a/qga/commands-posix.c
+++ b/qga/commands-posix.c
@@ -81,6 +81,34 @@ static void ga_wait_child(pid_t pid, int *status, Error **errp)
     g_assert(rpid == pid);
 }
 
+/*
+ * (gdb) bt
+ * #0  qmp_guest_shutdown (has_mode=false, mode=0x0, errp=errp@entry=0x7ffd6b9d2928) at ../qga/commands-posix.c:85
+ * #1  0x000055c142ed9765 in qmp_marshal_guest_shutdown (args=<optimized out>, ret=<optimized out>, errp=0x7ffd6b9d29a0)
+ *     at qga/qga-qapi-commands.c:270
+ * #2  0x000055c142eee853 in qmp_dispatch (cmds=cmds@entry=0x55c14312e9d0 <ga_commands>, request=request@entry=0x55c143c197f0,
+ *     allow_oob=allow_oob@entry=false, cur_mon=cur_mon@entry=0x0) at ../qapi/qmp-dispatch.c:211
+ * #3  0x000055c142ee32c0 in process_event (opaque=0x55c143c17080, obj=0x55c143c197f0, err=0x0) at ../qga/main.c:574
+ * #4  0x000055c142ef08eb in json_message_process_token (lexer=lexer@entry=0x55c143c17098, input=0x55c143c15780,
+ *     type=<optimized out>, x=28, y=0) at ../qobject/json-streamer.c:99
+ * #5  0x000055c142f04010 in json_lexer_feed_char (lexer=lexer@entry=0x55c143c17098, ch=125 '}', flush=flush@entry=false)
+ *     at ../qobject/json-lexer.c:313
+ * #6  0x000055c142f04191 in json_lexer_feed (lexer=lexer@entry=0x55c143c17098,
+ *     buffer=buffer@entry=0x7ffd6b9d2b30 "{\"execute\":\"guest-shutdown\"}\n", size=<optimized out>)
+ *     at ../qobject/json-lexer.c:350
+ * #7  0x000055c142ef0a2d in json_message_parser_feed (parser=parser@entry=0x55c143c17080,
+ *     buffer=buffer@entry=0x7ffd6b9d2b30 "{\"execute\":\"guest-shutdown\"}\n", size=<optimized out>)
+ *     at ../qobject/json-streamer.c:121
+ * #8  0x000055c142ee2c82 in channel_event_cb (condition=<optimized out>, data=0x55c143c17080) at ../qga/main.c:600
+ * #9  0x000055c142ee3b02 in ga_channel_client_event (channel=<optimized out>, condition=<optimized out>, data=0x55c143c174c0)
+ *     at ../qga/channel-posix.c:92
+ * #10 0x00007f10c385867d in g_main_context_dispatch () from /lib64/libglib-2.0.so.0
+ * #11 0x00007f10c3858a48 in g_main_context_iterate.isra () from /lib64/libglib-2.0.so.0
+ * #12 0x00007f10c3858d72 in g_main_loop_run () from /lib64/libglib-2.0.so.0
+ * #13 0x000055c142ed83ff in run_agent_once (s=0x55c143c17080) at ../qga/main.c:1391
+ * #14 run_agent (s=0x55c143c17080) at ../qga/main.c:1428
+ * #15 main (argc=<optimized out>, argv=<optimized out>) at ../qga/main.c:1541
+ */
 void qmp_guest_shutdown(bool has_mode, const char *mode, Error **errp)
 {
     const char *shutdown_flag;
diff --git a/qom/object.c b/qom/object.c
index d34608558..5d61273dc 100644
--- a/qom/object.c
+++ b/qom/object.c
@@ -854,6 +854,17 @@ bool object_set_propv(Object *obj,
 
 Object *object_dynamic_cast(Object *obj, const char *typename)
 {
+    /*
+     * 153 struct Object
+     * 154 {
+     * 155     // private:
+     * 156     ObjectClass *class;
+     * 157     ObjectFree *free;
+     * 158     GHashTable *properties;
+     * 159     uint32_t ref;
+     * 160     Object *parent;
+     * 161 };
+     */
     if (obj && object_class_dynamic_cast(object_get_class(obj), typename)) {
         return obj;
     }
@@ -1102,6 +1113,17 @@ static int do_object_child_foreach(Object *obj,
     ObjectProperty *prop;
     int ret = 0;
 
+    /*
+     * 153 struct Object
+     * 154 {
+     * 155     // private:
+     * 156     ObjectClass *class;
+     * 157     ObjectFree *free;
+     * 158     GHashTable *properties;
+     * 159     uint32_t ref;
+     * 160     Object *parent;
+     * 161 };
+     */
     g_hash_table_iter_init(&iter, obj->properties);
     while (g_hash_table_iter_next(&iter, NULL, (gpointer *)&prop)) {
         if (object_property_is_child(prop)) {
@@ -2125,6 +2147,13 @@ Object *object_resolve_path_type(const char *path, const char *typename,
     Object *obj;
     char **parts;
 
+    /*
+     * 按照"/"分割
+     *
+     * 从acpi_get_pm_info()进来 ...
+     * (gdb) p parts[0]
+     * $3 = 0x0
+     */
     parts = g_strsplit(path, "/", 0);
     assert(parts);
 
diff --git a/softmmu/cpus.c b/softmmu/cpus.c
index 23b30484b..2b0bcae8f 100644
--- a/softmmu/cpus.c
+++ b/softmmu/cpus.c
@@ -64,6 +64,32 @@
 
 #endif /* CONFIG_LINUX */
 
+/*
+ * struct QemuMutex {
+ *     pthread_mutex_t lock;
+ * #ifdef CONFIG_DEBUG_MUTEX
+ *     const char *file;
+ *     int line;
+ * #endif
+ *     bool initialized;
+ * };
+ *
+ * 旧的版本的例子:
+ * (gdb) p qemu_global_mutex
+ * $1 = {lock = {__data = {__lock = 2, __count = 0, __owner = 12671, __nusers = 1, __kind = 0, __spins = 0, __elision = 0, __list = {__prev = 0x0, __next = 0x0}},
+ *     __size = "\002\000\000\000\000\000\000\000\177\061\000\000\001", '\000' <repeats 26 times>, __align = 2}, initialized = true}
+ *
+ * 新版本没有lock的例子.
+ * (gdb) p qemu_global_mutex
+ * $1 = {lock = {__data = {__lock = 0, __count = 0, __owner = 0, __nusers = 0, __kind = 0, __spins = 0, __elision = 0, __list = {
+ *         __prev = 0x0, __next = 0x0}}, __size = '\000' <repeats 39 times>, __align = 0}, file = 0x0, line = 0, initialized = true}
+ *
+ * 新版本lock的例子.
+ * (gdb) p qemu_global_mutex
+ * $1 = {lock = {__data = {__lock = 1, __count = 0, __owner = 14315, __nusers = 1, __kind = 0, __spins = 0, __elision = 0, __list = {
+ *         __prev = 0x0, __next = 0x0}}, __size = "\001\000\000\000\000\000\000\000\353\067\000\000\001", '\000' <repeats 26 times>,
+ *     __align = 1}, file = 0x556291533beb "../util/main-loop.c", line = 318, initialized = true}
+ */
 static QemuMutex qemu_global_mutex;
 
 /*
@@ -166,6 +192,16 @@ void cpu_synchronize_all_pre_loadvm(void)
 
 void cpu_synchronize_state(CPUState *cpu)
 {
+    /*
+     * 在以下使用AcclOpsClass->synchronize_state:
+     *   - accel/hvf/hvf-accel-ops.c|474| <<hvf_accel_ops_class_init>> ops->synchronize_state = hvf_cpu_synchronize_state;
+     *   - accel/kvm/kvm-accel-ops.c|96| <<kvm_accel_ops_class_init>> ops->synchronize_state = kvm_cpu_synchronize_state;
+     *   - softmmu/cpus.c|169| <<cpu_synchronize_state>> if (cpus_accel->synchronize_state) {
+     *   - softmmu/cpus.c|170| <<cpu_synchronize_state>> cpus_accel->synchronize_state(cpu);
+     *   - target/i386/hax/hax-accel-ops.c|86| <<hax_accel_ops_class_init>> ops->synchronize_state = hax_cpu_synchronize_state;
+     *   - target/i386/nvmm/nvmm-accel-ops.c|95| <<nvmm_accel_ops_class_init>> ops->synchronize_state = nvmm_cpu_synchronize_state;
+     *   - target/i386/whpx/whpx-accel-ops.c|101| <<whpx_accel_ops_class_init>> ops->synchronize_state = whpx_cpu_synchronize_state;
+     */
     if (cpus_accel->synchronize_state) {
         cpus_accel->synchronize_state(cpu);
     }
@@ -173,6 +209,16 @@ void cpu_synchronize_state(CPUState *cpu)
 
 void cpu_synchronize_post_reset(CPUState *cpu)
 {
+    /*
+     * 在以下使用AcclOpsClass->synchronize_post_reset:
+     *   - accel/hvf/hvf-accel-ops.c|472| <<hvf_accel_ops_class_init>> ops->synchronize_post_reset = hvf_cpu_synchronize_post_reset;
+     *   - accel/kvm/kvm-accel-ops.c|94| <<kvm_accel_ops_class_init>> ops->synchronize_post_reset = kvm_cpu_synchronize_post_reset;
+     *   - softmmu/cpus.c|176| <<cpu_synchronize_post_reset>> if (cpus_accel->synchronize_post_reset) {
+     *   - softmmu/cpus.c|177| <<cpu_synchronize_post_reset>> cpus_accel->synchronize_post_reset(cpu);
+     *   - target/i386/hax/hax-accel-ops.c|84| <<hax_accel_ops_class_init>> ops->synchronize_post_reset = hax_cpu_synchronize_post_reset;
+     *   - target/i386/nvmm/nvmm-accel-ops.c|93| <<nvmm_accel_ops_class_init>> ops->synchronize_post_reset = nvmm_cpu_synchronize_post_reset;
+     *   - target/i386/whpx/whpx-accel-ops.c|99| <<whpx_accel_ops_class_init>> ops->synchronize_post_reset = whpx_cpu_synchronize_post_reset;
+     */
     if (cpus_accel->synchronize_post_reset) {
         cpus_accel->synchronize_post_reset(cpu);
     }
@@ -496,6 +542,13 @@ bool qemu_in_main_thread(void)
  */
 void qemu_mutex_lock_iothread_impl(const char *file, int line)
 {
+    /*
+     * 在以下使用:
+     *   - util/qsp.c|127| <<global>> QemuMutexLockFunc qemu_bql_mutex_lock_func = qemu_mutex_lock_impl;
+     *   - softmmu/cpus.c|519| <<qemu_mutex_lock_iothread_impl>> QemuMutexLockFunc bql_lock = qatomic_read(&qemu_bql_mutex_lock_func);
+     *   - util/qsp.c|442| <<qsp_enable>> qatomic_set(&qemu_bql_mutex_lock_func, qsp_bql_mutex_lock);
+     *   - util/qsp.c|453| <<qsp_disable>> qatomic_set(&qemu_bql_mutex_lock_func, qemu_mutex_lock_impl);
+     */
     QemuMutexLockFunc bql_lock = qatomic_read(&qemu_bql_mutex_lock_func);
 
     g_assert(!qemu_mutex_iothread_locked());
diff --git a/softmmu/memory.c b/softmmu/memory.c
index 7ba204883..0f02a4656 100644
--- a/softmmu/memory.c
+++ b/softmmu/memory.c
@@ -37,13 +37,50 @@
 //#define DEBUG_UNASSIGNED
 
 static unsigned memory_region_transaction_depth;
+/*
+ * 在以下使用memory_region_update_pending:
+ *   - softmmu/memory.c|1137| <<memory_region_transaction_commit>> if (memory_region_update_pending) {
+ *   - softmmu/memory.c|1146| <<memory_region_transaction_commit>> memory_region_update_pending = false;
+ *   - softmmu/memory.c|2178| <<memory_region_set_log>> memory_region_update_pending |= mr->enabled;
+ *   - softmmu/memory.c|2308| <<memory_region_set_readonly>> memory_region_update_pending |= mr->enabled;
+ *   - softmmu/memory.c|2318| <<memory_region_set_nonvolatile>> memory_region_update_pending |= mr->enabled;
+ *   - softmmu/memory.c|2328| <<memory_region_rom_device_set_romd>> memory_region_update_pending |= mr->enabled;
+ *   - softmmu/memory.c|2629| <<memory_region_update_container_subregions>> memory_region_update_pending |= mr->enabled && subregion->enabled;
+ *   - softmmu/memory.c|2679| <<memory_region_del_subregion>> memory_region_update_pending |= mr->enabled && subregion->enabled;
+ *   - softmmu/memory.c|2690| <<memory_region_set_enabled>> memory_region_update_pending = true;
+ *   - softmmu/memory.c|2706| <<memory_region_set_size>> memory_region_update_pending = true;
+ *   - softmmu/memory.c|2742| <<memory_region_set_alias_offset>> memory_region_update_pending |= mr->enabled;
+ *   - softmmu/memory.c|2913| <<memory_global_dirty_log_start>> memory_region_update_pending = true;
+ *   - softmmu/memory.c|2928| <<memory_global_dirty_log_do_stop>> memory_region_update_pending = true;
+ */
 static bool memory_region_update_pending;
+/*
+ * 在以下使用ioeventfd_update_pending:
+ *   - softmmu/memory.c|1107| <<memory_region_transaction_commit>> ioeventfd_update_pending = false;
+ *   - softmmu/memory.c|1109| <<memory_region_transaction_commit>> } else if (ioeventfd_update_pending) {
+ *   - softmmu/memory.c|1113| <<memory_region_transaction_commit>> ioeventfd_update_pending = false;
+ *   - softmmu/memory.c|2485| <<memory_region_add_eventfd>> ioeventfd_update_pending |= mr->enabled;
+ *   - softmmu/memory.c|2520| <<memory_region_del_eventfd>> ioeventfd_update_pending |= mr->enabled;
+ */
 static bool ioeventfd_update_pending;
 unsigned int global_dirty_tracking;
 
 static QTAILQ_HEAD(, MemoryListener) memory_listeners
     = QTAILQ_HEAD_INITIALIZER(memory_listeners);
 
+/*
+ * 在以下使用address_spaces (list):
+ *   - softmmu/memory.c|72| <<QTAILQ_HEAD>> = QTAILQ_HEAD_INITIALIZER(address_spaces);
+ *   - softmmu/memory.c|598| <<memory_region_to_address_space>> QTAILQ_FOREACH(as, &address_spaces, address_spaces_link) {
+ *   - softmmu/memory.c|1122| <<flatviews_reset>> QTAILQ_FOREACH(as, &address_spaces, address_spaces_link) {
+ *   - softmmu/memory.c|1209| <<memory_region_transaction_commit>> QTAILQ_FOREACH(as, &address_spaces, address_spaces_link) {
+ *   - softmmu/memory.c|1217| <<memory_region_transaction_commit>> QTAILQ_FOREACH(as, &address_spaces, address_spaces_link) {
+ *   - softmmu/memory.c|2491| <<memory_region_update_coalesced_range>> QTAILQ_FOREACH(as, &address_spaces, address_spaces_link) {
+ *   - softmmu/memory.c|3166| <<address_space_init>> QTAILQ_INSERT_TAIL(&address_spaces, as, address_spaces_link);
+ *   - softmmu/memory.c|3190| <<address_space_destroy>> QTAILQ_REMOVE(&address_spaces, as, address_spaces_link);
+ *   - softmmu/memory.c|3501| <<mtree_info_flatview>> QTAILQ_FOREACH(as, &address_spaces, address_spaces_link) {
+ *   - softmmu/memory.c|3579| <<mtree_info_as>> QTAILQ_FOREACH(as, &address_spaces, address_spaces_link) {
+ */
 static QTAILQ_HEAD(, AddressSpace) address_spaces
     = QTAILQ_HEAD_INITIALIZER(address_spaces);
 
@@ -170,6 +207,12 @@ struct MemoryRegionIoeventfd {
     EventNotifier *e;
 };
 
+/*
+ * called by:
+ *   - softmmu/memory.c|780| <<address_space_add_del_ioeventfds>> || memory_region_ioeventfd_before(&fds_old[iold],
+ *   - softmmu/memory.c|793| <<address_space_add_del_ioeventfds>> || memory_region_ioeventfd_before(&fds_new[inew],
+ *   - softmmu/memory.c|2522| <<memory_region_add_eventfd>> if (memory_region_ioeventfd_before(&mrfd, &mr->ioeventfds[i])) {
+ */
 static bool memory_region_ioeventfd_before(MemoryRegionIoeventfd *a,
                                            MemoryRegionIoeventfd *b)
 {
@@ -576,6 +619,12 @@ static AddressSpace *memory_region_to_address_space(MemoryRegion *mr)
 /* Render a memory region into the global view.  Ranges in @view obscure
  * ranges in @mr.
  */
+/*
+ * called by:
+ *   - softmmu/memory.c|656| <<render_memory_region>> render_memory_region(view, mr->alias, base, clip,
+ *   - softmmu/memory.c|663| <<render_memory_region>> render_memory_region(view, subregion, base, clip,
+ *   - softmmu/memory.c|785| <<generate_memory_topology>> render_memory_region(view, mr, int128_zero(),
+ */
 static void render_memory_region(FlatView *view,
                                  MemoryRegion *mr,
                                  Int128 base,
@@ -725,6 +774,12 @@ static MemoryRegion *memory_region_get_flatview_root(MemoryRegion *mr)
 }
 
 /* Render a memory topology into a list of disjoint absolute ranges. */
+/*
+ * called by:
+ *   - softmmu/memory.c|1035| <<flatviews_init>> empty_view = generate_memory_topology(NULL);
+ *   - softmmu/memory.c|1062| <<flatviews_reset>> generate_memory_topology(physmr);
+ *   - softmmu/memory.c|1117| <<address_space_update_topology>> generate_memory_topology(physmr);
+ */
 static FlatView *generate_memory_topology(MemoryRegion *mr)
 {
     int i;
@@ -751,6 +806,10 @@ static FlatView *generate_memory_topology(MemoryRegion *mr)
     return view;
 }
 
+/*
+ * called by:
+ *   - softmmu/memory.c|916| <<address_space_update_ioeventfds>> address_space_add_del_ioeventfds(as, ioeventfds, ioeventfd_nb,
+ */
 static void address_space_add_del_ioeventfds(AddressSpace *as,
                                              MemoryRegionIoeventfd *fds_new,
                                              unsigned fds_new_nb,
@@ -800,6 +859,17 @@ static void address_space_add_del_ioeventfds(AddressSpace *as,
     }
 }
 
+/*
+ * called by:
+ *   - softmmu/memory.c|913| <<address_space_update_ioeventfds>> view = address_space_get_flatview(as);
+ *   - softmmu/memory.c|2259| <<memory_region_sync_dirty_bitmap>> view = address_space_get_flatview(as);
+ *   - softmmu/memory.c|2295| <<memory_region_clear_dirty_bitmap>> view = address_space_get_flatview(as);
+ *   - softmmu/memory.c|2474| <<memory_region_update_coalesced_range>> view = address_space_get_flatview(as);
+ *   - softmmu/memory.c|3043| <<listener_add_address_space>> view = address_space_get_flatview(as);
+ *   - softmmu/memory.c|3069| <<listener_del_address_space>> view = address_space_get_flatview(as);
+ *   - softmmu/memory.c|3484| <<mtree_info_flatview>> view = address_space_get_flatview(as);
+ *   - softmmu/physmem.c|3352| <<address_space_cache_init>> cache->fv = address_space_get_flatview(as);
+ */
 FlatView *address_space_get_flatview(AddressSpace *as)
 {
     FlatView *view;
@@ -814,6 +884,47 @@ FlatView *address_space_get_flatview(AddressSpace *as)
     return view;
 }
 
+/*
+ * 当device_add cpu的时候:
+ *
+ * (gdb) bt
+ * #0  address_space_update_ioeventfds (as=0x555557b8eea0) at ../softmmu/memory.c:818
+ * #1  0x0000555555c6c86a in address_space_init (as=0x555557b8eea0, root=0x555556a5e770, name=0x555557b8ef00 "cpu-memory-4") at ../softmmu/memory.c:3025
+ * #2  0x0000555555c70e74 in cpu_address_space_init (cpu=0x555556dd7000, asidx=0, prefix=0x55555603415f "cpu-memory", mr=0x555556a5e770) at ../softmmu/physmem.c:748
+ * #3  0x0000555555a71fd1 in qemu_init_vcpu (cpu=0x555556dd7000) at ../softmmu/cpus.c:634
+ * #4  0x0000555555b633c0 in x86_cpu_realizefn (dev=0x555556dd7000, errp=0x7fffffffc4b0) at ../target/i386/cpu.c:6591
+ * #5  0x0000555555d21085 in device_set_realized (obj=0x555556dd7000, value=true, errp=0x7fffffffc7f0) at ../hw/core/qdev.c:553
+ * #6  0x0000555555d2aaf5 in property_set_bool (obj=0x555556dd7000, v=0x555557318610, name=0x5555560b9501 "realized", opaque=0x555556852210, errp=0x7fffffffc7f0) at ../qom/object.c:2273
+ * #7  0x0000555555d28b3c in object_property_set (obj=0x555556dd7000, name=0x5555560b9501 "realized", v=0x555557318610, errp=0x7fffffffc7f0) at ../qom/object.c:1408
+ * #8  0x0000555555d2cee7 in object_property_set_qobject (obj=0x555556dd7000, name=0x5555560b9501 "realized", value=0x555556f93610, errp=0x7fffffffc7f0) at ../qom/qom-qobject.c:28
+ * #9  0x0000555555d28ea1 in object_property_set_bool (obj=0x555556dd7000, name=0x5555560b9501 "realized", value=true, errp=0x7fffffffc7f0) at ../qom/object.c:1477
+ * #10 0x0000555555d2081d in qdev_realize (dev=0x555556dd7000, bus=0x0, errp=0x7fffffffc7f0) at ../hw/core/qdev.c:333
+ * #11 0x0000555555a7768e in qdev_device_add_from_qdict (opts=0x55555705ba10, from_json=false, errp=0x7fffffffc7f0) at ../softmmu/qdev-monitor.c:714
+ * #12 0x0000555555a7772c in qdev_device_add (opts=0x5555579113b0, errp=0x7fffffffc7f0) at ../softmmu/qdev-monitor.c:733
+ * #13 0x0000555555a77d40 in qmp_device_add (qdict=0x5555578b4b60, ret_data=0x0, errp=0x7fffffffc7f0) at ../softmmu/qdev-monitor.c:855
+ * #14 0x0000555555a78150 in hmp_device_add (mon=0x5555568485f0, qdict=0x5555578b4b60) at ../softmmu/qdev-monitor.c:963
+ * #15 0x0000555555accc3e in handle_hmp_command_exec (mon=0x5555568485f0, cmd=0x5555566fb220 <hmp_cmds+1920>, qdict=0x5555578b4b60) at ../monitor/hmp.c:1103
+ * #16 0x0000555555acce6b in handle_hmp_command (mon=0x5555568485f0, cmdline=0x555556ae1f1b "host-x86_64-cpu,id=core4,socket-id=0,core-id=4,thread-id=0") at ../monitor/hmp.c:1155
+ * #17 0x0000555555aca384 in monitor_command_cb (opaque=0x5555568485f0, cmdline=0x555556ae1f10 "device_add host-x86_64-cpu,id=core4,socket-id=0,core-id=4,thread-id=0", readline_opaque=0x0) at ../monitor/hmp.c:49
+ * #18 0x0000555555f19732 in readline_handle_byte (rs=0x555556ae1f10, ch=13) at ../util/readline.c:411
+ * #19 0x0000555555acd9a8 in monitor_read (opaque=0x5555568485f0, buf=0x7fffffffca50 "\r\320\377\377\377\177", size=1) at ../monitor/hmp.c:1393
+ * #20 0x0000555555e31768 in qemu_chr_be_write_impl (s=0x555556a69190, buf=0x7fffffffca50 "\r\320\377\377\377\177", len=1) at ../chardev/char.c:201
+ * #21 0x0000555555e317cc in qemu_chr_be_write (s=0x555556a69190, buf=0x7fffffffca50 "\r\320\377\377\377\177", len=1) at ../chardev/char.c:213
+ * #22 0x0000555555e341f9 in fd_chr_read (chan=0x555556a69250, cond=G_IO_IN, opaque=0x555556a69190) at ../chardev/char-fd.c:72
+ * #23 0x0000555555d33709 in qio_channel_fd_source_dispatch (source=0x555557384df0, callback=0x555555e340cf <fd_chr_read>, user_data=0x555556a69190) at ../io/channel-watch.c:84
+ * #24 0x00007ffff6c40119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #25 0x0000555555f12165 in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #26 0x0000555555f121df in os_host_main_loop_wait (timeout=499000000) at ../util/main-loop.c:320
+ * #27 0x0000555555f122e4 in main_loop_wait (nonblocking=0) at ../util/main-loop.c:596
+ * #28 0x0000555555a7a05e in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #29 0x000055555581fe62 in qemu_main (argc=32, argv=0x7fffffffdd38, envp=0x0) at ../softmmu/main.c:38
+ * #30 0x000055555581fe94 in main (argc=32, argv=0x7fffffffdd38) at ../softmmu/main.c:47
+ *
+ * called by:
+ *   - softmmu/memory.c|1104| <<memory_region_transaction_commit>> address_space_update_ioeventfds(as);
+ *   - softmmu/memory.c|1111| <<memory_region_transaction_commit>> address_space_update_ioeventfds(as);
+ *   - softmmu/memory.c|3013| <<address_space_init>> address_space_update_ioeventfds(as);
+ */
 static void address_space_update_ioeventfds(AddressSpace *as)
 {
     FlatView *view;
@@ -824,6 +935,25 @@ static void address_space_update_ioeventfds(AddressSpace *as)
     AddrRange tmp;
     unsigned i;
 
+    /*
+     * 在以下使用MemoryRegion->ioeventfd_nb:
+     *   - softmmu/memory.c|899| <<address_space_update_ioeventfds>> for (i = 0; i < fr->mr->ioeventfd_nb; ++i) {
+     *   - softmmu/memory.c|1545| <<memory_region_dispatch_write_eventfds>> for (i = 0; i < mr->ioeventfd_nb; i++) {
+     *   - softmmu/memory.c|2565| <<memory_region_add_eventfd>> for (i = 0; i < mr->ioeventfd_nb; ++i) {
+     *   - softmmu/memory.c|2570| <<memory_region_add_eventfd>> ++mr->ioeventfd_nb;
+     *   - softmmu/memory.c|2575| <<memory_region_add_eventfd>> sizeof(*mr->ioeventfds) * mr->ioeventfd_nb);
+     *   - softmmu/memory.c|2581| <<memory_region_add_eventfd>> sizeof(*mr->ioeventfds) * (mr->ioeventfd_nb-1 - i));
+     *   - softmmu/memory.c|2628| <<memory_region_del_eventfd>> for (i = 0; i < mr->ioeventfd_nb; ++i) {
+     *   - softmmu/memory.c|2633| <<memory_region_del_eventfd>> assert(i != mr->ioeventfd_nb);
+     *   - softmmu/memory.c|2635| <<memory_region_del_eventfd>> sizeof(*mr->ioeventfds) * (mr->ioeventfd_nb - (i+1)));
+     *   - softmmu/memory.c|2636| <<memory_region_del_eventfd>> --mr->ioeventfd_nb;
+     *   - softmmu/memory.c|2638| <<memory_region_del_eventfd>> sizeof(*mr->ioeventfds)*mr->ioeventfd_nb + 1);
+     * 在以下使用struct AddressSpace->ioeventfd_nb:
+     *   - softmmu/memory.c|878| <<address_space_update_ioeventfds>> ioeventfd_max = QEMU_ALIGN_UP(as->ioeventfd_nb, 4);
+     *   - softmmu/memory.c|921| <<address_space_update_ioeventfds>> as->ioeventfds, as->ioeventfd_nb);
+     *   - softmmu/memory.c|925| <<address_space_update_ioeventfds>> as->ioeventfd_nb = ioeventfd_nb;
+     *   - softmmu/memory.c|3126| <<address_space_init>> as->ioeventfd_nb = 0;
+     */
     /*
      * It is likely that the number of ioeventfds hasn't changed much, so use
      * the previous size as the starting value, with some headroom to avoid
@@ -832,9 +962,29 @@ static void address_space_update_ioeventfds(AddressSpace *as)
     ioeventfd_max = QEMU_ALIGN_UP(as->ioeventfd_nb, 4);
     ioeventfds = g_new(MemoryRegionIoeventfd, ioeventfd_max);
 
+    /*
+     * struct FlatView {
+     *     struct rcu_head rcu;
+     *     unsigned ref; 
+     *     FlatRange *ranges;
+     *     unsigned nr;
+     *     unsigned nr_allocated;
+     *     struct AddressSpaceDispatch *dispatch;
+     *     MemoryRegion *root;
+     * };
+     *
+     * FlatView *view;
+     */
     view = address_space_get_flatview(as);
+    /*
+     * 对于每一个fr
+     */
     FOR_EACH_FLAT_RANGE(fr, view) {
         for (i = 0; i < fr->mr->ioeventfd_nb; ++i) {
+            /*
+	     * 大概是:
+	     * fr->mr->ioeventfds[i].addr + (fr->addr.start - fr->offset_in_region)
+	     */
             tmp = addrrange_shift(fr->mr->ioeventfds[i].addr,
                                   int128_sub(fr->addr.start,
                                              int128_make64(fr->offset_in_region)));
@@ -851,6 +1001,13 @@ static void address_space_update_ioeventfds(AddressSpace *as)
         }
     }
 
+    /*
+     * 794 static void address_space_add_del_ioeventfds(AddressSpace *as,
+     * 795                                              MemoryRegionIoeventfd *fds_new,
+     * 796                                              unsigned fds_new_nb,
+     * 797                                              MemoryRegionIoeventfd *fds_old,
+     * 798                                              unsigned fds_old_nb)
+     */
     address_space_add_del_ioeventfds(as, ioeventfds, ioeventfd_nb,
                                      as->ioeventfds, as->ioeventfd_nb);
 
@@ -1001,6 +1158,10 @@ static void flatviews_init(void)
     }
 }
 
+/*
+ * called by:
+ *   - softmmu/memory.c|1138| <<memory_region_transaction_commit>> flatviews_reset();
+ */
 static void flatviews_reset(void)
 {
     AddressSpace *as;
@@ -1099,6 +1260,19 @@ void memory_region_transaction_commit(void)
 
             MEMORY_LISTENER_CALL_GLOBAL(begin, Forward);
 
+            /*
+	     * 在以下使用address_spaces (list):
+	     *   - softmmu/memory.c|72| <<QTAILQ_HEAD>> = QTAILQ_HEAD_INITIALIZER(address_spaces);
+             *   - softmmu/memory.c|598| <<memory_region_to_address_space>> QTAILQ_FOREACH(as, &address_spaces, address_spaces_link) {
+             *   - softmmu/memory.c|1122| <<flatviews_reset>> QTAILQ_FOREACH(as, &address_spaces, address_spaces_link) {
+             *   - softmmu/memory.c|1209| <<memory_region_transaction_commit>> QTAILQ_FOREACH(as, &address_spaces, address_spaces_link) {
+             *   - softmmu/memory.c|1217| <<memory_region_transaction_commit>> QTAILQ_FOREACH(as, &address_spaces, address_spaces_link) {
+             *   - softmmu/memory.c|2491| <<memory_region_update_coalesced_range>> QTAILQ_FOREACH(as, &address_spaces, address_spaces_link) {
+             *   - softmmu/memory.c|3166| <<address_space_init>> QTAILQ_INSERT_TAIL(&address_spaces, as, address_spaces_link);
+             *   - softmmu/memory.c|3190| <<address_space_destroy>> QTAILQ_REMOVE(&address_spaces, as, address_spaces_link);
+             *   - softmmu/memory.c|3501| <<mtree_info_flatview>> QTAILQ_FOREACH(as, &address_spaces, address_spaces_link) {
+             *   - softmmu/memory.c|3579| <<mtree_info_as>> QTAILQ_FOREACH(as, &address_spaces, address_spaces_link) {
+	     */
             QTAILQ_FOREACH(as, &address_spaces, address_spaces_link) {
                 address_space_set_flatview(as);
                 address_space_update_ioeventfds(as);
@@ -1485,6 +1659,27 @@ static bool memory_region_dispatch_write_eventfds(MemoryRegion *mr,
     return false;
 }
 
+/*
+ * called by:
+ *   - accel/tcg/cputlb.c|1429| <<io_writex>> r = memory_region_dispatch_write(mr, mr_offset, val, op, iotlbentry->attrs);
+ *   - hw/arm/armv7m.c|139| <<v7m_sysreg_ns_write>> return memory_region_dispatch_write(mr, addr, value,
+ *   - hw/arm/armv7m.c|186| <<v7m_systick_write>> return memory_region_dispatch_write(mr, addr, value,
+ *   - hw/ppc/pegasos2.c|225| <<pegasos2_mv_reg_write>> memory_region_dispatch_write(r, addr, val, size_memop(len) | MO_LE,
+ *   - hw/ppc/pnv_bmc.c|162| <<hiomap_erase>> result = memory_region_dispatch_write(&pnor->mmio, offset + i * 4,
+ *   - hw/remote/vfio-user-obj.c|383| <<vfu_object_mr_rw>> result = memory_region_dispatch_write(mr, offset, val,
+ *   - hw/s390x/s390-pci-inst.c|507| <<zpci_write_bar>> return memory_region_dispatch_write(mr, offset, data,
+ *   - hw/s390x/s390-pci-inst.c|843| <<pcistb_service_call>> result = memory_region_dispatch_write(mr, offset + i * 8,
+ *   - hw/vfio/pci-quirks.c|1069| <<vfio_rtl8168_quirk_address_write>> memory_region_dispatch_write(&vdev->pdev.msix_table_mmio,
+ *   - hw/virtio/virtio-pci.c|589| <<virtio_address_space_write>> memory_region_dispatch_write(mr, addr, val, size_memop(len) | MO_LE,
+ *   - softmmu/memory.c|1671| <<memory_region_dispatch_write>> return memory_region_dispatch_write(mr->alias,
+ *   - softmmu/physmem.c|2843| <<flatview_write_continue>> result |= memory_region_dispatch_write(mr, addr1, val,
+ *   - target/mips/tcg/sysemu/special_helper.c|157| <<helper_cache>> memory_region_dispatch_write(env->itc_tag, index, env->CP0_TagLo,
+ *   - memory_ldst.c.inc|283| <<glue>> r = memory_region_dispatch_write(mr, addr1, val, MO_32, attrs);
+ *   - memory_ldst.c.inc|319| <<glue>> r = memory_region_dispatch_write(mr, addr1, val,
+ *   - memory_ldst.c.inc|382| <<glue>> r = memory_region_dispatch_write(mr, addr1, val, MO_8, attrs);
+ *   - memory_ldst.c.inc|415| <<glue>> r = memory_region_dispatch_write(mr, addr1, val,
+ *   - memory_ldst.c.inc|479| <<glue>> r = memory_region_dispatch_write(mr, addr1, val,
+ */
 MemTxResult memory_region_dispatch_write(MemoryRegion *mr,
                                          hwaddr addr,
                                          uint64_t data,
@@ -2444,6 +2639,22 @@ void memory_region_clear_flush_coalesced(MemoryRegion *mr)
 
 static bool userspace_eventfd_warning;
 
+/*
+ * called by:
+ *   - hw/misc/ivshmem.c|365| <<ivshmem_add_eventfd>> memory_region_add_eventfd(&s->ivshmem_mmio,
+ *   - hw/misc/pci-testdev.c|113| <<pci_testdev_start>> memory_region_add_eventfd(test->mr,
+ *   - hw/nvme/ctrl.c|4270| <<nvme_init_cq_ioeventfd>> memory_region_add_eventfd(&n->iomem,
+ *   - hw/nvme/ctrl.c|4299| <<nvme_init_sq_ioeventfd>> memory_region_add_eventfd(&n->iomem,
+ *   - hw/vfio/pci-quirks.c|401| <<vfio_ioeventfd_init>> memory_region_add_eventfd(ioeventfd->mr, ioeventfd->addr, ioeventfd->size,
+ *   - hw/virtio/virtio-mmio.c|52| <<virtio_mmio_ioeventfd_assign>> memory_region_add_eventfd(&proxy->iomem, VIRTIO_MMIO_QUEUE_NOTIFY, 4,
+ *   - hw/virtio/virtio-pci.c|251| <<virtio_pci_ioeventfd_assign>> memory_region_add_eventfd(modern_mr, modern_addr, 0,
+ *   - hw/virtio/virtio-pci.c|254| <<virtio_pci_ioeventfd_assign>> memory_region_add_eventfd(modern_mr, modern_addr, 2,
+ *   - hw/virtio/virtio-pci.c|258| <<virtio_pci_ioeventfd_assign>> memory_region_add_eventfd(modern_notify_mr, 0, 2,
+ *   - hw/virtio/virtio-pci.c|263| <<virtio_pci_ioeventfd_assign>> memory_region_add_eventfd(legacy_mr, legacy_addr, 2,
+ *
+ * 核心思想就是制作MemoryRegionIoeventfd给MemoryRegion->ioeventfds[i]
+ * 可能会g_realloc()
+ */
 void memory_region_add_eventfd(MemoryRegion *mr,
                                hwaddr addr,
                                unsigned size,
@@ -2471,21 +2682,54 @@ void memory_region_add_eventfd(MemoryRegion *mr,
         adjust_endianness(mr, &mrfd.data, size_memop(size) | MO_TE);
     }
     memory_region_transaction_begin();
+    /*
+     * MemoryRegion *mr:
+     * -> unsigned ioeventfd_nb;
+     * -> MemoryRegionIoeventfd *ioeventfds;
+     */
     for (i = 0; i < mr->ioeventfd_nb; ++i) {
         if (memory_region_ioeventfd_before(&mrfd, &mr->ioeventfds[i])) {
             break;
         }
     }
     ++mr->ioeventfd_nb;
+    /*
+     * 似乎这里是唯一alloc的地方
+     */
     mr->ioeventfds = g_realloc(mr->ioeventfds,
                                   sizeof(*mr->ioeventfds) * mr->ioeventfd_nb);
+    /*
+     * dst: &mr->ioeventfds[i+1]
+     * src: &mr->ioeventfds[i]
+     */
     memmove(&mr->ioeventfds[i+1], &mr->ioeventfds[i],
             sizeof(*mr->ioeventfds) * (mr->ioeventfd_nb-1 - i));
     mr->ioeventfds[i] = mrfd;
+    /*
+     * 在以下使用ioeventfd_update_pending:
+     *   - softmmu/memory.c|1107| <<memory_region_transaction_commit>> ioeventfd_update_pending = false;
+     *   - softmmu/memory.c|1109| <<memory_region_transaction_commit>> } else if (ioeventfd_update_pending) {
+     *   - softmmu/memory.c|1113| <<memory_region_transaction_commit>> ioeventfd_update_pending = false;
+     *   - softmmu/memory.c|2485| <<memory_region_add_eventfd>> ioeventfd_update_pending |= mr->enabled;
+     *   - softmmu/memory.c|2520| <<memory_region_del_eventfd>> ioeventfd_update_pending |= mr->enabled;
+     */
     ioeventfd_update_pending |= mr->enabled;
     memory_region_transaction_commit();
 }
 
+/*
+ * called by:
+ *   - hw/misc/ivshmem.c|375| <<ivshmem_del_eventfd>> memory_region_del_eventfd(&s->ivshmem_mmio,
+ *   - hw/misc/pci-testdev.c|127| <<pci_testdev_stop>> memory_region_del_eventfd(test->mr,
+ *   - hw/nvme/ctrl.c|4312| <<nvme_free_sq>> memory_region_del_eventfd(&n->iomem,
+ *   - hw/nvme/ctrl.c|4703| <<nvme_free_cq>> memory_region_del_eventfd(&n->iomem,
+ *   - hw/vfio/pci-quirks.c|292| <<vfio_ioeventfd_exit>> memory_region_del_eventfd(ioeventfd->mr, ioeventfd->addr, ioeventfd->size,
+ *   - hw/virtio/virtio-mmio.c|55| <<virtio_mmio_ioeventfd_assign>> memory_region_del_eventfd(&proxy->iomem, VIRTIO_MMIO_QUEUE_NOTIFY, 4,
+ *   - hw/virtio/virtio-pci.c|269| <<virtio_pci_ioeventfd_assign>> memory_region_del_eventfd(modern_mr, modern_addr, 0,
+ *   - hw/virtio/virtio-pci.c|272| <<virtio_pci_ioeventfd_assign>> memory_region_del_eventfd(modern_mr, modern_addr, 2,
+ *   - hw/virtio/virtio-pci.c|276| <<virtio_pci_ioeventfd_assign>> memory_region_del_eventfd(modern_notify_mr, 0, 2,
+ *   - hw/virtio/virtio-pci.c|281| <<virtio_pci_ioeventfd_assign>> memory_region_del_eventfd(legacy_mr, legacy_addr, 2,
+ */
 void memory_region_del_eventfd(MemoryRegion *mr,
                                hwaddr addr,
                                unsigned size,
@@ -2999,6 +3243,20 @@ void address_space_remove_listeners(AddressSpace *as)
     }
 }
 
+/*
+ * 被特别多调用,几个特殊的例子:
+ *   - hw/i386/amd_iommu.c|1443| <<amdvi_host_dma_iommu>> address_space_init(&amdvi_dev_as->as, &amdvi_dev_as->root, name);
+ *   - hw/i386/intel_iommu.c|3459| <<vtd_find_add_as>> address_space_init(&vtd_dev_as->as, &vtd_dev_as->root, "vtd-root");
+ *   - hw/pci/pci.c|1143| <<do_pci_register_device>> address_space_init(&pci_dev->bus_master_as,
+ *   - hw/remote/iommu.c|57| <<remote_iommu_find_add_as>> address_space_init(&elem->as, elem->mr, NULL);
+ *   - hw/s390x/s390-pci-bus.c|618| <<s390_pci_get_iommu>> address_space_init(&iommu->as, &iommu->mr, as_name);
+ *   - hw/scsi/lsi53c895a.c|2305| <<lsi_scsi_realize>> address_space_init(&s->pci_io_as, pci_address_space_io(dev), "lsi-pci-io");
+ *   - hw/virtio/virtio-iommu.c|409| <<virtio_iommu_find_add_as>> address_space_init(&sdev->as, &sdev->root, TYPE_VIRTIO_IOMMU);
+ *   - softmmu/physmem.c|748| <<cpu_address_space_init>> address_space_init(as, mr, as_name);
+ *   - softmmu/physmem.c|2680| <<memory_map_init>> address_space_init(&address_space_memory, system_memory, "memory");
+ *   - softmmu/physmem.c|2685| <<memory_map_init>> address_space_init(&address_space_io, system_io, "I/O");
+ *   - target/i386/kvm/kvm.c|2416| <<register_smram_listener>> address_space_init(&smram_address_space, &smram_as_root, "KVM-SMRAM");
+ */
 void address_space_init(AddressSpace *as, MemoryRegion *root, const char *name)
 {
     memory_region_ref(root);
diff --git a/softmmu/physmem.c b/softmmu/physmem.c
index dc3c3e5f2..e4e44cda4 100644
--- a/softmmu/physmem.c
+++ b/softmmu/physmem.c
@@ -736,6 +736,16 @@ translate_fail:
     return &d->map.sections[PHYS_SECTION_UNASSIGNED];
 }
 
+/*
+ * called by:
+ *   - softmmu/cpus.c|634| <<qemu_init_vcpu>> cpu_address_space_init(cpu, 0, "cpu-memory", cpu->memory);
+ *   - target/arm/cpu.c|2025| <<arm_cpu_realizefn>> cpu_address_space_init(cs, ARMASIdx_S, "cpu-secure-memory",
+ *   - target/arm/cpu.c|2030| <<arm_cpu_realizefn>> cpu_address_space_init(cs, ARMASIdx_TagNS, "cpu-tag-memory",
+ *   - target/arm/cpu.c|2033| <<arm_cpu_realizefn>> cpu_address_space_init(cs, ARMASIdx_TagS, "cpu-tag-memory",
+ *   - target/arm/cpu.c|2038| <<arm_cpu_realizefn>> cpu_address_space_init(cs, ARMASIdx_NS, "cpu-memory", cs->memory);
+ *   - target/i386/tcg/sysemu/tcg-cpu.c|76| <<tcg_cpu_realizefn>> cpu_address_space_init(cs, 0, "cpu-memory", cs->memory);
+ *   - target/i386/tcg/sysemu/tcg-cpu.c|77| <<tcg_cpu_realizefn>> cpu_address_space_init(cs, 1, "cpu-smm", cpu->cpu_as_root);
+ */
 void cpu_address_space_init(CPUState *cpu, int asidx,
                             const char *prefix, MemoryRegion *mr)
 {
@@ -774,6 +784,14 @@ void cpu_address_space_init(CPUState *cpu, int asidx,
     }
 }
 
+/*
+ * called by:
+ *   - hw/arm/armv7m.c|591| <<armv7m_load_kernel>> as = cpu_get_address_space(cs, asidx);
+ *   - hw/arm/boot.c|59| <<arm_boot_address_space>> return cpu_get_address_space(cs, asidx);
+ *   - target/arm/cpu.h|3327| <<arm_addressspace>> return cpu_get_address_space(cs, arm_asidx_from_attrs(cs, attrs));
+ *   - target/arm/mte_helper.c|206| <<allocation_tag_mem>> tag_as = cpu_get_address_space(env_cpu(env), tag_asi);
+ *   - target/i386/cpu.h|2103| <<cpu_addressspace>> return cpu_get_address_space(cs, cpu_asidx_from_attrs(cs, attrs));
+ */
 AddressSpace *cpu_get_address_space(CPUState *cpu, int asidx)
 {
     /* Return the AddressSpace corresponding to the specified index */
diff --git a/softmmu/runstate.c b/softmmu/runstate.c
index 1e68680b9..4072ddc4b 100644
--- a/softmmu/runstate.c
+++ b/softmmu/runstate.c
@@ -432,6 +432,13 @@ static int qemu_debug_requested(void)
 /*
  * Reset the VM. Issue an event unless @reason is SHUTDOWN_CAUSE_NONE.
  */
+/*
+ * called by:
+ *   - hw/core/machine.c|1460| <<qdev_machine_creation_done>> qemu_system_reset(SHUTDOWN_CAUSE_NONE);
+ *   - hw/i386/xen/xen-hvm.c|1193| <<cpu_handle_ioreq>> qemu_system_reset(request);
+ *   - migration/savevm.c|3061| <<load_snapshot>> qemu_system_reset(SHUTDOWN_CAUSE_NONE);
+ *   - softmmu/runstate.c|694| <<main_loop_should_exit>> qemu_system_reset(request);
+ */
 void qemu_system_reset(ShutdownCause reason)
 {
     MachineClass *mc;
@@ -440,6 +447,9 @@ void qemu_system_reset(ShutdownCause reason)
 
     cpu_synchronize_all_states();
 
+    /*
+     * pc_machine_reset()
+     */
     if (mc && mc->reset) {
         mc->reset(current_machine);
     } else {
diff --git a/softmmu/vl.c b/softmmu/vl.c
index 706bd7cff..02a1a9fbc 100644
--- a/softmmu/vl.c
+++ b/softmmu/vl.c
@@ -178,6 +178,12 @@ static const char *vga_model = NULL;
 static DisplayOptions dpy;
 static int num_serial_hds;
 static Chardev **serial_hds;
+/*
+ * 在以下使用log_mask:
+ *   - softmmu/vl.c|2390| <<qemu_process_early_options>> if (log_mask) {
+ *   - softmmu/vl.c|2391| <<qemu_process_early_options>> mask = qemu_str_to_log_mask(log_mask);
+ *   - softmmu/vl.c|2900| <<qemu_init>> log_mask = optarg;
+ */
 static const char *log_mask;
 static const char *log_file;
 static bool list_data_dirs;
@@ -2355,6 +2361,10 @@ static int process_runstate_actions(void *opaque, QemuOpts *opts, Error **errp)
     return 0;
 }
 
+/*
+ * called by:
+ *   - softmmu/vl.c|3487| <<qemu_init>> qemu_process_early_options();
+ */
 static void qemu_process_early_options(void)
 {
 #ifdef CONFIG_SECCOMP
@@ -2396,6 +2406,10 @@ static void qemu_process_early_options(void)
     qemu_add_default_firmwarepath();
 }
 
+/*
+ * called by:
+ *   - softmmu/vl.c|3499| <<qemu_init>> qemu_process_help_options();
+ */
 static void qemu_process_help_options(void)
 {
     /*
diff --git a/target/i386/cpu-dump.c b/target/i386/cpu-dump.c
index 08ac957e9..3769d44e2 100644
--- a/target/i386/cpu-dump.c
+++ b/target/i386/cpu-dump.c
@@ -97,6 +97,14 @@ static void
 cpu_x86_dump_seg_cache(CPUX86State *env, FILE *f,
                        const char *name, struct SegmentCache *sc)
 {
+    /*
+     * typedef struct SegmentCache {
+     *     uint32_t selector;
+     *     target_ulong base;
+     *     uint32_t limit;
+     *     uint32_t flags;
+     * } SegmentCache;
+     */
 #ifdef TARGET_X86_64
     if (env->hflags & HF_CS64_MASK) {
         qemu_fprintf(f, "%-3s=%04x %016" PRIx64 " %08x %08x", name,
diff --git a/target/i386/cpu.c b/target/i386/cpu.c
index 1db1278a5..66047070c 100644
--- a/target/i386/cpu.c
+++ b/target/i386/cpu.c
@@ -673,6 +673,22 @@ void x86_cpu_vendor_words2str(char *dst, uint32_t vendor1,
 #define TCG_SGX_12_0_EBX_FEATURES 0
 #define TCG_SGX_12_1_EAX_FEATURES 0
 
+/*
+ * 在以下使用feature_word_info[FEATURE_WORDS]:
+ *   - target/i386/cpu-sysemu.c|68| <<x86_cpu_static_props>> FeatureWordInfo *fi = &feature_word_info[w];
+ *   - target/i386/cpu.c|1519| <<x86_cpu_get_migratable_flags>> FeatureWordInfo *wi = &feature_word_info[w];
+ *   - target/i386/cpu.c|4310| <<mark_unavailable_features>> FeatureWordInfo *f = &feature_word_info[w];
+ *   - target/i386/cpu.c|4560| <<x86_cpu_get_feature_words>> FeatureWordInfo *wi = &feature_word_info[w];
+ *   - target/i386/cpu.c|4613| <<x86_cpu_feature_name>> name = feature_word_info[w].feat_names[bitnr];
+ *   - target/i386/cpu.c|4614| <<x86_cpu_feature_name>> assert(bitnr < 32 || !(name && feature_word_info[w].type == CPUID_FEATURE_WORD));
+ *   - target/i386/cpu.c|4896| <<x86_cpu_list>> for (i = 0; i < ARRAY_SIZE(feature_word_info); i++) {
+ *   - target/i386/cpu.c|4897| <<x86_cpu_list>> FeatureWordInfo *fw = &feature_word_info[i];
+ *   - target/i386/cpu.c|4957| <<x86_cpu_get_supported_feature_word>> FeatureWordInfo *wi = &feature_word_info[w];
+ *   - target/i386/cpu.c|6121| <<x86_cpu_adjust_feat_level>> FeatureWordInfo *fi = &feature_word_info[w];
+ *   - target/i386/cpu.c|6125| <<x86_cpu_adjust_feat_level>> assert(feature_word_info[w].type == CPUID_FEATURE_WORD);
+ *   - target/i386/cpu.c|6256| <<x86_cpu_expand_features>> ~feature_word_info[w].no_autoenable_flags;
+ *   - target/i386/cpu.c|6780| <<x86_cpu_register_feature_bit_props>> FeatureWordInfo *fi = &feature_word_info[w];
+ */
 FeatureWordInfo feature_word_info[FEATURE_WORDS] = {
     [FEAT_1_EDX] = {
         .type = CPUID_FEATURE_WORD,
@@ -1533,6 +1549,28 @@ static uint64_t x86_cpu_get_migratable_flags(FeatureWord w)
     return r;
 }
 
+/*
+ * called by:
+ *   - hw/i386/sgx.c|95| <<sgx_calc_host_epc_sections>> host_cpuid(0x12, i + 2, &eax, &ebx, &ecx, &edx);
+ *   - hw/i386/sgx.c|169| <<qmp_query_sgx_capabilities>> host_cpuid(0x7, 0, &eax, &ebx, &ecx, &edx);
+ *   - hw/i386/sgx.c|174| <<qmp_query_sgx_capabilities>> host_cpuid(0x12, 0, &eax, &ebx, &ecx, &edx);
+ *   - target/i386/cpu.c|4992| <<x86_cpu_get_cache_cpuid>> host_cpuid(0, 0, &level, &unused, &unused, &unused);
+ *   - target/i386/cpu.c|4997| <<x86_cpu_get_cache_cpuid>> host_cpuid(0x80000000, 0, &level, &unused, &unused, &unused);
+ *   - target/i386/cpu.c|5009| <<x86_cpu_get_cache_cpuid>> host_cpuid(func, index, eax, ebx, ecx, edx);
+ *   - target/i386/cpu.c|5565| <<cpu_x86_cpuid>> host_cpuid(index, 2, eax, ebx, ecx, edx);
+ *   - target/i386/host-cpu.c|22| <<host_cpu_phys_bits>> host_cpuid(0x80000000, 0, &eax, NULL, NULL, NULL);
+ *   - target/i386/host-cpu.c|24| <<host_cpu_phys_bits>> host_cpuid(0x80000008, 0, &eax, NULL, NULL, NULL);
+ *   - target/i386/host-cpu.c|48| <<host_cpu_enable_cpu_pm>> host_cpuid(5, 0, &cpu->mwait.eax, &cpu->mwait.ebx,
+ *   - target/i386/host-cpu.c|123| <<host_cpu_fill_model_id>> host_cpuid(0x80000002 + i, 0, &eax, &ebx, &ecx, &edx);
+ *   - target/i386/host-cpu.c|136| <<host_cpu_vendor_fms>> host_cpuid(0x0, 0, &eax, &ebx, &ecx, &edx);
+ *   - target/i386/host-cpu.c|139| <<host_cpu_vendor_fms>> host_cpuid(0x1, 0, &eax, &ebx, &ecx, &edx);
+ *   - target/i386/host-cpu.c|159| <<host_cpu_instance_init>> host_cpuid(0, 0, NULL, &ebx, &ecx, &edx);
+ *   - target/i386/hvf/x86_cpuid.c|53| <<hvf_get_supported_cpuid>> host_cpuid(func, idx, &eax, &ebx, &ecx, &edx);
+ *   - target/i386/kvm/kvm-cpu.c|109| <<kvm_cpu_xsave_init>> host_cpuid(0xd, i, &eax, &ebx, &ecx, &edx);
+ *   - target/i386/kvm/kvm.c|5182| <<host_supports_vmx>> host_cpuid(1, 0, &unused, &unused, &ecx, &unused);
+ *   - target/i386/sev.c|607| <<sev_get_capabilities>> host_cpuid(0x8000001F, 0, NULL, &ebx, NULL, NULL);
+ *   - target/i386/sev.c|932| <<sev_kvm_init>> host_cpuid(0x8000001F, 0, NULL, &ebx, NULL, NULL);
+ */
 void host_cpuid(uint32_t function, uint32_t count,
                 uint32_t *eax, uint32_t *ebx, uint32_t *ecx, uint32_t *edx)
 {
@@ -4198,6 +4236,14 @@ static void max_x86_cpu_class_init(ObjectClass *oc, void *data)
     device_class_set_props(dc, max_x86_cpu_properties);
 }
 
+/*
+ * 4282 static const TypeInfo max_x86_cpu_type_info = {
+ * 4283     .name = X86_CPU_TYPE_NAME("max"),
+ * 4284     .parent = TYPE_X86_CPU,
+ * 4285     .instance_init = max_x86_cpu_initfn,
+ * 4286     .class_init = max_x86_cpu_class_init,
+ * 4287 };
+ */
 static void max_x86_cpu_initfn(Object *obj)
 {
     X86CPU *cpu = X86_CPU(obj);
@@ -4206,6 +4252,19 @@ static void max_x86_cpu_initfn(Object *obj)
      * "migratable" is true or false.
      */
     cpu->max_features = true;
+    /*
+     * 在以下使用ArchCPU->enable_pmu:
+     *   - target/i386/cpu.c|6994| <<global>> DEFINE_PROP_BOOL("pmu", X86CPU, enable_pmu, false),
+     *   - target/i386/cpu.c|5286| <<cpu_x86_cpuid>> if (!cpu->enable_pmu) {
+     *   - target/i386/cpu.c|5431| <<cpu_x86_cpuid>> if (accel_uses_host_cpuid() && cpu->enable_pmu) {
+     *   - target/i386/cpu.c|5471| <<cpu_x86_cpuid>> if (accel_uses_host_cpuid() && cpu->enable_pmu &&
+     *   - target/i386/cpu.c|5539| <<cpu_x86_cpuid>> if (kvm_enabled() && cpu->enable_pmu &&
+     *   - target/i386/cpu.c|5547| <<cpu_x86_cpuid>> accel_uses_host_cpuid() && cpu->enable_pmu &&
+     *   - target/i386/cpu.c|6475| <<x86_cpu_realizefn>> if (!cpu->enable_pmu) {
+     *   - target/i386/kvm/kvm.c|3161| <<kvm_init_msrs>> if (has_msr_perf_capabs && cpu->enable_pmu) {
+     *   - target/i386/kvm/kvm.c|3484| <<kvm_put_msrs>> if (kvm_enabled() && cpu->enable_pmu &&
+     *   - target/i386/kvm/kvm.c|3923| <<kvm_get_msrs>> if (kvm_enabled() && cpu->enable_pmu &&
+     */
     object_property_set_bool(OBJECT(cpu), "pmu", true, &error_abort);
 
     /*
@@ -4311,6 +4370,31 @@ static void x86_cpuid_version_get_family(Object *obj, Visitor *v,
     visit_type_int(v, name, &value, errp);
 }
 
+/*
+ * (gdb) bt
+ * #0  x86_cpuid_version_set_family (obj=0x555556aa7340, v=0x555556ab5960, name=0x555556072166 "family", opaque=0x0, errp=0x5555567d3638 <error_abort>) at ../target/i386/cpu.c:4317
+ * #1  0x0000555555d289e7 in object_property_set (obj=0x555556aa7340, name=0x555556072166 "family", v=0x555556ab5960, errp=0x5555567d3638 <error_abort>) at ../qom/object.c:1408
+ * #2  0x0000555555d2cd92 in object_property_set_qobject (obj=0x555556aa7340, name=0x555556072166 "family", value=0x555556ab5930, errp=0x5555567d3638 <error_abort>)
+ *                        at ../qom/qom-qobject.c:28
+ * #3  0x0000555555d28ec3 in object_property_set_int (obj=0x555556aa7340, name=0x555556072166 "family", value=23, errp=0x5555567d3638 <error_abort>) at ../qom/object.c:1509
+ * #4  0x0000555555b5f39b in x86_cpu_load_model (cpu=0x555556aa7340, model=0x55555682c1e0) at ../target/i386/cpu.c:5082
+ * #5  0x0000555555b63e51 in x86_cpu_initfn (obj=0x555556aa7340) at ../target/i386/cpu.c:6800
+ * #6  0x0000555555d26830 in object_init_with_type (obj=0x555556aa7340, ti=0x55555681b560) at ../qom/object.c:377
+ * #7  0x0000555555d26812 in object_init_with_type (obj=0x555556aa7340, ti=0x55555682c3e0) at ../qom/object.c:373
+ * #8  0x0000555555d26d62 in object_initialize_with_type (obj=0x555556aa7340, size=50432, type=0x55555682c3e0) at ../qom/object.c:519
+ * #9  0x0000555555d2746c in object_new_with_type (type=0x55555682c3e0) at ../qom/object.c:734
+ * #10 0x0000555555d274c3 in object_new (typename=0x55555682c560 "EPYC-x86_64-cpu") at ../qom/object.c:749
+ * #11 0x0000555555b22e7f in x86_cpu_new (x86ms=0x555556a53be0, apic_id=0, errp=0x5555567d3640 <error_fatal>) at ../hw/i386/x86.c:97
+ * #12 0x0000555555b22fd2 in x86_cpus_init (x86ms=0x555556a53be0, default_cpu_version=1) at ../hw/i386/x86.c:144
+ * #13 0x0000555555b2ea22 in pc_init1 (machine=0x555556a53be0, host_type=0x555556066191 "i440FX-pcihost", pci_type=0x55555606618a "i440FX") at ../hw/i386/pc_piix.c:159
+ * #14 0x0000555555b2f5f2 in pc_init_v7_1 (machine=0x555556a53be0) at ../hw/i386/pc_piix.c:445
+ * #15 0x00005555558a75be in machine_run_board_init (machine=0x555556a53be0, mem_path=0x0, errp=0x5555567d3640 <error_fatal>) at ../hw/core/machine.c:1400
+ * #16 0x0000555555a8000c in qemu_init_board () at ../softmmu/vl.c:2485
+ * #17 0x0000555555a8027d in qmp_x_exit_preconfig (errp=0x5555567d3640 <error_fatal>) at ../softmmu/vl.c:2581
+ * #18 0x0000555555a8290d in qemu_init (argc=18, argv=0x7fffffffdf08, envp=0x0) at ../softmmu/vl.c:3584
+ * #19 0x000055555581fe5d in qemu_main (argc=18, argv=0x7fffffffdf08, envp=0x0) at ../softmmu/main.c:37
+ * #20 0x000055555581fe94 in main (argc=18, argv=0x7fffffffdf08) at ../softmmu/main.c:47
+ */
 static void x86_cpuid_version_set_family(Object *obj, Visitor *v,
                                          const char *name, void *opaque,
                                          Error **errp)
@@ -4916,6 +5000,13 @@ CpuDefinitionInfoList *qmp_query_cpu_definitions(Error **errp)
     return cpu_list;
 }
 
+/*
+ * called by:
+ *   - target/i386/cpu.c|6278| <<x86_cpu_expand_features>> x86_cpu_get_supported_feature_word(w, cpu->migratable) &
+ *   - target/i386/cpu.c|6398| <<x86_cpu_filter_features>> x86_cpu_get_supported_feature_word(w, false);
+ *   - target/i386/cpu.c|6509| <<x86_cpu_realizefn>> x86_cpu_get_supported_feature_word(FEAT_PERF_CAPABILITIES, false);
+ *   - target/i386/kvm/kvm-cpu.c|105| <<kvm_cpu_xsave_init>> if ((x86_cpu_get_supported_feature_word(esa->feature, false) & esa->bits)
+ */
 uint64_t x86_cpu_get_supported_feature_word(FeatureWord w,
                                             bool migratable_only)
 {
@@ -5878,6 +5969,27 @@ static void x86_cpu_set_sgxlepubkeyhash(CPUX86State *env)
 #endif
 }
 
+/*
+ * (gdb) bt
+ * #0  x86_cpu_reset (dev=0x555556aa6f30) at ../target/i386/cpu.c:5883
+ * #1  0x0000555555d2195c in device_transitional_reset (obj=0x555556aa6f30) at ../hw/core/qdev.c:823
+ * #2  0x0000555555d235c7 in resettable_phase_hold (obj=0x555556aa6f30, opaque=0x0, type=RESET_TYPE_COLD) at ../hw/core/resettable.c:182
+ * #3  0x0000555555d2317f in resettable_assert_reset (obj=0x555556aa6f30, type=RESET_TYPE_COLD) at ../hw/core/resettable.c:60
+ * #4  0x0000555555d230c3 in resettable_reset (obj=0x555556aa6f30, type=RESET_TYPE_COLD) at ../hw/core/resettable.c:45
+ * #5  0x0000555555d205e2 in device_cold_reset (dev=0x555556aa6f30) at ../hw/core/qdev.c:296
+ * #6  0x000055555582049e in cpu_reset (cpu=0x555556aa6f30) at ../hw/core/cpu-common.c:114
+ * #7  0x0000555555b03810 in x86_cpu_machine_reset_cb (opaque=0x555556aa6f30) at ../target/i386/cpu-sysemu.c:250
+ * #8  0x0000555555d21e0b in qemu_devices_reset () at ../hw/core/reset.c:69
+ * #9  0x0000555555b4d111 in pc_machine_reset (machine=0x555556a53be0) at ../hw/i386/pc.c:1851
+ * #10 0x0000555555a798ac in qemu_system_reset (reason=SHUTDOWN_CAUSE_HOST_QMP_SYSTEM_RESET) at ../softmmu/runstate.c:444
+ * #11 0x0000555555a79f75 in main_loop_should_exit (status=0x7fffffffddc4) at ../softmmu/runstate.c:694
+ * #12 0x0000555555a7a06a in qemu_main_loop () at ../softmmu/runstate.c:730
+ * #13 0x000055555581fe62 in qemu_main (argc=18, argv=0x7fffffffdf18, envp=0x0) at ../softmmu/main.c:38
+ * #14 0x000055555581fe94 in main (argc=18, argv=0x7fffffffdf18) at ../softmmu/main.c:47
+ *
+ * 在以下使用x86_cpu_reset():
+ *   - target/i386/cpu.c|7101| <<x86_cpu_common_class_init>> device_class_set_parent_reset(dc, x86_cpu_reset, &xcc->parent_reset);
+ */
 static void x86_cpu_reset(DeviceState *dev)
 {
     CPUState *s = CPU(dev);
@@ -6379,9 +6491,79 @@ static void x86_cpu_hyperv_realize(X86CPU *cpu)
     cpu->hyperv_limits[2] = 0;
 }
 
+/*
+ * (gdb)
+ * #0  x86_cpu_realizefn (dev=0x555556a91910, errp=0x7fffffffd760) at ../target/i386/cpu.c:6383
+ * #1  0x0000555555d21ded in device_set_realized (obj=0x555556a91910, value=true, errp=0x7fffffffd870) at ../hw/core/qdev.c:553
+ * #2  0x0000555555d2b85d in property_set_bool (obj=0x555556a91910, v=0x555556aa09b0, name=0x5555560ba659 "realized", opaque=0x555556851e10, errp=0x7fffffffd870)
+ *                                             at ../qom/object.c:2273
+ * #3  0x0000555555d298a4 in object_property_set (obj=0x555556a91910, name=0x5555560ba659 "realized", v=0x555556aa09b0, errp=0x7fffffffd870) at ../qom/object.c:1408
+ * #4  0x0000555555d2dc4f in object_property_set_qobject (obj=0x555556a91910, name=0x5555560ba659 "realized", value=0x555556848200, errp=0x5555567d4f80 <error_fatal>) at ../qom/qom-qobject.c:28
+ * #5  0x0000555555d29c09 in object_property_set_bool (obj=0x555556a91910, name=0x5555560ba659 "realized", value=true, errp=0x5555567d4f80 <error_fatal>) at ../qom/object.c:1477
+ * #6  0x0000555555d21585 in qdev_realize (dev=0x555556a91910, bus=0x0, errp=0x5555567d4f80 <error_fatal>) at ../hw/core/qdev.c:333
+ * #7  0x0000555555b23c6f in x86_cpu_new (x86ms=0x555556a546e0, apic_id=0, errp=0x5555567d4f80 <error_fatal>) at ../hw/i386/x86.c:102
+ * #8  0x0000555555b23d79 in x86_cpus_init (x86ms=0x555556a546e0, default_cpu_version=1) at ../hw/i386/x86.c:144
+ * #9  0x0000555555b2f7c9 in pc_init1 (machine=0x555556a546e0, host_type=0x555556067d41 "i440FX-pcihost", pci_type=0x555556067d3a "i440FX") at ../hw/i386/pc_piix.c:159
+ * #10 0x0000555555b30399 in pc_init_v7_1 (machine=0x555556a546e0) at ../hw/i386/pc_piix.c:445
+ * #11 0x00005555558a870e in machine_run_board_init (machine=0x555556a546e0, mem_path=0x0, errp=0x5555567d4f80 <error_fatal>) at ../hw/core/machine.c:1400
+ * #12 0x0000555555a80fcc in qemu_init_board () at ../softmmu/vl.c:2492
+ * #13 0x0000555555a8123d in qmp_x_exit_preconfig (errp=0x5555567d4f80 <error_fatal>) at ../softmmu/vl.c:2588
+ * #14 0x0000555555a83915 in qemu_init (argc=15, argv=0x7fffffffdee8, envp=0x0) at ../softmmu/vl.c:3591
+ * #15 0x0000555555820fad in qemu_main (argc=15, argv=0x7fffffffdee8, envp=0x0) at ../softmmu/main.c:37
+ * #16 0x0000555555820fe4 in main (argc=15, argv=0x7fffffffdee8) at ../softmmu/main.c:47
+ *
+ * (gdb) bt
+ * #0  x86_cpu_realizefn (dev=0x555556db8000, errp=0x7fffffffc5d0) at ../target/i386/cpu.c:6383
+ * #1  0x0000555555d20f30 in device_set_realized (obj=0x555556db8000, value=true, errp=0x7fffffffc910) at ../hw/core/qdev.c:553
+ * #2  0x0000555555d2a9a0 in property_set_bool (obj=0x555556db8000, v=0x555557088ad0, name=0x5555560b94a1 "realized", opaque=0x555556851b60, errp=0x7fffffffc910) at ../qom/object.c:2273
+ * #3  0x0000555555d289e7 in object_property_set (obj=0x555556db8000, name=0x5555560b94a1 "realized", v=0x555557088ad0, errp=0x7fffffffc910) at ../qom/object.c:1408
+ * #4  0x0000555555d2cd92 in object_property_set_qobject (obj=0x555556db8000, name=0x5555560b94a1 "realized", value=0x5555575438b0, errp=0x7fffffffc910) at ../qom/qom-qobject.c:28
+ * #5  0x0000555555d28d4c in object_property_set_bool (obj=0x555556db8000, name=0x5555560b94a1 "realized", value=true, errp=0x7fffffffc910) at ../qom/object.c:1477
+ * #6  0x0000555555d206c8 in qdev_realize (dev=0x555556db8000, bus=0x0, errp=0x7fffffffc910) at ../hw/core/qdev.c:333
+ * #7  0x0000555555a7768e in qdev_device_add_from_qdict (opts=0x5555570edc80, from_json=false, errp=0x7fffffffc910) at ../softmmu/qdev-monitor.c:714
+ * #8  0x0000555555a7772c in qdev_device_add (opts=0x55555684aa00, errp=0x7fffffffc910) at ../softmmu/qdev-monitor.c:733
+ * #9  0x0000555555a77d40 in qmp_device_add (qdict=0x5555577deb30, ret_data=0x0, errp=0x7fffffffc910) at ../softmmu/qdev-monitor.c:855
+ * #10 0x0000555555a78150 in hmp_device_add (mon=0x555556847f00, qdict=0x5555577deb30) at ../softmmu/qdev-monitor.c:963
+ * #11 0x0000555555accc3e in handle_hmp_command_exec (mon=0x555556847f00, cmd=0x5555566fb220 <hmp_cmds+1920>, qdict=0x5555577deb30) at ../monitor/hmp.c:1103
+ * #12 0x0000555555acce6b in handle_hmp_command (mon=0x555556847f00, cmdline=0x555556ac2f1b "host-x86_64-cpu,id=core4,socket-id=0,core-id=4,thread-id=0") at ../monitor/hmp.c:1155
+ * #13 0x0000555555aca384 in monitor_command_cb (opaque=0x555556847f00, cmdline=0x555556ac2f10 "device_add host-x86_64-cpu,id=core4,socket-id=0,core-id=4,thread-id=0", readline_opaque=0x0) at ../monitor/hmp.c:49
+ * #14 0x0000555555f195dd in readline_handle_byte (rs=0x555556ac2f10, ch=13) at ../util/readline.c:411
+ * #15 0x0000555555acd9a8 in monitor_read (opaque=0x555556847f00, buf=0x7fffffffcb70 "\r\321\377\377\377\177", size=1) at ../monitor/hmp.c:1393
+ * #16 0x0000555555e31613 in qemu_chr_be_write_impl (s=0x555556a68c60, buf=0x7fffffffcb70 "\r\321\377\377\377\177", len=1) at ../chardev/char.c:201
+ * #17 0x0000555555e31677 in qemu_chr_be_write (s=0x555556a68c60, buf=0x7fffffffcb70 "\r\321\377\377\377\177", len=1) at ../chardev/char.c:213
+ * #18 0x0000555555e340a4 in fd_chr_read (chan=0x555556a68d20, cond=G_IO_IN, opaque=0x555556a68c60) at ../chardev/char-fd.c:72
+ * #19 0x0000555555d335b4 in qio_channel_fd_source_dispatch (source=0x5555570ddff0, callback=0x555555e33f7a <fd_chr_read>, user_data=0x555556a68c60) at ../io/channel-watch.c:84
+ * #20 0x00007ffff6c40119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #21 0x0000555555f12010 in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #22 0x0000555555f1208a in os_host_main_loop_wait (timeout=55505906) at ../util/main-loop.c:320
+ * #23 0x0000555555f1218f in main_loop_wait (nonblocking=0) at ../util/main-loop.c:596
+ * #24 0x0000555555a7a05e in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #25 0x000055555581fe62 in qemu_main (argc=26, argv=0x7fffffffde58, envp=0x0) at ../softmmu/main.c:38
+ * #26 0x000055555581fe94 in main (argc=26, argv=0x7fffffffde58) at ../softmmu/main.c:47
+ */
 static void x86_cpu_realizefn(DeviceState *dev, Error **errp)
 {
     CPUState *cs = CPU(dev);
+    /*
+     * struct ArchCPU {
+     *   //< private >
+     *   CPUState parent_obj;
+     *   {
+     *       //< private >
+     *       DeviceState parent_obj;
+     *         -> Object parent_obj;
+     *       //< public >
+     *
+     *       int nr_cores;
+     *       int nr_threads;
+     *   }
+     *   //< public >
+     *
+     *   CPUNegativeOffsetState neg;
+     *   CPUX86State env;
+     *     -> bool tsc_valid;
+     *   VMChangeStateEntry *vmsentry;
+     */
     X86CPU *cpu = X86_CPU(dev);
     X86CPUClass *xcc = X86_CPU_GET_CLASS(dev);
     CPUX86State *env = &cpu->env;
@@ -6627,6 +6809,34 @@ out:
     }
 }
 
+/*
+ * (gdb) bt
+ * #0  x86_cpu_unrealizefn (dev=0x555556db8000) at ../target/i386/cpu.c:6632
+ * #1  0x0000555555d21235 in device_set_realized (obj=0x555556db8000, value=false, errp=0x5555567d3638 <error_abort>) at ../hw/core/qdev.c:642
+ * #2  0x0000555555d2a9a0 in property_set_bool (obj=0x555556db8000, v=0x7ffe60008e80, name=0x5555560b94a1 "realized", opaque=0x555556851b60, errp=0x5555567d3638 <error_abort>) at ../qom/object.c:2273
+ * #3  0x0000555555d289e7 in object_property_set (obj=0x555556db8000, name=0x5555560b94a1 "realized", v=0x7ffe60008e80, errp=0x5555567d3638 <error_abort>) at ../qom/object.c:1408
+ * #4  0x0000555555d2cd92 in object_property_set_qobject (obj=0x555556db8000, name=0x5555560b94a1 "realized", value=0x7ffe60006fe0, errp=0x5555567d3638 <error_abort>) at ../qom/qom-qobject.c:28
+ * #5  0x0000555555d28d4c in object_property_set_bool (obj=0x555556db8000, name=0x5555560b94a1 "realized", value=false, errp=0x5555567d3638 <error_abort>) at ../qom/object.c:1477
+ * #6  0x0000555555d20735 in qdev_unrealize (dev=0x555556db8000) at ../hw/core/qdev.c:347
+ * #7  0x0000555555b234b9 in x86_cpu_unplug_cb (hotplug_dev=0x555556a543d0, dev=0x555556db8000, errp=0x0) at ../hw/i386/x86.c:257
+ * #8  0x0000555555b4c721 in pc_machine_device_unplug_cb (hotplug_dev=0x555556a543d0, dev=0x555556db8000, errp=0x0) at ../hw/i386/pc.c:1591
+ * #9  0x0000555555d253cc in hotplug_handler_unplug (plug_handler=0x555556a543d0, plugged_dev=0x555556db8000, errp=0x0) at ../hw/core/hotplug.c:56
+ * #10 0x000055555585deaa in cpu_hotplug_wr (opaque=0x55555778f390, addr=4, data=8, size=1) at ../hw/acpi/cpu.c:146
+ * #11 0x0000555555c650a3 in memory_region_write_accessor (mr=0x55555778f390, addr=4, value=0x7ffe6ddfd6a8, size=1, shift=0, mask=255, attrs=...) at ../softmmu/memory.c:492
+ * #12 0x0000555555c652e7 in access_with_adjusted_size (addr=4, value=0x7ffe6ddfd6a8, size=1, access_size_min=1, access_size_max=4, access_fn=
+ *     0x555555c64fad <memory_region_write_accessor>, mr=0x55555778f390, attrs=...) at ../softmmu/memory.c:554
+ * #13 0x0000555555c683dd in memory_region_dispatch_write (mr=0x55555778f390, addr=4, data=8, op=MO_8, attrs=...) at ../softmmu/memory.c:1514
+ * #14 0x0000555555c758f6 in flatview_write_continue (fv=0x7ffe600660f0, addr=44804, attrs=..., ptr=0x7ffff7ff0000, len=1, addr1=4, l=1, mr=0x55555778f390) at ../softmmu/physmem.c:2825
+ * #15 0x0000555555c75a59 in flatview_write (fv=0x7ffe600660f0, addr=44804, attrs=..., buf=0x7ffff7ff0000, len=1) at ../softmmu/physmem.c:2867
+ * #16 0x0000555555c75e09 in address_space_write (as=0x5555567b5420 <address_space_io>, addr=44804, attrs=..., buf=0x7ffff7ff0000, len=1) at ../softmmu/physmem.c:2963
+ * #17 0x0000555555c75e76 in address_space_rw (as=0x5555567b5420 <address_space_io>, addr=44804, attrs=..., buf=0x7ffff7ff0000, len=1, is_write=true) at ../softmmu/physmem.c:2973
+ * #18 0x0000555555d0db63 in kvm_handle_io (port=44804, attrs=..., data=0x7ffff7ff0000, direction=1, size=1, count=1) at ../accel/kvm/kvm-all.c:2693
+ * #19 0x0000555555d0e2dd in kvm_cpu_exec (cpu=0x555556b011e0) at ../accel/kvm/kvm-all.c:2944
+ * #20 0x0000555555d10faa in kvm_vcpu_thread_fn (arg=0x555556b011e0) at ../accel/kvm/kvm-accel-ops.c:49
+ * #21 0x0000555555eec4de in qemu_thread_start (args=0x555556b10400) at ../util/qemu-thread-posix.c:504
+ * #22 0x00007ffff55eeea5 in start_thread () at /lib64/libpthread.so.0
+ * #23 0x00007ffff53179fd in clone () at /lib64/libc.so.6
+ */
 static void x86_cpu_unrealizefn(DeviceState *dev)
 {
     X86CPU *cpu = X86_CPU(dev);
diff --git a/target/i386/cpu.h b/target/i386/cpu.h
index 82004b65b..ea61e0d36 100644
--- a/target/i386/cpu.h
+++ b/target/i386/cpu.h
@@ -428,8 +428,21 @@ typedef enum X86Seg {
 #define MSR_MCG_CTL                     0x17b
 #define MSR_MCG_EXT_CTL                 0x4d0
 
+/*
+ * 在以下使用MSR_P6_EVNTSEL0:
+ *   - target/i386/cpu.h|1319| <<MAX_GP_COUNTERS>> #define MAX_GP_COUNTERS (MSR_IA32_PERF_STATUS - MSR_P6_EVNTSEL0)
+ *   - target/i386/kvm/kvm.c|3380| <<kvm_put_msrs>> kvm_msr_entry_add(cpu, MSR_P6_EVNTSEL0 + i,
+ *   - target/i386/kvm/kvm.c|3880| <<kvm_get_msrs>> kvm_msr_entry_add(cpu, MSR_P6_EVNTSEL0 + i, 0);
+ *   - target/i386/kvm/kvm.c|4166| <<kvm_get_msrs>> case MSR_P6_EVNTSEL0 ... MSR_P6_EVNTSEL0 + MAX_GP_COUNTERS - 1:
+ *   - target/i386/kvm/kvm.c|4167| <<kvm_get_msrs>> env->msr_gp_evtsel[index - MSR_P6_EVNTSEL0] = msrs[i].data;
+ */
 #define MSR_P6_EVNTSEL0                 0x186
 
+/*
+ * 在以下使用MSR_IA32_PERF_STATUS:
+ *   - target/i386/cpu.h|1327| <<MAX_GP_COUNTERS>> #define MAX_GP_COUNTERS (MSR_IA32_PERF_STATUS - MSR_P6_EVNTSEL0)
+ *   - target/i386/tcg/sysemu/misc_helper.c|346| <<helper_rdmsr>> case MSR_IA32_PERF_STATUS:
+ */
 #define MSR_IA32_PERF_STATUS            0x198
 
 #define MSR_IA32_MISC_ENABLE            0x1a0
@@ -948,6 +961,15 @@ uint64_t x86_cpu_get_supported_feature_word(FeatureWord w,
 #define IS_INTEL_CPU(env) ((env)->cpuid_vendor1 == CPUID_VENDOR_INTEL_1 && \
                            (env)->cpuid_vendor2 == CPUID_VENDOR_INTEL_2 && \
                            (env)->cpuid_vendor3 == CPUID_VENDOR_INTEL_3)
+/*
+ * 在以下使用IS_AMD_CPU():
+ *   - hw/i386/pc.c|957| <<pc_memory_init>> if (IS_AMD_CPU(&cpu->env) && pcmc->enforce_amd_1tb_hole) {
+ *   - target/i386/cpu.c|5273| <<cpu_x86_cpuid>> } else if (cpu->vendor_cpuid_only && IS_AMD_CPU(env)) {
+ *   - target/i386/cpu.c|5309| <<cpu_x86_cpuid>> } else if (cpu->vendor_cpuid_only && IS_AMD_CPU(env)) {
+ *   - target/i386/cpu.c|6478| <<x86_cpu_realizefn>> if (IS_AMD_CPU(env)) {
+ *   - target/i386/cpu.c|6510| <<x86_cpu_realizefn>> if (IS_AMD_CPU(env)) {
+ *   - target/i386/cpu.c|6623| <<x86_cpu_realizefn>> if (IS_AMD_CPU(env) &&
+ */
 #define IS_AMD_CPU(env) ((env)->cpuid_vendor1 == CPUID_VENDOR_AMD_1 && \
                          (env)->cpuid_vendor2 == CPUID_VENDOR_AMD_2 && \
                          (env)->cpuid_vendor3 == CPUID_VENDOR_AMD_3)
@@ -1306,7 +1328,28 @@ typedef struct {
 #define CPU_NB_REGS CPU_NB_REGS32
 #endif
 
+/*
+ * 在以下使用MAX_FIXED_COUNTERS:
+ *   - target/i386/machine.c|686| <<global>> VMSTATE_UINT64_ARRAY(env.msr_fixed_counters, X86CPU, MAX_FIXED_COUNTERS),
+ *   - target/i386/cpu.h|1616| <<MMREG_UNION>> uint64_t msr_fixed_counters[MAX_FIXED_COUNTERS];
+ *   - target/i386/kvm/kvm.c|2009| <<kvm_arch_init_vcpu>> if (num_architectural_pmu_fixed_counters > MAX_FIXED_COUNTERS) {
+ *   - target/i386/kvm/kvm.c|2010| <<kvm_arch_init_vcpu>> num_architectural_pmu_fixed_counters = MAX_FIXED_COUNTERS;
+ *   - target/i386/kvm/kvm.c|4160| <<kvm_get_msrs>> case MSR_CORE_PERF_FIXED_CTR0 ... MSR_CORE_PERF_FIXED_CTR0 + MAX_FIXED_COUNTERS - 1:
+ *   - target/i386/machine.c|655| <<pmu_enable_needed>> for (i = 0; i < MAX_FIXED_COUNTERS; i++) {
+ */
 #define MAX_FIXED_COUNTERS 3
+/*
+ * 在以下使用MAX_GP_COUNTERS:
+ *   - target/i386/machine.c|687| <<global>> VMSTATE_UINT64_ARRAY(env.msr_gp_counters, X86CPU, MAX_GP_COUNTERS),
+ *   - target/i386/machine.c|688| <<global>> VMSTATE_UINT64_ARRAY(env.msr_gp_evtsel, X86CPU, MAX_GP_COUNTERS),
+ *   - target/i386/cpu.h|1617| <<MMREG_UNION>> uint64_t msr_gp_counters[MAX_GP_COUNTERS];
+ *   - target/i386/cpu.h|1625| <<MMREG_UNION>> uint64_t msr_gp_evtsel[MAX_GP_COUNTERS];
+ *   - target/i386/kvm/kvm.c|2002| <<kvm_arch_init_vcpu>> if (num_architectural_pmu_gp_counters > MAX_GP_COUNTERS) {
+ *   - target/i386/kvm/kvm.c|2003| <<kvm_arch_init_vcpu>> num_architectural_pmu_gp_counters = MAX_GP_COUNTERS;
+ *   - target/i386/kvm/kvm.c|4163| <<kvm_get_msrs>> case MSR_P6_PERFCTR0 ... MSR_P6_PERFCTR0 + MAX_GP_COUNTERS - 1:
+ *   - target/i386/kvm/kvm.c|4166| <<kvm_get_msrs>> case MSR_P6_EVNTSEL0 ... MSR_P6_EVNTSEL0 + MAX_GP_COUNTERS - 1:
+ *   - target/i386/machine.c|667| <<pmu_enable_needed>> for (i = 0; i < MAX_GP_COUNTERS; i++) {
+ */
 #define MAX_GP_COUNTERS    (MSR_IA32_PERF_STATUS - MSR_P6_EVNTSEL0)
 
 #define TARGET_INSN_START_EXTRA_WORDS 1
@@ -1598,6 +1641,13 @@ typedef struct CPUArchState {
     uint64_t msr_global_ovf_ctrl;
     uint64_t msr_fixed_counters[MAX_FIXED_COUNTERS];
     uint64_t msr_gp_counters[MAX_GP_COUNTERS];
+    /*
+     * 在以下使用CPUArchState->msr_gp_evtsel[MAX_GP_COUNTERS]:
+     *   - target/i386/machine.c|678| <<global>> VMSTATE_UINT64_ARRAY(env.msr_gp_evtsel, X86CPU, MAX_GP_COUNTERS),
+     *   - target/i386/kvm/kvm.c|3314| <<kvm_put_msrs>> env->msr_gp_evtsel[i]);
+     *   - target/i386/kvm/kvm.c|4088| <<kvm_get_msrs>> env->msr_gp_evtsel[index - MSR_P6_EVNTSEL0] = msrs[i].data;
+     *   - target/i386/machine.c|658| <<pmu_enable_needed>> if (env->msr_gp_counters[i] || env->msr_gp_evtsel[i]) {
+     */
     uint64_t msr_gp_evtsel[MAX_GP_COUNTERS];
 
     uint64_t pat;
@@ -1713,6 +1763,29 @@ typedef struct CPUArchState {
     uint32_t cpuid_vendor1;
     uint32_t cpuid_vendor2;
     uint32_t cpuid_vendor3;
+    /*
+     * 在以下使用CPUArchState->cpuid_version:
+     *   - hw/i386/fw_cfg.c|61| <<fw_cfg_build_smbios>> smbios_set_cpuid(cpu->env.cpuid_version, cpu->env.features[FEAT_1_EDX]);
+     *   - target/i386/cpu.c|4366| <<x86_cpuid_version_get_family>> value = (env->cpuid_version >> 8) & 0xf;
+     *   - target/i386/cpu.c|4368| <<x86_cpuid_version_get_family>> value += (env->cpuid_version >> 20) & 0xff;
+     *   - target/i386/cpu.c|4392| <<x86_cpuid_version_set_family>> env->cpuid_version &= ~0xff00f00;
+     *   - target/i386/cpu.c|4394| <<x86_cpuid_version_set_family>> env->cpuid_version |= 0xf00 | ((value - 0x0f) << 20);
+     *   - target/i386/cpu.c|4396| <<x86_cpuid_version_set_family>> env->cpuid_version |= value << 8;
+     *   - target/i386/cpu.c|4408| <<x86_cpuid_version_get_model>> value = (env->cpuid_version >> 4) & 0xf;
+     *   - target/i386/cpu.c|4409| <<x86_cpuid_version_get_model>> value |= ((env->cpuid_version >> 16) & 0xf) << 4;
+     *   - target/i386/cpu.c|4432| <<x86_cpuid_version_set_model>> env->cpuid_version &= ~0xf00f0;
+     *   - target/i386/cpu.c|4433| <<x86_cpuid_version_set_model>> env->cpuid_version |= ((value & 0xf) << 4) | ((value >> 4) << 16);
+     *   - target/i386/cpu.c|4444| <<x86_cpuid_version_get_stepping>> value = env->cpuid_version & 0xf;
+     *   - target/i386/cpu.c|4467| <<x86_cpuid_version_set_stepping>> env->cpuid_version &= ~0xf;
+     *   - target/i386/cpu.c|4468| <<x86_cpuid_version_set_stepping>> env->cpuid_version |= value & 0xf;
+     *   - target/i386/cpu.c|5318| <<cpu_x86_cpuid>> *eax = env->cpuid_version;
+     *   - target/i386/cpu.c|5759| <<cpu_x86_cpuid>> *eax = env->cpuid_version;
+     *   - target/i386/cpu.c|5903| <<cpu_x86_cpuid>> *eax = env->cpuid_version;
+     *   - target/i386/cpu.c|6022| <<x86_cpu_reset>> env->regs[R_EDX] = env->cpuid_version;
+     *   - target/i386/cpu.c|6129| <<mce_init>> if (((cenv->cpuid_version >> 8) & 0xf) >= 6
+     *   - target/i386/helper.c|64| <<cpu_x86_version>> int cpuver = env->cpuid_version;
+     *   - target/i386/kvm/kvm.c|2128| <<kvm_arch_init_vcpu>> if (((env->cpuid_version >> 8)&0xF) >= 6
+     */
     uint32_t cpuid_version;
     FeatureWordArray features;
     /* Features that were explicitly enabled/disabled */
@@ -1855,6 +1928,19 @@ struct ArchCPU {
      * bits returned by GET_SUPPORTED_CPUID (that depend on host CPU and kernel
      * capabilities) directly to the guest.
      */
+    /*
+     * 在以下使用ArchCPU->enable_pmu:
+     *   - target/i386/cpu.c|6994| <<global>> DEFINE_PROP_BOOL("pmu", X86CPU, enable_pmu, false),
+     *   - target/i386/cpu.c|5286| <<cpu_x86_cpuid>> if (!cpu->enable_pmu) {
+     *   - target/i386/cpu.c|5431| <<cpu_x86_cpuid>> if (accel_uses_host_cpuid() && cpu->enable_pmu) {
+     *   - target/i386/cpu.c|5471| <<cpu_x86_cpuid>> if (accel_uses_host_cpuid() && cpu->enable_pmu &&
+     *   - target/i386/cpu.c|5539| <<cpu_x86_cpuid>> if (kvm_enabled() && cpu->enable_pmu &&
+     *   - target/i386/cpu.c|5547| <<cpu_x86_cpuid>> accel_uses_host_cpuid() && cpu->enable_pmu &&
+     *   - target/i386/cpu.c|6475| <<x86_cpu_realizefn>> if (!cpu->enable_pmu) {
+     *   - target/i386/kvm/kvm.c|3161| <<kvm_init_msrs>> if (has_msr_perf_capabs && cpu->enable_pmu) {
+     *   - target/i386/kvm/kvm.c|3484| <<kvm_put_msrs>> if (kvm_enabled() && cpu->enable_pmu &&
+     *   - target/i386/kvm/kvm.c|3923| <<kvm_get_msrs>> if (kvm_enabled() && cpu->enable_pmu &&
+     */
     bool enable_pmu;
 
     /*
@@ -2098,6 +2184,18 @@ static inline int x86_asidx_from_attrs(CPUState *cs, MemTxAttrs attrs)
     return !!attrs.secure;
 }
 
+/*
+ * called by:
+ *   - target/i386/helper.c|602| <<x86_ldub_phys>> AddressSpace *as = cpu_addressspace(cs, attrs);
+ *   - target/i386/helper.c|612| <<x86_lduw_phys>> AddressSpace *as = cpu_addressspace(cs, attrs);
+ *   - target/i386/helper.c|622| <<x86_ldl_phys>> AddressSpace *as = cpu_addressspace(cs, attrs);
+ *   - target/i386/helper.c|632| <<x86_ldq_phys>> AddressSpace *as = cpu_addressspace(cs, attrs);
+ *   - target/i386/helper.c|642| <<x86_stb_phys>> AddressSpace *as = cpu_addressspace(cs, attrs);
+ *   - target/i386/helper.c|652| <<x86_stl_phys_notdirty>> AddressSpace *as = cpu_addressspace(cs, attrs);
+ *   - target/i386/helper.c|662| <<x86_stw_phys>> AddressSpace *as = cpu_addressspace(cs, attrs);
+ *   - target/i386/helper.c|672| <<x86_stl_phys>> AddressSpace *as = cpu_addressspace(cs, attrs);
+ *   - target/i386/helper.c|682| <<x86_stq_phys>> AddressSpace *as = cpu_addressspace(cs, attrs);
+ */
 static inline AddressSpace *cpu_addressspace(CPUState *cs, MemTxAttrs attrs)
 {
     return cpu_get_address_space(cs, cpu_asidx_from_attrs(cs, attrs));
diff --git a/target/i386/host-cpu.c b/target/i386/host-cpu.c
index 10f8aba86..d357a1dd3 100644
--- a/target/i386/host-cpu.c
+++ b/target/i386/host-cpu.c
@@ -80,6 +80,11 @@ static uint32_t host_cpu_adjust_phys_bits(X86CPU *cpu)
     return phys_bits;
 }
 
+/*
+ * 在以下使用host_cpu_realizefn():
+ *   - target/i386/hvf/hvf-cpu.c|80| <<hvf_cpu_accel_class_init>> acc->cpu_realizefn = host_cpu_realizefn;
+ *   - target/i386/kvm/kvm-cpu.c|52| <<kvm_cpu_realizefn>> return host_cpu_realizefn(cs, errp);
+ */
 bool host_cpu_realizefn(CPUState *cs, Error **errp)
 {
     X86CPU *cpu = X86_CPU(cs);
@@ -193,6 +198,28 @@ static void host_cpu_class_init(ObjectClass *oc, void *data)
         g_strdup_printf("processor with all supported host features ");
 }
 
+/*
+ * 在以下使用ArchCPU->enable_pmu:
+ *   - target/i386/cpu.c|6994| <<global>> DEFINE_PROP_BOOL("pmu", X86CPU, enable_pmu, false),
+ *   - target/i386/cpu.c|5286| <<cpu_x86_cpuid>> if (!cpu->enable_pmu) {
+ *   - target/i386/cpu.c|5431| <<cpu_x86_cpuid>> if (accel_uses_host_cpuid() && cpu->enable_pmu) {
+ *   - target/i386/cpu.c|5471| <<cpu_x86_cpuid>> if (accel_uses_host_cpuid() && cpu->enable_pmu &&
+ *   - target/i386/cpu.c|5539| <<cpu_x86_cpuid>> if (kvm_enabled() && cpu->enable_pmu &&
+ *   - target/i386/cpu.c|5547| <<cpu_x86_cpuid>> accel_uses_host_cpuid() && cpu->enable_pmu &&
+ *   - target/i386/cpu.c|6475| <<x86_cpu_realizefn>> if (!cpu->enable_pmu) {
+ *   - target/i386/kvm/kvm.c|3161| <<kvm_init_msrs>> if (has_msr_perf_capabs && cpu->enable_pmu) {
+ *   - target/i386/kvm/kvm.c|3484| <<kvm_put_msrs>> if (kvm_enabled() && cpu->enable_pmu &&
+ *   - target/i386/kvm/kvm.c|3923| <<kvm_get_msrs>> if (kvm_enabled() && cpu->enable_pmu &&
+ *
+ * 关于.parent = X86_CPU_TYPE_NAME("max"),
+ *
+ * 4253 static const TypeInfo max_x86_cpu_type_info = {
+ * 4254     .name = X86_CPU_TYPE_NAME("max"),
+ * 4255     .parent = TYPE_X86_CPU,
+ * 4256     .instance_init = max_x86_cpu_initfn,
+ * 4257     .class_init = max_x86_cpu_class_init,
+ * 4258 };
+ */
 static const TypeInfo host_cpu_type_info = {
     .name = X86_CPU_TYPE_NAME("host"),
     .parent = X86_CPU_TYPE_NAME("max"),
diff --git a/target/i386/kvm/kvm-cpu.c b/target/i386/kvm/kvm-cpu.c
index 7237378a7..68c1db7a0 100644
--- a/target/i386/kvm/kvm-cpu.c
+++ b/target/i386/kvm/kvm-cpu.c
@@ -193,6 +193,16 @@ static void kvm_cpu_accel_class_init(ObjectClass *oc, void *data)
     acc->cpu_realizefn = kvm_cpu_realizefn;
     acc->cpu_instance_init = kvm_cpu_instance_init;
 }
+/*
+ * 在以下使用TYPE_ACCEL_CPU:
+ *   - include/hw/core/accel-cpu.h|23| <<global>> #define TYPE_ACCEL_CPU "accel-" CPU_RESOLVING_TYPE
+ *   - accel/accel-common.c|133| <<global>> .name = TYPE_ACCEL_CPU,
+ *   - target/i386/hvf/hvf-cpu.c|87| <<global>> .parent = TYPE_ACCEL_CPU,
+ *   - target/i386/kvm/kvm-cpu.c|199| <<global>> .parent = TYPE_ACCEL_CPU,
+ *   - target/i386/tcg/tcg-cpu.c|152| <<global>> .parent = TYPE_ACCEL_CPU,
+ *   - include/hw/core/accel-cpu.h|24| <<ACCEL_CPU_NAME>> #define ACCEL_CPU_NAME(name) (name "-" TYPE_ACCEL_CPU)
+ *   - include/hw/core/accel-cpu.h|26| <<DECLARE_CLASS_CHECKERS>> DECLARE_CLASS_CHECKERS(AccelCPUClass, ACCEL_CPU, TYPE_ACCEL_CPU)
+ */
 static const TypeInfo kvm_cpu_accel_type_info = {
     .name = ACCEL_CPU_NAME("kvm"),
 
diff --git a/target/i386/kvm/kvm.c b/target/i386/kvm/kvm.c
index f148a6d52..878ddf853 100644
--- a/target/i386/kvm/kvm.c
+++ b/target/i386/kvm/kvm.c
@@ -119,11 +119,43 @@ static bool has_msr_core_capabs;
 static bool has_msr_vmx_vmfunc;
 static bool has_msr_ucode_rev;
 static bool has_msr_vmx_procbased_ctls2;
+/*
+ * 在以下使用has_msr_perf_capabs:
+ *   - target/i386/kvm/kvm.c|2410| <<kvm_get_supported_msrs>> has_msr_perf_capabs = true;
+ *   - target/i386/kvm/kvm.c|3161| <<kvm_init_msrs>> if (has_msr_perf_capabs && cpu->enable_pmu) {
+ */
 static bool has_msr_perf_capabs;
 static bool has_msr_pkrs;
 
+/*
+ * 在以下使用has_architectural_pmu_version:
+ *   - target/i386/kvm/kvm.c|1939| <<kvm_arch_init_vcpu>> has_architectural_pmu_version = eax & 0xff;
+ *   - target/i386/kvm/kvm.c|1940| <<kvm_arch_init_vcpu>> if (has_architectural_pmu_version > 0) {
+ *   - target/i386/kvm/kvm.c|1951| <<kvm_arch_init_vcpu>> if (has_architectural_pmu_version > 1) {
+ *   - target/i386/kvm/kvm.c|3256| <<kvm_put_msrs>> if (has_architectural_pmu_version > 0) {
+ *   - target/i386/kvm/kvm.c|3257| <<kvm_put_msrs>> if (has_architectural_pmu_version > 1) {
+ *   - target/i386/kvm/kvm.c|3274| <<kvm_put_msrs>> if (has_architectural_pmu_version > 1) {
+ *   - target/i386/kvm/kvm.c|3747| <<kvm_get_msrs>> if (has_architectural_pmu_version > 0) {
+ *   - target/i386/kvm/kvm.c|3748| <<kvm_get_msrs>> if (has_architectural_pmu_version > 1) {
+ */
 static uint32_t has_architectural_pmu_version;
+/*
+ * 在以下使用num_architectural_pmu_gp_counters:
+ *   - target/i386/kvm/kvm.c|1941| <<kvm_arch_init_vcpu>> num_architectural_pmu_gp_counters = (eax & 0xff00) >> 8;
+ *   - target/i386/kvm/kvm.c|1947| <<kvm_arch_init_vcpu>> if (num_architectural_pmu_gp_counters > MAX_GP_COUNTERS) {
+ *   - target/i386/kvm/kvm.c|1948| <<kvm_arch_init_vcpu>> num_architectural_pmu_gp_counters = MAX_GP_COUNTERS;
+ *   - target/i386/kvm/kvm.c|3268| <<kvm_put_msrs>> for (i = 0; i < num_architectural_pmu_gp_counters; i++) {
+ *   - target/i386/kvm/kvm.c|3757| <<kvm_get_msrs>> for (i = 0; i < num_architectural_pmu_gp_counters; i++) {
+ */
 static uint32_t num_architectural_pmu_gp_counters;
+/*
+ * 在以下使用num_architectural_pmu_fixed_counters:
+ *   - target/i386/kvm/kvm.c|1986| <<kvm_arch_init_vcpu>> num_architectural_pmu_fixed_counters = edx & 0x1f;
+ *   - target/i386/kvm/kvm.c|1988| <<kvm_arch_init_vcpu>> if (num_architectural_pmu_fixed_counters > MAX_FIXED_COUNTERS) {
+ *   - target/i386/kvm/kvm.c|1989| <<kvm_arch_init_vcpu>> num_architectural_pmu_fixed_counters = MAX_FIXED_COUNTERS;
+ *   - target/i386/kvm/kvm.c|3298| <<kvm_put_msrs>> for (i = 0; i < num_architectural_pmu_fixed_counters; i++) {
+ *   - target/i386/kvm/kvm.c|3788| <<kvm_get_msrs>> for (i = 0; i < num_architectural_pmu_fixed_counters; i++) {
+ */
 static uint32_t num_architectural_pmu_fixed_counters;
 
 static int has_xsave;
@@ -246,6 +278,10 @@ void kvm_synchronize_all_tsc(void)
     }
 }
 
+/*
+ * called by:
+ *   - target/i386/kvm/kvm.c|317| <<get_supported_cpuid>> while ((cpuid = try_get_cpuid(s, max)) == NULL) {
+ */
 static struct kvm_cpuid2 *try_get_cpuid(KVMState *s, int max)
 {
     struct kvm_cpuid2 *cpuid;
@@ -274,6 +310,10 @@ static struct kvm_cpuid2 *try_get_cpuid(KVMState *s, int max)
 /* Run KVM_GET_SUPPORTED_CPUID ioctl(), allocating a buffer large enough
  * for all entries.
  */
+/*
+ * called by:
+ *   - target/i386/kvm/kvm.c|385| <<kvm_arch_get_supported_cpuid>> cpuid = get_supported_cpuid(s);
+ */
 static struct kvm_cpuid2 *get_supported_cpuid(KVMState *s)
 {
     struct kvm_cpuid2 *cpuid;
@@ -327,6 +367,14 @@ static uint32_t cpuid_entry_get_reg(struct kvm_cpuid_entry2 *entry, int reg)
 
 /* Find matching entry for function/index on kvm_cpuid2 struct
  */
+/*
+ * called by:
+ *   - target/i386/kvm/kvm.c|428| <<kvm_arch_get_supported_cpuid>> struct kvm_cpuid_entry2 *entry = cpuid_find_entry(cpuid, function, index);
+ *   - target/i386/kvm/kvm.c|1287| <<hv_cpuid_get_host>> entry = cpuid_find_entry(cpuid, func, 0);
+ *   - target/i386/kvm/kvm.c|2160| <<kvm_arch_init_vcpu>> c = cpuid_find_entry(&cpuid_data.cpuid, 1, 0);
+ *   - target/i386/kvm/kvm.c|2166| <<kvm_arch_init_vcpu>> c = cpuid_find_entry(&cpuid_data.cpuid, 7, 0);
+ *   - target/i386/kvm/kvm.c|2203| <<kvm_arch_init_vcpu>> c = cpuid_find_entry(&cpuid_data.cpuid, kvm_base, 0);
+ */
 static struct kvm_cpuid_entry2 *cpuid_find_entry(struct kvm_cpuid2 *cpuid,
                                                  uint32_t function,
                                                  uint32_t index)
@@ -342,6 +390,35 @@ static struct kvm_cpuid_entry2 *cpuid_find_entry(struct kvm_cpuid2 *cpuid,
     return NULL;
 }
 
+/*
+ * called by:
+ *   - target/i386/cpu.c|4987| <<x86_cpu_get_supported_feature_word>> r = kvm_arch_get_supported_cpuid(kvm_state, wi->cpuid.eax,
+ *   - target/i386/cpu.c|5024| <<x86_cpu_get_supported_cpuid>> *eax = kvm_arch_get_supported_cpuid(kvm_state, func, index, R_EAX);
+ *   - target/i386/cpu.c|5025| <<x86_cpu_get_supported_cpuid>> *ebx = kvm_arch_get_supported_cpuid(kvm_state, func, index, R_EBX);
+ *   - target/i386/cpu.c|5026| <<x86_cpu_get_supported_cpuid>> *ecx = kvm_arch_get_supported_cpuid(kvm_state, func, index, R_ECX);
+ *   - target/i386/cpu.c|5027| <<x86_cpu_get_supported_cpuid>> *edx = kvm_arch_get_supported_cpuid(kvm_state, func, index, R_EDX);
+ *   - target/i386/cpu.c|5436| <<cpu_x86_cpuid>> !(kvm_arch_get_supported_cpuid(cs->kvm_state, 0x7, 0, R_EBX) &
+ *   - target/i386/cpu.c|5443| <<cpu_x86_cpuid>> !(kvm_arch_get_supported_cpuid(cs->kvm_state, 0x7, 0, R_ECX) &
+ *   - target/i386/cpu.c|6407| <<x86_cpu_filter_features>> uint32_t eax_0 = kvm_arch_get_supported_cpuid(s, 0x14, 0, R_EAX);
+ *   - target/i386/cpu.c|6408| <<x86_cpu_filter_features>> uint32_t ebx_0 = kvm_arch_get_supported_cpuid(s, 0x14, 0, R_EBX);
+ *   - target/i386/cpu.c|6409| <<x86_cpu_filter_features>> uint32_t ecx_0 = kvm_arch_get_supported_cpuid(s, 0x14, 0, R_ECX);
+ *   - target/i386/cpu.c|6410| <<x86_cpu_filter_features>> uint32_t eax_1 = kvm_arch_get_supported_cpuid(s, 0x14, 1, R_EAX);
+ *   - target/i386/cpu.c|6411| <<x86_cpu_filter_features>> uint32_t ebx_1 = kvm_arch_get_supported_cpuid(s, 0x14, 1, R_EBX);
+ *   - target/i386/kvm/kvm-cpu.c|77| <<kvm_cpu_max_instance_init>> kvm_arch_get_supported_cpuid(s, 0x0, 0, R_EAX);
+ *   - target/i386/kvm/kvm-cpu.c|79| <<kvm_cpu_max_instance_init>> kvm_arch_get_supported_cpuid(s, 0x80000000, 0, R_EAX);
+ *   - target/i386/kvm/kvm-cpu.c|81| <<kvm_cpu_max_instance_init>> kvm_arch_get_supported_cpuid(s, 0xC0000000, 0, R_EAX);
+ *   - target/i386/kvm/kvm.c|480| <<kvm_arch_get_supported_cpuid>> cpuid_1_edx = kvm_arch_get_supported_cpuid(s, 1, 0, R_EDX);
+ *   - target/i386/kvm/kvm.c|537| <<kvm_arch_get_supported_msr_feature>> if (kvm_arch_get_supported_cpuid(s, 0xD, 1, R_ECX) &
+ *   - target/i386/kvm/kvm.c|541| <<kvm_arch_get_supported_msr_feature>> if (kvm_arch_get_supported_cpuid(s, 1, 0, R_ECX) &
+ *   - target/i386/kvm/kvm.c|545| <<kvm_arch_get_supported_msr_feature>> if (kvm_arch_get_supported_cpuid(s, 7, 0, R_EBX) &
+ *   - target/i386/kvm/kvm.c|549| <<kvm_arch_get_supported_msr_feature>> if (kvm_arch_get_supported_cpuid(s, 7, 0, R_EBX) &
+ *   - target/i386/kvm/kvm.c|553| <<kvm_arch_get_supported_msr_feature>> if (kvm_arch_get_supported_cpuid(s, 0x80000001, 0, R_EDX) &
+ *   - target/i386/kvm/kvm.c|1726| <<kvm_init_xsave>> assert(kvm_arch_get_supported_cpuid(kvm_state, 0xd, 0, R_ECX) <=
+ *   - target/i386/kvm/kvm.c|3521| <<kvm_put_msrs>> int addr_num = kvm_arch_get_supported_cpuid(kvm_state,
+ *   - target/i386/kvm/kvm.c|3973| <<kvm_get_msrs>> kvm_arch_get_supported_cpuid(kvm_state, 0x14, 1, R_EAX) & 0x7;
+ *   - target/i386/kvm/kvm.c|5579| <<kvm_request_xsave_components>> supported = kvm_arch_get_supported_cpuid(s, 0xd, 0, R_EAX);
+ *   - target/i386/kvm/kvm.c|5580| <<kvm_request_xsave_components>> supported |= (uint64_t)kvm_arch_get_supported_cpuid(s, 0xd, 0, R_EDX) << 32;
+ */
 uint32_t kvm_arch_get_supported_cpuid(KVMState *s, uint32_t function,
                                       uint32_t index, int reg)
 {
@@ -350,6 +427,10 @@ uint32_t kvm_arch_get_supported_cpuid(KVMState *s, uint32_t function,
     uint32_t cpuid_1_edx;
     uint64_t bitmask;
 
+    /*
+     * called by:
+     *   - target/i386/kvm/kvm.c|385| <<kvm_arch_get_supported_cpuid>> cpuid = get_supported_cpuid(s);
+     */
     cpuid = get_supported_cpuid(s);
 
     struct kvm_cpuid_entry2 *entry = cpuid_find_entry(cpuid, function, index);
@@ -1695,6 +1776,10 @@ static void kvm_init_xsave(CPUX86State *env)
            env->xsave_buf_len);
 }
 
+/*
+ * called by:
+ *   - accel/kvm/kvm-all.c|519| <<kvm_init_vcpu>> ret = kvm_arch_init_vcpu(cpu);
+ */
 int kvm_arch_init_vcpu(CPUState *cs)
 {
     struct {
@@ -1936,8 +2021,27 @@ int kvm_arch_init_vcpu(CPUState *cs)
 
         cpu_x86_cpuid(env, 0x0a, 0, &eax, &unused, &unused, &edx);
 
+	/*
+	 * 在以下使用has_architectural_pmu_version:
+	 *   - target/i386/kvm/kvm.c|1939| <<kvm_arch_init_vcpu>> has_architectural_pmu_version = eax & 0xff;
+	 *   - target/i386/kvm/kvm.c|1940| <<kvm_arch_init_vcpu>> if (has_architectural_pmu_version > 0) {
+	 *   - target/i386/kvm/kvm.c|1951| <<kvm_arch_init_vcpu>> if (has_architectural_pmu_version > 1) {
+	 *   - target/i386/kvm/kvm.c|3256| <<kvm_put_msrs>> if (has_architectural_pmu_version > 0) {
+	 *   - target/i386/kvm/kvm.c|3257| <<kvm_put_msrs>> if (has_architectural_pmu_version > 1) {
+	 *   - target/i386/kvm/kvm.c|3274| <<kvm_put_msrs>> if (has_architectural_pmu_version > 1) {
+	 *   - target/i386/kvm/kvm.c|3747| <<kvm_get_msrs>> if (has_architectural_pmu_version > 0) {
+	 *   - target/i386/kvm/kvm.c|3748| <<kvm_get_msrs>> if (has_architectural_pmu_version > 1) {
+	 */
         has_architectural_pmu_version = eax & 0xff;
         if (has_architectural_pmu_version > 0) {
+            /*
+	     * 在以下使用num_architectural_pmu_gp_counters:
+	     *   - target/i386/kvm/kvm.c|1941| <<kvm_arch_init_vcpu>> num_architectural_pmu_gp_counters = (eax & 0xff00) >> 8;
+	     *   - target/i386/kvm/kvm.c|1947| <<kvm_arch_init_vcpu>> if (num_architectural_pmu_gp_counters > MAX_GP_COUNTERS) {
+	     *   - target/i386/kvm/kvm.c|1948| <<kvm_arch_init_vcpu>> num_architectural_pmu_gp_counters = MAX_GP_COUNTERS;
+	     *   - target/i386/kvm/kvm.c|3268| <<kvm_put_msrs>> for (i = 0; i < num_architectural_pmu_gp_counters; i++) {
+	     *   - target/i386/kvm/kvm.c|3757| <<kvm_get_msrs>> for (i = 0; i < num_architectural_pmu_gp_counters; i++) {
+	     */
             num_architectural_pmu_gp_counters = (eax & 0xff00) >> 8;
 
             /* Shouldn't be more than 32, since that's the number of bits
@@ -2111,6 +2215,9 @@ int kvm_arch_init_vcpu(CPUState *cs)
     cpuid_data.cpuid.nent = cpuid_i;
 
     cpuid_data.cpuid.padding = 0;
+    /*
+     * 只在此处使用KVM_SET_CPUID2.
+     */
     r = kvm_vcpu_ioctl(cs, KVM_SET_CPUID2, &cpuid_data);
     if (r) {
         goto fail;
@@ -2176,6 +2283,10 @@ int kvm_arch_destroy_vcpu(CPUState *cs)
     return 0;
 }
 
+/*
+ * called by:
+ *   - target/i386/cpu.c|6027| <<x86_cpu_reset>> kvm_arch_reset_vcpu(cpu);
+ */
 void kvm_arch_reset_vcpu(X86CPU *cpu)
 {
     CPUX86State *env = &cpu->env;
@@ -2253,6 +2364,10 @@ static int kvm_get_supported_feature_msrs(KVMState *s)
     return 0;
 }
 
+/*
+ * called by:
+ *   - target/i386/kvm/kvm.c|2515| <<kvm_arch_init>> ret = kvm_get_supported_msrs(s);
+ */
 static int kvm_get_supported_msrs(KVMState *s)
 {
     int ret = 0;
@@ -2361,6 +2476,11 @@ static int kvm_get_supported_msrs(KVMState *s)
                 has_msr_core_capabs = true;
                 break;
             case MSR_IA32_PERF_CAPABILITIES:
+                /*
+		 * 在以下使用has_msr_perf_capabs:
+                 *   - target/i386/kvm/kvm.c|2410| <<kvm_get_supported_msrs>> has_msr_perf_capabs = true;
+                 *   - target/i386/kvm/kvm.c|3161| <<kvm_init_msrs>> if (has_msr_perf_capabs && cpu->enable_pmu) {
+		 */
                 has_msr_perf_capabs = true;
                 break;
             case MSR_IA32_VMX_VMFUNC:
@@ -2418,6 +2538,72 @@ static void register_smram_listener(Notifier *n, void *unused)
                                  &smram_address_space, 1, "kvm-smram");
 }
 
+/*
+ * (gdb) bt
+ * #0  kvm_arch_init (ms=0x555556a54770, s=0x555556847200) at ../target/i386/kvm/kvm.c:2426
+ * #1  0x0000555555d0e59a in kvm_init (ms=0x555556a54770) at ../accel/kvm/kvm-all.c:2618
+ * #2  0x0000555555af1814 in accel_init_machine (accel=0x555556847200, ms=0x555556a54770) at ../accel/accel-softmmu.c:39
+ * #3  0x0000555555a80590 in do_configure_accelerator (opaque=0x7fffffffdbb5, opts=0x555556a714b0, errp=0x5555567d4f80 <error_fatal>) at ../softmmu/vl.c:2196
+ * #4  0x0000555555ef7c39 in qemu_opts_foreach
+ *     (list=0x5555566d5580 <qemu_accel_opts>, func=0x555555a8046a <do_configure_accelerator>, opaque=0x7fffffffdbb5, errp=0x5555567d4f80 <error_fatal>) at ../util/qemu-option.c:1135
+ * #5  0x0000555555a807f1 in configure_accelerators (progname=0x7fffffffe1fd "/home/opc/ext4/qemu-7.1.0/build/x86_64-softmmu/qemu-system-x86_64") at ../softmmu/vl.c:2262
+ * #6  0x0000555555a837c3 in qemu_init (argc=18, argv=0x7fffffffdeb8, envp=0x0) at ../softmmu/vl.c:3533
+ * #7  0x0000555555820fad in qemu_main (argc=18, argv=0x7fffffffdeb8, envp=0x0) at ../softmmu/main.c:37
+ * #8  0x0000555555820fe4 in main (argc=18, argv=0x7fffffffdeb8) at ../softmmu/main.c:47
+ *
+ * (gdb) bt
+ * #0  max_x86_cpu_initfn (obj=0x555556a91b10) at ../target/i386/cpu.c:4203
+ * #1  0x0000555555d275a3 in object_init_with_type (obj=0x555556a91b10, ti=0x55555682ea10) at ../qom/object.c:377
+ * #2  0x0000555555d27585 in object_init_with_type (obj=0x555556a91b10, ti=0x55555682ed70) at ../qom/object.c:373
+ * #3  0x0000555555d27ad5 in object_initialize_with_type (obj=0x555556a91b10, size=50432, type=0x55555682ed70) at ../qom/object.c:519
+ * #4  0x0000555555d281df in object_new_with_type (type=0x55555682ed70) at ../qom/object.c:734
+ * #5  0x0000555555d28236 in object_new (typename=0x55555682eef0 "host-x86_64-cpu") at ../qom/object.c:749
+ * #6  0x0000555555b23be1 in x86_cpu_new (x86ms=0x555556a54770, apic_id=0, errp=0x5555567d4f80 <error_fatal>) at ../hw/i386/x86.c:97
+ * #7  0x0000555555b23d34 in x86_cpus_init (x86ms=0x555556a54770, default_cpu_version=1) at ../hw/i386/x86.c:144
+ * #8  0x0000555555b2f784 in pc_init1 (machine=0x555556a54770, host_type=0x555556067ce1 "i440FX-pcihost", pci_type=0x555556067cda "i440FX") at ../hw/i386/pc_piix.c:159
+ * #9  0x0000555555b30354 in pc_init_v7_1 (machine=0x555556a54770) at ../hw/i386/pc_piix.c:445
+ * #10 0x00005555558a870e in machine_run_board_init (machine=0x555556a54770, mem_path=0x0, errp=0x5555567d4f80 <error_fatal>) at ../hw/core/machine.c:1400
+ * #11 0x0000555555a80f7c in qemu_init_board () at ../softmmu/vl.c:2485
+ * #12 0x0000555555a811ed in qmp_x_exit_preconfig (errp=0x5555567d4f80 <error_fatal>) at ../softmmu/vl.c:2581
+ * #13 0x0000555555a838c5 in qemu_init (argc=18, argv=0x7fffffffdeb8, envp=0x0) at ../softmmu/vl.c:3584
+ * #14 0x0000555555820fad in qemu_main (argc=18, argv=0x7fffffffdeb8, envp=0x0) at ../softmmu/main.c:37
+ * #15 0x0000555555820fe4 in main (argc=18, argv=0x7fffffffdeb8) at ../softmmu/main.c:47
+ *
+ * (gdb) bt
+ * #0  cpu_list_add (cpu=0x555556a91b10) at ../cpus-common.c:84
+ * #1  0x0000555555c8114b in cpu_exec_realizefn (cpu=0x555556a91b10, errp=0x7fffffffd6a8) at ../cpu.c:138
+ * #2  0x0000555555b63c39 in x86_cpu_realizefn (dev=0x555556a91b10, errp=0x7fffffffd730) at ../target/i386/cpu.c:6471
+ * #3  0x0000555555d21ca3 in device_set_realized (obj=0x555556a91b10, value=true, errp=0x7fffffffd840) at ../hw/core/qdev.c:553
+ * #4  0x0000555555d2b713 in property_set_bool (obj=0x555556a91b10, v=0x555556aa0b30, name=0x5555560ba599 "realized", opaque=0x555556851f00, errp=0x7fffffffd840) at ../qom/object.c:2273
+ * #5  0x0000555555d2975a in object_property_set (obj=0x555556a91b10, name=0x5555560ba599 "realized", v=0x555556aa0b30, errp=0x7fffffffd840) at ../qom/object.c:1408
+ * #6  0x0000555555d2db05 in object_property_set_qobject (obj=0x555556a91b10, name=0x5555560ba599 "realized", value=0x555556a91880, errp=0x5555567d4f80 <error_fatal>)
+       at ../qom/qom-qobject.c:28
+ * #7  0x0000555555d29abf in object_property_set_bool (obj=0x555556a91b10, name=0x5555560ba599 "realized", value=true, errp=0x5555567d4f80 <error_fatal>) at ../qom/object.c:1477
+ * #8  0x0000555555d2143b in qdev_realize (dev=0x555556a91b10, bus=0x0, errp=0x5555567d4f80 <error_fatal>) at ../hw/core/qdev.c:333
+ * #9  0x0000555555b23c2a in x86_cpu_new (x86ms=0x555556a54770, apic_id=0, errp=0x5555567d4f80 <error_fatal>) at ../hw/i386/x86.c:102
+ * #10 0x0000555555b23d34 in x86_cpus_init (x86ms=0x555556a54770, default_cpu_version=1) at ../hw/i386/x86.c:144
+ * #11 0x0000555555b2f784 in pc_init1 (machine=0x555556a54770, host_type=0x555556067ce1 "i440FX-pcihost", pci_type=0x555556067cda "i440FX") at ../hw/i386/pc_piix.c:159
+ * #12 0x0000555555b30354 in pc_init_v7_1 (machine=0x555556a54770) at ../hw/i386/pc_piix.c:445
+ * #13 0x00005555558a870e in machine_run_board_init (machine=0x555556a54770, mem_path=0x0, errp=0x5555567d4f80 <error_fatal>) at ../hw/core/machine.c:1400
+ * #14 0x0000555555a80f7c in qemu_init_board () at ../softmmu/vl.c:2485
+ * #15 0x0000555555a811ed in qmp_x_exit_preconfig (errp=0x5555567d4f80 <error_fatal>) at ../softmmu/vl.c:2581
+ * #16 0x0000555555a838c5 in qemu_init (argc=18, argv=0x7fffffffdeb8, envp=0x0) at ../softmmu/vl.c:3584
+ * #17 0x0000555555820fad in qemu_main (argc=18, argv=0x7fffffffdeb8, envp=0x0) at ../softmmu/main.c:37
+ * #18 0x0000555555820fe4 in main (argc=18, argv=0x7fffffffdeb8) at ../softmmu/main.c:47
+ *
+ * (gdb) bt
+ * #0  kvm_init_vcpu (cpu=0x555556a91b10, errp=0x5555567d4f80 <error_fatal>) at ../accel/kvm/kvm-all.c:467
+ * #1  0x0000555555d11cd3 in kvm_vcpu_thread_fn (arg=0x555556a91b10) at ../accel/kvm/kvm-accel-ops.c:40
+ * #2  0x0000555555eef738 in qemu_thread_start (args=0x555556aa1630) at ../util/qemu-thread-posix.c:504
+ * #3  0x00007ffff5be9ea5 in start_thread () at /lib64/libpthread.so.0
+ * #4  0x00007ffff5912b2d in clone () at /lib64/libc.so.6
+ *
+ * (gdb) bt
+ * #0  accel_setup_post (ms=0x555556a54770) at ../accel/accel-softmmu.c:57
+ * #1  0x0000555555a838d9 in qemu_init (argc=18, argv=0x7fffffffdeb8, envp=0x0) at ../softmmu/vl.c:3587
+ * #2  0x0000555555820fad in qemu_main (argc=18, argv=0x7fffffffdeb8, envp=0x0) at ../softmmu/main.c:37
+ * #3  0x0000555555820fe4 in main (argc=18, argv=0x7fffffffdeb8) at ../softmmu/main.c:47
+ */
 int kvm_arch_init(MachineState *ms, KVMState *s)
 {
     uint64_t identity_base = 0xfffbc000;
@@ -2729,6 +2915,10 @@ static int kvm_put_xcrs(X86CPU *cpu)
     return kvm_vcpu_ioctl(CPU(cpu), KVM_SET_XCRS, &xcrs);
 }
 
+/*
+ * called by:
+ *   - target/i386/kvm/kvm.c|4801| <<kvm_arch_put_registers>> ret = has_sregs2 ? kvm_put_sregs2(x86_cpu) : kvm_put_sregs(x86_cpu);
+ */
 static int kvm_put_sregs(X86CPU *cpu)
 {
     CPUX86State *env = &cpu->env;
@@ -2779,6 +2969,10 @@ static int kvm_put_sregs(X86CPU *cpu)
     return kvm_vcpu_ioctl(CPU(cpu), KVM_SET_SREGS, &sregs);
 }
 
+/*
+ * called by:
+ *   - target/i386/kvm/kvm.c|4801| <<kvm_arch_put_registers>> ret = has_sregs2 ? kvm_put_sregs2(x86_cpu) : kvm_put_sregs(x86_cpu);
+ */
 static int kvm_put_sregs2(X86CPU *cpu)
 {
     CPUX86State *env = &cpu->env;
@@ -2836,6 +3030,13 @@ static int kvm_put_sregs2(X86CPU *cpu)
 
 static void kvm_msr_buf_reset(X86CPU *cpu)
 {
+    /*
+     * ArchCPU:
+     * -> struct kvm_msrs *kvm_msr_buf;
+     *    -> __u32 nmsrs; // number of msrs in entries
+     *    -> __u32 pad;
+     *    -> struct kvm_msr_entry entries[0];
+     */
     memset(cpu->kvm_msr_buf, 0, MSR_BUF_SIZE);
 }
 
@@ -3097,6 +3298,10 @@ static int kvm_buf_set_msrs(X86CPU *cpu)
     return 0;
 }
 
+/*
+ * called by:
+ *   - target/i386/kvm/kvm.c|2202| <<kvm_arch_init_vcpu>> kvm_init_msrs(cpu);
+ */
 static void kvm_init_msrs(X86CPU *cpu)
 {
     CPUX86State *env = &cpu->env;
@@ -3112,6 +3317,11 @@ static void kvm_init_msrs(X86CPU *cpu)
                           env->features[FEAT_CORE_CAPABILITY]);
     }
 
+    /*
+     * 在以下使用has_msr_perf_capabs:
+     *   - target/i386/kvm/kvm.c|2410| <<kvm_get_supported_msrs>> has_msr_perf_capabs = true;
+     *   - target/i386/kvm/kvm.c|3161| <<kvm_init_msrs>> if (has_msr_perf_capabs && cpu->enable_pmu) {
+     */
     if (has_msr_perf_capabs && cpu->enable_pmu) {
         kvm_msr_entry_add_perf(cpu, env->features);
     }
@@ -3131,6 +3341,31 @@ static void kvm_init_msrs(X86CPU *cpu)
     assert(kvm_buf_set_msrs(cpu) == 0);
 }
 
+/*
+ * (gdb) bt
+ * #0  kvm_put_msrs (cpu=0x555556ae2360, level=2) at ../target/i386/kvm/kvm.c:3135
+ * #1  0x0000555555b1497a in kvm_arch_put_registers (cpu=0x555556ae2360, level=2) at ../target/i386/kvm/kvm.c:4559
+ * #2  0x0000555555d0de56 in do_kvm_cpu_synchronize_post_reset (cpu=0x555556ae2360, arg=...) at ../accel/kvm/kvm-all.c:2780
+ * #3  0x0000555555821f77 in process_queued_cpu_work (cpu=0x555556ae2360) at ../cpus-common.c:351
+ * #4  0x0000555555a717d4 in qemu_wait_io_event_common (cpu=0x555556ae2360) at ../softmmu/cpus.c:411
+ * #5  0x0000555555a71865 in qemu_wait_io_event (cpu=0x555556ae2360) at ../softmmu/cpus.c:435
+ * #6  0x0000555555d10fce in kvm_vcpu_thread_fn (arg=0x555556ae2360) at ../accel/kvm/kvm-accel-ops.c:54
+ * #7  0x0000555555eec4de in qemu_thread_start (args=0x555556af1620) at ../util/qemu-thread-posix.c:504
+ * #8  0x00007ffff55eeea5 in start_thread () at /lib64/libpthread.so.0
+ * #9  0x00007ffff53179fd in clone () at /lib64/libc.so.6
+ *
+ * (gdb) bt
+ * #0  kvm_put_msrs (cpu=0x555556ae2360, level=1) at ../target/i386/kvm/kvm.c:3135
+ * #1  0x0000555555b1497a in kvm_arch_put_registers (cpu=0x555556ae2360, level=1) at ../target/i386/kvm/kvm.c:4559
+ * #2  0x0000555555d0e12c in kvm_cpu_exec (cpu=0x555556ae2360) at ../accel/kvm/kvm-all.c:2884
+ * #3  0x0000555555d10faa in kvm_vcpu_thread_fn (arg=0x555556ae2360) at ../accel/kvm/kvm-accel-ops.c:49
+ * #4  0x0000555555eec4de in qemu_thread_start (args=0x555556af1620) at ../util/qemu-thread-posix.c:504
+ * #5  0x00007ffff55eeea5 in start_thread () at /lib64/libpthread.so.0
+ * #6  0x00007ffff53179fd in clone () at /lib64/libc.so.6
+ *
+ * called by:
+ *   - target/i386/kvm/kvm.c|4565| <<kvm_arch_put_registers>> ret = kvm_put_msrs(x86_cpu, level);
+ */
 static int kvm_put_msrs(X86CPU *cpu, int level)
 {
     CPUX86State *env = &cpu->env;
@@ -3224,6 +3459,28 @@ static int kvm_put_msrs(X86CPU *cpu, int level)
             kvm_msr_entry_add(cpu, MSR_KVM_POLL_CONTROL, env->poll_control_msr);
         }
 
+        /*
+	 * version 1:
+	 * 
+	 * IA32_PMCx MSRs 从 0x0c1开始
+	 * IA32_PERFEVTSELx MSRs 从0x186开始
+	 *
+	 * 当IA_PERF_CAPABILITIES.FW_WRITE[bit 13] == 1的时候:
+	 * IA32_PMCx从0x4c1开始
+	 *
+	 * MSR_P6_PERFCTR0 + i,
+	 * MSR_P6_EVNTSEL0 + i,
+	 * MSR_CORE_PERF_FIXED_CTR0 + i
+	 *
+	 * MSR_CORE_PERF_FIXED_CTR_CTRL
+	 * MSR_CORE_PERF_GLOBAL_CTRL
+	 * MSR_CORE_PERF_GLOBAL_STATUS,
+	 * MSR_CORE_PERF_GLOBAL_OVF_CTRL,
+	 */
+        /*
+	 * 在以下使用has_architectural_pmu_version:
+	 *   - target/i386/kvm/kvm.c|1939| <<kvm_arch_init_vcpu>> has_architectural_pmu_version = eax & 0xff;
+	 */
         if (has_architectural_pmu_version > 0) {
             if (has_architectural_pmu_version > 1) {
                 /* Stop the counter.  */
@@ -3232,16 +3489,38 @@ static int kvm_put_msrs(X86CPU *cpu, int level)
             }
 
             /* Set the counter values.  */
+            /*
+	     * 在以下使用num_architectural_pmu_fixed_counters:
+	     *   - target/i386/kvm/kvm.c|1986| <<kvm_arch_init_vcpu>> num_architectural_pmu_fixed_counters = edx & 0x1f;
+             *   - target/i386/kvm/kvm.c|1989| <<kvm_arch_init_vcpu>> num_architectural_pmu_fixed_counters = MAX_FIXED_COUNTERS;
+             */
             for (i = 0; i < num_architectural_pmu_fixed_counters; i++) {
                 kvm_msr_entry_add(cpu, MSR_CORE_PERF_FIXED_CTR0 + i,
                                   env->msr_fixed_counters[i]);
             }
+            /*
+	     * 在以下使用MSR_F15H_PERF_CTR0:
+	     *   - target/i386/cpu.h|1319| <<MAX_GP_COUNTERS>> #define MAX_GP_COUNTERS (MSR_IA32_PERF_STATUS - MSR_P6_EVNTSEL0)
+	     *   - target/i386/kvm/kvm.c|3313| <<kvm_put_msrs>> kvm_msr_entry_add(cpu, MSR_P6_EVNTSEL0 + i,
+	     *   - target/i386/kvm/kvm.c|3801| <<kvm_get_msrs>> kvm_msr_entry_add(cpu, MSR_P6_EVNTSEL0 + i, 0);
+	     *   - target/i386/kvm/kvm.c|4087| <<kvm_get_msrs>> case MSR_P6_EVNTSEL0 ... MSR_P6_EVNTSEL0 + MAX_GP_COUNTERS - 1:
+	     *   - target/i386/kvm/kvm.c|4088| <<kvm_get_msrs>> env->msr_gp_evtsel[index - MSR_P6_EVNTSEL0] = msrs[i].data;
+	     *
+	     * 在以下使用num_architectural_pmu_gp_counters:
+             *   - target/i386/kvm/kvm.c|1941| <<kvm_arch_init_vcpu>> num_architectural_pmu_gp_counters = (eax & 0xff00) >> 8;
+             *   - target/i386/kvm/kvm.c|1947| <<kvm_arch_init_vcpu>> if (num_architectural_pmu_gp_counters > MAX_GP_COUNTERS) {
+             *   - target/i386/kvm/kvm.c|1948| <<kvm_arch_init_vcpu>> num_architectural_pmu_gp_counters = MAX_GP_COUNTERS;
+	     */
             for (i = 0; i < num_architectural_pmu_gp_counters; i++) {
                 kvm_msr_entry_add(cpu, MSR_P6_PERFCTR0 + i,
                                   env->msr_gp_counters[i]);
                 kvm_msr_entry_add(cpu, MSR_P6_EVNTSEL0 + i,
                                   env->msr_gp_evtsel[i]);
             }
+            /*
+	     * 在以下使用has_architectural_pmu_version:
+	     *   - target/i386/kvm/kvm.c|1939| <<kvm_arch_init_vcpu>> has_architectural_pmu_version = eax & 0xff;
+	     */
             if (has_architectural_pmu_version > 1) {
                 kvm_msr_entry_add(cpu, MSR_CORE_PERF_GLOBAL_STATUS,
                                   env->msr_global_status);
@@ -3725,6 +4004,14 @@ static int kvm_get_msrs(X86CPU *cpu)
         for (i = 0; i < num_architectural_pmu_fixed_counters; i++) {
             kvm_msr_entry_add(cpu, MSR_CORE_PERF_FIXED_CTR0 + i, 0);
         }
+        /*
+	 * 在以下使用MSR_F15H_PERF_CTR0:
+         *   - target/i386/cpu.h|1319| <<MAX_GP_COUNTERS>> #define MAX_GP_COUNTERS (MSR_IA32_PERF_STATUS - MSR_P6_EVNTSEL0)
+         *   - target/i386/kvm/kvm.c|3313| <<kvm_put_msrs>> kvm_msr_entry_add(cpu, MSR_P6_EVNTSEL0 + i,
+         *   - target/i386/kvm/kvm.c|3801| <<kvm_get_msrs>> kvm_msr_entry_add(cpu, MSR_P6_EVNTSEL0 + i, 0);
+         *   - target/i386/kvm/kvm.c|4087| <<kvm_get_msrs>> case MSR_P6_EVNTSEL0 ... MSR_P6_EVNTSEL0 + MAX_GP_COUNTERS - 1:
+         *   - target/i386/kvm/kvm.c|4088| <<kvm_get_msrs>> env->msr_gp_evtsel[index - MSR_P6_EVNTSEL0] = msrs[i].data;
+	 */
         for (i = 0; i < num_architectural_pmu_gp_counters; i++) {
             kvm_msr_entry_add(cpu, MSR_P6_PERFCTR0 + i, 0);
             kvm_msr_entry_add(cpu, MSR_P6_EVNTSEL0 + i, 0);
@@ -4505,6 +4792,12 @@ static int kvm_get_nested_state(X86CPU *cpu)
     return ret;
 }
 
+/*
+ * called by:
+ *   - accel/kvm/kvm-all.c|2780| <<do_kvm_cpu_synchronize_post_reset>> kvm_arch_put_registers(cpu, KVM_PUT_RESET_STATE);
+ *   - accel/kvm/kvm-all.c|2791| <<do_kvm_cpu_synchronize_post_init>> kvm_arch_put_registers(cpu, KVM_PUT_FULL_STATE);
+ *   - accel/kvm/kvm-all.c|2884| <<kvm_cpu_exec>> kvm_arch_put_registers(cpu, KVM_PUT_RUNTIME_STATE);
+ */
 int kvm_arch_put_registers(CPUState *cpu, int level)
 {
     X86CPU *x86_cpu = X86_CPU(cpu);
diff --git a/target/i386/machine.c b/target/i386/machine.c
index cecd476e9..0a9cc4522 100644
--- a/target/i386/machine.c
+++ b/target/i386/machine.c
@@ -639,6 +639,9 @@ static const VMStateDescription vmstate_msr_ia32_feature_control = {
     }
 };
 
+/*
+ * VMStateDescription vmstate_msr_architectural_pmu.pmu_enable_needed()
+ */
 static bool pmu_enable_needed(void *opaque)
 {
     X86CPU *cpu = opaque;
@@ -654,6 +657,13 @@ static bool pmu_enable_needed(void *opaque)
             return true;
         }
     }
+    /*
+     * 在以下使用CPUArchState->msr_gp_evtsel[MAX_GP_COUNTERS]:
+     *   - target/i386/machine.c|678| <<global>> VMSTATE_UINT64_ARRAY(env.msr_gp_evtsel, X86CPU, MAX_GP_COUNTERS),
+     *   - target/i386/kvm/kvm.c|3314| <<kvm_put_msrs>> env->msr_gp_evtsel[i]);
+     *   - target/i386/kvm/kvm.c|4088| <<kvm_get_msrs>> env->msr_gp_evtsel[index - MSR_P6_EVNTSEL0] = msrs[i].data;
+     *   - target/i386/machine.c|658| <<pmu_enable_needed>> if (env->msr_gp_counters[i] || env->msr_gp_evtsel[i]) {
+     */
     for (i = 0; i < MAX_GP_COUNTERS; i++) {
         if (env->msr_gp_counters[i] || env->msr_gp_evtsel[i]) {
             return true;
diff --git a/ui/spice-core.c b/ui/spice-core.c
index c3ac20ad4..fcb64d05e 100644
--- a/ui/spice-core.c
+++ b/ui/spice-core.c
@@ -894,6 +894,11 @@ int qemu_spice_add_display_interface(QXLInstance *qxlin, QemuConsole *con)
     return qemu_spice_add_interface(&qxlin->base);
 }
 
+/*
+ * called by:
+ *   - ui/spice-core.c|925| <<qemu_spice_set_passwd>> return qemu_spice_set_ticket(fail_if_conn, disconnect_if_conn);
+ *   - ui/spice-core.c|931| <<qemu_spice_set_pw_expire>> return qemu_spice_set_ticket(false, false);
+ */
 static int qemu_spice_set_ticket(bool fail_if_conn, bool disconnect_if_conn)
 {
     time_t lifetime, now = time(NULL);
diff --git a/util/aio-posix.c b/util/aio-posix.c
index 731f3826c..c95653ba7 100644
--- a/util/aio-posix.c
+++ b/util/aio-posix.c
@@ -97,6 +97,53 @@ static bool aio_remove_fd_handler(AioContext *ctx, AioHandler *node)
     return true;
 }
 
+/*
+ * called by:
+ *   - block/curl.c|127| <<curl_drop_socket>> aio_set_fd_handler(s->aio_context, socket->fd, false,
+ *   - block/curl.c|175| <<curl_sock_cb>> aio_set_fd_handler(s->aio_context, fd, false,
+ *   - block/curl.c|179| <<curl_sock_cb>> aio_set_fd_handler(s->aio_context, fd, false,
+ *   - block/curl.c|183| <<curl_sock_cb>> aio_set_fd_handler(s->aio_context, fd, false,
+ *   - block/curl.c|188| <<curl_sock_cb>> aio_set_fd_handler(s->aio_context, fd, false,
+ *   - block/export/fuse.c|225| <<setup_fuse_export>> aio_set_fd_handler(exp->common.ctx,
+ *   - block/export/fuse.c|269| <<fuse_export_shutdown>> aio_set_fd_handler(exp->common.ctx,
+ *   - block/export/vduse-blk.c|127| <<vduse_blk_enable_queue>> aio_set_fd_handler(vblk_exp->export.ctx, vduse_queue_get_fd(vq),
+ *   - block/export/vduse-blk.c|137| <<vduse_blk_disable_queue>> aio_set_fd_handler(vblk_exp->export.ctx, vduse_queue_get_fd(vq),
+ *   - block/export/vduse-blk.c|157| <<vduse_blk_attach_ctx>> aio_set_fd_handler(vblk_exp->export.ctx, vduse_dev_get_fd(vblk_exp->dev),
+ *   - block/export/vduse-blk.c|168| <<vduse_blk_attach_ctx>> aio_set_fd_handler(vblk_exp->export.ctx, fd, true,
+ *   - block/export/vduse-blk.c|184| <<vduse_blk_detach_ctx>> aio_set_fd_handler(vblk_exp->export.ctx, fd,
+ *   - block/export/vduse-blk.c|187| <<vduse_blk_detach_ctx>> aio_set_fd_handler(vblk_exp->export.ctx, vduse_dev_get_fd(vblk_exp->dev),
+ *   - block/export/vduse-blk.c|326| <<vduse_blk_exp_create>> aio_set_fd_handler(exp->ctx, vduse_dev_get_fd(vblk_exp->dev), true,
+ *   - block/io_uring.c|410| <<luring_detach_aio_context>> aio_set_fd_handler(old_context, s->ring.ring_fd, false,
+ *   - block/io_uring.c|420| <<luring_attach_aio_context>> aio_set_fd_handler(s->aio_context, s->ring.ring_fd, false,
+ *   - block/iscsi.c|486| <<iscsi_set_events>> aio_set_fd_handler(iscsilun->aio_context, iscsi_get_fd(iscsi),
+ *   - block/iscsi.c|1771| <<iscsi_detach_aio_context>> aio_set_fd_handler(iscsilun->aio_context, iscsi_get_fd(iscsilun->iscsi),
+ *   - block/nfs.c|196| <<nfs_set_events>> aio_set_fd_handler(client->aio_context, nfs_get_fd(client->context),
+ *   - block/nfs.c|374| <<nfs_detach_aio_context>> aio_set_fd_handler(client->aio_context, nfs_get_fd(client->context),
+ *   - block/nfs.c|392| <<nfs_client_close>> aio_set_fd_handler(client->aio_context, nfs_get_fd(client->context),
+ *   - block/ssh.c|1021| <<restart_coroutine>> aio_set_fd_handler(ctx, s->sock, false, NULL, NULL, NULL, NULL, NULL);
+ *   - block/ssh.c|1050| <<co_yield>> aio_set_fd_handler(bdrv_get_aio_context(bs), s->sock,
+ *   - hw/xen/xen-bus.c|1117| <<xen_device_set_event_channel_context>> aio_set_fd_handler(channel->ctx, xenevtchn_fd(channel->xeh), true,
+ *   - hw/xen/xen-bus.c|1121| <<xen_device_set_event_channel_context>> aio_set_fd_handler(channel->ctx, xenevtchn_fd(channel->xeh), true,
+ *   - hw/xen/xen-bus.c|1195| <<xen_device_unbind_event_channel>> aio_set_fd_handler(channel->ctx, xenevtchn_fd(channel->xeh), true,
+ *   - io/channel-command.c|370| <<qio_channel_command_set_aio_fd_handler>> aio_set_fd_handler(ctx, cioc->readfd, false,
+ *   - io/channel-command.c|372| <<qio_channel_command_set_aio_fd_handler>> aio_set_fd_handler(ctx, cioc->writefd, false,
+ *   - io/channel-file.c|200| <<qio_channel_file_set_aio_fd_handler>> aio_set_fd_handler(ctx, fioc->fd, false, io_read, io_write,
+ *   - io/channel-socket.c|885| <<qio_channel_socket_set_aio_fd_handler>> aio_set_fd_handler(ctx, sioc->fd, false,
+ *   - migration/rdma.c|3101| <<qio_channel_rdma_set_aio_fd_handler>> aio_set_fd_handler(ctx, rioc->rdmain->recv_comp_channel->fd,
+ *   - migration/rdma.c|3103| <<qio_channel_rdma_set_aio_fd_handler>> aio_set_fd_handler(ctx, rioc->rdmain->send_comp_channel->fd,
+ *   - migration/rdma.c|3106| <<qio_channel_rdma_set_aio_fd_handler>> aio_set_fd_handler(ctx, rioc->rdmaout->recv_comp_channel->fd,
+ *   - migration/rdma.c|3108| <<qio_channel_rdma_set_aio_fd_handler>> aio_set_fd_handler(ctx, rioc->rdmaout->send_comp_channel->fd,
+ *   - util/aio-posix.c|204| <<aio_set_event_notifier>> aio_set_fd_handler(ctx, event_notifier_get_fd(notifier), is_external,
+ *   - util/aio-win32.c|64| <<aio_set_fd_handler>> void aio_set_fd_handler(AioContext *ctx,
+ *   - util/main-loop.c|682| <<qemu_set_fd_handler>> aio_set_fd_handler(iohandler_ctx, fd, false,
+ *   - util/qemu-coroutine-io.c|77| <<fd_coroutine_enter>> aio_set_fd_handler(data->ctx, data->fd, false,
+ *   - util/qemu-coroutine-io.c|90| <<yield_until_fd_readable>> aio_set_fd_handler(
+ *   - util/vhost-user-server.c|274| <<set_watch>> aio_set_fd_handler(server->ioc->ctx, fd, true, kick_handler,
+ *   - util/vhost-user-server.c|295| <<remove_watch>> aio_set_fd_handler(server->ioc->ctx, fd, true,
+ *   - util/vhost-user-server.c|359| <<vhost_user_server_stop>> aio_set_fd_handler(server->ctx, vu_fd_watch->fd, true,
+ *   - util/vhost-user-server.c|402| <<vhost_user_server_attach_aio_context>> aio_set_fd_handler(ctx, vu_fd_watch->fd, true, kick_handler, NULL,
+ *   - util/vhost-user-server.c|416| <<vhost_user_server_detach_aio_context>> aio_set_fd_handler(server->ctx, vu_fd_watch->fd, true,
+ */
 void aio_set_fd_handler(AioContext *ctx,
                         int fd,
                         bool is_external,
@@ -322,6 +369,11 @@ static void aio_free_deleted_handlers(AioContext *ctx)
     qemu_lockcnt_inc_and_unlock(&ctx->list_lock);
 }
 
+/*
+ * called by:
+ *   - util/aio-posix.c|399| <<aio_dispatch_ready_handlers>> progress = aio_dispatch_handler(ctx, node) || progress;
+ *   - util/aio-posix.c|412| <<aio_dispatch_handlers>> progress = aio_dispatch_handler(ctx, node) || progress;
+ */
 static bool aio_dispatch_handler(AioContext *ctx, AioHandler *node)
 {
     bool progress = false;
@@ -403,6 +455,13 @@ static bool aio_dispatch_ready_handlers(AioContext *ctx,
 }
 
 /* Slower than aio_dispatch_ready_handlers() but only used via glib */
+/*
+ * called by:
+ *   - util/aio-posix.c|422| <<aio_dispatch>> aio_dispatch_handlers(ctx);
+ *   - util/aio-win32.c|258| <<aio_dispatch_handlers>> static bool aio_dispatch_handlers(AioContext *ctx, HANDLE event)
+ *   - util/aio-win32.c|321| <<aio_dispatch>> aio_dispatch_handlers(ctx, INVALID_HANDLE_VALUE);
+ *   - util/aio-win32.c|416| <<aio_poll>> progress |= aio_dispatch_handlers(ctx, event);
+ */
 static bool aio_dispatch_handlers(AioContext *ctx)
 {
     AioHandler *node, *tmp;
@@ -600,6 +659,24 @@ static bool try_poll_mode(AioContext *ctx, AioHandlerList *ready_list,
     return false;
 }
 
+/*
+ * 非test在以下使用aio_poll():
+ *   - backends/tpm/tpm_backend.c|55| <<tpm_backend_finish_sync>> aio_poll(qemu_get_aio_context(), true);
+ *   - block.c|569| <<bdrv_create>> aio_poll(qemu_get_aio_context(), true);
+ *   - block/io.c|2969| <<bdrv_aio_cancel>> aio_poll(acb->aiocb_info->get_aio_context(acb), true);
+ *   - block/io.c|2976| <<bdrv_aio_cancel>> aio_poll(bdrv_get_aio_context(acb->bs), true);
+ *   - hw/9pfs/9p.c|4315| <<v9fs_reset>> aio_poll(qemu_get_aio_context(), true);
+ *   - hw/9pfs/9p.c|4322| <<v9fs_reset>> aio_poll(qemu_get_aio_context(), true);
+ *   - hw/ppc/spapr_nvdimm.c|600| <<spapr_nvdimm_finish_flushes>> aio_poll(qemu_get_aio_context(), true);
+ *   - include/block/aio-wait.h|88| <<AIO_WAIT_WHILE>> aio_poll(ctx_, true); \
+ *   - include/block/aio-wait.h|98| <<AIO_WAIT_WHILE>> aio_poll(qemu_get_aio_context(), true); \
+ *   - iothread.c|67| <<iothread_run>> aio_poll(iothread->ctx, true);
+ *   - monitor/monitor.c|656| <<monitor_cleanup>> (aio_poll(iohandler_get_aio_context(), false),
+ *   - net/filter-mirror.c|131| <<filter_send>> aio_poll(qemu_get_aio_context(), true);
+ *   - qemu-img.c|918| <<run_block_job>> aio_poll(aio_context, true);
+ *   - qemu-io-cmds.c|616| <<do_co_pwrite_zeroes>> aio_poll(blk_get_aio_context(blk), true);
+ *   - qemu-io-cmds.c|2293| <<wait_break_f>> aio_poll(blk_get_aio_context(blk), true);
+ */
 bool aio_poll(AioContext *ctx, bool blocking)
 {
     AioHandlerList ready_list = QLIST_HEAD_INITIALIZER(ready_list);
diff --git a/util/aio-wait.c b/util/aio-wait.c
index 98c5accd2..948ee021b 100644
--- a/util/aio-wait.c
+++ b/util/aio-wait.c
@@ -82,5 +82,22 @@ void aio_wait_bh_oneshot(AioContext *ctx, QEMUBHFunc *cb, void *opaque)
     assert(qemu_get_current_aio_context() == qemu_get_aio_context());
 
     aio_bh_schedule_oneshot(ctx, aio_wait_bh, &data);
+    /*
+     * AIO_WAIT_WHILE:
+     * @ctx: the aio context, or NULL if multiple aio contexts (for which the
+     *       caller does not hold a lock) are involved in the polling condition.
+     * @cond: wait while this conditional expression is true
+     *  
+     * Wait while a condition is true.  Use this to implement synchronous
+     * operations that require event loop activity.
+     *  
+     * The caller must be sure that something calls aio_wait_kick() when the value
+     * of @cond might have changed.
+     *
+     * The caller's thread must be the IOThread that owns @ctx or the main loop
+     * thread (with @ctx acquired exactly once).  This function cannot be used to
+     * wait on conditions between two IOThreads since that could lead to deadlock,
+     * go via the main loop instead.
+     */
     AIO_WAIT_WHILE(ctx, !data.done);
 }
diff --git a/util/async.c b/util/async.c
index 63434ddae..c2cf07802 100644
--- a/util/async.c
+++ b/util/async.c
@@ -402,6 +402,10 @@ ThreadPool *aio_get_thread_pool(AioContext *ctx)
 }
 
 #ifdef CONFIG_LINUX_AIO
+/*
+ * called by:
+ *   - block/file-posix.c|712| <<raw_open_common>> if (!aio_setup_linux_aio(bdrv_get_aio_context(bs), errp)) {
+ */
 LinuxAioState *aio_setup_linux_aio(AioContext *ctx, Error **errp)
 {
     if (!ctx->linux_aio) {
diff --git a/util/coroutine-sigaltstack.c b/util/coroutine-sigaltstack.c
index e2690c5f4..a2e75b8c7 100644
--- a/util/coroutine-sigaltstack.c
+++ b/util/coroutine-sigaltstack.c
@@ -145,6 +145,10 @@ static void coroutine_trampoline(int signal)
     coroutine_bootstrap(self, co);
 }
 
+/*
+ * called by:
+ *   - util/qemu-coroutine.c|90| <<qemu_coroutine_create>> co = qemu_coroutine_new();
+ */
 Coroutine *qemu_coroutine_new(void)
 {
     CoroutineSigAltStack *co;
diff --git a/util/log.c b/util/log.c
index d6eb0378c..912f580bc 100644
--- a/util/log.c
+++ b/util/log.c
@@ -186,6 +186,12 @@ valid_filename_template(const char *filename, bool per_thread, Error **errp)
 }
 
 /* enable or disable low levels log */
+/*
+ * called by:
+ *   - util/log.c|302| <<qemu_set_log>> return qemu_set_log_internal(NULL, false, log_flags, errp);
+ *   - util/log.c|307| <<qemu_set_log_filename>> return qemu_set_log_internal(filename, true, qemu_loglevel, errp);
+ *   - util/log.c|312| <<qemu_set_log_filename_flags>> return qemu_set_log_internal(name, true, flags, errp);
+ */
 static bool qemu_set_log_internal(const char *filename, bool changed_name,
                                   int log_flags, Error **errp)
 {
@@ -297,6 +303,16 @@ static bool qemu_set_log_internal(const char *filename, bool changed_name,
     return true;
 }
 
+/*
+ * called by:
+ *   - monitor/misc.c|445| <<hmp_log>> if (!qemu_set_log(mask, &err)) {
+ *   - qemu-img.c|5443| <<main>> qemu_set_log(LOG_TRACE, &error_fatal);
+ *   - qemu-io.c|638| <<main>> qemu_set_log(LOG_TRACE, &error_fatal);
+ *   - qemu-nbd.c|814| <<main>> qemu_set_log(LOG_TRACE, &error_fatal);
+ *   - scsi/qemu-pr-helper.c|1006| <<main>> qemu_set_log(LOG_TRACE, &error_fatal);
+ *   - storage-daemon/qemu-storage-daemon.c|419| <<main>> qemu_set_log(LOG_TRACE, &error_fatal);
+ *   - tests/unit/test-logging.c|124| <<test_logfile_write>> qemu_set_log(CPU_LOG_TB_OUT_ASM, &error_abort);
+ */
 bool qemu_set_log(int log_flags, Error **errp)
 {
     return qemu_set_log_internal(NULL, false, log_flags, errp);
@@ -449,6 +465,13 @@ const QEMULogItem qemu_log_items[] = {
 };
 
 /* takes a comma separated list of log masks. Return 0 if error. */
+/*
+ * called by:
+ *   - bsd-user/main.c|410| <<main>> mask = qemu_str_to_log_mask(log_mask);
+ *   - linux-user/main.c|250| <<handle_arg_log>> last_log_mask = qemu_str_to_log_mask(arg);
+ *   - monitor/misc.c|438| <<hmp_log>> mask = qemu_str_to_log_mask(items);
+ *   - softmmu/vl.c|2387| <<qemu_process_early_options>> mask = qemu_str_to_log_mask(log_mask);
+ */
 int qemu_str_to_log_mask(const char *str)
 {
     const QEMULogItem *item;
@@ -486,6 +509,12 @@ int qemu_str_to_log_mask(const char *str)
     return 0;
 }
 
+/*
+ * called by:
+ *   - bsd-user/main.c|412| <<main>> qemu_print_log_usage(stdout);
+ *   - linux-user/main.c|252| <<handle_arg_log>> qemu_print_log_usage(stdout);
+ *   - softmmu/vl.c|2399| <<qemu_process_early_options>> qemu_print_log_usage(stdout);
+ */
 void qemu_print_log_usage(FILE *f)
 {
     const QEMULogItem *item;
diff --git a/util/main-loop.c b/util/main-loop.c
index f00a25451..654ea6bd4 100644
--- a/util/main-loop.c
+++ b/util/main-loop.c
@@ -288,6 +288,21 @@ static void glib_pollfds_fill(int64_t *cur_timeout)
     *cur_timeout = qemu_soonest_timeout(timeout_ns, *cur_timeout);
 }
 
+/*
+ * (gdb) bt
+ * #0  iscsi_nop_timed_event (opaque=0x5562784d9560) at ../block/iscsi.c:1408
+ * #1  0x00005562769a610f in timerlist_run_timers (timer_list=0x556278288ec0) at ../util/qemu-timer.c:576
+ * #2  0x00005562769a6265 in timerlistgroup_run_timers (tlg=0x556278288d58) at ../util/qemu-timer.c:615
+ * #3  0x00005562769751a2 in aio_dispatch (ctx=0x556278288ba0) at ../util/aio-posix.c:426
+ * #4  0x000055627698e302 in aio_ctx_dispatch (source=0x556278288ba0, callback=0x0, user_data=0x0) at ../util/async.c:320
+ * #5  0x00007fcdadc14119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #6  0x00005562769a000b in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #7  0x00005562769a0085 in os_host_main_loop_wait (timeout=493486878) at ../util/main-loop.c:320
+ * #8  0x00005562769a018a in main_loop_wait (nonblocking=0) at ../util/main-loop.c:596
+ * #9  0x00005562765022ee in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #10 0x00005562762a80f2 in qemu_main (argc=28, argv=0x7ffd0bd2bd08, envp=0x0) at ../softmmu/main.c:38
+ * #11 0x00005562762a8124 in main (argc=28, argv=0x7ffd0bd2bd08) at ../softmmu/main.c:47
+ */
 static void glib_pollfds_poll(void)
 {
     GMainContext *context = g_main_context_default();
@@ -300,6 +315,24 @@ static void glib_pollfds_poll(void)
 
 #define MAX_MAIN_LOOP_SPIN (1000)
 
+/*
+ * (gdb) bt
+ * #0  iscsi_nop_timed_event (opaque=0x5562784d9560) at ../block/iscsi.c:1408
+ * #1  0x00005562769a610f in timerlist_run_timers (timer_list=0x556278288ec0) at ../util/qemu-timer.c:576
+ * #2  0x00005562769a6265 in timerlistgroup_run_timers (tlg=0x556278288d58) at ../util/qemu-timer.c:615
+ * #3  0x00005562769751a2 in aio_dispatch (ctx=0x556278288ba0) at ../util/aio-posix.c:426
+ * #4  0x000055627698e302 in aio_ctx_dispatch (source=0x556278288ba0, callback=0x0, user_data=0x0) at ../util/async.c:320
+ * #5  0x00007fcdadc14119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #6  0x00005562769a000b in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #7  0x00005562769a0085 in os_host_main_loop_wait (timeout=493486878) at ../util/main-loop.c:320
+ * #8  0x00005562769a018a in main_loop_wait (nonblocking=0) at ../util/main-loop.c:596
+ * #9  0x00005562765022ee in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #10 0x00005562762a80f2 in qemu_main (argc=28, argv=0x7ffd0bd2bd08, envp=0x0) at ../softmmu/main.c:38
+ * #11 0x00005562762a8124 in main (argc=28, argv=0x7ffd0bd2bd08) at ../softmmu/main.c:47
+ *
+ * called by:
+ *   - util/main-loop.c|596| <<main_loop_wait>> ret = os_host_main_loop_wait(timeout_ns);
+ */
 static int os_host_main_loop_wait(int64_t timeout)
 {
     GMainContext *context = g_main_context_default();
diff --git a/util/qemu-config.c b/util/qemu-config.c
index 433488aa5..72fd3f8a0 100644
--- a/util/qemu-config.c
+++ b/util/qemu-config.c
@@ -241,6 +241,9 @@ static QemuOptsList machine_opts = {
     }
 };
 
+/*
+ * 只被qmp调用
+ */
 CommandLineOptionInfoList *qmp_query_command_line_options(bool has_option,
                                                           const char *option,
                                                           Error **errp)
diff --git a/util/qemu-coroutine.c b/util/qemu-coroutine.c
index 4a8bd63ef..8d783446c 100644
--- a/util/qemu-coroutine.c
+++ b/util/qemu-coroutine.c
@@ -192,6 +192,59 @@ void qemu_coroutine_enter_if_inactive(Coroutine *co)
     }
 }
 
+/*
+ * (gdb) bt
+ * #0  qemu_coroutine_yield () at ../util/qemu-coroutine.c:197
+ * #1  0x0000555555f16b44 in thread_pool_submit_co (pool=0x7fffe8002370, func=0x555555e15acd <handle_aiocb_rw>, arg=0x7ffe45ddd730) at ../util/thread-pool.c:293
+ * #2  0x0000555555e16bf1 in raw_thread_pool_submit (bs=0x555556a6b8a0, func=0x555555e15acd <handle_aiocb_rw>, arg=0x7ffe45ddd730) at ../block/file-posix.c:2061
+ * #3  0x0000555555e16e19 in raw_co_prw (bs=0x555556a6b8a0, offset=128565248, bytes=4096, qiov=0x7fffe8008b48, type=1) at ../block/file-posix.c:2109
+ * #4  0x0000555555e16e69 in raw_co_preadv (bs=0x555556a6b8a0, offset=128565248, bytes=4096, qiov=0x7fffe8008b48, flags=0) at ../block/file-posix.c:2116
+ * #5  0x0000555555da1fcb in bdrv_driver_preadv (bs=0x555556a6b8a0, offset=128565248, bytes=4096, qiov=0x7fffe8008b48, qiov_offset=0, flags=0) at ../block/io.c:1160
+ * #6  0x0000555555da3133 in bdrv_aligned_preadv (child=0x555556a77680, req=0x7ffe45ddd970, offset=128565248, bytes=4096, align=512, qiov=0x7fffe8008b48, qiov_offset=0, flags=0) at ../block/io.c:1548
+ * #7  0x0000555555da3b6a in bdrv_co_preadv_part (child=0x555556a77680, offset=128565248, bytes=4096, qiov=0x7fffe8008b48, qiov_offset=0, flags=0) at ../block/io.c:1821
+ * #8  0x0000555555dd62fa in qcow2_co_preadv_task (bs=0x555556a71350, subc_type=QCOW2_SUBCLUSTER_NORMAL, host_offset=128565248, offset=4306878464, bytes=4096, qiov=0x7fffe8008b48, qiov_offset=0)
+ *     at ../block/qcow2.c:2294
+ * #9  0x0000555555dd63ad in qcow2_co_preadv_task_entry (task=0x7ffe45dddb20) at ../block/qcow2.c:2310
+ * #10 0x0000555555dd6100 in qcow2_add_task
+ *     (bs=0x555556a71350, pool=0x0, func=0x555555dd6321 <qcow2_co_preadv_task_entry>, subcluster_type=QCOW2_SUBCLUSTER_NORMAL, host_offset=128565248, offset=4306878464, bytes=4096,
+ *     qiov=0x7fffe8008b48, qiov_offset=0, l2meta=0x0) at ../block/qcow2.c:2252
+ * #11 0x0000555555dd6562 in qcow2_co_preadv_part (bs=0x555556a71350, offset=4306878464, bytes=4096, qiov=0x7fffe8008b48, qiov_offset=0, flags=0) at ../block/qcow2.c:2354
+ * #12 0x0000555555da1f4e in bdrv_driver_preadv (bs=0x555556a71350, offset=4306878464, bytes=4096, qiov=0x7fffe8008b48, qiov_offset=0, flags=0) at ../block/io.c:1150
+ * #13 0x0000555555da3133 in bdrv_aligned_preadv (child=0x55555774db90, req=0x7ffe45ddde00, offset=4306878464, bytes=4096, align=1, qiov=0x7fffe8008b48, qiov_offset=0, flags=0) at ../block/io.c:1548
+ * #14 0x0000555555da3b6a in bdrv_co_preadv_part (child=0x55555774db90, offset=4306878464, bytes=4096, qiov=0x7fffe8008b48, qiov_offset=0, flags=0) at ../block/io.c:1821
+ * #15 0x0000555555d90d83 in blk_co_do_preadv_part (blk=0x55555774d840, offset=4306878464, bytes=4096, qiov=0x7fffe8008b48, qiov_offset=0, flags=0) at ../block/block-backend.c:1311
+ * #16 0x0000555555d914f7 in blk_aio_read_entry (opaque=0x7fffe800bd80) at ../block/block-backend.c:1556
+ * #17 0x0000555555f02abd in coroutine_trampoline (i0=-402628976, i1=32767) at ../util/coroutine-ucontext.c:177
+ * #18 0x00007ffff5261190 in __start_context () at /lib64/libc.so.6
+ * #19 0x00007fffef695cf0 in  ()
+ * #20 0x0000000000000000 in  ()
+ *
+ * Thread 3 "IO iothread01" hit Breakpoint 1, qemu_coroutine_yield () at ../util/qemu-coroutine.c:197
+ * 197	    Coroutine *self = qemu_coroutine_self();
+ * (gdb) bt
+ * #0  qemu_coroutine_yield () at ../util/qemu-coroutine.c:197
+ * #1  0x0000555555e22421 in laio_co_submit (bs=0x555556a6b8a0, s=0x7ffe5814c8e0, fd=14, offset=8355229696, qiov=0x7fffe8008e38, type=2, dev_max_batch=0) at ../block/linux-aio.c:434
+ * #2  0x0000555555e16d8d in raw_co_prw (bs=0x555556a6b8a0, offset=8355229696, bytes=4096, qiov=0x7fffe8008e38, type=2) at ../block/file-posix.c:2091
+ * #3  0x0000555555e16eca in raw_co_pwritev (bs=0x555556a6b8a0, offset=8355229696, bytes=4096, qiov=0x7fffe8008e38, flags=0) at ../block/file-posix.c:2124
+ * #4  0x0000555555da233e in bdrv_driver_pwritev (bs=0x555556a6b8a0, offset=8355229696, bytes=4096, qiov=0x7fffe8008e38, qiov_offset=0, flags=0) at ../block/io.c:1233
+ * #5  0x0000555555da498d in bdrv_aligned_pwritev (child=0x555556a777e0, req=0x7ffe46cec940, offset=8355229696, bytes=4096, align=512, qiov=0x7fffe8008e38, qiov_offset=0, flags=0) at ../block/io.c:2097
+ * #6  0x0000555555da5296 in bdrv_co_pwritev_part (child=0x555556a777e0, offset=8355229696, bytes=4096, qiov=0x7fffe8008e38, qiov_offset=0, flags=0) at ../block/io.c:2289
+ * #7  0x0000555555dd6c30 in qcow2_co_pwritev_task (bs=0x555556a714b0, host_offset=8355229696, offset=6820900864, bytes=4096, qiov=0x7fffe8008e38, qiov_offset=0, l2meta=0x0) at ../block/qcow2.c:2567
+ * #8  0x0000555555dd6d5e in qcow2_co_pwritev_task_entry (task=0x7ffe46cecb40) at ../block/qcow2.c:2597
+ * #9  0x0000555555dd6100 in qcow2_add_task
+ *     (bs=0x555556a714b0, pool=0x0, func=0x555555dd6cd3 <qcow2_co_pwritev_task_entry>, subcluster_type=QCOW2_SUBCLUSTER_UNALLOCATED_PLAIN, host_offset=8355229696, offset=6820900864, bytes=4096,
+ *     qiov=0x7fffe8008e38, qiov_offset=0, l2meta=0x0) at ../block/qcow2.c:2252
+ * #10 0x0000555555dd6f33 in qcow2_co_pwritev_part (bs=0x555556a714b0, offset=6820900864, bytes=4096, qiov=0x7fffe8008e38, qiov_offset=0, flags=0) at ../block/qcow2.c:2648
+ * #11 0x0000555555da22a0 in bdrv_driver_pwritev (bs=0x555556a714b0, offset=6820900864, bytes=4096, qiov=0x7fffe8008e38, qiov_offset=0, flags=0) at ../block/io.c:1221
+ * #12 0x0000555555da498d in bdrv_aligned_pwritev (child=0x55555774dd00, req=0x7ffe46cece00, offset=6820900864, bytes=4096, align=1, qiov=0x7fffe8008e38, qiov_offset=0, flags=0) at ../block/io.c:2097
+ * #13 0x0000555555da5296 in bdrv_co_pwritev_part (child=0x55555774dd00, offset=6820900864, bytes=4096, qiov=0x7fffe8008e38, qiov_offset=0, flags=0) at ../block/io.c:2289
+ * #14 0x0000555555d90fe0 in blk_co_do_pwritev_part (blk=0x55555774d9b0, offset=6820900864, bytes=4096, qiov=0x7fffe8008e38, qiov_offset=0, flags=0) at ../block/block-backend.c:1388
+ * #15 0x0000555555d915a7 in blk_aio_write_entry (opaque=0x7fffe800a480) at ../block/block-backend.c:1568
+ * #16 0x0000555555f02abd in coroutine_trampoline (i0=-402632592, i1=32767) at ../util/coroutine-ucontext.c:177
+ * #17 0x00007ffff5261190 in __start_context () at /lib64/libc.so.6
+ * #18 0x00007fffef695cf0 in  ()
+ * #19 0x0000000000000000 in  ()
+ */
 void coroutine_fn qemu_coroutine_yield(void)
 {
     Coroutine *self = qemu_coroutine_self();
diff --git a/util/qemu-option.c b/util/qemu-option.c
index eedd08929..81e1bebf7 100644
--- a/util/qemu-option.c
+++ b/util/qemu-option.c
@@ -1122,6 +1122,35 @@ bool qemu_opts_validate(QemuOpts *opts, const QemuOptDesc *desc, Error **errp)
  * When @func() returns non-zero, break the loop and return that value.
  * Return zero when the loop completes.
  */
+/*
+ * called by:
+ *   - block/blkdebug.c|309| <<read_config>> qemu_opts_foreach(&inject_error_opts, add_rule, &d, &local_err);
+ *   - block/blkdebug.c|317| <<read_config>> qemu_opts_foreach(&set_state_opts, add_rule, &d, &local_err);
+ *   - hw/core/numa.c|732| <<parse_numa_opts>> qemu_opts_foreach(qemu_find_opts("numa"), parse_numa, ms, &error_fatal);
+ *   - net/net.c|1570| <<net_init_clients>> if (qemu_opts_foreach(qemu_find_opts("netdev"),
+ *   - net/net.c|1575| <<net_init_clients>> if (qemu_opts_foreach(qemu_find_opts("nic"), net_param_nic, NULL, errp)) {
+ *   - net/net.c|1579| <<net_init_clients>> if (qemu_opts_foreach(qemu_find_opts("net"), net_init_client, NULL, errp)) {
+ *   - softmmu/tpm.c|166| <<tpm_init>> if (qemu_opts_foreach(qemu_find_opts("tpmdev"),
+ *   - softmmu/vl.c|710| <<configure_blockdev>> qemu_opts_foreach(qemu_find_opts("drive"), drive_enable_snapshot,
+ *   - softmmu/vl.c|713| <<configure_blockdev>> if (qemu_opts_foreach(qemu_find_opts("drive"), drive_init_func,
+ *   - softmmu/vl.c|1265| <<qemu_disable_default_devices>> qemu_opts_foreach(qemu_find_opts("device"),
+ *   - softmmu/vl.c|1267| <<qemu_disable_default_devices>> qemu_opts_foreach(qemu_find_opts("global"),
+ *   - softmmu/vl.c|1881| <<qemu_create_early_backends>> qemu_opts_foreach(qemu_find_opts("chardev"),
+ *   - softmmu/vl.c|1885| <<qemu_create_early_backends>> qemu_opts_foreach(qemu_find_opts("fsdev"),
+ *   - softmmu/vl.c|1921| <<qemu_create_late_backends>> qemu_opts_foreach(qemu_find_opts("mon"),
+ *   - softmmu/vl.c|2161| <<user_register_global_props>> qemu_opts_foreach(qemu_find_opts("global"),
+ *   - softmmu/vl.c|2218| <<configure_accelerators>> qemu_opts_foreach(qemu_find_opts("icount"),
+ *   - softmmu/vl.c|2268| <<configure_accelerators>> if (!qemu_opts_foreach(qemu_find_opts("accel"),
+ *   - softmmu/vl.c|2373| <<qemu_process_early_options>> qemu_opts_foreach(olist, parse_sandbox, NULL, &error_fatal);
+ *   - softmmu/vl.c|2377| <<qemu_process_early_options>> qemu_opts_foreach(qemu_find_opts("name"),
+ *   - softmmu/vl.c|2380| <<qemu_process_early_options>> if (qemu_opts_foreach(qemu_find_opts("action"),
+ *   - softmmu/vl.c|2386| <<qemu_process_early_options>> qemu_opts_foreach(qemu_find_opts("add-fd"),
+ *   - softmmu/vl.c|2389| <<qemu_process_early_options>> qemu_opts_foreach(qemu_find_opts("add-fd"),
+ *   - softmmu/vl.c|2422| <<qemu_process_help_options>> if (qemu_opts_foreach(qemu_find_opts("device"),
+ *   - softmmu/vl.c|2480| <<qemu_init_displays>> qemu_opts_foreach(qemu_find_opts("vnc"),
+ *   - softmmu/vl.c|2513| <<qemu_create_cli_devices>> qemu_opts_foreach(qemu_find_opts("fw_cfg"),
+ *   - softmmu/vl.c|2524| <<qemu_create_cli_devices>> qemu_opts_foreach(qemu_find_opts("device"),
+ */
 int qemu_opts_foreach(QemuOptsList *list, qemu_opts_loopfunc func,
                       void *opaque, Error **errp)
 {
diff --git a/util/qemu-thread-common.h b/util/qemu-thread-common.h
index 2af6b1208..f3cac9c8b 100644
--- a/util/qemu-thread-common.h
+++ b/util/qemu-thread-common.h
@@ -41,6 +41,11 @@ static inline void qemu_mutex_post_lock(QemuMutex *mutex,
     trace_qemu_mutex_locked(mutex, file, line);
 }
 
+/*
+ * called by:
+ *   - util/qemu-thread-posix.c|115| <<qemu_mutex_unlock_impl>> qemu_mutex_pre_unlock(mutex, file, line);
+ *   - util/qemu-thread-posix.c|224| <<qemu_cond_wait_impl>> qemu_mutex_pre_unlock(mutex, file, line);
+ */
 static inline void qemu_mutex_pre_unlock(QemuMutex *mutex,
                                          const char *file, int line)
 {
diff --git a/util/qemu-thread-posix.c b/util/qemu-thread-posix.c
index ac1d56e67..b0f537e5f 100644
--- a/util/qemu-thread-posix.c
+++ b/util/qemu-thread-posix.c
@@ -195,6 +195,12 @@ void qemu_cond_signal(QemuCond *cond)
     int err;
 
     assert(cond->initialized);
+    /*
+     * pthread_cond_signal函数的作用是发送一个信号给另外
+     * 一个正在处于阻塞等待状态的线程,使其脱离阻塞状态,
+     * 继续执行.如果没有线程处在阻塞等待状态,
+     * pthread_cond_signal也会成功返回.
+     */
     err = pthread_cond_signal(&cond->cond);
     if (err)
         error_exit(err, __func__);
diff --git a/util/qsp.c b/util/qsp.c
index 8562b14a8..a6cddd473 100644
--- a/util/qsp.c
+++ b/util/qsp.c
@@ -124,6 +124,13 @@ static const char * const qsp_typenames[] = {
     [QSP_CONDVAR]   = "condvar",
 };
 
+/*
+ * 在以下使用:
+ *   - util/qsp.c|127| <<global>> QemuMutexLockFunc qemu_bql_mutex_lock_func = qemu_mutex_lock_impl;
+ *   - softmmu/cpus.c|519| <<qemu_mutex_lock_iothread_impl>> QemuMutexLockFunc bql_lock = qatomic_read(&qemu_bql_mutex_lock_func);
+ *   - util/qsp.c|442| <<qsp_enable>> qatomic_set(&qemu_bql_mutex_lock_func, qsp_bql_mutex_lock);
+ *   - util/qsp.c|453| <<qsp_disable>> qatomic_set(&qemu_bql_mutex_lock_func, qemu_mutex_lock_impl);
+ */
 QemuMutexLockFunc qemu_bql_mutex_lock_func = qemu_mutex_lock_impl;
 QemuMutexLockFunc qemu_mutex_lock_func = qemu_mutex_lock_impl;
 QemuMutexTrylockFunc qemu_mutex_trylock_func = qemu_mutex_trylock_impl;
diff --git a/util/readline.c b/util/readline.c
index f1ac6e476..7ece21ec6 100644
--- a/util/readline.c
+++ b/util/readline.c
@@ -273,6 +273,51 @@ static void readline_hist_add(ReadLineState *rs, const char *cmdline)
 
 /* completion support */
 
+/*
+ * (gdb) bt
+ * #0  readline_add_completion (rs=0x555556ac2f10, str=0x7fffffffc830 "registers") at ../util/readline.c:278
+ * #1  0x0000555555acd136 in cmd_completion (mon=0x555556848620, name=0x55555730bc30 "reg", list=0x55555609e7a1 "registers") at ../monitor/hmp.c:1190
+ * #2  0x0000555555acd505 in monitor_find_completion_by_table (mon=0x555556848620, cmd_table=0x5555566f9740 <hmp_info_cmds>, args=0x7fffffffc9d8, nb_args=1) at ../monitor/hmp.c:1284
+ * #3  0x0000555555acd5a5 in monitor_find_completion_by_table (mon=0x555556848620, cmd_table=0x5555566faaa0 <hmp_cmds>, args=0x7fffffffc9d0, nb_args=2) at ../monitor/hmp.c:1301
+ * #4  0x0000555555acd90d in monitor_find_completion (opaque=0x555556848620, cmdline=0x5555574f8f60 "info reg") at ../monitor/hmp.c:1380
+ * #5  0x0000555555f1906b in readline_completion (rs=0x555556ac2f10) at ../util/readline.c:307
+ * #6  0x0000555555f19522 in readline_handle_byte (rs=0x555556ac2f10, ch=9) at ../util/readline.c:397
+ * #7  0x0000555555acd9a8 in monitor_read (opaque=0x555556848620, buf=0x7fffffffcbe0 "\t\321\377\377\377\177", size=1) at ../monitor/hmp.c:1393
+ * #8  0x0000555555e31613 in qemu_chr_be_write_impl (s=0x555556a68ab0, buf=0x7fffffffcbe0 "\t\321\377\377\377\177", len=1) at ../chardev/char.c:201
+ * #9  0x0000555555e31677 in qemu_chr_be_write (s=0x555556a68ab0, buf=0x7fffffffcbe0 "\t\321\377\377\377\177", len=1) at ../chardev/char.c:213
+ * #10 0x0000555555e340a4 in fd_chr_read (chan=0x555556a68bc0, cond=G_IO_IN, opaque=0x555556a68ab0) at ../chardev/char-fd.c:72
+ * #11 0x0000555555d335b4 in qio_channel_fd_source_dispatch (source=0x5555578095c0, callback=0x555555e33f7a <fd_chr_read>, user_data=0x555556a68ab0) at ../io/channel-watch.c:84
+ * #12 0x00007ffff6c40119 in g_main_context_dispatch () at /lib64/libglib-2.0.so.0
+ * #13 0x0000555555f12010 in glib_pollfds_poll () at ../util/main-loop.c:297
+ * #14 0x0000555555f1208a in os_host_main_loop_wait (timeout=746322616) at ../util/main-loop.c:320
+ * #15 0x0000555555f1218f in main_loop_wait (nonblocking=0) at ../util/main-loop.c:596
+ * #16 0x0000555555a7a05e in qemu_main_loop () at ../softmmu/runstate.c:734
+ * #17 0x000055555581fe62 in qemu_main (argc=20, argv=0x7fffffffdec8, envp=0x0) at ../softmmu/main.c:38
+ * #18 0x000055555581fe94 in main (argc=20, argv=0x7fffffffdec8) at ../softmmu/main.c:47
+ *
+ * called by:
+ *   - monitor/hmp.c|1198| <<cmd_completion>> readline_add_completion(mon->rs, cmd);
+ *   - monitor/hmp.c|1259| <<file_completion>> readline_add_completion(mon->rs, file);
+ *   - monitor/hmp.c|1346| <<monitor_find_completion_by_table>> readline_add_completion(mon->rs, name);
+ *   - monitor/misc.c|1486| <<add_completion_option>> readline_add_completion(rs, option);
+ *   - monitor/misc.c|1506| <<chardev_add_completion>> readline_add_completion(rs, chr_name);
+ *   - monitor/misc.c|1548| <<device_add_completion>> readline_add_completion(rs, name);
+ *   - monitor/misc.c|1572| <<object_add_completion>> readline_add_completion(rs, name);
+ *   - monitor/misc.c|1619| <<peripheral_device_del_completion>> readline_add_completion(rs, dev->id);
+ *   - monitor/misc.c|1642| <<chardev_remove_completion>> readline_add_completion(rs, chr->label);
+ *   - monitor/misc.c|1664| <<ringbuf_completion>> readline_add_completion(rs, chr_info->label);
+ *   - monitor/misc.c|1710| <<object_del_completion>> readline_add_completion(rs, info->name);
+ *   - monitor/misc.c|1734| <<sendkey_completion>> readline_add_completion(rs, QKeyCode_str(i));
+ *   - monitor/misc.c|1754| <<set_link_completion>> readline_add_completion(rs, name);
+ *   - monitor/misc.c|1782| <<netdev_del_completion>> readline_add_completion(rs, name);
+ *   - monitor/misc.c|1799| <<info_trace_events_completion>> readline_add_completion(rs, trace_event_get_name(ev));
+ *   - monitor/misc.c|1817| <<trace_event_completion>> readline_add_completion(rs, trace_event_get_name(ev));
+ *   - monitor/misc.c|1851| <<migrate_set_capability_completion>> readline_add_completion(rs, name);
+ *   - monitor/misc.c|1872| <<migrate_set_parameter_completion>> readline_add_completion(rs, name);
+ *   - monitor/misc.c|1905| <<vm_completion>> readline_add_completion(rs, completion);
+ *   - monitor/misc.c|1909| <<vm_completion>> readline_add_completion(rs, completion);
+ *   - qemu-io.c|355| <<completion_match>> readline_add_completion(readline_state, cmd);
+ */
 void readline_add_completion(ReadLineState *rs, const char *str)
 {
     if (rs->nb_completions < READLINE_MAX_COMPLETIONS) {
@@ -296,6 +341,10 @@ static int completion_comp(const void *a, const void *b)
     return strcmp(*(const char **) a, *(const char **) b);
 }
 
+/*
+ * called by:
+ *   - util/readline.c|395| <<readline_handle_byte>> readline_completion(rs);
+ */
 static void readline_completion(ReadLineState *rs)
 {
     int len, i, j, max_width, nb_cols, max_prefix;
diff --git a/util/thread-pool.c b/util/thread-pool.c
index 31113b586..316c2c168 100644
--- a/util/thread-pool.c
+++ b/util/thread-pool.c
@@ -276,6 +276,18 @@ typedef struct ThreadPoolCo {
     int ret;
 } ThreadPoolCo;
 
+/*
+ * (gdb) bt
+ * #0  thread_pool_co_cb (opaque=0x7ffe3cef1670, ret=0) at ../util/thread-pool.c:281
+ * #1  0x0000555555f166e2 in thread_pool_completion_bh (opaque=0x7fffe8002370) at ../util/thread-pool.c:199
+ * #2  0x0000555555effdcc in aio_bh_call (bh=0x7fffe8002470) at ../util/async.c:150
+ * #3  0x0000555555effed6 in aio_bh_poll (ctx=0x555556a67590) at ../util/async.c:178
+ * #4  0x0000555555ee7aa5 in aio_poll (ctx=0x555556a67590, blocking=true) at ../util/aio-posix.c:712
+ * #5  0x0000555555d5cb66 in iothread_run (opaque=0x555556a67220) at ../iothread.c:67
+ * #6  0x0000555555eec4de in qemu_thread_start (args=0x555556a67c00) at ../util/qemu-thread-posix.c:504
+ * #7  0x00007ffff55eeea5 in start_thread () at /lib64/libpthread.so.0
+ * #8  0x00007ffff53179fd in clone () at /lib64/libc.so.6
+ */
 static void thread_pool_co_cb(void *opaque, int ret)
 {
     ThreadPoolCo *co = opaque;
@@ -284,6 +296,50 @@ static void thread_pool_co_cb(void *opaque, int ret)
     aio_co_wake(co->co);
 }
 
+/*
+ * (gdb) bt
+ * #0  raw_thread_pool_submit (bs=0x560c43bfbe00, func=0x560c424f3acd <handle_aiocb_rw>, arg=0x7f9a7f76d730) at ../block/file-posix.c:2060
+ * #1  0x0000560c424f4e19 in raw_co_prw (bs=0x560c43bfbe00, offset=5971968, bytes=8192, qiov=0x7f9a7800e670, type=1) at ../block/file-posix.c:2109
+ * #2  0x0000560c424f4e69 in raw_co_preadv (bs=0x560c43bfbe00, offset=5971968, bytes=8192, qiov=0x7f9a7800e670, flags=0) at ../block/file-posix.c:2116
+ * #3  0x0000560c4247ffcb in bdrv_driver_preadv (bs=0x560c43bfbe00, offset=5971968, bytes=8192, qiov=0x7f9a7800e670, qiov_offset=0, flags=0) at ../block/io.c:1160
+ * #4  0x0000560c42481133 in bdrv_aligned_preadv (child=0x560c43c02020, req=0x7f9a7f76d970, offset=5971968, bytes=8192, align=1, qiov=0x7f9a7800e670, qiov_offset=0, flags=0) at ../block/io.c:1548
+ * #5  0x0000560c42481b6a in bdrv_co_preadv_part (child=0x560c43c02020, offset=5971968, bytes=8192, qiov=0x7f9a7800e670, qiov_offset=0, flags=0) at ../block/io.c:1821
+ * #6  0x0000560c424b42fa in qcow2_co_preadv_task (bs=0x560c43bf4770, subc_type=QCOW2_SUBCLUSTER_NORMAL, host_offset=5971968, offset=6867263488, bytes=8192, qiov=0x7f9a7800e670, qiov_offset=0)
+ *     at ../block/qcow2.c:2294
+ * #7  0x0000560c424b43ad in qcow2_co_preadv_task_entry (task=0x7f9a7f76db20) at ../block/qcow2.c:2310
+ * #8  0x0000560c424b4100 in qcow2_add_task
+ *     (bs=0x560c43bf4770, pool=0x0, func=0x560c424b4321 <qcow2_co_preadv_task_entry>, subcluster_type=QCOW2_SUBCLUSTER_NORMAL, host_offset=5971968, offset=6867263488, bytes=8192, qiov=0x7f9a7800e670, qiov_offset=0, l2meta=0x0) at ../block/qcow2.c:2252
+ * #9  0x0000560c424b4562 in qcow2_co_preadv_part (bs=0x560c43bf4770, offset=6867263488, bytes=8192, qiov=0x7f9a7800e670, qiov_offset=0, flags=0) at ../block/qcow2.c:2354
+ * #10 0x0000560c4247ff4e in bdrv_driver_preadv (bs=0x560c43bf4770, offset=6867263488, bytes=8192, qiov=0x7f9a7800e670, qiov_offset=0, flags=0) at ../block/io.c:1150
+ * #11 0x0000560c42481133 in bdrv_aligned_preadv (child=0x560c43bface0, req=0x7f9a7f76de00, offset=6867263488, bytes=8192, align=1, qiov=0x7f9a7800e670, qiov_offset=0, flags=0) at ../block/io.c:1548
+ * #12 0x0000560c42481b6a in bdrv_co_preadv_part (child=0x560c43bface0, offset=6867263488, bytes=8192, qiov=0x7f9a7800e670, qiov_offset=0, flags=0) at ../block/io.c:1821
+ * #13 0x0000560c4246ed83 in blk_co_do_preadv_part (blk=0x560c43bf4420, offset=6867263488, bytes=8192, qiov=0x7f9a7800e670, qiov_offset=0, flags=0) at ../block/block-backend.c:1311
+ * #14 0x0000560c4246f4f7 in blk_aio_read_entry (opaque=0x7f9a7800ca90) at ../block/block-backend.c:1556
+ * #15 0x0000560c425e0abd in coroutine_trampoline (i0=1136662672, i1=22028) at ../util/coroutine-ucontext.c:177
+ * #16 0x00007f9a85b38190 in __start_context () at /lib64/libc.so.6
+ * #17 0x00007ffee1ff0d00 in  ()
+ * #18 0x0000000000000000 in  ()
+ * (gdb) info threads 
+ *   Id   Target Id                                           Frame 
+ *   1    Thread 0x7f9a888aac80 (LWP 23424) "qemu-system-x86" 0x00007f9a85be3d8f in ppoll () from /lib64/libc.so.6
+ *   2    Thread 0x7f9a8076f700 (LWP 23425) "qemu-system-x86" 0x00007f9a85be8d19 in syscall () from /lib64/libc.so.6
+ * * 3    Thread 0x7f9a7ff6e700 (LWP 23426) "IO iothread01"   raw_thread_pool_submit (bs=0x560c43bfbe00, func=0x560c424f3acd <handle_aiocb_rw>, arg=0x7f9a7f76d730) at ../block/file-posix.c:2060
+ *   4    Thread 0x7f9a7ea05700 (LWP 23431) "CPU 0/KVM"       0x00007f9a85be5397 in ioctl () from /lib64/libc.so.6
+ *   5    Thread 0x7f9a7e204700 (LWP 23432) "CPU 1/KVM"       0x00007f9a85be5397 in ioctl () from /lib64/libc.so.6
+ *   6    Thread 0x7f9a7da03700 (LWP 23433) "CPU 2/KVM"       0x00007f9a85be5397 in ioctl () from /lib64/libc.so.6
+ *   7    Thread 0x7f9a7d202700 (LWP 23434) "CPU 3/KVM"       0x00007f9a85be5397 in ioctl () from /lib64/libc.so.6
+ *   8    Thread 0x7f98f63ff700 (LWP 23436) "vnc_worker"      0x00007f9a85ec9a35 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0
+ *   10   Thread 0x7f98ddbdb700 (LWP 23440) "worker"          0x00007f9a85ec9de2 in pthread_cond_timedwait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0
+ *   12   Thread 0x7f98dc9d7700 (LWP 23442) "worker"          0x00007f9a85ec9de2 in pthread_cond_timedwait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0
+ *   20   Thread 0x7f98b9ffb700 (LWP 23453) "worker"          0x00007f9a85ec9de2 in pthread_cond_timedwait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0
+ *
+ * called by:
+ *   - block/file-posix.c|2061| <<raw_thread_pool_submit>> return thread_pool_submit_co(pool, func, arg);
+ *   - block/qcow2-threads.c|54| <<qcow2_co_process>> ret = thread_pool_submit_co(pool, func, arg);
+ *   - scsi/pr-manager.c|65| <<pr_manager_execute>> return thread_pool_submit_co(pool, pr_manager_worker, &data);
+ *   - scsi/qemu-pr-helper.c|195| <<do_sgio>> r = thread_pool_submit_co(pool, do_sgio_worker, &data);
+ *   - tests/unit/test-thread-pool.c|81| <<co_test_cb>> thread_pool_submit_co(pool, worker_cb, data);
+ */
 int coroutine_fn thread_pool_submit_co(ThreadPool *pool, ThreadPoolFunc *func,
                                        void *arg)
 {
-- 
2.34.1

