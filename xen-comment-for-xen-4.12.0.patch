From 16e5e9d6226e46098a345dacf7c0de6736564c3c Mon Sep 17 00:00:00 2001
From: Dongli Zhang <dongli.zhang0129@gmail.com>
Date: Mon, 15 Jun 2020 21:23:44 -0700
Subject: [PATCH 1/1] xen comment for xen-4.12.0

xen-4.12.0

Signed-off-by: Dongli Zhang <dongli.zhang0129@gmail.com>
---
 tools/xenstore/hashtable.c             |   5 +
 tools/xenstore/talloc.c                | 266 +++++++++++++++
 tools/xenstore/tdb.c                   | 445 ++++++++++++++++++++++++-
 tools/xenstore/tdb.h                   |  19 ++
 tools/xenstore/xenstored_core.c        | 167 ++++++++++
 tools/xenstore/xenstored_core.h        |  41 +++
 tools/xenstore/xenstored_domain.c      |  23 ++
 tools/xenstore/xenstored_transaction.c | 306 +++++++++++++++++
 tools/xenstore/xenstored_watch.c       |  11 +
 tools/xenstore/xs_tdb_dump.c           |   5 +
 xen/arch/x86/domain.c                  |   4 +
 xen/arch/x86/emul-i8254.c              | 141 ++++++++
 xen/arch/x86/hvm/hvm.c                 |   8 +
 xen/arch/x86/hvm/vioapic.c             |  13 +
 xen/arch/x86/hvm/vlapic.c              |  69 ++++
 xen/arch/x86/hvm/vmx/intr.c            |   9 +
 xen/arch/x86/hvm/vmx/vmcs.c            |  89 +++++
 xen/arch/x86/hvm/vmx/vmx.c             |  11 +
 xen/arch/x86/hvm/vpic.c                |  26 ++
 xen/arch/x86/hvm/vpt.c                 | 381 +++++++++++++++++++++
 xen/arch/x86/irq.c                     |  66 ++++
 xen/arch/x86/mm/hap/hap.c              |   4 +
 xen/common/domain.c                    |  23 ++
 xen/common/timer.c                     | 381 +++++++++++++++++++++
 xen/include/asm-x86/hvm/hvm.h          |  11 +
 xen/include/asm-x86/hvm/vcpu.h         |  14 +
 xen/include/asm-x86/hvm/vlapic.h       |  14 +
 xen/include/asm-x86/hvm/vmx/vmcs.h     |   9 +
 xen/include/asm-x86/hvm/vpt.h          | 104 ++++++
 xen/include/asm-x86/irq.h              |  23 ++
 xen/include/asm-x86/paging.h           |   5 +
 xen/include/public/arch-x86/hvm/save.h |   6 +
 32 files changed, 2698 insertions(+), 1 deletion(-)

diff --git a/tools/xenstore/hashtable.c b/tools/xenstore/hashtable.c
index 0ba1d55..0709aa6 100644
--- a/tools/xenstore/hashtable.c
+++ b/tools/xenstore/hashtable.c
@@ -31,6 +31,11 @@ const unsigned int prime_table_length = sizeof(primes)/sizeof(primes[0]);
 const unsigned int max_load_factor = 65; /* percentage */
 
 /*****************************************************************************/
+/*
+ * called by:
+ *   - xenstore/xenstored_core.c|1789| <<check_store_>> create_hashtable(16, hash_from_key_fn, keys_equal_fn);
+ *   - xenstore/xenstored_core.c|1916| <<check_store>> create_hashtable(16, hash_from_key_fn, keys_equal_fn);
+ */
 struct hashtable *
 create_hashtable(unsigned int minsize,
                  unsigned int (*hashf) (void*),
diff --git a/tools/xenstore/talloc.c b/tools/xenstore/talloc.c
index d7edcf3..bf6fd1e 100644
--- a/tools/xenstore/talloc.c
+++ b/tools/xenstore/talloc.c
@@ -57,9 +57,47 @@
 #define ALWAYS_REALLOC 0
 
 
+/*
+ * 在以下使用MAX_TALLOC_SIZE:
+ *   - xenstore/talloc.c|211| <<_talloc>> if (size >= MAX_TALLOC_SIZE) {
+ *   - xenstore/talloc.c|649| <<_talloc_realloc>> if (size >= MAX_TALLOC_SIZE) {
+ *   - xenstore/talloc.c|1236| <<_talloc_array>> if (count >= MAX_TALLOC_SIZE/el_size) {
+ *   - xenstore/talloc.c|1247| <<_talloc_zero_array>> if (count >= MAX_TALLOC_SIZE/el_size) {
+ *   - xenstore/talloc.c|1259| <<_talloc_realloc_array>> if (count >= MAX_TALLOC_SIZE/el_size) {
+ */
 #define MAX_TALLOC_SIZE 0x10000000
+/*
+ * 在以下使用TALLOC_MAGIC:
+ *   - xenstore/talloc.c|147| <<talloc_chunk_from_ptr>> if ((tc->flags & ~0xF) != TALLOC_MAGIC) {
+ *   - xenstore/talloc.c|219| <<_talloc>> tc->flags = TALLOC_MAGIC;
+ */
 #define TALLOC_MAGIC 0xe814ec70
+/*
+ * 在以下使用TALLOC_FLAG_FREE:
+ *   - xenstore/talloc.c|150| <<talloc_chunk_from_ptr>> if (tc->flags & TALLOC_FLAG_FREE) {
+ *   - xenstore/talloc.c|626| <<talloc_free>> tc->flags |= TALLOC_FLAG_FREE;
+ *   - xenstore/talloc.c|666| <<_talloc_realloc>> tc->flags |= TALLOC_FLAG_FREE;
+ *   - xenstore/talloc.c|678| <<_talloc_realloc>> tc->flags &= ~TALLOC_FLAG_FREE;
+ *   - xenstore/talloc.c|683| <<_talloc_realloc>> tc->flags &= ~TALLOC_FLAG_FREE;
+ */
 #define TALLOC_FLAG_FREE 0x01
+/*
+ * 在以下使用TALLOC_FLAG_LOOP:
+ *   - xenstore/talloc.c|594| <<talloc_free>> if (tc->flags & TALLOC_FLAG_LOOP) {
+ *   - xenstore/talloc.c|612| <<talloc_free>> tc->flags |= TALLOC_FLAG_LOOP;
+ *   - xenstore/talloc.c|778| <<talloc_total_size>> if (tc->flags & TALLOC_FLAG_LOOP) {
+ *   - xenstore/talloc.c|782| <<talloc_total_size>> tc->flags |= TALLOC_FLAG_LOOP;
+ *   - xenstore/talloc.c|789| <<talloc_total_size>> tc->flags &= ~TALLOC_FLAG_LOOP;
+ *   - xenstore/talloc.c|802| <<talloc_total_blocks>> if (tc->flags & TALLOC_FLAG_LOOP) {
+ *   - xenstore/talloc.c|806| <<talloc_total_blocks>> tc->flags |= TALLOC_FLAG_LOOP;
+ *   - xenstore/talloc.c|813| <<talloc_total_blocks>> tc->flags &= ~TALLOC_FLAG_LOOP;
+ *   - xenstore/talloc.c|840| <<talloc_report_depth>> if (tc->flags & TALLOC_FLAG_LOOP) {
+ *   - xenstore/talloc.c|844| <<talloc_report_depth>> tc->flags |= TALLOC_FLAG_LOOP;
+ *   - xenstore/talloc.c|862| <<talloc_report_depth>> tc->flags &= ~TALLOC_FLAG_LOOP;
+ *   - xenstore/talloc.c|952| <<talloc_report_depth_str>> if (tc->flags & TALLOC_FLAG_LOOP) {
+ *   - xenstore/talloc.c|956| <<talloc_report_depth_str>> tc->flags |= TALLOC_FLAG_LOOP;
+ *   - xenstore/talloc.c|980| <<talloc_report_depth_str>> tc->flags &= ~TALLOC_FLAG_LOOP;
+ */
 #define TALLOC_FLAG_LOOP 0x02
 #define TALLOC_MAGIC_REFERENCE ((const char *)1)
 
@@ -81,7 +119,39 @@
    talloc_enable_leak_report_full() is called, otherwise it remains
    NULL
 */
+/*
+ * 在以下使用null_context:
+ *   - xenstore/talloc.c|176| <<_talloc>> context = null_context;
+ *   - xenstore/talloc.c|292| <<talloc_unreference>> context = null_context;
+ *   - xenstore/talloc.c|295| <<talloc_unreference>> if ((context == null_context) && tc->null_refs) {
+ *   - xenstore/talloc.c|332| <<talloc_unlink>> context = null_context;
+ *   - xenstore/talloc.c|519| <<talloc_free_children>> const void *new_parent = null_context;
+ *   - xenstore/talloc.c|525| <<talloc_free_children>> if (new_parent == null_context) {
+ *   - xenstore/talloc.c|686| <<talloc_steal>> new_ctx = null_context;
+ *   - xenstore/talloc.c|738| <<talloc_total_size>> ptr = null_context;
+ *   - xenstore/talloc.c|839| <<talloc_report_full>> ptr = null_context;
+ *   - xenstore/talloc.c|860| <<talloc_report>> ptr = null_context;
+ *   - xenstore/talloc.c|885| <<talloc_report_null>> if (talloc_total_size(null_context) != 0) {
+ *   - xenstore/talloc.c|886| <<talloc_report_null>> talloc_report(null_context, stderr);
+ *   - xenstore/talloc.c|895| <<talloc_report_null_full>> if (talloc_total_size(null_context) != 0) {
+ *   - xenstore/talloc.c|896| <<talloc_report_null_full>> talloc_report_full(null_context, stderr);
+ *   - xenstore/talloc.c|905| <<talloc_enable_null_tracking>> if (null_context == NULL) {
+ *   - xenstore/talloc.c|906| <<talloc_enable_null_tracking>> null_context = talloc_named_const(NULL, 0, "null_context");
+ *   - xenstore/talloc.c|960| <<talloc_describe_all>> if (null_context == NULL) {
+ *   - xenstore/talloc.c|966| <<talloc_describe_all>> talloc_get_name(null_context),
+ *   - xenstore/talloc.c|967| <<talloc_describe_all>> (unsigned long )talloc_total_size(null_context),
+ *   - xenstore/talloc.c|968| <<talloc_describe_all>> (unsigned long )talloc_total_blocks(null_context));
+ *   - xenstore/talloc.c|973| <<talloc_describe_all>> talloc_report_depth_str(null_context, &s, &len, &buflen, 1);
+ */
 static const void *null_context;
+/*
+ * called by:
+ *   - xenstore/talloc.c|1246| <<talloc_autofree>> talloc_free(cleanup_context);
+ *   - xenstore/talloc.c|1247| <<talloc_autofree>> cleanup_context = NULL;
+ *   - xenstore/talloc.c|1266| <<talloc_autofree_context>> if (cleanup_context == NULL) {
+ *   - xenstore/talloc.c|1267| <<talloc_autofree_context>> cleanup_context = talloc_named_const(NULL, 0, "autofree_context");
+ *   - xenstore/talloc.c|1270| <<talloc_autofree_context>> return cleanup_context;
+ */
 static void *cleanup_context;
 
 
@@ -105,9 +175,17 @@ struct talloc_chunk {
 
 /* 16 byte alignment seems to keep everyone happy */
 #define TC_HDR_SIZE ((sizeof(struct talloc_chunk)+15)&~15)
+/*
+ * 参数的tc再加上TC_HDR_SIZE
+ * 似乎内存的结构是HDR_SIZE+data
+ */
 #define TC_PTR_FROM_CHUNK(tc) ((void *)(TC_HDR_SIZE + (char*)tc))
 
 /* panic if we get a bad magic value */
+/*
+ * 似乎内存的结构是HDR_SIZE+data
+ * 这里是根据data获得HDR
+ */
 static struct talloc_chunk *talloc_chunk_from_ptr(const void *ptr)
 {
 	const char *pp = ptr;
@@ -122,6 +200,12 @@ static struct talloc_chunk *talloc_chunk_from_ptr(const void *ptr)
 }
 
 /* hook into the front of the list */
+/*
+ * 在以下使用_TLIST_ADD()
+ *   - xenstore/talloc.c|274| <<_talloc>> _TLIST_ADD(parent->child, tc);
+ *   - xenstore/talloc.c|348| <<talloc_reference>> _TLIST_ADD(tc->refs, handle);
+ *   - xenstore/talloc.c|795| <<talloc_steal>> _TLIST_ADD(new_tc->child, tc);
+ */
 #define _TLIST_ADD(list, p) \
 do { \
         if (!(list)) { \
@@ -136,6 +220,14 @@ do { \
 } while (0)
 
 /* remove an element from a list - element doesn't have to be in list. */
+/*
+ * 在以下使用_TLIST_REMOVE():
+ *   - xenstore/talloc.c|318| <<talloc_reference_destructor>> _TLIST_REMOVE(tc2->refs, handle);
+ *   - xenstore/talloc.c|384| <<talloc_unreference>> _TLIST_REMOVE(tc->refs, h);
+ *   - xenstore/talloc.c|656| <<talloc_free>> _TLIST_REMOVE(tc->parent->child, tc);
+ *   - xenstore/talloc.c|764| <<talloc_steal>> _TLIST_REMOVE(tc->parent->child, tc);
+ *   - xenstore/talloc.c|784| <<talloc_steal>> _TLIST_REMOVE(tc->parent->child, tc);
+ */
 #define _TLIST_REMOVE(list, p) \
 do { \
 	if ((p) == (list)) { \
@@ -152,22 +244,66 @@ do { \
 /*
   return the parent chunk of a pointer
 */
+/*
+ * called by:
+ *   - xenstore/talloc.c|235| <<talloc_parent>> struct talloc_chunk *tc = talloc_parent_chunk(ptr);
+ *   - xenstore/talloc.c|372| <<talloc_unreference>> struct talloc_chunk *p = talloc_parent_chunk(h);
+ *   - xenstore/talloc.c|411| <<talloc_unlink>> if (talloc_parent_chunk(ptr) != NULL) {
+ *   - xenstore/talloc.c|415| <<talloc_unlink>> if (talloc_chunk_from_ptr(context) != talloc_parent_chunk(ptr)) {
+ *   - xenstore/talloc.c|426| <<talloc_unlink>> new_p = talloc_parent_chunk(tc_p->refs);
+ *   - xenstore/talloc.c|592| <<talloc_free_children>> struct talloc_chunk *p = talloc_parent_chunk(tc->child->refs);
+ *   - xenstore/talloc.c|597| <<talloc_free_children>> struct talloc_chunk *p = talloc_parent_chunk(ptr);
+ *
+ * 先根据参数的ptr再加上TC_HDR_SIZE (似乎内存的结构是HDR_SIZE+data)
+ * 然后根据HDR的talloc_chunk->prev一直往上找
+ * 找到最上面的talloc_chunk->parent
+ */
 static struct talloc_chunk *talloc_parent_chunk(const void *ptr)
 {
+	/*
+	 * 参数的tc再加上TC_HDR_SIZE
+	 * 似乎内存的结构是HDR_SIZE+data
+	 */
 	struct talloc_chunk *tc = talloc_chunk_from_ptr(ptr);
 	while (tc->prev) tc=tc->prev;
 	return tc->parent;
 }
 
+/*
+ * called by:
+ *   - xenstore/talloc.h|114| <<talloc_named>> void *talloc_parent(const void *ptr);
+ *
+ * 先根据参数的ptr再加上TC_HDR_SIZE (似乎内存的结构是HDR_SIZE+data)
+ * 然后根据HDR的talloc_chunk->prev一直往上找
+ * 找到最上面的talloc_chunk->parent
+ * 最后把parent再加上TC_HDR_SIZE返回parent的数据
+ */
 void *talloc_parent(const void *ptr)
 {
+	/*
+	 * 先根据参数的ptr再加上TC_HDR_SIZE (似乎内存的结构是HDR_SIZE+data)
+	 * 然后根据HDR的talloc_chunk->prev一直往上找
+	 * 找到最上面的talloc_chunk->parent
+	 */
 	struct talloc_chunk *tc = talloc_parent_chunk(ptr);
+	/*
+	 * 参数的tc再加上TC_HDR_SIZE
+	 * 似乎内存的结构是HDR_SIZE+data
+	 */
 	return tc? TC_PTR_FROM_CHUNK(tc) : NULL;
 }
 
 /* 
    Allocate a bit of memory as a child of an existing pointer
 */
+/*
+ * called by:
+ *   - xenstore/talloc.c|544| <<talloc_named>> ptr = _talloc(context, size);
+ *   - xenstore/talloc.c|563| <<talloc_named_const>> ptr = _talloc(context, size);
+ *   - xenstore/talloc.c|615| <<talloc_init>> ptr = _talloc(NULL, 0);
+ *   - xenstore/talloc.c|1203| <<talloc_strndup>> ret = _talloc(t, len + 1);
+ *   - xenstore/talloc.c|1237| <<talloc_vasprintf>> ret = _talloc(t, len+1);
+ */
 void *_talloc(const void *context, size_t size)
 {
 	struct talloc_chunk *tc;
@@ -180,6 +316,7 @@ void *_talloc(const void *context, size_t size)
 		return NULL;
 	}
 
+	/* 似乎内存的结构是HDR_SIZE+data */
 	tc = malloc(TC_HDR_SIZE+size);
 	if (tc == NULL) return NULL;
 
@@ -192,19 +329,34 @@ void *_talloc(const void *context, size_t size)
 	tc->null_refs = 0;
 
 	if (context) {
+		/*
+		 * 似乎内存的结构是HDR_SIZE+data
+		 * 这里是根据data获得HDR
+		 */
 		struct talloc_chunk *parent = talloc_chunk_from_ptr(context);
 
 		tc->parent = parent;
 
+		/*
+		 * struct talloc_chunk:
+		 *  -> struct talloc_chunk *parent, *child;
+		 */
 		if (parent->child) {
 			parent->child->parent = NULL;
 		}
 
+		/*
+		 * 似乎只有child list最头上的才有parent
+		 */
 		_TLIST_ADD(parent->child, tc);
 	} else {
 		tc->next = tc->prev = tc->parent = NULL;
 	}
 
+	/*
+	 * 参数的tc再加上TC_HDR_SIZE
+	 * 似乎内存的结构是HDR_SIZE+data
+	 */
 	return TC_PTR_FROM_CHUNK(tc);
 }
 
@@ -215,8 +367,27 @@ void *_talloc(const void *context, size_t size)
   if the destructor fails then the free is failed, and the memory can
   be continued to be used
 */
+/*
+ * called by:
+ *   - xenstore/talloc.c|403| <<talloc_reference>> talloc_set_destructor(handle, talloc_reference_destructor);
+ *   - xenstore/talloc.c|440| <<talloc_unreference>> talloc_set_destructor(h, NULL);
+ *   - xenstore/xenstored_core.c|1142| <<create_node>> talloc_set_destructor(i, destroy_node);
+ *   - xenstore/xenstored_core.c|1147| <<create_node>> talloc_set_destructor(i, NULL);
+ *   - xenstore/xenstored_core.c|1568| <<new_connection>> talloc_set_destructor(new, destroy_conn);
+ *   - xenstore/xenstored_core.c|1987| <<init_sockets>> talloc_set_destructor(sock, destroy_fd);
+ *   - xenstore/xenstored_core.c|1988| <<init_sockets>> talloc_set_destructor(ro_sock, destroy_fd);
+ *   - xenstore/xenstored_domain.c|318| <<new_domain>> talloc_set_destructor(domain, destroy_domain);
+ *   - xenstore/xenstored_domain.c|636| <<domain_init>> talloc_set_destructor(xc_handle, close_xc_handle);
+ *   - xenstore/xenstored_domain.c|646| <<domain_init>> talloc_set_destructor(xgt_handle, close_xgt_handle);
+ *   - xenstore/xenstored_transaction.c|652| <<do_transaction_start>> talloc_set_destructor(trans, destroy_transaction);
+ *   - xenstore/xenstored_watch.c|205| <<do_watch>> talloc_set_destructor(watch, destroy_watch);
+ */
 void talloc_set_destructor(const void *ptr, int (*destructor)(void *))
 {
+	/*
+	 * 似乎内存的结构是HDR_SIZE+data
+	 * 这里是根据data获得HDR
+	 */
 	struct talloc_chunk *tc = talloc_chunk_from_ptr(ptr);
 	tc->destructor = destructor;
 }
@@ -229,6 +400,10 @@ void talloc_increase_ref_count(const void *ptr)
 	struct talloc_chunk *tc;
 	if (ptr == NULL) return;
 
+	/*
+	 * 似乎内存的结构是HDR_SIZE+data
+	 * 这里是根据data获得HDR
+	 */
 	tc = talloc_chunk_from_ptr(ptr);
 	tc->null_refs++;
 }
@@ -244,6 +419,10 @@ static int talloc_reference_destructor(void *ptr)
 	if (tc1->destructor != (talloc_destructor_t)-1) {
 		tc1->destructor = NULL;
 	}
+	/*
+	 * struct talloc_chunk:
+	 *  -> struct talloc_reference_handle *refs;
+	 */
 	_TLIST_REMOVE(tc2->refs, handle);
 	talloc_free(handle);
 	return 0;
@@ -397,6 +576,16 @@ void talloc_set_name(const void *ptr, const char *fmt, ...)
    more efficient way to add a name to a pointer - the name must point to a 
    true string constant
 */
+/*
+ * called by:
+ *   - xenstore/talloc.c|623| <<talloc_named_const>> talloc_set_name_const(ptr, name);
+ *   - xenstore/talloc.c|863| <<_talloc_realloc>> talloc_set_name_const(TC_PTR_FROM_CHUNK(tc), name);
+ *   - xenstore/talloc.c|1282| <<talloc_strdup>> talloc_set_name_const(ret, ret);
+ *   - xenstore/talloc.c|1325| <<talloc_strndup>> talloc_set_name_const(ret, ret);
+ *   - xenstore/talloc.c|1360| <<talloc_vasprintf>> talloc_set_name_const(ret, ret);
+ *   - xenstore/talloc.c|1425| <<talloc_vasprintf_append>> talloc_set_name_const(s, s);
+ *   - xenstore/talloc.h|73| <<talloc_set_type>> #define talloc_set_type(ptr, type) talloc_set_name_const(ptr, #type)
+ */
 void talloc_set_name_const(const void *ptr, const char *name)
 {
 	struct talloc_chunk *tc = talloc_chunk_from_ptr(ptr);
@@ -408,6 +597,10 @@ void talloc_set_name_const(const void *ptr, const char *name)
   talloc_named() operates just like talloc() except that it allows you
   to name the pointer.
 */
+/*
+ * called by:
+ *   - xenstore/talloc.h|108| <<talloc_set_name>> void *talloc_named(const void *context, size_t size,
+ */
 void *talloc_named(const void *context, size_t size, const char *fmt, ...)
 {
 	va_list ap;
@@ -547,6 +740,10 @@ int talloc_free(void *ptr)
 		return -1;
 	}
 
+	/*
+	 * 似乎内存的结构是HDR_SIZE+data
+	 * 这里是根据data获得HDR
+	 */
 	tc = talloc_chunk_from_ptr(ptr);
 
 	if (tc->null_refs) {
@@ -583,6 +780,7 @@ int talloc_free(void *ptr)
 
 	if (tc->parent) {
 		_TLIST_REMOVE(tc->parent->child, tc);
+		/* 似乎children链表中只有第一个元素有parent */
 		if (tc->parent->child) {
 			tc->parent->child->parent = tc->parent;
 		}
@@ -591,6 +789,14 @@ int talloc_free(void *ptr)
 		if (tc->next) tc->next->prev = tc->prev;
 	}
 
+	/*
+	 * 在以下使用TALLOC_FLAG_FREE:
+	 *   - xenstore/talloc.c|150| <<talloc_chunk_from_ptr>> if (tc->flags & TALLOC_FLAG_FREE) {
+	 *   - xenstore/talloc.c|626| <<talloc_free>> tc->flags |= TALLOC_FLAG_FREE;
+	 *   - xenstore/talloc.c|666| <<_talloc_realloc>> tc->flags |= TALLOC_FLAG_FREE;
+	 *   - xenstore/talloc.c|678| <<_talloc_realloc>> tc->flags &= ~TALLOC_FLAG_FREE;
+	 *   - xenstore/talloc.c|683| <<_talloc_realloc>> tc->flags &= ~TALLOC_FLAG_FREE;
+	 */
 	tc->flags |= TALLOC_FLAG_FREE;
 
 	free(tc);
@@ -674,6 +880,16 @@ void *_talloc_realloc(const void *context, void *ptr, size_t size, const char *n
    ptr on success, or NULL if it could not be transferred.
    passing NULL as ptr will always return NULL with no side effects.
 */
+/*
+ * called by:
+ *   - xenstore/talloc.c|545| <<talloc_unlink>> talloc_steal(new_parent, ptr);
+ *   - xenstore/talloc.c|712| <<talloc_free_children>> talloc_steal(new_parent, child);
+ *   - xenstore/xenstored_core.c|450| <<read_node>> talloc_steal(node, data.dptr);
+ *   - xenstore/xenstored_domain.c|413| <<do_introduce>> talloc_steal(domain->conn, domain);
+ *   - xenstore/xenstored_domain.c|617| <<dom0_init>> talloc_steal(dom0->conn, dom0);
+ *   - xenstore/xenstored_transaction.c|651| <<do_transaction_start>> talloc_steal(conn, trans);
+ *   - xenstore/xenstored_transaction.c|730| <<do_transaction_end>> talloc_steal(in, trans);
+ */
 void *talloc_steal(const void *new_ctx, const void *ptr)
 {
 	struct talloc_chunk *tc, *new_tc;
@@ -686,6 +902,10 @@ void *talloc_steal(const void *new_ctx, const void *ptr)
 		new_ctx = null_context;
 	}
 
+	/*
+	 * 似乎内存的结构是HDR_SIZE+data
+	 * 这里是根据data获得HDR
+	 */
 	tc = talloc_chunk_from_ptr(ptr);
 
 	if (new_ctx == NULL) {
@@ -703,6 +923,10 @@ void *talloc_steal(const void *new_ctx, const void *ptr)
 		return discard_const_p(void, ptr);
 	}
 
+	/*
+	 * 似乎内存的结构是HDR_SIZE+data
+	 * 这里是根据data获得HDR
+	 */
 	new_tc = talloc_chunk_from_ptr(new_ctx);
 
 	if (tc == new_tc) {
@@ -729,6 +953,19 @@ void *talloc_steal(const void *new_ctx, const void *ptr)
 /*
   return the total size of a talloc pool (subtree)
 */
+/*
+ * called by:
+ *   - xenstore/talloc.c|968| <<talloc_total_size>> total += talloc_total_size(TC_PTR_FROM_CHUNK(c));
+ *   - xenstore/talloc.c|1038| <<talloc_report_depth>> (unsigned long )talloc_total_size(TC_PTR_FROM_CHUNK(c)),
+ *   - xenstore/talloc.c|1059| <<talloc_report_full>> (unsigned long )talloc_total_size(ptr),
+ *   - xenstore/talloc.c|1080| <<talloc_report>> (unsigned long )talloc_total_size(ptr),
+ *   - xenstore/talloc.c|1088| <<talloc_report>> (unsigned long )talloc_total_size(TC_PTR_FROM_CHUNK(c)),
+ *   - xenstore/talloc.c|1099| <<talloc_report_null>> if (talloc_total_size(null_context) != 0) {
+ *   - xenstore/talloc.c|1109| <<talloc_report_null_full>> if (talloc_total_size(null_context) != 0) {
+ *   - xenstore/talloc.c|1155| <<talloc_report_depth_str>> (unsigned long )talloc_total_size(TC_PTR_FROM_CHUNK(c)),
+ *   - xenstore/talloc.c|1181| <<talloc_describe_all>> (unsigned long )talloc_total_size(null_context),
+ *   - xenstore/talloc.h|119| <<talloc_init>> off_t talloc_total_size(const void *ptr);
+ */
 off_t talloc_total_size(const void *ptr)
 {
 	off_t total = 0;
@@ -741,6 +978,10 @@ off_t talloc_total_size(const void *ptr)
 		return 0;
 	}
 
+	/*
+	 * 似乎内存的结构是HDR_SIZE+data
+	 * 这里是根据data获得HDR
+	 */
 	tc = talloc_chunk_from_ptr(ptr);
 
 	if (tc->flags & TALLOC_FLAG_LOOP) {
@@ -751,6 +992,11 @@ off_t talloc_total_size(const void *ptr)
 
 	total = tc->size;
 	for (c=tc->child;c;c=c->next) {
+		/*
+		 * TC_PTR_FROM_CHUNK():
+		 * 参数的tc再加上TC_HDR_SIZE
+		 * 似乎内存的结构是HDR_SIZE+data
+		 */
 		total += talloc_total_size(TC_PTR_FROM_CHUNK(c));
 	}
 
@@ -762,6 +1008,16 @@ off_t talloc_total_size(const void *ptr)
 /*
   return the total number of blocks in a talloc pool (subtree)
 */
+/*
+ * called by:
+ *   - xenstore/talloc.c|1014| <<talloc_total_blocks>> total += talloc_total_blocks(TC_PTR_FROM_CHUNK(c));
+ *   - xenstore/talloc.c|1061| <<talloc_report_depth>> (unsigned long )talloc_total_blocks(TC_PTR_FROM_CHUNK(c)),
+ *   - xenstore/talloc.c|1082| <<talloc_report_full>> (unsigned long )talloc_total_blocks(ptr));
+ *   - xenstore/talloc.c|1103| <<talloc_report>> (unsigned long )talloc_total_blocks(ptr));
+ *   - xenstore/talloc.c|1111| <<talloc_report>> (unsigned long )talloc_total_blocks(TC_PTR_FROM_CHUNK(c)));
+ *   - xenstore/talloc.c|1178| <<talloc_report_depth_str>> (unsigned long )talloc_total_blocks(TC_PTR_FROM_CHUNK(c)),
+ *   - xenstore/talloc.c|1204| <<talloc_describe_all>> (unsigned long )talloc_total_blocks(null_context));
+ */
 off_t talloc_total_blocks(const void *ptr)
 {
 	off_t total = 0;
@@ -1251,6 +1507,16 @@ static void talloc_autofree(void)
   return a context which will be auto-freed on exit
   this is useful for reducing the noise in leak reports
 */
+/*
+ * called by:
+ *   - xenstore/xenstored_core.c|1494| <<new_connection>> new = talloc_zero(talloc_autofree_context(), struct connection);
+ *   - xenstore/xenstored_core.c|1633| <<setup_structure>> tdbname = talloc_strdup(talloc_autofree_context(), xs_daemon_tdb());
+ *   - xenstore/xenstored_core.c|1902| <<init_sockets>> *psock = sock = talloc(talloc_autofree_context(), int );
+ *   - xenstore/xenstored_core.c|1908| <<init_sockets>> *pro_sock = ro_sock = talloc(talloc_autofree_context(), int );
+ *   - xenstore/xenstored_domain.c|241| <<domain_cleanup>> talloc_unlink(talloc_autofree_context(), domain->conn);
+ *   - xenstore/xenstored_domain.c|628| <<domain_init>> xc_handle = talloc(talloc_autofree_context(), xc_interface*);
+ *   - xenstore/xenstored_domain.c|638| <<domain_init>> xgt_handle = talloc(talloc_autofree_context(), xengnttab_handle*);
+ */
 void *talloc_autofree_context(void)
 {
 	if (cleanup_context == NULL) {
diff --git a/tools/xenstore/tdb.c b/tools/xenstore/tdb.c
index 29593b7..6851914 100644
--- a/tools/xenstore/tdb.c
+++ b/tools/xenstore/tdb.c
@@ -56,12 +56,36 @@
 #define TDB_MAGIC_FOOD "TDB file\n"
 #define TDB_VERSION (0x26011967 + 7)
 #define TDB_MAGIC (0x26011999U)
+/*
+ * 在以下使用TDB_FREE_MAGIC:
+ *   - xenstore/tdb.c|612| <<rec_free_read>> rec->magic = TDB_FREE_MAGIC;
+ *   - xenstore/tdb.c|617| <<rec_free_read>> if (rec->magic != TDB_FREE_MAGIC) {
+ *   - xenstore/tdb.c|732| <<tdb_free>> if (r.magic == TDB_FREE_MAGIC) {
+ *   - xenstore/tdb.c|762| <<tdb_free>> if (l.magic == TDB_FREE_MAGIC) {
+ *   - xenstore/tdb.c|784| <<tdb_free>> rec->magic = TDB_FREE_MAGIC;
+ */
 #define TDB_FREE_MAGIC (~TDB_MAGIC)
+/*
+ * 在以下使用TDB_DEAD_MAGIC:
+ *   - xenstore/tdb.c|79| <<TDB_DEAD>> #define TDB_DEAD(r) ((r)->magic == TDB_DEAD_MAGIC)
+ *   - xenstore/tdb.c|1466| <<do_delete>> rec->magic = TDB_DEAD_MAGIC;
+ */
 #define TDB_DEAD_MAGIC (0xFEE1DEAD)
 #define TDB_ALIGNMENT 4
 #define MIN_REC_SIZE (2*sizeof(struct list_struct) + TDB_ALIGNMENT)
 #define DEFAULT_HASH_SIZE 131
 #define TDB_PAGE_SIZE 0x2000
+/*
+ * 在以下使用FREELIST_TOP:
+ *   - xenstore/tdb.c|340| <<tdb_unlock>> ret = tdb_brlock(tdb, FREELIST_TOP+4*list, F_UNLCK, F_SETLKW, 0);
+ *   - xenstore/tdb.c|74| <<TDB_HASH_TOP>> #define TDB_HASH_TOP(hash) (FREELIST_TOP + (BUCKET(hash)+1)*sizeof(tdb_off))
+ *   - xenstore/tdb.c|305| <<tdb_lock>> if (tdb_brlock(tdb,FREELIST_TOP+4*list,ltype,F_SETLKW, 0)) {
+ *   - xenstore/tdb.c|675| <<remove_from_freelist>> last_ptr = FREELIST_TOP;
+ *   - xenstore/tdb.c|779| <<tdb_free>> if (ofs_read(tdb, FREELIST_TOP, &rec->next) == -1 ||
+ *   - xenstore/tdb.c|781| <<tdb_free>> ofs_write(tdb, FREELIST_TOP, &offset) == -1) {
+ *   - xenstore/tdb.c|1035| <<tdb_allocate>> last_ptr = FREELIST_TOP;
+ *   - xenstore/tdb.c|1038| <<tdb_allocate>> if (ofs_read(tdb, FREELIST_TOP, &rec_ptr) == -1)
+ */
 #define FREELIST_TOP (sizeof(struct tdb_header))
 #define TDB_ALIGN(x,a) (((x) + (a)-1) & ~((a)-1))
 #define TDB_BYTEREV(x) (((((x)&0xff)<<24)|((x)&0xFF00)<<8)|(((x)>>8)&0xFF00)|((x)>>24))
@@ -108,6 +132,13 @@ static TDB_DATA tdb_null;
 /* all contexts, to ensure no double-opens (fcntl locks don't nest!) */
 static TDB_CONTEXT *tdbs = NULL;
 
+/*
+ * called by:
+ *   - xenstore/tdb.c|342| <<tdb_oob>> if (tdb_munmap(tdb) == -1)
+ *   - xenstore/tdb.c|715| <<tdb_expand>> tdb_munmap(tdb);
+ *   - xenstore/tdb.c|1810| <<tdb_open_ex>> tdb_munmap(tdb);
+ *   - xenstore/tdb.c|1840| <<tdb_close>> tdb_munmap(tdb);
+ */
 static int tdb_munmap(TDB_CONTEXT *tdb)
 {
 	if (tdb->flags & TDB_INTERNAL)
@@ -115,6 +146,25 @@ static int tdb_munmap(TDB_CONTEXT *tdb)
 
 #ifdef HAVE_MMAP
 	if (tdb->map_ptr) {
+		/*
+		 * 在以下使用map_size:
+		 *   - xenstore/tdb.c|125| <<tdb_munmap>> int ret = munmap(tdb->map_ptr, tdb->map_size);
+		 *   - xenstore/tdb.c|147| <<tdb_mmap>> tdb->map_ptr = mmap(NULL, tdb->map_size,
+		 *   - xenstore/tdb.c|158| <<tdb_mmap>> tdb->map_size, strerror(errno)));
+		 *   - xenstore/tdb.c|329| <<tdb_oob>> if (len <= tdb->map_size)
+		 *   - xenstore/tdb.c|336| <<tdb_oob>> (int )len, (int )tdb->map_size));
+		 *   - xenstore/tdb.c|357| <<tdb_oob>> tdb->map_size = st.st_size;
+		 *   - xenstore/tdb.c|587| <<tdb_free>> if (right + sizeof(*rec) <= tdb->map_size) {
+		 *   - xenstore/tdb.c|735| <<tdb_expand>> tdb_oob(tdb, tdb->map_size + 1, 1);
+		 *   - xenstore/tdb.c|739| <<tdb_expand>> size = TDB_ALIGN(tdb->map_size + size*10, TDB_PAGE_SIZE) - tdb->map_size;
+		 *   - xenstore/tdb.c|752| <<tdb_expand>> if (expand_file(tdb, tdb->map_size, size) != 0)
+		 *   - xenstore/tdb.c|756| <<tdb_expand>> tdb->map_size += size;
+		 *   - xenstore/tdb.c|760| <<tdb_expand>> tdb->map_size);
+		 *   - xenstore/tdb.c|762| <<tdb_expand>> tdb->map_size -= size;
+		 *   - xenstore/tdb.c|782| <<tdb_expand>> offset = tdb->map_size - size;
+		 *   - xenstore/tdb.c|958| <<tdb_new_database>> tdb->map_size = size;
+		 *   - xenstore/tdb.c|1851| <<tdb_open_ex>> tdb->map_size = st.st_size;
+		 */
 		int ret = munmap(tdb->map_ptr, tdb->map_size);
 		if (ret != 0)
 			return ret;
@@ -124,6 +174,12 @@ static int tdb_munmap(TDB_CONTEXT *tdb)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - xenstore/tdb.c|345| <<tdb_oob>> tdb_mmap(tdb);
+ *   - xenstore/tdb.c|747| <<tdb_expand>> tdb_mmap(tdb);
+ *   - xenstore/tdb.c|1768| <<tdb_open_ex>> tdb_mmap(tdb);
+ */
 static void tdb_mmap(TDB_CONTEXT *tdb)
 {
 	if (tdb->flags & TDB_INTERNAL)
@@ -153,6 +209,12 @@ static void tdb_mmap(TDB_CONTEXT *tdb)
 }
 
 /* Endian conversion: we only ever deal with 4 byte quantities */
+/*
+ * called by:
+ *   - xenstore/tdb.c|196| <<CONVERT>> #define CONVERT(x) (DOCONV() ? convert(&x, sizeof(x)) : &x)
+ *   - xenstore/tdb.c|443| <<tdb_read>> convert(buf, len);
+ *   - xenstore/tdb.c|1870| <<tdb_open_ex>> convert(&tdb->header, sizeof(tdb->header));
+ */
 static void *convert(void *buf, uint32_t size)
 {
 	uint32_t i, *p = buf;
@@ -189,6 +251,20 @@ struct list_struct {
 
    On error, errno is also set so that errors are passed back properly
    through tdb_open(). */
+/*
+ * called by:
+ *   - xenstore/tdb.c|322| <<global>> ret = tdb_brlock(tdb, FREELIST_TOP+4*list, F_UNLCK, F_SETLKW, 0);
+ *   - xenstore/tdb.c|287| <<tdb_lock>> if (tdb_brlock(tdb,FREELIST_TOP+4*list,ltype,F_SETLKW, 0)) {
+ *   - xenstore/tdb.c|1240| <<lock_record>> return off ? tdb_brlock(tdb, off, F_RDLCK, F_SETLKW, 0) : 0;
+ *   - xenstore/tdb.c|1258| <<write_lock_record>> return tdb_brlock(tdb, off, F_WRLCK, F_SETLK, 1);
+ *   - xenstore/tdb.c|1272| <<write_unlock_record>> return tdb_brlock(tdb, off, F_UNLCK, F_SETLK, 0);
+ *   - xenstore/tdb.c|1293| <<unlock_record>> return (count == 1 ? tdb_brlock(tdb, off, F_UNLCK, F_SETLKW, 0) : 0);
+ *   - xenstore/tdb.c|1839| <<tdb_open_ex>> if (tdb_brlock(tdb, GLOBAL_LOCK, F_WRLCK, F_SETLKW, 0) == -1) {
+ *   - xenstore/tdb.c|1847| <<tdb_open_ex>> (locked = (tdb_brlock(tdb, ACTIVE_LOCK, F_WRLCK, F_SETLK, 0) == 0))) {
+ *   - xenstore/tdb.c|1909| <<tdb_open_ex>> if (tdb_brlock(tdb, ACTIVE_LOCK, F_UNLCK, F_SETLK, 0) == -1) {
+ *   - xenstore/tdb.c|1924| <<tdb_open_ex>> if (tdb_brlock(tdb, ACTIVE_LOCK, F_RDLCK, F_SETLKW, 0) == -1)
+ *   - xenstore/tdb.c|1933| <<tdb_open_ex>> if (tdb_brlock(tdb, GLOBAL_LOCK, F_UNLCK, F_SETLKW, 0) == -1)
+ */
 static int tdb_brlock(TDB_CONTEXT *tdb, tdb_off offset, 
 		      int rw_type, int lck_type, int probe)
 {
@@ -310,6 +386,15 @@ static uint32_t default_tdb_hash(TDB_DATA *key)
    if necessary 
    note that "len" is the minimum length needed for the db
 */
+/*
+ * called by:
+ *   - xenstore/tdb.c|398| <<tdb_write>> if (tdb_oob(tdb, off + len, 0) != 0)
+ *   - xenstore/tdb.c|431| <<tdb_read>> if (tdb_oob(tdb, off + len, 0) != 0)
+ *   - xenstore/tdb.c|459| <<tdb_key_eq>> if (tdb_oob(tdb, off + key.dsize, 0) != 0)
+ *   - xenstore/tdb.c|521| <<rec_read>> return tdb_oob(tdb, rec->next+sizeof(*rec), 0);
+ *   - xenstore/tdb.c|552| <<rec_free_read>> if (tdb_oob(tdb, rec->next+sizeof(*rec), 0) != 0)
+ *   - xenstore/tdb.c|760| <<tdb_expand>> tdb_oob(tdb, tdb->map_size + 1, 1);
+ */
 static int tdb_oob(TDB_CONTEXT *tdb, tdb_off len, int probe)
 {
 	struct stat st;
@@ -347,8 +432,24 @@ static int tdb_oob(TDB_CONTEXT *tdb, tdb_off len, int probe)
 }
 
 /* write a lump of data at a specified offset */
+/*
+ * called by:
+ *   - xenstore/tdb.c|451| <<ofs_write>> return tdb_write(tdb, offset, CONVERT(off), sizeof(*d));
+ *   - xenstore/tdb.c|470| <<rec_write>> return tdb_write(tdb, offset, CONVERT(r), sizeof(r));
+ *   - xenstore/tdb.c|485| <<rec_free_read>> if (tdb_write(tdb, off, rec, sizeof(*rec)) == -1)
+ *   - xenstore/tdb.c|1016| <<tdb_update_hash>> if (tdb_write(tdb, rec_ptr + sizeof(rec) + rec.key_len,
+ *   - xenstore/tdb.c|1503| <<tdb_store>> || tdb_write(tdb, rec_ptr+sizeof(rec), p, key.dsize+dbuf.dsize)==-1
+ *
+ * 核心思想就是把buf写入tdb->map_ptr+off
+ */
 static int tdb_write(TDB_CONTEXT *tdb, tdb_off off, void *buf, tdb_len len)
 {
+	/*
+	 * check for an out of bounds access - if it is out of bounds then
+	 * see if the database has been expanded by someone else and expand
+	 * if necessary
+	 * note that "len" is the minimum length needed for the db
+	 */
 	if (tdb_oob(tdb, off + len, 0) != 0)
 		return -1;
 
@@ -370,6 +471,18 @@ static int tdb_write(TDB_CONTEXT *tdb, tdb_off off, void *buf, tdb_len len)
 }
 
 /* read a lump of data at a specified offset, maybe convert */
+/*
+ * called by:
+ *   - xenstore/tdb.c|413| <<tdb_key_eq>> if (tdb_read(tdb, off, buf, len, 0) != 0)
+ *   - xenstore/tdb.c|436| <<tdb_alloc_read>> if (tdb_read(tdb, offset, buf, len, 0) == -1) {
+ *   - xenstore/tdb.c|446| <<ofs_read>> return tdb_read(tdb, offset, (char *)d, sizeof(*d), DOCONV());
+ *   - xenstore/tdb.c|457| <<rec_read>> if (tdb_read(tdb, offset, rec, sizeof(*rec),DOCONV()) == -1)
+ *   - xenstore/tdb.c|476| <<rec_free_read>> if (tdb_read(tdb, off, rec, sizeof(*rec),DOCONV()) == -1)
+ *   - xenstore/tdb.c|553| <<tdb_free>> if (tdb_read(tdb, right, &r, sizeof(r), DOCONV()) == -1) {
+ *   - xenstore/tdb.c|583| <<tdb_free>> if (tdb_read(tdb, left, &l, sizeof(l), DOCONV()) == -1) {
+ *
+ * 核心思想就是把tdb->map_ptr+off写入buf
+ */
 static int tdb_read(TDB_CONTEXT *tdb,tdb_off off,void *buf,tdb_len len,int cv)
 {
 	if (tdb_oob(tdb, off + len, 0) != 0)
@@ -395,6 +508,12 @@ static int tdb_read(TDB_CONTEXT *tdb,tdb_off off,void *buf,tdb_len len,int cv)
 }
 
 /* don't allocate memory: used in tdb_delete path. */
+/*
+ * called by:
+ *   - xenstore/tdb.c|1084| <<tdb_find>> int cmp = tdb_key_eq(tdb, rec_ptr + sizeof(*r), key);
+ *
+ * 核心思想是判断tdb->map_ptr+off和key.dptr是否相同(key.dsize大小)
+ */
 static int tdb_key_eq(TDB_CONTEXT *tdb, tdb_off off, TDB_DATA key)
 {
 	char buf[64];
@@ -422,6 +541,14 @@ static int tdb_key_eq(TDB_CONTEXT *tdb, tdb_off off, TDB_DATA key)
 }
 
 /* read a lump of data, allocating the space for it */
+/*
+ * called by:
+ *   - xenstore/tdb.c|1242| <<tdb_fetch>> ret.dptr = tdb_alloc_read(tdb, rec_ptr + sizeof(rec) + rec.key_len,
+ *   - xenstore/tdb.c|1523| <<tdb_traverse>> key.dptr = tdb_alloc_read(tdb, tl.off + sizeof(rec),
+ *   - xenstore/tdb.c|1582| <<tdb_firstkey>> key.dptr =tdb_alloc_read(tdb,tdb->travlocks.off+sizeof(rec),key.dsize);
+ *   - xenstore/tdb.c|1605| <<tdb_nextkey>> || !(k = tdb_alloc_read(tdb,tdb->travlocks.off+sizeof(rec),
+ *   - xenstore/tdb.c|1636| <<tdb_nextkey>> key.dptr = tdb_alloc_read(tdb, tdb->travlocks.off+sizeof(rec),
+ */
 static char *tdb_alloc_read(TDB_CONTEXT *tdb, tdb_off offset, tdb_len len)
 {
 	char *buf;
@@ -433,6 +560,9 @@ static char *tdb_alloc_read(TDB_CONTEXT *tdb, tdb_off offset, tdb_len len)
 			   len, strerror(errno)));
 		return TDB_ERRCODE(TDB_ERR_OOM, buf);
 	}
+	/*
+	 * 核心思想就是把tdb->map_ptr+offset写入buf
+	 */
 	if (tdb_read(tdb, offset, buf, len, 0) == -1) {
 		SAFE_FREE(buf);
 		return NULL;
@@ -443,6 +573,9 @@ static char *tdb_alloc_read(TDB_CONTEXT *tdb, tdb_off offset, tdb_len len)
 /* read/write a tdb_off */
 static int ofs_read(TDB_CONTEXT *tdb, tdb_off offset, tdb_off *d)
 {
+	/*
+	 * 核心思想就是把tdb->map_ptr+off写入d
+	 */
 	return tdb_read(tdb, offset, (char*)d, sizeof(*d), DOCONV());
 }
 static int ofs_write(TDB_CONTEXT *tdb, tdb_off offset, tdb_off *d)
@@ -454,6 +587,9 @@ static int ofs_write(TDB_CONTEXT *tdb, tdb_off offset, tdb_off *d)
 /* read/write a record */
 static int rec_read(TDB_CONTEXT *tdb, tdb_off offset, struct list_struct *rec)
 {
+	/*
+	 * 核心思想就是把tdb->map_ptr+off写入rec
+	 */
 	if (tdb_read(tdb, offset, rec, sizeof(*rec),DOCONV()) == -1)
 		return -1;
 	if (TDB_BAD_MAGIC(rec)) {
@@ -471,6 +607,11 @@ static int rec_write(TDB_CONTEXT *tdb, tdb_off offset, struct list_struct *rec)
 }
 
 /* read a freelist record and check for simple errors */
+/*
+ * called by:
+ *   - xenstore/tdb.c|997| <<tdb_allocate>> if (rec_free_read(tdb, rec_ptr, rec) == -1) {
+ *   - xenstore/tdb.c|1020| <<tdb_allocate>> if (rec_free_read(tdb, bestfit.rec_ptr, rec) == -1) {
+ */
 static int rec_free_read(TDB_CONTEXT *tdb, tdb_off off, struct list_struct *rec)
 {
 	if (tdb_read(tdb, off, rec, sizeof(*rec),DOCONV()) == -1)
@@ -499,6 +640,15 @@ static int rec_free_read(TDB_CONTEXT *tdb, tdb_off off, struct list_struct *rec)
 }
 
 /* update a record tailer (must hold allocation lock) */
+/*
+ * called by:
+ *   - xenstore/tdb.c|661| <<tdb_free>> if (update_tailer(tdb, offset, rec) != 0) {
+ *   - xenstore/tdb.c|719| <<tdb_free>> if (update_tailer(tdb, offset, rec) == -1) {
+ *   - xenstore/tdb.c|943| <<tdb_allocate_ofs>> if (update_tailer(tdb, rec_ptr, rec) == -1) {
+ *
+ * 更新list_struct数据中倒数第一个的元素, 是totalsize (tailer)
+ * 大小更新为list_struct (包括后面的data)占据的大小
+ */
 static int update_tailer(TDB_CONTEXT *tdb, tdb_off offset,
 			 const struct list_struct *rec)
 {
@@ -506,11 +656,39 @@ static int update_tailer(TDB_CONTEXT *tdb, tdb_off offset,
 
 	/* Offset of tailer from record header */
 	totalsize = sizeof(*rec) + rec->rec_len;
+	/*
+	 * struct list_struct {
+	 *	tdb_off next; // offset of the next record in the list
+	 *	tdb_len rec_len; // total byte length of record
+	 *	tdb_len key_len; // byte length of key
+	 *	tdb_len data_len; // byte length of data
+	 *	uint32_t full_hash; // the full 32 bit hash of the key
+	 *	uint32_t magic;   // try to catch errors
+	 *	// the following union is implied:
+	 *	//	union {
+	 *	//		char record[rec_len];
+	 *	//		struct {
+	 *	//			char key[key_len];
+	 *	//			char data[data_len];
+	 *	//		}
+	 *	//		uint32_t totalsize; (tailer)
+	 *	//	}
+	 * };
+	 *
+	 * 更新list_struct数据中倒数第一个的元素, 是totalsize (tailer)
+	 */
 	return ofs_write(tdb, offset + totalsize - sizeof(tdb_off),
 			 &totalsize);
 }
 
 /* Remove an element from the freelist.  Must have alloc lock. */
+/*
+ * called by:
+ *   - xenstore/tdb.c|678| <<tdb_free>> if (remove_from_freelist(tdb, right, r.next) == -1) {
+ *   - xenstore/tdb.c|708| <<tdb_free>> if (remove_from_freelist(tdb, left, l.next) == -1) {
+ *
+ * 把off代表的地址从freelist删除掉
+ */
 static int remove_from_freelist(TDB_CONTEXT *tdb, tdb_off off, tdb_off next)
 {
 	tdb_off last_ptr, i;
@@ -531,6 +709,12 @@ static int remove_from_freelist(TDB_CONTEXT *tdb, tdb_off off, tdb_off next)
 
 /* Add an element into the freelist. Merge adjacent records if
    neccessary. */
+/*
+ * called by:
+ *   - xenstore/tdb.c|760| <<tdb_expand>> if (tdb_free(tdb, offset, &rec) == -1)
+ *   - xenstore/tdb.c|821| <<tdb_allocate_ofs>> if (tdb_free(tdb, newrec_ptr, &newrec) == -1) {
+ *   - xenstore/tdb.c|1202| <<do_delete>> if (tdb_free(tdb, rec_ptr, rec) == -1)
+ */
 static int tdb_free(TDB_CONTEXT *tdb, tdb_off offset, struct list_struct *rec)
 {
 	tdb_off right, left;
@@ -540,6 +724,10 @@ static int tdb_free(TDB_CONTEXT *tdb, tdb_off offset, struct list_struct *rec)
 		return -1;
 
 	/* set an initial tailer, so if we fail we don't leave a bogus record */
+	/*
+	 * 更新list_struct数据中倒数第一个的元素, 是totalsize (tailer)
+	 * 大小更新为list_struct (包括后面的data)占据的大小
+	 */
 	if (update_tailer(tdb, offset, rec) != 0) {
 		TDB_LOG((tdb, 0, "tdb_free: upfate_tailer failed!\n"));
 		goto fail;
@@ -598,6 +786,10 @@ left:
 	}
 
 update:
+	/*
+	 * 更新list_struct数据中倒数第一个的元素, 是totalsize (tailer)
+	 * 大小更新为list_struct (包括后面的data)占据的大小
+	 */
 	if (update_tailer(tdb, offset, rec) == -1) {
 		TDB_LOG((tdb, 0, "tdb_free: update_tailer failed at %u\n", offset));
 		goto fail;
@@ -625,6 +817,10 @@ update:
 
 /* expand a file.  we prefer to use ftruncate, as that is what posix
   says to use for mmap expansion */
+/*
+ * called by:
+ *   - xenstore/tdb.c|725| <<tdb_expand>> if (expand_file(tdb, tdb->map_size, size) != 0)
+ */
 static int expand_file(TDB_CONTEXT *tdb, tdb_off size, tdb_off addition)
 {
 	char buf[1024];
@@ -676,6 +872,10 @@ static int expand_file(TDB_CONTEXT *tdb, tdb_off size, tdb_off addition)
 
 /* expand the database at least size bytes by expanding the underlying
    file and doing the mmap again if necessary */
+/*
+ * called by:
+ *   - xenstore/tdb.c|896| <<tdb_allocate>> if (tdb_expand(tdb, length + sizeof(*rec)) == 0)
+ */
 static int tdb_expand(TDB_CONTEXT *tdb, tdb_off size)
 {
 	struct list_struct rec;
@@ -708,6 +908,25 @@ static int tdb_expand(TDB_CONTEXT *tdb, tdb_off size)
 			goto fail;
 	}
 
+	/*
+	 * 在以下使用map_size:
+	 *   - xenstore/tdb.c|125| <<tdb_munmap>> int ret = munmap(tdb->map_ptr, tdb->map_size);
+	 *   - xenstore/tdb.c|147| <<tdb_mmap>> tdb->map_ptr = mmap(NULL, tdb->map_size,
+	 *   - xenstore/tdb.c|158| <<tdb_mmap>> tdb->map_size, strerror(errno)));
+	 *   - xenstore/tdb.c|329| <<tdb_oob>> if (len <= tdb->map_size)
+	 *   - xenstore/tdb.c|336| <<tdb_oob>> (int )len, (int )tdb->map_size));
+	 *   - xenstore/tdb.c|357| <<tdb_oob>> tdb->map_size = st.st_size;
+	 *   - xenstore/tdb.c|587| <<tdb_free>> if (right + sizeof(*rec) <= tdb->map_size) {
+	 *   - xenstore/tdb.c|735| <<tdb_expand>> tdb_oob(tdb, tdb->map_size + 1, 1);
+	 *   - xenstore/tdb.c|739| <<tdb_expand>> size = TDB_ALIGN(tdb->map_size + size*10, TDB_PAGE_SIZE) - tdb->map_size;
+	 *   - xenstore/tdb.c|752| <<tdb_expand>> if (expand_file(tdb, tdb->map_size, size) != 0)
+	 *   - xenstore/tdb.c|756| <<tdb_expand>> tdb->map_size += size;
+	 *   - xenstore/tdb.c|760| <<tdb_expand>> tdb->map_size);
+	 *   - xenstore/tdb.c|762| <<tdb_expand>> tdb->map_size -= size;
+	 *   - xenstore/tdb.c|782| <<tdb_expand>> offset = tdb->map_size - size;
+	 *   - xenstore/tdb.c|958| <<tdb_new_database>> tdb->map_size = size;
+	 *   - xenstore/tdb.c|1851| <<tdb_open_ex>> tdb->map_size = st.st_size;
+	 */
 	tdb->map_size += size;
 
 	if (tdb->flags & TDB_INTERNAL) {
@@ -750,6 +969,10 @@ static int tdb_expand(TDB_CONTEXT *tdb, tdb_off size)
    the core of tdb_allocate - called when we have decided which
    free list entry to use
  */
+/*
+ * called by:
+ *   - xenstore/tdb.c|889| <<tdb_allocate>> newrec_ptr = tdb_allocate_ofs(tdb, length, bestfit.rec_ptr, rec, bestfit.last_ptr);
+ */
 static tdb_off tdb_allocate_ofs(TDB_CONTEXT *tdb, tdb_len length, tdb_off rec_ptr,
 				struct list_struct *rec, tdb_off last_ptr)
 {
@@ -811,6 +1034,10 @@ static tdb_off tdb_allocate_ofs(TDB_CONTEXT *tdb, tdb_len length, tdb_off rec_pt
 
    0 is returned if the space could not be allocated
  */
+/*
+ * called by:
+ *   - xenstore/tdb.c|1575| <<tdb_store>> if (!(rec_ptr = tdb_allocate(tdb, key.dsize + dbuf.dsize, &rec)))
+ */
 static tdb_off tdb_allocate(TDB_CONTEXT *tdb, tdb_len length,
 			    struct list_struct *rec)
 {
@@ -883,6 +1110,11 @@ static tdb_off tdb_allocate(TDB_CONTEXT *tdb, tdb_len length,
 }
 
 /* initialise a new database with a specified hash size */
+/*
+ * called by:
+ *   - xenstore/tdb.c|1643| <<tdb_open_ex>> if (tdb_new_database(tdb, hash_size) != 0) {
+ *   - xenstore/tdb.c|1680| <<tdb_open_ex>> if (!(open_flags & O_CREAT) || tdb_new_database(tdb, hash_size) == -1) {
+ */
 static int tdb_new_database(TDB_CONTEXT *tdb, int hash_size)
 {
 	struct tdb_header *newdb;
@@ -927,34 +1159,58 @@ static int tdb_new_database(TDB_CONTEXT *tdb, int hash_size)
 
 /* Returns 0 on fail.  On success, return offset of record, and fills
    in rec */
+/*
+ * called by:
+ *   - xenstore/tdb.c|965| <<tdb_find_lock_hash>> if (!(rec_ptr = tdb_find(tdb, key, hash, rec)))
+ *   - xenstore/tdb.c|1007| <<tdb_update_hash>> if (!(rec_ptr = tdb_find(tdb, key, hash, &rec)))
+ */
 static tdb_off tdb_find(TDB_CONTEXT *tdb, TDB_DATA key, uint32_t hash,
 			struct list_struct *r)
 {
 	tdb_off rec_ptr;
 	
 	/* read in the hash top */
+	/*
+	 * 把hash对应的bucket(32位)地址读入rec_ptr
+	 */
 	if (ofs_read(tdb, TDB_HASH_TOP(hash), &rec_ptr) == -1)
 		return 0;
 
 	/* keep looking until we find the right record */
 	while (rec_ptr) {
+		/*
+		 * r的结构是list_struct
+		 */
 		if (rec_read(tdb, rec_ptr, r) == -1)
 			return 0;
 
 		if (!TDB_DEAD(r) && hash==r->full_hash && key.dsize==r->key_len) {
 			/* a very likely hit - read the key */
+			/*
+			 * 核心思想是判断tdb->map_ptr+off和key.dptr是否相同(key.dsize大小)
+			 */
 			int cmp = tdb_key_eq(tdb, rec_ptr + sizeof(*r), key);
 			if (cmp < 0)
 				return 0;
 			else if (cmp > 0)
 				return rec_ptr;
 		}
+		/*
+		 * 如果没找到, 再去查看下一个
+		 */
 		rec_ptr = r->next;
 	}
 	return TDB_ERRCODE(TDB_ERR_NOEXIST, 0);
 }
 
 /* As tdb_find, but if you succeed, keep the lock */
+/*
+ * called by:
+ *   - xenstore/tdb.c|1095| <<tdb_fetch>> if (!(rec_ptr = tdb_find_lock_hash(tdb,key,hash,F_RDLCK,&rec)))
+ *   - xenstore/tdb.c|1119| <<tdb_exists_hash>> if (tdb_find_lock_hash(tdb, key, hash, F_RDLCK, &rec) == 0)
+ *   - xenstore/tdb.c|1445| <<tdb_nextkey>> tdb->travlocks.off = tdb_find_lock_hash(tdb, oldkey, tdb->hash_fn(&oldkey), F_WRLCK, &rec);
+ *   - xenstore/tdb.c|1484| <<tdb_delete_hash>> if (!(rec_ptr = tdb_find_lock_hash(tdb, key, hash, F_WRLCK, &rec)))
+ */
 static tdb_off tdb_find_lock_hash(TDB_CONTEXT *tdb, TDB_DATA key, uint32_t hash, int locktype,
 			     struct list_struct *rec)
 {
@@ -967,11 +1223,20 @@ static tdb_off tdb_find_lock_hash(TDB_CONTEXT *tdb, TDB_DATA key, uint32_t hash,
 	return rec_ptr;
 }
 
+/*
+ * called by:
+ *   - xenstore/xenstored_core.c|437| <<read_node>> if (tdb_error(tdb_ctx) == TDB_ERR_NOEXIST) {
+ *   - xenstore/xenstored_transaction.c|479| <<finalize_transaction>> if (tdb_error(tdb_ctx) != TDB_ERR_NOEXIST)
+ */
 enum TDB_ERROR tdb_error(TDB_CONTEXT *tdb)
 {
 	return tdb->ecode;
 }
 
+/*
+ * called by:
+ *   - xenstore/tdb.c|1018| <<tdb_errorstr>> for (i = 0; i < sizeof(emap) / sizeof(struct tdb_errname); i++)
+ */
 static struct tdb_errname {
 	enum TDB_ERROR ecode; const char *estring;
 } emap[] = { {TDB_SUCCESS, "Success"},
@@ -984,6 +1249,10 @@ static struct tdb_errname {
 	     {TDB_ERR_NOEXIST, "Record does not exist"} };
 
 /* Error string for the last tdb error */
+/*
+ * called by:
+ *   - xenstore/xenstored_core.c|442| <<read_node>> log("TDB error on read: %s", tdb_errorstr(tdb_ctx));
+ */
 const char *tdb_errorstr(TDB_CONTEXT *tdb)
 {
 	uint32_t i;
@@ -998,6 +1267,10 @@ const char *tdb_errorstr(TDB_CONTEXT *tdb)
    on failure return -1.
 */
 
+/*
+ * called by:
+ *   - xenstore/tdb.c|1544| <<tdb_store>> if (tdb_update_hash(tdb, key, hash, dbuf) == 0)
+ */
 static int tdb_update_hash(TDB_CONTEXT *tdb, TDB_DATA key, uint32_t hash, TDB_DATA dbuf)
 {
 	struct list_struct rec;
@@ -1033,6 +1306,25 @@ static int tdb_update_hash(TDB_CONTEXT *tdb, TDB_DATA key, uint32_t hash, TDB_DA
  * a non-zero pointer
  */
 
+/*
+ * (gdb) bt
+ * #0  tdb_fetch (tdb=0x13dd810, key=...) at tdb.c:1147
+ * #1  0x000000000040320f in read_node (conn=0x13ddb70, ctx=0x13de930, name=<value optimized out>)
+ *     at xenstored_core.c:415
+ * #2  0x0000000000403ac7 in get_node (conn=0x13ddb70, ctx=0x13de930, name=0x13de8b0 "/local/domain/0/name",
+ *     perm=XS_PERM_READ) at xenstored_core.c:587
+ * #3  0x000000000040429d in do_read (conn=0x13ddb70) at xenstored_core.c:806
+ * #4  process_message (conn=0x13ddb70) at xenstored_core.c:1254
+ * #5  consider_message (conn=0x13ddb70) at xenstored_core.c:1341
+ * #6  handle_input (conn=0x13ddb70) at xenstored_core.c:1387
+ * #7  0x00000000004053ba in main (argc=<value optimized out>, argv=<value optimized out>) at xenstored_core.c:2095
+ *
+ * called by:
+ *   - xenstore/xenstored_core.c|434| <<read_node>> data = tdb_fetch(tdb_ctx, key);
+ *   - xenstore/xenstored_transaction.c|461| <<finalize_transaction>> data = tdb_fetch(tdb_ctx, key);
+ *   - xenstore/xenstored_transaction.c|497| <<finalize_transaction>> data = tdb_fetch(tdb_ctx, ta_key);
+ *   - xenstore/xs_tdb_dump.c|56| <<main>> data = tdb_fetch(tdb, key);
+ */
 TDB_DATA tdb_fetch(TDB_CONTEXT *tdb, TDB_DATA key)
 {
 	tdb_off rec_ptr;
@@ -1041,10 +1333,43 @@ TDB_DATA tdb_fetch(TDB_CONTEXT *tdb, TDB_DATA key)
 	uint32_t hash;
 
 	/* find which hash bucket it is in */
+	/*
+	 * 一个例子default_tdb_hash()
+	 */
 	hash = tdb->hash_fn(&key);
 	if (!(rec_ptr = tdb_find_lock_hash(tdb,key,hash,F_RDLCK,&rec)))
 		return tdb_null;
 
+	/*
+	 * 这里就是从数据库读取了
+	 * 上面重点还是获得offset吧
+	 *
+	 * 204 // the body of the database is made of one list_struct for the free space
+	 * 205 // plus a separate data list for each hash value
+	 * 206 struct list_struct {
+	 * 207         tdb_off next; // offset of the next record in the list
+	 * 208         tdb_len rec_len; // total byte length of record
+	 * 209         tdb_len key_len; // byte length of key
+	 * 210         tdb_len data_len; // byte length of data
+	 * 211         uint32_t full_hash; // the full 32 bit hash of the key
+	 * 212         uint32_t magic;   // try to catch errors
+	 *             下面是注释
+	 * 213         //   the following union is implied:
+	 * 214         //        union {
+	 * 215         //                char record[rec_len];
+	 * 216         //                struct {
+	 * 217         //                        char key[key_len];
+	 * 218         //                        char data[data_len];
+	 * 219         //                }
+	 * 220         //                uint32_t totalsize; (tailer)
+	 * 221         //        }
+	 * 222         //
+	 * 223 };
+	 *
+	 *
+	 * read a lump of data, allocating the space for it
+	 * tdb_read()核心思想就是把tdb->map_ptr+offset写入buf
+	 */
 	ret.dptr = tdb_alloc_read(tdb, rec_ptr + sizeof(rec) + rec.key_len,
 				  rec.data_len);
 	ret.dsize = rec.data_len;
@@ -1058,6 +1383,10 @@ TDB_DATA tdb_fetch(TDB_CONTEXT *tdb, TDB_DATA key)
    this doesn't match the conventions in the rest of this module, but is
    compatible with gdbm
 */
+/*
+ * called by:
+ *   - xenstore/tdb.c|1538| <<tdb_store>> if (tdb_exists_hash(tdb, key, hash)) {
+ */
 static int tdb_exists_hash(TDB_CONTEXT *tdb, TDB_DATA key, uint32_t hash)
 {
 	struct list_struct rec;
@@ -1069,6 +1398,11 @@ static int tdb_exists_hash(TDB_CONTEXT *tdb, TDB_DATA key, uint32_t hash)
 }
 
 /* record lock stops delete underneath */
+/*
+ * called by:
+ *   - xenstore/tdb.c|1294| <<tdb_next_lock>> if (lock_record(tdb, tlock->off) != 0)
+ *   - xenstore/tdb.c|1449| <<tdb_nextkey>> if (lock_record(tdb, tdb->travlocks.off) != 0) {
+ */
 static int lock_record(TDB_CONTEXT *tdb, tdb_off off)
 {
 	return off ? tdb_brlock(tdb, off, F_RDLCK, F_SETLKW, 0) : 0;
@@ -1078,7 +1412,11 @@ static int lock_record(TDB_CONTEXT *tdb, tdb_off off)
   Note this is meant to be F_SETLK, *not* F_SETLKW, as it's not
   an error to fail to get the lock here.
 */
- 
+
+/*
+ * called by:
+ *   - xenstore/tdb.c|1176| <<do_delete>> if (write_lock_record(tdb, rec_ptr) == -1) {
+ */
 static int write_lock_record(TDB_CONTEXT *tdb, tdb_off off)
 {
 	struct tdb_traverse_lock *i;
@@ -1093,11 +1431,23 @@ static int write_lock_record(TDB_CONTEXT *tdb, tdb_off off)
   an error to fail to get the lock here.
 */
 
+/*
+ * called by:
+ *   - xenstore/tdb.c|1181| <<do_delete>> if (write_unlock_record(tdb, rec_ptr) != 0)
+ */
 static int write_unlock_record(TDB_CONTEXT *tdb, tdb_off off)
 {
 	return tdb_brlock(tdb, off, F_UNLCK, F_SETLK, 0);
 }
 /* fcntl locks don't stack: avoid unlocking someone else's */
+/*
+ * called by:
+ *   - xenstore/tdb.c|1269| <<tdb_next_lock>> if (unlock_record(tdb, tlock->off) != 0)
+ *   - xenstore/tdb.c|1353| <<tdb_traverse>> if (unlock_record(tdb, tl.off) != 0)
+ *   - xenstore/tdb.c|1369| <<tdb_traverse>> if (unlock_record(tdb, tl.off) != 0) {
+ *   - xenstore/tdb.c|1398| <<tdb_firstkey>> if (unlock_record(tdb, tdb->travlocks.off) != 0)
+ *   - xenstore/tdb.c|1433| <<tdb_nextkey>> if (unlock_record(tdb, tdb->travlocks.off) != 0)
+ */
 static int unlock_record(TDB_CONTEXT *tdb, tdb_off off)
 {
 	struct tdb_traverse_lock *i;
@@ -1112,6 +1462,13 @@ static int unlock_record(TDB_CONTEXT *tdb, tdb_off off)
 }
 
 /* actually delete an entry in the database given the offset */
+/*
+ * called by:
+ *   - xenstore/tdb.c|1303| <<tdb_next_lock>> do_delete(tdb, current, rec) != 0)
+ *   - xenstore/tdb.c|1486| <<tdb_delete_hash>> ret = do_delete(tdb, rec_ptr, &rec);
+ *
+ * rec_ptr是tdb中rec的地址
+ */
 static int do_delete(TDB_CONTEXT *tdb, tdb_off rec_ptr, struct list_struct*rec)
 {
 	tdb_off last_ptr, i;
@@ -1128,8 +1485,15 @@ static int do_delete(TDB_CONTEXT *tdb, tdb_off rec_ptr, struct list_struct*rec)
 		return -1;
 
 	/* find previous record in hash chain */
+	/*
+	 * 找到要删除的rec的hash bucket的第一个list_struct
+	 */
 	if (ofs_read(tdb, TDB_HASH_TOP(rec->full_hash), &i) == -1)
 		return -1;
+	/*
+	 * 找到指向要删除的list_struct的上一个list_struct (lastrec)
+	 * last_ptr是上一个list_struct的offset
+	 */
 	for (last_ptr = 0; i != rec_ptr; last_ptr = i, i = lastrec.next)
 		if (rec_read(tdb, i, &lastrec) == -1)
 			return -1;
@@ -1137,16 +1501,35 @@ static int do_delete(TDB_CONTEXT *tdb, tdb_off rec_ptr, struct list_struct*rec)
 	/* unlink it: next ptr is at start of record. */
 	if (last_ptr == 0)
 		last_ptr = TDB_HASH_TOP(rec->full_hash);
+	/*
+	 * 让上一个list_struct的next直接指向下一个的next
+	 * 把中间的list_struct略过了
+	 */
 	if (ofs_write(tdb, last_ptr, &rec->next) == -1)
 		return -1;
 
 	/* recover the space */
+	/*
+	 * 在以下调用tdb_free():
+	 *   - xenstore/tdb.c|760| <<tdb_expand>> if (tdb_free(tdb, offset, &rec) == -1)
+	 *   - xenstore/tdb.c|821| <<tdb_allocate_ofs>> if (tdb_free(tdb, newrec_ptr, &newrec) == -1) {
+	 *   - xenstore/tdb.c|1202| <<do_delete>> if (tdb_free(tdb, rec_ptr, rec) == -1)
+	 *
+	 * Add an element into the freelist. Merge adjacent records if
+	 * neccessary.
+	 */
 	if (tdb_free(tdb, rec_ptr, rec) == -1)
 		return -1;
 	return 0;
 }
 
 /* Uses traverse lock: 0 = finish, -1 = error, other = record offset */
+/*
+ * called by:
+ *   - xenstore/tdb.c|1344| <<tdb_traverse>> while ((ret = tdb_next_lock(tdb, &tl, &rec)) > 0) {
+ *   - xenstore/tdb.c|1402| <<tdb_firstkey>> if (tdb_next_lock(tdb, &tdb->travlocks, &rec) <= 0)
+ *   - xenstore/tdb.c|1458| <<tdb_nextkey>> if (tdb_next_lock(tdb, &tdb->travlocks, &rec) > 0) {
+ */
 static int tdb_next_lock(TDB_CONTEXT *tdb, struct tdb_traverse_lock *tlock,
 			 struct list_struct *rec)
 {
@@ -1267,6 +1650,10 @@ static int tdb_next_lock(TDB_CONTEXT *tdb, struct tdb_traverse_lock *tlock,
    if fn is NULL then it is not called
    a non-zero return value from fn() indicates that the traversal should stop
   */
+/*
+ * called by:
+ *   - xenstore/xenstored_core.c|1904| <<clean_store>> tdb_traverse(tdb_ctx, &clean_store_, reachable);
+ */
 int tdb_traverse(TDB_CONTEXT *tdb, tdb_traverse_func fn, void *private)
 {
 	TDB_DATA key, dbuf;
@@ -1327,6 +1714,10 @@ out:
 }
 
 /* find the first entry in the database and return its key */
+/*
+ * called by:
+ *   - xenstore/xs_tdb_dump.c|51| <<main>> key = tdb_firstkey(tdb);
+ */
 TDB_DATA tdb_firstkey(TDB_CONTEXT *tdb)
 {
 	TDB_DATA key;
@@ -1348,6 +1739,10 @@ TDB_DATA tdb_firstkey(TDB_CONTEXT *tdb)
 }
 
 /* find the next entry in the database, returning its key */
+/*
+ * called by:
+ *   - xenstore/xs_tdb_dump.c|82| <<main>> key = tdb_nextkey(tdb, key);
+ */
 TDB_DATA tdb_nextkey(TDB_CONTEXT *tdb, TDB_DATA oldkey)
 {
 	uint32_t oldhash;
@@ -1404,6 +1799,11 @@ TDB_DATA tdb_nextkey(TDB_CONTEXT *tdb, TDB_DATA oldkey)
 }
 
 /* delete an entry in the database given a key */
+/*
+ * called by:
+ *   - xenstore/tdb.c|1473| <<tdb_delete>> return tdb_delete_hash(tdb, key, hash);
+ *   - xenstore/tdb.c|1529| <<tdb_store>> tdb_delete_hash(tdb, key, hash);
+ */
 static int tdb_delete_hash(TDB_CONTEXT *tdb, TDB_DATA key, uint32_t hash)
 {
 	tdb_off rec_ptr;
@@ -1412,12 +1812,24 @@ static int tdb_delete_hash(TDB_CONTEXT *tdb, TDB_DATA key, uint32_t hash)
 
 	if (!(rec_ptr = tdb_find_lock_hash(tdb, key, hash, F_WRLCK, &rec)))
 		return -1;
+	/*
+	 * rec的类型是struct list_struct
+	 */
 	ret = do_delete(tdb, rec_ptr, &rec);
 	if (tdb_unlock(tdb, BUCKET(rec.full_hash), F_WRLCK) != 0)
 		TDB_LOG((tdb, 0, "tdb_delete: WARNING tdb_unlock failed!\n"));
 	return ret;
 }
 
+/*
+ * called by:
+ *   - xenstore/xenstored_core.c|1030| <<delete_node_single>> if (tdb_delete(tdb_ctx, key) != 0) {
+ *   - xenstore/xenstored_core.c|1118| <<destroy_node>> tdb_delete(tdb_ctx, key);
+ *   - xenstore/xenstored_core.c|1888| <<clean_store_>> tdb_delete(tdb, key);
+ *   - xenstore/xenstored_transaction.c|531| <<finalize_transaction>> } else if (tdb_delete(tdb_ctx, key))
+ *   - xenstore/xenstored_transaction.c|536| <<finalize_transaction>> if (i->ta_node && tdb_delete(tdb_ctx, ta_key))
+ *   - xenstore/xenstored_transaction.c|568| <<destroy_transaction>> tdb_delete(tdb_ctx, key);
+ */
 int tdb_delete(TDB_CONTEXT *tdb, TDB_DATA key)
 {
 	uint32_t hash = tdb->hash_fn(&key);
@@ -1429,6 +1841,17 @@ int tdb_delete(TDB_CONTEXT *tdb, TDB_DATA key)
 
    return 0 on success, -1 on failure
 */
+/*
+ * called by:
+ *   - xenstore/xenstored_core.c|450| <<write_node_raw>> if (tdb_store(tdb_ctx, *key, data, TDB_REPLACE) != 0) {
+ *   - xenstore/xenstored_transaction.c|366| <<finalize_transaction>> ret = tdb_store(tdb_ctx, key, data,
+ *
+ * (gdb) p key
+ * $28 = {
+ *   dptr = 0x13de210 "/local/domain/1", 
+ *   dsize = 15
+ * }
+ */
 int tdb_store(TDB_CONTEXT *tdb, TDB_DATA key, TDB_DATA dbuf, int flag)
 {
 	struct list_struct rec;
@@ -1509,6 +1932,10 @@ fail:
 	goto out;
 }
 
+/*
+ * called by:
+ *   - xenstore/tdb.c|1700| <<tdb_open_ex>> if (tdb_already_open(st.st_dev, st.st_ino)) {
+ */
 static int tdb_already_open(dev_t device,
 			    ino_t ino)
 {
@@ -1524,6 +1951,10 @@ static int tdb_already_open(dev_t device,
 }
 
 /* a default logging function */
+/*
+ * 在以下使用null_log_fn():
+ *   - xenstore/tdb.c|1620| <<tdb_open_ex>> tdb->log_fn = log_fn?log_fn:null_log_fn;
+ */
 static void null_log_fn(TDB_CONTEXT *tdb __attribute__((unused)),
 			int level __attribute__((unused)),
 			const char *fmt __attribute__((unused)), ...)
@@ -1531,6 +1962,15 @@ static void null_log_fn(TDB_CONTEXT *tdb __attribute__((unused)),
 }
 
 
+/*
+ * 调用的参数:
+ * 1713         tdb_ctx = tdb_open_ex(tdbname, 7919, tdb_flags, O_RDWR|O_CREAT|O_EXCL,
+ * 1714                               0640, &tdb_logger, NULL);
+ *
+ * called by:
+ *   - xenstore/xenstored_core.c|1709| <<setup_structure>> tdb_ctx = tdb_open_ex(tdbname, 7919, tdb_flags, O_RDWR|O_CREAT|O_EXCL,
+ *   - xenstore/xs_tdb_dump.c|46| <<main>> tdb = tdb_open_ex(talloc_strdup(NULL, argv[1]), 0, 0, O_RDONLY, 0,
+ */
 TDB_CONTEXT *tdb_open_ex(const char *name, int hash_size, int tdb_flags,
 			 int open_flags, mode_t mode,
 			 tdb_log_func log_fn,
@@ -1717,6 +2157,9 @@ TDB_CONTEXT *tdb_open_ex(const char *name, int hash_size, int tdb_flags,
  *
  * @returns -1 for error; 0 for success.
  **/
+/*
+ * ### 没人调用 ###
+ */
 int tdb_close(TDB_CONTEXT *tdb)
 {
 	TDB_CONTEXT **i;
diff --git a/tools/xenstore/tdb.h b/tools/xenstore/tdb.h
index 557cf72..4523abd 100644
--- a/tools/xenstore/tdb.h
+++ b/tools/xenstore/tdb.h
@@ -93,6 +93,25 @@ typedef struct tdb_context {
 	char *name; /* the name of the database */
 	void *map_ptr; /* where it is currently mapped */
 	int fd; /* open file descriptor for the database */
+	/*
+	 * 在以下使用map_size:
+	 *   - xenstore/tdb.c|125| <<tdb_munmap>> int ret = munmap(tdb->map_ptr, tdb->map_size);
+	 *   - xenstore/tdb.c|147| <<tdb_mmap>> tdb->map_ptr = mmap(NULL, tdb->map_size,
+	 *   - xenstore/tdb.c|158| <<tdb_mmap>> tdb->map_size, strerror(errno)));
+	 *   - xenstore/tdb.c|329| <<tdb_oob>> if (len <= tdb->map_size)
+	 *   - xenstore/tdb.c|336| <<tdb_oob>> (int )len, (int )tdb->map_size));
+	 *   - xenstore/tdb.c|357| <<tdb_oob>> tdb->map_size = st.st_size;
+	 *   - xenstore/tdb.c|587| <<tdb_free>> if (right + sizeof(*rec) <= tdb->map_size) {
+	 *   - xenstore/tdb.c|735| <<tdb_expand>> tdb_oob(tdb, tdb->map_size + 1, 1);
+	 *   - xenstore/tdb.c|739| <<tdb_expand>> size = TDB_ALIGN(tdb->map_size + size*10, TDB_PAGE_SIZE) - tdb->map_size;
+	 *   - xenstore/tdb.c|752| <<tdb_expand>> if (expand_file(tdb, tdb->map_size, size) != 0)
+	 *   - xenstore/tdb.c|756| <<tdb_expand>> tdb->map_size += size;
+	 *   - xenstore/tdb.c|760| <<tdb_expand>> tdb->map_size);
+	 *   - xenstore/tdb.c|762| <<tdb_expand>> tdb->map_size -= size;
+	 *   - xenstore/tdb.c|782| <<tdb_expand>> offset = tdb->map_size - size;
+	 *   - xenstore/tdb.c|958| <<tdb_new_database>> tdb->map_size = size;
+	 *   - xenstore/tdb.c|1851| <<tdb_open_ex>> tdb->map_size = st.st_size;
+	 */
 	tdb_len map_size; /* how much space has been mapped */
 	int read_only; /* opened read-only */
 	struct tdb_lock_type *locked; /* array of chain locks */
diff --git a/tools/xenstore/xenstored_core.c b/tools/xenstore/xenstored_core.c
index c8e4237..a7ec96a 100644
--- a/tools/xenstore/xenstored_core.c
+++ b/tools/xenstore/xenstored_core.c
@@ -79,6 +79,25 @@ static bool recovery = true;
 static int reopen_log_pipe[2];
 static int reopen_log_pipe0_pollfd_idx = -1;
 char *tracefile = NULL;
+/*
+ * 在以下使用tdb_ctx:
+ *   - xenstore/xenstored_core.c|388| <<read_node>> data = tdb_fetch(tdb_ctx, key);
+ *   - xenstore/xenstored_core.c|391| <<read_node>> if (tdb_error(tdb_ctx) == TDB_ERR_NOEXIST) {
+ *   - xenstore/xenstored_core.c|396| <<read_node>> log("TDB error on read: %s", tdb_errorstr(tdb_ctx));
+ *   - xenstore/xenstored_core.c|455| <<write_node_raw>> if (tdb_store(tdb_ctx, *key, data, TDB_REPLACE) != 0) {
+ *   - xenstore/xenstored_core.c|899| <<delete_node_single>> if (tdb_delete(tdb_ctx, key) != 0) {
+ *   - xenstore/xenstored_core.c|987| <<destroy_node>> tdb_delete(tdb_ctx, key);
+ *   - xenstore/xenstored_core.c|1558| <<setup_structure>> tdb_ctx = tdb_open_ex(tdbname, 7919, tdb_flags, O_RDWR|O_CREAT|O_EXCL,
+ *   - xenstore/xenstored_core.c|1560| <<setup_structure>> if (!tdb_ctx)
+ *   - xenstore/xenstored_core.c|1753| <<clean_store>> tdb_traverse(tdb_ctx, &clean_store_, reachable);
+ *   - xenstore/xenstored_transaction.c|425| <<finalize_transaction>> data = tdb_fetch(tdb_ctx, key);
+ *   - xenstore/xenstored_transaction.c|428| <<finalize_transaction>> if (tdb_error(tdb_ctx) != TDB_ERR_NOEXIST)
+ *   - xenstore/xenstored_transaction.c|449| <<finalize_transaction>> data = tdb_fetch(tdb_ctx, ta_key);
+ *   - xenstore/xenstored_transaction.c|463| <<finalize_transaction>> ret = tdb_store(tdb_ctx, key, data,
+ *   - xenstore/xenstored_transaction.c|468| <<finalize_transaction>> } else if (tdb_delete(tdb_ctx, key))
+ *   - xenstore/xenstored_transaction.c|473| <<finalize_transaction>> if (i->ta_node && tdb_delete(tdb_ctx, ta_key))
+ *   - xenstore/xenstored_transaction.c|505| <<destroy_transaction>> tdb_delete(tdb_ctx, key);
+ */
 TDB_CONTEXT *tdb_ctx = NULL;
 
 static const char *sockmsg_string(enum xsd_sockmsg_type type);
@@ -99,7 +118,17 @@ static const char *sockmsg_string(enum xsd_sockmsg_type type);
 
 int quota_nb_entry_per_domain = 1000;
 int quota_nb_watch_per_domain = 128;
+/*
+ * 在以下使用quota_max_entry_size:
+ *   - xenstore/xenstored_core.c|480| <<write_node_raw>> data.dsize >= quota_max_entry_size) {
+ *   - xenstore/xenstored_core.c|1995| <<main>> quota_max_entry_size = strtol(optarg, NULL, 10);
+ */
 int quota_max_entry_size = 2048; /* 2K */
+/*
+ * 在以下使用quota_max_transaction:
+ *   - xenstore/xenstored_core.c|1949| <<main>> quota_max_transaction = strtol(optarg, NULL, 10);
+ *   - xenstore/xenstored_transaction.c|526| <<do_transaction_start>> if (conn->id && conn->transaction_started > quota_max_transaction)
+ */
 int quota_max_transaction = 10;
 
 void trace(const char *fmt, ...)
@@ -358,6 +387,20 @@ static void initialize_fds(int sock, int *p_sock_pollfd_idx,
  * If it fails, returns NULL and sets errno.
  * Temporary memory allocations will be done with ctx.
  */
+/*
+ * called by:
+ *   - xenstore/xenstored_core.c|545| <<ask_parents>> node = read_node(conn, ctx, name);
+ *   - xenstore/xenstored_core.c|602| <<get_node>> node = read_node(conn, ctx, name);
+ *   - xenstore/xenstored_core.c|944| <<construct_node>> parent = read_node(conn, parentname, parentname);
+ *   - xenstore/xenstored_core.c|1115| <<delete_node>> child = name ? read_node(conn, node, name) : NULL;
+ *   - xenstore/xenstored_core.c|1173| <<_rm>> parent = read_node(conn, ctx, parentname);
+ *   - xenstore/xenstored_core.c|1200| <<do_rm>> node = read_node(conn, in, parentname);
+ *   - xenstore/xenstored_core.c|1646| <<check_store_>> struct node *node = read_node(NULL, name, name);
+ *   - xenstore/xenstored_core.c|1672| <<check_store_>> childnode = read_node(NULL, childname, childname);
+ *
+ * name的一个例子"/local/domain/0/name"
+ * 另外一个例子"/loca/domain/1"
+ */
 static struct node *read_node(struct connection *conn, const void *ctx,
 			      const char *name)
 {
@@ -380,6 +423,14 @@ static struct node *read_node(struct connection *conn, const void *ctx,
 	if (transaction_prepend(conn, name, &key))
 		return NULL;
 
+	/*
+	 * key的一个例子.
+	 * (gdb) p key
+         * $31 = {
+         *   dptr = 0x13dde20 "/local/domain/1",
+         *   dsize = 15
+         * }
+	 */
 	data = tdb_fetch(tdb_ctx, key);
 
 	if (data.dptr == NULL) {
@@ -399,6 +450,9 @@ static struct node *read_node(struct connection *conn, const void *ctx,
 	talloc_steal(node, data.dptr);
 
 	/* Datalen, childlen, number of permissions */
+	/*
+	 * hdr是struct xs_tdb_record_hdr
+	 */
 	hdr = (void *)data.dptr;
 	node->generation = hdr->generation;
 	node->num_perms = hdr->num_perms;
@@ -412,11 +466,32 @@ static struct node *read_node(struct connection *conn, const void *ctx,
 	/* Children is strings, nul separated. */
 	node->children = node->data + node->datalen;
 
+	/*
+	 * A node has been accessed.
+	 *
+	 * Modifying accesses (write, delete) always update the generation (global and
+	 * node->generation).
+	 *
+	 * Accesses in a transaction will be added to the list of accessed nodes
+	 * if not already done. Read type accesses will copy the node to the
+	 * transaction specific data base part, write type accesses go there
+	 * anyway.
+	 *
+	 * If not NULL, key will be supplied with name and length of name of the node
+	 * to be accessed in the data base.
+	 */
 	access_node(conn, node, NODE_ACCESS_READ, NULL);
 
 	return node;
 }
 
+/*
+ * called by:
+ *   - xenstore/xenstored_core.c|514| <<write_node>> return write_node_raw(conn, &key, node);
+ *   - xenstore/xenstored_transaction.c|363| <<access_node>> ret = write_node_raw(conn, &local_key, node);
+ *
+ * Write a node to the tdb data base.
+ */
 int write_node_raw(struct connection *conn, TDB_DATA *key, struct node *node)
 {
 	TDB_DATA data;
@@ -427,20 +502,42 @@ int write_node_raw(struct connection *conn, TDB_DATA *key, struct node *node)
 		+ node->num_perms*sizeof(node->perms[0])
 		+ node->datalen + node->childlen;
 
+	/*
+	 * 在以下使用quota_max_entry_size:
+	 *   - xenstore/xenstored_core.c|480| <<write_node_raw>> data.dsize >= quota_max_entry_size) {
+	 *   - xenstore/xenstored_core.c|1995| <<main>> quota_max_entry_size = strtol(optarg, NULL, 10);
+	 */
 	if (domain_is_unprivileged(conn) &&
 	    data.dsize >= quota_max_entry_size) {
 		errno = ENOSPC;
 		return errno;
 	}
 
+	/*
+	 * data.dptr包括以下数据:
+	 *     sizeof(*hdr)
+	 *     + node->num_perms*sizeof(node->perms[0])
+	 *     + node->datalen + node->childlen;
+	 */
 	data.dptr = talloc_size(node, data.dsize);
 	hdr = (void *)data.dptr;
+	/*
+	 * 先填充header
+	 */
 	hdr->generation = node->generation;
 	hdr->num_perms = node->num_perms;
 	hdr->datalen = node->datalen;
+	/*
+	 * struct xs_tdb_record_hdr:
+	 *   -> uint32_t children;
+	 *
+	 * struct node:
+	 *   -> char *children
+	 */
 	hdr->childlen = node->childlen;
 
 	memcpy(hdr->perms, node->perms, node->num_perms*sizeof(node->perms[0]));
+	/* p是真正存放数据的地方 */
 	p = hdr->perms + node->num_perms;
 	memcpy(p, node->data, node->datalen);
 	p += node->datalen;
@@ -455,6 +552,31 @@ int write_node_raw(struct connection *conn, TDB_DATA *key, struct node *node)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - xenstore/xenstored_core.c|1079| <<create_node>> if (write_node(conn, i)) {
+ *   - xenstore/xenstored_core.c|1119| <<do_write>> if (write_node(conn, node))
+ *   - xenstore/xenstored_core.c|1195| <<remove_child_entry>> return write_node(conn, node);
+ *   - xenstore/xenstored_core.c|1334| <<do_set_perms>> if (write_node(conn, node))
+ *   - xenstore/xenstored_core.c|1600| <<manual_node>> if (write_node(NULL, node))
+ *
+ * (gdb) p *node
+ * $26 = {
+ *   name = 0x13de210 "/local/domain/1", 
+ *   tdb = 0x13dd810, 
+ *   parent = 0x0, 
+ *   num_perms = 2, 
+ *   perms = 0x13dedec, 
+ *   datalen = 0, 
+ *   data = 0x13dedfc, 
+ *   childlen = 48, 
+ *   children = 0x13df360 "vm"
+ * }
+ *
+ * 一个例子:
+ * node->name = "/"
+ * node->children = "tool"
+ */
 static int write_node(struct connection *conn, struct node *node)
 {
 	TDB_DATA key;
@@ -564,6 +686,23 @@ static int errno_from_parents(struct connection *conn, const void *ctx,
  * If it fails, returns NULL and sets errno.
  * Temporary memory allocations are done with ctx.
  */
+/*
+ * (gdb) bt
+ * #0  get_node (conn=0x13ddb70, ctx=0x13de930, name=0x13de8b0 "/local/domain/0/name", perm=XS_PERM_READ)
+ *     at xenstored_core.c:583
+ * #1  0x000000000040429d in do_read (conn=0x13ddb70) at xenstored_core.c:806
+ * #2  process_message (conn=0x13ddb70) at xenstored_core.c:1254
+ * #3  consider_message (conn=0x13ddb70) at xenstored_core.c:1341
+ * #4  handle_input (conn=0x13ddb70) at xenstored_core.c:1387
+ * #5  0x00000000004053ba in main (argc=<value optimized out>, argv=<value optimized out>) at xenstored_core.c:2095
+ *
+ * Breakpoint 5, get_node (conn=0x13ddb70, ctx=0x13de930, name=0x13de8b0 "/local/domain/0/name", perm=XS_PERM_READ)
+ *   at xenstored_core.c:583
+ *
+ * called by:
+ *   - xenstore/xenstored_core.c|911| <<get_node_canonicalized>> return get_node(conn, ctx, *canonical_name, perm);
+ *   - xenstore/xenstored_watch.c|92| <<add_event>> struct node *node = get_node(conn, ctx, name, XS_PERM_READ);
+ */
 struct node *get_node(struct connection *conn,
 		      const void *ctx,
 		      const char *name,
@@ -1013,6 +1152,10 @@ static struct node *create_node(struct connection *conn, const void *ctx,
 }
 
 /* path, data... */
+/*
+ * 在以下使用do_write():
+ *   - xenstore/xenstored_core.c|1420| <<global>> [XS_WRITE] = { "WRITE", do_write },
+ */
 static int do_write(struct connection *conn, struct buffered_data *in)
 {
 	unsigned int offset, datalen;
@@ -1498,6 +1641,12 @@ static void accept_connection(int sock, bool canwrite)
 static int tdb_flags;
 
 /* We create initial nodes manually. */
+/*
+ * called by:
+ *   - xenstore/xenstored_core.c|1635| <<setup_structure>> manual_node("/", "tool");
+ *   - xenstore/xenstored_core.c|1636| <<setup_structure>> manual_node("/tool", "xenstored");
+ *   - xenstore/xenstored_core.c|1637| <<setup_structure>> manual_node("/tool/xenstored", NULL);
+ */
 static void manual_node(const char *name, const char *child)
 {
 	struct node *node;
@@ -1516,6 +1665,10 @@ static void manual_node(const char *name, const char *child)
 
 	if (write_node(NULL, node))
 		barf_perror("Could not create initial node %s", name);
+	/*
+	 * !!! 这里free了node!
+	 * 说明内存中的node不是永久的
+	 */
 	talloc_free(node);
 }
 
@@ -1540,9 +1693,16 @@ static void tdb_logger(TDB_CONTEXT *tdb, int level, const char * fmt, ...)
 	}
 }
 
+/*
+ * called by:
+ *   - xenstore/xenstored_core.c|2082| <<main>> setup_structure();
+ */
 static void setup_structure(void)
 {
 	char *tdbname;
+	/*
+	 * tdbname应该就是tdb的path了
+	 */
 	tdbname = talloc_strdup(talloc_autofree_context(), xs_daemon_tdb());
 	if (!tdbname)
 		barf_perror("Could not create tdbname");
@@ -1550,6 +1710,13 @@ static void setup_structure(void)
 	if (!(tdb_flags & TDB_INTERNAL))
 		unlink(tdbname);
 
+	/*
+	 * called by:
+	 *   - xenstore/xenstored_core.c|1709| <<setup_structure>> tdb_ctx = tdb_open_ex(tdbname, 7919, tdb_flags, O_RDWR|O_CREAT|O_EXCL,
+	 *   - xenstore/xs_tdb_dump.c|46| <<main>> tdb = tdb_open_ex(talloc_strdup(NULL, argv[1]), 0, 0, O_RDONLY, 0,
+	 *
+	 * TDB_CONTEXT *类型
+	 */
 	tdb_ctx = tdb_open_ex(tdbname, 7919, tdb_flags, O_RDWR|O_CREAT|O_EXCL,
 			      0640, &tdb_logger, NULL);
 	if (!tdb_ctx)
diff --git a/tools/xenstore/xenstored_core.h b/tools/xenstore/xenstored_core.h
index 3d27feb..c654507 100644
--- a/tools/xenstore/xenstored_core.h
+++ b/tools/xenstore/xenstored_core.h
@@ -92,6 +92,14 @@ struct connection
 	/* List of in-progress transactions. */
 	struct list_head transaction_list;
 	uint32_t next_transaction_id;
+	/*
+	 * 在以下使用connection->transaction_started:
+	 *   - xenstore/xenstored_core.c|1431| <<new_connection>> new->transaction_started = 0;
+	 *   - xenstore/xenstored_transaction.c|548| <<do_transaction_start>> if (conn->id && conn->transaction_started > quota_max_transaction)
+	 *   - xenstore/xenstored_transaction.c|571| <<do_transaction_start>> conn->transaction_started++;
+	 *   - xenstore/xenstored_transaction.c|617| <<do_transaction_end>> conn->transaction_started--;
+	 *   - xenstore/xenstored_transaction.c|719| <<conn_delete_all_transactions>> conn->transaction_started = 0;
+	 */
 	unsigned int transaction_started;
 
 	/* The domain I'm associated with, if any. */
@@ -116,6 +124,16 @@ struct node {
 	struct node *parent;
 
 	/* Generation count. */
+	/*
+	 * 在以下使用node->generation:
+	 *   - xenstore/xenstored_core.c|387| <<read_node>> node->generation = NO_GENERATION;
+	 *   - xenstore/xenstored_core.c|403| <<read_node>> node->generation = hdr->generation;
+	 *   - xenstore/xenstored_core.c|438| <<write_node_raw>> hdr->generation = node->generation;
+	 *   - xenstore/xenstored_core.c|838| <<send_directory_part>> genlen = snprintf(gen, sizeof(gen), "%"PRIu64, node->generation) + 1;
+	 *   - xenstore/xenstored_transaction.c|237| <<access_node>> node->generation = generation++;
+	 *   - xenstore/xenstored_transaction.c|275| <<access_node>> i->generation = node->generation;
+	 *   - xenstore/xenstored_transaction.c|277| <<access_node>> if (node->generation != NO_GENERATION) {
+	 */
 	uint64_t generation;
 #define NO_GENERATION ~((uint64_t)0)
 
@@ -129,6 +147,29 @@ struct node {
 
 	/* Children, each nul-terminated. */
 	unsigned int childlen;
+	/*
+	 * 在以下使用node->children:
+	 *   - xenstore/xenstored_core.c|448| <<read_node>> node->children = node->data + node->datalen;
+	 *   - xenstore/xenstored_core.c|496| <<write_node_raw>> memcpy(p, node->children, node->childlen);
+	 *   - xenstore/xenstored_core.c|863| <<send_directory>> send_reply(conn, XS_DIRECTORY, node->children, node->childlen);
+	 *   - xenstore/xenstored_core.c|898| <<send_directory_part>> child = node->children + off;
+	 *   - xenstore/xenstored_core.c|912| <<send_directory_part>> memcpy(data + genlen, node->children + off, len);
+	 *   - xenstore/xenstored_core.c|983| <<construct_node>> children = talloc_array(ctx, char , parent->childlen + baselen);
+	 *   - xenstore/xenstored_core.c|986| <<construct_node>> memcpy(children, parent->children, parent->childlen);
+	 *   - xenstore/xenstored_core.c|987| <<construct_node>> memcpy(children + parent->childlen, base, baselen);
+	 *   - xenstore/xenstored_core.c|988| <<construct_node>> parent->children = children;
+	 *   - xenstore/xenstored_core.c|1009| <<construct_node>> node->children = node->data = NULL;
+	 *   - xenstore/xenstored_core.c|1135| <<delete_node>> for (i = 0; i < node->childlen; i += strlen(node->children+i) + 1) {
+	 *   - xenstore/xenstored_core.c|1139| <<delete_node>> node->children + i);
+	 *   - xenstore/xenstored_core.c|1146| <<delete_node>> node->name, node->children + i);
+	 *   - xenstore/xenstored_core.c|1164| <<remove_child_entry>> size_t childlen = strlen(node->children + offset);
+	 *   - xenstore/xenstored_core.c|1165| <<remove_child_entry>> memdel(node->children, offset, childlen + 1, node->childlen);
+	 *   - xenstore/xenstored_core.c|1176| <<delete_child>> for (i = 0; i < node->childlen; i += strlen(node->children+i) + 1) {
+	 *   - xenstore/xenstored_core.c|1177| <<delete_child>> if (streq(node->children+i, childname)) {
+	 *   - xenstore/xenstored_core.c|1562| <<manual_node>> node->children = (char *)child;
+	 *   - xenstore/xenstored_core.c|1688| <<check_store_>> size_t childlen = strlen(node->children + i);
+	 *   - xenstore/xenstored_core.c|1690| <<check_store_>> node->children + i);
+	 */
 	char *children;
 };
 
diff --git a/tools/xenstore/xenstored_domain.c b/tools/xenstore/xenstored_domain.c
index fa66550..0b375b6 100644
--- a/tools/xenstore/xenstored_domain.c
+++ b/tools/xenstore/xenstored_domain.c
@@ -658,6 +658,11 @@ void domain_init(void)
 	virq_port = rc;
 }
 
+/*
+ * called by:
+ *   - xenstore/xenstored_core.c|1102| <<construct_node>> domain_entry_inc(conn, node);
+ *   - xenstore/xenstored_core.c|1398| <<do_set_perms>> domain_entry_inc(conn, node);
+ */
 void domain_entry_inc(struct connection *conn, struct node *node)
 {
 	struct domain *d;
@@ -710,6 +715,10 @@ void domain_entry_dec(struct connection *conn, struct node *node)
 	}
 }
 
+/*
+ * called by:
+ *   - xenstore/xenstored_transaction.c|688| <<transaction_fix_domains>> cnt = domain_entry_fix(d->domid, d->nbentry, update);
+ */
 int domain_entry_fix(unsigned int domid, int num, bool update)
 {
 	struct domain *d;
@@ -765,6 +774,13 @@ static wrl_creditt wrl_config_gburst         = WRL_GBURST * WRL_FACTOR;
 static wrl_creditt wrl_config_newdoms_dburst =
 	                         WRL_DBURST * WRL_NEWDOMS * WRL_FACTOR;
 
+/*
+ * 在以下使用wrl_ntransactions:
+ *   - xenstore/xenstored_domain.c|972| <<wrl_apply_debit_direct>> if (!wrl_ntransactions)
+ *   - xenstore/xenstored_domain.c|981| <<wrl_apply_debit_trans_commit>> if (wrl_ntransactions <= 1)
+ *   - xenstore/xenstored_transaction.c|496| <<destroy_transaction>> wrl_ntransactions--;
+ *   - xenstore/xenstored_transaction.c|572| <<do_transaction_start>> wrl_ntransactions++;
+ */
 long wrl_ntransactions;
 
 static long wrl_ndomains;
@@ -978,6 +994,13 @@ void wrl_apply_debit_direct(struct connection *conn)
 
 void wrl_apply_debit_trans_commit(struct connection *conn)
 {
+	/*
+	 * 在以下使用wrl_ntransactions:
+	 *   - xenstore/xenstored_domain.c|972| <<wrl_apply_debit_direct>> if (!wrl_ntransactions)
+	 *   - xenstore/xenstored_domain.c|981| <<wrl_apply_debit_trans_commit>> if (wrl_ntransactions <= 1)
+	 *   - xenstore/xenstored_transaction.c|496| <<destroy_transaction>> wrl_ntransactions--;
+	 *   - xenstore/xenstored_transaction.c|572| <<do_transaction_start>> wrl_ntransactions++;
+	 */
 	if (wrl_ntransactions <= 1)
 		/* our own transaction appears in the counter */
 		return;
diff --git a/tools/xenstore/xenstored_transaction.c b/tools/xenstore/xenstored_transaction.c
index 75816dd..a932dbb 100644
--- a/tools/xenstore/xenstored_transaction.c
+++ b/tools/xenstore/xenstored_transaction.c
@@ -118,6 +118,11 @@ struct accessed_node
 	bool check_gen;
 
 	/* Modified? */
+	/*
+	 * 在以下使用accessed_node->modified:
+	 *   - xenstore/xenstored_transaction.c|403| <<access_node>> i->modified = true;
+	 *   - xenstore/xenstored_transaction.c|509| <<finalize_transaction>> if (i->modified) {
+	 */
 	bool modified;
 
 	/* Transaction node in data base? */
@@ -145,32 +150,108 @@ struct transaction
 	uint32_t id;
 
 	/* Generation when transaction started. */
+	/*
+	 * 在以下使用transaction->generation:
+	 *   - xenstore/xenstored_transaction.c|184| <<transaction_get_node_name>> return talloc_asprintf(ctx, "%"PRIu64"/%s", trans->generation, name);
+	 *   - xenstore/xenstored_transaction.c|448| <<do_transaction_start>> trans->generation = generation++;
+	 *   - xenstore/xenstored_transaction.c|588| <<check_transactions>> trans->generation);
+	 */
 	uint64_t generation;
 
 	/* List of accessed nodes. */
+	/*
+	 * 在以下使用transaction->accessed:
+	 *   - xenstore/xenstored_transaction.c|174| <<find_accessed_node>> list_for_each_entry(i, &trans->accessed, list)
+	 *   - xenstore/xenstored_transaction.c|285| <<access_node>> list_add_tail(&i->list, &trans->accessed);
+	 *   - xenstore/xenstored_transaction.c|332| <<finalize_transaction>> list_for_each_entry(i, &trans->accessed, list) {
+	 *   - xenstore/xenstored_transaction.c|350| <<finalize_transaction>> while ((i = list_top(&trans->accessed, struct accessed_node, list))) {
+	 *   - xenstore/xenstored_transaction.c|398| <<destroy_transaction>> while ((i = list_top(&trans->accessed, struct accessed_node, list))) {
+	 *   - xenstore/xenstored_transaction.c|445| <<do_transaction_start>> INIT_LIST_HEAD(&trans->accessed);
+	 *   - xenstore/xenstored_transaction.c|592| <<check_transactions>> list_for_each_entry(i, &trans->accessed, list) {
+	 *
+	 * 存储所有的struct accessed_node
+	 */
 	struct list_head accessed;
 
 	/* List of changed domains - to record the changed domain entry number */
+	/*
+	 * 在以下使用transaction->changed_domains:
+	 *   - xenstore/xenstored_transaction.c|446| <<do_transaction_start>> INIT_LIST_HEAD(&trans->changed_domains);
+	 *   - xenstore/xenstored_transaction.c|474| <<transaction_fix_domains>> list_for_each_entry(d, &trans->changed_domains, list) {
+	 *   - xenstore/xenstored_transaction.c|525| <<transaction_entry_inc>> list_for_each_entry(d, &trans->changed_domains, list)
+	 *   - xenstore/xenstored_transaction.c|539| <<transaction_entry_inc>> list_add_tail(&d->list, &trans->changed_domains);
+	 *   - xenstore/xenstored_transaction.c|546| <<transaction_entry_dec>> list_for_each_entry(d, &trans->changed_domains, list)
+	 *   - xenstore/xenstored_transaction.c|560| <<transaction_entry_dec>> list_add_tail(&d->list, &trans->changed_domains);
+	 */
 	struct list_head changed_domains;
 
 	/* Flag for letting transaction fail. */
 	bool fail;
 };
 
+/*
+ * 在以下使用quota_max_transaction:
+ *   - xenstore/xenstored_core.c|1949| <<main>> quota_max_transaction = strtol(optarg, NULL, 10);
+ *   - xenstore/xenstored_transaction.c|526| <<do_transaction_start>> if (conn->id && conn->transaction_started > quota_max_transaction)
+ */
 extern int quota_max_transaction;
+/*
+ * 在以下使用全局的generation:
+ *   - xenstore/xenstored_transaction.c|298| <<access_node>> node->generation = generation++;
+ *   - xenstore/xenstored_transaction.c|430| <<finalize_transaction>> hdr->generation = generation++;
+ *   - xenstore/xenstored_transaction.c|537| <<do_transaction_start>> trans->generation = generation++;
+ */
 static uint64_t generation;
 
+/*
+ * called by:
+ *   - xenstore/xenstored_transaction.c|223| <<transaction_prepend>> set_tdb_key(name, key);
+ *   - xenstore/xenstored_transaction.c|232| <<transaction_prepend>> set_tdb_key(tdb_name, key);
+ *   - xenstore/xenstored_transaction.c|270| <<access_node>> set_tdb_key(node->name, key);
+ *   - xenstore/xenstored_transaction.c|303| <<access_node>> set_tdb_key(trans_name, &local_key);
+ *   - xenstore/xenstored_transaction.c|321| <<access_node>> set_tdb_key(trans_name, key);
+ *   - xenstore/xenstored_transaction.c|365| <<finalize_transaction>> set_tdb_key(i->node, &key);
+ *   - xenstore/xenstored_transaction.c|385| <<finalize_transaction>> set_tdb_key(trans_name, &ta_key);
+ *   - xenstore/xenstored_transaction.c|388| <<finalize_transaction>> set_tdb_key(i->node, &key);
+ *   - xenstore/xenstored_transaction.c|441| <<destroy_transaction>> set_tdb_key(trans_name, &key);
+ *
+ * typedef struct TDB_DATA {
+ *	char *dptr;
+ *	size_t dsize;
+ * } TDB_DATA;
+ *
+ * 用name填充key
+ */
 static void set_tdb_key(const char *name, TDB_DATA *key)
 {
 	key->dptr = (char *)name;
 	key->dsize = strlen(name);
 }
 
+/*
+ * called by:
+ *   - xenstore/xenstored_transaction.c|222| <<transaction_prepend>> !find_accessed_node(conn->transaction, name)) {
+ *   - xenstore/xenstored_transaction.c|280| <<access_node>> i = find_accessed_node(trans, node->name);
+ *
+ * 遍历transaction->accessed返回和参数name相同的struct accessed_node
+ */
 static struct accessed_node *find_accessed_node(struct transaction *trans,
 						const char *name)
 {
 	struct accessed_node *i;
 
+	/*
+	 * 在以下使用transaction->accessed:
+	 *   - xenstore/xenstored_transaction.c|174| <<find_accessed_node>> list_for_each_entry(i, &trans->accessed, list)
+	 *   - xenstore/xenstored_transaction.c|285| <<access_node>> list_add_tail(&i->list, &trans->accessed);
+	 *   - xenstore/xenstored_transaction.c|332| <<finalize_transaction>> list_for_each_entry(i, &trans->accessed, list) {
+	 *   - xenstore/xenstored_transaction.c|350| <<finalize_transaction>> while ((i = list_top(&trans->accessed, struct accessed_node, list))) {
+	 *   - xenstore/xenstored_transaction.c|398| <<destroy_transaction>> while ((i = list_top(&trans->accessed, struct accessed_node, list))) {
+	 *   - xenstore/xenstored_transaction.c|445| <<do_transaction_start>> INIT_LIST_HEAD(&trans->accessed);
+	 *   - xenstore/xenstored_transaction.c|592| <<check_transactions>> list_for_each_entry(i, &trans->accessed, list) {
+	 *
+	 * 存储所有的struct accessed_node
+	 */
 	list_for_each_entry(i, &trans->accessed, list)
 		if (streq(i->node, name))
 			return i;
@@ -178,6 +259,14 @@ static struct accessed_node *find_accessed_node(struct transaction *trans,
 	return NULL;
 }
 
+/*
+ * called by:
+ *   - xenstore/xenstored_transaction.c|227| <<transaction_prepend>> tdb_name = transaction_get_node_name(conn->transaction,
+ *   - xenstore/xenstored_transaction.c|276| <<access_node>> trans_name = transaction_get_node_name(node, trans, node->name);
+ *   - xenstore/xenstored_transaction.c|380| <<finalize_transaction>> trans_name = transaction_get_node_name(i, trans, i->node);
+ *   - xenstore/xenstored_transaction.c|438| <<destroy_transaction>> trans_name = transaction_get_node_name(i, trans,
+ *   - xenstore/xenstored_transaction.c|661| <<check_transactions>> tnode = transaction_get_node_name(tname, trans,
+ */
 static char *transaction_get_node_name(void *ctx, struct transaction *trans,
 				       const char *name)
 {
@@ -188,22 +277,39 @@ static char *transaction_get_node_name(void *ctx, struct transaction *trans,
  * Prepend the transaction to name if node has been modified in the current
  * transaction.
  */
+/*
+ * called by:
+ *   - xenstore/xenstored_core.c|380| <<read_node>> if (transaction_prepend(conn, name, &key))
+ */
 int transaction_prepend(struct connection *conn, const char *name,
 			TDB_DATA *key)
 {
 	char *tdb_name;
 
+	/*
+	 * find_accessed_node():
+	 * 遍历transaction->accessed返回和参数name相同的struct accessed_node
+	 */
 	if (!conn || !conn->transaction ||
 	    !find_accessed_node(conn->transaction, name)) {
 		set_tdb_key(name, key);
 		return 0;
 	}
 
+	/*
+	 * 在以下调用transaction_get_node_name():
+	 *   - xenstore/xenstored_transaction.c|227| <<transaction_prepend>> tdb_name = transaction_get_node_name(conn->transaction,
+	 *   - xenstore/xenstored_transaction.c|276| <<access_node>> trans_name = transaction_get_node_name(node, trans, node->name);
+	 *   - xenstore/xenstored_transaction.c|380| <<finalize_transaction>> trans_name = transaction_get_node_name(i, trans, i->node);
+	 *   - xenstore/xenstored_transaction.c|438| <<destroy_transaction>> trans_name = transaction_get_node_name(i, trans,
+	 *   - xenstore/xenstored_transaction.c|661| <<check_transactions>> tnode = transaction_get_node_name(tname, trans,
+	 */
 	tdb_name = transaction_get_node_name(conn->transaction,
 					     conn->transaction, name);
 	if (!tdb_name)
 		return errno;
 
+	/* 用name填充key */
 	set_tdb_key(tdb_name, key);
 
 	return 0;
@@ -223,6 +329,13 @@ int transaction_prepend(struct connection *conn, const char *name,
  * If not NULL, key will be supplied with name and length of name of the node
  * to be accessed in the data base.
  */
+/*
+ * called by:
+ *   - xenstore/xenstored_core.c|388| <<read_node>> access_node(conn, node, NODE_ACCESS_READ, NULL);
+ *   - xenstore/xenstored_core.c|415| <<read_node>> access_node(conn, node, NODE_ACCESS_READ, NULL);
+ *   - xenstore/xenstored_core.c|462| <<write_node>> if (access_node(conn, node, NODE_ACCESS_WRITE, &key))
+ *   - xenstore/xenstored_core.c|891| <<delete_node_single>> if (access_node(conn, node, NODE_ACCESS_DELETE, &key))
+ */
 int access_node(struct connection *conn, struct node *node,
 		enum node_access_type type, TDB_DATA *key)
 {
@@ -233,6 +346,9 @@ int access_node(struct connection *conn, struct node *node,
 	int ret;
 	bool introduce = false;
 
+	/*
+	 * 不是read就要增加generation
+	 */
 	if (type != NODE_ACCESS_READ) {
 		node->generation = generation++;
 		if (conn && !conn->transaction)
@@ -252,6 +368,9 @@ int access_node(struct connection *conn, struct node *node,
 	if (!trans_name)
 		goto nomem;
 
+	/*
+	 * 遍历transaction->accessed返回和参数name相同的struct accessed_node
+	 */
 	i = find_accessed_node(trans, node->name);
 	if (!i) {
 		i = talloc_zero(trans, struct accessed_node);
@@ -285,6 +404,11 @@ int access_node(struct connection *conn, struct node *node,
 		list_add_tail(&i->list, &trans->accessed);
 	}
 
+	/*
+	 * 在以下使用accessed_node->modified:
+	 *   - xenstore/xenstored_transaction.c|403| <<access_node>> i->modified = true;
+	 *   - xenstore/xenstored_transaction.c|509| <<finalize_transaction>> if (i->modified) {
+	 */
 	if (type != NODE_ACCESS_READ)
 		i->modified = true;
 
@@ -319,6 +443,10 @@ err:
  * transaction prepended. Delete all transaction specific nodes in the data
  * base.
  */
+/*
+ * called by:
+ *   - xenstore/xenstored_transaction.c|508| <<do_transaction_end>> if (finalize_transaction(conn, trans))
+ */
 static int finalize_transaction(struct connection *conn,
 				struct transaction *trans)
 {
@@ -329,11 +457,39 @@ static int finalize_transaction(struct connection *conn,
 	char *trans_name;
 	int ret;
 
+	/*
+	 * 在以下使用transaction->accessed:
+	 *   - xenstore/xenstored_transaction.c|174| <<find_accessed_node>> list_for_each_entry(i, &trans->accessed, list)
+	 *   - xenstore/xenstored_transaction.c|285| <<access_node>> list_add_tail(&i->list, &trans->accessed);
+	 *   - xenstore/xenstored_transaction.c|332| <<finalize_transaction>> list_for_each_entry(i, &trans->accessed, list) {
+	 *   - xenstore/xenstored_transaction.c|350| <<finalize_transaction>> while ((i = list_top(&trans->accessed, struct accessed_node, list))) {
+	 *   - xenstore/xenstored_transaction.c|398| <<destroy_transaction>> while ((i = list_top(&trans->accessed, struct accessed_node, list))) {
+	 *   - xenstore/xenstored_transaction.c|445| <<do_transaction_start>> INIT_LIST_HEAD(&trans->accessed);
+	 *   - xenstore/xenstored_transaction.c|592| <<check_transactions>> list_for_each_entry(i, &trans->accessed, list) {
+	 *
+	 * 存储所有的struct accessed_node
+	 *
+	 * 这里的for循环是把所以accessed node从tdb读出来, 看看tdb的generation是否对的上
+	 */
 	list_for_each_entry(i, &trans->accessed, list) {
 		if (!i->check_gen)
 			continue;
 
+		/* 用name填充key */
 		set_tdb_key(i->node, &key);
+		/*
+		 * find an entry in the database given a key
+		 *
+		 * If an entry doesn't exist tdb_err will be set to
+		 * TDB_ERR_NOEXIST. If a key has no data attached
+		 * then the TDB_DATA will have zero length but
+		 * a non-zero pointer
+		 */
+		/*
+		 * TDB_DATA data:
+		 *   -> char *dptr;
+		 *   -> size_t dsize;
+		 */
 		data = tdb_fetch(tdb_ctx, key);
 		hdr = (void *)data.dptr;
 		if (!data.dptr) {
@@ -343,10 +499,25 @@ static int finalize_transaction(struct connection *conn,
 		} else
 			gen = hdr->generation;
 		talloc_free(data.dptr);
+		/*
+		 * struct accessed_node *i;
+		 */
 		if (i->generation != gen)
 			return EAGAIN;
 	}
 
+	/*
+	 * 在以下使用transaction->accessed:
+	 *   - xenstore/xenstored_transaction.c|174| <<find_accessed_node>> list_for_each_entry(i, &trans->accessed, list)
+	 *   - xenstore/xenstored_transaction.c|285| <<access_node>> list_add_tail(&i->list, &trans->accessed);
+	 *   - xenstore/xenstored_transaction.c|332| <<finalize_transaction>> list_for_each_entry(i, &trans->accessed, list) {
+	 *   - xenstore/xenstored_transaction.c|350| <<finalize_transaction>> while ((i = list_top(&trans->accessed, struct accessed_node, list))) {
+	 *   - xenstore/xenstored_transaction.c|398| <<destroy_transaction>> while ((i = list_top(&trans->accessed, struct accessed_node, list))) {
+	 *   - xenstore/xenstored_transaction.c|445| <<do_transaction_start>> INIT_LIST_HEAD(&trans->accessed);
+	 *   - xenstore/xenstored_transaction.c|592| <<check_transactions>> list_for_each_entry(i, &trans->accessed, list) {
+	 *
+	 * 存储所有的struct accessed_node
+	 */
 	while ((i = list_top(&trans->accessed, struct accessed_node, list))) {
 		trans_name = transaction_get_node_name(i, trans, i->node);
 		if (!trans_name)
@@ -355,14 +526,31 @@ static int finalize_transaction(struct connection *conn,
 
 		set_tdb_key(trans_name, &ta_key);
 
+		/*
+		 * 在以下使用accessed_node->modified:
+		 *   - xenstore/xenstored_transaction.c|403| <<access_node>> i->modified = true;
+		 *   - xenstore/xenstored_transaction.c|509| <<finalize_transaction>> if (i->modified) {
+		 */
 		if (i->modified) {
 			set_tdb_key(i->node, &key);
 			if (i->ta_node) {
 				data = tdb_fetch(tdb_ctx, ta_key);
 				if (!data.dptr)
 					goto err;
+				/*
+				 * struct xs_tdb_record_hdr *hdr;
+				 */
 				hdr = (void *)data.dptr;
 				hdr->generation = generation++;
+				/*
+				 * store an element in the database, replacing any existing element
+				 * with the same key
+				 * return 0 on success, -1 on failure
+				 *
+				 * called by:
+				 *   - xenstore/xenstored_core.c|450| <<write_node_raw>> if (tdb_store(tdb_ctx, *key, data, TDB_REPLACE) != 0) {
+				 *   - xenstore/xenstored_transaction.c|366| <<finalize_transaction>> ret = tdb_store(tdb_ctx, key, data,
+				 */
 				ret = tdb_store(tdb_ctx, key, data,
 						TDB_REPLACE);
 				talloc_free(data.dptr);
@@ -370,6 +558,17 @@ static int finalize_transaction(struct connection *conn,
 					goto err;
 			} else if (tdb_delete(tdb_ctx, key))
 					goto err;
+			/*
+			 * called by:
+			 *   - xenstore/xenstored_core.c|1185| <<do_write>> fire_watches(conn, in, name, false);
+			 *   - xenstore/xenstored_core.c|1207| <<do_mkdir>> fire_watches(conn, in, name, false);
+			 *   - xenstore/xenstored_core.c|1334| <<do_rm>> fire_watches(conn, in, name, true);
+			 *   - xenstore/xenstored_core.c|1399| <<do_set_perms>> fire_watches(conn, in, name, false);
+			 *   - xenstore/xenstored_domain.c|214| <<destroy_domain>> fire_watches(NULL, domain, "@releaseDomain", false);
+			 *   - xenstore/xenstored_domain.c|249| <<domain_cleanup>> fire_watches(NULL, NULL, "@releaseDomain", false);
+			 *   - xenstore/xenstored_domain.c|415| <<do_introduce>> fire_watches(NULL, in, "@introduceDomain", false);
+			 *   - xenstore/xenstored_transaction.c|533| <<finalize_transaction>> fire_watches(conn, trans, i->node, false);
+			 */
 			fire_watches(conn, trans, i->node, false);
 		}
 
@@ -386,6 +585,10 @@ err:
 	return EIO;
 }
 
+/*
+ * called by:
+ *   - xenstore/xenstored_transaction.c|503| <<do_transaction_start>> talloc_set_destructor(trans, destroy_transaction);
+ */
 static int destroy_transaction(void *_transaction)
 {
 	struct transaction *trans = _transaction;
@@ -411,6 +614,13 @@ static int destroy_transaction(void *_transaction)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - xenstore/xenstored_core.c|1312| <<process_message>> trans = transaction_lookup(conn, in->hdr.msg.tx_id);
+ *   - xenstore/xenstored_transaction.c|497| <<do_transaction_start>> exists = transaction_lookup(conn, conn->next_transaction_id++);
+ *
+ * 在conn->transaction_list中寻找和id相同的transaction
+ */
 struct transaction *transaction_lookup(struct connection *conn, uint32_t id)
 {
 	struct transaction *trans;
@@ -425,6 +635,12 @@ struct transaction *transaction_lookup(struct connection *conn, uint32_t id)
 	return ERR_PTR(-ENOENT);
 }
 
+/*
+ * 在以下使用do_transaction_start():
+ *   - xenstore/xenstored_core.c|1276| <<global>> [XS_TRANSACTION_START] = { "TRANSACTION_START", do_transaction_start },
+ *
+ * struct transaction里没有tdb
+ */
 int do_transaction_start(struct connection *conn, struct buffered_data *in)
 {
 	struct transaction *trans, *exists;
@@ -445,6 +661,17 @@ int do_transaction_start(struct connection *conn, struct buffered_data *in)
 	INIT_LIST_HEAD(&trans->accessed);
 	INIT_LIST_HEAD(&trans->changed_domains);
 	trans->fail = false;
+	/*
+	 * 在以下使用transaction->generation:
+	 *   - xenstore/xenstored_transaction.c|184| <<transaction_get_node_name>> return talloc_asprintf(ctx, "%"PRIu64"/%s", trans->generation, name);
+	 *   - xenstore/xenstored_transaction.c|448| <<do_transaction_start>> trans->generation = generation++;
+	 *   - xenstore/xenstored_transaction.c|588| <<check_transactions>> trans->generation);
+	 *
+	 * 在以下使用全局的generation:
+	 *   - xenstore/xenstored_transaction.c|298| <<access_node>> node->generation = generation++;
+	 *   - xenstore/xenstored_transaction.c|430| <<finalize_transaction>> hdr->generation = generation++;
+	 *   - xenstore/xenstored_transaction.c|537| <<do_transaction_start>> trans->generation = generation++;
+	 */
 	trans->generation = generation++;
 
 	/* Pick an unused transaction identifier. */
@@ -455,9 +682,29 @@ int do_transaction_start(struct connection *conn, struct buffered_data *in)
 
 	/* Now we own it. */
 	list_add_tail(&trans->list, &conn->transaction_list);
+	/*
+	 * move a lump of memory from one talloc context to another return the
+	 * ptr on success, or NULL if it could not be transferred.
+	 * passing NULL as ptr will always return NULL with no side effects
+	 */
 	talloc_steal(conn, trans);
 	talloc_set_destructor(trans, destroy_transaction);
+	/*
+	 * 在以下使用connection->transaction_started:
+	 *   - xenstore/xenstored_core.c|1431| <<new_connection>> new->transaction_started = 0;
+	 *   - xenstore/xenstored_transaction.c|548| <<do_transaction_start>> if (conn->id && conn->transaction_started > quota_max_transaction)
+	 *   - xenstore/xenstored_transaction.c|571| <<do_transaction_start>> conn->transaction_started++;
+	 *   - xenstore/xenstored_transaction.c|617| <<do_transaction_end>> conn->transaction_started--;
+	 *   - xenstore/xenstored_transaction.c|719| <<conn_delete_all_transactions>> conn->transaction_started = 0;
+	 */
 	conn->transaction_started++;
+	/*
+	 * 在以下使用wrl_ntransactions:
+	 *   - xenstore/xenstored_domain.c|972| <<wrl_apply_debit_direct>> if (!wrl_ntransactions)
+	 *   - xenstore/xenstored_domain.c|981| <<wrl_apply_debit_trans_commit>> if (wrl_ntransactions <= 1)
+	 *   - xenstore/xenstored_transaction.c|496| <<destroy_transaction>> wrl_ntransactions--;
+	 *   - xenstore/xenstored_transaction.c|572| <<do_transaction_start>> wrl_ntransactions++;
+	 */
 	wrl_ntransactions++;
 
 	snprintf(id_str, sizeof(id_str), "%u", trans->id);
@@ -466,11 +713,25 @@ int do_transaction_start(struct connection *conn, struct buffered_data *in)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - xenstore/xenstored_transaction.c|505| <<do_transaction_end>> ret = transaction_fix_domains(trans, false);
+ *   - xenstore/xenstored_transaction.c|514| <<do_transaction_end>> transaction_fix_domains(trans, true);
+ */
 static int transaction_fix_domains(struct transaction *trans, bool update)
 {
 	struct changed_domain *d;
 	int cnt;
 
+	/*
+	 * 在以下使用transaction->changed_domains:
+	 *   - xenstore/xenstored_transaction.c|446| <<do_transaction_start>> INIT_LIST_HEAD(&trans->changed_domains);
+	 *   - xenstore/xenstored_transaction.c|474| <<transaction_fix_domains>> list_for_each_entry(d, &trans->changed_domains, list) {
+	 *   - xenstore/xenstored_transaction.c|525| <<transaction_entry_inc>> list_for_each_entry(d, &trans->changed_domains, list)
+	 *   - xenstore/xenstored_transaction.c|539| <<transaction_entry_inc>> list_add_tail(&d->list, &trans->changed_domains);
+	 *   - xenstore/xenstored_transaction.c|546| <<transaction_entry_dec>> list_for_each_entry(d, &trans->changed_domains, list)
+	 *   - xenstore/xenstored_transaction.c|560| <<transaction_entry_dec>> list_add_tail(&d->list, &trans->changed_domains);
+	 */
 	list_for_each_entry(d, &trans->changed_domains, list) {
 		cnt = domain_entry_fix(d->domid, d->nbentry, update);
 		if (!update && cnt >= quota_nb_entry_per_domain)
@@ -480,6 +741,10 @@ static int transaction_fix_domains(struct transaction *trans, bool update)
 	return 0;
 }
 
+/*
+ * 在以下使用do_transaction_end():
+ *   - xenstore/xenstored_core.c|1277| <<global>> [XS_TRANSACTION_END] = { "TRANSACTION_END", do_transaction_end },
+ */
 int do_transaction_end(struct connection *conn, struct buffered_data *in)
 {
 	const char *arg = onearg(in);
@@ -494,9 +759,22 @@ int do_transaction_end(struct connection *conn, struct buffered_data *in)
 
 	conn->transaction = NULL;
 	list_del(&trans->list);
+	/*
+	 * 在以下使用connection->transaction_started:
+	 *   - xenstore/xenstored_core.c|1431| <<new_connection>> new->transaction_started = 0;
+	 *   - xenstore/xenstored_transaction.c|548| <<do_transaction_start>> if (conn->id && conn->transaction_started > quota_max_transaction)
+	 *   - xenstore/xenstored_transaction.c|571| <<do_transaction_start>> conn->transaction_started++;
+	 *   - xenstore/xenstored_transaction.c|617| <<do_transaction_end>> conn->transaction_started--;
+	 *   - xenstore/xenstored_transaction.c|719| <<conn_delete_all_transactions>> conn->transaction_started = 0;
+	 */
 	conn->transaction_started--;
 
 	/* Attach transaction to in for auto-cleanup */
+	/*
+	 * move a lump of memory from one talloc context to another return the
+	 * ptr on success, or NULL if it could not be transferred.
+	 * passing NULL as ptr will always return NULL with no side effects.
+	 */
 	talloc_steal(in, trans);
 
 	if (streq(arg, "T")) {
@@ -505,6 +783,15 @@ int do_transaction_end(struct connection *conn, struct buffered_data *in)
 		ret = transaction_fix_domains(trans, false);
 		if (ret)
 			return ret;
+		/*
+		 * Finalize transaction:
+		 * Walk through accessed nodes and check generation against global data.
+		 * If all entries match, read the transaction entries and write them without
+		 * transaction prepended. Delete all transaction specific nodes in the data
+		 * base.
+		 *
+		 * 只在这里被调用
+		 */
 		if (finalize_transaction(conn, trans))
 			return EAGAIN;
 
@@ -518,6 +805,11 @@ int do_transaction_end(struct connection *conn, struct buffered_data *in)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - xenstore/xenstored_domain.c|670| <<domain_entry_inc>> transaction_entry_inc(conn->transaction,
+ *   - xenstore/xenstored_domain.c|679| <<domain_entry_inc>> transaction_entry_inc(conn->transaction,
+ */
 void transaction_entry_inc(struct transaction *trans, unsigned int domid)
 {
 	struct changed_domain *d;
@@ -539,6 +831,11 @@ void transaction_entry_inc(struct transaction *trans, unsigned int domid)
 	list_add_tail(&d->list, &trans->changed_domains);
 }
 
+/*
+ * called by:
+ *   - xenstore/xenstored_domain.c|696| <<domain_entry_dec>> transaction_entry_dec(conn->transaction,
+ *   - xenstore/xenstored_domain.c|705| <<domain_entry_dec>> transaction_entry_dec(conn->transaction,
+ */
 void transaction_entry_dec(struct transaction *trans, unsigned int domid)
 {
 	struct changed_domain *d;
@@ -560,6 +857,11 @@ void transaction_entry_dec(struct transaction *trans, unsigned int domid)
 	list_add_tail(&d->list, &trans->changed_domains);
 }
 
+/*
+ * called by:
+ *   - xenstore/xenstored_domain.c|358| <<domain_conn_reset>> conn_delete_all_transactions(conn);
+ *   - xenstore/xenstored_domain.c|568| <<do_reset_watches>> conn_delete_all_transactions(conn);
+ */
 void conn_delete_all_transactions(struct connection *conn)
 {
 	struct transaction *trans;
@@ -575,6 +877,10 @@ void conn_delete_all_transactions(struct connection *conn)
 	conn->transaction_started = 0;
 }
 
+/*
+ * called by:
+ *   - xenstore/xenstored_core.c|1765| <<check_store>> !check_transactions(reachable))
+ */
 int check_transactions(struct hashtable *hash)
 {
 	struct connection *conn;
diff --git a/tools/xenstore/xenstored_watch.c b/tools/xenstore/xenstored_watch.c
index 0dc5a40..74fc835 100644
--- a/tools/xenstore/xenstored_watch.c
+++ b/tools/xenstore/xenstored_watch.c
@@ -123,6 +123,17 @@ static void add_event(struct connection *conn,
  * Check whether any watch events are to be sent.
  * Temporary memory allocations are done with ctx.
  */
+/*
+ * called by:
+ *   - xenstore/xenstored_core.c|1185| <<do_write>> fire_watches(conn, in, name, false);
+ *   - xenstore/xenstored_core.c|1207| <<do_mkdir>> fire_watches(conn, in, name, false);
+ *   - xenstore/xenstored_core.c|1334| <<do_rm>> fire_watches(conn, in, name, true);
+ *   - xenstore/xenstored_core.c|1399| <<do_set_perms>> fire_watches(conn, in, name, false);
+ *   - xenstore/xenstored_domain.c|214| <<destroy_domain>> fire_watches(NULL, domain, "@releaseDomain", false);
+ *   - xenstore/xenstored_domain.c|249| <<domain_cleanup>> fire_watches(NULL, NULL, "@releaseDomain", false);
+ *   - xenstore/xenstored_domain.c|415| <<do_introduce>> fire_watches(NULL, in, "@introduceDomain", false);
+ *   - xenstore/xenstored_transaction.c|533| <<finalize_transaction>> fire_watches(conn, trans, i->node, false);
+ */
 void fire_watches(struct connection *conn, void *ctx, const char *name,
 		  bool recurse)
 {
diff --git a/tools/xenstore/xs_tdb_dump.c b/tools/xenstore/xs_tdb_dump.c
index 207ed44..bb14d0e 100644
--- a/tools/xenstore/xs_tdb_dump.c
+++ b/tools/xenstore/xs_tdb_dump.c
@@ -43,6 +43,11 @@ int main(int argc, char *argv[])
 	if (argc != 2)
 		barf("Usage: xs_tdb_dump <tdbfile>");
 
+	/*
+	 * called by:
+	 *   - xenstore/xenstored_core.c|1709| <<setup_structure>> tdb_ctx = tdb_open_ex(tdbname, 7919, tdb_flags, O_RDWR|O_CREAT|O_EXCL,
+	 *   - xenstore/xs_tdb_dump.c|46| <<main>> tdb = tdb_open_ex(talloc_strdup(NULL, argv[1]), 0, 0, O_RDONLY, 0,
+	 */
 	tdb = tdb_open_ex(talloc_strdup(NULL, argv[1]), 0, 0, O_RDONLY, 0,
 			  &tdb_logger, NULL);
 	if (!tdb)
diff --git a/xen/arch/x86/domain.c b/xen/arch/x86/domain.c
index 8d579e2..6f6c92c 100644
--- a/xen/arch/x86/domain.c
+++ b/xen/arch/x86/domain.c
@@ -338,6 +338,10 @@ void arch_vcpu_regs_init(struct vcpu *v)
     v->arch.dr7 = X86_DR7_DEFAULT;
 }
 
+/*
+ * called only by:
+ *   - common/domain.c|179| <<vcpu_create>> if ( arch_vcpu_create(v) != 0 )
+ */
 int arch_vcpu_create(struct vcpu *v)
 {
     struct domain *d = v->domain;
diff --git a/xen/arch/x86/emul-i8254.c b/xen/arch/x86/emul-i8254.c
index 73be418..9510975 100644
--- a/xen/arch/x86/emul-i8254.c
+++ b/xen/arch/x86/emul-i8254.c
@@ -38,7 +38,17 @@
 #include <asm/hvm/vpt.h>
 #include <asm/current.h>
 
+/*
+ * https://wiki.osdev.org/Programmable_Interval_Timer
+ *
+ * 配置的入口函数handle_pit_io()
+ */
+
+/* 参数的x是struct domain */
 #define domain_vpit(x) (&(x)->arch.vpit)
+/*
+ * domain_vpit()的参数是(x)->domain, 不是x
+ */
 #define vcpu_vpit(x)   (domain_vpit((x)->domain))
 #define vpit_domain(x) (container_of((x), struct domain, arch.vpit))
 #define vpit_vcpu(x)   (pt_global_vcpu_target(vpit_domain(x)))
@@ -53,9 +63,26 @@ static int handle_pit_io(
 static int handle_speaker_io(
     int dir, unsigned int port, unsigned int bytes, uint32_t *val);
 
+/*
+ * called by:
+ *   - arch/x86/emul-i8254.c|80| <<pit_get_count>> d = muldiv64(get_guest_time(v) - pit->count_load_time[channel],
+ *   - arch/x86/emul-i8254.c|111| <<pit_get_out>> d = muldiv64(get_guest_time(v) - pit->count_load_time[channel],
+ *   - arch/x86/emul-i8254.c|158| <<pit_set_gate>> pit->count_load_time[channel] = get_guest_time(v);
+ *   - arch/x86/emul-i8254.c|180| <<pit_time_fired>> *count_load_time = get_guest_time(v);
+ *   - arch/x86/emul-i8254.c|205| <<pit_load_count>> pit->count_load_time[channel] = get_guest_time(v);
+ *   - arch/x86/emul-i8254.c|478| <<pit_load>> pit->pt0.last_plt_gtime = get_guest_time(d->vcpu[0]);
+ */
 #define get_guest_time(v) \
    (is_hvm_vcpu(v) ? hvm_get_guest_time(v) : (u64)get_s_time())
 
+/*
+ * used by:
+ *   - arch/x86/emul-i8254.c|226| <<pit_latch_count>> c->latched_count = pit_get_count(pit, channel);
+ *   - arch/x86/emul-i8254.c|369| <<pit_ioport_read>> count = pit_get_count(pit, addr);
+ *   - arch/x86/emul-i8254.c|373| <<pit_ioport_read>> count = pit_get_count(pit, addr);
+ *   - arch/x86/emul-i8254.c|377| <<pit_ioport_read>> count = pit_get_count(pit, addr);
+ *   - arch/x86/emul-i8254.c|382| <<pit_ioport_read>> count = pit_get_count(pit, addr);
+ */
 static int pit_get_count(PITState *pit, int channel)
 {
     uint64_t d;
@@ -87,6 +114,11 @@ static int pit_get_count(PITState *pit, int channel)
     return counter;
 }
 
+/*
+ * called by:
+ *   - arch/x86/emul-i8254.c|266| <<pit_latch_status>> c->status = ((pit_get_out(pit, channel) << 7) |
+ *   - arch/x86/emul-i8254.c|630| <<speaker_ioport_read>> (pit_get_out(pit, 2) << 5) | (refresh_clock << 4));
+ */
 static int pit_get_out(PITState *pit, int channel)
 {
     struct hvm_hw_pit_channel *s = &pit->hw.channels[channel];
@@ -156,6 +188,11 @@ static int pit_get_gate(PITState *pit, int channel)
     return pit->hw.channels[channel].gate;
 }
 
+/*
+ * 调用的地方:
+ *   - arch/x86/hvm/vpt.c|566| <<pt_update_irq>> cb(v, cb_priv);
+ *   - arch/x86/hvm/vpt.c|628| <<pt_intr_post>> cb(v, cb_priv);
+ */
 static void pit_time_fired(struct vcpu *v, void *priv)
 {
     uint64_t *count_load_time = priv;
@@ -163,6 +200,16 @@ static void pit_time_fired(struct vcpu *v, void *priv)
     *count_load_time = get_guest_time(v);
 }
 
+/*
+ * called by:
+ *   - arch/x86/emul-i8254.c|302| <<pit_ioport_write>> pit_load_count(pit, addr, val);
+ *   - arch/x86/emul-i8254.c|305| <<pit_ioport_write>> pit_load_count(pit, addr, val << 8);
+ *   - arch/x86/emul-i8254.c|312| <<pit_ioport_write>> pit_load_count(pit, addr, s->write_latch | (val << 8));
+ *   - arch/x86/emul-i8254.c|439| <<pit_load>> pit_load_count(pit, i, pit->hw.channels[i].count);
+ *   - arch/x86/emul-i8254.c|477| <<pit_reset>> pit_load_count(pit, i, 0);
+ *
+ * 在pit_ioport_write()中只被pit_ioport_write()的0x40, 0x41和0x42三个port调用
+ */
 static void pit_load_count(PITState *pit, int channel, int val)
 {
     u32 period;
@@ -207,6 +254,11 @@ static void pit_load_count(PITState *pit, int channel, int val)
     }
 }
 
+/*
+ * called by:
+ *   - arch/x86/emul-i8254.c|304| <<pit_ioport_write>> pit_latch_count(pit, channel);
+ *   - arch/x86/emul-i8254.c|317| <<pit_ioport_write>> pit_latch_count(pit, channel);
+ */
 static void pit_latch_count(PITState *pit, int channel)
 {
     struct hvm_hw_pit_channel *c = &pit->hw.channels[channel];
@@ -220,6 +272,10 @@ static void pit_latch_count(PITState *pit, int channel)
     }
 }
 
+/*
+ * called by:
+ *   - arch/x86/emul-i8254.c|306| <<pit_ioport_write>> pit_latch_status(pit, channel);
+ */
 static void pit_latch_status(PITState *pit, int channel)
 {
     struct hvm_hw_pit_channel *c = &pit->hw.channels[channel];
@@ -237,12 +293,34 @@ static void pit_latch_status(PITState *pit, int channel)
     }
 }
 
+/*
+ * called by:
+ *   - arch/x86/emul-i8254.c|521| <<handle_pit_io>> pit_ioport_write(vpit, port, *val);
+ */
+/*
+ * called by:
+ *   - arch/x86/emul-i8254.c|575| <<handle_pit_io>> pit_ioport_write(vpit, port, *val);
+ *
+ * 参数addr就是port:
+ * 0x40   Channel 0 data port (read/write)
+ * 0x41   Channel 1 data port (read/write)
+ * 0x42   Channel 2 data port (read/write)
+ * 0x43   Mode/Command register (write only, a read is ignored)
+ */
 static void pit_ioport_write(struct PITState *pit, uint32_t addr, uint32_t val)
 {
     int channel, access;
     struct hvm_hw_pit_channel *s;
 
     val  &= 0xff;
+    /*
+     * 0x40 = 1000000
+     * 0x41 = 1000001
+     * 0x42 = 1000010
+     * 0x43 = 1000011
+     *
+     * 0x03 = 11
+     */
     addr &= 3;
 
     spin_lock(&pit->lock);
@@ -295,6 +373,9 @@ static void pit_ioport_write(struct PITState *pit, uint32_t addr, uint32_t val)
         {
         default:
         case RW_STATE_LSB:
+            /*
+	     * 在pit_ioport_write()中只被pit_ioport_write()的0x40, 0x41和0x42三个port调用
+	     */
             pit_load_count(pit, addr, val);
             break;
         case RW_STATE_MSB:
@@ -314,6 +395,10 @@ static void pit_ioport_write(struct PITState *pit, uint32_t addr, uint32_t val)
     spin_unlock(&pit->lock);
 }
 
+/*
+ * called by:
+ *   - arch/x86/emul-i8254.c|580| <<handle_pit_io>> *val = pit_ioport_read(vpit, port);
+ */
 static uint32_t pit_ioport_read(struct PITState *pit, uint32_t addr)
 {
     int ret, count;
@@ -391,6 +476,10 @@ void pit_stop_channel0_irq(PITState *pit)
     spin_unlock(&pit->lock);
 }
 
+/*
+ * used by:
+ *   - arch/x86/emul-i8254.c|466| <<global>> HVM_REGISTER_SAVE_RESTORE(PIT, pit_save, pit_load, 1, HVMSR_PER_DOM);
+ */
 static int pit_save(struct vcpu *v, hvm_domain_context_t *h)
 {
     struct domain *d = v->domain;
@@ -409,6 +498,10 @@ static int pit_save(struct vcpu *v, hvm_domain_context_t *h)
     return rc;
 }
 
+/*
+ * used by:
+ *   - arch/x86/emul-i8254.c|466| <<global>> HVM_REGISTER_SAVE_RESTORE(PIT, pit_save, pit_load, 1, HVMSR_PER_DOM);
+ */
 static int pit_load(struct domain *d, hvm_domain_context_t *h)
 {
     PITState *pit = domain_vpit(d);
@@ -442,6 +535,11 @@ static int pit_load(struct domain *d, hvm_domain_context_t *h)
 HVM_REGISTER_SAVE_RESTORE(PIT, pit_save, pit_load, 1, HVMSR_PER_DOM);
 #endif
 
+/*
+ * called by:
+ *   - arch/x86/emul-i8254.c|489| <<pit_init>> pit_reset(d);
+ *   - arch/x86/hvm/hvm.c|3953| <<hvm_s3_suspend>> pit_reset(d);
+ */
 void pit_reset(struct domain *d)
 {
     PITState *pit = domain_vpit(d);
@@ -471,8 +569,15 @@ void pit_reset(struct domain *d)
     spin_unlock(&pit->lock);
 }
 
+/*
+ * called by only:
+ *   - arch/x86/domain.c|612| <<arch_domain_create>> pit_init(d, cpu_khz);
+ */
 void pit_init(struct domain *d, unsigned long cpu_khz)
 {
+    /*
+     * domain->arch.vpit
+     */
     PITState *pit = domain_vpit(d);
 
     if ( !has_vpit(d) )
@@ -489,6 +594,10 @@ void pit_init(struct domain *d, unsigned long cpu_khz)
     pit_reset(d);
 }
 
+/*
+ * called by:
+ *   - arch/x86/domain.c|2102| <<domain_relinquish_resources>> pit_deinit(d);
+ */
 void pit_deinit(struct domain *d)
 {
     PITState *pit = domain_vpit(d);
@@ -504,11 +613,25 @@ void pit_deinit(struct domain *d)
 }
 
 /* the intercept action for PIT DM retval:0--not handled; 1--handled */  
+/*
+ * used by:
+ *   - arch/x86/emul-i8254.c|498| <<pit_init>> register_portio_handler(d, PIT_BASE, 4, handle_pit_io);
+ *   - arch/x86/emul-i8254.c|605| <<pv_pit_handler>> handle_pit_io(ioreq.dir, port, 1, &val);
+ *
+ * 参数dir: IOREQ_WRITE或者IOREQ_READ
+ *
+ * 参数port:
+ * 0x40   Channel 0 data port (read/write)
+ * 0x41   Channel 1 data port (read/write)
+ * 0x42   Channel 2 data port (read/write)
+ * 0x43   Mode/Command register (write only, a read is ignored)
+ */
 static int handle_pit_io(
     int dir, unsigned int port, unsigned int bytes, uint32_t *val)
 {
     struct PITState *vpit = vcpu_vpit(current);
 
+    /* 只在这里用到了参数的bytes */
     if ( bytes != 1 )
     {
         gdprintk(XENLOG_WARNING, "PIT bad access\n");
@@ -531,6 +654,10 @@ static int handle_pit_io(
     return X86EMUL_OKAY;
 }
 
+/*
+ * called by:
+ *   - arch/x86/emul-i8254.c|614| <<handle_speaker_io>> speaker_ioport_write(vpit, port, *val);
+ */
 static void speaker_ioport_write(
     struct PITState *pit, uint32_t addr, uint32_t val)
 {
@@ -538,6 +665,10 @@ static void speaker_ioport_write(
     pit_set_gate(pit, 2, val & 1);
 }
 
+/*
+ * called by only:
+ *   - arch/x86/emul-i8254.c|616| <<handle_speaker_io>> *val = speaker_ioport_read(vpit, port);
+ */
 static uint32_t speaker_ioport_read(
     struct PITState *pit, uint32_t addr)
 {
@@ -547,6 +678,11 @@ static uint32_t speaker_ioport_read(
             (pit_get_out(pit, 2) << 5) | (refresh_clock << 4));
 }
 
+/*
+ * used by:
+ *   - arch/x86/emul-i8254.c|535| <<pit_init>> register_portio_handler(d, 0x61, 1, handle_speaker_io);
+ *   - arch/x86/emul-i8254.c|644| <<pv_pit_handler>> handle_speaker_io(ioreq.dir, port, 1, &val);
+ */
 static int handle_speaker_io(
     int dir, unsigned int port, uint32_t bytes, uint32_t *val)
 {
@@ -566,6 +702,11 @@ static int handle_speaker_io(
     return X86EMUL_OKAY;
 }
 
+/*
+ * called by:
+ *   - arch/x86/pv/emul-priv-op.c|237| <<guest_io_read>> sub_data = pv_pit_handler(port, 0, 0);
+ *   - arch/x86/pv/emul-priv-op.c|370| <<guest_io_write>> pv_pit_handler(port, (uint8_t)data, 1);
+ */
 int pv_pit_handler(int port, int data, int write)
 {
     ioreq_t ioreq = {
diff --git a/xen/arch/x86/hvm/hvm.c b/xen/arch/x86/hvm/hvm.c
index 8adbb61..9b2424d 100644
--- a/xen/arch/x86/hvm/hvm.c
+++ b/xen/arch/x86/hvm/hvm.c
@@ -142,6 +142,10 @@ static struct notifier_block cpu_nfb = {
     .notifier_call = cpu_callback
 };
 
+/*
+ * used by only:
+ *   - arch/x86/hvm/hvm.c|206| <<global>> presmp_initcall(hvm_enable);
+ */
 static int __init hvm_enable(void)
 {
     const struct hvm_function_table *fns = NULL;
@@ -1487,6 +1491,10 @@ static int __init hvm_register_CPU_save_and_restore(void)
 }
 __initcall(hvm_register_CPU_save_and_restore);
 
+/*
+ * called only by:
+ *   - arch/x86/domain.c|369| <<arch_vcpu_create>> rc = hvm_vcpu_initialise(v);
+ */
 int hvm_vcpu_initialise(struct vcpu *v)
 {
     int rc;
diff --git a/xen/arch/x86/hvm/vioapic.c b/xen/arch/x86/hvm/vioapic.c
index 9c25f72..fa0fb5d 100644
--- a/xen/arch/x86/hvm/vioapic.c
+++ b/xen/arch/x86/hvm/vioapic.c
@@ -375,6 +375,12 @@ static const struct hvm_mmio_ops vioapic_mmio_ops = {
     .write = vioapic_write
 };
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vioapic.c|434| <<vioapic_deliver>> ioapic_inj_irq(vioapic, target, vector, trig_mode, delivery_mode);
+ *   - arch/x86/hvm/vioapic.c|452| <<vioapic_deliver>> ioapic_inj_irq(vioapic, vcpu_vlapic(v), vector,
+ *   - arch/x86/hvm/vioapic.c|461| <<vioapic_deliver>> ioapic_inj_irq(vioapic, vcpu_vlapic(v), vector,
+ */
 static void ioapic_inj_irq(
     struct hvm_vioapic *vioapic,
     struct vlapic *target,
@@ -396,6 +402,13 @@ static inline int pit_channel0_enabled(void)
     return pt_active(&current->domain->arch.vpit.pt0);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vioapic.c|266| <<vioapic_write_redirent>> vioapic_deliver(vioapic, idx);
+ *   - arch/x86/hvm/vioapic.c|507| <<vioapic_irq_positive_edge>> vioapic_deliver(vioapic, pin);
+ *   - arch/x86/hvm/vioapic.c|512| <<vioapic_irq_positive_edge>> vioapic_deliver(vioapic, pin);
+ *   - arch/x86/hvm/vioapic.c|551| <<vioapic_update_EOI>> vioapic_deliver(vioapic, pin);
+ */
 static void vioapic_deliver(struct hvm_vioapic *vioapic, unsigned int pin)
 {
     uint16_t dest = vioapic->redirtbl[pin].fields.dest_id;
diff --git a/xen/arch/x86/hvm/vlapic.c b/xen/arch/x86/hvm/vlapic.c
index a1a43cd..af1d080 100644
--- a/xen/arch/x86/hvm/vlapic.c
+++ b/xen/arch/x86/hvm/vlapic.c
@@ -149,6 +149,17 @@ bool vlapic_test_irq(const struct vlapic *vlapic, uint8_t vec)
     return vlapic_test_vector(vec, &vlapic->regs->data[APIC_IRR]);
 }
 
+/*
+ * called by:
+ *   - arch/x86/cpu/vpmu.c|324| <<vpmu_do_interrupt>> vlapic_set_irq(vlapic, vlapic_lvtpc & APIC_VECTOR_MASK, 0);
+ *   - arch/x86/hvm/irq.c|322| <<hvm_assert_evtchn_irq>> vlapic_set_irq(vcpu_vlapic(v), vector, 0);
+ *   - arch/x86/hvm/svm/svm.c|947| <<svm_lwp_interrupt>> vlapic_set_irq(
+ *   - arch/x86/hvm/vioapic.c|391| <<ioapic_inj_irq>> vlapic_set_irq(target, vector, trig_mode);
+ *   - arch/x86/hvm/vlapic.c|135| <<vlapic_error>> vlapic_set_irq(vlapic, lvterr & APIC_VECTOR_MASK, 0);
+ *   - arch/x86/hvm/vlapic.c|352| <<vlapic_accept_irq>> vlapic_set_irq(vlapic, vector, 0);
+ *   - arch/x86/hvm/vmsi.c|58| <<vmsi_inj_irq>> vlapic_set_irq(target, vector, trig_mode);
+ *   - arch/x86/hvm/vpt.c|384| <<pt_update_irq>> vlapic_set_irq(vcpu_vlapic(v), irq, 0);
+ */
 void vlapic_set_irq(struct vlapic *vlapic, uint8_t vec, uint8_t trig)
 {
     struct vcpu *target = vlapic_vcpu(vlapic);
@@ -775,6 +786,15 @@ static void vlapic_update_timer(struct vlapic *vlapic, uint32_t lvtt,
     }
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/viridian/synic.c|88| <<viridian_synic_wrmsr>> vlapic_reg_write(v, APIC_ICR2, val >> 32);
+ *   - arch/x86/hvm/viridian/synic.c|89| <<viridian_synic_wrmsr>> vlapic_reg_write(v, APIC_ICR, val);
+ *   - arch/x86/hvm/viridian/synic.c|93| <<viridian_synic_wrmsr>> vlapic_reg_write(v, APIC_TASKPRI, val);
+ *   - arch/x86/hvm/vlapic.c|951| <<vlapic_mmio_write>> vlapic_reg_write(v, offset, val);
+ *   - arch/x86/hvm/vlapic.c|971| <<vlapic_apicv_write>> vlapic_reg_write(v, offset, val);
+ *   - arch/x86/hvm/vlapic.c|1056| <<guest_wrmsr_x2apic>> vlapic_reg_write(v, offset, msr_content);
+ */
 void vlapic_reg_write(struct vcpu *v, unsigned int reg, uint32_t val)
 {
     struct vlapic *vlapic = vcpu_vlapic(v);
@@ -1234,6 +1254,12 @@ void vlapic_tdt_msr_set(struct vlapic *vlapic, uint64_t value)
                 vlapic->hw.tdt_msr, guest_tsc);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vlapic.c|1290| <<vlapic_accept_pic_intr>> v ? __vlapic_accept_pic_intr(v) : -1);
+ *   - arch/x86/hvm/vlapic.c|1293| <<vlapic_accept_pic_intr>> __vlapic_accept_pic_intr(v));
+ *   - arch/x86/hvm/vlapic.c|1312| <<vlapic_adjust_i8259_target>> if ( __vlapic_accept_pic_intr(v) )
+ */
 static int __vlapic_accept_pic_intr(struct vcpu *v)
 {
     struct domain *d = v->domain;
@@ -1258,6 +1284,10 @@ static int __vlapic_accept_pic_intr(struct vcpu *v)
              ((lvt0 & (APIC_MODE_MASK|APIC_LVT_MASKED)) == APIC_DM_EXTINT) ||
              /* LAPIC is fully disabled? */
              vlapic_hw_disabled(vlapic)));
+
+    /*
+     * 上面APIC_DM_EXTINT = 0x00700
+     */
 }
 
 int vlapic_accept_pic_intr(struct vcpu *v)
@@ -1273,6 +1303,14 @@ int vlapic_accept_pic_intr(struct vcpu *v)
             __vlapic_accept_pic_intr(v));
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vioapic.c|257| <<vioapic_write_redirent>> vlapic_adjust_i8259_target(d);
+ *   - arch/x86/hvm/vlapic.c|863| <<vlapic_reg_write>> vlapic_adjust_i8259_target(v->domain);
+ *   - arch/x86/hvm/vlapic.c|1573| <<lapic_load_regs>> vlapic_adjust_i8259_target(d);
+ *
+ * 目前还不明白, 这个函数控制8259的中断发到哪一个apic?
+ */
 void vlapic_adjust_i8259_target(struct domain *d)
 {
     struct vcpu *v;
@@ -1289,10 +1327,19 @@ void vlapic_adjust_i8259_target(struct domain *d)
  found:
     if ( d->arch.hvm.i8259_target == v )
         return;
+    /*
+     * hvm是struct hvm_domain
+     * i8259_target是struct vcpu
+     */
     d->arch.hvm.i8259_target = v;
     pt_adjust_global_vcpu_target(v);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/irq.c|533| <<hvm_vcpu_has_pending_irq>> vector = vlapic_has_pending_irq(v);
+ *   - arch/x86/hvm/vmx/vvmx.c|1322| <<nvmx_update_apicv>> rvi = vlapic_has_pending_irq(v);
+ */
 int vlapic_has_pending_irq(struct vcpu *v)
 {
     struct vlapic *vlapic = vcpu_vlapic(v);
@@ -1372,6 +1419,11 @@ bool_t is_vlapic_lvtpc_enabled(struct vlapic *vlapic)
 }
 
 /* Reset the VLAPIC back to its init state. */
+/*
+ * called by:
+ *   - arch/x86/hvm/vlapic.c|300| <<vlapic_init_sipi_one>> vlapic_do_init(vcpu_vlapic(target));
+ *   - arch/x86/hvm/vlapic.c|1428| <<vlapic_reset>> vlapic_do_init(vlapic);
+ */
 static void vlapic_do_init(struct vlapic *vlapic)
 {
     int i;
@@ -1413,6 +1465,12 @@ static void vlapic_do_init(struct vlapic *vlapic)
 }
 
 /* Reset the VLAPIC back to its power-on/reset state. */
+/*
+ * called by:
+ *   - arch/x86/hvm/hvm.c|3946| <<hvm_s3_suspend>> vlapic_reset(vcpu_vlapic(v));
+ *   - arch/x86/hvm/vlapic.c|1139| <<guest_wrmsr_apic_base>> vlapic_reset(vlapic);
+ *   - arch/x86/hvm/vlapic.c|1630| <<vlapic_init>> vlapic_reset(vlapic);
+ */
 void vlapic_reset(struct vlapic *vlapic)
 {
     const struct vcpu *v = vlapic_vcpu(vlapic);
@@ -1580,6 +1638,10 @@ HVM_REGISTER_SAVE_RESTORE(LAPIC, lapic_save_hidden,
 HVM_REGISTER_SAVE_RESTORE(LAPIC_REGS, lapic_save_regs,
                           lapic_load_regs, 1, HVMSR_PER_VCPU);
 
+/*
+ * called by only:
+ *   - arch/x86/hvm/hvm.c|1505| <<hvm_vcpu_initialise>> rc = vlapic_init(v);
+ */
 int vlapic_init(struct vcpu *v)
 {
     struct vlapic *vlapic = vcpu_vlapic(v);
@@ -1588,6 +1650,13 @@ int vlapic_init(struct vcpu *v)
 
     if ( !has_vlapic(v->domain) )
     {
+        /*
+	 * VLAPIC_HW_DISABLED在以下被使用:
+	 *   - arch/x86/hvm/vlapic.c|1140| <<guest_wrmsr_apic_base>> vlapic->hw.disabled &= ~VLAPIC_HW_DISABLED;
+	 *   - arch/x86/hvm/vlapic.c|1145| <<guest_wrmsr_apic_base>> vlapic->hw.disabled |= VLAPIC_HW_DISABLED;
+	 *   - arch/x86/hvm/vlapic.c|1591| <<vlapic_init>> vlapic->hw.disabled = VLAPIC_HW_DISABLED;
+	 *   - include/asm-x86/hvm/vlapic.h|48| <<vlapic_hw_disabled>> #define vlapic_hw_disabled(vlapic) ((vlapic)->hw.disabled & VLAPIC_HW_DISABLED)
+	 */
         vlapic->hw.disabled = VLAPIC_HW_DISABLED;
         return 0;
     }
diff --git a/xen/arch/x86/hvm/vmx/intr.c b/xen/arch/x86/hvm/vmx/intr.c
index 0d097cf..9fec710 100644
--- a/xen/arch/x86/hvm/vmx/intr.c
+++ b/xen/arch/x86/hvm/vmx/intr.c
@@ -226,6 +226,12 @@ static int nvmx_intr_intercept(struct vcpu *v, struct hvm_intack intack)
 
 void vmx_intr_assist(void)
 {
+    /*
+     * struct hvm_intack {
+     *     uint8_t source; // enum hvm_intsrc
+     *     uint8_t vector;
+     * };
+     */
     struct hvm_intack intack;
     struct vcpu *v = current;
     unsigned int tpr_threshold = 0;
@@ -250,6 +256,9 @@ void vmx_intr_assist(void)
     do {
         unsigned long intr_info;
 
+	/*
+	 * source是hvm_intsrc_lapic???
+	 */
         intack = hvm_vcpu_has_pending_irq(v);
         if ( likely(intack.source == hvm_intsrc_none) )
             goto out;
diff --git a/xen/arch/x86/hvm/vmx/vmcs.c b/xen/arch/x86/hvm/vmx/vmcs.c
index 74f2a08..fb85a30 100644
--- a/xen/arch/x86/hvm/vmx/vmcs.c
+++ b/xen/arch/x86/hvm/vmx/vmcs.c
@@ -42,6 +42,33 @@
 #include <asm/tboot.h>
 #include <asm/apic.h>
 
+/*
+ * 'xl debug-keys v'可以打印出所有的vmcs
+ *
+ *
+ * 3处会初始化vmcs的地方 (主要最后一处)
+ *
+ * hvm_cpu_up()
+ *  -> vmx_cpu_up()
+ *      -> _vmx_cpu_up(bool bsp) --> bsp == false
+ *          -> vmx_init_vmcs_config()
+ *
+ *
+ * presmp_initcall(hvm_enable)
+ *  -> hvm_enable()
+ *      -> start_vmx()
+ *          -> _vmx_cpu_up() --> bsp == true
+ *              -> vmx_init_vmcs_config()
+ *
+ *
+ * vcpu_create(vcpu_id)
+ *  -> arch_vcpu_create(vcpu)
+ *      -> hvm_vcpu_initialise(vcpu)
+ *          -> vmx_function_table.vcpu_initialise = vmx_vcpu_initialise(vcpu)
+ *              -> vmx_create_vmcs(vcpu)
+ *                  -> construct_vmcs()
+ */
+
 static bool_t __read_mostly opt_vpid_enabled = 1;
 boolean_param("vpid", opt_vpid_enabled);
 
@@ -166,6 +193,10 @@ static bool_t cap_check(const char *name, u32 expected, u32 saw)
     return saw != expected;
 }
 
+/*
+ * calle by only:
+ *   - arch/x86/hvm/vmx/vmcs.c|645| <<_vmx_cpu_up>> if ( (rc = vmx_init_vmcs_config()) != 0 )
+ */
 static int vmx_init_vmcs_config(void)
 {
     u32 vmx_basic_msr_low, vmx_basic_msr_high, min, opt;
@@ -598,6 +629,30 @@ void vmx_cpu_dead(unsigned int cpu)
     vmx_pi_desc_fixup(cpu);
 }
 
+/*
+ * 在测试机上有4个cpu, 第0个(bsp=true)和其他3个不一样
+ *
+ * 在CPU 0上执行
+ * [0] _vmx_cpu_up
+ * [0] smp_send_call_function_mask
+ * [0] on_selected_cpus
+ * [0] mwait-idle.c#mwait_idle_cpu_init
+ * [0] start_vmx
+ * [0] hvm.c#hvm_enable
+ * [0] do_presmp_initcalls
+ * [0] __start_xen
+ * [0] __high_start
+ *
+ * 在剩下的3个非bsp的cpu分别执行
+ * [0] _vmx_cpu_up
+ * [0] alloc_direct_apic_vector
+ * [0] intel_mcheck_init
+ * [0] start_secondary
+ *
+ * called by:
+ *   - arch/x86/hvm/vmx/vmcs.c|697| <<vmx_cpu_up>> return _vmx_cpu_up(false);
+ *   - arch/x86/hvm/vmx/vmx.c|2446| <<start_vmx>> if ( _vmx_cpu_up(true) )
+ */
 int _vmx_cpu_up(bool bsp)
 {
     u32 eax, edx;
@@ -688,6 +743,13 @@ int _vmx_cpu_up(bool bsp)
     return 0;
 }
 
+/*
+ * called by:
+ *   - arch/arm/platform.c|104| <<platform_cpu_up>> return platform->cpu_up(cpu);
+ *   - include/asm-x86/hvm/hvm.h|530| <<hvm_cpu_up>> return (hvm_funcs.cpu_up ? hvm_funcs.cpu_up() : 0);
+ *
+ * struct hvm_function_table vmx_function_table.cpu_up = vmx_cpu_up()
+ */
 int vmx_cpu_up()
 {
     return _vmx_cpu_up(false);
@@ -981,6 +1043,21 @@ static void pi_desc_init(struct vcpu *v)
     v->arch.hvm.vmx.pi_desc.ndst = APIC_INVALID_DEST;
 }
 
+/*
+ * 对于2个vcpu的hvm, 被调用两次
+ *
+ * [0] vmx_create_vmcs
+ * [0] vmx.c#vmx_vcpu_initialise
+ * [0] vlapic_init
+ * [0] hvm_vcpu_initialise
+ * [0] vcpu_init_fpu
+ * [0] arch_vcpu_create
+ * [0] vcpu_create
+ * [0] do_domctl
+ *
+ * called by only:
+ *   - arch/x86/hvm/vmx/vmcs.c|1781| <<vmx_create_vmcs>> if ( (rc = construct_vmcs(v)) != 0 )
+ */
 static int construct_vmcs(struct vcpu *v)
 {
     struct domain *d = v->domain;
@@ -1019,6 +1096,14 @@ static int construct_vmcs(struct vcpu *v)
 
     if ( paging_mode_hap(d) )
     {
+        /*
+	 * hap一般hvm下都是打开的!
+	 */
+
+        /*
+         * 这里取消了invlpg和cr3的访问,
+	 * 所以调用invlpg和访问cr3就不会trap了
+         */
         v->arch.hvm.vmx.exec_control &= ~(CPU_BASED_INVLPG_EXITING |
                                           CPU_BASED_CR3_LOAD_EXITING |
                                           CPU_BASED_CR3_STORE_EXITING);
@@ -1726,6 +1811,10 @@ void vmx_domain_update_eptp(struct domain *d)
     ept_sync_domain(p2m);
 }
 
+/*
+ * called only by:
+ *   - arch/x86/hvm/vmx/vmx.c|434| <<vmx_vcpu_initialise>> if ( (rc = vmx_create_vmcs(v)) != 0 )
+ */
 int vmx_create_vmcs(struct vcpu *v)
 {
     struct vmx_vcpu *vmx = &v->arch.hvm.vmx;
diff --git a/xen/arch/x86/hvm/vmx/vmx.c b/xen/arch/x86/hvm/vmx/vmx.c
index 725dd88..989b6a6 100644
--- a/xen/arch/x86/hvm/vmx/vmx.c
+++ b/xen/arch/x86/hvm/vmx/vmx.c
@@ -421,6 +421,13 @@ static void vmx_domain_destroy(struct domain *d)
     vmx_free_vlapic_mapping(d);
 }
 
+/*
+ * struct hvm_function_table vmx_function_table.vcpu_initialise = vmx_vcpu_initialise()
+ *
+ * called by:
+ *   - arch/arm/processor.c|39| <<processor_vcpu_initialise>> this_cpu(processor)->vcpu_initialise(v);
+ *   - arch/x86/hvm/hvm.c|1513| <<hvm_vcpu_initialise>> if ( (rc = hvm_funcs.vcpu_initialise(v)) != 0 )
+ */
 static int vmx_vcpu_initialise(struct vcpu *v)
 {
     int rc;
@@ -2439,6 +2446,10 @@ static void pi_notification_interrupt(struct cpu_user_regs *regs)
 static void __init lbr_tsx_fixup_check(void);
 static void __init bdw_erratum_bdf14_fixup_check(void);
 
+/*
+ * called by:
+ *   - arch/x86/hvm/hvm.c|150| <<hvm_enable>> fns = start_vmx();
+ */
 const struct hvm_function_table * __init start_vmx(void)
 {
     set_in_cr4(X86_CR4_VMXE);
diff --git a/xen/arch/x86/hvm/vpic.c b/xen/arch/x86/hvm/vpic.c
index 3f3fb7a..6eec184 100644
--- a/xen/arch/x86/hvm/vpic.c
+++ b/xen/arch/x86/hvm/vpic.c
@@ -61,6 +61,12 @@ static int vpic_get_priority(struct hvm_hw_vpic *vpic, uint8_t mask)
 }
 
 /* Return the PIC's highest priority pending interrupt. Return -1 if none. */
+/*
+ * called by:
+ *   - arch/x86/hvm/vpic.c|101| <<vpic_update_int_output>> irq = vpic_get_highest_priority_irq(vpic);
+ *   - arch/x86/hvm/vpic.c|166| <<vpic_intack>> irq = vpic_get_highest_priority_irq(vpic);
+ *   - arch/x86/hvm/vpic.c|173| <<vpic_intack>> irq = vpic_get_highest_priority_irq(vpic);
+ */
 static int vpic_get_highest_priority_irq(struct hvm_hw_vpic *vpic)
 {
     int cur_priority, priority, irq;
@@ -92,6 +98,16 @@ static int vpic_get_highest_priority_irq(struct hvm_hw_vpic *vpic)
     return (priority < cur_priority) ? irq : -1;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpic.c|127| <<vpic_update_int_output>> vpic_update_int_output(vpic);
+ *   - arch/x86/hvm/vpic.c|134| <<vpic_update_int_output>> vpic_update_int_output(vpic);
+ *   - arch/x86/hvm/vpic.c|154| <<__vpic_intack>> vpic_update_int_output(vpic);
+ *   - arch/x86/hvm/vpic.c|261| <<vpic_ioport_write>> vpic_update_int_output(vpic);
+ *   - arch/x86/hvm/vpic.c|304| <<vpic_ioport_write>> vpic_update_int_output(vpic);
+ *   - arch/x86/hvm/vpic.c|464| <<vpic_irq_positive_edge>> vpic_update_int_output(vpic);
+ *   - arch/x86/hvm/vpic.c|482| <<vpic_irq_negative_edge>> vpic_update_int_output(vpic);
+ */
 static void vpic_update_int_output(struct hvm_hw_vpic *vpic)
 {
     int irq;
@@ -154,6 +170,11 @@ static void __vpic_intack(struct hvm_hw_vpic *vpic, int irq)
     vpic_update_int_output(vpic);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpic.c|317| <<vpic_ioport_read>> return vpic_intack(vpic);
+ *   - arch/x86/hvm/vpic.c|497| <<vpic_ack_pending_irq>> irq = vpic_intack(vpic);
+ */
 static int vpic_intack(struct hvm_hw_vpic *vpic)
 {
     int irq = -1;
@@ -335,6 +356,11 @@ static int vpic_intercept_pic_io(
         return X86EMUL_OKAY;
     }
 
+    /*
+     * vpic的声明:
+     *
+     * struct hvm_hw_vpic     vpic[2];
+     */
     vpic = &current->domain->arch.hvm.vpic[port >> 7];
 
     if ( dir == IOREQ_WRITE )
diff --git a/xen/arch/x86/hvm/vpt.c b/xen/arch/x86/hvm/vpt.c
index ecd25d7..5cab502 100644
--- a/xen/arch/x86/hvm/vpt.c
+++ b/xen/arch/x86/hvm/vpt.c
@@ -23,18 +23,70 @@
 #include <asm/apic.h>
 #include <asm/mc146818rtc.h>
 
+/*
+ * used by:
+ *   - arch/x86/hvm/vpt.c|201| <<pt_process_missed_ticks>> if ( mode_is(pt->vcpu->domain, no_missed_ticks_pending) )
+ *   - arch/x86/hvm/vpt.c|210| <<pt_freeze_time>> if ( !mode_is(v->domain, delay_for_missed_ticks) )
+ *   - arch/x86/hvm/vpt.c|218| <<pt_thaw_time>> if ( !mode_is(v->domain, delay_for_missed_ticks) )
+ *   - arch/x86/hvm/vpt.c|299| <<pt_irq_fired>> else if ( mode_is(v->domain, one_missed_tick_pending) ||
+ *   - arch/x86/hvm/vpt.c|300| <<pt_irq_fired>> mode_is(v->domain, no_missed_ticks_pending) )
+ *   - arch/x86/hvm/vpt.c|318| <<pt_irq_fired>> if ( mode_is(v->domain, delay_for_missed_ticks) &&
+ *
+ * #define HVM_PARAM_TIMER_MODE   10
+ *
+ * #define HVMPTM_delay_for_missed_ticks    0
+ *   Do not advance a vcpu's time beyond the correct delivery time for
+ *   interrupts that have been missed due to preemption. Deliver missed
+ *   interrupts when the vcpu is rescheduled and advance the vcpu's virtual
+ *   time stepwise for each one.
+ *
+ * #define HVMPTM_no_delay_for_missed_ticks 1
+ *   As above, missed interrupts are delivered, but guest time always tracks
+ *   wallclock (i.e., real) time while doing so.
+ *
+ * #define HVMPTM_no_missed_ticks_pending   2
+ *   No missed interrupts are held pending. Instead, to ensure ticks are
+ *   delivered at some non-zero rate, if we detect missed ticks then the
+ *   internal tick alarm is not disabled if the VCPU is preempted during the
+ *   next tick period.
+ *
+ * #define HVMPTM_one_missed_tick_pending   3
+ *   Missed interrupts are collapsed together and delivered as one 'late tick'.
+ *   Guest time always tracks wallclock (i.e., real) time.
+ */
 #define mode_is(d, name) \
     ((d)->arch.hvm.params[HVM_PARAM_TIMER_MODE] == HVMPTM_##name)
 
+/*
+ * called only by:
+ *   - arch/x86/hvm/hvm.c|654| <<hvm_domain_initialise>> hvm_init_guest_time(d);
+ */
 void hvm_init_guest_time(struct domain *d)
 {
+    /*
+     * struct domain
+     *   struct arch_domain arch;
+     *     struct hvm_domain hvm;
+     *       struct pl_time *pl_time;
+     */
     struct pl_time *pl = d->arch.hvm.pl_time;
 
     spin_lock_init(&pl->pl_time_lock);
+    /*
+     * struct pl_time的stime_offset使用的地方:
+     *   - arch/x86/hvm/vpt.c|47| <<hvm_init_guest_time>> pl->stime_offset = -(u64)get_s_time();
+     *   - arch/x86/hvm/vpt.c|66| <<hvm_get_guest_time_fixed>> now = get_s_time_fixed(at_tsc) + pl->stime_offset;
+     */
     pl->stime_offset = -(u64)get_s_time();
     pl->last_guest_time = 0;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/hvm.c|412| <<hvm_set_guest_tsc_fixed>> tsc = hvm_get_guest_time_fixed(v, at_tsc);
+ *   - arch/x86/hvm/hvm.c|451| <<hvm_get_guest_tsc_fixed>> tsc = hvm_get_guest_time_fixed(v, at_tsc);
+ *   - include/asm-x86/hvm/hvm.h|357| <<hvm_get_guest_time>> #define hvm_get_guest_time(v) hvm_get_guest_time_fixed(v, 0)
+ */
 uint64_t hvm_get_guest_time_fixed(const struct vcpu *v, uint64_t at_tsc)
 {
     struct pl_time *pl = v->domain->arch.hvm.pl_time;
@@ -58,6 +110,11 @@ uint64_t hvm_get_guest_time_fixed(const struct vcpu *v, uint64_t at_tsc)
     return now + v->arch.hvm.stime_offset;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpt.c|213| <<pt_thaw_time>> hvm_set_guest_time(v, v->arch.hvm.guest_time);
+ *   - arch/x86/hvm/vpt.c|304| <<pt_irq_fired>> hvm_set_guest_time(v, pt->last_plt_gtime);
+ */
 void hvm_set_guest_time(struct vcpu *v, u64 guest_time)
 {
     u64 offset = guest_time - hvm_get_guest_time(v);
@@ -75,16 +132,35 @@ void hvm_set_guest_time(struct vcpu *v, u64 guest_time)
     }
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpt.c|427| <<is_pt_irq>> (intack.vector == pt_irq_vector(pt, intack.source)) )
+ *
+ * hvm_intsrc src有以下种类:
+ * - hvm_intsrc_none,
+ * - hvm_intsrc_pic,
+ * - hvm_intsrc_lapic,
+ * - hvm_intsrc_nmi,
+ * - hvm_intsrc_mce,
+ * - hvm_intsrc_vector
+ */
 static int pt_irq_vector(struct periodic_time *pt, enum hvm_intsrc src)
 {
     struct vcpu *v = pt->vcpu;
     unsigned int gsi, isa_irq;
     int vector;
 
+    /*
+     * source的种类:
+     *   #define PTSRC_isa    1 // ISA time source
+     *   #define PTSRC_lapic  2 // LAPIC time source
+     *   #define PTSRC_ioapic 3 // IOAPIC time source
+     */
     if ( pt->source == PTSRC_lapic )
         return pt->irq;
 
     isa_irq = pt->irq;
+    /* #define hvm_isa_irq_to_gsi(isa_irq) ((isa_irq) ? : 2) */
     gsi = hvm_isa_irq_to_gsi(isa_irq);
 
     if ( src == hvm_intsrc_pic )
@@ -104,6 +180,10 @@ static int pt_irq_vector(struct periodic_time *pt, enum hvm_intsrc src)
     return vector;
 }
 
+/*
+ * called by only:
+ *   - arch/x86/hvm/vpt.c|380| <<pt_update_irq>> if ( (pt->irq != RTC_IRQ || !pt->priv) && pt_irq_masked(pt) &&
+ */
 static int pt_irq_masked(struct periodic_time *pt)
 {
     struct vcpu *v = pt->vcpu;
@@ -127,6 +207,7 @@ static int pt_irq_masked(struct periodic_time *pt)
         if ( !(pic_imr & (1 << (pt->irq & 7))) && vlapic_accept_pic_intr(v) )
             return 0;
 
+	/* #define hvm_isa_irq_to_gsi(isa_irq) ((isa_irq) ? : 2) */
         gsi = hvm_isa_irq_to_gsi(pt->irq);
     }
 
@@ -171,10 +252,20 @@ static void pt_unlock(struct periodic_time *pt)
     spin_unlock(&pt->vcpu->arch.hvm.tm_lock);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpt.c|247| <<pt_restore_timer>> pt_process_missed_ticks(pt);
+ *   - arch/x86/hvm/vpt.c|287| <<pt_irq_fired>> pt_process_missed_ticks(pt);
+ *   - arch/x86/hvm/vpt.c|296| <<pt_irq_fired>> pt_process_missed_ticks(pt);
+ */
 static void pt_process_missed_ticks(struct periodic_time *pt)
 {
     s_time_t missed_ticks, now = NOW();
 
+    /*
+     * 在以下修改:
+     *   - arch/x86/hvm/vpt.c|627| <<create_periodic_time>> pt->one_shot = !period;
+     */
     if ( pt->one_shot )
         return;
 
@@ -182,6 +273,17 @@ static void pt_process_missed_ticks(struct periodic_time *pt)
     if ( missed_ticks <= 0 )
         return;
 
+    /*
+     * periodic_time->period使用的地方:
+     *   - arch/x86/hvm/vpt.c|254| <<pt_process_missed_ticks>> missed_ticks = missed_ticks / (s_time_t) pt->period + 1;
+     *   - arch/x86/hvm/vpt.c|259| <<pt_process_missed_ticks>> pt->scheduled += missed_ticks * pt->period;
+     *   - arch/x86/hvm/vpt.c|333| <<pt_timer_fn>> pt->scheduled += pt->period;
+     *   - arch/x86/hvm/vpt.c|367| <<pt_irq_fired>> pt->last_plt_gtime += pt->period;
+     *   - arch/x86/hvm/vpt.c|424| <<pt_update_irq>> if ( (pt->last_plt_gtime + pt->period) < max_lag )
+     *   - arch/x86/hvm/vpt.c|426| <<pt_update_irq>> max_lag = pt->last_plt_gtime + pt->period;
+     *   - arch/x86/hvm/vpt.c|627| <<create_periodic_time>> pt->period = period;
+     *   - arch/x86/hvm/vpt.c|642| <<create_periodic_time>> pt->scheduled = align_timer(pt->scheduled, pt->period);
+     */
     missed_ticks = missed_ticks / (s_time_t) pt->period + 1;
     if ( mode_is(pt->vcpu->domain, no_missed_ticks_pending) )
         pt->do_not_freeze = !pt->pending_intr_nr;
@@ -190,6 +292,10 @@ static void pt_process_missed_ticks(struct periodic_time *pt)
     pt->scheduled += missed_ticks * pt->period;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpt.c|296| <<pt_save_timer>> pt_freeze_time(v);
+ */
 static void pt_freeze_time(struct vcpu *v)
 {
     if ( !mode_is(v->domain, delay_for_missed_ticks) )
@@ -198,6 +304,10 @@ static void pt_freeze_time(struct vcpu *v)
     v->arch.hvm.guest_time = hvm_get_guest_time(v);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpt.c|317| <<pt_restore_timer>> pt_thaw_time(v);
+ */
 static void pt_thaw_time(struct vcpu *v)
 {
     if ( !mode_is(v->domain, delay_for_missed_ticks) )
@@ -210,6 +320,10 @@ static void pt_thaw_time(struct vcpu *v)
     v->arch.hvm.guest_time = 0;
 }
 
+/*
+ * called by:
+ *   - arch/x86/domain.c|1741| <<context_switch>> pt_save_timer(prev);
+ */
 void pt_save_timer(struct vcpu *v)
 {
     struct list_head *head = &v->arch.hvm.tm_list;
@@ -229,6 +343,10 @@ void pt_save_timer(struct vcpu *v)
     spin_unlock(&v->arch.hvm.tm_lock);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/hvm.c|521| <<hvm_do_resume>> pt_restore_timer(v);
+ */
 void pt_restore_timer(struct vcpu *v)
 {
     struct list_head *head = &v->arch.hvm.tm_list;
@@ -250,13 +368,51 @@ void pt_restore_timer(struct vcpu *v)
     spin_unlock(&v->arch.hvm.tm_lock);
 }
 
+/*
+ * used by only:
+ *   - arch/x86/hvm/vpt.c|621| <<create_periodic_time>> init_timer(&pt->timer, pt_timer_fn, pt, v->processor);
+ */
 static void pt_timer_fn(void *data)
 {
     struct periodic_time *pt = data;
 
+    /*
+     * 参考pt_update_irq()
+     */
+
     pt_lock(pt);
 
+    /*
+     * used by:
+     *   - arch/x86/hvm/vpt.c|241| <<pt_process_missed_ticks>> pt->do_not_freeze = !pt->pending_intr_nr;
+     *   - arch/x86/hvm/vpt.c|243| <<pt_process_missed_ticks>> pt->pending_intr_nr += missed_ticks;
+     *   - arch/x86/hvm/vpt.c|295| <<pt_restore_timer>> if ( pt->pending_intr_nr == 0 )
+     *   - arch/x86/hvm/vpt.c|317| <<pt_timer_fn>> pt->pending_intr_nr++;
+     *   - arch/x86/hvm/vpt.c|340| <<pt_irq_fired>> pt->pending_intr_nr = 0;
+     *   - arch/x86/hvm/vpt.c|347| <<pt_irq_fired>> pt->pending_intr_nr = 0;
+     *   - arch/x86/hvm/vpt.c|353| <<pt_irq_fired>> if ( --pt->pending_intr_nr == 0 )
+     *   - arch/x86/hvm/vpt.c|356| <<pt_irq_fired>> if ( pt->pending_intr_nr == 0 )
+     *   - arch/x86/hvm/vpt.c|385| <<pt_update_irq>> if ( pt->pending_intr_nr )
+     *   - arch/x86/hvm/vpt.c|498| <<is_pt_irq>> if ( pt->pending_intr_nr && pt->irq_issued &&
+     *   - arch/x86/hvm/vpt.c|588| <<create_periodic_time>> pt->pending_intr_nr = 0;
+     *   - arch/x86/hvm/vpt.c|668| <<destroy_periodic_time>> pt->pending_intr_nr = 0;
+     *   - arch/x86/hvm/vpt.c|753| <<pt_resume>> if ( pt->pending_intr_nr && !pt->on_list )
+     *   - include/asm-x86/hvm/vpt.h|160| <<pt_active>> #define pt_active(pt) ((pt)->on_list || (pt)->pending_intr_nr)
+     */
     pt->pending_intr_nr++;
+    /*
+     * used by:
+     *   - arch/x86/hvm/vpt.c|235| <<pt_process_missed_ticks>> missed_ticks = now - pt->scheduled;
+     *   - arch/x86/hvm/vpt.c|244| <<pt_process_missed_ticks>> pt->scheduled += missed_ticks * pt->period;
+     *   - arch/x86/hvm/vpt.c|298| <<pt_restore_timer>> set_timer(&pt->timer, pt->scheduled);
+     *   - arch/x86/hvm/vpt.c|318| <<pt_timer_fn>> pt->scheduled += pt->period;
+     *   - arch/x86/hvm/vpt.c|348| <<pt_irq_fired>> set_timer(&pt->timer, pt->scheduled);
+     *   - arch/x86/hvm/vpt.c|357| <<pt_irq_fired>> set_timer(&pt->timer, pt->scheduled);
+     *   - arch/x86/hvm/vpt.c|607| <<create_periodic_time>> pt->scheduled = NOW() + delta;
+     *   - arch/x86/hvm/vpt.c|613| <<create_periodic_time>> pt->scheduled = align_timer(pt->scheduled, pt->period);
+     *   - arch/x86/hvm/vpt.c|623| <<create_periodic_time>> pt->scheduled += delta >> 1;
+     *   - arch/x86/hvm/vpt.c|634| <<create_periodic_time>> set_timer(&pt->timer, pt->scheduled);
+     */
     pt->scheduled += pt->period;
     pt->do_not_freeze = 0;
 
@@ -265,6 +421,11 @@ static void pt_timer_fn(void *data)
     pt_unlock(pt);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpt.c|410| <<pt_update_irq>> pt_irq_fired(v, pt);
+ *   - arch/x86/hvm/vpt.c|472| <<pt_intr_post>> pt_irq_fired(v, pt);
+ */
 static void pt_irq_fired(struct vcpu *v, struct periodic_time *pt)
 {
     pt->irq_issued = false;
@@ -287,6 +448,17 @@ static void pt_irq_fired(struct vcpu *v, struct periodic_time *pt)
     else
     {
         pt->last_plt_gtime += pt->period;
+        /*
+	 * pending_intr_nr在以下设置:
+	 *   - arch/x86/hvm/vpt.c|243| <<pt_process_missed_ticks>> pt->pending_intr_nr += missed_ticks;
+	 *   - arch/x86/hvm/vpt.c|295| <<pt_restore_timer>> if ( pt->pending_intr_nr == 0 )
+	 *   - arch/x86/hvm/vpt.c|317| <<pt_timer_fn>> pt->pending_intr_nr++;
+	 *   - arch/x86/hvm/vpt.c|340| <<pt_irq_fired>> pt->pending_intr_nr = 0;
+	 *   - arch/x86/hvm/vpt.c|347| <<pt_irq_fired>> pt->pending_intr_nr = 0;
+	 *   - arch/x86/hvm/vpt.c|353| <<pt_irq_fired>> if ( --pt->pending_intr_nr == 0 )
+	 *   - arch/x86/hvm/vpt.c|588| <<create_periodic_time>> pt->pending_intr_nr = 0;
+	 *   - arch/x86/hvm/vpt.c|668| <<destroy_periodic_time>> pt->pending_intr_nr = 0;
+	 */
         if ( --pt->pending_intr_nr == 0 )
         {
             pt_process_missed_ticks(pt);
@@ -300,6 +472,11 @@ static void pt_irq_fired(struct vcpu *v, struct periodic_time *pt)
         hvm_set_guest_time(v, pt->last_plt_gtime);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/svm/intr.c|146| <<svm_intr_assist>> pt_update_irq(v);
+ *   - arch/x86/hvm/vmx/intr.c|248| <<vmx_intr_assist>> pt_vector = pt_update_irq(v);
+ */
 int pt_update_irq(struct vcpu *v)
 {
     struct list_head *head = &v->arch.hvm.tm_list;
@@ -312,6 +489,9 @@ int pt_update_irq(struct vcpu *v)
 
     earliest_pt = NULL;
     max_lag = -1ULL;
+    /*
+     * head就是&v->arch.hvm.tm_list
+     */
     list_for_each_entry_safe ( pt, temp, head, list )
     {
         if ( pt->pending_intr_nr )
@@ -329,6 +509,13 @@ int pt_update_irq(struct vcpu *v)
             {
                 if ( (pt->last_plt_gtime + pt->period) < max_lag )
                 {
+                    /*
+		     * 在以下设置last_plt_gtime:
+		     *   - arch/x86/emul-i8254.c|465| <<pit_load>> pit->pt0.last_plt_gtime = get_guest_time(d->vcpu[0]);
+		     *   - arch/x86/hvm/vpt.c|409| <<pt_irq_fired>> pt->last_plt_gtime = hvm_get_guest_time(v);
+		     *   - arch/x86/hvm/vpt.c|416| <<pt_irq_fired>> pt->last_plt_gtime += pt->period;
+		     *   - arch/x86/hvm/vpt.c|696| <<create_periodic_time>> pt->last_plt_gtime = hvm_get_guest_time(pt->vcpu);
+		     */
                     max_lag = pt->last_plt_gtime + pt->period;
                     earliest_pt = pt;
                 }
@@ -415,9 +602,27 @@ int pt_update_irq(struct vcpu *v)
     return pt_vector;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpt.c|445| <<pt_intr_post>> pt = is_pt_irq(v, intack);
+ */
 static struct periodic_time *is_pt_irq(
     struct vcpu *v, struct hvm_intack intack)
 {
+    /*
+     * used by:
+     *   - arch/x86/domain.c|1740| <<context_switch>> if ( is_hvm_domain(prevd) && !list_empty(&prev->arch.hvm.tm_list) )
+     *   - arch/x86/hvm/hvm.c|1506| <<hvm_vcpu_initialise>> INIT_LIST_HEAD(&v->arch.hvm.tm_list);
+     *   - arch/x86/hvm/vpt.c|269| <<pt_save_timer>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|288| <<pt_restore_timer>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|373| <<pt_update_irq>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|466| <<pt_update_irq>> list_for_each_entry ( pt, &v->arch.hvm.tm_list, list )
+     *   - arch/x86/hvm/vpt.c|493| <<is_pt_irq>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|548| <<pt_migrate>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|631| <<create_periodic_time>> list_add(&pt->list, &v->arch.hvm.tm_list);
+     *   - arch/x86/hvm/vpt.c|708| <<pt_adjust_vcpu>> list_add(&pt->list, &v->arch.hvm.tm_list);
+     *   - arch/x86/hvm/vpt.c|756| <<pt_resume>> list_add(&pt->list, &pt->vcpu->arch.hvm.tm_list);
+     */
     struct list_head *head = &v->arch.hvm.tm_list;
     struct periodic_time *pt;
 
@@ -431,6 +636,15 @@ static struct periodic_time *is_pt_irq(
     return NULL;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/svm/intr.c|217| <<svm_intr_assist>> pt_intr_post(v, intack);
+ *   - arch/x86/hvm/vmx/intr.c|206| <<nvmx_intr_intercept>> pt_intr_post(v, intack);
+ *   - arch/x86/hvm/vmx/intr.c|390| <<vmx_intr_assist>> pt_intr_post(v, intack);
+ *   - arch/x86/hvm/vmx/intr.c|396| <<vmx_intr_assist>> pt_intr_post(v, intack);
+ *
+ * 对于第四个timer check是hvm_intsrc_lapic
+ */
 void pt_intr_post(struct vcpu *v, struct hvm_intack intack)
 {
     struct periodic_time *pt;
@@ -449,6 +663,11 @@ void pt_intr_post(struct vcpu *v, struct hvm_intack intack)
         return;
     }
 
+    /*
+     * called by:
+     *   - arch/x86/hvm/vpt.c|410| <<pt_update_irq>> pt_irq_fired(v, pt);
+     *   - arch/x86/hvm/vpt.c|472| <<pt_intr_post>> pt_irq_fired(v, pt);
+     */
     pt_irq_fired(v, pt);
 
     cb = pt->cb;
@@ -460,6 +679,10 @@ void pt_intr_post(struct vcpu *v, struct hvm_intack intack)
         cb(v, cb_priv);
 }
 
+/*
+ * used by only:
+ *   - arch/x86/hvm/hvm.c|467| <<hvm_migrate_timers>> pt_migrate(v);
+ */
 void pt_migrate(struct vcpu *v)
 {
     struct list_head *head = &v->arch.hvm.tm_list;
@@ -473,10 +696,34 @@ void pt_migrate(struct vcpu *v)
     spin_unlock(&v->arch.hvm.tm_lock);
 }
 
+/*
+ * called by:
+ *   - arch/x86/emul-i8254.c|193| <<pit_load_count>> create_periodic_time(v, &pit->pt0, period, period, 0, pit_time_fired,
+ *   - arch/x86/emul-i8254.c|200| <<pit_load_count>> create_periodic_time(v, &pit->pt0, period, 0, 0, pit_time_fired,
+ *   - arch/x86/hvm/hpet.c|312| <<hpet_set_timer>> create_periodic_time(vhpet_vcpu(h), &h->pt[tn],
+ *   - arch/x86/hvm/rtc.c|158| <<rtc_timer_update>> create_periodic_time(v, &s->pt, delta, period,
+ *   - arch/x86/hvm/vlapic.c|749| <<vlapic_update_timer>> create_periodic_time(current, &vlapic->pt, delta,
+ *   - arch/x86/hvm/vlapic.c|1202| <<vlapic_tdt_msr_set>> create_periodic_time(v, &vlapic->pt, delta, 0,
+ *   - arch/x86/hvm/vlapic.c|1216| <<vlapic_tdt_msr_set>> create_periodic_time(v, &vlapic->pt, 0, 0,
+ *   - arch/x86/hvm/vlapic.c|1453| <<lapic_rearm>> create_periodic_time(vlapic_vcpu(s), &s->pt, period,
+ *
+ * 一个例子是
+ * 213         create_periodic_time(v, &pit->pt0, period, period, 0, pit_time_fired,
+ * 214                              &pit->count_load_time[channel], false);
+ */
 void create_periodic_time(
     struct vcpu *v, struct periodic_time *pt, uint64_t delta,
     uint64_t period, uint8_t irq, time_cb *cb, void *data, bool level)
 {
+    /*
+     * pt->source在以下设置:
+     *   - arch/x86/emul-i8254.c|495| <<pit_reset>> pit->pt0.source = PTSRC_isa;
+     *   - arch/x86/hvm/hpet.c|289| <<hpet_set_timer>> h->pt[tn].source = PTSRC_isa;
+     *   - arch/x86/hvm/hpet.c|294| <<hpet_set_timer>> h->pt[tn].source = PTSRC_ioapic;
+     *   - arch/x86/hvm/hpet.c|731| <<hpet_set>> h->pt[i].source = PTSRC_isa;
+     *   - arch/x86/hvm/rtc.c|799| <<rtc_reset>> s->pt.source = PTSRC_isa;
+     *   - arch/x86/hvm/vlapic.c|1664| <<vlapic_init>> vlapic->pt.source = PTSRC_lapic;
+     */
     if ( !pt->source ||
          (irq >= NR_ISAIRQS && pt->source == PTSRC_isa) ||
          (level && period) ||
@@ -491,6 +738,15 @@ void create_periodic_time(
 
     spin_lock(&v->arch.hvm.tm_lock);
 
+    /*
+     *   - arch/x86/hvm/vpt.c|243| <<pt_process_missed_ticks>> pt->pending_intr_nr += missed_ticks;
+     *   - arch/x86/hvm/vpt.c|317| <<pt_timer_fn>> pt->pending_intr_nr++;
+     *   - arch/x86/hvm/vpt.c|340| <<pt_irq_fired>> pt->pending_intr_nr = 0;
+     *   - arch/x86/hvm/vpt.c|347| <<pt_irq_fired>> pt->pending_intr_nr = 0;
+     *   - arch/x86/hvm/vpt.c|353| <<pt_irq_fired>> if ( --pt->pending_intr_nr == 0 )
+     *   - arch/x86/hvm/vpt.c|588| <<create_periodic_time>> pt->pending_intr_nr = 0;
+     *   - arch/x86/hvm/vpt.c|668| <<destroy_periodic_time>> pt->pending_intr_nr = 0;
+     */
     pt->pending_intr_nr = 0;
     pt->do_not_freeze = 0;
     pt->irq_issued = 0;
@@ -510,12 +766,28 @@ void create_periodic_time(
     pt->irq = irq;
     pt->one_shot = !period;
     pt->level = level;
+    /*
+     * used by:
+     *   - arch/x86/hvm/vpt.c|235| <<pt_process_missed_ticks>> missed_ticks = now - pt->scheduled;
+     *   - arch/x86/hvm/vpt.c|244| <<pt_process_missed_ticks>> pt->scheduled += missed_ticks * pt->period;
+     *   - arch/x86/hvm/vpt.c|298| <<pt_restore_timer>> set_timer(&pt->timer, pt->scheduled);
+     *   - arch/x86/hvm/vpt.c|318| <<pt_timer_fn>> pt->scheduled += pt->period;
+     *   - arch/x86/hvm/vpt.c|348| <<pt_irq_fired>> set_timer(&pt->timer, pt->scheduled);
+     *   - arch/x86/hvm/vpt.c|357| <<pt_irq_fired>> set_timer(&pt->timer, pt->scheduled);
+     *   - arch/x86/hvm/vpt.c|607| <<create_periodic_time>> pt->scheduled = NOW() + delta;
+     *   - arch/x86/hvm/vpt.c|613| <<create_periodic_time>> pt->scheduled = align_timer(pt->scheduled, pt->period);
+     *   - arch/x86/hvm/vpt.c|623| <<create_periodic_time>> pt->scheduled += delta >> 1;
+     *   - arch/x86/hvm/vpt.c|634| <<create_periodic_time>> set_timer(&pt->timer, pt->scheduled);
+     */
     pt->scheduled = NOW() + delta;
 
     if ( !pt->one_shot )
     {
         if ( v->domain->arch.hvm.params[HVM_PARAM_VPT_ALIGN] )
         {
+            /*
+	     * Calculate the aligned first tick time for a given periodic timer.
+	     */
             pt->scheduled = align_timer(pt->scheduled, pt->period);
         }
         else if ( pt->source == PTSRC_lapic )
@@ -530,10 +802,35 @@ void create_periodic_time(
         }
     }
 
+    /*
+     * 调用cb的地方:
+     *   - arch/x86/hvm/vpt.c|566| <<pt_update_irq>> cb(v, cb_priv);
+     *   - arch/x86/hvm/vpt.c|628| <<pt_intr_post>> cb(v, cb_priv);
+     *
+     * vmx_intr_assist()
+     *  -> pt_update_irq()
+     *      -> cb = pit_time_fired()
+     *  -> pt_intr_post() 两种情况会调用
+     *      -> cb = pit_time_fired()
+     */
     pt->cb = cb;
     pt->priv = data;
 
     pt->on_list = 1;
+    /*
+     * used by:
+     *   - arch/x86/domain.c|1740| <<context_switch>> if ( is_hvm_domain(prevd) && !list_empty(&prev->arch.hvm.tm_list) )
+     *   - arch/x86/hvm/hvm.c|1506| <<hvm_vcpu_initialise>> INIT_LIST_HEAD(&v->arch.hvm.tm_list);
+     *   - arch/x86/hvm/vpt.c|269| <<pt_save_timer>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|288| <<pt_restore_timer>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|373| <<pt_update_irq>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|466| <<pt_update_irq>> list_for_each_entry ( pt, &v->arch.hvm.tm_list, list )
+     *   - arch/x86/hvm/vpt.c|493| <<is_pt_irq>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|548| <<pt_migrate>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|631| <<create_periodic_time>> list_add(&pt->list, &v->arch.hvm.tm_list);
+     *   - arch/x86/hvm/vpt.c|708| <<pt_adjust_vcpu>> list_add(&pt->list, &v->arch.hvm.tm_list);
+     *   - arch/x86/hvm/vpt.c|756| <<pt_resume>> list_add(&pt->list, &pt->vcpu->arch.hvm.tm_list);
+     */
     list_add(&pt->list, &v->arch.hvm.tm_list);
 
     init_timer(&pt->timer, pt_timer_fn, pt, v->processor);
@@ -542,6 +839,25 @@ void create_periodic_time(
     spin_unlock(&v->arch.hvm.tm_lock);
 }
 
+/*
+ * callled by:
+ *   - arch/x86/emul-i8254.c|205| <<pit_load_count>> destroy_periodic_time(&pit->pt0);
+ *   - arch/x86/emul-i8254.c|390| <<pit_stop_channel0_irq>> destroy_periodic_time(&pit->pt0);
+ *   - arch/x86/emul-i8254.c|457| <<pit_reset>> destroy_periodic_time(&pit->pt0);
+ *   - arch/x86/emul-i8254.c|502| <<pit_deinit>> destroy_periodic_time(&pit->pt0);
+ *   - arch/x86/hvm/hpet.c|214| <<hpet_stop_timer>> destroy_periodic_time(&h->pt[tn]);
+ *   - arch/x86/hvm/hpet.c|282| <<hpet_set_timer>> destroy_periodic_time(&h->pt[tn]);
+ *   - arch/x86/hvm/rtc.c|95| <<rtc_pf_callback>> destroy_periodic_time(&s->pt);
+ *   - arch/x86/hvm/rtc.c|169| <<rtc_timer_update>> destroy_periodic_time(&s->pt);
+ *   - arch/x86/hvm/rtc.c|522| <<rtc_ioport_write>> destroy_periodic_time(&s->pt);
+ *   - arch/x86/hvm/rtc.c|797| <<rtc_reset>> destroy_periodic_time(&s->pt);
+ *   - arch/x86/hvm/rtc.c|845| <<rtc_deinit>> destroy_periodic_time(&s->pt);
+ *   - arch/x86/hvm/vlapic.c|779| <<vlapic_update_timer>> destroy_periodic_time(&vlapic->pt);
+ *   - arch/x86/hvm/vlapic.c|1245| <<vlapic_tdt_msr_set>> destroy_periodic_time(&vlapic->pt);
+ *   - arch/x86/hvm/vlapic.c|1464| <<vlapic_do_init>> destroy_periodic_time(&vlapic->pt);
+ *   - arch/x86/hvm/vlapic.c|1711| <<vlapic_destroy>> destroy_periodic_time(&vlapic->pt);
+ *   - arch/x86/hvm/vpt.c|584| <<create_periodic_time>> destroy_periodic_time(pt);
+ */
 void destroy_periodic_time(struct periodic_time *pt)
 {
     /* Was this structure previously initialised by create_periodic_time()? */
@@ -562,6 +878,15 @@ void destroy_periodic_time(struct periodic_time *pt)
     kill_timer(&pt->timer);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpt.c|625| <<pt_adjust_global_vcpu_target>> pt_adjust_vcpu(&vpit->pt0, v);
+ *   - arch/x86/hvm/vpt.c|631| <<pt_adjust_global_vcpu_target>> pt_adjust_vcpu(&pl_time->vrtc.pt, v);
+ *   - arch/x86/hvm/vpt.c|636| <<pt_adjust_global_vcpu_target>> pt_adjust_vcpu(&pl_time->vhpet.pt[i], v);
+ *
+ * 只有一条调用路径:
+ * vlapic_adjust_i8259_target() --> pt_adjust_global_vcpu_target() --> pt_adjust_vcpu()
+ */
 static void pt_adjust_vcpu(struct periodic_time *pt, struct vcpu *v)
 {
     int on_list;
@@ -583,6 +908,25 @@ static void pt_adjust_vcpu(struct periodic_time *pt, struct vcpu *v)
     if ( on_list )
     {
         pt->on_list = 1;
+	/*
+	 * used by:
+	 *   - arch/x86/domain.c|1740| <<context_switch>> if ( is_hvm_domain(prevd) && !list_empty(&prev->arch.hvm.tm_list) )
+	 *   - arch/x86/hvm/hvm.c|1506| <<hvm_vcpu_initialise>> INIT_LIST_HEAD(&v->arch.hvm.tm_list);
+	 *   - arch/x86/hvm/vpt.c|269| <<pt_save_timer>> struct list_head *head = &v->arch.hvm.tm_list;
+	 *   - arch/x86/hvm/vpt.c|288| <<pt_restore_timer>> struct list_head *head = &v->arch.hvm.tm_list;
+	 *   - arch/x86/hvm/vpt.c|373| <<pt_update_irq>> struct list_head *head = &v->arch.hvm.tm_list;
+	 *   - arch/x86/hvm/vpt.c|466| <<pt_update_irq>> list_for_each_entry ( pt, &v->arch.hvm.tm_list, list )
+	 *   - arch/x86/hvm/vpt.c|493| <<is_pt_irq>> struct list_head *head = &v->arch.hvm.tm_list;
+	 *   - arch/x86/hvm/vpt.c|548| <<pt_migrate>> struct list_head *head = &v->arch.hvm.tm_list;
+	 *   - arch/x86/hvm/vpt.c|631| <<create_periodic_time>> list_add(&pt->list, &v->arch.hvm.tm_list);
+	 *   - arch/x86/hvm/vpt.c|708| <<pt_adjust_vcpu>> list_add(&pt->list, &v->arch.hvm.tm_list);
+	 *   - arch/x86/hvm/vpt.c|756| <<pt_resume>> list_add(&pt->list, &pt->vcpu->arch.hvm.tm_list);
+	 *
+	 * struct vcpu
+	 *  -> struct arch_vcpu arch
+	 *      -> struct hvm_vcpu hvm
+	 *          -> struct list_head tm_list
+	 */
         list_add(&pt->list, &v->arch.hvm.tm_list);
 
         migrate_timer(&pt->timer, v->processor);
@@ -590,6 +934,10 @@ static void pt_adjust_vcpu(struct periodic_time *pt, struct vcpu *v)
     spin_unlock(&v->arch.hvm.tm_lock);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vlapic.c|1293| <<vlapic_adjust_i8259_target>> pt_adjust_global_vcpu_target(v);
+ */
 void pt_adjust_global_vcpu_target(struct vcpu *v)
 {
     struct PITState *vpit;
@@ -599,6 +947,22 @@ void pt_adjust_global_vcpu_target(struct vcpu *v)
     if ( !v || !has_vpit(v->domain) )
         return;
 
+    /*
+     * struct domain
+     *  -> struct arch_domain arch
+     *      -> struct hvm_domain hvm
+     *          -> struct pl_time *pl_time
+     *              -> struct RTCState  vrtc
+     *                  -> struct periodic_time pt
+     *                      -> struct timer timer
+     *              -> struct HPETState vhpet
+     *                  -> struct periodic_time pt[HPET_TIMER_NUM]
+     *                      -> struct timer timer
+     *      -> struct PITState vpit
+     *          -> struct periodic_time pt0
+     *              -> struct timer timer
+     */
+
     vpit = &v->domain->arch.vpit;
 
     spin_lock(&vpit->lock);
@@ -618,6 +982,13 @@ void pt_adjust_global_vcpu_target(struct vcpu *v)
 }
 
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpt.c|768| <<pt_may_unmask_irq>> pt_resume(&d->arch.vpit.pt0);
+ *   - arch/x86/hvm/vpt.c|769| <<pt_may_unmask_irq>> pt_resume(&d->arch.hvm.pl_time->vrtc.pt);
+ *   - arch/x86/hvm/vpt.c|771| <<pt_may_unmask_irq>> pt_resume(&d->arch.hvm.pl_time->vhpet.pt[i]);
+ *   - arch/x86/hvm/vpt.c|775| <<pt_may_unmask_irq>> pt_resume(vlapic_pt);
+ */
 static void pt_resume(struct periodic_time *pt)
 {
     if ( pt->vcpu == NULL )
@@ -633,6 +1004,16 @@ static void pt_resume(struct periodic_time *pt)
     pt_unlock(pt);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vioapic.c|290| <<vioapic_write_redirent>> pt_may_unmask_irq(d, NULL);
+ *   - arch/x86/hvm/vlapic.c|846| <<vlapic_reg_write>> pt_may_unmask_irq(vlapic_domain(vlapic), &vlapic->pt);
+ *   - arch/x86/hvm/vlapic.c|884| <<vlapic_reg_write>> pt_may_unmask_irq(v->domain, NULL);
+ *   - arch/x86/hvm/vlapic.c|887| <<vlapic_reg_write>> pt_may_unmask_irq(NULL, &vlapic->pt);
+ *   - arch/x86/hvm/vlapic.c|1161| <<guest_wrmsr_apic_base>> pt_may_unmask_irq(vlapic_domain(vlapic), &vlapic->pt);
+ *   - arch/x86/hvm/vlapic.c|1166| <<guest_wrmsr_apic_base>> pt_may_unmask_irq(vlapic_domain(vlapic), NULL);
+ *   - arch/x86/hvm/vpic.c|330| <<vpic_ioport_write>> pt_may_unmask_irq(vpic_domain(vpic), NULL);
+ */
 void pt_may_unmask_irq(struct domain *d, struct periodic_time *vlapic_pt)
 {
     int i;
diff --git a/xen/arch/x86/irq.c b/xen/arch/x86/irq.c
index 23b4f42..211d796 100644
--- a/xen/arch/x86/irq.c
+++ b/xen/arch/x86/irq.c
@@ -48,6 +48,29 @@ static DECLARE_BITMAP(used_vectors, NR_VECTORS);
 
 static DEFINE_SPINLOCK(vector_lock);
 
+/*
+ * used by:
+ *   - arch/x86/irq.c|51| <<global>> DEFINE_PER_CPU(vector_irq_t, vector_irq);
+ *   - include/asm-x86/irq.h|52| <<global>> DECLARE_PER_CPU(vector_irq_t, vector_irq);
+ *   - arch/x86/i8259.c|106| <<_disable_8259A_irq>> per_cpu(vector_irq, 0)[LEGACY_VECTOR(irq)] = ~irq;
+ *   - arch/x86/i8259.c|122| <<enable_8259A_irq>> per_cpu(vector_irq, 0)[LEGACY_VECTOR(desc->irq)] = desc->irq;
+ *   - arch/x86/i8259.c|350| <<init_IRQ>> per_cpu(vector_irq, cpu)[FIRST_LEGACY_VECTOR + irq] = irq;
+ *   - arch/x86/i8259.c|355| <<init_IRQ>> per_cpu(vector_irq, cpu)[IRQ0_VECTOR] = 0;
+ *   - arch/x86/irq.c|134| <<__bind_irq_vector>> per_cpu(vector_irq, cpu)[vector] = irq;
+ *   - arch/x86/irq.c|258| <<__clear_irq_vector>> ASSERT( per_cpu(vector_irq, cpu)[vector] == irq );
+ *   - arch/x86/irq.c|259| <<__clear_irq_vector>> per_cpu(vector_irq, cpu)[vector] = ~irq;
+ *   - arch/x86/irq.c|283| <<__clear_irq_vector>> ASSERT( per_cpu(vector_irq, cpu)[old_vector] == irq );
+ *   - arch/x86/irq.c|285| <<__clear_irq_vector>> per_cpu(vector_irq, cpu)[old_vector] = ~irq;
+ *   - arch/x86/irq.c|359| <<init_irq_data>> this_cpu(vector_irq)[vector] = INT_MIN;
+ *   - arch/x86/irq.c|515| <<__assign_irq_vector>> if (per_cpu(vector_irq, new_cpu)[vector] >= 0)
+ *   - arch/x86/irq.c|527| <<__assign_irq_vector>> per_cpu(vector_irq, new_cpu)[vector] = irq;
+ *   - arch/x86/irq.c|577| <<setup_vector_irq>> per_cpu(vector_irq, cpu)[vector] = INT_MIN;
+ *   - arch/x86/irq.c|591| <<setup_vector_irq>> per_cpu(vector_irq, cpu)[vector] = irq;
+ *   - arch/x86/irq.c|651| <<irq_move_cleanup_interrupt>> irq = __get_cpu_var(vector_irq)[vector];
+ *   - arch/x86/irq.c|689| <<irq_move_cleanup_interrupt>> __get_cpu_var(vector_irq)[vector] = ~irq;
+ *   - arch/x86/irq.c|821| <<do_IRQ>> int irq = __get_cpu_var(vector_irq[vector]);
+ *   - arch/x86/smpboot.c|1376| <<smp_intr_init>> per_cpu(vector_irq, cpu)[vector] = irq;
+ */
 DEFINE_PER_CPU(vector_irq_t, vector_irq);
 
 DEFINE_PER_CPU(struct cpu_user_regs *, __irq_regs);
@@ -791,6 +814,16 @@ uint8_t alloc_hipriority_vector(void)
     return next++;
 }
 
+/*
+ * used by:
+ *   - arch/x86/irq.c|817| <<global>> static void (*direct_apic_vector[NR_VECTORS])(struct cpu_user_regs *);
+ *   - arch/x86/irq.c|821| <<set_direct_apic_vector>> BUG_ON(direct_apic_vector[vector] != NULL);
+ *   - arch/x86/irq.c|822| <<set_direct_apic_vector>> direct_apic_vector[vector] = handler;
+ *   - arch/x86/irq.c|875| <<do_IRQ>> if (direct_apic_vector[vector] != NULL) {
+ *   - arch/x86/irq.c|876| <<do_IRQ>> (*direct_apic_vector[vector])(regs);
+ *   - arch/x86/irq.c|2393| <<dump_irqs>> if ( direct_apic_vector[i] )
+ *   - arch/x86/irq.c|2394| <<dump_irqs>> printk(" %#02x -> %ps()\n", i, direct_apic_vector[i]);
+ */
 static void (*direct_apic_vector[NR_VECTORS])(struct cpu_user_regs *);
 void set_direct_apic_vector(
     uint8_t vector, void (*handler)(struct cpu_user_regs *))
@@ -818,6 +851,29 @@ void do_IRQ(struct cpu_user_regs *regs)
     uint32_t          tsc_in;
     struct irq_desc  *desc;
     unsigned int      vector = (u8)regs->entry_vector;
+    /*
+     * percpu的vector_irq[]在以下使用:
+     *   - arch/x86/irq.c|51| <<global>> DEFINE_PER_CPU(vector_irq_t, vector_irq);
+     *   - include/asm-x86/irq.h|52| <<global>> DECLARE_PER_CPU(vector_irq_t, vector_irq);
+     *   - arch/x86/i8259.c|106| <<_disable_8259A_irq>> per_cpu(vector_irq, 0)[LEGACY_VECTOR(irq)] = ~irq;
+     *   - arch/x86/i8259.c|122| <<enable_8259A_irq>> per_cpu(vector_irq, 0)[LEGACY_VECTOR(desc->irq)] = desc->irq;
+     *   - arch/x86/i8259.c|350| <<init_IRQ>> per_cpu(vector_irq, cpu)[FIRST_LEGACY_VECTOR + irq] = irq;
+     *   - arch/x86/i8259.c|355| <<init_IRQ>> per_cpu(vector_irq, cpu)[IRQ0_VECTOR] = 0;
+     *   - arch/x86/irq.c|134| <<__bind_irq_vector>> per_cpu(vector_irq, cpu)[vector] = irq;
+     *   - arch/x86/irq.c|258| <<__clear_irq_vector>> ASSERT( per_cpu(vector_irq, cpu)[vector] == irq );
+     *   - arch/x86/irq.c|259| <<__clear_irq_vector>> per_cpu(vector_irq, cpu)[vector] = ~irq;
+     *   - arch/x86/irq.c|283| <<__clear_irq_vector>> ASSERT( per_cpu(vector_irq, cpu)[old_vector] == irq );
+     *   - arch/x86/irq.c|285| <<__clear_irq_vector>> per_cpu(vector_irq, cpu)[old_vector] = ~irq;
+     *   - arch/x86/irq.c|359| <<init_irq_data>> this_cpu(vector_irq)[vector] = INT_MIN;
+     *   - arch/x86/irq.c|515| <<__assign_irq_vector>> if (per_cpu(vector_irq, new_cpu)[vector] >= 0)
+     *   - arch/x86/irq.c|527| <<__assign_irq_vector>> per_cpu(vector_irq, new_cpu)[vector] = irq;
+     *   - arch/x86/irq.c|577| <<setup_vector_irq>> per_cpu(vector_irq, cpu)[vector] = INT_MIN;
+     *   - arch/x86/irq.c|591| <<setup_vector_irq>> per_cpu(vector_irq, cpu)[vector] = irq;
+     *   - arch/x86/irq.c|651| <<irq_move_cleanup_interrupt>> irq = __get_cpu_var(vector_irq)[vector];
+     *   - arch/x86/irq.c|689| <<irq_move_cleanup_interrupt>> __get_cpu_var(vector_irq)[vector] = ~irq;
+     *   - arch/x86/irq.c|821| <<do_IRQ>> int irq = __get_cpu_var(vector_irq[vector]);
+     *   - arch/x86/smpboot.c|1376| <<smp_intr_init>> per_cpu(vector_irq, cpu)[vector] = irq;
+     */
     int irq = __get_cpu_var(vector_irq[vector]);
     struct cpu_user_regs *old_regs = set_irq_regs(regs);
     
@@ -826,6 +882,16 @@ void do_IRQ(struct cpu_user_regs *regs)
     irq_enter();
 
     if (irq < 0) {
+        /*
+	 * direct_apic_vector[]在以下使用:
+	 *   - arch/x86/irq.c|817| <<global>> static void (*direct_apic_vector[NR_VECTORS])(struct cpu_user_regs *);
+	 *   - arch/x86/irq.c|821| <<set_direct_apic_vector>> BUG_ON(direct_apic_vector[vector] != NULL);
+	 *   - arch/x86/irq.c|822| <<set_direct_apic_vector>> direct_apic_vector[vector] = handler;
+	 *   - arch/x86/irq.c|875| <<do_IRQ>> if (direct_apic_vector[vector] != NULL) {
+	 *   - arch/x86/irq.c|876| <<do_IRQ>> (*direct_apic_vector[vector])(regs);
+	 *   - arch/x86/irq.c|2393| <<dump_irqs>> if ( direct_apic_vector[i] )
+	 *   - arch/x86/irq.c|2394| <<dump_irqs>> printk(" %#02x -> %ps()\n", i, direct_apic_vector[i]);
+	 */
         if (direct_apic_vector[vector] != NULL) {
             (*direct_apic_vector[vector])(regs);
         } else {
diff --git a/xen/arch/x86/mm/hap/hap.c b/xen/arch/x86/mm/hap/hap.c
index 412a442..1758c9e 100644
--- a/xen/arch/x86/mm/hap/hap.c
+++ b/xen/arch/x86/mm/hap/hap.c
@@ -438,6 +438,10 @@ void hap_domain_init(struct domain *d)
     paging_log_dirty_init(d, &hap_ops);
 }
 
+/*
+ * called by only:
+ *   - arch/x86/mm/paging.c|847| <<paging_enable>> return hap_enable(d, mode);
+ */
 /* return 0 for success, -errno for failure */
 int hap_enable(struct domain *d, u32 mode)
 {
diff --git a/xen/common/domain.c b/xen/common/domain.c
index 32bca8d..68605e7 100644
--- a/xen/common/domain.c
+++ b/xen/common/domain.c
@@ -134,6 +134,16 @@ static void vcpu_destroy(struct vcpu *v)
     free_vcpu_struct(v);
 }
 
+/*
+ * called by:
+ *   - arch/arm/domain_build.c|83| <<alloc_dom0_vcpu0>> return vcpu_create(dom0, 0, 0);
+ *   - arch/arm/domain_build.c|1992| <<construct_domain>> if ( vcpu_create(d, i, cpu) == NULL )
+ *   - arch/arm/domain_build.c|2029| <<construct_domU>> if ( vcpu_create(d, 0, 0) == NULL )
+ *   - arch/x86/dom0_build.c|206| <<dom0_setup_vcpu>> struct vcpu *v = vcpu_create(d, vcpu_id, cpu);
+ *   - common/domctl.c|565| <<do_domctl():XEN_DOMCTL_max_vcpus>> if ( vcpu_create(d, i, cpu) == NULL )
+ *   - common/schedule.c|1648| <<cpu_schedule_up>> vcpu_create(idle_vcpu[0]->domain, cpu, cpu);
+ *   - common/schedule.c|1821| <<scheduler_init>> if ( vcpu_create(idle_domain, 0, 0) == NULL )
+ */
 struct vcpu *vcpu_create(
     struct domain *d, unsigned int vcpu_id, unsigned int cpu_id)
 {
@@ -271,6 +281,11 @@ custom_param("extra_guest_irqs", parse_extra_guest_irqs);
  * from the RCU path, or from the domain_create() error path before the domain
  * is inserted into the domlist.
  */
+/*
+ * called by:
+ *   - common/domain.c|526| <<domain_create>> _domain_destroy(d);
+ *   - common/domain.c|957| <<complete_domain_destroy>> _domain_destroy(d);
+ */
 static void _domain_destroy(struct domain *d)
 {
     BUG_ON(!d->is_dying);
@@ -886,6 +901,10 @@ void domain_pause_for_debugger(void)
 #endif
 
 /* Complete domain destroy after RCU readers are not holding old references. */
+/*
+ * used by:
+ *   - common/domain.c|988| <<domain_destroy>> call_rcu(&d->rcu, complete_domain_destroy);
+ */
 static void complete_domain_destroy(struct rcu_head *head)
 {
     struct domain *d = container_of(head, struct domain, rcu);
@@ -950,6 +969,10 @@ static void complete_domain_destroy(struct rcu_head *head)
 }
 
 /* Release resources belonging to task @p. */
+/*
+ * called by:
+ *   - include/xen/sched.h|516| <<put_domain>> if ( atomic_dec_and_test(&(_d)->refcnt) ) domain_destroy(_d)
+ */
 void domain_destroy(struct domain *d)
 {
     struct domain **pd;
diff --git a/xen/common/timer.c b/xen/common/timer.c
index 376581b..8535cb9 100644
--- a/xen/common/timer.c
+++ b/xen/common/timer.c
@@ -25,14 +25,46 @@
 #include <asm/atomic.h>
 
 /* We program the time hardware this far behind the closest deadline. */
+/*
+ * used by only:
+ *   - common/timer.c|777| <<timer_softirq_action>> (deadline == STIME_MAX) ? 0 : MAX(deadline, now + timer_slop);
+ */
 static unsigned int timer_slop __read_mostly = 50000; /* 50 us */
 integer_param("timer_slop", timer_slop);
 
 struct timers {
     spinlock_t     lock;
+    /*
+     * heap分配的地方:
+     *   - common/timer.c|546| <<timer_softirq_action>> ts->heap = newheap;
+     *   - common/timer.c|702| <<cpu_callback>> ts->heap = &dummy_heap;
+     */
     struct timer **heap;
     struct timer  *list;
+    /*
+     * running设置的地方:
+     *   - common/timer.c|657| <<execute_timer>> ts->running = t;
+     *   - common/timer.c|661| <<execute_timer>> ts->running = NULL;
+     */
     struct timer  *running;
+    /*
+     * 在以下添加:
+     *   - common/timer.c|333| <<deactivate_timer>> list_add(&timer->inactive, &per_cpu(timers, timer->cpu).inactive);
+     *   - common/timer.c|440| <<init_timer>> list_add(&timer->inactive, &per_cpu(timers, cpu).inactive);
+     *   - common/timer.c|586| <<migrate_timer>> list_add(&timer->inactive, &per_cpu(timers, new_cpu).inactive);
+     *   - common/timer.c|668| <<execute_timer>> list_add(&t->inactive, &ts->inactive);
+     *   - common/timer.c|875| <<migrate_timers_from_cpu>> list_add(&t->inactive, &new_ts->inactive);
+     *
+     * 在以下删除:
+     *   - common/timer.c|314| <<activate_timer>> list_del(&timer->inactive);
+     *   - common/timer.c|584| <<migrate_timer>> list_del(&timer->inactive);
+     *   - common/timer.c|640| <<kill_timer>> list_del(&timer->inactive);
+     *   - common/timer.c|873| <<migrate_timers_from_cpu>> list_del(&t->inactive);
+     *
+     * 使用的例子:
+     *   - common/timer.c|870| <<migrate_timers_from_cpu>> while ( !list_empty(&old_ts->inactive) )
+     *   - common/timer.c|902| <<cpu_callback>> INIT_LIST_HEAD(&ts->inactive);
+     */
     struct list_head inactive;
 } __cacheline_aligned;
 
@@ -41,19 +73,78 @@ static DEFINE_PER_CPU(struct timers, timers);
 /* Protects lock-free access to per-timer cpu field against cpu offlining. */
 static DEFINE_RCU_READ_LOCK(timer_cpu_read_lock);
 
+/*
+ * used by:
+ *   - arch/x86/acpi/cpu_idle.c|403| <<mwait_idle_with_hints>> s_time_t expires = per_cpu(timer_deadline, cpu);
+ *   - arch/x86/acpi/cpuidle_menu.c|179| <<get_sleep_length_us>> s_time_t us = (this_cpu(timer_deadline) - NOW()) / 1000;
+ *   - arch/x86/hpet.c|190| <<handle_hpet_broadcast>> s_time_t deadline = ACCESS_ONCE(per_cpu(timer_deadline, cpu));
+ *   - arch/x86/hpet.c|696| <<hpet_broadcast_enter>> s_time_t deadline = per_cpu(timer_deadline, cpu);
+ *   - arch/x86/hpet.c|727| <<hpet_broadcast_exit>> s_time_t deadline = per_cpu(timer_deadline, cpu);
+ *   - arch/x86/time.c|1951| <<pit_broadcast_exit>> reprogram_timer(this_cpu(timer_deadline));
+ *   - common/timer.c|555| <<timer_softirq_action>> this_cpu(timer_deadline) =
+ *   - common/timer.c|558| <<timer_softirq_action>> if ( !reprogram_timer(this_cpu(timer_deadline)) )
+ */
 DEFINE_PER_CPU(s_time_t, timer_deadline);
 
 /****************************************************************************
  * HEAP OPERATIONS.
  */
 
+/*
+ * 一般来说, struct timer **h是二维指针
+ *
+ * **h ---> -------------------
+ *          |  h[0] reserverd |----> 在地址里保存limit和size
+ *          |-----------------|
+ *          |  struct timer * |-----> struct timer
+ *          |-----------------|
+ *          |  struct timer * |-----> struct timer
+ *          |-----------------|
+ *          |  struct timer * |-----> struct timer
+ *          |-----------------|
+ *          |  struct timer * |-----> struct timer
+ *          -------------------
+ *
+ * 对于dummy_heap来说有一点点的不一样
+ * struct *dummy_heap
+ *
+ * &dummy_heap就成了
+ *
+ * &dummy_heap ---> ----------------------
+ *                  |   struct timer *   |
+ *                  ----------------------
+ *                  本来应该存储一个地址
+ *                  现在直接存储limit和size
+ */
+
+/*
+ * called by:
+ *   - common/timer.c|59| <<down_heap>> int sz = GET_HEAP_SIZE(heap), nxt;
+ *   - common/timer.c|97| <<remove_from_heap>> int sz = GET_HEAP_SIZE(heap);
+ *   - common/timer.c|124| <<add_to_heap>> int sz = GET_HEAP_SIZE(heap);
+ *   - common/timer.c|524| <<timer_softirq_action>> while ( (GET_HEAP_SIZE(heap) != 0) &&
+ *   - common/timer.c|550| <<timer_softirq_action>> if ( GET_HEAP_SIZE(heap) != 0 )
+ *   - common/timer.c|594| <<dump_timerq>> for ( j = 1; j <= GET_HEAP_SIZE(ts->heap); j++ )
+ *   - common/timer.c|625| <<migrate_timers_from_cpu>> while ( (t = GET_HEAP_SIZE(old_ts->heap)
+ */
 #define GET_HEAP_SIZE(_h)     ((int)(((u16 *)(_h))[0]))
+/*
+ * called by:
+ *   - common/timer.c|102| <<remove_from_heap>> SET_HEAP_SIZE(heap, sz-1);
+ *   - common/timer.c|109| <<remove_from_heap>> SET_HEAP_SIZE(heap, --sz);
+ *   - common/timer.c|130| <<add_to_heap>> SET_HEAP_SIZE(heap, ++sz);
+ *   - common/timer.c|689| <<timer_init>> SET_HEAP_SIZE(&dummy_heap, 0);
+ */
 #define SET_HEAP_SIZE(_h,_v)  (((u16 *)(_h))[0] = (u16)(_v))
 
 #define GET_HEAP_LIMIT(_h)    ((int)(((u16 *)(_h))[1]))
 #define SET_HEAP_LIMIT(_h,_v) (((u16 *)(_h))[1] = (u16)(_v))
 
 /* Sink down element @pos of @heap. */
+/*
+ * called by only:
+ *   - common/timer.c|114| <<remove_from_heap>> down_heap(heap, pos);
+ */
 static void down_heap(struct timer **heap, int pos)
 {
     int sz = GET_HEAP_SIZE(heap), nxt;
@@ -75,6 +166,11 @@ static void down_heap(struct timer **heap, int pos)
 }
 
 /* Float element @pos up @heap. */
+/*
+ * called by:
+ *   - common/timer.c|149| <<remove_from_heap>> up_heap(heap, pos);
+ *   - common/timer.c|170| <<add_to_heap>> up_heap(heap, sz);
+ */
 static void up_heap(struct timer **heap, int pos)
 {
     struct timer *t = heap[pos];
@@ -140,6 +236,10 @@ static int add_to_heap(struct timer **heap, struct timer *t)
  * LINKED LIST OPERATIONS.
  */
 
+/*
+ * called by:
+ *   - common/timer.c|284| <<remove_entry>> rc = remove_from_list(&timers->list, t);
+ */
 static int remove_from_list(struct timer **pprev, struct timer *t)
 {
     struct timer *curr, **_pprev = pprev;
@@ -152,6 +252,10 @@ static int remove_from_list(struct timer **pprev, struct timer *t)
     return (_pprev == pprev);
 }
 
+/*
+ * called by:
+ *   - common/timer.c|211| <<add_entry>> return add_to_list(&timers->list, t);
+ */
 static int add_to_list(struct timer **pprev, struct timer *t)
 {
     struct timer *curr, **_pprev = pprev;
@@ -170,6 +274,9 @@ static int add_to_list(struct timer **pprev, struct timer *t)
  * TIMER OPERATIONS.
  */
 
+/*
+ * 在heap或者list上移除, 设置状态为TIMER_STATUS_invalid
+ */
 static int remove_entry(struct timer *t)
 {
     struct timers *timers = &per_cpu(timers, t->cpu);
@@ -192,8 +299,20 @@ static int remove_entry(struct timer *t)
     return rc;
 }
 
+/*
+ * called by:
+ *   - common/timer.c|220| <<activate_timer>> if ( add_entry(timer) )
+ *   - common/timer.c|499| <<timer_softirq_action>> add_entry(t);
+ *   - common/timer.c|584| <<migrate_timers_from_cpu>> notify |= add_entry(t);
+ *
+ * 先添加到heap, 设置状态为TIMER_STATUS_in_heap
+ * 否则添加到list, 设置状态为TIMER_STATUS_in_list
+ */
 static int add_entry(struct timer *t)
 {
+    /*
+     * 定义在最开始: static DEFINE_PER_CPU(struct timers, timers);
+     */
     struct timers *timers = &per_cpu(timers, t->cpu);
     int rc;
 
@@ -211,18 +330,44 @@ static int add_entry(struct timer *t)
     return add_to_list(&timers->list, t);
 }
 
+/*
+ * called by:
+ *   - common/timer.c|315| <<set_timer>> activate_timer(timer);
+ *   - common/timer.c|395| <<migrate_timer>> activate_timer(timer);
+ *
+ * 先从timers->inactive上删除(设置状态为TIMER_STATUS_invalid)
+ * 然后先添加到heap, 设置状态为TIMER_STATUS_in_heap
+ * 否则添加到list, 设置状态为TIMER_STATUS_in_list
+ */
 static inline void activate_timer(struct timer *timer)
 {
     ASSERT(timer->status == TIMER_STATUS_inactive);
     timer->status = TIMER_STATUS_invalid;
     list_del(&timer->inactive);
 
+    /*
+     * 先添加到heap, 设置状态为TIMER_STATUS_in_heap
+     * 否则添加到list, 设置状态为TIMER_STATUS_in_list
+     */
     if ( add_entry(timer) )
         cpu_raise_softirq(timer->cpu, TIMER_SOFTIRQ);
 }
 
+/*
+ * called by:
+ *   - common/timer.c|429| <<set_timer>> deactivate_timer(timer);
+ *   - common/timer.c|473| <<stop_timer>> deactivate_timer(timer);
+ *   - common/timer.c|551| <<migrate_timer>> deactivate_timer(timer);
+ *   - common/timer.c|607| <<kill_timer>> deactivate_timer(timer);
+ *
+ * 在heap或者list上移除, 设置状态为TIMER_STATUS_invalid
+ * 然后把状态设置为TIMER_STATUS_inactive, 添加到timers->inactive上
+ */
 static inline void deactivate_timer(struct timer *timer)
 {
+    /*
+     * 在heap或者list上移除, 设置状态为TIMER_STATUS_invalid
+     */
     if ( remove_entry(timer) )
         cpu_raise_softirq(timer->cpu, TIMER_SOFTIRQ);
 
@@ -273,6 +418,17 @@ static inline void timer_unlock(struct timer *timer)
 })
 
 
+/*
+ * called by:
+ *   - common/timer.c|428| <<set_timer>> if ( active_timer(timer) )
+ *   - common/timer.c|472| <<stop_timer>> if ( active_timer(timer) )
+ *   - common/timer.c|486| <<timer_expires_before>> ret = active_timer(timer) && timer->expires <= t;
+ *   - common/timer.c|549| <<migrate_timer>> active = active_timer(timer);
+ *   - common/timer.c|606| <<kill_timer>> if ( active_timer(timer) )
+ *
+ * 如果状态是TIMER_STATUS_in_heap或者TIMER_STATUS_in_list返回true
+ * 也就是说如果在timers->head或者timers->list上返回true
+ */
 static bool_t active_timer(struct timer *timer)
 {
     ASSERT(timer->status >= TIMER_STATUS_inactive);
@@ -281,6 +437,37 @@ static bool_t active_timer(struct timer *timer)
 }
 
 
+/*
+ * called by:
+ *   - arch/x86/cpu/mcheck/amd_nonfatal.c|244| <<amd_nonfatal_mcheck_init>> init_timer(&mce_timer, mce_amd_work_fn, NULL, 0);
+ *   - arch/x86/cpu/mcheck/non-fatal.c|109| <<init_nonfatal_mce_checker>> init_timer(&mce_timer, mce_work_fn, NULL, 0);
+ *   - arch/x86/hvm/pmtimer.c|367| <<pmtimer_init>> init_timer(&s->timer, pmt_timer_callback, s, v->processor);
+ *   - arch/x86/hvm/rtc.c|811| <<rtc_init>> init_timer(&s->update_timer, rtc_update_timer, s, smp_processor_id());
+ *   - arch/x86/hvm/rtc.c|812| <<rtc_init>> init_timer(&s->update_timer2, rtc_update_timer2, s, smp_processor_id());
+ *   - arch/x86/hvm/rtc.c|813| <<rtc_init>> init_timer(&s->alarm_timer, rtc_alarm_cb, s, smp_processor_id());
+ *   - arch/x86/hvm/vpt.c|633| <<create_periodic_time>> init_timer(&pt->timer, pt_timer_fn, pt, v->processor);
+ *   - arch/x86/irq.c|958| <<irq_ratelimit_init>> init_timer(&irq_ratelimit_timer, irq_ratelimit_timer_fn, NULL, 0);
+ *   - arch/x86/irq.c|1628| <<pirq_guest_bind>> init_timer(&action->eoi_timer, irq_guest_eoi_timer_fn, desc, 0);
+ *   - arch/x86/nmi.c|439| <<cpu_nmi_callback>> init_timer(&per_cpu(nmi_timer, cpu), nmi_timer_fn, NULL, cpu);
+ *   - arch/x86/time.c|1752| <<try_platform_timer_tail>> init_timer(&plt_overflow_timer, plt_overflow, NULL, 0);
+ *   - arch/x86/time.c|1761| <<try_platform_timer_tail>> init_timer(&calibration_timer, time_calibration, NULL, 0);
+ *   - common/rcupdate.c|566| <<rcu_init_percpu_data>> init_timer(&rdp->idle_timer, rcu_idle_timer_handler, rdp, cpu);
+ *   - common/sched_credit.c|592| <<init_pdata>> init_timer(&prv->master_ticker, csched_acct, prv, cpu);
+ *   - common/sched_credit.c|600| <<init_pdata>> init_timer(&spc->ticker, csched_tick, (void *)(unsigned long )cpu, cpu);
+ *   - common/sched_credit2.c|3063| <<csched2_alloc_domdata>> init_timer(&sdom->repl_timer, replenish_domain_budget, sdom,
+ *   - common/sched_rt.c|720| <<rt_init_pdata>> init_timer(&prv->repl_timer, repl_timer_handler, (void *)ops, cpu);
+ *   - common/sched_rt.c|759| <<rt_switch_sched>> init_timer(&prv->repl_timer, repl_timer_handler, (void *)new_ops, cpu);
+ *   - common/schedule.c|266| <<sched_init_vcpu>> init_timer(&v->periodic_timer, vcpu_periodic_timer_fn,
+ *   - common/schedule.c|268| <<sched_init_vcpu>> init_timer(&v->singleshot_timer, vcpu_singleshot_timer_fn,
+ *   - common/schedule.c|270| <<sched_init_vcpu>> init_timer(&v->poll_timer, poll_timer_fn,
+ *   - common/schedule.c|1164| <<watchdog_domain_init>> init_timer(&d->watchdog_timer[i], domain_watchdog_timeout, d, 0);
+ *   - common/schedule.c|1640| <<cpu_schedule_up>> init_timer(&sd->s_timer, s_timer_fn, NULL, cpu);
+ *   - drivers/char/ehci-dbgp.c|1361| <<ehci_dbgp_init_postirq>> init_timer(&dbgp->timer, ehci_dbgp_poll, port, 0);
+ *   - drivers/char/ns16550.c|752| <<ns16550_init_postirq>> init_timer(&uart->timer, ns16550_poll, port, 0);
+ *   - drivers/char/ns16550.c|753| <<ns16550_init_postirq>> init_timer(&uart->resume_timer, ns16550_delayed_resume, port, 0);
+ *   - drivers/cpufreq/cpufreq_ondemand.c|192| <<dbs_timer_init>> init_timer(&per_cpu(dbs_timer, dbs_info->cpu), do_dbs_timer,
+ *   - drivers/passthrough/io.c|566| <<pt_irq_create_bind>> init_timer(&pirq_dpci->timer, pt_irq_time_out, pirq_dpci, 0);
+ */
 void init_timer(
     struct timer *timer,
     void        (*function)(void *),
@@ -300,6 +487,18 @@ void init_timer(
 }
 
 
+/*
+ * 一个例子:
+ * [0] set_timer
+ * [0] pt_intr_post
+ * [0] vmx_intr_assist
+ *
+ * 被很多调用, vpt的例子:
+ *   - arch/x86/hvm/vpt.c|298| <<pt_restore_timer>> set_timer(&pt->timer, pt->scheduled);
+ *   - arch/x86/hvm/vpt.c|348| <<pt_irq_fired>> set_timer(&pt->timer, pt->scheduled);
+ *   - arch/x86/hvm/vpt.c|368| <<pt_irq_fired>> set_timer(&pt->timer, pt->scheduled);
+ *   - arch/x86/hvm/vpt.c|645| <<create_periodic_time>> set_timer(&pt->timer, pt->scheduled);
+ */
 void set_timer(struct timer *timer, s_time_t expires)
 {
     unsigned long flags;
@@ -307,17 +506,60 @@ void set_timer(struct timer *timer, s_time_t expires)
     if ( !timer_lock_irqsave(timer, flags) )
         return;
 
+    /*
+     * active_timer():
+     *
+     * 如果状态是TIMER_STATUS_in_heap或者TIMER_STATUS_in_list返回true
+     * 也就是说如果在timers->head或者timers->list上返回true
+     *
+     *
+     * deactivate_timer():
+     *
+     * 在heap或者list上移除, 设置状态为TIMER_STATUS_invalid
+     * 然后把状态设置为TIMER_STATUS_inactive, 添加到timers->inactive上
+     */
     if ( active_timer(timer) )
         deactivate_timer(timer);
 
     timer->expires = expires;
 
+    /*
+     * 先从timers->inactive上删除(设置状态为TIMER_STATUS_invalid)
+     * 然后先添加到heap, 设置状态为TIMER_STATUS_in_heap
+     * 否则添加到list, 设置状态为TIMER_STATUS_in_list
+     */
     activate_timer(timer);
 
     timer_unlock_irqrestore(timer, flags);
 }
 
 
+/*
+ * called by:
+ *   - arch/arm/vtimer.c|159| <<virt_timer_restore>> stop_timer(&v->arch.virt_timer.timer);
+ *   - arch/arm/vtimer.c|193| <<vtimer_cntp_ctl>> stop_timer(&v->arch.phys_timer.timer);
+ *   - arch/x86/hvm/rtc.c|181| <<check_update_timer>> stop_timer(&s->update_timer);
+ *   - arch/x86/hvm/rtc.c|182| <<check_update_timer>> stop_timer(&s->update_timer2);
+ *   - arch/x86/hvm/rtc.c|258| <<alarm_timer_update>> stop_timer(&s->alarm_timer);
+ *   - arch/x86/hvm/vpt.c|279| <<pt_save_timer>> stop_timer(&pt->timer);
+ *   - arch/x86/irq.c|1263| <<__do_IRQ_guest>> stop_timer(&action->eoi_timer);
+ *   - arch/x86/pv/shim.c|415| <<pv_shim_shutdown>> stop_timer(&v->singleshot_timer);
+ *   - common/domain.c|1514| <<XEN_GUEST_HANDLE_PARAM>> stop_timer(&v->singleshot_timer);
+ *   - common/rcupdate.c|503| <<rcu_idle_timer_stop>> stop_timer(&rdp->idle_timer);
+ *   - common/sched_credit.c|2246| <<csched_tick_suspend>> stop_timer(&spc->ticker);
+ *   - common/sched_credit2.c|2959| <<csched2_dom_cntl>> stop_timer(&sdom->repl_timer);
+ *   - common/sched_rt.c|554| <<replq_remove>> stop_timer(&prv->repl_timer);
+ *   - common/schedule.c|1143| <<domain_watchdog>> stop_timer(&d->watchdog_timer[id]);
+ *   - common/schedule.c|1358| <<do_set_timer_op>> stop_timer(&v->singleshot_timer);
+ *   - common/schedule.c|1515| <<schedule>> stop_timer(&sd->s_timer);
+ *   - common/schedule.c|1576| <<schedule>> stop_timer(&prev->periodic_timer);
+ *   - drivers/char/ehci-dbgp.c|1415| <<ehci_dbgp_suspend>> stop_timer(&dbgp->timer);
+ *   - drivers/char/ns16550.c|845| <<ns16550_suspend>> stop_timer(&uart->timer);
+ *   - drivers/cpufreq/cpufreq_ondemand.c|373| <<cpufreq_dbs_timer_suspend>> stop_timer( &per_cpu(dbs_timer, cpu) );
+ *   - drivers/passthrough/io.c|969| <<hvm_pirq_eoi>> stop_timer(&pirq_dpci->timer);
+ *   - drivers/passthrough/vtd/x86/hvm.c|40| <<_hvm_dpci_isairq_eoi>> stop_timer(&pirq_dpci->timer);
+ *   - include/xen/timer.h|71| <<_hvm_dpci_isairq_eoi>> void stop_timer(struct timer *timer);
+ */
 void stop_timer(struct timer *timer)
 {
     unsigned long flags;
@@ -331,6 +573,10 @@ void stop_timer(struct timer *timer)
     timer_unlock_irqrestore(timer, flags);
 }
 
+/*
+ * called by:
+ *   - include/xen/timer.h|76| <<timer_is_expired>> #define timer_is_expired(t) timer_expires_before(t, NOW())
+ */
 bool timer_expires_before(struct timer *timer, s_time_t t)
 {
     unsigned long flags;
@@ -346,6 +592,25 @@ bool timer_expires_before(struct timer *timer, s_time_t t)
     return ret;
 }
 
+/*
+ * called by:
+ *   - arch/arm/vtimer.c|160| <<virt_timer_restore>> migrate_timer(&v->arch.virt_timer.timer, v->processor);
+ *   - arch/arm/vtimer.c|161| <<virt_timer_restore>> migrate_timer(&v->arch.phys_timer.timer, v->processor);
+ *   - arch/x86/hvm/rtc.c|733| <<rtc_migrate_timers>> migrate_timer(&s->update_timer, v->processor);
+ *   - arch/x86/hvm/rtc.c|734| <<rtc_migrate_timers>> migrate_timer(&s->update_timer2, v->processor);
+ *   - arch/x86/hvm/rtc.c|735| <<rtc_migrate_timers>> migrate_timer(&s->alarm_timer, v->processor);
+ *   - arch/x86/hvm/vpt.c|565| <<pt_migrate>> migrate_timer(&pt->timer, v->processor);
+ *   - arch/x86/hvm/vpt.c|721| <<pt_adjust_vcpu>> migrate_timer(&pt->timer, v->processor);
+ *   - arch/x86/irq.c|1264| <<__do_IRQ_guest>> migrate_timer(&action->eoi_timer, smp_processor_id());
+ *   - common/domain.c|1504| <<XEN_GUEST_HANDLE_PARAM(VCPUOP_set_singleshot_timer)>> migrate_timer(&v->singleshot_timer, smp_processor_id());
+ *   - common/sched_credit.c|550| <<csched_deinit_pdata>> migrate_timer(&prv->master_ticker, prv->master);
+ *   - common/sched_rt.c|801| <<rt_deinit_pdata>> migrate_timer(&prv->repl_timer, new_cpu);
+ *   - common/schedule.c|368| <<sched_move_domain>> migrate_timer(&v->periodic_timer, new_p);
+ *   - common/schedule.c|369| <<sched_move_domain>> migrate_timer(&v->singleshot_timer, new_p);
+ *   - common/schedule.c|370| <<sched_move_domain>> migrate_timer(&v->poll_timer, new_p);
+ *   - common/schedule.c|1380| <<do_set_timer_op>> migrate_timer(&v->singleshot_timer, smp_processor_id());
+ *   - common/schedule.c|1466| <<vcpu_periodic_timer_work>> migrate_timer(&v->periodic_timer, smp_processor_id());
+ */
 void migrate_timer(struct timer *timer, unsigned int new_cpu)
 {
     unsigned int old_cpu;
@@ -383,14 +648,35 @@ void migrate_timer(struct timer *timer, unsigned int new_cpu)
 
     rcu_read_unlock(&timer_cpu_read_lock);
 
+    /*
+     * 如果状态是TIMER_STATUS_in_heap或者TIMER_STATUS_in_list返回true
+     * 也就是说如果在timers->head或者timers->list上返回true
+     */
     active = active_timer(timer);
+    /*
+     * deactivate_timer():
+     * 在heap或者list上移除, 设置状态为TIMER_STATUS_invalid
+     * 然后把状态设置为TIMER_STATUS_inactive, 添加到timers->inactive上
+     */
     if ( active )
         deactivate_timer(timer);
 
+    /*
+     * 从旧的cpu上把timer移除
+     */
     list_del(&timer->inactive);
     write_atomic(&timer->cpu, new_cpu);
+    /*
+     * 把timer添加到新的cpu的timers->inactive上
+     */
     list_add(&timer->inactive, &per_cpu(timers, new_cpu).inactive);
 
+    /*
+     * activate_timer():
+     * 先从timers->inactive上删除(设置状态为TIMER_STATUS_invalid)
+     * 然后先添加到heap, 设置状态为TIMER_STATUS_in_heap
+     * 否则添加到list, 设置状态为TIMER_STATUS_in_list
+     */
     if ( active )
         activate_timer(timer);
 
@@ -399,6 +685,37 @@ void migrate_timer(struct timer *timer, unsigned int new_cpu)
 }
 
 
+/*
+ * called by:
+ *   - arch/arm/vtimer.c|135| <<vcpu_timer_destroy>> kill_timer(&v->arch.virt_timer.timer);
+ *   - arch/arm/vtimer.c|136| <<vcpu_timer_destroy>> kill_timer(&v->arch.phys_timer.timer);
+ *   - arch/x86/hvm/pmtimer.c|379| <<pmtimer_deinit>> kill_timer(&s->timer);
+ *   - arch/x86/hvm/rtc.c|846| <<rtc_deinit>> kill_timer(&s->update_timer);
+ *   - arch/x86/hvm/rtc.c|847| <<rtc_deinit>> kill_timer(&s->update_timer2);
+ *   - arch/x86/hvm/rtc.c|848| <<rtc_deinit>> kill_timer(&s->alarm_timer);
+ *   - arch/x86/hvm/vpt.c|686| <<destroy_periodic_time>> kill_timer(&pt->timer);
+ *   - arch/x86/irq.c|1872| <<pirq_guest_unbind>> kill_timer(&oldaction->eoi_timer);
+ *   - arch/x86/irq.c|1917| <<pirq_guest_force_unbind>> kill_timer(&oldaction->eoi_timer);
+ *   - arch/x86/nmi.c|444| <<cpu_nmi_callback>> kill_timer(&per_cpu(nmi_timer, cpu));
+ *   - arch/x86/time.c|727| <<reset_platform_timer>> kill_timer(&plt_overflow_timer);
+ *   - arch/x86/time.c|728| <<reset_platform_timer>> kill_timer(&calibration_timer);
+ *   - arch/x86/time.c|1973| <<time_suspend>> kill_timer(&calibration_timer);
+ *   - common/rcupdate.c|536| <<rcu_offline_cpu>> kill_timer(&rdp->idle_timer);
+ *   - common/sched_credit.c|558| <<csched_deinit_pdata>> kill_timer(&spc->ticker);
+ *   - common/sched_credit.c|560| <<csched_deinit_pdata>> kill_timer(&prv->master_ticker);
+ *   - common/sched_credit2.c|3087| <<csched2_free_domdata>> kill_timer(&sdom->repl_timer);
+ *   - common/sched_rt.c|796| <<rt_deinit_pdata>> kill_timer(&prv->repl_timer);
+ *   - common/schedule.c|410| <<sched_destroy_vcpu>> kill_timer(&v->periodic_timer);
+ *   - common/schedule.c|411| <<sched_destroy_vcpu>> kill_timer(&v->singleshot_timer);
+ *   - common/schedule.c|412| <<sched_destroy_vcpu>> kill_timer(&v->poll_timer);
+ *   - common/schedule.c|1172| <<watchdog_domain_destroy>> kill_timer(&d->watchdog_timer[i]);
+ *   - common/schedule.c|1698| <<cpu_schedule_down>> kill_timer(&sd->s_timer);
+ *   - drivers/char/ehci-dbgp.c|1390| <<ehci_dbgp_check_release>> kill_timer(&dbgp->timer);
+ *   - drivers/cpufreq/cpufreq_ondemand.c|215| <<dbs_timer_exit>> kill_timer(&per_cpu(dbs_timer, dbs_info->cpu));
+ *   - drivers/passthrough/io.c|572| <<pt_irq_create_bind>> kill_timer(&pirq_dpci->timer);
+ *   - drivers/passthrough/io.c|740| <<pt_irq_destroy_bind>> kill_timer(&pirq_dpci->timer);
+ *   - drivers/passthrough/pci.c|872| <<pci_clean_dpci_irq>> kill_timer(&pirq_dpci->timer);
+ */
 void kill_timer(struct timer *timer)
 {
     unsigned int old_cpu, cpu;
@@ -425,6 +742,15 @@ void kill_timer(struct timer *timer)
 }
 
 
+/*
+ * called by:
+ *   - common/timer.c|617| <<timer_softirq_action>> execute_timer(ts, t);
+ *   - common/timer.c|624| <<timer_softirq_action>> execute_timer(ts, t);
+ *
+ * 把状态设置为TIMER_STATUS_inactive
+ * 放入timers->inactive
+ * 调用timer的function()
+ */
 static void execute_timer(struct timers *ts, struct timer *t)
 {
     void (*fn)(void *) = t->function;
@@ -456,6 +782,23 @@ static void timer_softirq_action(void)
         /* old_limit == (2^n)-1; new_limit == (2^(n+4))-1 */
         int old_limit = GET_HEAP_LIMIT(heap);
         int new_limit = ((old_limit + 1) << 4) - 1;
+        /*
+	 * * 一般来说, struct timer **h是二维指针
+	 *
+	 * **h ---> -------------------
+	 *          |  h[0] reserverd |----> 在地址里保存limit和size
+	 *          |-----------------|
+	 *          |  struct timer * |-----> struct timer
+	 *          |-----------------|
+	 *          |  struct timer * |-----> struct timer
+	 *          |-----------------|
+	 *          |  struct timer * |-----> struct timer
+	 *          |-----------------|
+	 *          |  struct timer * |-----> struct timer
+	 *          |-----------------|
+	 *
+	 * 这里分配的时候new_limit后面有个+1
+	 */
         struct timer **newheap = xmalloc_array(struct timer *, new_limit + 1);
         if ( newheap != NULL )
         {
@@ -464,12 +807,19 @@ static void timer_softirq_action(void)
             SET_HEAP_LIMIT(newheap, new_limit);
             ts->heap = newheap;
             spin_unlock_irq(&ts->lock);
+            /*
+	     * 这里判断不为0是为了dummy_heap
+	     */
             if ( old_limit != 0 )
                 xfree(heap);
             heap = newheap;
         }
     }
 
+    /*
+     * 上面按照list的分配了heap, 但是没有把list的放入heap!!!
+     */
+
     spin_lock_irq(&ts->lock);
 
     now = NOW();
@@ -479,6 +829,11 @@ static void timer_softirq_action(void)
             ((t = heap[1])->expires < now) )
     {
         remove_from_heap(heap, t);
+	/*
+	 * 把状态设置为TIMER_STATUS_inactive
+	 * 放入timers->inactive
+	 * 调用timer的function()
+	 */
         execute_timer(ts, t);
     }
 
@@ -486,10 +841,18 @@ static void timer_softirq_action(void)
     while ( ((t = ts->list) != NULL) && (t->expires < now) )
     {
         ts->list = t->list_next;
+	/*
+	 * 把状态设置为TIMER_STATUS_inactive
+	 * 放入timers->inactive
+	 * 调用timer的function()
+	 */
         execute_timer(ts, t);
     }
 
     /* Try to move timers from linked list to more efficient heap. */
+    /*
+     * 把剩下list上的全部放入heap
+     */
     next = ts->list;
     ts->list = NULL;
     while ( unlikely((t = next) != NULL) )
@@ -515,6 +878,14 @@ static void timer_softirq_action(void)
     spin_unlock_irq(&ts->lock);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpt.c|627| <<create_periodic_time>> pt->scheduled = align_timer(pt->scheduled, pt->period);
+ *   - drivers/cpufreq/cpufreq_ondemand.c|185| <<do_dbs_timer>> align_timer(NOW() , dbs_tuners_ins.sampling_rate));
+ *   - drivers/cpufreq/cpufreq_ondemand.c|395| <<cpufreq_dbs_timer_resume>> set_timer(t, align_timer(now, dbs_tuners_ins.sampling_rate));
+ *
+ * Calculate the aligned first tick time for a given periodic timer.
+ */
 s_time_t align_timer(s_time_t firsttick, uint64_t period)
 {
     if ( !period )
@@ -553,6 +924,10 @@ static void dump_timerq(unsigned char key)
     }
 }
 
+/*
+ * called by only:
+ *   - common/timer.c|706| <<cpu_callback>> migrate_timers_from_cpu(cpu);
+ */
 static void migrate_timers_from_cpu(unsigned int old_cpu)
 {
     unsigned int new_cpu = cpumask_any(&cpu_online_map);
@@ -599,6 +974,12 @@ static void migrate_timers_from_cpu(unsigned int old_cpu)
         cpu_raise_softirq(new_cpu, TIMER_SOFTIRQ);
 }
 
+/*
+ * used by:
+ *   - common/timer.c|696| <<cpu_callback>> ts->heap = &dummy_heap;
+ *   - common/timer.c|724| <<timer_init>> SET_HEAP_SIZE(&dummy_heap, 0);
+ *   - common/timer.c|725| <<timer_init>> SET_HEAP_LIMIT(&dummy_heap, 0);
+ */
 static struct timer *dummy_heap;
 
 static int cpu_callback(
diff --git a/xen/include/asm-x86/hvm/hvm.h b/xen/include/asm-x86/hvm/hvm.h
index 53ffebb..8f2ec45 100644
--- a/xen/include/asm-x86/hvm/hvm.h
+++ b/xen/include/asm-x86/hvm/hvm.h
@@ -38,6 +38,17 @@ extern bool_t opt_hvm_fep;
 enum hvm_intsrc {
     hvm_intsrc_none,
     hvm_intsrc_pic,
+    /*
+     * 在以下使用:
+     *   - arch/x86/hvm/hvm.c|3796| <<hvm_interrupt_blocked>> if ( intack.source == hvm_intsrc_lapic )
+     *   - arch/x86/hvm/irq.c|561| <<hvm_vcpu_ack_pending_irq>> case hvm_intsrc_lapic:
+     *   - arch/x86/hvm/svm/intr.c|128| <<svm_enable_intr_window>> intr.fields.ign_tpr = (intack.source != hvm_intsrc_lapic);
+     *   - arch/x86/hvm/svm/nestedsvm.c|1564| <<nestedsvm_vcpu_interrupt>> case hvm_intsrc_lapic:
+     *   - arch/x86/hvm/vmx/intr.c|197| <<nvmx_intr_intercept>> intack.source == hvm_intsrc_lapic )
+     *   - arch/x86/hvm/vmx/intr.c|286| <<vmx_intr_assist>> ASSERT(intack.source == hvm_intsrc_lapic);
+     *   - arch/x86/hvm/vmx/vvmx.c|1308| <<nvmx_update_apicv>> nvmx->intr.source == hvm_intsrc_lapic &&
+     *   - arch/x86/hvm/vpt.c|148| <<pt_irq_vector>> ASSERT(src == hvm_intsrc_lapic);
+     */
     hvm_intsrc_lapic,
     hvm_intsrc_nmi,
     hvm_intsrc_mce,
diff --git a/xen/include/asm-x86/hvm/vcpu.h b/xen/include/asm-x86/hvm/vcpu.h
index 6c84d5a..09f3ac2 100644
--- a/xen/include/asm-x86/hvm/vcpu.h
+++ b/xen/include/asm-x86/hvm/vcpu.h
@@ -167,6 +167,20 @@ struct hvm_vcpu {
 
     /* Lock and list for virtual platform timers. */
     spinlock_t          tm_lock;
+    /*
+     * used by:
+     *   - arch/x86/domain.c|1740| <<context_switch>> if ( is_hvm_domain(prevd) && !list_empty(&prev->arch.hvm.tm_list) )
+     *   - arch/x86/hvm/hvm.c|1506| <<hvm_vcpu_initialise>> INIT_LIST_HEAD(&v->arch.hvm.tm_list);
+     *   - arch/x86/hvm/vpt.c|269| <<pt_save_timer>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|288| <<pt_restore_timer>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|373| <<pt_update_irq>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|466| <<pt_update_irq>> list_for_each_entry ( pt, &v->arch.hvm.tm_list, list )
+     *   - arch/x86/hvm/vpt.c|493| <<is_pt_irq>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|548| <<pt_migrate>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|631| <<create_periodic_time>> list_add(&pt->list, &v->arch.hvm.tm_list);
+     *   - arch/x86/hvm/vpt.c|708| <<pt_adjust_vcpu>> list_add(&pt->list, &v->arch.hvm.tm_list);
+     *   - arch/x86/hvm/vpt.c|756| <<pt_resume>> list_add(&pt->list, &pt->vcpu->arch.hvm.tm_list);
+     */
     struct list_head    tm_list;
 
     bool                flag_dr_dirty;
diff --git a/xen/include/asm-x86/hvm/vlapic.h b/xen/include/asm-x86/hvm/vlapic.h
index dde66b4..593553d 100644
--- a/xen/include/asm-x86/hvm/vlapic.h
+++ b/xen/include/asm-x86/hvm/vlapic.h
@@ -42,7 +42,21 @@
  *  2. 'Software disable': via APIC_SPIV[8].
  *     APIC is visible but does not respond to interrupt messages.
  */
+/*
+ * used by:
+ *   - arch/x86/hvm/vlapic.c|1140| <<guest_wrmsr_apic_base>> vlapic->hw.disabled &= ~VLAPIC_HW_DISABLED;
+ *   - arch/x86/hvm/vlapic.c|1145| <<guest_wrmsr_apic_base>> vlapic->hw.disabled |= VLAPIC_HW_DISABLED;
+ *   - arch/x86/hvm/vlapic.c|1591| <<vlapic_init>> vlapic->hw.disabled = VLAPIC_HW_DISABLED;
+ *   - include/asm-x86/hvm/vlapic.h|48| <<vlapic_hw_disabled>> #define vlapic_hw_disabled(vlapic) ((vlapic)->hw.disabled & VLAPIC_HW_DISABLED)
+ */
 #define VLAPIC_HW_DISABLED              0x1
+/*
+ * used by:
+ *   - arch/x86/hvm/vlapic.c|814| <<vlapic_reg_write>> vlapic->hw.disabled |= VLAPIC_SW_DISABLED;
+ *   - arch/x86/hvm/vlapic.c|825| <<vlapic_reg_write>> vlapic->hw.disabled &= ~VLAPIC_SW_DISABLED;
+ *   - arch/x86/hvm/vlapic.c|1409| <<vlapic_do_init>> vlapic->hw.disabled |= VLAPIC_SW_DISABLED;
+ *   - include/asm-x86/hvm/vlapic.h|47| <<vlapic_sw_disabled>> #define vlapic_sw_disabled(vlapic) ((vlapic)->hw.disabled & VLAPIC_SW_DISABLED)
+ */
 #define VLAPIC_SW_DISABLED              0x2
 #define vlapic_sw_disabled(vlapic) ((vlapic)->hw.disabled & VLAPIC_SW_DISABLED)
 #define vlapic_hw_disabled(vlapic) ((vlapic)->hw.disabled & VLAPIC_HW_DISABLED)
diff --git a/xen/include/asm-x86/hvm/vmx/vmcs.h b/xen/include/asm-x86/hvm/vmx/vmcs.h
index b3e8001..4da9802 100644
--- a/xen/include/asm-x86/hvm/vmx/vmcs.h
+++ b/xen/include/asm-x86/hvm/vmx/vmcs.h
@@ -194,6 +194,15 @@ void vmx_vmcs_reload(struct vcpu *v);
 #define CPU_BASED_VIRTUAL_INTR_PENDING        0x00000004
 #define CPU_BASED_USE_TSC_OFFSETING           0x00000008
 #define CPU_BASED_HLT_EXITING                 0x00000080
+/*
+ * used by:
+ *   - arch/x86/hvm/vmx/vmcs.c|196| <<vmx_init_vmcs_config>> CPU_BASED_INVLPG_EXITING |
+ *   - arch/x86/hvm/vmx/vmcs.c|309| <<vmx_init_vmcs_config>> if ( must_be_one & (CPU_BASED_INVLPG_EXITING |
+ *   - arch/x86/hvm/vmx/vmcs.c|1022| <<construct_vmcs>> v->arch.hvm.vmx.exec_control &= ~(CPU_BASED_INVLPG_EXITING |
+ *   - arch/x86/hvm/vmx/vvmx.c|2152| <<nvmx_msr_read_intercept>> CPU_BASED_INVLPG_EXITING |
+ *   - arch/x86/hvm/vmx/vvmx.c|2173| <<nvmx_msr_read_intercept>> CPU_BASED_INVLPG_EXITING);
+ *   - arch/x86/hvm/vmx/vvmx.c|2533| <<nvmx_n2_vmexit_handler>> if ( ctrl & CPU_BASED_INVLPG_EXITING )
+ */
 #define CPU_BASED_INVLPG_EXITING              0x00000200
 #define CPU_BASED_MWAIT_EXITING               0x00000400
 #define CPU_BASED_RDPMC_EXITING               0x00000800
diff --git a/xen/include/asm-x86/hvm/vpt.h b/xen/include/asm-x86/hvm/vpt.h
index 99169dd..784b3cb 100644
--- a/xen/include/asm-x86/hvm/vpt.h
+++ b/xen/include/asm-x86/hvm/vpt.h
@@ -36,22 +36,114 @@
 typedef void time_cb(struct vcpu *v, void *opaque);
 
 struct periodic_time {
+    /*
+     * 用来挂载在v->arch.hvm.tm_list
+     */
     struct list_head list;
     bool on_list;
+    /*
+     * 在以下修改:
+     *   - arch/x86/hvm/vpt.c|627| <<create_periodic_time>> pt->one_shot = !period;
+     */
     bool one_shot;
+    /*
+     * used by:
+     *   - arch/x86/hvm/vpt.c|289| <<pt_process_missed_ticks>> pt->do_not_freeze = !pt->pending_intr_nr;
+     *   - arch/x86/hvm/vpt.c|338| <<pt_save_timer>> if ( !pt->do_not_freeze )
+     *   - arch/x86/hvm/vpt.c|383| <<pt_timer_fn>> pt->do_not_freeze = 0;
+     *   - arch/x86/hvm/vpt.c|664| <<create_periodic_time>> pt->do_not_freeze = 0;
+     */
     bool do_not_freeze;
+    /*
+     * used by:
+     *   - arch/x86/hvm/vpt.c|397| <<pt_irq_fired>> pt->irq_issued = false;
+     *   - arch/x86/hvm/vpt.c|488| <<pt_update_irq>> earliest_pt->irq_issued = 1;
+     *   - arch/x86/hvm/vpt.c|573| <<is_pt_irq>> if ( pt->pending_intr_nr && pt->irq_issued &&
+     *   - arch/x86/hvm/vpt.c|665| <<create_periodic_time>> pt->irq_issued = 0;
+     */
     bool irq_issued;
+    /*
+     * 只在下面使用:
+     *   - arch/x86/hvm/vpt.c|670| <<create_periodic_time>> if ( !test_and_set_bool(pt->warned_timeout_too_short) )
+     */
     bool warned_timeout_too_short;
     bool level;
 #define PTSRC_isa    1 /* ISA time source */
 #define PTSRC_lapic  2 /* LAPIC time source */
 #define PTSRC_ioapic 3 /* IOAPIC time source */
+    /*
+     * 在以下设置:
+     *   - arch/x86/emul-i8254.c|495| <<pit_reset>> pit->pt0.source = PTSRC_isa;
+     *   - arch/x86/hvm/hpet.c|289| <<hpet_set_timer>> h->pt[tn].source = PTSRC_isa;
+     *   - arch/x86/hvm/hpet.c|294| <<hpet_set_timer>> h->pt[tn].source = PTSRC_ioapic;
+     *   - arch/x86/hvm/hpet.c|731| <<hpet_set>> h->pt[i].source = PTSRC_isa;
+     *   - arch/x86/hvm/rtc.c|799| <<rtc_reset>> s->pt.source = PTSRC_isa;
+     *   - arch/x86/hvm/vlapic.c|1664| <<vlapic_init>> vlapic->pt.source = PTSRC_lapic;
+     */
     u8 source;                  /* PTSRC_ */
     u8 irq;
     struct vcpu *vcpu;          /* vcpu timer interrupt delivers to */
+    /*
+     * used by:
+     *   - arch/x86/hvm/vpt.c|241| <<pt_process_missed_ticks>> pt->do_not_freeze = !pt->pending_intr_nr;
+     *   - arch/x86/hvm/vpt.c|243| <<pt_process_missed_ticks>> pt->pending_intr_nr += missed_ticks;
+     *   - arch/x86/hvm/vpt.c|295| <<pt_restore_timer>> if ( pt->pending_intr_nr == 0 )
+     *   - arch/x86/hvm/vpt.c|317| <<pt_timer_fn>> pt->pending_intr_nr++;
+     *   - arch/x86/hvm/vpt.c|340| <<pt_irq_fired>> pt->pending_intr_nr = 0;
+     *   - arch/x86/hvm/vpt.c|347| <<pt_irq_fired>> pt->pending_intr_nr = 0;
+     *   - arch/x86/hvm/vpt.c|353| <<pt_irq_fired>> if ( --pt->pending_intr_nr == 0 )
+     *   - arch/x86/hvm/vpt.c|356| <<pt_irq_fired>> if ( pt->pending_intr_nr == 0 )
+     *   - arch/x86/hvm/vpt.c|385| <<pt_update_irq>> if ( pt->pending_intr_nr )
+     *   - arch/x86/hvm/vpt.c|498| <<is_pt_irq>> if ( pt->pending_intr_nr && pt->irq_issued &&
+     *   - arch/x86/hvm/vpt.c|588| <<create_periodic_time>> pt->pending_intr_nr = 0;
+     *   - arch/x86/hvm/vpt.c|668| <<destroy_periodic_time>> pt->pending_intr_nr = 0;
+     *   - arch/x86/hvm/vpt.c|753| <<pt_resume>> if ( pt->pending_intr_nr && !pt->on_list )
+     *   - include/asm-x86/hvm/vpt.h|160| <<pt_active>> #define pt_active(pt) ((pt)->on_list || (pt)->pending_intr_nr)
+     */
     u32 pending_intr_nr;        /* pending timer interrupts */
+    /*
+     * periodic_time->period使用的地方:
+     *   - arch/x86/hvm/vpt.c|254| <<pt_process_missed_ticks>> missed_ticks = missed_ticks / (s_time_t) pt->period + 1;
+     *   - arch/x86/hvm/vpt.c|259| <<pt_process_missed_ticks>> pt->scheduled += missed_ticks * pt->period;
+     *   - arch/x86/hvm/vpt.c|333| <<pt_timer_fn>> pt->scheduled += pt->period;
+     *   - arch/x86/hvm/vpt.c|367| <<pt_irq_fired>> pt->last_plt_gtime += pt->period;
+     *   - arch/x86/hvm/vpt.c|424| <<pt_update_irq>> if ( (pt->last_plt_gtime + pt->period) < max_lag )
+     *   - arch/x86/hvm/vpt.c|426| <<pt_update_irq>> max_lag = pt->last_plt_gtime + pt->period;
+     *   - arch/x86/hvm/vpt.c|627| <<create_periodic_time>> pt->period = period;
+     *   - arch/x86/hvm/vpt.c|642| <<create_periodic_time>> pt->scheduled = align_timer(pt->scheduled, pt->period);
+     */
     u64 period;                 /* frequency in ns */
+    /*
+     * used by:
+     *   - arch/x86/hvm/vpt.c|235| <<pt_process_missed_ticks>> missed_ticks = now - pt->scheduled;
+     *   - arch/x86/hvm/vpt.c|244| <<pt_process_missed_ticks>> pt->scheduled += missed_ticks * pt->period;
+     *   - arch/x86/hvm/vpt.c|298| <<pt_restore_timer>> set_timer(&pt->timer, pt->scheduled);
+     *   - arch/x86/hvm/vpt.c|318| <<pt_timer_fn>> pt->scheduled += pt->period;
+     *   - arch/x86/hvm/vpt.c|348| <<pt_irq_fired>> set_timer(&pt->timer, pt->scheduled);
+     *   - arch/x86/hvm/vpt.c|357| <<pt_irq_fired>> set_timer(&pt->timer, pt->scheduled);
+     *   - arch/x86/hvm/vpt.c|607| <<create_periodic_time>> pt->scheduled = NOW() + delta;
+     *   - arch/x86/hvm/vpt.c|613| <<create_periodic_time>> pt->scheduled = align_timer(pt->scheduled, pt->period);
+     *   - arch/x86/hvm/vpt.c|623| <<create_periodic_time>> pt->scheduled += delta >> 1;
+     *   - arch/x86/hvm/vpt.c|634| <<create_periodic_time>> set_timer(&pt->timer, pt->scheduled);
+     */
     s_time_t scheduled;         /* scheduled timer interrupt */
+    /*
+     * 在以下设置last_plt_gtime:
+     *   - arch/x86/emul-i8254.c|465| <<pit_load>> pit->pt0.last_plt_gtime = get_guest_time(d->vcpu[0]);
+     *   - arch/x86/hvm/vpt.c|409| <<pt_irq_fired>> pt->last_plt_gtime = hvm_get_guest_time(v);
+     *   - arch/x86/hvm/vpt.c|416| <<pt_irq_fired>> pt->last_plt_gtime += pt->period;
+     *   - arch/x86/hvm/vpt.c|696| <<create_periodic_time>> pt->last_plt_gtime = hvm_get_guest_time(pt->vcpu);
+     *
+     * 在以下使用last_plt_gtime:
+     *   - arch/x86/hvm/vlapic.c|765| <<vlapic_update_timer>> vlapic->timer_last_update = vlapic->pt.last_plt_gtime;
+     *   - arch/x86/hvm/vlapic.c|1225| <<vlapic_tdt_msr_set>> vlapic->timer_last_update = vlapic->pt.last_plt_gtime;
+     *   - arch/x86/hvm/vlapic.c|1239| <<vlapic_tdt_msr_set>> vlapic->timer_last_update = vlapic->pt.last_plt_gtime;
+     *   - arch/x86/hvm/vlapic.c|1516| <<lapic_rearm>> s->timer_last_update = s->pt.last_plt_gtime;
+     *   - arch/x86/hvm/vpt.c|437| <<pt_irq_fired>> (hvm_get_guest_time(v) < pt->last_plt_gtime) )
+     *   - arch/x86/hvm/vpt.c|438| <<pt_irq_fired>> hvm_set_guest_time(v, pt->last_plt_gtime);
+     *   - arch/x86/hvm/vpt.c|473| <<pt_update_irq>> if ( (pt->last_plt_gtime + pt->period) < max_lag )
+     *   - arch/x86/hvm/vpt.c|475| <<pt_update_irq>> max_lag = pt->last_plt_gtime + pt->period;
+     */
     u64 last_plt_gtime;         /* platform time when last IRQ is injected */
     struct timer timer;         /* ac_timer */
     time_cb *cb;
@@ -66,6 +158,18 @@ typedef struct PITState {
     /* Hardware state */
     struct hvm_hw_pit hw;
     /* Last time the counters read zero, for calcuating counter reads */
+    /*
+     * used by:
+     *   - arch/x86/emul-i8254.c|89| <<pit_get_count>> d = muldiv64(get_guest_time(v) - pit->count_load_time[channel],
+     *   - arch/x86/emul-i8254.c|120| <<pit_get_out>> d = muldiv64(get_guest_time(v) - pit->count_load_time[channel],
+     *   - arch/x86/emul-i8254.c|167| <<pit_set_gate>> pit->count_load_time[channel] = get_guest_time(v);
+     *   - arch/x86/emul-i8254.c|187| <<pit_time_fired>> uint64_t *count_load_time = priv;
+     *   - arch/x86/emul-i8254.c|189| <<pit_time_fired>> *count_load_time = get_guest_time(v);
+     *   - arch/x86/emul-i8254.c|212| <<pit_load_count>> pit->count_load_time[channel] = 0;
+     *   - arch/x86/emul-i8254.c|214| <<pit_load_count>> pit->count_load_time[channel] = get_guest_time(v);
+     *   - arch/x86/emul-i8254.c|228| <<pit_load_count>> &pit->count_load_time[channel], false);
+     *   - arch/x86/emul-i8254.c|235| <<pit_load_count>> &pit->count_load_time[channel], false);
+     */
     int64_t count_load_time[3];
     /* Channel 0 IRQ handling. */
     struct periodic_time pt0;
diff --git a/xen/include/asm-x86/irq.h b/xen/include/asm-x86/irq.h
index 4b39997..be4aac6 100644
--- a/xen/include/asm-x86/irq.h
+++ b/xen/include/asm-x86/irq.h
@@ -49,6 +49,29 @@ struct arch_irq_desc {
 #define IRQ_VECTOR_UNASSIGNED (-1)
 
 typedef int vector_irq_t[NR_VECTORS];
+/*
+ * used by:
+ *   - arch/x86/irq.c|51| <<global>> DEFINE_PER_CPU(vector_irq_t, vector_irq);
+ *   - include/asm-x86/irq.h|52| <<global>> DECLARE_PER_CPU(vector_irq_t, vector_irq);
+ *   - arch/x86/i8259.c|106| <<_disable_8259A_irq>> per_cpu(vector_irq, 0)[LEGACY_VECTOR(irq)] = ~irq;
+ *   - arch/x86/i8259.c|122| <<enable_8259A_irq>> per_cpu(vector_irq, 0)[LEGACY_VECTOR(desc->irq)] = desc->irq;
+ *   - arch/x86/i8259.c|350| <<init_IRQ>> per_cpu(vector_irq, cpu)[FIRST_LEGACY_VECTOR + irq] = irq;
+ *   - arch/x86/i8259.c|355| <<init_IRQ>> per_cpu(vector_irq, cpu)[IRQ0_VECTOR] = 0;
+ *   - arch/x86/irq.c|134| <<__bind_irq_vector>> per_cpu(vector_irq, cpu)[vector] = irq;
+ *   - arch/x86/irq.c|258| <<__clear_irq_vector>> ASSERT( per_cpu(vector_irq, cpu)[vector] == irq );
+ *   - arch/x86/irq.c|259| <<__clear_irq_vector>> per_cpu(vector_irq, cpu)[vector] = ~irq;
+ *   - arch/x86/irq.c|283| <<__clear_irq_vector>> ASSERT( per_cpu(vector_irq, cpu)[old_vector] == irq );
+ *   - arch/x86/irq.c|285| <<__clear_irq_vector>> per_cpu(vector_irq, cpu)[old_vector] = ~irq;
+ *   - arch/x86/irq.c|359| <<init_irq_data>> this_cpu(vector_irq)[vector] = INT_MIN;
+ *   - arch/x86/irq.c|515| <<__assign_irq_vector>> if (per_cpu(vector_irq, new_cpu)[vector] >= 0)
+ *   - arch/x86/irq.c|527| <<__assign_irq_vector>> per_cpu(vector_irq, new_cpu)[vector] = irq;
+ *   - arch/x86/irq.c|577| <<setup_vector_irq>> per_cpu(vector_irq, cpu)[vector] = INT_MIN;
+ *   - arch/x86/irq.c|591| <<setup_vector_irq>> per_cpu(vector_irq, cpu)[vector] = irq;
+ *   - arch/x86/irq.c|651| <<irq_move_cleanup_interrupt>> irq = __get_cpu_var(vector_irq)[vector];
+ *   - arch/x86/irq.c|689| <<irq_move_cleanup_interrupt>> __get_cpu_var(vector_irq)[vector] = ~irq;
+ *   - arch/x86/irq.c|821| <<do_IRQ>> int irq = __get_cpu_var(vector_irq[vector]);
+ *   - arch/x86/smpboot.c|1376| <<smp_intr_init>> per_cpu(vector_irq, cpu)[vector] = irq;
+ */
 DECLARE_PER_CPU(vector_irq_t, vector_irq);
 
 extern bool opt_noirqbalance;
diff --git a/xen/include/asm-x86/paging.h b/xen/include/asm-x86/paging.h
index 18a7eae..3469b29 100644
--- a/xen/include/asm-x86/paging.h
+++ b/xen/include/asm-x86/paging.h
@@ -46,6 +46,11 @@
 #define PG_SH_enable   0
 #define PG_SH_forced   0
 #endif
+/*
+ * used by:
+ *   - arch/x86/mm/hap/hap.c|505| <<hap_enable>> d->arch.paging.mode = mode | PG_HAP_enable;
+ *   - include/asm-x86/paging.h|69| <<paging_mode_hap>> #define paging_mode_hap(_d) (!!((_d)->arch.paging.mode & PG_HAP_enable))
+ */
 #define PG_HAP_enable  (1U << PG_HAP_shift)
 
 /* common paging mode bits */
diff --git a/xen/include/public/arch-x86/hvm/save.h b/xen/include/public/arch-x86/hvm/save.h
index 40be84e..030499a 100644
--- a/xen/include/public/arch-x86/hvm/save.h
+++ b/xen/include/public/arch-x86/hvm/save.h
@@ -475,6 +475,12 @@ struct hvm_hw_pit {
         uint8_t status_latched;
         uint8_t status;
         uint8_t read_state;
+        /*
+	 * 在以下修改:
+	 *   - arch/x86/emul-i8254.c|359| <<pit_ioport_write>> s->write_state = access;
+	 *   - arch/x86/emul-i8254.c|386| <<pit_ioport_write>> s->write_state = RW_STATE_WORD1;
+	 *   - arch/x86/emul-i8254.c|390| <<pit_ioport_write>> s->write_state = RW_STATE_WORD0;
+	 */
         uint8_t write_state;
         uint8_t write_latch;
         uint8_t rw_mode;
-- 
2.17.1

