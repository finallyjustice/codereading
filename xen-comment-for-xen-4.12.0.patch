From 8bb79bc059b80df407e8148dfaf5fa3c1255e6fb Mon Sep 17 00:00:00 2001
From: Dongli Zhang <dongli.zhang0129@gmail.com>
Date: Tue, 12 May 2020 17:33:02 -0700
Subject: [PATCH 1/1] xen comment for xen-4.12.0

xen-4.12.0

Signed-off-by: Dongli Zhang <dongli.zhang0129@gmail.com>
---
 tools/xenstore/tdb.c                   |   5 +
 tools/xenstore/xenstored_core.h        |  10 +
 tools/xenstore/xenstored_transaction.c |  62 ++++
 xen/arch/x86/domain.c                  |   4 +
 xen/arch/x86/emul-i8254.c              | 141 +++++++++
 xen/arch/x86/hvm/hvm.c                 |   8 +
 xen/arch/x86/hvm/vioapic.c             |  13 +
 xen/arch/x86/hvm/vlapic.c              |  69 +++++
 xen/arch/x86/hvm/vmx/intr.c            |   9 +
 xen/arch/x86/hvm/vmx/vmcs.c            |  89 ++++++
 xen/arch/x86/hvm/vmx/vmx.c             |  11 +
 xen/arch/x86/hvm/vpic.c                |  26 ++
 xen/arch/x86/hvm/vpt.c                 | 381 +++++++++++++++++++++++++
 xen/arch/x86/irq.c                     |  66 +++++
 xen/arch/x86/mm/hap/hap.c              |   4 +
 xen/common/domain.c                    |  23 ++
 xen/common/timer.c                     | 381 +++++++++++++++++++++++++
 xen/include/asm-x86/hvm/hvm.h          |  11 +
 xen/include/asm-x86/hvm/vcpu.h         |  14 +
 xen/include/asm-x86/hvm/vlapic.h       |  14 +
 xen/include/asm-x86/hvm/vmx/vmcs.h     |   9 +
 xen/include/asm-x86/hvm/vpt.h          | 104 +++++++
 xen/include/asm-x86/irq.h              |  23 ++
 xen/include/asm-x86/paging.h           |   5 +
 xen/include/public/arch-x86/hvm/save.h |   6 +
 25 files changed, 1488 insertions(+)

diff --git a/tools/xenstore/tdb.c b/tools/xenstore/tdb.c
index 29593b7..9725519 100644
--- a/tools/xenstore/tdb.c
+++ b/tools/xenstore/tdb.c
@@ -1429,6 +1429,11 @@ int tdb_delete(TDB_CONTEXT *tdb, TDB_DATA key)
 
    return 0 on success, -1 on failure
 */
+/*
+ * called by:
+ *   - xenstore/xenstored_core.c|450| <<write_node_raw>> if (tdb_store(tdb_ctx, *key, data, TDB_REPLACE) != 0) {
+ *   - xenstore/xenstored_transaction.c|366| <<finalize_transaction>> ret = tdb_store(tdb_ctx, key, data,
+ */
 int tdb_store(TDB_CONTEXT *tdb, TDB_DATA key, TDB_DATA dbuf, int flag)
 {
 	struct list_struct rec;
diff --git a/tools/xenstore/xenstored_core.h b/tools/xenstore/xenstored_core.h
index 3d27feb..7817a5c 100644
--- a/tools/xenstore/xenstored_core.h
+++ b/tools/xenstore/xenstored_core.h
@@ -116,6 +116,16 @@ struct node {
 	struct node *parent;
 
 	/* Generation count. */
+	/*
+	 * 在以下使用node->generation:
+	 *   - xenstore/xenstored_core.c|387| <<read_node>> node->generation = NO_GENERATION;
+	 *   - xenstore/xenstored_core.c|403| <<read_node>> node->generation = hdr->generation;
+	 *   - xenstore/xenstored_core.c|438| <<write_node_raw>> hdr->generation = node->generation;
+	 *   - xenstore/xenstored_core.c|838| <<send_directory_part>> genlen = snprintf(gen, sizeof(gen), "%"PRIu64, node->generation) + 1;
+	 *   - xenstore/xenstored_transaction.c|237| <<access_node>> node->generation = generation++;
+	 *   - xenstore/xenstored_transaction.c|275| <<access_node>> i->generation = node->generation;
+	 *   - xenstore/xenstored_transaction.c|277| <<access_node>> if (node->generation != NO_GENERATION) {
+	 */
 	uint64_t generation;
 #define NO_GENERATION ~((uint64_t)0)
 
diff --git a/tools/xenstore/xenstored_transaction.c b/tools/xenstore/xenstored_transaction.c
index 75816dd..be2b0f1 100644
--- a/tools/xenstore/xenstored_transaction.c
+++ b/tools/xenstore/xenstored_transaction.c
@@ -145,12 +145,37 @@ struct transaction
 	uint32_t id;
 
 	/* Generation when transaction started. */
+	/*
+	 * 在以下使用transaction->generation:
+	 *   - xenstore/xenstored_transaction.c|184| <<transaction_get_node_name>> return talloc_asprintf(ctx, "%"PRIu64"/%s", trans->generation, name);
+	 *   - xenstore/xenstored_transaction.c|448| <<do_transaction_start>> trans->generation = generation++;
+	 *   - xenstore/xenstored_transaction.c|588| <<check_transactions>> trans->generation);
+	 */
 	uint64_t generation;
 
 	/* List of accessed nodes. */
+	/*
+	 * 在以下使用transaction->accessed:
+	 *   - xenstore/xenstored_transaction.c|174| <<find_accessed_node>> list_for_each_entry(i, &trans->accessed, list)
+	 *   - xenstore/xenstored_transaction.c|285| <<access_node>> list_add_tail(&i->list, &trans->accessed);
+	 *   - xenstore/xenstored_transaction.c|332| <<finalize_transaction>> list_for_each_entry(i, &trans->accessed, list) {
+	 *   - xenstore/xenstored_transaction.c|350| <<finalize_transaction>> while ((i = list_top(&trans->accessed, struct accessed_node, list))) {
+	 *   - xenstore/xenstored_transaction.c|398| <<destroy_transaction>> while ((i = list_top(&trans->accessed, struct accessed_node, list))) {
+	 *   - xenstore/xenstored_transaction.c|445| <<do_transaction_start>> INIT_LIST_HEAD(&trans->accessed);
+	 *   - xenstore/xenstored_transaction.c|592| <<check_transactions>> list_for_each_entry(i, &trans->accessed, list) {
+	 */
 	struct list_head accessed;
 
 	/* List of changed domains - to record the changed domain entry number */
+	/*
+	 * 在以下使用transaction->changed_domains:
+	 *   - xenstore/xenstored_transaction.c|446| <<do_transaction_start>> INIT_LIST_HEAD(&trans->changed_domains);
+	 *   - xenstore/xenstored_transaction.c|474| <<transaction_fix_domains>> list_for_each_entry(d, &trans->changed_domains, list) {
+	 *   - xenstore/xenstored_transaction.c|525| <<transaction_entry_inc>> list_for_each_entry(d, &trans->changed_domains, list)
+	 *   - xenstore/xenstored_transaction.c|539| <<transaction_entry_inc>> list_add_tail(&d->list, &trans->changed_domains);
+	 *   - xenstore/xenstored_transaction.c|546| <<transaction_entry_dec>> list_for_each_entry(d, &trans->changed_domains, list)
+	 *   - xenstore/xenstored_transaction.c|560| <<transaction_entry_dec>> list_add_tail(&d->list, &trans->changed_domains);
+	 */
 	struct list_head changed_domains;
 
 	/* Flag for letting transaction fail. */
@@ -319,6 +344,10 @@ err:
  * transaction prepended. Delete all transaction specific nodes in the data
  * base.
  */
+/*
+ * called by:
+ *   - xenstore/xenstored_transaction.c|508| <<do_transaction_end>> if (finalize_transaction(conn, trans))
+ */
 static int finalize_transaction(struct connection *conn,
 				struct transaction *trans)
 {
@@ -363,6 +392,15 @@ static int finalize_transaction(struct connection *conn,
 					goto err;
 				hdr = (void *)data.dptr;
 				hdr->generation = generation++;
+				/*
+				 * store an element in the database, replacing any existing element
+				 * with the same key
+				 * return 0 on success, -1 on failure
+				 *
+				 * called by:
+				 *   - xenstore/xenstored_core.c|450| <<write_node_raw>> if (tdb_store(tdb_ctx, *key, data, TDB_REPLACE) != 0) {
+				 *   - xenstore/xenstored_transaction.c|366| <<finalize_transaction>> ret = tdb_store(tdb_ctx, key, data,
+				 */
 				ret = tdb_store(tdb_ctx, key, data,
 						TDB_REPLACE);
 				talloc_free(data.dptr);
@@ -425,6 +463,12 @@ struct transaction *transaction_lookup(struct connection *conn, uint32_t id)
 	return ERR_PTR(-ENOENT);
 }
 
+/*
+ * 在以下使用do_transaction_start():
+ *   - xenstore/xenstored_core.c|1276| <<global>> [XS_TRANSACTION_START] = { "TRANSACTION_START", do_transaction_start },
+ *
+ * struct transaction里没有tdb
+ */
 int do_transaction_start(struct connection *conn, struct buffered_data *in)
 {
 	struct transaction *trans, *exists;
@@ -466,6 +510,11 @@ int do_transaction_start(struct connection *conn, struct buffered_data *in)
 	return 0;
 }
 
+/*
+ * called by:
+ *   - xenstore/xenstored_transaction.c|505| <<do_transaction_end>> ret = transaction_fix_domains(trans, false);
+ *   - xenstore/xenstored_transaction.c|514| <<do_transaction_end>> transaction_fix_domains(trans, true);
+ */
 static int transaction_fix_domains(struct transaction *trans, bool update)
 {
 	struct changed_domain *d;
@@ -480,6 +529,10 @@ static int transaction_fix_domains(struct transaction *trans, bool update)
 	return 0;
 }
 
+/*
+ * 在以下使用do_transaction_end():
+ *   - xenstore/xenstored_core.c|1277| <<global>> [XS_TRANSACTION_END] = { "TRANSACTION_END", do_transaction_end },
+ */
 int do_transaction_end(struct connection *conn, struct buffered_data *in)
 {
 	const char *arg = onearg(in);
@@ -505,6 +558,15 @@ int do_transaction_end(struct connection *conn, struct buffered_data *in)
 		ret = transaction_fix_domains(trans, false);
 		if (ret)
 			return ret;
+		/*
+		 * Finalize transaction:
+		 * Walk through accessed nodes and check generation against global data.
+		 * If all entries match, read the transaction entries and write them without
+		 * transaction prepended. Delete all transaction specific nodes in the data
+		 * base.
+		 *
+		 * 只在这里被调用
+		 */
 		if (finalize_transaction(conn, trans))
 			return EAGAIN;
 
diff --git a/xen/arch/x86/domain.c b/xen/arch/x86/domain.c
index 8d579e2..6f6c92c 100644
--- a/xen/arch/x86/domain.c
+++ b/xen/arch/x86/domain.c
@@ -338,6 +338,10 @@ void arch_vcpu_regs_init(struct vcpu *v)
     v->arch.dr7 = X86_DR7_DEFAULT;
 }
 
+/*
+ * called only by:
+ *   - common/domain.c|179| <<vcpu_create>> if ( arch_vcpu_create(v) != 0 )
+ */
 int arch_vcpu_create(struct vcpu *v)
 {
     struct domain *d = v->domain;
diff --git a/xen/arch/x86/emul-i8254.c b/xen/arch/x86/emul-i8254.c
index 73be418..9510975 100644
--- a/xen/arch/x86/emul-i8254.c
+++ b/xen/arch/x86/emul-i8254.c
@@ -38,7 +38,17 @@
 #include <asm/hvm/vpt.h>
 #include <asm/current.h>
 
+/*
+ * https://wiki.osdev.org/Programmable_Interval_Timer
+ *
+ * 配置的入口函数handle_pit_io()
+ */
+
+/* 参数的x是struct domain */
 #define domain_vpit(x) (&(x)->arch.vpit)
+/*
+ * domain_vpit()的参数是(x)->domain, 不是x
+ */
 #define vcpu_vpit(x)   (domain_vpit((x)->domain))
 #define vpit_domain(x) (container_of((x), struct domain, arch.vpit))
 #define vpit_vcpu(x)   (pt_global_vcpu_target(vpit_domain(x)))
@@ -53,9 +63,26 @@ static int handle_pit_io(
 static int handle_speaker_io(
     int dir, unsigned int port, unsigned int bytes, uint32_t *val);
 
+/*
+ * called by:
+ *   - arch/x86/emul-i8254.c|80| <<pit_get_count>> d = muldiv64(get_guest_time(v) - pit->count_load_time[channel],
+ *   - arch/x86/emul-i8254.c|111| <<pit_get_out>> d = muldiv64(get_guest_time(v) - pit->count_load_time[channel],
+ *   - arch/x86/emul-i8254.c|158| <<pit_set_gate>> pit->count_load_time[channel] = get_guest_time(v);
+ *   - arch/x86/emul-i8254.c|180| <<pit_time_fired>> *count_load_time = get_guest_time(v);
+ *   - arch/x86/emul-i8254.c|205| <<pit_load_count>> pit->count_load_time[channel] = get_guest_time(v);
+ *   - arch/x86/emul-i8254.c|478| <<pit_load>> pit->pt0.last_plt_gtime = get_guest_time(d->vcpu[0]);
+ */
 #define get_guest_time(v) \
    (is_hvm_vcpu(v) ? hvm_get_guest_time(v) : (u64)get_s_time())
 
+/*
+ * used by:
+ *   - arch/x86/emul-i8254.c|226| <<pit_latch_count>> c->latched_count = pit_get_count(pit, channel);
+ *   - arch/x86/emul-i8254.c|369| <<pit_ioport_read>> count = pit_get_count(pit, addr);
+ *   - arch/x86/emul-i8254.c|373| <<pit_ioport_read>> count = pit_get_count(pit, addr);
+ *   - arch/x86/emul-i8254.c|377| <<pit_ioport_read>> count = pit_get_count(pit, addr);
+ *   - arch/x86/emul-i8254.c|382| <<pit_ioport_read>> count = pit_get_count(pit, addr);
+ */
 static int pit_get_count(PITState *pit, int channel)
 {
     uint64_t d;
@@ -87,6 +114,11 @@ static int pit_get_count(PITState *pit, int channel)
     return counter;
 }
 
+/*
+ * called by:
+ *   - arch/x86/emul-i8254.c|266| <<pit_latch_status>> c->status = ((pit_get_out(pit, channel) << 7) |
+ *   - arch/x86/emul-i8254.c|630| <<speaker_ioport_read>> (pit_get_out(pit, 2) << 5) | (refresh_clock << 4));
+ */
 static int pit_get_out(PITState *pit, int channel)
 {
     struct hvm_hw_pit_channel *s = &pit->hw.channels[channel];
@@ -156,6 +188,11 @@ static int pit_get_gate(PITState *pit, int channel)
     return pit->hw.channels[channel].gate;
 }
 
+/*
+ * 调用的地方:
+ *   - arch/x86/hvm/vpt.c|566| <<pt_update_irq>> cb(v, cb_priv);
+ *   - arch/x86/hvm/vpt.c|628| <<pt_intr_post>> cb(v, cb_priv);
+ */
 static void pit_time_fired(struct vcpu *v, void *priv)
 {
     uint64_t *count_load_time = priv;
@@ -163,6 +200,16 @@ static void pit_time_fired(struct vcpu *v, void *priv)
     *count_load_time = get_guest_time(v);
 }
 
+/*
+ * called by:
+ *   - arch/x86/emul-i8254.c|302| <<pit_ioport_write>> pit_load_count(pit, addr, val);
+ *   - arch/x86/emul-i8254.c|305| <<pit_ioport_write>> pit_load_count(pit, addr, val << 8);
+ *   - arch/x86/emul-i8254.c|312| <<pit_ioport_write>> pit_load_count(pit, addr, s->write_latch | (val << 8));
+ *   - arch/x86/emul-i8254.c|439| <<pit_load>> pit_load_count(pit, i, pit->hw.channels[i].count);
+ *   - arch/x86/emul-i8254.c|477| <<pit_reset>> pit_load_count(pit, i, 0);
+ *
+ * 在pit_ioport_write()中只被pit_ioport_write()的0x40, 0x41和0x42三个port调用
+ */
 static void pit_load_count(PITState *pit, int channel, int val)
 {
     u32 period;
@@ -207,6 +254,11 @@ static void pit_load_count(PITState *pit, int channel, int val)
     }
 }
 
+/*
+ * called by:
+ *   - arch/x86/emul-i8254.c|304| <<pit_ioport_write>> pit_latch_count(pit, channel);
+ *   - arch/x86/emul-i8254.c|317| <<pit_ioport_write>> pit_latch_count(pit, channel);
+ */
 static void pit_latch_count(PITState *pit, int channel)
 {
     struct hvm_hw_pit_channel *c = &pit->hw.channels[channel];
@@ -220,6 +272,10 @@ static void pit_latch_count(PITState *pit, int channel)
     }
 }
 
+/*
+ * called by:
+ *   - arch/x86/emul-i8254.c|306| <<pit_ioport_write>> pit_latch_status(pit, channel);
+ */
 static void pit_latch_status(PITState *pit, int channel)
 {
     struct hvm_hw_pit_channel *c = &pit->hw.channels[channel];
@@ -237,12 +293,34 @@ static void pit_latch_status(PITState *pit, int channel)
     }
 }
 
+/*
+ * called by:
+ *   - arch/x86/emul-i8254.c|521| <<handle_pit_io>> pit_ioport_write(vpit, port, *val);
+ */
+/*
+ * called by:
+ *   - arch/x86/emul-i8254.c|575| <<handle_pit_io>> pit_ioport_write(vpit, port, *val);
+ *
+ * 参数addr就是port:
+ * 0x40   Channel 0 data port (read/write)
+ * 0x41   Channel 1 data port (read/write)
+ * 0x42   Channel 2 data port (read/write)
+ * 0x43   Mode/Command register (write only, a read is ignored)
+ */
 static void pit_ioport_write(struct PITState *pit, uint32_t addr, uint32_t val)
 {
     int channel, access;
     struct hvm_hw_pit_channel *s;
 
     val  &= 0xff;
+    /*
+     * 0x40 = 1000000
+     * 0x41 = 1000001
+     * 0x42 = 1000010
+     * 0x43 = 1000011
+     *
+     * 0x03 = 11
+     */
     addr &= 3;
 
     spin_lock(&pit->lock);
@@ -295,6 +373,9 @@ static void pit_ioport_write(struct PITState *pit, uint32_t addr, uint32_t val)
         {
         default:
         case RW_STATE_LSB:
+            /*
+	     * 在pit_ioport_write()中只被pit_ioport_write()的0x40, 0x41和0x42三个port调用
+	     */
             pit_load_count(pit, addr, val);
             break;
         case RW_STATE_MSB:
@@ -314,6 +395,10 @@ static void pit_ioport_write(struct PITState *pit, uint32_t addr, uint32_t val)
     spin_unlock(&pit->lock);
 }
 
+/*
+ * called by:
+ *   - arch/x86/emul-i8254.c|580| <<handle_pit_io>> *val = pit_ioport_read(vpit, port);
+ */
 static uint32_t pit_ioport_read(struct PITState *pit, uint32_t addr)
 {
     int ret, count;
@@ -391,6 +476,10 @@ void pit_stop_channel0_irq(PITState *pit)
     spin_unlock(&pit->lock);
 }
 
+/*
+ * used by:
+ *   - arch/x86/emul-i8254.c|466| <<global>> HVM_REGISTER_SAVE_RESTORE(PIT, pit_save, pit_load, 1, HVMSR_PER_DOM);
+ */
 static int pit_save(struct vcpu *v, hvm_domain_context_t *h)
 {
     struct domain *d = v->domain;
@@ -409,6 +498,10 @@ static int pit_save(struct vcpu *v, hvm_domain_context_t *h)
     return rc;
 }
 
+/*
+ * used by:
+ *   - arch/x86/emul-i8254.c|466| <<global>> HVM_REGISTER_SAVE_RESTORE(PIT, pit_save, pit_load, 1, HVMSR_PER_DOM);
+ */
 static int pit_load(struct domain *d, hvm_domain_context_t *h)
 {
     PITState *pit = domain_vpit(d);
@@ -442,6 +535,11 @@ static int pit_load(struct domain *d, hvm_domain_context_t *h)
 HVM_REGISTER_SAVE_RESTORE(PIT, pit_save, pit_load, 1, HVMSR_PER_DOM);
 #endif
 
+/*
+ * called by:
+ *   - arch/x86/emul-i8254.c|489| <<pit_init>> pit_reset(d);
+ *   - arch/x86/hvm/hvm.c|3953| <<hvm_s3_suspend>> pit_reset(d);
+ */
 void pit_reset(struct domain *d)
 {
     PITState *pit = domain_vpit(d);
@@ -471,8 +569,15 @@ void pit_reset(struct domain *d)
     spin_unlock(&pit->lock);
 }
 
+/*
+ * called by only:
+ *   - arch/x86/domain.c|612| <<arch_domain_create>> pit_init(d, cpu_khz);
+ */
 void pit_init(struct domain *d, unsigned long cpu_khz)
 {
+    /*
+     * domain->arch.vpit
+     */
     PITState *pit = domain_vpit(d);
 
     if ( !has_vpit(d) )
@@ -489,6 +594,10 @@ void pit_init(struct domain *d, unsigned long cpu_khz)
     pit_reset(d);
 }
 
+/*
+ * called by:
+ *   - arch/x86/domain.c|2102| <<domain_relinquish_resources>> pit_deinit(d);
+ */
 void pit_deinit(struct domain *d)
 {
     PITState *pit = domain_vpit(d);
@@ -504,11 +613,25 @@ void pit_deinit(struct domain *d)
 }
 
 /* the intercept action for PIT DM retval:0--not handled; 1--handled */  
+/*
+ * used by:
+ *   - arch/x86/emul-i8254.c|498| <<pit_init>> register_portio_handler(d, PIT_BASE, 4, handle_pit_io);
+ *   - arch/x86/emul-i8254.c|605| <<pv_pit_handler>> handle_pit_io(ioreq.dir, port, 1, &val);
+ *
+ * 参数dir: IOREQ_WRITE或者IOREQ_READ
+ *
+ * 参数port:
+ * 0x40   Channel 0 data port (read/write)
+ * 0x41   Channel 1 data port (read/write)
+ * 0x42   Channel 2 data port (read/write)
+ * 0x43   Mode/Command register (write only, a read is ignored)
+ */
 static int handle_pit_io(
     int dir, unsigned int port, unsigned int bytes, uint32_t *val)
 {
     struct PITState *vpit = vcpu_vpit(current);
 
+    /* 只在这里用到了参数的bytes */
     if ( bytes != 1 )
     {
         gdprintk(XENLOG_WARNING, "PIT bad access\n");
@@ -531,6 +654,10 @@ static int handle_pit_io(
     return X86EMUL_OKAY;
 }
 
+/*
+ * called by:
+ *   - arch/x86/emul-i8254.c|614| <<handle_speaker_io>> speaker_ioport_write(vpit, port, *val);
+ */
 static void speaker_ioport_write(
     struct PITState *pit, uint32_t addr, uint32_t val)
 {
@@ -538,6 +665,10 @@ static void speaker_ioport_write(
     pit_set_gate(pit, 2, val & 1);
 }
 
+/*
+ * called by only:
+ *   - arch/x86/emul-i8254.c|616| <<handle_speaker_io>> *val = speaker_ioport_read(vpit, port);
+ */
 static uint32_t speaker_ioport_read(
     struct PITState *pit, uint32_t addr)
 {
@@ -547,6 +678,11 @@ static uint32_t speaker_ioport_read(
             (pit_get_out(pit, 2) << 5) | (refresh_clock << 4));
 }
 
+/*
+ * used by:
+ *   - arch/x86/emul-i8254.c|535| <<pit_init>> register_portio_handler(d, 0x61, 1, handle_speaker_io);
+ *   - arch/x86/emul-i8254.c|644| <<pv_pit_handler>> handle_speaker_io(ioreq.dir, port, 1, &val);
+ */
 static int handle_speaker_io(
     int dir, unsigned int port, uint32_t bytes, uint32_t *val)
 {
@@ -566,6 +702,11 @@ static int handle_speaker_io(
     return X86EMUL_OKAY;
 }
 
+/*
+ * called by:
+ *   - arch/x86/pv/emul-priv-op.c|237| <<guest_io_read>> sub_data = pv_pit_handler(port, 0, 0);
+ *   - arch/x86/pv/emul-priv-op.c|370| <<guest_io_write>> pv_pit_handler(port, (uint8_t)data, 1);
+ */
 int pv_pit_handler(int port, int data, int write)
 {
     ioreq_t ioreq = {
diff --git a/xen/arch/x86/hvm/hvm.c b/xen/arch/x86/hvm/hvm.c
index 8adbb61..9b2424d 100644
--- a/xen/arch/x86/hvm/hvm.c
+++ b/xen/arch/x86/hvm/hvm.c
@@ -142,6 +142,10 @@ static struct notifier_block cpu_nfb = {
     .notifier_call = cpu_callback
 };
 
+/*
+ * used by only:
+ *   - arch/x86/hvm/hvm.c|206| <<global>> presmp_initcall(hvm_enable);
+ */
 static int __init hvm_enable(void)
 {
     const struct hvm_function_table *fns = NULL;
@@ -1487,6 +1491,10 @@ static int __init hvm_register_CPU_save_and_restore(void)
 }
 __initcall(hvm_register_CPU_save_and_restore);
 
+/*
+ * called only by:
+ *   - arch/x86/domain.c|369| <<arch_vcpu_create>> rc = hvm_vcpu_initialise(v);
+ */
 int hvm_vcpu_initialise(struct vcpu *v)
 {
     int rc;
diff --git a/xen/arch/x86/hvm/vioapic.c b/xen/arch/x86/hvm/vioapic.c
index 9c25f72..fa0fb5d 100644
--- a/xen/arch/x86/hvm/vioapic.c
+++ b/xen/arch/x86/hvm/vioapic.c
@@ -375,6 +375,12 @@ static const struct hvm_mmio_ops vioapic_mmio_ops = {
     .write = vioapic_write
 };
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vioapic.c|434| <<vioapic_deliver>> ioapic_inj_irq(vioapic, target, vector, trig_mode, delivery_mode);
+ *   - arch/x86/hvm/vioapic.c|452| <<vioapic_deliver>> ioapic_inj_irq(vioapic, vcpu_vlapic(v), vector,
+ *   - arch/x86/hvm/vioapic.c|461| <<vioapic_deliver>> ioapic_inj_irq(vioapic, vcpu_vlapic(v), vector,
+ */
 static void ioapic_inj_irq(
     struct hvm_vioapic *vioapic,
     struct vlapic *target,
@@ -396,6 +402,13 @@ static inline int pit_channel0_enabled(void)
     return pt_active(&current->domain->arch.vpit.pt0);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vioapic.c|266| <<vioapic_write_redirent>> vioapic_deliver(vioapic, idx);
+ *   - arch/x86/hvm/vioapic.c|507| <<vioapic_irq_positive_edge>> vioapic_deliver(vioapic, pin);
+ *   - arch/x86/hvm/vioapic.c|512| <<vioapic_irq_positive_edge>> vioapic_deliver(vioapic, pin);
+ *   - arch/x86/hvm/vioapic.c|551| <<vioapic_update_EOI>> vioapic_deliver(vioapic, pin);
+ */
 static void vioapic_deliver(struct hvm_vioapic *vioapic, unsigned int pin)
 {
     uint16_t dest = vioapic->redirtbl[pin].fields.dest_id;
diff --git a/xen/arch/x86/hvm/vlapic.c b/xen/arch/x86/hvm/vlapic.c
index a1a43cd..af1d080 100644
--- a/xen/arch/x86/hvm/vlapic.c
+++ b/xen/arch/x86/hvm/vlapic.c
@@ -149,6 +149,17 @@ bool vlapic_test_irq(const struct vlapic *vlapic, uint8_t vec)
     return vlapic_test_vector(vec, &vlapic->regs->data[APIC_IRR]);
 }
 
+/*
+ * called by:
+ *   - arch/x86/cpu/vpmu.c|324| <<vpmu_do_interrupt>> vlapic_set_irq(vlapic, vlapic_lvtpc & APIC_VECTOR_MASK, 0);
+ *   - arch/x86/hvm/irq.c|322| <<hvm_assert_evtchn_irq>> vlapic_set_irq(vcpu_vlapic(v), vector, 0);
+ *   - arch/x86/hvm/svm/svm.c|947| <<svm_lwp_interrupt>> vlapic_set_irq(
+ *   - arch/x86/hvm/vioapic.c|391| <<ioapic_inj_irq>> vlapic_set_irq(target, vector, trig_mode);
+ *   - arch/x86/hvm/vlapic.c|135| <<vlapic_error>> vlapic_set_irq(vlapic, lvterr & APIC_VECTOR_MASK, 0);
+ *   - arch/x86/hvm/vlapic.c|352| <<vlapic_accept_irq>> vlapic_set_irq(vlapic, vector, 0);
+ *   - arch/x86/hvm/vmsi.c|58| <<vmsi_inj_irq>> vlapic_set_irq(target, vector, trig_mode);
+ *   - arch/x86/hvm/vpt.c|384| <<pt_update_irq>> vlapic_set_irq(vcpu_vlapic(v), irq, 0);
+ */
 void vlapic_set_irq(struct vlapic *vlapic, uint8_t vec, uint8_t trig)
 {
     struct vcpu *target = vlapic_vcpu(vlapic);
@@ -775,6 +786,15 @@ static void vlapic_update_timer(struct vlapic *vlapic, uint32_t lvtt,
     }
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/viridian/synic.c|88| <<viridian_synic_wrmsr>> vlapic_reg_write(v, APIC_ICR2, val >> 32);
+ *   - arch/x86/hvm/viridian/synic.c|89| <<viridian_synic_wrmsr>> vlapic_reg_write(v, APIC_ICR, val);
+ *   - arch/x86/hvm/viridian/synic.c|93| <<viridian_synic_wrmsr>> vlapic_reg_write(v, APIC_TASKPRI, val);
+ *   - arch/x86/hvm/vlapic.c|951| <<vlapic_mmio_write>> vlapic_reg_write(v, offset, val);
+ *   - arch/x86/hvm/vlapic.c|971| <<vlapic_apicv_write>> vlapic_reg_write(v, offset, val);
+ *   - arch/x86/hvm/vlapic.c|1056| <<guest_wrmsr_x2apic>> vlapic_reg_write(v, offset, msr_content);
+ */
 void vlapic_reg_write(struct vcpu *v, unsigned int reg, uint32_t val)
 {
     struct vlapic *vlapic = vcpu_vlapic(v);
@@ -1234,6 +1254,12 @@ void vlapic_tdt_msr_set(struct vlapic *vlapic, uint64_t value)
                 vlapic->hw.tdt_msr, guest_tsc);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vlapic.c|1290| <<vlapic_accept_pic_intr>> v ? __vlapic_accept_pic_intr(v) : -1);
+ *   - arch/x86/hvm/vlapic.c|1293| <<vlapic_accept_pic_intr>> __vlapic_accept_pic_intr(v));
+ *   - arch/x86/hvm/vlapic.c|1312| <<vlapic_adjust_i8259_target>> if ( __vlapic_accept_pic_intr(v) )
+ */
 static int __vlapic_accept_pic_intr(struct vcpu *v)
 {
     struct domain *d = v->domain;
@@ -1258,6 +1284,10 @@ static int __vlapic_accept_pic_intr(struct vcpu *v)
              ((lvt0 & (APIC_MODE_MASK|APIC_LVT_MASKED)) == APIC_DM_EXTINT) ||
              /* LAPIC is fully disabled? */
              vlapic_hw_disabled(vlapic)));
+
+    /*
+     * 上面APIC_DM_EXTINT = 0x00700
+     */
 }
 
 int vlapic_accept_pic_intr(struct vcpu *v)
@@ -1273,6 +1303,14 @@ int vlapic_accept_pic_intr(struct vcpu *v)
             __vlapic_accept_pic_intr(v));
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vioapic.c|257| <<vioapic_write_redirent>> vlapic_adjust_i8259_target(d);
+ *   - arch/x86/hvm/vlapic.c|863| <<vlapic_reg_write>> vlapic_adjust_i8259_target(v->domain);
+ *   - arch/x86/hvm/vlapic.c|1573| <<lapic_load_regs>> vlapic_adjust_i8259_target(d);
+ *
+ * 目前还不明白, 这个函数控制8259的中断发到哪一个apic?
+ */
 void vlapic_adjust_i8259_target(struct domain *d)
 {
     struct vcpu *v;
@@ -1289,10 +1327,19 @@ void vlapic_adjust_i8259_target(struct domain *d)
  found:
     if ( d->arch.hvm.i8259_target == v )
         return;
+    /*
+     * hvm是struct hvm_domain
+     * i8259_target是struct vcpu
+     */
     d->arch.hvm.i8259_target = v;
     pt_adjust_global_vcpu_target(v);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/irq.c|533| <<hvm_vcpu_has_pending_irq>> vector = vlapic_has_pending_irq(v);
+ *   - arch/x86/hvm/vmx/vvmx.c|1322| <<nvmx_update_apicv>> rvi = vlapic_has_pending_irq(v);
+ */
 int vlapic_has_pending_irq(struct vcpu *v)
 {
     struct vlapic *vlapic = vcpu_vlapic(v);
@@ -1372,6 +1419,11 @@ bool_t is_vlapic_lvtpc_enabled(struct vlapic *vlapic)
 }
 
 /* Reset the VLAPIC back to its init state. */
+/*
+ * called by:
+ *   - arch/x86/hvm/vlapic.c|300| <<vlapic_init_sipi_one>> vlapic_do_init(vcpu_vlapic(target));
+ *   - arch/x86/hvm/vlapic.c|1428| <<vlapic_reset>> vlapic_do_init(vlapic);
+ */
 static void vlapic_do_init(struct vlapic *vlapic)
 {
     int i;
@@ -1413,6 +1465,12 @@ static void vlapic_do_init(struct vlapic *vlapic)
 }
 
 /* Reset the VLAPIC back to its power-on/reset state. */
+/*
+ * called by:
+ *   - arch/x86/hvm/hvm.c|3946| <<hvm_s3_suspend>> vlapic_reset(vcpu_vlapic(v));
+ *   - arch/x86/hvm/vlapic.c|1139| <<guest_wrmsr_apic_base>> vlapic_reset(vlapic);
+ *   - arch/x86/hvm/vlapic.c|1630| <<vlapic_init>> vlapic_reset(vlapic);
+ */
 void vlapic_reset(struct vlapic *vlapic)
 {
     const struct vcpu *v = vlapic_vcpu(vlapic);
@@ -1580,6 +1638,10 @@ HVM_REGISTER_SAVE_RESTORE(LAPIC, lapic_save_hidden,
 HVM_REGISTER_SAVE_RESTORE(LAPIC_REGS, lapic_save_regs,
                           lapic_load_regs, 1, HVMSR_PER_VCPU);
 
+/*
+ * called by only:
+ *   - arch/x86/hvm/hvm.c|1505| <<hvm_vcpu_initialise>> rc = vlapic_init(v);
+ */
 int vlapic_init(struct vcpu *v)
 {
     struct vlapic *vlapic = vcpu_vlapic(v);
@@ -1588,6 +1650,13 @@ int vlapic_init(struct vcpu *v)
 
     if ( !has_vlapic(v->domain) )
     {
+        /*
+	 * VLAPIC_HW_DISABLED在以下被使用:
+	 *   - arch/x86/hvm/vlapic.c|1140| <<guest_wrmsr_apic_base>> vlapic->hw.disabled &= ~VLAPIC_HW_DISABLED;
+	 *   - arch/x86/hvm/vlapic.c|1145| <<guest_wrmsr_apic_base>> vlapic->hw.disabled |= VLAPIC_HW_DISABLED;
+	 *   - arch/x86/hvm/vlapic.c|1591| <<vlapic_init>> vlapic->hw.disabled = VLAPIC_HW_DISABLED;
+	 *   - include/asm-x86/hvm/vlapic.h|48| <<vlapic_hw_disabled>> #define vlapic_hw_disabled(vlapic) ((vlapic)->hw.disabled & VLAPIC_HW_DISABLED)
+	 */
         vlapic->hw.disabled = VLAPIC_HW_DISABLED;
         return 0;
     }
diff --git a/xen/arch/x86/hvm/vmx/intr.c b/xen/arch/x86/hvm/vmx/intr.c
index 0d097cf..9fec710 100644
--- a/xen/arch/x86/hvm/vmx/intr.c
+++ b/xen/arch/x86/hvm/vmx/intr.c
@@ -226,6 +226,12 @@ static int nvmx_intr_intercept(struct vcpu *v, struct hvm_intack intack)
 
 void vmx_intr_assist(void)
 {
+    /*
+     * struct hvm_intack {
+     *     uint8_t source; // enum hvm_intsrc
+     *     uint8_t vector;
+     * };
+     */
     struct hvm_intack intack;
     struct vcpu *v = current;
     unsigned int tpr_threshold = 0;
@@ -250,6 +256,9 @@ void vmx_intr_assist(void)
     do {
         unsigned long intr_info;
 
+	/*
+	 * source是hvm_intsrc_lapic???
+	 */
         intack = hvm_vcpu_has_pending_irq(v);
         if ( likely(intack.source == hvm_intsrc_none) )
             goto out;
diff --git a/xen/arch/x86/hvm/vmx/vmcs.c b/xen/arch/x86/hvm/vmx/vmcs.c
index 74f2a08..fb85a30 100644
--- a/xen/arch/x86/hvm/vmx/vmcs.c
+++ b/xen/arch/x86/hvm/vmx/vmcs.c
@@ -42,6 +42,33 @@
 #include <asm/tboot.h>
 #include <asm/apic.h>
 
+/*
+ * 'xl debug-keys v'可以打印出所有的vmcs
+ *
+ *
+ * 3处会初始化vmcs的地方 (主要最后一处)
+ *
+ * hvm_cpu_up()
+ *  -> vmx_cpu_up()
+ *      -> _vmx_cpu_up(bool bsp) --> bsp == false
+ *          -> vmx_init_vmcs_config()
+ *
+ *
+ * presmp_initcall(hvm_enable)
+ *  -> hvm_enable()
+ *      -> start_vmx()
+ *          -> _vmx_cpu_up() --> bsp == true
+ *              -> vmx_init_vmcs_config()
+ *
+ *
+ * vcpu_create(vcpu_id)
+ *  -> arch_vcpu_create(vcpu)
+ *      -> hvm_vcpu_initialise(vcpu)
+ *          -> vmx_function_table.vcpu_initialise = vmx_vcpu_initialise(vcpu)
+ *              -> vmx_create_vmcs(vcpu)
+ *                  -> construct_vmcs()
+ */
+
 static bool_t __read_mostly opt_vpid_enabled = 1;
 boolean_param("vpid", opt_vpid_enabled);
 
@@ -166,6 +193,10 @@ static bool_t cap_check(const char *name, u32 expected, u32 saw)
     return saw != expected;
 }
 
+/*
+ * calle by only:
+ *   - arch/x86/hvm/vmx/vmcs.c|645| <<_vmx_cpu_up>> if ( (rc = vmx_init_vmcs_config()) != 0 )
+ */
 static int vmx_init_vmcs_config(void)
 {
     u32 vmx_basic_msr_low, vmx_basic_msr_high, min, opt;
@@ -598,6 +629,30 @@ void vmx_cpu_dead(unsigned int cpu)
     vmx_pi_desc_fixup(cpu);
 }
 
+/*
+ * 在测试机上有4个cpu, 第0个(bsp=true)和其他3个不一样
+ *
+ * 在CPU 0上执行
+ * [0] _vmx_cpu_up
+ * [0] smp_send_call_function_mask
+ * [0] on_selected_cpus
+ * [0] mwait-idle.c#mwait_idle_cpu_init
+ * [0] start_vmx
+ * [0] hvm.c#hvm_enable
+ * [0] do_presmp_initcalls
+ * [0] __start_xen
+ * [0] __high_start
+ *
+ * 在剩下的3个非bsp的cpu分别执行
+ * [0] _vmx_cpu_up
+ * [0] alloc_direct_apic_vector
+ * [0] intel_mcheck_init
+ * [0] start_secondary
+ *
+ * called by:
+ *   - arch/x86/hvm/vmx/vmcs.c|697| <<vmx_cpu_up>> return _vmx_cpu_up(false);
+ *   - arch/x86/hvm/vmx/vmx.c|2446| <<start_vmx>> if ( _vmx_cpu_up(true) )
+ */
 int _vmx_cpu_up(bool bsp)
 {
     u32 eax, edx;
@@ -688,6 +743,13 @@ int _vmx_cpu_up(bool bsp)
     return 0;
 }
 
+/*
+ * called by:
+ *   - arch/arm/platform.c|104| <<platform_cpu_up>> return platform->cpu_up(cpu);
+ *   - include/asm-x86/hvm/hvm.h|530| <<hvm_cpu_up>> return (hvm_funcs.cpu_up ? hvm_funcs.cpu_up() : 0);
+ *
+ * struct hvm_function_table vmx_function_table.cpu_up = vmx_cpu_up()
+ */
 int vmx_cpu_up()
 {
     return _vmx_cpu_up(false);
@@ -981,6 +1043,21 @@ static void pi_desc_init(struct vcpu *v)
     v->arch.hvm.vmx.pi_desc.ndst = APIC_INVALID_DEST;
 }
 
+/*
+ * 对于2个vcpu的hvm, 被调用两次
+ *
+ * [0] vmx_create_vmcs
+ * [0] vmx.c#vmx_vcpu_initialise
+ * [0] vlapic_init
+ * [0] hvm_vcpu_initialise
+ * [0] vcpu_init_fpu
+ * [0] arch_vcpu_create
+ * [0] vcpu_create
+ * [0] do_domctl
+ *
+ * called by only:
+ *   - arch/x86/hvm/vmx/vmcs.c|1781| <<vmx_create_vmcs>> if ( (rc = construct_vmcs(v)) != 0 )
+ */
 static int construct_vmcs(struct vcpu *v)
 {
     struct domain *d = v->domain;
@@ -1019,6 +1096,14 @@ static int construct_vmcs(struct vcpu *v)
 
     if ( paging_mode_hap(d) )
     {
+        /*
+	 * hap一般hvm下都是打开的!
+	 */
+
+        /*
+         * 这里取消了invlpg和cr3的访问,
+	 * 所以调用invlpg和访问cr3就不会trap了
+         */
         v->arch.hvm.vmx.exec_control &= ~(CPU_BASED_INVLPG_EXITING |
                                           CPU_BASED_CR3_LOAD_EXITING |
                                           CPU_BASED_CR3_STORE_EXITING);
@@ -1726,6 +1811,10 @@ void vmx_domain_update_eptp(struct domain *d)
     ept_sync_domain(p2m);
 }
 
+/*
+ * called only by:
+ *   - arch/x86/hvm/vmx/vmx.c|434| <<vmx_vcpu_initialise>> if ( (rc = vmx_create_vmcs(v)) != 0 )
+ */
 int vmx_create_vmcs(struct vcpu *v)
 {
     struct vmx_vcpu *vmx = &v->arch.hvm.vmx;
diff --git a/xen/arch/x86/hvm/vmx/vmx.c b/xen/arch/x86/hvm/vmx/vmx.c
index 725dd88..989b6a6 100644
--- a/xen/arch/x86/hvm/vmx/vmx.c
+++ b/xen/arch/x86/hvm/vmx/vmx.c
@@ -421,6 +421,13 @@ static void vmx_domain_destroy(struct domain *d)
     vmx_free_vlapic_mapping(d);
 }
 
+/*
+ * struct hvm_function_table vmx_function_table.vcpu_initialise = vmx_vcpu_initialise()
+ *
+ * called by:
+ *   - arch/arm/processor.c|39| <<processor_vcpu_initialise>> this_cpu(processor)->vcpu_initialise(v);
+ *   - arch/x86/hvm/hvm.c|1513| <<hvm_vcpu_initialise>> if ( (rc = hvm_funcs.vcpu_initialise(v)) != 0 )
+ */
 static int vmx_vcpu_initialise(struct vcpu *v)
 {
     int rc;
@@ -2439,6 +2446,10 @@ static void pi_notification_interrupt(struct cpu_user_regs *regs)
 static void __init lbr_tsx_fixup_check(void);
 static void __init bdw_erratum_bdf14_fixup_check(void);
 
+/*
+ * called by:
+ *   - arch/x86/hvm/hvm.c|150| <<hvm_enable>> fns = start_vmx();
+ */
 const struct hvm_function_table * __init start_vmx(void)
 {
     set_in_cr4(X86_CR4_VMXE);
diff --git a/xen/arch/x86/hvm/vpic.c b/xen/arch/x86/hvm/vpic.c
index 3f3fb7a..6eec184 100644
--- a/xen/arch/x86/hvm/vpic.c
+++ b/xen/arch/x86/hvm/vpic.c
@@ -61,6 +61,12 @@ static int vpic_get_priority(struct hvm_hw_vpic *vpic, uint8_t mask)
 }
 
 /* Return the PIC's highest priority pending interrupt. Return -1 if none. */
+/*
+ * called by:
+ *   - arch/x86/hvm/vpic.c|101| <<vpic_update_int_output>> irq = vpic_get_highest_priority_irq(vpic);
+ *   - arch/x86/hvm/vpic.c|166| <<vpic_intack>> irq = vpic_get_highest_priority_irq(vpic);
+ *   - arch/x86/hvm/vpic.c|173| <<vpic_intack>> irq = vpic_get_highest_priority_irq(vpic);
+ */
 static int vpic_get_highest_priority_irq(struct hvm_hw_vpic *vpic)
 {
     int cur_priority, priority, irq;
@@ -92,6 +98,16 @@ static int vpic_get_highest_priority_irq(struct hvm_hw_vpic *vpic)
     return (priority < cur_priority) ? irq : -1;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpic.c|127| <<vpic_update_int_output>> vpic_update_int_output(vpic);
+ *   - arch/x86/hvm/vpic.c|134| <<vpic_update_int_output>> vpic_update_int_output(vpic);
+ *   - arch/x86/hvm/vpic.c|154| <<__vpic_intack>> vpic_update_int_output(vpic);
+ *   - arch/x86/hvm/vpic.c|261| <<vpic_ioport_write>> vpic_update_int_output(vpic);
+ *   - arch/x86/hvm/vpic.c|304| <<vpic_ioport_write>> vpic_update_int_output(vpic);
+ *   - arch/x86/hvm/vpic.c|464| <<vpic_irq_positive_edge>> vpic_update_int_output(vpic);
+ *   - arch/x86/hvm/vpic.c|482| <<vpic_irq_negative_edge>> vpic_update_int_output(vpic);
+ */
 static void vpic_update_int_output(struct hvm_hw_vpic *vpic)
 {
     int irq;
@@ -154,6 +170,11 @@ static void __vpic_intack(struct hvm_hw_vpic *vpic, int irq)
     vpic_update_int_output(vpic);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpic.c|317| <<vpic_ioport_read>> return vpic_intack(vpic);
+ *   - arch/x86/hvm/vpic.c|497| <<vpic_ack_pending_irq>> irq = vpic_intack(vpic);
+ */
 static int vpic_intack(struct hvm_hw_vpic *vpic)
 {
     int irq = -1;
@@ -335,6 +356,11 @@ static int vpic_intercept_pic_io(
         return X86EMUL_OKAY;
     }
 
+    /*
+     * vpic的声明:
+     *
+     * struct hvm_hw_vpic     vpic[2];
+     */
     vpic = &current->domain->arch.hvm.vpic[port >> 7];
 
     if ( dir == IOREQ_WRITE )
diff --git a/xen/arch/x86/hvm/vpt.c b/xen/arch/x86/hvm/vpt.c
index ecd25d7..5cab502 100644
--- a/xen/arch/x86/hvm/vpt.c
+++ b/xen/arch/x86/hvm/vpt.c
@@ -23,18 +23,70 @@
 #include <asm/apic.h>
 #include <asm/mc146818rtc.h>
 
+/*
+ * used by:
+ *   - arch/x86/hvm/vpt.c|201| <<pt_process_missed_ticks>> if ( mode_is(pt->vcpu->domain, no_missed_ticks_pending) )
+ *   - arch/x86/hvm/vpt.c|210| <<pt_freeze_time>> if ( !mode_is(v->domain, delay_for_missed_ticks) )
+ *   - arch/x86/hvm/vpt.c|218| <<pt_thaw_time>> if ( !mode_is(v->domain, delay_for_missed_ticks) )
+ *   - arch/x86/hvm/vpt.c|299| <<pt_irq_fired>> else if ( mode_is(v->domain, one_missed_tick_pending) ||
+ *   - arch/x86/hvm/vpt.c|300| <<pt_irq_fired>> mode_is(v->domain, no_missed_ticks_pending) )
+ *   - arch/x86/hvm/vpt.c|318| <<pt_irq_fired>> if ( mode_is(v->domain, delay_for_missed_ticks) &&
+ *
+ * #define HVM_PARAM_TIMER_MODE   10
+ *
+ * #define HVMPTM_delay_for_missed_ticks    0
+ *   Do not advance a vcpu's time beyond the correct delivery time for
+ *   interrupts that have been missed due to preemption. Deliver missed
+ *   interrupts when the vcpu is rescheduled and advance the vcpu's virtual
+ *   time stepwise for each one.
+ *
+ * #define HVMPTM_no_delay_for_missed_ticks 1
+ *   As above, missed interrupts are delivered, but guest time always tracks
+ *   wallclock (i.e., real) time while doing so.
+ *
+ * #define HVMPTM_no_missed_ticks_pending   2
+ *   No missed interrupts are held pending. Instead, to ensure ticks are
+ *   delivered at some non-zero rate, if we detect missed ticks then the
+ *   internal tick alarm is not disabled if the VCPU is preempted during the
+ *   next tick period.
+ *
+ * #define HVMPTM_one_missed_tick_pending   3
+ *   Missed interrupts are collapsed together and delivered as one 'late tick'.
+ *   Guest time always tracks wallclock (i.e., real) time.
+ */
 #define mode_is(d, name) \
     ((d)->arch.hvm.params[HVM_PARAM_TIMER_MODE] == HVMPTM_##name)
 
+/*
+ * called only by:
+ *   - arch/x86/hvm/hvm.c|654| <<hvm_domain_initialise>> hvm_init_guest_time(d);
+ */
 void hvm_init_guest_time(struct domain *d)
 {
+    /*
+     * struct domain
+     *   struct arch_domain arch;
+     *     struct hvm_domain hvm;
+     *       struct pl_time *pl_time;
+     */
     struct pl_time *pl = d->arch.hvm.pl_time;
 
     spin_lock_init(&pl->pl_time_lock);
+    /*
+     * struct pl_time的stime_offset使用的地方:
+     *   - arch/x86/hvm/vpt.c|47| <<hvm_init_guest_time>> pl->stime_offset = -(u64)get_s_time();
+     *   - arch/x86/hvm/vpt.c|66| <<hvm_get_guest_time_fixed>> now = get_s_time_fixed(at_tsc) + pl->stime_offset;
+     */
     pl->stime_offset = -(u64)get_s_time();
     pl->last_guest_time = 0;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/hvm.c|412| <<hvm_set_guest_tsc_fixed>> tsc = hvm_get_guest_time_fixed(v, at_tsc);
+ *   - arch/x86/hvm/hvm.c|451| <<hvm_get_guest_tsc_fixed>> tsc = hvm_get_guest_time_fixed(v, at_tsc);
+ *   - include/asm-x86/hvm/hvm.h|357| <<hvm_get_guest_time>> #define hvm_get_guest_time(v) hvm_get_guest_time_fixed(v, 0)
+ */
 uint64_t hvm_get_guest_time_fixed(const struct vcpu *v, uint64_t at_tsc)
 {
     struct pl_time *pl = v->domain->arch.hvm.pl_time;
@@ -58,6 +110,11 @@ uint64_t hvm_get_guest_time_fixed(const struct vcpu *v, uint64_t at_tsc)
     return now + v->arch.hvm.stime_offset;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpt.c|213| <<pt_thaw_time>> hvm_set_guest_time(v, v->arch.hvm.guest_time);
+ *   - arch/x86/hvm/vpt.c|304| <<pt_irq_fired>> hvm_set_guest_time(v, pt->last_plt_gtime);
+ */
 void hvm_set_guest_time(struct vcpu *v, u64 guest_time)
 {
     u64 offset = guest_time - hvm_get_guest_time(v);
@@ -75,16 +132,35 @@ void hvm_set_guest_time(struct vcpu *v, u64 guest_time)
     }
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpt.c|427| <<is_pt_irq>> (intack.vector == pt_irq_vector(pt, intack.source)) )
+ *
+ * hvm_intsrc src有以下种类:
+ * - hvm_intsrc_none,
+ * - hvm_intsrc_pic,
+ * - hvm_intsrc_lapic,
+ * - hvm_intsrc_nmi,
+ * - hvm_intsrc_mce,
+ * - hvm_intsrc_vector
+ */
 static int pt_irq_vector(struct periodic_time *pt, enum hvm_intsrc src)
 {
     struct vcpu *v = pt->vcpu;
     unsigned int gsi, isa_irq;
     int vector;
 
+    /*
+     * source的种类:
+     *   #define PTSRC_isa    1 // ISA time source
+     *   #define PTSRC_lapic  2 // LAPIC time source
+     *   #define PTSRC_ioapic 3 // IOAPIC time source
+     */
     if ( pt->source == PTSRC_lapic )
         return pt->irq;
 
     isa_irq = pt->irq;
+    /* #define hvm_isa_irq_to_gsi(isa_irq) ((isa_irq) ? : 2) */
     gsi = hvm_isa_irq_to_gsi(isa_irq);
 
     if ( src == hvm_intsrc_pic )
@@ -104,6 +180,10 @@ static int pt_irq_vector(struct periodic_time *pt, enum hvm_intsrc src)
     return vector;
 }
 
+/*
+ * called by only:
+ *   - arch/x86/hvm/vpt.c|380| <<pt_update_irq>> if ( (pt->irq != RTC_IRQ || !pt->priv) && pt_irq_masked(pt) &&
+ */
 static int pt_irq_masked(struct periodic_time *pt)
 {
     struct vcpu *v = pt->vcpu;
@@ -127,6 +207,7 @@ static int pt_irq_masked(struct periodic_time *pt)
         if ( !(pic_imr & (1 << (pt->irq & 7))) && vlapic_accept_pic_intr(v) )
             return 0;
 
+	/* #define hvm_isa_irq_to_gsi(isa_irq) ((isa_irq) ? : 2) */
         gsi = hvm_isa_irq_to_gsi(pt->irq);
     }
 
@@ -171,10 +252,20 @@ static void pt_unlock(struct periodic_time *pt)
     spin_unlock(&pt->vcpu->arch.hvm.tm_lock);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpt.c|247| <<pt_restore_timer>> pt_process_missed_ticks(pt);
+ *   - arch/x86/hvm/vpt.c|287| <<pt_irq_fired>> pt_process_missed_ticks(pt);
+ *   - arch/x86/hvm/vpt.c|296| <<pt_irq_fired>> pt_process_missed_ticks(pt);
+ */
 static void pt_process_missed_ticks(struct periodic_time *pt)
 {
     s_time_t missed_ticks, now = NOW();
 
+    /*
+     * 在以下修改:
+     *   - arch/x86/hvm/vpt.c|627| <<create_periodic_time>> pt->one_shot = !period;
+     */
     if ( pt->one_shot )
         return;
 
@@ -182,6 +273,17 @@ static void pt_process_missed_ticks(struct periodic_time *pt)
     if ( missed_ticks <= 0 )
         return;
 
+    /*
+     * periodic_time->period使用的地方:
+     *   - arch/x86/hvm/vpt.c|254| <<pt_process_missed_ticks>> missed_ticks = missed_ticks / (s_time_t) pt->period + 1;
+     *   - arch/x86/hvm/vpt.c|259| <<pt_process_missed_ticks>> pt->scheduled += missed_ticks * pt->period;
+     *   - arch/x86/hvm/vpt.c|333| <<pt_timer_fn>> pt->scheduled += pt->period;
+     *   - arch/x86/hvm/vpt.c|367| <<pt_irq_fired>> pt->last_plt_gtime += pt->period;
+     *   - arch/x86/hvm/vpt.c|424| <<pt_update_irq>> if ( (pt->last_plt_gtime + pt->period) < max_lag )
+     *   - arch/x86/hvm/vpt.c|426| <<pt_update_irq>> max_lag = pt->last_plt_gtime + pt->period;
+     *   - arch/x86/hvm/vpt.c|627| <<create_periodic_time>> pt->period = period;
+     *   - arch/x86/hvm/vpt.c|642| <<create_periodic_time>> pt->scheduled = align_timer(pt->scheduled, pt->period);
+     */
     missed_ticks = missed_ticks / (s_time_t) pt->period + 1;
     if ( mode_is(pt->vcpu->domain, no_missed_ticks_pending) )
         pt->do_not_freeze = !pt->pending_intr_nr;
@@ -190,6 +292,10 @@ static void pt_process_missed_ticks(struct periodic_time *pt)
     pt->scheduled += missed_ticks * pt->period;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpt.c|296| <<pt_save_timer>> pt_freeze_time(v);
+ */
 static void pt_freeze_time(struct vcpu *v)
 {
     if ( !mode_is(v->domain, delay_for_missed_ticks) )
@@ -198,6 +304,10 @@ static void pt_freeze_time(struct vcpu *v)
     v->arch.hvm.guest_time = hvm_get_guest_time(v);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpt.c|317| <<pt_restore_timer>> pt_thaw_time(v);
+ */
 static void pt_thaw_time(struct vcpu *v)
 {
     if ( !mode_is(v->domain, delay_for_missed_ticks) )
@@ -210,6 +320,10 @@ static void pt_thaw_time(struct vcpu *v)
     v->arch.hvm.guest_time = 0;
 }
 
+/*
+ * called by:
+ *   - arch/x86/domain.c|1741| <<context_switch>> pt_save_timer(prev);
+ */
 void pt_save_timer(struct vcpu *v)
 {
     struct list_head *head = &v->arch.hvm.tm_list;
@@ -229,6 +343,10 @@ void pt_save_timer(struct vcpu *v)
     spin_unlock(&v->arch.hvm.tm_lock);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/hvm.c|521| <<hvm_do_resume>> pt_restore_timer(v);
+ */
 void pt_restore_timer(struct vcpu *v)
 {
     struct list_head *head = &v->arch.hvm.tm_list;
@@ -250,13 +368,51 @@ void pt_restore_timer(struct vcpu *v)
     spin_unlock(&v->arch.hvm.tm_lock);
 }
 
+/*
+ * used by only:
+ *   - arch/x86/hvm/vpt.c|621| <<create_periodic_time>> init_timer(&pt->timer, pt_timer_fn, pt, v->processor);
+ */
 static void pt_timer_fn(void *data)
 {
     struct periodic_time *pt = data;
 
+    /*
+     * 参考pt_update_irq()
+     */
+
     pt_lock(pt);
 
+    /*
+     * used by:
+     *   - arch/x86/hvm/vpt.c|241| <<pt_process_missed_ticks>> pt->do_not_freeze = !pt->pending_intr_nr;
+     *   - arch/x86/hvm/vpt.c|243| <<pt_process_missed_ticks>> pt->pending_intr_nr += missed_ticks;
+     *   - arch/x86/hvm/vpt.c|295| <<pt_restore_timer>> if ( pt->pending_intr_nr == 0 )
+     *   - arch/x86/hvm/vpt.c|317| <<pt_timer_fn>> pt->pending_intr_nr++;
+     *   - arch/x86/hvm/vpt.c|340| <<pt_irq_fired>> pt->pending_intr_nr = 0;
+     *   - arch/x86/hvm/vpt.c|347| <<pt_irq_fired>> pt->pending_intr_nr = 0;
+     *   - arch/x86/hvm/vpt.c|353| <<pt_irq_fired>> if ( --pt->pending_intr_nr == 0 )
+     *   - arch/x86/hvm/vpt.c|356| <<pt_irq_fired>> if ( pt->pending_intr_nr == 0 )
+     *   - arch/x86/hvm/vpt.c|385| <<pt_update_irq>> if ( pt->pending_intr_nr )
+     *   - arch/x86/hvm/vpt.c|498| <<is_pt_irq>> if ( pt->pending_intr_nr && pt->irq_issued &&
+     *   - arch/x86/hvm/vpt.c|588| <<create_periodic_time>> pt->pending_intr_nr = 0;
+     *   - arch/x86/hvm/vpt.c|668| <<destroy_periodic_time>> pt->pending_intr_nr = 0;
+     *   - arch/x86/hvm/vpt.c|753| <<pt_resume>> if ( pt->pending_intr_nr && !pt->on_list )
+     *   - include/asm-x86/hvm/vpt.h|160| <<pt_active>> #define pt_active(pt) ((pt)->on_list || (pt)->pending_intr_nr)
+     */
     pt->pending_intr_nr++;
+    /*
+     * used by:
+     *   - arch/x86/hvm/vpt.c|235| <<pt_process_missed_ticks>> missed_ticks = now - pt->scheduled;
+     *   - arch/x86/hvm/vpt.c|244| <<pt_process_missed_ticks>> pt->scheduled += missed_ticks * pt->period;
+     *   - arch/x86/hvm/vpt.c|298| <<pt_restore_timer>> set_timer(&pt->timer, pt->scheduled);
+     *   - arch/x86/hvm/vpt.c|318| <<pt_timer_fn>> pt->scheduled += pt->period;
+     *   - arch/x86/hvm/vpt.c|348| <<pt_irq_fired>> set_timer(&pt->timer, pt->scheduled);
+     *   - arch/x86/hvm/vpt.c|357| <<pt_irq_fired>> set_timer(&pt->timer, pt->scheduled);
+     *   - arch/x86/hvm/vpt.c|607| <<create_periodic_time>> pt->scheduled = NOW() + delta;
+     *   - arch/x86/hvm/vpt.c|613| <<create_periodic_time>> pt->scheduled = align_timer(pt->scheduled, pt->period);
+     *   - arch/x86/hvm/vpt.c|623| <<create_periodic_time>> pt->scheduled += delta >> 1;
+     *   - arch/x86/hvm/vpt.c|634| <<create_periodic_time>> set_timer(&pt->timer, pt->scheduled);
+     */
     pt->scheduled += pt->period;
     pt->do_not_freeze = 0;
 
@@ -265,6 +421,11 @@ static void pt_timer_fn(void *data)
     pt_unlock(pt);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpt.c|410| <<pt_update_irq>> pt_irq_fired(v, pt);
+ *   - arch/x86/hvm/vpt.c|472| <<pt_intr_post>> pt_irq_fired(v, pt);
+ */
 static void pt_irq_fired(struct vcpu *v, struct periodic_time *pt)
 {
     pt->irq_issued = false;
@@ -287,6 +448,17 @@ static void pt_irq_fired(struct vcpu *v, struct periodic_time *pt)
     else
     {
         pt->last_plt_gtime += pt->period;
+        /*
+	 * pending_intr_nr在以下设置:
+	 *   - arch/x86/hvm/vpt.c|243| <<pt_process_missed_ticks>> pt->pending_intr_nr += missed_ticks;
+	 *   - arch/x86/hvm/vpt.c|295| <<pt_restore_timer>> if ( pt->pending_intr_nr == 0 )
+	 *   - arch/x86/hvm/vpt.c|317| <<pt_timer_fn>> pt->pending_intr_nr++;
+	 *   - arch/x86/hvm/vpt.c|340| <<pt_irq_fired>> pt->pending_intr_nr = 0;
+	 *   - arch/x86/hvm/vpt.c|347| <<pt_irq_fired>> pt->pending_intr_nr = 0;
+	 *   - arch/x86/hvm/vpt.c|353| <<pt_irq_fired>> if ( --pt->pending_intr_nr == 0 )
+	 *   - arch/x86/hvm/vpt.c|588| <<create_periodic_time>> pt->pending_intr_nr = 0;
+	 *   - arch/x86/hvm/vpt.c|668| <<destroy_periodic_time>> pt->pending_intr_nr = 0;
+	 */
         if ( --pt->pending_intr_nr == 0 )
         {
             pt_process_missed_ticks(pt);
@@ -300,6 +472,11 @@ static void pt_irq_fired(struct vcpu *v, struct periodic_time *pt)
         hvm_set_guest_time(v, pt->last_plt_gtime);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/svm/intr.c|146| <<svm_intr_assist>> pt_update_irq(v);
+ *   - arch/x86/hvm/vmx/intr.c|248| <<vmx_intr_assist>> pt_vector = pt_update_irq(v);
+ */
 int pt_update_irq(struct vcpu *v)
 {
     struct list_head *head = &v->arch.hvm.tm_list;
@@ -312,6 +489,9 @@ int pt_update_irq(struct vcpu *v)
 
     earliest_pt = NULL;
     max_lag = -1ULL;
+    /*
+     * head就是&v->arch.hvm.tm_list
+     */
     list_for_each_entry_safe ( pt, temp, head, list )
     {
         if ( pt->pending_intr_nr )
@@ -329,6 +509,13 @@ int pt_update_irq(struct vcpu *v)
             {
                 if ( (pt->last_plt_gtime + pt->period) < max_lag )
                 {
+                    /*
+		     * 在以下设置last_plt_gtime:
+		     *   - arch/x86/emul-i8254.c|465| <<pit_load>> pit->pt0.last_plt_gtime = get_guest_time(d->vcpu[0]);
+		     *   - arch/x86/hvm/vpt.c|409| <<pt_irq_fired>> pt->last_plt_gtime = hvm_get_guest_time(v);
+		     *   - arch/x86/hvm/vpt.c|416| <<pt_irq_fired>> pt->last_plt_gtime += pt->period;
+		     *   - arch/x86/hvm/vpt.c|696| <<create_periodic_time>> pt->last_plt_gtime = hvm_get_guest_time(pt->vcpu);
+		     */
                     max_lag = pt->last_plt_gtime + pt->period;
                     earliest_pt = pt;
                 }
@@ -415,9 +602,27 @@ int pt_update_irq(struct vcpu *v)
     return pt_vector;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpt.c|445| <<pt_intr_post>> pt = is_pt_irq(v, intack);
+ */
 static struct periodic_time *is_pt_irq(
     struct vcpu *v, struct hvm_intack intack)
 {
+    /*
+     * used by:
+     *   - arch/x86/domain.c|1740| <<context_switch>> if ( is_hvm_domain(prevd) && !list_empty(&prev->arch.hvm.tm_list) )
+     *   - arch/x86/hvm/hvm.c|1506| <<hvm_vcpu_initialise>> INIT_LIST_HEAD(&v->arch.hvm.tm_list);
+     *   - arch/x86/hvm/vpt.c|269| <<pt_save_timer>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|288| <<pt_restore_timer>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|373| <<pt_update_irq>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|466| <<pt_update_irq>> list_for_each_entry ( pt, &v->arch.hvm.tm_list, list )
+     *   - arch/x86/hvm/vpt.c|493| <<is_pt_irq>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|548| <<pt_migrate>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|631| <<create_periodic_time>> list_add(&pt->list, &v->arch.hvm.tm_list);
+     *   - arch/x86/hvm/vpt.c|708| <<pt_adjust_vcpu>> list_add(&pt->list, &v->arch.hvm.tm_list);
+     *   - arch/x86/hvm/vpt.c|756| <<pt_resume>> list_add(&pt->list, &pt->vcpu->arch.hvm.tm_list);
+     */
     struct list_head *head = &v->arch.hvm.tm_list;
     struct periodic_time *pt;
 
@@ -431,6 +636,15 @@ static struct periodic_time *is_pt_irq(
     return NULL;
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/svm/intr.c|217| <<svm_intr_assist>> pt_intr_post(v, intack);
+ *   - arch/x86/hvm/vmx/intr.c|206| <<nvmx_intr_intercept>> pt_intr_post(v, intack);
+ *   - arch/x86/hvm/vmx/intr.c|390| <<vmx_intr_assist>> pt_intr_post(v, intack);
+ *   - arch/x86/hvm/vmx/intr.c|396| <<vmx_intr_assist>> pt_intr_post(v, intack);
+ *
+ * 对于第四个timer check是hvm_intsrc_lapic
+ */
 void pt_intr_post(struct vcpu *v, struct hvm_intack intack)
 {
     struct periodic_time *pt;
@@ -449,6 +663,11 @@ void pt_intr_post(struct vcpu *v, struct hvm_intack intack)
         return;
     }
 
+    /*
+     * called by:
+     *   - arch/x86/hvm/vpt.c|410| <<pt_update_irq>> pt_irq_fired(v, pt);
+     *   - arch/x86/hvm/vpt.c|472| <<pt_intr_post>> pt_irq_fired(v, pt);
+     */
     pt_irq_fired(v, pt);
 
     cb = pt->cb;
@@ -460,6 +679,10 @@ void pt_intr_post(struct vcpu *v, struct hvm_intack intack)
         cb(v, cb_priv);
 }
 
+/*
+ * used by only:
+ *   - arch/x86/hvm/hvm.c|467| <<hvm_migrate_timers>> pt_migrate(v);
+ */
 void pt_migrate(struct vcpu *v)
 {
     struct list_head *head = &v->arch.hvm.tm_list;
@@ -473,10 +696,34 @@ void pt_migrate(struct vcpu *v)
     spin_unlock(&v->arch.hvm.tm_lock);
 }
 
+/*
+ * called by:
+ *   - arch/x86/emul-i8254.c|193| <<pit_load_count>> create_periodic_time(v, &pit->pt0, period, period, 0, pit_time_fired,
+ *   - arch/x86/emul-i8254.c|200| <<pit_load_count>> create_periodic_time(v, &pit->pt0, period, 0, 0, pit_time_fired,
+ *   - arch/x86/hvm/hpet.c|312| <<hpet_set_timer>> create_periodic_time(vhpet_vcpu(h), &h->pt[tn],
+ *   - arch/x86/hvm/rtc.c|158| <<rtc_timer_update>> create_periodic_time(v, &s->pt, delta, period,
+ *   - arch/x86/hvm/vlapic.c|749| <<vlapic_update_timer>> create_periodic_time(current, &vlapic->pt, delta,
+ *   - arch/x86/hvm/vlapic.c|1202| <<vlapic_tdt_msr_set>> create_periodic_time(v, &vlapic->pt, delta, 0,
+ *   - arch/x86/hvm/vlapic.c|1216| <<vlapic_tdt_msr_set>> create_periodic_time(v, &vlapic->pt, 0, 0,
+ *   - arch/x86/hvm/vlapic.c|1453| <<lapic_rearm>> create_periodic_time(vlapic_vcpu(s), &s->pt, period,
+ *
+ * 一个例子是
+ * 213         create_periodic_time(v, &pit->pt0, period, period, 0, pit_time_fired,
+ * 214                              &pit->count_load_time[channel], false);
+ */
 void create_periodic_time(
     struct vcpu *v, struct periodic_time *pt, uint64_t delta,
     uint64_t period, uint8_t irq, time_cb *cb, void *data, bool level)
 {
+    /*
+     * pt->source在以下设置:
+     *   - arch/x86/emul-i8254.c|495| <<pit_reset>> pit->pt0.source = PTSRC_isa;
+     *   - arch/x86/hvm/hpet.c|289| <<hpet_set_timer>> h->pt[tn].source = PTSRC_isa;
+     *   - arch/x86/hvm/hpet.c|294| <<hpet_set_timer>> h->pt[tn].source = PTSRC_ioapic;
+     *   - arch/x86/hvm/hpet.c|731| <<hpet_set>> h->pt[i].source = PTSRC_isa;
+     *   - arch/x86/hvm/rtc.c|799| <<rtc_reset>> s->pt.source = PTSRC_isa;
+     *   - arch/x86/hvm/vlapic.c|1664| <<vlapic_init>> vlapic->pt.source = PTSRC_lapic;
+     */
     if ( !pt->source ||
          (irq >= NR_ISAIRQS && pt->source == PTSRC_isa) ||
          (level && period) ||
@@ -491,6 +738,15 @@ void create_periodic_time(
 
     spin_lock(&v->arch.hvm.tm_lock);
 
+    /*
+     *   - arch/x86/hvm/vpt.c|243| <<pt_process_missed_ticks>> pt->pending_intr_nr += missed_ticks;
+     *   - arch/x86/hvm/vpt.c|317| <<pt_timer_fn>> pt->pending_intr_nr++;
+     *   - arch/x86/hvm/vpt.c|340| <<pt_irq_fired>> pt->pending_intr_nr = 0;
+     *   - arch/x86/hvm/vpt.c|347| <<pt_irq_fired>> pt->pending_intr_nr = 0;
+     *   - arch/x86/hvm/vpt.c|353| <<pt_irq_fired>> if ( --pt->pending_intr_nr == 0 )
+     *   - arch/x86/hvm/vpt.c|588| <<create_periodic_time>> pt->pending_intr_nr = 0;
+     *   - arch/x86/hvm/vpt.c|668| <<destroy_periodic_time>> pt->pending_intr_nr = 0;
+     */
     pt->pending_intr_nr = 0;
     pt->do_not_freeze = 0;
     pt->irq_issued = 0;
@@ -510,12 +766,28 @@ void create_periodic_time(
     pt->irq = irq;
     pt->one_shot = !period;
     pt->level = level;
+    /*
+     * used by:
+     *   - arch/x86/hvm/vpt.c|235| <<pt_process_missed_ticks>> missed_ticks = now - pt->scheduled;
+     *   - arch/x86/hvm/vpt.c|244| <<pt_process_missed_ticks>> pt->scheduled += missed_ticks * pt->period;
+     *   - arch/x86/hvm/vpt.c|298| <<pt_restore_timer>> set_timer(&pt->timer, pt->scheduled);
+     *   - arch/x86/hvm/vpt.c|318| <<pt_timer_fn>> pt->scheduled += pt->period;
+     *   - arch/x86/hvm/vpt.c|348| <<pt_irq_fired>> set_timer(&pt->timer, pt->scheduled);
+     *   - arch/x86/hvm/vpt.c|357| <<pt_irq_fired>> set_timer(&pt->timer, pt->scheduled);
+     *   - arch/x86/hvm/vpt.c|607| <<create_periodic_time>> pt->scheduled = NOW() + delta;
+     *   - arch/x86/hvm/vpt.c|613| <<create_periodic_time>> pt->scheduled = align_timer(pt->scheduled, pt->period);
+     *   - arch/x86/hvm/vpt.c|623| <<create_periodic_time>> pt->scheduled += delta >> 1;
+     *   - arch/x86/hvm/vpt.c|634| <<create_periodic_time>> set_timer(&pt->timer, pt->scheduled);
+     */
     pt->scheduled = NOW() + delta;
 
     if ( !pt->one_shot )
     {
         if ( v->domain->arch.hvm.params[HVM_PARAM_VPT_ALIGN] )
         {
+            /*
+	     * Calculate the aligned first tick time for a given periodic timer.
+	     */
             pt->scheduled = align_timer(pt->scheduled, pt->period);
         }
         else if ( pt->source == PTSRC_lapic )
@@ -530,10 +802,35 @@ void create_periodic_time(
         }
     }
 
+    /*
+     * 调用cb的地方:
+     *   - arch/x86/hvm/vpt.c|566| <<pt_update_irq>> cb(v, cb_priv);
+     *   - arch/x86/hvm/vpt.c|628| <<pt_intr_post>> cb(v, cb_priv);
+     *
+     * vmx_intr_assist()
+     *  -> pt_update_irq()
+     *      -> cb = pit_time_fired()
+     *  -> pt_intr_post() 两种情况会调用
+     *      -> cb = pit_time_fired()
+     */
     pt->cb = cb;
     pt->priv = data;
 
     pt->on_list = 1;
+    /*
+     * used by:
+     *   - arch/x86/domain.c|1740| <<context_switch>> if ( is_hvm_domain(prevd) && !list_empty(&prev->arch.hvm.tm_list) )
+     *   - arch/x86/hvm/hvm.c|1506| <<hvm_vcpu_initialise>> INIT_LIST_HEAD(&v->arch.hvm.tm_list);
+     *   - arch/x86/hvm/vpt.c|269| <<pt_save_timer>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|288| <<pt_restore_timer>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|373| <<pt_update_irq>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|466| <<pt_update_irq>> list_for_each_entry ( pt, &v->arch.hvm.tm_list, list )
+     *   - arch/x86/hvm/vpt.c|493| <<is_pt_irq>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|548| <<pt_migrate>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|631| <<create_periodic_time>> list_add(&pt->list, &v->arch.hvm.tm_list);
+     *   - arch/x86/hvm/vpt.c|708| <<pt_adjust_vcpu>> list_add(&pt->list, &v->arch.hvm.tm_list);
+     *   - arch/x86/hvm/vpt.c|756| <<pt_resume>> list_add(&pt->list, &pt->vcpu->arch.hvm.tm_list);
+     */
     list_add(&pt->list, &v->arch.hvm.tm_list);
 
     init_timer(&pt->timer, pt_timer_fn, pt, v->processor);
@@ -542,6 +839,25 @@ void create_periodic_time(
     spin_unlock(&v->arch.hvm.tm_lock);
 }
 
+/*
+ * callled by:
+ *   - arch/x86/emul-i8254.c|205| <<pit_load_count>> destroy_periodic_time(&pit->pt0);
+ *   - arch/x86/emul-i8254.c|390| <<pit_stop_channel0_irq>> destroy_periodic_time(&pit->pt0);
+ *   - arch/x86/emul-i8254.c|457| <<pit_reset>> destroy_periodic_time(&pit->pt0);
+ *   - arch/x86/emul-i8254.c|502| <<pit_deinit>> destroy_periodic_time(&pit->pt0);
+ *   - arch/x86/hvm/hpet.c|214| <<hpet_stop_timer>> destroy_periodic_time(&h->pt[tn]);
+ *   - arch/x86/hvm/hpet.c|282| <<hpet_set_timer>> destroy_periodic_time(&h->pt[tn]);
+ *   - arch/x86/hvm/rtc.c|95| <<rtc_pf_callback>> destroy_periodic_time(&s->pt);
+ *   - arch/x86/hvm/rtc.c|169| <<rtc_timer_update>> destroy_periodic_time(&s->pt);
+ *   - arch/x86/hvm/rtc.c|522| <<rtc_ioport_write>> destroy_periodic_time(&s->pt);
+ *   - arch/x86/hvm/rtc.c|797| <<rtc_reset>> destroy_periodic_time(&s->pt);
+ *   - arch/x86/hvm/rtc.c|845| <<rtc_deinit>> destroy_periodic_time(&s->pt);
+ *   - arch/x86/hvm/vlapic.c|779| <<vlapic_update_timer>> destroy_periodic_time(&vlapic->pt);
+ *   - arch/x86/hvm/vlapic.c|1245| <<vlapic_tdt_msr_set>> destroy_periodic_time(&vlapic->pt);
+ *   - arch/x86/hvm/vlapic.c|1464| <<vlapic_do_init>> destroy_periodic_time(&vlapic->pt);
+ *   - arch/x86/hvm/vlapic.c|1711| <<vlapic_destroy>> destroy_periodic_time(&vlapic->pt);
+ *   - arch/x86/hvm/vpt.c|584| <<create_periodic_time>> destroy_periodic_time(pt);
+ */
 void destroy_periodic_time(struct periodic_time *pt)
 {
     /* Was this structure previously initialised by create_periodic_time()? */
@@ -562,6 +878,15 @@ void destroy_periodic_time(struct periodic_time *pt)
     kill_timer(&pt->timer);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpt.c|625| <<pt_adjust_global_vcpu_target>> pt_adjust_vcpu(&vpit->pt0, v);
+ *   - arch/x86/hvm/vpt.c|631| <<pt_adjust_global_vcpu_target>> pt_adjust_vcpu(&pl_time->vrtc.pt, v);
+ *   - arch/x86/hvm/vpt.c|636| <<pt_adjust_global_vcpu_target>> pt_adjust_vcpu(&pl_time->vhpet.pt[i], v);
+ *
+ * 只有一条调用路径:
+ * vlapic_adjust_i8259_target() --> pt_adjust_global_vcpu_target() --> pt_adjust_vcpu()
+ */
 static void pt_adjust_vcpu(struct periodic_time *pt, struct vcpu *v)
 {
     int on_list;
@@ -583,6 +908,25 @@ static void pt_adjust_vcpu(struct periodic_time *pt, struct vcpu *v)
     if ( on_list )
     {
         pt->on_list = 1;
+	/*
+	 * used by:
+	 *   - arch/x86/domain.c|1740| <<context_switch>> if ( is_hvm_domain(prevd) && !list_empty(&prev->arch.hvm.tm_list) )
+	 *   - arch/x86/hvm/hvm.c|1506| <<hvm_vcpu_initialise>> INIT_LIST_HEAD(&v->arch.hvm.tm_list);
+	 *   - arch/x86/hvm/vpt.c|269| <<pt_save_timer>> struct list_head *head = &v->arch.hvm.tm_list;
+	 *   - arch/x86/hvm/vpt.c|288| <<pt_restore_timer>> struct list_head *head = &v->arch.hvm.tm_list;
+	 *   - arch/x86/hvm/vpt.c|373| <<pt_update_irq>> struct list_head *head = &v->arch.hvm.tm_list;
+	 *   - arch/x86/hvm/vpt.c|466| <<pt_update_irq>> list_for_each_entry ( pt, &v->arch.hvm.tm_list, list )
+	 *   - arch/x86/hvm/vpt.c|493| <<is_pt_irq>> struct list_head *head = &v->arch.hvm.tm_list;
+	 *   - arch/x86/hvm/vpt.c|548| <<pt_migrate>> struct list_head *head = &v->arch.hvm.tm_list;
+	 *   - arch/x86/hvm/vpt.c|631| <<create_periodic_time>> list_add(&pt->list, &v->arch.hvm.tm_list);
+	 *   - arch/x86/hvm/vpt.c|708| <<pt_adjust_vcpu>> list_add(&pt->list, &v->arch.hvm.tm_list);
+	 *   - arch/x86/hvm/vpt.c|756| <<pt_resume>> list_add(&pt->list, &pt->vcpu->arch.hvm.tm_list);
+	 *
+	 * struct vcpu
+	 *  -> struct arch_vcpu arch
+	 *      -> struct hvm_vcpu hvm
+	 *          -> struct list_head tm_list
+	 */
         list_add(&pt->list, &v->arch.hvm.tm_list);
 
         migrate_timer(&pt->timer, v->processor);
@@ -590,6 +934,10 @@ static void pt_adjust_vcpu(struct periodic_time *pt, struct vcpu *v)
     spin_unlock(&v->arch.hvm.tm_lock);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vlapic.c|1293| <<vlapic_adjust_i8259_target>> pt_adjust_global_vcpu_target(v);
+ */
 void pt_adjust_global_vcpu_target(struct vcpu *v)
 {
     struct PITState *vpit;
@@ -599,6 +947,22 @@ void pt_adjust_global_vcpu_target(struct vcpu *v)
     if ( !v || !has_vpit(v->domain) )
         return;
 
+    /*
+     * struct domain
+     *  -> struct arch_domain arch
+     *      -> struct hvm_domain hvm
+     *          -> struct pl_time *pl_time
+     *              -> struct RTCState  vrtc
+     *                  -> struct periodic_time pt
+     *                      -> struct timer timer
+     *              -> struct HPETState vhpet
+     *                  -> struct periodic_time pt[HPET_TIMER_NUM]
+     *                      -> struct timer timer
+     *      -> struct PITState vpit
+     *          -> struct periodic_time pt0
+     *              -> struct timer timer
+     */
+
     vpit = &v->domain->arch.vpit;
 
     spin_lock(&vpit->lock);
@@ -618,6 +982,13 @@ void pt_adjust_global_vcpu_target(struct vcpu *v)
 }
 
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpt.c|768| <<pt_may_unmask_irq>> pt_resume(&d->arch.vpit.pt0);
+ *   - arch/x86/hvm/vpt.c|769| <<pt_may_unmask_irq>> pt_resume(&d->arch.hvm.pl_time->vrtc.pt);
+ *   - arch/x86/hvm/vpt.c|771| <<pt_may_unmask_irq>> pt_resume(&d->arch.hvm.pl_time->vhpet.pt[i]);
+ *   - arch/x86/hvm/vpt.c|775| <<pt_may_unmask_irq>> pt_resume(vlapic_pt);
+ */
 static void pt_resume(struct periodic_time *pt)
 {
     if ( pt->vcpu == NULL )
@@ -633,6 +1004,16 @@ static void pt_resume(struct periodic_time *pt)
     pt_unlock(pt);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vioapic.c|290| <<vioapic_write_redirent>> pt_may_unmask_irq(d, NULL);
+ *   - arch/x86/hvm/vlapic.c|846| <<vlapic_reg_write>> pt_may_unmask_irq(vlapic_domain(vlapic), &vlapic->pt);
+ *   - arch/x86/hvm/vlapic.c|884| <<vlapic_reg_write>> pt_may_unmask_irq(v->domain, NULL);
+ *   - arch/x86/hvm/vlapic.c|887| <<vlapic_reg_write>> pt_may_unmask_irq(NULL, &vlapic->pt);
+ *   - arch/x86/hvm/vlapic.c|1161| <<guest_wrmsr_apic_base>> pt_may_unmask_irq(vlapic_domain(vlapic), &vlapic->pt);
+ *   - arch/x86/hvm/vlapic.c|1166| <<guest_wrmsr_apic_base>> pt_may_unmask_irq(vlapic_domain(vlapic), NULL);
+ *   - arch/x86/hvm/vpic.c|330| <<vpic_ioport_write>> pt_may_unmask_irq(vpic_domain(vpic), NULL);
+ */
 void pt_may_unmask_irq(struct domain *d, struct periodic_time *vlapic_pt)
 {
     int i;
diff --git a/xen/arch/x86/irq.c b/xen/arch/x86/irq.c
index 23b4f42..211d796 100644
--- a/xen/arch/x86/irq.c
+++ b/xen/arch/x86/irq.c
@@ -48,6 +48,29 @@ static DECLARE_BITMAP(used_vectors, NR_VECTORS);
 
 static DEFINE_SPINLOCK(vector_lock);
 
+/*
+ * used by:
+ *   - arch/x86/irq.c|51| <<global>> DEFINE_PER_CPU(vector_irq_t, vector_irq);
+ *   - include/asm-x86/irq.h|52| <<global>> DECLARE_PER_CPU(vector_irq_t, vector_irq);
+ *   - arch/x86/i8259.c|106| <<_disable_8259A_irq>> per_cpu(vector_irq, 0)[LEGACY_VECTOR(irq)] = ~irq;
+ *   - arch/x86/i8259.c|122| <<enable_8259A_irq>> per_cpu(vector_irq, 0)[LEGACY_VECTOR(desc->irq)] = desc->irq;
+ *   - arch/x86/i8259.c|350| <<init_IRQ>> per_cpu(vector_irq, cpu)[FIRST_LEGACY_VECTOR + irq] = irq;
+ *   - arch/x86/i8259.c|355| <<init_IRQ>> per_cpu(vector_irq, cpu)[IRQ0_VECTOR] = 0;
+ *   - arch/x86/irq.c|134| <<__bind_irq_vector>> per_cpu(vector_irq, cpu)[vector] = irq;
+ *   - arch/x86/irq.c|258| <<__clear_irq_vector>> ASSERT( per_cpu(vector_irq, cpu)[vector] == irq );
+ *   - arch/x86/irq.c|259| <<__clear_irq_vector>> per_cpu(vector_irq, cpu)[vector] = ~irq;
+ *   - arch/x86/irq.c|283| <<__clear_irq_vector>> ASSERT( per_cpu(vector_irq, cpu)[old_vector] == irq );
+ *   - arch/x86/irq.c|285| <<__clear_irq_vector>> per_cpu(vector_irq, cpu)[old_vector] = ~irq;
+ *   - arch/x86/irq.c|359| <<init_irq_data>> this_cpu(vector_irq)[vector] = INT_MIN;
+ *   - arch/x86/irq.c|515| <<__assign_irq_vector>> if (per_cpu(vector_irq, new_cpu)[vector] >= 0)
+ *   - arch/x86/irq.c|527| <<__assign_irq_vector>> per_cpu(vector_irq, new_cpu)[vector] = irq;
+ *   - arch/x86/irq.c|577| <<setup_vector_irq>> per_cpu(vector_irq, cpu)[vector] = INT_MIN;
+ *   - arch/x86/irq.c|591| <<setup_vector_irq>> per_cpu(vector_irq, cpu)[vector] = irq;
+ *   - arch/x86/irq.c|651| <<irq_move_cleanup_interrupt>> irq = __get_cpu_var(vector_irq)[vector];
+ *   - arch/x86/irq.c|689| <<irq_move_cleanup_interrupt>> __get_cpu_var(vector_irq)[vector] = ~irq;
+ *   - arch/x86/irq.c|821| <<do_IRQ>> int irq = __get_cpu_var(vector_irq[vector]);
+ *   - arch/x86/smpboot.c|1376| <<smp_intr_init>> per_cpu(vector_irq, cpu)[vector] = irq;
+ */
 DEFINE_PER_CPU(vector_irq_t, vector_irq);
 
 DEFINE_PER_CPU(struct cpu_user_regs *, __irq_regs);
@@ -791,6 +814,16 @@ uint8_t alloc_hipriority_vector(void)
     return next++;
 }
 
+/*
+ * used by:
+ *   - arch/x86/irq.c|817| <<global>> static void (*direct_apic_vector[NR_VECTORS])(struct cpu_user_regs *);
+ *   - arch/x86/irq.c|821| <<set_direct_apic_vector>> BUG_ON(direct_apic_vector[vector] != NULL);
+ *   - arch/x86/irq.c|822| <<set_direct_apic_vector>> direct_apic_vector[vector] = handler;
+ *   - arch/x86/irq.c|875| <<do_IRQ>> if (direct_apic_vector[vector] != NULL) {
+ *   - arch/x86/irq.c|876| <<do_IRQ>> (*direct_apic_vector[vector])(regs);
+ *   - arch/x86/irq.c|2393| <<dump_irqs>> if ( direct_apic_vector[i] )
+ *   - arch/x86/irq.c|2394| <<dump_irqs>> printk(" %#02x -> %ps()\n", i, direct_apic_vector[i]);
+ */
 static void (*direct_apic_vector[NR_VECTORS])(struct cpu_user_regs *);
 void set_direct_apic_vector(
     uint8_t vector, void (*handler)(struct cpu_user_regs *))
@@ -818,6 +851,29 @@ void do_IRQ(struct cpu_user_regs *regs)
     uint32_t          tsc_in;
     struct irq_desc  *desc;
     unsigned int      vector = (u8)regs->entry_vector;
+    /*
+     * percpu的vector_irq[]在以下使用:
+     *   - arch/x86/irq.c|51| <<global>> DEFINE_PER_CPU(vector_irq_t, vector_irq);
+     *   - include/asm-x86/irq.h|52| <<global>> DECLARE_PER_CPU(vector_irq_t, vector_irq);
+     *   - arch/x86/i8259.c|106| <<_disable_8259A_irq>> per_cpu(vector_irq, 0)[LEGACY_VECTOR(irq)] = ~irq;
+     *   - arch/x86/i8259.c|122| <<enable_8259A_irq>> per_cpu(vector_irq, 0)[LEGACY_VECTOR(desc->irq)] = desc->irq;
+     *   - arch/x86/i8259.c|350| <<init_IRQ>> per_cpu(vector_irq, cpu)[FIRST_LEGACY_VECTOR + irq] = irq;
+     *   - arch/x86/i8259.c|355| <<init_IRQ>> per_cpu(vector_irq, cpu)[IRQ0_VECTOR] = 0;
+     *   - arch/x86/irq.c|134| <<__bind_irq_vector>> per_cpu(vector_irq, cpu)[vector] = irq;
+     *   - arch/x86/irq.c|258| <<__clear_irq_vector>> ASSERT( per_cpu(vector_irq, cpu)[vector] == irq );
+     *   - arch/x86/irq.c|259| <<__clear_irq_vector>> per_cpu(vector_irq, cpu)[vector] = ~irq;
+     *   - arch/x86/irq.c|283| <<__clear_irq_vector>> ASSERT( per_cpu(vector_irq, cpu)[old_vector] == irq );
+     *   - arch/x86/irq.c|285| <<__clear_irq_vector>> per_cpu(vector_irq, cpu)[old_vector] = ~irq;
+     *   - arch/x86/irq.c|359| <<init_irq_data>> this_cpu(vector_irq)[vector] = INT_MIN;
+     *   - arch/x86/irq.c|515| <<__assign_irq_vector>> if (per_cpu(vector_irq, new_cpu)[vector] >= 0)
+     *   - arch/x86/irq.c|527| <<__assign_irq_vector>> per_cpu(vector_irq, new_cpu)[vector] = irq;
+     *   - arch/x86/irq.c|577| <<setup_vector_irq>> per_cpu(vector_irq, cpu)[vector] = INT_MIN;
+     *   - arch/x86/irq.c|591| <<setup_vector_irq>> per_cpu(vector_irq, cpu)[vector] = irq;
+     *   - arch/x86/irq.c|651| <<irq_move_cleanup_interrupt>> irq = __get_cpu_var(vector_irq)[vector];
+     *   - arch/x86/irq.c|689| <<irq_move_cleanup_interrupt>> __get_cpu_var(vector_irq)[vector] = ~irq;
+     *   - arch/x86/irq.c|821| <<do_IRQ>> int irq = __get_cpu_var(vector_irq[vector]);
+     *   - arch/x86/smpboot.c|1376| <<smp_intr_init>> per_cpu(vector_irq, cpu)[vector] = irq;
+     */
     int irq = __get_cpu_var(vector_irq[vector]);
     struct cpu_user_regs *old_regs = set_irq_regs(regs);
     
@@ -826,6 +882,16 @@ void do_IRQ(struct cpu_user_regs *regs)
     irq_enter();
 
     if (irq < 0) {
+        /*
+	 * direct_apic_vector[]在以下使用:
+	 *   - arch/x86/irq.c|817| <<global>> static void (*direct_apic_vector[NR_VECTORS])(struct cpu_user_regs *);
+	 *   - arch/x86/irq.c|821| <<set_direct_apic_vector>> BUG_ON(direct_apic_vector[vector] != NULL);
+	 *   - arch/x86/irq.c|822| <<set_direct_apic_vector>> direct_apic_vector[vector] = handler;
+	 *   - arch/x86/irq.c|875| <<do_IRQ>> if (direct_apic_vector[vector] != NULL) {
+	 *   - arch/x86/irq.c|876| <<do_IRQ>> (*direct_apic_vector[vector])(regs);
+	 *   - arch/x86/irq.c|2393| <<dump_irqs>> if ( direct_apic_vector[i] )
+	 *   - arch/x86/irq.c|2394| <<dump_irqs>> printk(" %#02x -> %ps()\n", i, direct_apic_vector[i]);
+	 */
         if (direct_apic_vector[vector] != NULL) {
             (*direct_apic_vector[vector])(regs);
         } else {
diff --git a/xen/arch/x86/mm/hap/hap.c b/xen/arch/x86/mm/hap/hap.c
index 412a442..1758c9e 100644
--- a/xen/arch/x86/mm/hap/hap.c
+++ b/xen/arch/x86/mm/hap/hap.c
@@ -438,6 +438,10 @@ void hap_domain_init(struct domain *d)
     paging_log_dirty_init(d, &hap_ops);
 }
 
+/*
+ * called by only:
+ *   - arch/x86/mm/paging.c|847| <<paging_enable>> return hap_enable(d, mode);
+ */
 /* return 0 for success, -errno for failure */
 int hap_enable(struct domain *d, u32 mode)
 {
diff --git a/xen/common/domain.c b/xen/common/domain.c
index 32bca8d..68605e7 100644
--- a/xen/common/domain.c
+++ b/xen/common/domain.c
@@ -134,6 +134,16 @@ static void vcpu_destroy(struct vcpu *v)
     free_vcpu_struct(v);
 }
 
+/*
+ * called by:
+ *   - arch/arm/domain_build.c|83| <<alloc_dom0_vcpu0>> return vcpu_create(dom0, 0, 0);
+ *   - arch/arm/domain_build.c|1992| <<construct_domain>> if ( vcpu_create(d, i, cpu) == NULL )
+ *   - arch/arm/domain_build.c|2029| <<construct_domU>> if ( vcpu_create(d, 0, 0) == NULL )
+ *   - arch/x86/dom0_build.c|206| <<dom0_setup_vcpu>> struct vcpu *v = vcpu_create(d, vcpu_id, cpu);
+ *   - common/domctl.c|565| <<do_domctl():XEN_DOMCTL_max_vcpus>> if ( vcpu_create(d, i, cpu) == NULL )
+ *   - common/schedule.c|1648| <<cpu_schedule_up>> vcpu_create(idle_vcpu[0]->domain, cpu, cpu);
+ *   - common/schedule.c|1821| <<scheduler_init>> if ( vcpu_create(idle_domain, 0, 0) == NULL )
+ */
 struct vcpu *vcpu_create(
     struct domain *d, unsigned int vcpu_id, unsigned int cpu_id)
 {
@@ -271,6 +281,11 @@ custom_param("extra_guest_irqs", parse_extra_guest_irqs);
  * from the RCU path, or from the domain_create() error path before the domain
  * is inserted into the domlist.
  */
+/*
+ * called by:
+ *   - common/domain.c|526| <<domain_create>> _domain_destroy(d);
+ *   - common/domain.c|957| <<complete_domain_destroy>> _domain_destroy(d);
+ */
 static void _domain_destroy(struct domain *d)
 {
     BUG_ON(!d->is_dying);
@@ -886,6 +901,10 @@ void domain_pause_for_debugger(void)
 #endif
 
 /* Complete domain destroy after RCU readers are not holding old references. */
+/*
+ * used by:
+ *   - common/domain.c|988| <<domain_destroy>> call_rcu(&d->rcu, complete_domain_destroy);
+ */
 static void complete_domain_destroy(struct rcu_head *head)
 {
     struct domain *d = container_of(head, struct domain, rcu);
@@ -950,6 +969,10 @@ static void complete_domain_destroy(struct rcu_head *head)
 }
 
 /* Release resources belonging to task @p. */
+/*
+ * called by:
+ *   - include/xen/sched.h|516| <<put_domain>> if ( atomic_dec_and_test(&(_d)->refcnt) ) domain_destroy(_d)
+ */
 void domain_destroy(struct domain *d)
 {
     struct domain **pd;
diff --git a/xen/common/timer.c b/xen/common/timer.c
index 376581b..8535cb9 100644
--- a/xen/common/timer.c
+++ b/xen/common/timer.c
@@ -25,14 +25,46 @@
 #include <asm/atomic.h>
 
 /* We program the time hardware this far behind the closest deadline. */
+/*
+ * used by only:
+ *   - common/timer.c|777| <<timer_softirq_action>> (deadline == STIME_MAX) ? 0 : MAX(deadline, now + timer_slop);
+ */
 static unsigned int timer_slop __read_mostly = 50000; /* 50 us */
 integer_param("timer_slop", timer_slop);
 
 struct timers {
     spinlock_t     lock;
+    /*
+     * heap分配的地方:
+     *   - common/timer.c|546| <<timer_softirq_action>> ts->heap = newheap;
+     *   - common/timer.c|702| <<cpu_callback>> ts->heap = &dummy_heap;
+     */
     struct timer **heap;
     struct timer  *list;
+    /*
+     * running设置的地方:
+     *   - common/timer.c|657| <<execute_timer>> ts->running = t;
+     *   - common/timer.c|661| <<execute_timer>> ts->running = NULL;
+     */
     struct timer  *running;
+    /*
+     * 在以下添加:
+     *   - common/timer.c|333| <<deactivate_timer>> list_add(&timer->inactive, &per_cpu(timers, timer->cpu).inactive);
+     *   - common/timer.c|440| <<init_timer>> list_add(&timer->inactive, &per_cpu(timers, cpu).inactive);
+     *   - common/timer.c|586| <<migrate_timer>> list_add(&timer->inactive, &per_cpu(timers, new_cpu).inactive);
+     *   - common/timer.c|668| <<execute_timer>> list_add(&t->inactive, &ts->inactive);
+     *   - common/timer.c|875| <<migrate_timers_from_cpu>> list_add(&t->inactive, &new_ts->inactive);
+     *
+     * 在以下删除:
+     *   - common/timer.c|314| <<activate_timer>> list_del(&timer->inactive);
+     *   - common/timer.c|584| <<migrate_timer>> list_del(&timer->inactive);
+     *   - common/timer.c|640| <<kill_timer>> list_del(&timer->inactive);
+     *   - common/timer.c|873| <<migrate_timers_from_cpu>> list_del(&t->inactive);
+     *
+     * 使用的例子:
+     *   - common/timer.c|870| <<migrate_timers_from_cpu>> while ( !list_empty(&old_ts->inactive) )
+     *   - common/timer.c|902| <<cpu_callback>> INIT_LIST_HEAD(&ts->inactive);
+     */
     struct list_head inactive;
 } __cacheline_aligned;
 
@@ -41,19 +73,78 @@ static DEFINE_PER_CPU(struct timers, timers);
 /* Protects lock-free access to per-timer cpu field against cpu offlining. */
 static DEFINE_RCU_READ_LOCK(timer_cpu_read_lock);
 
+/*
+ * used by:
+ *   - arch/x86/acpi/cpu_idle.c|403| <<mwait_idle_with_hints>> s_time_t expires = per_cpu(timer_deadline, cpu);
+ *   - arch/x86/acpi/cpuidle_menu.c|179| <<get_sleep_length_us>> s_time_t us = (this_cpu(timer_deadline) - NOW()) / 1000;
+ *   - arch/x86/hpet.c|190| <<handle_hpet_broadcast>> s_time_t deadline = ACCESS_ONCE(per_cpu(timer_deadline, cpu));
+ *   - arch/x86/hpet.c|696| <<hpet_broadcast_enter>> s_time_t deadline = per_cpu(timer_deadline, cpu);
+ *   - arch/x86/hpet.c|727| <<hpet_broadcast_exit>> s_time_t deadline = per_cpu(timer_deadline, cpu);
+ *   - arch/x86/time.c|1951| <<pit_broadcast_exit>> reprogram_timer(this_cpu(timer_deadline));
+ *   - common/timer.c|555| <<timer_softirq_action>> this_cpu(timer_deadline) =
+ *   - common/timer.c|558| <<timer_softirq_action>> if ( !reprogram_timer(this_cpu(timer_deadline)) )
+ */
 DEFINE_PER_CPU(s_time_t, timer_deadline);
 
 /****************************************************************************
  * HEAP OPERATIONS.
  */
 
+/*
+ * 一般来说, struct timer **h是二维指针
+ *
+ * **h ---> -------------------
+ *          |  h[0] reserverd |----> 在地址里保存limit和size
+ *          |-----------------|
+ *          |  struct timer * |-----> struct timer
+ *          |-----------------|
+ *          |  struct timer * |-----> struct timer
+ *          |-----------------|
+ *          |  struct timer * |-----> struct timer
+ *          |-----------------|
+ *          |  struct timer * |-----> struct timer
+ *          -------------------
+ *
+ * 对于dummy_heap来说有一点点的不一样
+ * struct *dummy_heap
+ *
+ * &dummy_heap就成了
+ *
+ * &dummy_heap ---> ----------------------
+ *                  |   struct timer *   |
+ *                  ----------------------
+ *                  本来应该存储一个地址
+ *                  现在直接存储limit和size
+ */
+
+/*
+ * called by:
+ *   - common/timer.c|59| <<down_heap>> int sz = GET_HEAP_SIZE(heap), nxt;
+ *   - common/timer.c|97| <<remove_from_heap>> int sz = GET_HEAP_SIZE(heap);
+ *   - common/timer.c|124| <<add_to_heap>> int sz = GET_HEAP_SIZE(heap);
+ *   - common/timer.c|524| <<timer_softirq_action>> while ( (GET_HEAP_SIZE(heap) != 0) &&
+ *   - common/timer.c|550| <<timer_softirq_action>> if ( GET_HEAP_SIZE(heap) != 0 )
+ *   - common/timer.c|594| <<dump_timerq>> for ( j = 1; j <= GET_HEAP_SIZE(ts->heap); j++ )
+ *   - common/timer.c|625| <<migrate_timers_from_cpu>> while ( (t = GET_HEAP_SIZE(old_ts->heap)
+ */
 #define GET_HEAP_SIZE(_h)     ((int)(((u16 *)(_h))[0]))
+/*
+ * called by:
+ *   - common/timer.c|102| <<remove_from_heap>> SET_HEAP_SIZE(heap, sz-1);
+ *   - common/timer.c|109| <<remove_from_heap>> SET_HEAP_SIZE(heap, --sz);
+ *   - common/timer.c|130| <<add_to_heap>> SET_HEAP_SIZE(heap, ++sz);
+ *   - common/timer.c|689| <<timer_init>> SET_HEAP_SIZE(&dummy_heap, 0);
+ */
 #define SET_HEAP_SIZE(_h,_v)  (((u16 *)(_h))[0] = (u16)(_v))
 
 #define GET_HEAP_LIMIT(_h)    ((int)(((u16 *)(_h))[1]))
 #define SET_HEAP_LIMIT(_h,_v) (((u16 *)(_h))[1] = (u16)(_v))
 
 /* Sink down element @pos of @heap. */
+/*
+ * called by only:
+ *   - common/timer.c|114| <<remove_from_heap>> down_heap(heap, pos);
+ */
 static void down_heap(struct timer **heap, int pos)
 {
     int sz = GET_HEAP_SIZE(heap), nxt;
@@ -75,6 +166,11 @@ static void down_heap(struct timer **heap, int pos)
 }
 
 /* Float element @pos up @heap. */
+/*
+ * called by:
+ *   - common/timer.c|149| <<remove_from_heap>> up_heap(heap, pos);
+ *   - common/timer.c|170| <<add_to_heap>> up_heap(heap, sz);
+ */
 static void up_heap(struct timer **heap, int pos)
 {
     struct timer *t = heap[pos];
@@ -140,6 +236,10 @@ static int add_to_heap(struct timer **heap, struct timer *t)
  * LINKED LIST OPERATIONS.
  */
 
+/*
+ * called by:
+ *   - common/timer.c|284| <<remove_entry>> rc = remove_from_list(&timers->list, t);
+ */
 static int remove_from_list(struct timer **pprev, struct timer *t)
 {
     struct timer *curr, **_pprev = pprev;
@@ -152,6 +252,10 @@ static int remove_from_list(struct timer **pprev, struct timer *t)
     return (_pprev == pprev);
 }
 
+/*
+ * called by:
+ *   - common/timer.c|211| <<add_entry>> return add_to_list(&timers->list, t);
+ */
 static int add_to_list(struct timer **pprev, struct timer *t)
 {
     struct timer *curr, **_pprev = pprev;
@@ -170,6 +274,9 @@ static int add_to_list(struct timer **pprev, struct timer *t)
  * TIMER OPERATIONS.
  */
 
+/*
+ * 在heap或者list上移除, 设置状态为TIMER_STATUS_invalid
+ */
 static int remove_entry(struct timer *t)
 {
     struct timers *timers = &per_cpu(timers, t->cpu);
@@ -192,8 +299,20 @@ static int remove_entry(struct timer *t)
     return rc;
 }
 
+/*
+ * called by:
+ *   - common/timer.c|220| <<activate_timer>> if ( add_entry(timer) )
+ *   - common/timer.c|499| <<timer_softirq_action>> add_entry(t);
+ *   - common/timer.c|584| <<migrate_timers_from_cpu>> notify |= add_entry(t);
+ *
+ * 先添加到heap, 设置状态为TIMER_STATUS_in_heap
+ * 否则添加到list, 设置状态为TIMER_STATUS_in_list
+ */
 static int add_entry(struct timer *t)
 {
+    /*
+     * 定义在最开始: static DEFINE_PER_CPU(struct timers, timers);
+     */
     struct timers *timers = &per_cpu(timers, t->cpu);
     int rc;
 
@@ -211,18 +330,44 @@ static int add_entry(struct timer *t)
     return add_to_list(&timers->list, t);
 }
 
+/*
+ * called by:
+ *   - common/timer.c|315| <<set_timer>> activate_timer(timer);
+ *   - common/timer.c|395| <<migrate_timer>> activate_timer(timer);
+ *
+ * 先从timers->inactive上删除(设置状态为TIMER_STATUS_invalid)
+ * 然后先添加到heap, 设置状态为TIMER_STATUS_in_heap
+ * 否则添加到list, 设置状态为TIMER_STATUS_in_list
+ */
 static inline void activate_timer(struct timer *timer)
 {
     ASSERT(timer->status == TIMER_STATUS_inactive);
     timer->status = TIMER_STATUS_invalid;
     list_del(&timer->inactive);
 
+    /*
+     * 先添加到heap, 设置状态为TIMER_STATUS_in_heap
+     * 否则添加到list, 设置状态为TIMER_STATUS_in_list
+     */
     if ( add_entry(timer) )
         cpu_raise_softirq(timer->cpu, TIMER_SOFTIRQ);
 }
 
+/*
+ * called by:
+ *   - common/timer.c|429| <<set_timer>> deactivate_timer(timer);
+ *   - common/timer.c|473| <<stop_timer>> deactivate_timer(timer);
+ *   - common/timer.c|551| <<migrate_timer>> deactivate_timer(timer);
+ *   - common/timer.c|607| <<kill_timer>> deactivate_timer(timer);
+ *
+ * 在heap或者list上移除, 设置状态为TIMER_STATUS_invalid
+ * 然后把状态设置为TIMER_STATUS_inactive, 添加到timers->inactive上
+ */
 static inline void deactivate_timer(struct timer *timer)
 {
+    /*
+     * 在heap或者list上移除, 设置状态为TIMER_STATUS_invalid
+     */
     if ( remove_entry(timer) )
         cpu_raise_softirq(timer->cpu, TIMER_SOFTIRQ);
 
@@ -273,6 +418,17 @@ static inline void timer_unlock(struct timer *timer)
 })
 
 
+/*
+ * called by:
+ *   - common/timer.c|428| <<set_timer>> if ( active_timer(timer) )
+ *   - common/timer.c|472| <<stop_timer>> if ( active_timer(timer) )
+ *   - common/timer.c|486| <<timer_expires_before>> ret = active_timer(timer) && timer->expires <= t;
+ *   - common/timer.c|549| <<migrate_timer>> active = active_timer(timer);
+ *   - common/timer.c|606| <<kill_timer>> if ( active_timer(timer) )
+ *
+ * 如果状态是TIMER_STATUS_in_heap或者TIMER_STATUS_in_list返回true
+ * 也就是说如果在timers->head或者timers->list上返回true
+ */
 static bool_t active_timer(struct timer *timer)
 {
     ASSERT(timer->status >= TIMER_STATUS_inactive);
@@ -281,6 +437,37 @@ static bool_t active_timer(struct timer *timer)
 }
 
 
+/*
+ * called by:
+ *   - arch/x86/cpu/mcheck/amd_nonfatal.c|244| <<amd_nonfatal_mcheck_init>> init_timer(&mce_timer, mce_amd_work_fn, NULL, 0);
+ *   - arch/x86/cpu/mcheck/non-fatal.c|109| <<init_nonfatal_mce_checker>> init_timer(&mce_timer, mce_work_fn, NULL, 0);
+ *   - arch/x86/hvm/pmtimer.c|367| <<pmtimer_init>> init_timer(&s->timer, pmt_timer_callback, s, v->processor);
+ *   - arch/x86/hvm/rtc.c|811| <<rtc_init>> init_timer(&s->update_timer, rtc_update_timer, s, smp_processor_id());
+ *   - arch/x86/hvm/rtc.c|812| <<rtc_init>> init_timer(&s->update_timer2, rtc_update_timer2, s, smp_processor_id());
+ *   - arch/x86/hvm/rtc.c|813| <<rtc_init>> init_timer(&s->alarm_timer, rtc_alarm_cb, s, smp_processor_id());
+ *   - arch/x86/hvm/vpt.c|633| <<create_periodic_time>> init_timer(&pt->timer, pt_timer_fn, pt, v->processor);
+ *   - arch/x86/irq.c|958| <<irq_ratelimit_init>> init_timer(&irq_ratelimit_timer, irq_ratelimit_timer_fn, NULL, 0);
+ *   - arch/x86/irq.c|1628| <<pirq_guest_bind>> init_timer(&action->eoi_timer, irq_guest_eoi_timer_fn, desc, 0);
+ *   - arch/x86/nmi.c|439| <<cpu_nmi_callback>> init_timer(&per_cpu(nmi_timer, cpu), nmi_timer_fn, NULL, cpu);
+ *   - arch/x86/time.c|1752| <<try_platform_timer_tail>> init_timer(&plt_overflow_timer, plt_overflow, NULL, 0);
+ *   - arch/x86/time.c|1761| <<try_platform_timer_tail>> init_timer(&calibration_timer, time_calibration, NULL, 0);
+ *   - common/rcupdate.c|566| <<rcu_init_percpu_data>> init_timer(&rdp->idle_timer, rcu_idle_timer_handler, rdp, cpu);
+ *   - common/sched_credit.c|592| <<init_pdata>> init_timer(&prv->master_ticker, csched_acct, prv, cpu);
+ *   - common/sched_credit.c|600| <<init_pdata>> init_timer(&spc->ticker, csched_tick, (void *)(unsigned long )cpu, cpu);
+ *   - common/sched_credit2.c|3063| <<csched2_alloc_domdata>> init_timer(&sdom->repl_timer, replenish_domain_budget, sdom,
+ *   - common/sched_rt.c|720| <<rt_init_pdata>> init_timer(&prv->repl_timer, repl_timer_handler, (void *)ops, cpu);
+ *   - common/sched_rt.c|759| <<rt_switch_sched>> init_timer(&prv->repl_timer, repl_timer_handler, (void *)new_ops, cpu);
+ *   - common/schedule.c|266| <<sched_init_vcpu>> init_timer(&v->periodic_timer, vcpu_periodic_timer_fn,
+ *   - common/schedule.c|268| <<sched_init_vcpu>> init_timer(&v->singleshot_timer, vcpu_singleshot_timer_fn,
+ *   - common/schedule.c|270| <<sched_init_vcpu>> init_timer(&v->poll_timer, poll_timer_fn,
+ *   - common/schedule.c|1164| <<watchdog_domain_init>> init_timer(&d->watchdog_timer[i], domain_watchdog_timeout, d, 0);
+ *   - common/schedule.c|1640| <<cpu_schedule_up>> init_timer(&sd->s_timer, s_timer_fn, NULL, cpu);
+ *   - drivers/char/ehci-dbgp.c|1361| <<ehci_dbgp_init_postirq>> init_timer(&dbgp->timer, ehci_dbgp_poll, port, 0);
+ *   - drivers/char/ns16550.c|752| <<ns16550_init_postirq>> init_timer(&uart->timer, ns16550_poll, port, 0);
+ *   - drivers/char/ns16550.c|753| <<ns16550_init_postirq>> init_timer(&uart->resume_timer, ns16550_delayed_resume, port, 0);
+ *   - drivers/cpufreq/cpufreq_ondemand.c|192| <<dbs_timer_init>> init_timer(&per_cpu(dbs_timer, dbs_info->cpu), do_dbs_timer,
+ *   - drivers/passthrough/io.c|566| <<pt_irq_create_bind>> init_timer(&pirq_dpci->timer, pt_irq_time_out, pirq_dpci, 0);
+ */
 void init_timer(
     struct timer *timer,
     void        (*function)(void *),
@@ -300,6 +487,18 @@ void init_timer(
 }
 
 
+/*
+ * 一个例子:
+ * [0] set_timer
+ * [0] pt_intr_post
+ * [0] vmx_intr_assist
+ *
+ * 被很多调用, vpt的例子:
+ *   - arch/x86/hvm/vpt.c|298| <<pt_restore_timer>> set_timer(&pt->timer, pt->scheduled);
+ *   - arch/x86/hvm/vpt.c|348| <<pt_irq_fired>> set_timer(&pt->timer, pt->scheduled);
+ *   - arch/x86/hvm/vpt.c|368| <<pt_irq_fired>> set_timer(&pt->timer, pt->scheduled);
+ *   - arch/x86/hvm/vpt.c|645| <<create_periodic_time>> set_timer(&pt->timer, pt->scheduled);
+ */
 void set_timer(struct timer *timer, s_time_t expires)
 {
     unsigned long flags;
@@ -307,17 +506,60 @@ void set_timer(struct timer *timer, s_time_t expires)
     if ( !timer_lock_irqsave(timer, flags) )
         return;
 
+    /*
+     * active_timer():
+     *
+     * 如果状态是TIMER_STATUS_in_heap或者TIMER_STATUS_in_list返回true
+     * 也就是说如果在timers->head或者timers->list上返回true
+     *
+     *
+     * deactivate_timer():
+     *
+     * 在heap或者list上移除, 设置状态为TIMER_STATUS_invalid
+     * 然后把状态设置为TIMER_STATUS_inactive, 添加到timers->inactive上
+     */
     if ( active_timer(timer) )
         deactivate_timer(timer);
 
     timer->expires = expires;
 
+    /*
+     * 先从timers->inactive上删除(设置状态为TIMER_STATUS_invalid)
+     * 然后先添加到heap, 设置状态为TIMER_STATUS_in_heap
+     * 否则添加到list, 设置状态为TIMER_STATUS_in_list
+     */
     activate_timer(timer);
 
     timer_unlock_irqrestore(timer, flags);
 }
 
 
+/*
+ * called by:
+ *   - arch/arm/vtimer.c|159| <<virt_timer_restore>> stop_timer(&v->arch.virt_timer.timer);
+ *   - arch/arm/vtimer.c|193| <<vtimer_cntp_ctl>> stop_timer(&v->arch.phys_timer.timer);
+ *   - arch/x86/hvm/rtc.c|181| <<check_update_timer>> stop_timer(&s->update_timer);
+ *   - arch/x86/hvm/rtc.c|182| <<check_update_timer>> stop_timer(&s->update_timer2);
+ *   - arch/x86/hvm/rtc.c|258| <<alarm_timer_update>> stop_timer(&s->alarm_timer);
+ *   - arch/x86/hvm/vpt.c|279| <<pt_save_timer>> stop_timer(&pt->timer);
+ *   - arch/x86/irq.c|1263| <<__do_IRQ_guest>> stop_timer(&action->eoi_timer);
+ *   - arch/x86/pv/shim.c|415| <<pv_shim_shutdown>> stop_timer(&v->singleshot_timer);
+ *   - common/domain.c|1514| <<XEN_GUEST_HANDLE_PARAM>> stop_timer(&v->singleshot_timer);
+ *   - common/rcupdate.c|503| <<rcu_idle_timer_stop>> stop_timer(&rdp->idle_timer);
+ *   - common/sched_credit.c|2246| <<csched_tick_suspend>> stop_timer(&spc->ticker);
+ *   - common/sched_credit2.c|2959| <<csched2_dom_cntl>> stop_timer(&sdom->repl_timer);
+ *   - common/sched_rt.c|554| <<replq_remove>> stop_timer(&prv->repl_timer);
+ *   - common/schedule.c|1143| <<domain_watchdog>> stop_timer(&d->watchdog_timer[id]);
+ *   - common/schedule.c|1358| <<do_set_timer_op>> stop_timer(&v->singleshot_timer);
+ *   - common/schedule.c|1515| <<schedule>> stop_timer(&sd->s_timer);
+ *   - common/schedule.c|1576| <<schedule>> stop_timer(&prev->periodic_timer);
+ *   - drivers/char/ehci-dbgp.c|1415| <<ehci_dbgp_suspend>> stop_timer(&dbgp->timer);
+ *   - drivers/char/ns16550.c|845| <<ns16550_suspend>> stop_timer(&uart->timer);
+ *   - drivers/cpufreq/cpufreq_ondemand.c|373| <<cpufreq_dbs_timer_suspend>> stop_timer( &per_cpu(dbs_timer, cpu) );
+ *   - drivers/passthrough/io.c|969| <<hvm_pirq_eoi>> stop_timer(&pirq_dpci->timer);
+ *   - drivers/passthrough/vtd/x86/hvm.c|40| <<_hvm_dpci_isairq_eoi>> stop_timer(&pirq_dpci->timer);
+ *   - include/xen/timer.h|71| <<_hvm_dpci_isairq_eoi>> void stop_timer(struct timer *timer);
+ */
 void stop_timer(struct timer *timer)
 {
     unsigned long flags;
@@ -331,6 +573,10 @@ void stop_timer(struct timer *timer)
     timer_unlock_irqrestore(timer, flags);
 }
 
+/*
+ * called by:
+ *   - include/xen/timer.h|76| <<timer_is_expired>> #define timer_is_expired(t) timer_expires_before(t, NOW())
+ */
 bool timer_expires_before(struct timer *timer, s_time_t t)
 {
     unsigned long flags;
@@ -346,6 +592,25 @@ bool timer_expires_before(struct timer *timer, s_time_t t)
     return ret;
 }
 
+/*
+ * called by:
+ *   - arch/arm/vtimer.c|160| <<virt_timer_restore>> migrate_timer(&v->arch.virt_timer.timer, v->processor);
+ *   - arch/arm/vtimer.c|161| <<virt_timer_restore>> migrate_timer(&v->arch.phys_timer.timer, v->processor);
+ *   - arch/x86/hvm/rtc.c|733| <<rtc_migrate_timers>> migrate_timer(&s->update_timer, v->processor);
+ *   - arch/x86/hvm/rtc.c|734| <<rtc_migrate_timers>> migrate_timer(&s->update_timer2, v->processor);
+ *   - arch/x86/hvm/rtc.c|735| <<rtc_migrate_timers>> migrate_timer(&s->alarm_timer, v->processor);
+ *   - arch/x86/hvm/vpt.c|565| <<pt_migrate>> migrate_timer(&pt->timer, v->processor);
+ *   - arch/x86/hvm/vpt.c|721| <<pt_adjust_vcpu>> migrate_timer(&pt->timer, v->processor);
+ *   - arch/x86/irq.c|1264| <<__do_IRQ_guest>> migrate_timer(&action->eoi_timer, smp_processor_id());
+ *   - common/domain.c|1504| <<XEN_GUEST_HANDLE_PARAM(VCPUOP_set_singleshot_timer)>> migrate_timer(&v->singleshot_timer, smp_processor_id());
+ *   - common/sched_credit.c|550| <<csched_deinit_pdata>> migrate_timer(&prv->master_ticker, prv->master);
+ *   - common/sched_rt.c|801| <<rt_deinit_pdata>> migrate_timer(&prv->repl_timer, new_cpu);
+ *   - common/schedule.c|368| <<sched_move_domain>> migrate_timer(&v->periodic_timer, new_p);
+ *   - common/schedule.c|369| <<sched_move_domain>> migrate_timer(&v->singleshot_timer, new_p);
+ *   - common/schedule.c|370| <<sched_move_domain>> migrate_timer(&v->poll_timer, new_p);
+ *   - common/schedule.c|1380| <<do_set_timer_op>> migrate_timer(&v->singleshot_timer, smp_processor_id());
+ *   - common/schedule.c|1466| <<vcpu_periodic_timer_work>> migrate_timer(&v->periodic_timer, smp_processor_id());
+ */
 void migrate_timer(struct timer *timer, unsigned int new_cpu)
 {
     unsigned int old_cpu;
@@ -383,14 +648,35 @@ void migrate_timer(struct timer *timer, unsigned int new_cpu)
 
     rcu_read_unlock(&timer_cpu_read_lock);
 
+    /*
+     * 如果状态是TIMER_STATUS_in_heap或者TIMER_STATUS_in_list返回true
+     * 也就是说如果在timers->head或者timers->list上返回true
+     */
     active = active_timer(timer);
+    /*
+     * deactivate_timer():
+     * 在heap或者list上移除, 设置状态为TIMER_STATUS_invalid
+     * 然后把状态设置为TIMER_STATUS_inactive, 添加到timers->inactive上
+     */
     if ( active )
         deactivate_timer(timer);
 
+    /*
+     * 从旧的cpu上把timer移除
+     */
     list_del(&timer->inactive);
     write_atomic(&timer->cpu, new_cpu);
+    /*
+     * 把timer添加到新的cpu的timers->inactive上
+     */
     list_add(&timer->inactive, &per_cpu(timers, new_cpu).inactive);
 
+    /*
+     * activate_timer():
+     * 先从timers->inactive上删除(设置状态为TIMER_STATUS_invalid)
+     * 然后先添加到heap, 设置状态为TIMER_STATUS_in_heap
+     * 否则添加到list, 设置状态为TIMER_STATUS_in_list
+     */
     if ( active )
         activate_timer(timer);
 
@@ -399,6 +685,37 @@ void migrate_timer(struct timer *timer, unsigned int new_cpu)
 }
 
 
+/*
+ * called by:
+ *   - arch/arm/vtimer.c|135| <<vcpu_timer_destroy>> kill_timer(&v->arch.virt_timer.timer);
+ *   - arch/arm/vtimer.c|136| <<vcpu_timer_destroy>> kill_timer(&v->arch.phys_timer.timer);
+ *   - arch/x86/hvm/pmtimer.c|379| <<pmtimer_deinit>> kill_timer(&s->timer);
+ *   - arch/x86/hvm/rtc.c|846| <<rtc_deinit>> kill_timer(&s->update_timer);
+ *   - arch/x86/hvm/rtc.c|847| <<rtc_deinit>> kill_timer(&s->update_timer2);
+ *   - arch/x86/hvm/rtc.c|848| <<rtc_deinit>> kill_timer(&s->alarm_timer);
+ *   - arch/x86/hvm/vpt.c|686| <<destroy_periodic_time>> kill_timer(&pt->timer);
+ *   - arch/x86/irq.c|1872| <<pirq_guest_unbind>> kill_timer(&oldaction->eoi_timer);
+ *   - arch/x86/irq.c|1917| <<pirq_guest_force_unbind>> kill_timer(&oldaction->eoi_timer);
+ *   - arch/x86/nmi.c|444| <<cpu_nmi_callback>> kill_timer(&per_cpu(nmi_timer, cpu));
+ *   - arch/x86/time.c|727| <<reset_platform_timer>> kill_timer(&plt_overflow_timer);
+ *   - arch/x86/time.c|728| <<reset_platform_timer>> kill_timer(&calibration_timer);
+ *   - arch/x86/time.c|1973| <<time_suspend>> kill_timer(&calibration_timer);
+ *   - common/rcupdate.c|536| <<rcu_offline_cpu>> kill_timer(&rdp->idle_timer);
+ *   - common/sched_credit.c|558| <<csched_deinit_pdata>> kill_timer(&spc->ticker);
+ *   - common/sched_credit.c|560| <<csched_deinit_pdata>> kill_timer(&prv->master_ticker);
+ *   - common/sched_credit2.c|3087| <<csched2_free_domdata>> kill_timer(&sdom->repl_timer);
+ *   - common/sched_rt.c|796| <<rt_deinit_pdata>> kill_timer(&prv->repl_timer);
+ *   - common/schedule.c|410| <<sched_destroy_vcpu>> kill_timer(&v->periodic_timer);
+ *   - common/schedule.c|411| <<sched_destroy_vcpu>> kill_timer(&v->singleshot_timer);
+ *   - common/schedule.c|412| <<sched_destroy_vcpu>> kill_timer(&v->poll_timer);
+ *   - common/schedule.c|1172| <<watchdog_domain_destroy>> kill_timer(&d->watchdog_timer[i]);
+ *   - common/schedule.c|1698| <<cpu_schedule_down>> kill_timer(&sd->s_timer);
+ *   - drivers/char/ehci-dbgp.c|1390| <<ehci_dbgp_check_release>> kill_timer(&dbgp->timer);
+ *   - drivers/cpufreq/cpufreq_ondemand.c|215| <<dbs_timer_exit>> kill_timer(&per_cpu(dbs_timer, dbs_info->cpu));
+ *   - drivers/passthrough/io.c|572| <<pt_irq_create_bind>> kill_timer(&pirq_dpci->timer);
+ *   - drivers/passthrough/io.c|740| <<pt_irq_destroy_bind>> kill_timer(&pirq_dpci->timer);
+ *   - drivers/passthrough/pci.c|872| <<pci_clean_dpci_irq>> kill_timer(&pirq_dpci->timer);
+ */
 void kill_timer(struct timer *timer)
 {
     unsigned int old_cpu, cpu;
@@ -425,6 +742,15 @@ void kill_timer(struct timer *timer)
 }
 
 
+/*
+ * called by:
+ *   - common/timer.c|617| <<timer_softirq_action>> execute_timer(ts, t);
+ *   - common/timer.c|624| <<timer_softirq_action>> execute_timer(ts, t);
+ *
+ * 把状态设置为TIMER_STATUS_inactive
+ * 放入timers->inactive
+ * 调用timer的function()
+ */
 static void execute_timer(struct timers *ts, struct timer *t)
 {
     void (*fn)(void *) = t->function;
@@ -456,6 +782,23 @@ static void timer_softirq_action(void)
         /* old_limit == (2^n)-1; new_limit == (2^(n+4))-1 */
         int old_limit = GET_HEAP_LIMIT(heap);
         int new_limit = ((old_limit + 1) << 4) - 1;
+        /*
+	 * * 一般来说, struct timer **h是二维指针
+	 *
+	 * **h ---> -------------------
+	 *          |  h[0] reserverd |----> 在地址里保存limit和size
+	 *          |-----------------|
+	 *          |  struct timer * |-----> struct timer
+	 *          |-----------------|
+	 *          |  struct timer * |-----> struct timer
+	 *          |-----------------|
+	 *          |  struct timer * |-----> struct timer
+	 *          |-----------------|
+	 *          |  struct timer * |-----> struct timer
+	 *          |-----------------|
+	 *
+	 * 这里分配的时候new_limit后面有个+1
+	 */
         struct timer **newheap = xmalloc_array(struct timer *, new_limit + 1);
         if ( newheap != NULL )
         {
@@ -464,12 +807,19 @@ static void timer_softirq_action(void)
             SET_HEAP_LIMIT(newheap, new_limit);
             ts->heap = newheap;
             spin_unlock_irq(&ts->lock);
+            /*
+	     * 这里判断不为0是为了dummy_heap
+	     */
             if ( old_limit != 0 )
                 xfree(heap);
             heap = newheap;
         }
     }
 
+    /*
+     * 上面按照list的分配了heap, 但是没有把list的放入heap!!!
+     */
+
     spin_lock_irq(&ts->lock);
 
     now = NOW();
@@ -479,6 +829,11 @@ static void timer_softirq_action(void)
             ((t = heap[1])->expires < now) )
     {
         remove_from_heap(heap, t);
+	/*
+	 * 把状态设置为TIMER_STATUS_inactive
+	 * 放入timers->inactive
+	 * 调用timer的function()
+	 */
         execute_timer(ts, t);
     }
 
@@ -486,10 +841,18 @@ static void timer_softirq_action(void)
     while ( ((t = ts->list) != NULL) && (t->expires < now) )
     {
         ts->list = t->list_next;
+	/*
+	 * 把状态设置为TIMER_STATUS_inactive
+	 * 放入timers->inactive
+	 * 调用timer的function()
+	 */
         execute_timer(ts, t);
     }
 
     /* Try to move timers from linked list to more efficient heap. */
+    /*
+     * 把剩下list上的全部放入heap
+     */
     next = ts->list;
     ts->list = NULL;
     while ( unlikely((t = next) != NULL) )
@@ -515,6 +878,14 @@ static void timer_softirq_action(void)
     spin_unlock_irq(&ts->lock);
 }
 
+/*
+ * called by:
+ *   - arch/x86/hvm/vpt.c|627| <<create_periodic_time>> pt->scheduled = align_timer(pt->scheduled, pt->period);
+ *   - drivers/cpufreq/cpufreq_ondemand.c|185| <<do_dbs_timer>> align_timer(NOW() , dbs_tuners_ins.sampling_rate));
+ *   - drivers/cpufreq/cpufreq_ondemand.c|395| <<cpufreq_dbs_timer_resume>> set_timer(t, align_timer(now, dbs_tuners_ins.sampling_rate));
+ *
+ * Calculate the aligned first tick time for a given periodic timer.
+ */
 s_time_t align_timer(s_time_t firsttick, uint64_t period)
 {
     if ( !period )
@@ -553,6 +924,10 @@ static void dump_timerq(unsigned char key)
     }
 }
 
+/*
+ * called by only:
+ *   - common/timer.c|706| <<cpu_callback>> migrate_timers_from_cpu(cpu);
+ */
 static void migrate_timers_from_cpu(unsigned int old_cpu)
 {
     unsigned int new_cpu = cpumask_any(&cpu_online_map);
@@ -599,6 +974,12 @@ static void migrate_timers_from_cpu(unsigned int old_cpu)
         cpu_raise_softirq(new_cpu, TIMER_SOFTIRQ);
 }
 
+/*
+ * used by:
+ *   - common/timer.c|696| <<cpu_callback>> ts->heap = &dummy_heap;
+ *   - common/timer.c|724| <<timer_init>> SET_HEAP_SIZE(&dummy_heap, 0);
+ *   - common/timer.c|725| <<timer_init>> SET_HEAP_LIMIT(&dummy_heap, 0);
+ */
 static struct timer *dummy_heap;
 
 static int cpu_callback(
diff --git a/xen/include/asm-x86/hvm/hvm.h b/xen/include/asm-x86/hvm/hvm.h
index 53ffebb..8f2ec45 100644
--- a/xen/include/asm-x86/hvm/hvm.h
+++ b/xen/include/asm-x86/hvm/hvm.h
@@ -38,6 +38,17 @@ extern bool_t opt_hvm_fep;
 enum hvm_intsrc {
     hvm_intsrc_none,
     hvm_intsrc_pic,
+    /*
+     * 在以下使用:
+     *   - arch/x86/hvm/hvm.c|3796| <<hvm_interrupt_blocked>> if ( intack.source == hvm_intsrc_lapic )
+     *   - arch/x86/hvm/irq.c|561| <<hvm_vcpu_ack_pending_irq>> case hvm_intsrc_lapic:
+     *   - arch/x86/hvm/svm/intr.c|128| <<svm_enable_intr_window>> intr.fields.ign_tpr = (intack.source != hvm_intsrc_lapic);
+     *   - arch/x86/hvm/svm/nestedsvm.c|1564| <<nestedsvm_vcpu_interrupt>> case hvm_intsrc_lapic:
+     *   - arch/x86/hvm/vmx/intr.c|197| <<nvmx_intr_intercept>> intack.source == hvm_intsrc_lapic )
+     *   - arch/x86/hvm/vmx/intr.c|286| <<vmx_intr_assist>> ASSERT(intack.source == hvm_intsrc_lapic);
+     *   - arch/x86/hvm/vmx/vvmx.c|1308| <<nvmx_update_apicv>> nvmx->intr.source == hvm_intsrc_lapic &&
+     *   - arch/x86/hvm/vpt.c|148| <<pt_irq_vector>> ASSERT(src == hvm_intsrc_lapic);
+     */
     hvm_intsrc_lapic,
     hvm_intsrc_nmi,
     hvm_intsrc_mce,
diff --git a/xen/include/asm-x86/hvm/vcpu.h b/xen/include/asm-x86/hvm/vcpu.h
index 6c84d5a..09f3ac2 100644
--- a/xen/include/asm-x86/hvm/vcpu.h
+++ b/xen/include/asm-x86/hvm/vcpu.h
@@ -167,6 +167,20 @@ struct hvm_vcpu {
 
     /* Lock and list for virtual platform timers. */
     spinlock_t          tm_lock;
+    /*
+     * used by:
+     *   - arch/x86/domain.c|1740| <<context_switch>> if ( is_hvm_domain(prevd) && !list_empty(&prev->arch.hvm.tm_list) )
+     *   - arch/x86/hvm/hvm.c|1506| <<hvm_vcpu_initialise>> INIT_LIST_HEAD(&v->arch.hvm.tm_list);
+     *   - arch/x86/hvm/vpt.c|269| <<pt_save_timer>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|288| <<pt_restore_timer>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|373| <<pt_update_irq>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|466| <<pt_update_irq>> list_for_each_entry ( pt, &v->arch.hvm.tm_list, list )
+     *   - arch/x86/hvm/vpt.c|493| <<is_pt_irq>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|548| <<pt_migrate>> struct list_head *head = &v->arch.hvm.tm_list;
+     *   - arch/x86/hvm/vpt.c|631| <<create_periodic_time>> list_add(&pt->list, &v->arch.hvm.tm_list);
+     *   - arch/x86/hvm/vpt.c|708| <<pt_adjust_vcpu>> list_add(&pt->list, &v->arch.hvm.tm_list);
+     *   - arch/x86/hvm/vpt.c|756| <<pt_resume>> list_add(&pt->list, &pt->vcpu->arch.hvm.tm_list);
+     */
     struct list_head    tm_list;
 
     bool                flag_dr_dirty;
diff --git a/xen/include/asm-x86/hvm/vlapic.h b/xen/include/asm-x86/hvm/vlapic.h
index dde66b4..593553d 100644
--- a/xen/include/asm-x86/hvm/vlapic.h
+++ b/xen/include/asm-x86/hvm/vlapic.h
@@ -42,7 +42,21 @@
  *  2. 'Software disable': via APIC_SPIV[8].
  *     APIC is visible but does not respond to interrupt messages.
  */
+/*
+ * used by:
+ *   - arch/x86/hvm/vlapic.c|1140| <<guest_wrmsr_apic_base>> vlapic->hw.disabled &= ~VLAPIC_HW_DISABLED;
+ *   - arch/x86/hvm/vlapic.c|1145| <<guest_wrmsr_apic_base>> vlapic->hw.disabled |= VLAPIC_HW_DISABLED;
+ *   - arch/x86/hvm/vlapic.c|1591| <<vlapic_init>> vlapic->hw.disabled = VLAPIC_HW_DISABLED;
+ *   - include/asm-x86/hvm/vlapic.h|48| <<vlapic_hw_disabled>> #define vlapic_hw_disabled(vlapic) ((vlapic)->hw.disabled & VLAPIC_HW_DISABLED)
+ */
 #define VLAPIC_HW_DISABLED              0x1
+/*
+ * used by:
+ *   - arch/x86/hvm/vlapic.c|814| <<vlapic_reg_write>> vlapic->hw.disabled |= VLAPIC_SW_DISABLED;
+ *   - arch/x86/hvm/vlapic.c|825| <<vlapic_reg_write>> vlapic->hw.disabled &= ~VLAPIC_SW_DISABLED;
+ *   - arch/x86/hvm/vlapic.c|1409| <<vlapic_do_init>> vlapic->hw.disabled |= VLAPIC_SW_DISABLED;
+ *   - include/asm-x86/hvm/vlapic.h|47| <<vlapic_sw_disabled>> #define vlapic_sw_disabled(vlapic) ((vlapic)->hw.disabled & VLAPIC_SW_DISABLED)
+ */
 #define VLAPIC_SW_DISABLED              0x2
 #define vlapic_sw_disabled(vlapic) ((vlapic)->hw.disabled & VLAPIC_SW_DISABLED)
 #define vlapic_hw_disabled(vlapic) ((vlapic)->hw.disabled & VLAPIC_HW_DISABLED)
diff --git a/xen/include/asm-x86/hvm/vmx/vmcs.h b/xen/include/asm-x86/hvm/vmx/vmcs.h
index b3e8001..4da9802 100644
--- a/xen/include/asm-x86/hvm/vmx/vmcs.h
+++ b/xen/include/asm-x86/hvm/vmx/vmcs.h
@@ -194,6 +194,15 @@ void vmx_vmcs_reload(struct vcpu *v);
 #define CPU_BASED_VIRTUAL_INTR_PENDING        0x00000004
 #define CPU_BASED_USE_TSC_OFFSETING           0x00000008
 #define CPU_BASED_HLT_EXITING                 0x00000080
+/*
+ * used by:
+ *   - arch/x86/hvm/vmx/vmcs.c|196| <<vmx_init_vmcs_config>> CPU_BASED_INVLPG_EXITING |
+ *   - arch/x86/hvm/vmx/vmcs.c|309| <<vmx_init_vmcs_config>> if ( must_be_one & (CPU_BASED_INVLPG_EXITING |
+ *   - arch/x86/hvm/vmx/vmcs.c|1022| <<construct_vmcs>> v->arch.hvm.vmx.exec_control &= ~(CPU_BASED_INVLPG_EXITING |
+ *   - arch/x86/hvm/vmx/vvmx.c|2152| <<nvmx_msr_read_intercept>> CPU_BASED_INVLPG_EXITING |
+ *   - arch/x86/hvm/vmx/vvmx.c|2173| <<nvmx_msr_read_intercept>> CPU_BASED_INVLPG_EXITING);
+ *   - arch/x86/hvm/vmx/vvmx.c|2533| <<nvmx_n2_vmexit_handler>> if ( ctrl & CPU_BASED_INVLPG_EXITING )
+ */
 #define CPU_BASED_INVLPG_EXITING              0x00000200
 #define CPU_BASED_MWAIT_EXITING               0x00000400
 #define CPU_BASED_RDPMC_EXITING               0x00000800
diff --git a/xen/include/asm-x86/hvm/vpt.h b/xen/include/asm-x86/hvm/vpt.h
index 99169dd..784b3cb 100644
--- a/xen/include/asm-x86/hvm/vpt.h
+++ b/xen/include/asm-x86/hvm/vpt.h
@@ -36,22 +36,114 @@
 typedef void time_cb(struct vcpu *v, void *opaque);
 
 struct periodic_time {
+    /*
+     * 用来挂载在v->arch.hvm.tm_list
+     */
     struct list_head list;
     bool on_list;
+    /*
+     * 在以下修改:
+     *   - arch/x86/hvm/vpt.c|627| <<create_periodic_time>> pt->one_shot = !period;
+     */
     bool one_shot;
+    /*
+     * used by:
+     *   - arch/x86/hvm/vpt.c|289| <<pt_process_missed_ticks>> pt->do_not_freeze = !pt->pending_intr_nr;
+     *   - arch/x86/hvm/vpt.c|338| <<pt_save_timer>> if ( !pt->do_not_freeze )
+     *   - arch/x86/hvm/vpt.c|383| <<pt_timer_fn>> pt->do_not_freeze = 0;
+     *   - arch/x86/hvm/vpt.c|664| <<create_periodic_time>> pt->do_not_freeze = 0;
+     */
     bool do_not_freeze;
+    /*
+     * used by:
+     *   - arch/x86/hvm/vpt.c|397| <<pt_irq_fired>> pt->irq_issued = false;
+     *   - arch/x86/hvm/vpt.c|488| <<pt_update_irq>> earliest_pt->irq_issued = 1;
+     *   - arch/x86/hvm/vpt.c|573| <<is_pt_irq>> if ( pt->pending_intr_nr && pt->irq_issued &&
+     *   - arch/x86/hvm/vpt.c|665| <<create_periodic_time>> pt->irq_issued = 0;
+     */
     bool irq_issued;
+    /*
+     * 只在下面使用:
+     *   - arch/x86/hvm/vpt.c|670| <<create_periodic_time>> if ( !test_and_set_bool(pt->warned_timeout_too_short) )
+     */
     bool warned_timeout_too_short;
     bool level;
 #define PTSRC_isa    1 /* ISA time source */
 #define PTSRC_lapic  2 /* LAPIC time source */
 #define PTSRC_ioapic 3 /* IOAPIC time source */
+    /*
+     * 在以下设置:
+     *   - arch/x86/emul-i8254.c|495| <<pit_reset>> pit->pt0.source = PTSRC_isa;
+     *   - arch/x86/hvm/hpet.c|289| <<hpet_set_timer>> h->pt[tn].source = PTSRC_isa;
+     *   - arch/x86/hvm/hpet.c|294| <<hpet_set_timer>> h->pt[tn].source = PTSRC_ioapic;
+     *   - arch/x86/hvm/hpet.c|731| <<hpet_set>> h->pt[i].source = PTSRC_isa;
+     *   - arch/x86/hvm/rtc.c|799| <<rtc_reset>> s->pt.source = PTSRC_isa;
+     *   - arch/x86/hvm/vlapic.c|1664| <<vlapic_init>> vlapic->pt.source = PTSRC_lapic;
+     */
     u8 source;                  /* PTSRC_ */
     u8 irq;
     struct vcpu *vcpu;          /* vcpu timer interrupt delivers to */
+    /*
+     * used by:
+     *   - arch/x86/hvm/vpt.c|241| <<pt_process_missed_ticks>> pt->do_not_freeze = !pt->pending_intr_nr;
+     *   - arch/x86/hvm/vpt.c|243| <<pt_process_missed_ticks>> pt->pending_intr_nr += missed_ticks;
+     *   - arch/x86/hvm/vpt.c|295| <<pt_restore_timer>> if ( pt->pending_intr_nr == 0 )
+     *   - arch/x86/hvm/vpt.c|317| <<pt_timer_fn>> pt->pending_intr_nr++;
+     *   - arch/x86/hvm/vpt.c|340| <<pt_irq_fired>> pt->pending_intr_nr = 0;
+     *   - arch/x86/hvm/vpt.c|347| <<pt_irq_fired>> pt->pending_intr_nr = 0;
+     *   - arch/x86/hvm/vpt.c|353| <<pt_irq_fired>> if ( --pt->pending_intr_nr == 0 )
+     *   - arch/x86/hvm/vpt.c|356| <<pt_irq_fired>> if ( pt->pending_intr_nr == 0 )
+     *   - arch/x86/hvm/vpt.c|385| <<pt_update_irq>> if ( pt->pending_intr_nr )
+     *   - arch/x86/hvm/vpt.c|498| <<is_pt_irq>> if ( pt->pending_intr_nr && pt->irq_issued &&
+     *   - arch/x86/hvm/vpt.c|588| <<create_periodic_time>> pt->pending_intr_nr = 0;
+     *   - arch/x86/hvm/vpt.c|668| <<destroy_periodic_time>> pt->pending_intr_nr = 0;
+     *   - arch/x86/hvm/vpt.c|753| <<pt_resume>> if ( pt->pending_intr_nr && !pt->on_list )
+     *   - include/asm-x86/hvm/vpt.h|160| <<pt_active>> #define pt_active(pt) ((pt)->on_list || (pt)->pending_intr_nr)
+     */
     u32 pending_intr_nr;        /* pending timer interrupts */
+    /*
+     * periodic_time->period使用的地方:
+     *   - arch/x86/hvm/vpt.c|254| <<pt_process_missed_ticks>> missed_ticks = missed_ticks / (s_time_t) pt->period + 1;
+     *   - arch/x86/hvm/vpt.c|259| <<pt_process_missed_ticks>> pt->scheduled += missed_ticks * pt->period;
+     *   - arch/x86/hvm/vpt.c|333| <<pt_timer_fn>> pt->scheduled += pt->period;
+     *   - arch/x86/hvm/vpt.c|367| <<pt_irq_fired>> pt->last_plt_gtime += pt->period;
+     *   - arch/x86/hvm/vpt.c|424| <<pt_update_irq>> if ( (pt->last_plt_gtime + pt->period) < max_lag )
+     *   - arch/x86/hvm/vpt.c|426| <<pt_update_irq>> max_lag = pt->last_plt_gtime + pt->period;
+     *   - arch/x86/hvm/vpt.c|627| <<create_periodic_time>> pt->period = period;
+     *   - arch/x86/hvm/vpt.c|642| <<create_periodic_time>> pt->scheduled = align_timer(pt->scheduled, pt->period);
+     */
     u64 period;                 /* frequency in ns */
+    /*
+     * used by:
+     *   - arch/x86/hvm/vpt.c|235| <<pt_process_missed_ticks>> missed_ticks = now - pt->scheduled;
+     *   - arch/x86/hvm/vpt.c|244| <<pt_process_missed_ticks>> pt->scheduled += missed_ticks * pt->period;
+     *   - arch/x86/hvm/vpt.c|298| <<pt_restore_timer>> set_timer(&pt->timer, pt->scheduled);
+     *   - arch/x86/hvm/vpt.c|318| <<pt_timer_fn>> pt->scheduled += pt->period;
+     *   - arch/x86/hvm/vpt.c|348| <<pt_irq_fired>> set_timer(&pt->timer, pt->scheduled);
+     *   - arch/x86/hvm/vpt.c|357| <<pt_irq_fired>> set_timer(&pt->timer, pt->scheduled);
+     *   - arch/x86/hvm/vpt.c|607| <<create_periodic_time>> pt->scheduled = NOW() + delta;
+     *   - arch/x86/hvm/vpt.c|613| <<create_periodic_time>> pt->scheduled = align_timer(pt->scheduled, pt->period);
+     *   - arch/x86/hvm/vpt.c|623| <<create_periodic_time>> pt->scheduled += delta >> 1;
+     *   - arch/x86/hvm/vpt.c|634| <<create_periodic_time>> set_timer(&pt->timer, pt->scheduled);
+     */
     s_time_t scheduled;         /* scheduled timer interrupt */
+    /*
+     * 在以下设置last_plt_gtime:
+     *   - arch/x86/emul-i8254.c|465| <<pit_load>> pit->pt0.last_plt_gtime = get_guest_time(d->vcpu[0]);
+     *   - arch/x86/hvm/vpt.c|409| <<pt_irq_fired>> pt->last_plt_gtime = hvm_get_guest_time(v);
+     *   - arch/x86/hvm/vpt.c|416| <<pt_irq_fired>> pt->last_plt_gtime += pt->period;
+     *   - arch/x86/hvm/vpt.c|696| <<create_periodic_time>> pt->last_plt_gtime = hvm_get_guest_time(pt->vcpu);
+     *
+     * 在以下使用last_plt_gtime:
+     *   - arch/x86/hvm/vlapic.c|765| <<vlapic_update_timer>> vlapic->timer_last_update = vlapic->pt.last_plt_gtime;
+     *   - arch/x86/hvm/vlapic.c|1225| <<vlapic_tdt_msr_set>> vlapic->timer_last_update = vlapic->pt.last_plt_gtime;
+     *   - arch/x86/hvm/vlapic.c|1239| <<vlapic_tdt_msr_set>> vlapic->timer_last_update = vlapic->pt.last_plt_gtime;
+     *   - arch/x86/hvm/vlapic.c|1516| <<lapic_rearm>> s->timer_last_update = s->pt.last_plt_gtime;
+     *   - arch/x86/hvm/vpt.c|437| <<pt_irq_fired>> (hvm_get_guest_time(v) < pt->last_plt_gtime) )
+     *   - arch/x86/hvm/vpt.c|438| <<pt_irq_fired>> hvm_set_guest_time(v, pt->last_plt_gtime);
+     *   - arch/x86/hvm/vpt.c|473| <<pt_update_irq>> if ( (pt->last_plt_gtime + pt->period) < max_lag )
+     *   - arch/x86/hvm/vpt.c|475| <<pt_update_irq>> max_lag = pt->last_plt_gtime + pt->period;
+     */
     u64 last_plt_gtime;         /* platform time when last IRQ is injected */
     struct timer timer;         /* ac_timer */
     time_cb *cb;
@@ -66,6 +158,18 @@ typedef struct PITState {
     /* Hardware state */
     struct hvm_hw_pit hw;
     /* Last time the counters read zero, for calcuating counter reads */
+    /*
+     * used by:
+     *   - arch/x86/emul-i8254.c|89| <<pit_get_count>> d = muldiv64(get_guest_time(v) - pit->count_load_time[channel],
+     *   - arch/x86/emul-i8254.c|120| <<pit_get_out>> d = muldiv64(get_guest_time(v) - pit->count_load_time[channel],
+     *   - arch/x86/emul-i8254.c|167| <<pit_set_gate>> pit->count_load_time[channel] = get_guest_time(v);
+     *   - arch/x86/emul-i8254.c|187| <<pit_time_fired>> uint64_t *count_load_time = priv;
+     *   - arch/x86/emul-i8254.c|189| <<pit_time_fired>> *count_load_time = get_guest_time(v);
+     *   - arch/x86/emul-i8254.c|212| <<pit_load_count>> pit->count_load_time[channel] = 0;
+     *   - arch/x86/emul-i8254.c|214| <<pit_load_count>> pit->count_load_time[channel] = get_guest_time(v);
+     *   - arch/x86/emul-i8254.c|228| <<pit_load_count>> &pit->count_load_time[channel], false);
+     *   - arch/x86/emul-i8254.c|235| <<pit_load_count>> &pit->count_load_time[channel], false);
+     */
     int64_t count_load_time[3];
     /* Channel 0 IRQ handling. */
     struct periodic_time pt0;
diff --git a/xen/include/asm-x86/irq.h b/xen/include/asm-x86/irq.h
index 4b39997..be4aac6 100644
--- a/xen/include/asm-x86/irq.h
+++ b/xen/include/asm-x86/irq.h
@@ -49,6 +49,29 @@ struct arch_irq_desc {
 #define IRQ_VECTOR_UNASSIGNED (-1)
 
 typedef int vector_irq_t[NR_VECTORS];
+/*
+ * used by:
+ *   - arch/x86/irq.c|51| <<global>> DEFINE_PER_CPU(vector_irq_t, vector_irq);
+ *   - include/asm-x86/irq.h|52| <<global>> DECLARE_PER_CPU(vector_irq_t, vector_irq);
+ *   - arch/x86/i8259.c|106| <<_disable_8259A_irq>> per_cpu(vector_irq, 0)[LEGACY_VECTOR(irq)] = ~irq;
+ *   - arch/x86/i8259.c|122| <<enable_8259A_irq>> per_cpu(vector_irq, 0)[LEGACY_VECTOR(desc->irq)] = desc->irq;
+ *   - arch/x86/i8259.c|350| <<init_IRQ>> per_cpu(vector_irq, cpu)[FIRST_LEGACY_VECTOR + irq] = irq;
+ *   - arch/x86/i8259.c|355| <<init_IRQ>> per_cpu(vector_irq, cpu)[IRQ0_VECTOR] = 0;
+ *   - arch/x86/irq.c|134| <<__bind_irq_vector>> per_cpu(vector_irq, cpu)[vector] = irq;
+ *   - arch/x86/irq.c|258| <<__clear_irq_vector>> ASSERT( per_cpu(vector_irq, cpu)[vector] == irq );
+ *   - arch/x86/irq.c|259| <<__clear_irq_vector>> per_cpu(vector_irq, cpu)[vector] = ~irq;
+ *   - arch/x86/irq.c|283| <<__clear_irq_vector>> ASSERT( per_cpu(vector_irq, cpu)[old_vector] == irq );
+ *   - arch/x86/irq.c|285| <<__clear_irq_vector>> per_cpu(vector_irq, cpu)[old_vector] = ~irq;
+ *   - arch/x86/irq.c|359| <<init_irq_data>> this_cpu(vector_irq)[vector] = INT_MIN;
+ *   - arch/x86/irq.c|515| <<__assign_irq_vector>> if (per_cpu(vector_irq, new_cpu)[vector] >= 0)
+ *   - arch/x86/irq.c|527| <<__assign_irq_vector>> per_cpu(vector_irq, new_cpu)[vector] = irq;
+ *   - arch/x86/irq.c|577| <<setup_vector_irq>> per_cpu(vector_irq, cpu)[vector] = INT_MIN;
+ *   - arch/x86/irq.c|591| <<setup_vector_irq>> per_cpu(vector_irq, cpu)[vector] = irq;
+ *   - arch/x86/irq.c|651| <<irq_move_cleanup_interrupt>> irq = __get_cpu_var(vector_irq)[vector];
+ *   - arch/x86/irq.c|689| <<irq_move_cleanup_interrupt>> __get_cpu_var(vector_irq)[vector] = ~irq;
+ *   - arch/x86/irq.c|821| <<do_IRQ>> int irq = __get_cpu_var(vector_irq[vector]);
+ *   - arch/x86/smpboot.c|1376| <<smp_intr_init>> per_cpu(vector_irq, cpu)[vector] = irq;
+ */
 DECLARE_PER_CPU(vector_irq_t, vector_irq);
 
 extern bool opt_noirqbalance;
diff --git a/xen/include/asm-x86/paging.h b/xen/include/asm-x86/paging.h
index 18a7eae..3469b29 100644
--- a/xen/include/asm-x86/paging.h
+++ b/xen/include/asm-x86/paging.h
@@ -46,6 +46,11 @@
 #define PG_SH_enable   0
 #define PG_SH_forced   0
 #endif
+/*
+ * used by:
+ *   - arch/x86/mm/hap/hap.c|505| <<hap_enable>> d->arch.paging.mode = mode | PG_HAP_enable;
+ *   - include/asm-x86/paging.h|69| <<paging_mode_hap>> #define paging_mode_hap(_d) (!!((_d)->arch.paging.mode & PG_HAP_enable))
+ */
 #define PG_HAP_enable  (1U << PG_HAP_shift)
 
 /* common paging mode bits */
diff --git a/xen/include/public/arch-x86/hvm/save.h b/xen/include/public/arch-x86/hvm/save.h
index 40be84e..030499a 100644
--- a/xen/include/public/arch-x86/hvm/save.h
+++ b/xen/include/public/arch-x86/hvm/save.h
@@ -475,6 +475,12 @@ struct hvm_hw_pit {
         uint8_t status_latched;
         uint8_t status;
         uint8_t read_state;
+        /*
+	 * 在以下修改:
+	 *   - arch/x86/emul-i8254.c|359| <<pit_ioport_write>> s->write_state = access;
+	 *   - arch/x86/emul-i8254.c|386| <<pit_ioport_write>> s->write_state = RW_STATE_WORD1;
+	 *   - arch/x86/emul-i8254.c|390| <<pit_ioport_write>> s->write_state = RW_STATE_WORD0;
+	 */
         uint8_t write_state;
         uint8_t write_latch;
         uint8_t rw_mode;
-- 
2.17.1

